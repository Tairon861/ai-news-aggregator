<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 01 Aug 2025 18:34:46 +0000</lastBuildDate><item><title>How decades-old frozen embryos are changing the shape of families (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/08/01/1120911/decades-old-frozen-embryos-are-changing-the-shape-of-families/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/GettyImages-2112096911-crop.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;This week we welcomed a record-breaking baby to the world. Thaddeus Daniel Pierce, who arrived over the weekend, developed from an embryo that was frozen in storage for 30 and a half years. You could call him the world’s oldest baby.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;His parents, Lindsey and Tim Pierce, were themselves only young children when that embryo was created, all the way back in 1994.&lt;/strong&gt; Linda Archerd, who donated the embryo, described the experience as “surreal.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;Stories like this also highlight how reproductive technologies are shaping families. Thaddeus already has a 30-year-old sister and a 10-year-old niece. Lindsey and Tim are his birth parents, but his genes came from two other people who divorced decades ago.&lt;/p&gt;  &lt;p&gt;And while baby Thaddeus is a record-breaker, plenty of other babies have been born from embryos that have been frozen for significant spells of time.&lt;/p&gt; 
 &lt;p&gt;Thaddeus has taken the title of “world’s oldest baby” from the previous record-holders: twins Lydia Ann and Timothy Ronald Ridgeway, born in 2022, who developed from embryos that were created 30 years earlier, in 1992. Before that, the title was held by Molly Gibson, who developed from an embryo that was in storage for 27 years.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;These remarkable stories suggest there may be no limit to how long embryos can be stored. &lt;/strong&gt;Even after more than 30 years of being frozen at -196 °C (-321 °F), these tiny cells can be reanimated and develop into healthy babies. (Proponents of cryogenics can only &lt;em&gt;dream&lt;/em&gt; of achieving anything like this with grown people.)&lt;/p&gt; 
 &lt;p&gt;These stories also serve as a reminder that thanks to advances in cryopreservation and the ever-increasing popularity of IVF, a growing number of embryos are being stored in tanks. No one knows for sure how many there are, but there are millions of them.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Not all of them will be used in IVF.&lt;/strong&gt; There are plenty of reasons why someone who created embryos might never use them. Archerd says that while she had always planned to use all four of the embryos she created with her then husband, he didn’t want a bigger family. Some couples create embryos and then separate. Some people “age out” of being able to use their embryos themselves—many clinics refuse to transfer an embryo to people in their late 40s or older.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;What then? In most cases, people who have embryos they won’t use can choose to donate them, either to potential parents or for research, or discard them. Donation to other parents&amp;nbsp;tends to be the least popular option. (In some countries, none of those options are available, and unused embryos end up in a strange limbo—you can read more about that&amp;nbsp;here.)&lt;/p&gt;  &lt;p&gt;But some people, like Archerd, do donate their embryos. The recipients of those embryos will be the legal parents of the resulting children, but they won’t share a genetic link. The children might not ever meet their genetic “parents.” (Archerd is, however, very keen to meet Thaddeus.)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt;&lt;p&gt;Some people might have donated their embryos anonymously. But anonymity can never be guaranteed. Nowadays, consumer genetic tests allow anyone to search for family members—even if the people they track down thought they were making an anonymous donation 20 years ago, before these tests even existed.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;These kinds of tests have already resulted in surprise revelations that have disrupted families.&lt;/strong&gt; People who discover that they were conceived using a donated egg or sperm can find multiple long-lost siblings. One man who spoke at a major reproduction conference in 2024 said that since taking a DNA test,&amp;nbsp;he had found he had 50&amp;nbsp;of them.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The&amp;nbsp;general advice now is for parents to let their children know how they were conceived relatively early on.&lt;/p&gt;  &lt;p&gt;When I shared the story of baby Thaddeus on social media, a couple of people commented that they had concerns for the child. One person mentioned the age gap between Thaddeus and his 30-year-old sister. That person added that being donor conceived “isn’t easy.”&lt;/p&gt; 

 &lt;p&gt;For the record, that is not what researchers find when they evaluate donor-conceived children and their families. Studies find that embryo donation doesn’t affect parents’ attachment to a child&amp;nbsp;or their parenting style. And&amp;nbsp;donor-conceived children tend to be psychosocially well adjusted.&lt;/p&gt;  &lt;p&gt;Families come in all shapes and sizes. Reproductive technologies are extending the range of those shapes and sizes.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article first appeared in The Checkup,&amp;nbsp;&lt;/em&gt;MIT Technology Review’s&lt;em&gt;&amp;nbsp;weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first,&amp;nbsp;&lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;br /&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/GettyImages-2112096911-crop.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;This week we welcomed a record-breaking baby to the world. Thaddeus Daniel Pierce, who arrived over the weekend, developed from an embryo that was frozen in storage for 30 and a half years. You could call him the world’s oldest baby.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;His parents, Lindsey and Tim Pierce, were themselves only young children when that embryo was created, all the way back in 1994.&lt;/strong&gt; Linda Archerd, who donated the embryo, described the experience as “surreal.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;Stories like this also highlight how reproductive technologies are shaping families. Thaddeus already has a 30-year-old sister and a 10-year-old niece. Lindsey and Tim are his birth parents, but his genes came from two other people who divorced decades ago.&lt;/p&gt;  &lt;p&gt;And while baby Thaddeus is a record-breaker, plenty of other babies have been born from embryos that have been frozen for significant spells of time.&lt;/p&gt; 
 &lt;p&gt;Thaddeus has taken the title of “world’s oldest baby” from the previous record-holders: twins Lydia Ann and Timothy Ronald Ridgeway, born in 2022, who developed from embryos that were created 30 years earlier, in 1992. Before that, the title was held by Molly Gibson, who developed from an embryo that was in storage for 27 years.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;These remarkable stories suggest there may be no limit to how long embryos can be stored. &lt;/strong&gt;Even after more than 30 years of being frozen at -196 °C (-321 °F), these tiny cells can be reanimated and develop into healthy babies. (Proponents of cryogenics can only &lt;em&gt;dream&lt;/em&gt; of achieving anything like this with grown people.)&lt;/p&gt; 
 &lt;p&gt;These stories also serve as a reminder that thanks to advances in cryopreservation and the ever-increasing popularity of IVF, a growing number of embryos are being stored in tanks. No one knows for sure how many there are, but there are millions of them.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Not all of them will be used in IVF.&lt;/strong&gt; There are plenty of reasons why someone who created embryos might never use them. Archerd says that while she had always planned to use all four of the embryos she created with her then husband, he didn’t want a bigger family. Some couples create embryos and then separate. Some people “age out” of being able to use their embryos themselves—many clinics refuse to transfer an embryo to people in their late 40s or older.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;What then? In most cases, people who have embryos they won’t use can choose to donate them, either to potential parents or for research, or discard them. Donation to other parents&amp;nbsp;tends to be the least popular option. (In some countries, none of those options are available, and unused embryos end up in a strange limbo—you can read more about that&amp;nbsp;here.)&lt;/p&gt;  &lt;p&gt;But some people, like Archerd, do donate their embryos. The recipients of those embryos will be the legal parents of the resulting children, but they won’t share a genetic link. The children might not ever meet their genetic “parents.” (Archerd is, however, very keen to meet Thaddeus.)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt;&lt;p&gt;Some people might have donated their embryos anonymously. But anonymity can never be guaranteed. Nowadays, consumer genetic tests allow anyone to search for family members—even if the people they track down thought they were making an anonymous donation 20 years ago, before these tests even existed.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;These kinds of tests have already resulted in surprise revelations that have disrupted families.&lt;/strong&gt; People who discover that they were conceived using a donated egg or sperm can find multiple long-lost siblings. One man who spoke at a major reproduction conference in 2024 said that since taking a DNA test,&amp;nbsp;he had found he had 50&amp;nbsp;of them.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The&amp;nbsp;general advice now is for parents to let their children know how they were conceived relatively early on.&lt;/p&gt;  &lt;p&gt;When I shared the story of baby Thaddeus on social media, a couple of people commented that they had concerns for the child. One person mentioned the age gap between Thaddeus and his 30-year-old sister. That person added that being donor conceived “isn’t easy.”&lt;/p&gt; 

 &lt;p&gt;For the record, that is not what researchers find when they evaluate donor-conceived children and their families. Studies find that embryo donation doesn’t affect parents’ attachment to a child&amp;nbsp;or their parenting style. And&amp;nbsp;donor-conceived children tend to be psychosocially well adjusted.&lt;/p&gt;  &lt;p&gt;Families come in all shapes and sizes. Reproductive technologies are extending the range of those shapes and sizes.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article first appeared in The Checkup,&amp;nbsp;&lt;/em&gt;MIT Technology Review’s&lt;em&gt;&amp;nbsp;weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first,&amp;nbsp;&lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;br /&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/08/01/1120911/decades-old-frozen-embryos-are-changing-the-shape-of-families/</guid><pubDate>Fri, 01 Aug 2025 09:00:00 +0000</pubDate></item><item><title>[NEW] MLE-STAR: A state-of-the-art machine learning engineering agent (The latest research from Google)</title><link>https://research.google/blog/mle-star-a-state-of-the-art-machine-learning-engineering-agents/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Despite their promising initial strides, current MLE agents face several limitations that curtail their efficacy. First, their heavy reliance on pre-existing LLM knowledge often leads to a bias towards familiar and frequently used methods (e.g., the scikit-learn library for tabular data), overlooking potentially superior task-specific approaches. Furthermore, these agents typically employ an exploration strategy that modifies the entire code structure simultaneously in each iteration. This frequently causes agents to prematurely shift focus to other stages (e.g., model selection or hyperparameter tuning) because they lack the capacity for deep, iterative exploration within specific pipeline components, such as exhaustively experimenting with different feature engineering options.&lt;/p&gt;&lt;p&gt;In our recent paper, we introduce MLE-STAR, a novel ML engineering agent that integrates web search and targeted code block refinement. Unlike alternatives, MLE-STAR tackles ML challenges by first searching the web for proper models to get a solid foundation. It then carefully improves this foundation by testing which parts of the code are most important. MLE-STAR also utilizes a new method to blend several models together for even better results. This approach is very successful — it won medals in 63% of the Kaggle competitions in MLE-Bench-Lite, significantly outperforming the alternatives.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Despite their promising initial strides, current MLE agents face several limitations that curtail their efficacy. First, their heavy reliance on pre-existing LLM knowledge often leads to a bias towards familiar and frequently used methods (e.g., the scikit-learn library for tabular data), overlooking potentially superior task-specific approaches. Furthermore, these agents typically employ an exploration strategy that modifies the entire code structure simultaneously in each iteration. This frequently causes agents to prematurely shift focus to other stages (e.g., model selection or hyperparameter tuning) because they lack the capacity for deep, iterative exploration within specific pipeline components, such as exhaustively experimenting with different feature engineering options.&lt;/p&gt;&lt;p&gt;In our recent paper, we introduce MLE-STAR, a novel ML engineering agent that integrates web search and targeted code block refinement. Unlike alternatives, MLE-STAR tackles ML challenges by first searching the web for proper models to get a solid foundation. It then carefully improves this foundation by testing which parts of the code are most important. MLE-STAR also utilizes a new method to blend several models together for even better results. This approach is very successful — it won medals in 63% of the Kaggle competitions in MLE-Bench-Lite, significantly outperforming the alternatives.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/mle-star-a-state-of-the-art-machine-learning-engineering-agents/</guid><pubDate>Fri, 01 Aug 2025 10:00:00 +0000</pubDate></item><item><title>Google rolls out Gemini Deep Think AI, a reasoning model that tests multiple ideas in parallel (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/01/google-rolls-out-gemini-deep-think-ai-a-reasoning-model-that-tests-multiple-ideas-in-parallel/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google DeepMind is rolling out Gemini 2.5 Deep Think, which, the company says, is its most advanced AI reasoning model, able to answer questions by exploring and considering multiple ideas simultaneously and then using those outputs to choose the best answer.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Subscribers to Google’s $250-per-month Ultra subscription will gain access to Gemini 2.5 Deep Think in the Gemini app starting Friday.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;First unveiled in May at Google I/O 2025, Gemini 2.5 Deep Think is Google’s first publicly available multi-agent model. These systems spawn multiple AI agents to tackle a question in parallel, a process that uses significantly more computational resources than a single agent, but tends to result in better answers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google used a variation of Gemini 2.5 Deep Think to score a gold medal at this year’s International Math Olympiad (IMO).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside Gemini 2.5 Deep Think, the company says it is releasing the model it used at the IMO to a select group of mathematicians and academics. Google says this AI model “takes hours to reason,” instead of seconds or minutes like most consumer-facing AI models. The company hopes the IMO model will enhance research efforts, and aims to get feedback on how to improve the multi-agent system for academic use cases.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google notes that the Gemini 2.5 Deep Think model is a significant improvement over what it announced at I/O. The company also claims to have developed “novel reinforcement learning techniques” to encourage Gemini 2.5 Deep Think to make better use of its reasoning paths.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Deep Think can help people tackle problems that require creativity, strategic planning and making improvements step-by-step,” said Google in a blog post shared with TechCrunch.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The company says Gemini 2.5 Deep Think achieves state-of-the-art performance on Humanity’s Last Exam (HLE) — a challenging test measuring AI’s ability to answer thousands of crowdsourced questions across math, humanities, and science. Google claims its model scored 34.8% on HLE (without tools), compared to xAI’s Grok 4, which scored 25.4%, and OpenAI’s o3, which scored 20.3%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google also says Gemini 2.5 Deep Think outperforms AI models from OpenAI, xAI, and Anthropic on LiveCodeBench 6, a challenging test of competitive coding tasks. Google’s model scored 87.6%, whereas Grok 4 scored 79%, and OpenAI’s o3 scored 72%.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3033173" height="680" src="https://techcrunch.com/wp-content/uploads/2025/07/image.png?w=580" width="580" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Benchmark scores&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Gemini 2.5 Deep Think automatically works with tools such as code execution and Google Search, and the company says it’s capable of producing “much longer responses” than traditional AI models.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In Google’s testing, the model produced more detailed and aesthetically pleasing web development tasks compared to other AI models. The company claims the model could aid researchers and “potentially accelerate the path to discovery.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3033177" height="442" src="https://techcrunch.com/wp-content/uploads/2025/08/Screenshot-2025-07-31-at-5.31.36PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Art scenes made by Google’s AI&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;It seems that several leading AI labs are converging around the multi-agent approach.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Elon Musk’s xAI recently released a multi-agent system of its own, Grok 4 Heavy, which it says was able to achieve industry-leading performance on several benchmarks. OpenAI researcher Noam Brown said on a podcast that the unreleased AI model the company used to achieve a gold medal at this year’s International Math Olympiad was also a multi-agent system. Meanwhile, Anthropic’s Research agent, which generates thorough research briefs, is also powered by a multi-agent system.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite the strong performance, it seems that multi-agent systems are even costlier to serve than traditional AI models. That means tech companies may keep these systems gated behind their most expensive subscription plans, which xAI and now Google have chosen to do.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the coming weeks, Google says it plans to share Gemini 2.5 Deep Think with a select group of testers via the Gemini API. The company says it wants to better understand how developers and enterprises may use its multi-agent system.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google DeepMind is rolling out Gemini 2.5 Deep Think, which, the company says, is its most advanced AI reasoning model, able to answer questions by exploring and considering multiple ideas simultaneously and then using those outputs to choose the best answer.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Subscribers to Google’s $250-per-month Ultra subscription will gain access to Gemini 2.5 Deep Think in the Gemini app starting Friday.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;First unveiled in May at Google I/O 2025, Gemini 2.5 Deep Think is Google’s first publicly available multi-agent model. These systems spawn multiple AI agents to tackle a question in parallel, a process that uses significantly more computational resources than a single agent, but tends to result in better answers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google used a variation of Gemini 2.5 Deep Think to score a gold medal at this year’s International Math Olympiad (IMO).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside Gemini 2.5 Deep Think, the company says it is releasing the model it used at the IMO to a select group of mathematicians and academics. Google says this AI model “takes hours to reason,” instead of seconds or minutes like most consumer-facing AI models. The company hopes the IMO model will enhance research efforts, and aims to get feedback on how to improve the multi-agent system for academic use cases.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google notes that the Gemini 2.5 Deep Think model is a significant improvement over what it announced at I/O. The company also claims to have developed “novel reinforcement learning techniques” to encourage Gemini 2.5 Deep Think to make better use of its reasoning paths.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Deep Think can help people tackle problems that require creativity, strategic planning and making improvements step-by-step,” said Google in a blog post shared with TechCrunch.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The company says Gemini 2.5 Deep Think achieves state-of-the-art performance on Humanity’s Last Exam (HLE) — a challenging test measuring AI’s ability to answer thousands of crowdsourced questions across math, humanities, and science. Google claims its model scored 34.8% on HLE (without tools), compared to xAI’s Grok 4, which scored 25.4%, and OpenAI’s o3, which scored 20.3%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google also says Gemini 2.5 Deep Think outperforms AI models from OpenAI, xAI, and Anthropic on LiveCodeBench 6, a challenging test of competitive coding tasks. Google’s model scored 87.6%, whereas Grok 4 scored 79%, and OpenAI’s o3 scored 72%.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3033173" height="680" src="https://techcrunch.com/wp-content/uploads/2025/07/image.png?w=580" width="580" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Benchmark scores&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Gemini 2.5 Deep Think automatically works with tools such as code execution and Google Search, and the company says it’s capable of producing “much longer responses” than traditional AI models.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In Google’s testing, the model produced more detailed and aesthetically pleasing web development tasks compared to other AI models. The company claims the model could aid researchers and “potentially accelerate the path to discovery.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3033177" height="442" src="https://techcrunch.com/wp-content/uploads/2025/08/Screenshot-2025-07-31-at-5.31.36PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Art scenes made by Google’s AI&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;It seems that several leading AI labs are converging around the multi-agent approach.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Elon Musk’s xAI recently released a multi-agent system of its own, Grok 4 Heavy, which it says was able to achieve industry-leading performance on several benchmarks. OpenAI researcher Noam Brown said on a podcast that the unreleased AI model the company used to achieve a gold medal at this year’s International Math Olympiad was also a multi-agent system. Meanwhile, Anthropic’s Research agent, which generates thorough research briefs, is also powered by a multi-agent system.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite the strong performance, it seems that multi-agent systems are even costlier to serve than traditional AI models. That means tech companies may keep these systems gated behind their most expensive subscription plans, which xAI and now Google have chosen to do.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the coming weeks, Google says it plans to share Gemini 2.5 Deep Think with a select group of testers via the Gemini API. The company says it wants to better understand how developers and enterprises may use its multi-agent system.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/01/google-rolls-out-gemini-deep-think-ai-a-reasoning-model-that-tests-multiple-ideas-in-parallel/</guid><pubDate>Fri, 01 Aug 2025 11:00:00 +0000</pubDate></item><item><title>Try Deep Think in the Gemini app (Google DeepMind Blog)</title><link>https://deepmind.google/discover/blog/try-deep-think-in-the-gemini-app/</link><description>&lt;div class="article-image-hero"&gt;
  &lt;div class="article-image-hero__container"&gt;
    &lt;figure class="article-image--full-aspect article-module"&gt;
      &lt;div class="aspect-ratio-image"&gt;
        &lt;div class="aspect-ratio-image__container"&gt;
          &lt;img alt="Gemini 2.5 Deep Think" class="aspect-ratio-image__image uni-progressive-image--blur" height="150px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2-5-deep-think_blog_header.width-2200.format-webp.webp" width="360px" /&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      
    &lt;/figure&gt;
  &lt;/div&gt;
&lt;/div&gt;&lt;div class="uni-content uni-blog-article-container article-container__content
                      
                      "&gt;

            
              







            

            
            
&lt;!--article text--&gt;

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Today, we’re making Deep Think available in the Gemini app to Google AI Ultra subscribers – the latest in a lineup of extremely capable AI tools and features made exclusively available to them.&lt;/p&gt;&lt;p&gt;This new release incorporates feedback from early trusted testers and research breakthroughs. It’s a significant improvement over what was first announced at I/O, as measured in terms of key benchmark improvements and trusted tester feedback. It is a variation of the model that recently achieved the gold-medal standard at this year’s International Mathematical Olympiad (IMO). While that model takes hours to reason about complex math problems, today’s release is faster and more usable day-to-day, while still reaching Bronze-level performance on the 2025 IMO benchmark, based on internal evaluations.&lt;/p&gt;&lt;p&gt;Deep Think could be a powerful tool in creative problem solving:&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;As we put Deep Think in the hands of Google AI Ultra subscribers, we’re also sharing the official version of the Gemini 2.5 Deep Think model that achieved the gold-medal standard with a small group of mathematicians and academics. We look forward to hearing how it could enhance their research and inquiry, and we’ll use their feedback as we continue to improve this offering.&lt;/p&gt;&lt;p&gt;This release represents a significant step forward in our mission to build more helpful and capable AI, and furthers our commitment to using Gemini to push the frontier of human knowledge.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;How Deep Think works: extending Gemini’s parallel “thinking time”&lt;/h2&gt;&lt;p&gt;Just as people tackle complex problems by taking the time to explore different angles, weigh potential solutions, and refine a final answer, Deep Think pushes the frontier of thinking capabilities by using parallel thinking techniques. This approach lets Gemini generate many ideas at once and consider them simultaneously, even revising or combining different ideas over time, before arriving at the best answer.&lt;/p&gt;&lt;p&gt;Moreover, by extending the inference time or "thinking time," we give Gemini more time to explore different hypotheses, and arrive at creative solutions to complex problems.&lt;/p&gt;&lt;p&gt;We’ve also developed novel reinforcement learning techniques that encourage the model to make use of these extended reasoning paths, thus enabling Deep Think to become a better, more intuitive problem-solver over time.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;How Deep Think stacks up: state-of-the-art performance&lt;/h2&gt;&lt;p&gt;Deep Think can help people tackle problems that require creativity, strategic planning and making improvements step-by-step, such as:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Iterative development and design:&lt;/b&gt; We’ve been impressed by Deep Think’s performance on tasks that require building something complex, piece by piece. For example, we’ve observed Deep Think can improve both the aesthetics and functionality of web development tasks.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    















  
    &lt;div&gt;
      &lt;div class="rich-text"&gt;&lt;p&gt;Deep Think in the Gemini app uses parallel thinking techniques to deliver more detailed, creative and thoughtful responses.&lt;/p&gt;&lt;/div&gt;
    &lt;/div&gt;
  
  
    &lt;div&gt;
      &lt;img alt="A comparison of three AI-generated voxel art scenes. Each image shows a pagoda in a garden with trees and cherry blossoms, demonstrating increasing detail and complexity from left to right. The images are labeled &amp;quot;Gemini 2.5 Flash,&amp;quot; &amp;quot;Gemini 2.5 Pro,&amp;quot; and &amp;quot;Gemini 2.5 Deep Think.&amp;quot;" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2-5-deep-think_blog-image_pagoda_.width-1000.format-webp.webp" /&gt;
    &lt;/div&gt;
  



  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Scientific and mathematical discovery:&lt;/b&gt; Because it can reason through highly complex problems, Deep Think can be a powerful tool for researchers. It can help formulate and explore mathematical conjectures or reason through complex scientific literature, potentially accelerating the path to discovery.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Algorithmic development and code:&lt;/b&gt; Deep Think particularly excels at tough coding problems in which problem formulation and careful consideration of tradeoffs and time complexity is paramount.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Deep Think’s performance is also reflected in challenging benchmarks that measure coding, science, knowledge and reasoning capabilities. For example, compared to other models without tool use, Gemini 2.5 Deep Think achieves state-of-the-art performance across LiveCodeBench V6, which measures competitive code performance, and Humanity’s Last Exam, a challenging benchmark that measures expertise in different domains, including science and math.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    















  
  
    &lt;div&gt;
      &lt;img alt="A set of four bar charts comparing AI model performance. Gemini 2.5 is the top performer in reasoning, code, and math benchmarks against Gemini 2.5 Pro, OpenAI 03, and Grok 4." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/all_benchmarks_blog.width-1000.format-webp.webp" /&gt;
    &lt;/div&gt;
  



  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;How we’re advancing Gemini responsibly&lt;/h2&gt;&lt;p&gt;We continue to build safety and responsibility into Gemini throughout the training and deployment lifecycle. In testing, Gemini 2.5 Deep Think demonstrated improved content safety and tone-objectivity compared to Gemini 2.5 Pro, but did have a higher tendency to refuse benign requests.&lt;/p&gt;&lt;p&gt;As Gemini's problem-solving abilities advance, we are taking a deeper look at risks that come with increased complexity, including our frontier safety evaluations and the implementation of planned mitigations for critical capability levels.&lt;/p&gt;&lt;p&gt;Further details on the safety outcomes of Gemini 2.5 Deep Think are available in the model card.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;How to use Deep Think in the Gemini app today&lt;/h2&gt;&lt;p&gt;If you’re a Google AI Ultra subscriber, you can use Deep Think in the Gemini app today with a fixed set of prompts a day by toggling “Deep Think” in the prompt bar when selecting 2.5 Pro in the model drop down. Deep Think automatically works with tools such as code execution and Google Search, and can produce much longer responses.&lt;/p&gt;&lt;p&gt;We are also working to release Deep Think with and without tools to a set of trusted testers via the Gemini API in the coming weeks, to better understand its usability for developer and enterprise use cases.&lt;/p&gt;&lt;p&gt;Teams at nearly every layer of the stack, from research to deployment, have worked to make Deep Think faster, more reliable, and user friendly for Gemini app users. We can’t wait to see what you build with it.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  


            
            

            
              


&lt;div class="
    uni-blog-article-tags
    article-tags
    
  "&gt;
  &lt;div class="uni-blog-article-tags__wrapper"&gt;
    &lt;span class="uni-blog-article-tags__label uni-eyebrow"&gt;POSTED IN:&lt;/span&gt;
  &lt;/div&gt;
  &lt;nav class="uni-blog-article-tags__container uni-click-tracker"&gt;
    &lt;ul class="uni-blog-article-tags__tags-list"&gt;
    
      &lt;li&gt;
        
        
        


  


Gemini Models


  


      &lt;/li&gt;
    

    
      &lt;li&gt;
        
        
        


  


Gemini App


  


      &lt;/li&gt;
    
      &lt;li&gt;
        
        
        


  


Google DeepMind


  


      &lt;/li&gt;
    
    &lt;/ul&gt;
  &lt;/nav&gt;
&lt;/div&gt;

            
          &lt;/div&gt;</description><content:encoded>&lt;div class="article-image-hero"&gt;
  &lt;div class="article-image-hero__container"&gt;
    &lt;figure class="article-image--full-aspect article-module"&gt;
      &lt;div class="aspect-ratio-image"&gt;
        &lt;div class="aspect-ratio-image__container"&gt;
          &lt;img alt="Gemini 2.5 Deep Think" class="aspect-ratio-image__image uni-progressive-image--blur" height="150px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2-5-deep-think_blog_header.width-2200.format-webp.webp" width="360px" /&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      
    &lt;/figure&gt;
  &lt;/div&gt;
&lt;/div&gt;&lt;div class="uni-content uni-blog-article-container article-container__content
                      
                      "&gt;

            
              







            

            
            
&lt;!--article text--&gt;

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Today, we’re making Deep Think available in the Gemini app to Google AI Ultra subscribers – the latest in a lineup of extremely capable AI tools and features made exclusively available to them.&lt;/p&gt;&lt;p&gt;This new release incorporates feedback from early trusted testers and research breakthroughs. It’s a significant improvement over what was first announced at I/O, as measured in terms of key benchmark improvements and trusted tester feedback. It is a variation of the model that recently achieved the gold-medal standard at this year’s International Mathematical Olympiad (IMO). While that model takes hours to reason about complex math problems, today’s release is faster and more usable day-to-day, while still reaching Bronze-level performance on the 2025 IMO benchmark, based on internal evaluations.&lt;/p&gt;&lt;p&gt;Deep Think could be a powerful tool in creative problem solving:&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;As we put Deep Think in the hands of Google AI Ultra subscribers, we’re also sharing the official version of the Gemini 2.5 Deep Think model that achieved the gold-medal standard with a small group of mathematicians and academics. We look forward to hearing how it could enhance their research and inquiry, and we’ll use their feedback as we continue to improve this offering.&lt;/p&gt;&lt;p&gt;This release represents a significant step forward in our mission to build more helpful and capable AI, and furthers our commitment to using Gemini to push the frontier of human knowledge.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;How Deep Think works: extending Gemini’s parallel “thinking time”&lt;/h2&gt;&lt;p&gt;Just as people tackle complex problems by taking the time to explore different angles, weigh potential solutions, and refine a final answer, Deep Think pushes the frontier of thinking capabilities by using parallel thinking techniques. This approach lets Gemini generate many ideas at once and consider them simultaneously, even revising or combining different ideas over time, before arriving at the best answer.&lt;/p&gt;&lt;p&gt;Moreover, by extending the inference time or "thinking time," we give Gemini more time to explore different hypotheses, and arrive at creative solutions to complex problems.&lt;/p&gt;&lt;p&gt;We’ve also developed novel reinforcement learning techniques that encourage the model to make use of these extended reasoning paths, thus enabling Deep Think to become a better, more intuitive problem-solver over time.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;How Deep Think stacks up: state-of-the-art performance&lt;/h2&gt;&lt;p&gt;Deep Think can help people tackle problems that require creativity, strategic planning and making improvements step-by-step, such as:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Iterative development and design:&lt;/b&gt; We’ve been impressed by Deep Think’s performance on tasks that require building something complex, piece by piece. For example, we’ve observed Deep Think can improve both the aesthetics and functionality of web development tasks.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    















  
    &lt;div&gt;
      &lt;div class="rich-text"&gt;&lt;p&gt;Deep Think in the Gemini app uses parallel thinking techniques to deliver more detailed, creative and thoughtful responses.&lt;/p&gt;&lt;/div&gt;
    &lt;/div&gt;
  
  
    &lt;div&gt;
      &lt;img alt="A comparison of three AI-generated voxel art scenes. Each image shows a pagoda in a garden with trees and cherry blossoms, demonstrating increasing detail and complexity from left to right. The images are labeled &amp;quot;Gemini 2.5 Flash,&amp;quot; &amp;quot;Gemini 2.5 Pro,&amp;quot; and &amp;quot;Gemini 2.5 Deep Think.&amp;quot;" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2-5-deep-think_blog-image_pagoda_.width-1000.format-webp.webp" /&gt;
    &lt;/div&gt;
  



  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Scientific and mathematical discovery:&lt;/b&gt; Because it can reason through highly complex problems, Deep Think can be a powerful tool for researchers. It can help formulate and explore mathematical conjectures or reason through complex scientific literature, potentially accelerating the path to discovery.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Algorithmic development and code:&lt;/b&gt; Deep Think particularly excels at tough coding problems in which problem formulation and careful consideration of tradeoffs and time complexity is paramount.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Deep Think’s performance is also reflected in challenging benchmarks that measure coding, science, knowledge and reasoning capabilities. For example, compared to other models without tool use, Gemini 2.5 Deep Think achieves state-of-the-art performance across LiveCodeBench V6, which measures competitive code performance, and Humanity’s Last Exam, a challenging benchmark that measures expertise in different domains, including science and math.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    















  
  
    &lt;div&gt;
      &lt;img alt="A set of four bar charts comparing AI model performance. Gemini 2.5 is the top performer in reasoning, code, and math benchmarks against Gemini 2.5 Pro, OpenAI 03, and Grok 4." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/all_benchmarks_blog.width-1000.format-webp.webp" /&gt;
    &lt;/div&gt;
  



  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;How we’re advancing Gemini responsibly&lt;/h2&gt;&lt;p&gt;We continue to build safety and responsibility into Gemini throughout the training and deployment lifecycle. In testing, Gemini 2.5 Deep Think demonstrated improved content safety and tone-objectivity compared to Gemini 2.5 Pro, but did have a higher tendency to refuse benign requests.&lt;/p&gt;&lt;p&gt;As Gemini's problem-solving abilities advance, we are taking a deeper look at risks that come with increased complexity, including our frontier safety evaluations and the implementation of planned mitigations for critical capability levels.&lt;/p&gt;&lt;p&gt;Further details on the safety outcomes of Gemini 2.5 Deep Think are available in the model card.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;How to use Deep Think in the Gemini app today&lt;/h2&gt;&lt;p&gt;If you’re a Google AI Ultra subscriber, you can use Deep Think in the Gemini app today with a fixed set of prompts a day by toggling “Deep Think” in the prompt bar when selecting 2.5 Pro in the model drop down. Deep Think automatically works with tools such as code execution and Google Search, and can produce much longer responses.&lt;/p&gt;&lt;p&gt;We are also working to release Deep Think with and without tools to a set of trusted testers via the Gemini API in the coming weeks, to better understand its usability for developer and enterprise use cases.&lt;/p&gt;&lt;p&gt;Teams at nearly every layer of the stack, from research to deployment, have worked to make Deep Think faster, more reliable, and user friendly for Gemini app users. We can’t wait to see what you build with it.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  


            
            

            
              


&lt;div class="
    uni-blog-article-tags
    article-tags
    
  "&gt;
  &lt;div class="uni-blog-article-tags__wrapper"&gt;
    &lt;span class="uni-blog-article-tags__label uni-eyebrow"&gt;POSTED IN:&lt;/span&gt;
  &lt;/div&gt;
  &lt;nav class="uni-blog-article-tags__container uni-click-tracker"&gt;
    &lt;ul class="uni-blog-article-tags__tags-list"&gt;
    
      &lt;li&gt;
        
        
        


  


Gemini Models


  


      &lt;/li&gt;
    

    
      &lt;li&gt;
        
        
        


  


Gemini App


  


      &lt;/li&gt;
    
      &lt;li&gt;
        
        
        


  


Google DeepMind


  


      &lt;/li&gt;
    
    &lt;/ul&gt;
  &lt;/nav&gt;
&lt;/div&gt;

            
          &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://deepmind.google/discover/blog/try-deep-think-in-the-gemini-app/</guid><pubDate>Fri, 01 Aug 2025 11:09:35 +0000</pubDate></item><item><title>Leak suggests OpenAI’s open-source AI model release is imminent (AI News)</title><link>https://www.artificialintelligence-news.com/news/leak-openai-open-source-ai-model-release-imminent/</link><description>&lt;p&gt;A leak suggests that OpenAI is about to launch a powerful new open-source AI model, potentially within hours.&lt;/p&gt;&lt;p&gt;The evidence comes from a trail of digital breadcrumbs, eagerly pored over by developers. At the centre of it all are screenshots showing a series of model repositories with names like yofo-deepcurrent/gpt-oss-120b and yofo-wildflower/gpt-oss-20b. The repos have since been deleted, but the accounts feature OpenAI team members.&lt;/p&gt;&lt;p&gt;That gpt-oss tag is the real smoking gun, seemingly a clear signpost for ‘GPT Open Source Software’. For a company that has increasingly guarded its top-tier models, this would be somewhat of a return to its roots. The fact that we are seeing multiple versions, with different codenames and sizes, suggests a well-planned family of models are about to make their debut.&lt;/p&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Screenshot of alleged leaked repos for OpenAI's open-source AI model that is set for imminent launch." class="wp-image-107267" height="1024" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/openai-open-source-ai-model-open-source-artificial-intelligence-leak-gpt-679x1024.jpeg" width="679" /&gt;&lt;/figure&gt;&lt;p&gt;Thanks to a leaked configuration file, we can even peek under the bonnet of the suspected 120 billion parameter version.&lt;/p&gt;&lt;p&gt;The model appears to be built on a Mixture of Experts, or MoE, architecture. Think of it less like a single, monolithic brain trying to know everything, and more like a board of 128 specialist advisors. When a query comes in, the system intelligently selects the four best experts for the job. This gives the model the vast knowledge of its huge parameter count, but the speed and agility of a much smaller system, as only a fraction of it is working at any one time.&lt;/p&gt;&lt;p&gt;This design puts OpenAI’s open-source AI model squarely in competition with the darlings of the scene, like Mistral AI’s Mixtral and Meta’s Llama family.&lt;/p&gt;&lt;p&gt;And the specs don’t stop there. OpenAI’s open-source AI model appears to boast a huge vocabulary, which should make it more efficient with a wider range of languages, and uses Sliding Window Attention to handle long streams of text without breaking a sweat. In practice, this all points to a model that is both powerful and practical to run.&lt;/p&gt;&lt;p&gt;So, why would OpenAI make such a move now? For years, the company has faced gentle jabs and outright criticism for straying from its more open beginnings. Launching a powerful gpt-oss would be a massive charm offensive aimed directly at the developers and researchers who felt left behind.&lt;/p&gt;&lt;p&gt;Of course, it’s also a shrewd competitive play. Meta and Mistral have shown how a thriving open-source ecosystem can drive innovation. By dropping a powerful open-source AI model like this appears to be into the mix, OpenAI isn’t just joining the race; it’s attempting to redefine the track.&lt;/p&gt;&lt;p&gt;Until we get the official word from OpenAI, this is all still, technically, rumour. But it’s a rumour with substance, backed by code and configuration files.&lt;/p&gt;&lt;p&gt;The launch of a high-performance, 120-billion-parameter open-source MoE model from the most famous name in AI would be nothing short of a landmark event, and it appears to be imminent.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Mariia Shalabaieva)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Zuckerberg outlines Meta’s AI vision for ‘personal superintelligence’&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;A leak suggests that OpenAI is about to launch a powerful new open-source AI model, potentially within hours.&lt;/p&gt;&lt;p&gt;The evidence comes from a trail of digital breadcrumbs, eagerly pored over by developers. At the centre of it all are screenshots showing a series of model repositories with names like yofo-deepcurrent/gpt-oss-120b and yofo-wildflower/gpt-oss-20b. The repos have since been deleted, but the accounts feature OpenAI team members.&lt;/p&gt;&lt;p&gt;That gpt-oss tag is the real smoking gun, seemingly a clear signpost for ‘GPT Open Source Software’. For a company that has increasingly guarded its top-tier models, this would be somewhat of a return to its roots. The fact that we are seeing multiple versions, with different codenames and sizes, suggests a well-planned family of models are about to make their debut.&lt;/p&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Screenshot of alleged leaked repos for OpenAI's open-source AI model that is set for imminent launch." class="wp-image-107267" height="1024" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/openai-open-source-ai-model-open-source-artificial-intelligence-leak-gpt-679x1024.jpeg" width="679" /&gt;&lt;/figure&gt;&lt;p&gt;Thanks to a leaked configuration file, we can even peek under the bonnet of the suspected 120 billion parameter version.&lt;/p&gt;&lt;p&gt;The model appears to be built on a Mixture of Experts, or MoE, architecture. Think of it less like a single, monolithic brain trying to know everything, and more like a board of 128 specialist advisors. When a query comes in, the system intelligently selects the four best experts for the job. This gives the model the vast knowledge of its huge parameter count, but the speed and agility of a much smaller system, as only a fraction of it is working at any one time.&lt;/p&gt;&lt;p&gt;This design puts OpenAI’s open-source AI model squarely in competition with the darlings of the scene, like Mistral AI’s Mixtral and Meta’s Llama family.&lt;/p&gt;&lt;p&gt;And the specs don’t stop there. OpenAI’s open-source AI model appears to boast a huge vocabulary, which should make it more efficient with a wider range of languages, and uses Sliding Window Attention to handle long streams of text without breaking a sweat. In practice, this all points to a model that is both powerful and practical to run.&lt;/p&gt;&lt;p&gt;So, why would OpenAI make such a move now? For years, the company has faced gentle jabs and outright criticism for straying from its more open beginnings. Launching a powerful gpt-oss would be a massive charm offensive aimed directly at the developers and researchers who felt left behind.&lt;/p&gt;&lt;p&gt;Of course, it’s also a shrewd competitive play. Meta and Mistral have shown how a thriving open-source ecosystem can drive innovation. By dropping a powerful open-source AI model like this appears to be into the mix, OpenAI isn’t just joining the race; it’s attempting to redefine the track.&lt;/p&gt;&lt;p&gt;Until we get the official word from OpenAI, this is all still, technically, rumour. But it’s a rumour with substance, backed by code and configuration files.&lt;/p&gt;&lt;p&gt;The launch of a high-performance, 120-billion-parameter open-source MoE model from the most famous name in AI would be nothing short of a landmark event, and it appears to be imminent.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Mariia Shalabaieva)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Zuckerberg outlines Meta’s AI vision for ‘personal superintelligence’&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/leak-openai-open-source-ai-model-release-imminent/</guid><pubDate>Fri, 01 Aug 2025 12:03:44 +0000</pubDate></item><item><title>The Download: how fertility tech is changing families, and Trump’s latest tariffs (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/08/01/1120918/the-download-how-fertility-tech-is-changing-families-and-trumps-latest-tariffs/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;How decades-old frozen embryos are changing the shape of families&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;This week we welcomed a record-breaking baby to the world. Thaddeus Daniel Pierce, who arrived over the weekend, developed from an embryo that was frozen in storage for 30 and a half years. You could call him the world’s oldest baby.&lt;/p&gt;&lt;p&gt;His parents, Lindsey and Tim Pierce, were themselves only young children when that embryo was created, all the way back in 1994. Linda Archerd, who donated the embryo, described the experience as “surreal.”&lt;/p&gt;&lt;p&gt;Stories like this also highlight how reproductive technologies are shaping families. But while baby Thaddeus is a record-breaker, plenty of other babies have been born from embryos that have been frozen for significant spells of time.&lt;strong&gt; &lt;/strong&gt;Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Jessica Hamzelou&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;This article first appeared in The Checkup, MIT Technology Review’s weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;&lt;strong&gt;If you’re interested in reading more about fertility tech, why not check out:&lt;/strong&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;+ Earlier this month, researchers announced babies had been born from a trial of three-person IVF. The long-awaited results suggest that the approach can reduce the risk of mitochondrial disease—but not everyone is convinced.&lt;/p&gt;&lt;p&gt;+ Frozen embryos are filling storage banks around the world. It's a struggle to know what to do with them.&lt;/p&gt;&lt;p&gt;+ Read about how a mobile lab is bringing IVF to rural communities in South Africa.&lt;/p&gt;  &lt;p&gt;+ Why family-friendly policies and gender equality might be more helpful than IVF technology when it comes to averting the looming fertility crisis.&lt;/p&gt;&lt;p&gt;+ The first babies conceived with a sperm-injecting robot have been born. Meet the startups trying to engineer a desktop fertility machine.&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Donald Trump has announced new tariffs across the world&lt;/strong&gt;&lt;br /&gt;They will affect virtually every nation—some more favorably than others. (CNN)&lt;br /&gt;+ &lt;em&gt;The new rates range widely from 10% to 41%. &lt;/em&gt;(NYT $)&lt;br /&gt;+ &lt;em&gt;The African country Lesotho had declared a tariff-induced state of emergency. &lt;/em&gt;(WSJ $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 Palantir has signed a $10 billion deal with the US Army&lt;/strong&gt;&lt;br /&gt;It’s the latest in a string of lucrative agreements with federal agencies. (WP $)&lt;br /&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;&lt;strong&gt;3 Tech giants are raking in cash&lt;/strong&gt;&lt;br /&gt;But we still don’t know how useful a lot of the AI they’re currently building will prove to be. (FT $)&lt;br /&gt;+ &lt;em&gt;It’s a boon for investors, but not necessarily for employees. &lt;/em&gt;(WSJ $)&lt;br /&gt;+ &lt;em&gt;It's unclear whose approach will result in sustainable profits. &lt;/em&gt;(Semafor)&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;&lt;br /&gt;&lt;strong&gt;4&lt;/strong&gt; &lt;strong&gt;Neuralink is planning its first trial in the UK&lt;/strong&gt;&lt;br /&gt;To join the current five patients using its brain implant. (Reuters)&lt;br /&gt;+ &lt;em&gt;This patient’s Neuralink brain implant gets a boost from generative AI. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;strong&gt;5 US states are working to preserve access to lifesaving vaccines&lt;/strong&gt;&lt;br /&gt;Despite the shifting federal recommendations. (Wired $)&lt;br /&gt;+ &lt;em&gt;The FDA plans to limit access to covid vaccines. Here’s why that’s not all bad. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 Vast online groups in China are sharing explicit photos of women&lt;/strong&gt;&lt;br /&gt;Non-consensual images are being passed around hundreds of thousands of men. (The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Reddit wants to be a search engine&lt;/strong&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;In response to the AI-ification of other platforms. (The Verge)&lt;br /&gt;+ &lt;em&gt;AI means the end of internet search as we’ve known it. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 Why airships could be a viable internet satellite alternative&lt;/strong&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;It could result in less space junk, for one. (IEEE Spectrum)&lt;br /&gt;+ &lt;em&gt;Welcome to the big blimp boom. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;9 Trust in AI coding tools is falling&lt;/strong&gt;&lt;br /&gt;The majority of devs use them, but they aren’t always reliable. (Ars Technica)&lt;br /&gt;+ &lt;em&gt;What is vibe coding, exactly? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 Weight-loss drugs could help to slow down aging&lt;/strong&gt;&lt;br /&gt;New trials suggest recipients can become biologically younger. (New Scientist $)&lt;br /&gt;+ &lt;em&gt;Aging hits us in our 40s and 60s. But well-being doesn’t have to fall off a cliff. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p class="has-large-font-size"&gt;&lt;strong&gt;“We look forward to joining Matt on his private island next year.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Kiana Ehsani, CEO of AI agent startup Vercept, jokes about the departure of fellow co-founder Matt Deitke to join Meta’s superintelligence team for a cool $250 million, the New York Times reports.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;br /&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcslIpHrRduW9THwxoTWUKCT52mhzY0X0o3vCVCEZlnHx-VcBl4capWQvWUgVap8RS1z4ZiE4P82n202eA-HezO2ALXA03yXGn9fbQwyP83CRAFh5wBlL3YibJ_cFfwjceJzsYu?key=GN7j3j340HzjVEb3MsqxFA" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;How ChatGPT will revolutionize the economy&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;There’s a gold rush underway to make money from generative AI models like ChatGPT. You can practically hear the shrieks from corner offices around the world: “What is our ChatGPT play? How do we make money off this?”&lt;/p&gt;&lt;p&gt;But while companies and executives want to cash in, the likely impact of generative AI on workers and the economy on the whole is far less obvious.&lt;/p&gt;&lt;p&gt;Will ChatGPT make the already troubling income and wealth inequality in the US and many other countries even worse, or could it in fact provide a much-needed boost to productivity? Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—David Rotman&lt;/em&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;+ Yikes—a gigantic stick insect has been discovered in (where else?) Australia.&lt;br /&gt;+ This X account shares random, mundane objects each day&lt;br /&gt;+ If you love a good skyscraper, these are the cities where you’re most likely to encounter them.&lt;br /&gt;+ Yum, ancient Pompeii honey 🍯&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;How decades-old frozen embryos are changing the shape of families&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;This week we welcomed a record-breaking baby to the world. Thaddeus Daniel Pierce, who arrived over the weekend, developed from an embryo that was frozen in storage for 30 and a half years. You could call him the world’s oldest baby.&lt;/p&gt;&lt;p&gt;His parents, Lindsey and Tim Pierce, were themselves only young children when that embryo was created, all the way back in 1994. Linda Archerd, who donated the embryo, described the experience as “surreal.”&lt;/p&gt;&lt;p&gt;Stories like this also highlight how reproductive technologies are shaping families. But while baby Thaddeus is a record-breaker, plenty of other babies have been born from embryos that have been frozen for significant spells of time.&lt;strong&gt; &lt;/strong&gt;Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Jessica Hamzelou&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;This article first appeared in The Checkup, MIT Technology Review’s weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;&lt;strong&gt;If you’re interested in reading more about fertility tech, why not check out:&lt;/strong&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;+ Earlier this month, researchers announced babies had been born from a trial of three-person IVF. The long-awaited results suggest that the approach can reduce the risk of mitochondrial disease—but not everyone is convinced.&lt;/p&gt;&lt;p&gt;+ Frozen embryos are filling storage banks around the world. It's a struggle to know what to do with them.&lt;/p&gt;&lt;p&gt;+ Read about how a mobile lab is bringing IVF to rural communities in South Africa.&lt;/p&gt;  &lt;p&gt;+ Why family-friendly policies and gender equality might be more helpful than IVF technology when it comes to averting the looming fertility crisis.&lt;/p&gt;&lt;p&gt;+ The first babies conceived with a sperm-injecting robot have been born. Meet the startups trying to engineer a desktop fertility machine.&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Donald Trump has announced new tariffs across the world&lt;/strong&gt;&lt;br /&gt;They will affect virtually every nation—some more favorably than others. (CNN)&lt;br /&gt;+ &lt;em&gt;The new rates range widely from 10% to 41%. &lt;/em&gt;(NYT $)&lt;br /&gt;+ &lt;em&gt;The African country Lesotho had declared a tariff-induced state of emergency. &lt;/em&gt;(WSJ $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 Palantir has signed a $10 billion deal with the US Army&lt;/strong&gt;&lt;br /&gt;It’s the latest in a string of lucrative agreements with federal agencies. (WP $)&lt;br /&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;&lt;strong&gt;3 Tech giants are raking in cash&lt;/strong&gt;&lt;br /&gt;But we still don’t know how useful a lot of the AI they’re currently building will prove to be. (FT $)&lt;br /&gt;+ &lt;em&gt;It’s a boon for investors, but not necessarily for employees. &lt;/em&gt;(WSJ $)&lt;br /&gt;+ &lt;em&gt;It's unclear whose approach will result in sustainable profits. &lt;/em&gt;(Semafor)&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;&lt;br /&gt;&lt;strong&gt;4&lt;/strong&gt; &lt;strong&gt;Neuralink is planning its first trial in the UK&lt;/strong&gt;&lt;br /&gt;To join the current five patients using its brain implant. (Reuters)&lt;br /&gt;+ &lt;em&gt;This patient’s Neuralink brain implant gets a boost from generative AI. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;strong&gt;5 US states are working to preserve access to lifesaving vaccines&lt;/strong&gt;&lt;br /&gt;Despite the shifting federal recommendations. (Wired $)&lt;br /&gt;+ &lt;em&gt;The FDA plans to limit access to covid vaccines. Here’s why that’s not all bad. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 Vast online groups in China are sharing explicit photos of women&lt;/strong&gt;&lt;br /&gt;Non-consensual images are being passed around hundreds of thousands of men. (The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Reddit wants to be a search engine&lt;/strong&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;In response to the AI-ification of other platforms. (The Verge)&lt;br /&gt;+ &lt;em&gt;AI means the end of internet search as we’ve known it. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 Why airships could be a viable internet satellite alternative&lt;/strong&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;It could result in less space junk, for one. (IEEE Spectrum)&lt;br /&gt;+ &lt;em&gt;Welcome to the big blimp boom. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;9 Trust in AI coding tools is falling&lt;/strong&gt;&lt;br /&gt;The majority of devs use them, but they aren’t always reliable. (Ars Technica)&lt;br /&gt;+ &lt;em&gt;What is vibe coding, exactly? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 Weight-loss drugs could help to slow down aging&lt;/strong&gt;&lt;br /&gt;New trials suggest recipients can become biologically younger. (New Scientist $)&lt;br /&gt;+ &lt;em&gt;Aging hits us in our 40s and 60s. But well-being doesn’t have to fall off a cliff. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p class="has-large-font-size"&gt;&lt;strong&gt;“We look forward to joining Matt on his private island next year.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Kiana Ehsani, CEO of AI agent startup Vercept, jokes about the departure of fellow co-founder Matt Deitke to join Meta’s superintelligence team for a cool $250 million, the New York Times reports.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;br /&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcslIpHrRduW9THwxoTWUKCT52mhzY0X0o3vCVCEZlnHx-VcBl4capWQvWUgVap8RS1z4ZiE4P82n202eA-HezO2ALXA03yXGn9fbQwyP83CRAFh5wBlL3YibJ_cFfwjceJzsYu?key=GN7j3j340HzjVEb3MsqxFA" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;How ChatGPT will revolutionize the economy&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;There’s a gold rush underway to make money from generative AI models like ChatGPT. You can practically hear the shrieks from corner offices around the world: “What is our ChatGPT play? How do we make money off this?”&lt;/p&gt;&lt;p&gt;But while companies and executives want to cash in, the likely impact of generative AI on workers and the economy on the whole is far less obvious.&lt;/p&gt;&lt;p&gt;Will ChatGPT make the already troubling income and wealth inequality in the US and many other countries even worse, or could it in fact provide a much-needed boost to productivity? Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—David Rotman&lt;/em&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;+ Yikes—a gigantic stick insect has been discovered in (where else?) Australia.&lt;br /&gt;+ This X account shares random, mundane objects each day&lt;br /&gt;+ If you love a good skyscraper, these are the cities where you’re most likely to encounter them.&lt;br /&gt;+ Yum, ancient Pompeii honey 🍯&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/08/01/1120918/the-download-how-fertility-tech-is-changing-families-and-trumps-latest-tariffs/</guid><pubDate>Fri, 01 Aug 2025 12:10:00 +0000</pubDate></item><item><title>[NEW] Vast Data in talks with Alphabet’s CapitalG, Nvidia to fund round at up to $30B valuation (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/01/vast-data-in-talks-with-alphabets-capitalg-nvidia-to-fund-round-at-up-to-30b-valuation/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/GettyImages-2216028442.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI storage platform Vast Data is in talks with Alphabet’s venture arm CapitalG and existing backer Nvidia to raise a fresh round that could value the startup at up to $30 billion, Reuters reported, citing two sources.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch reported last month that Vast Data was working to raise funds at a $25 billion valuation.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The round could close in the next few weeks, per Reuters, which would make New York-based Vast Data — last valued at $9.1 billion in 2023 — one of the most valuable tech companies.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Vast Data develops storage technology that claims to enable efficiency in AI data centers. As the AI boom intensifies and the U.S. government greenlights the scaled build-out of data centers, AI infrastructure startups are becoming a hot new focus for investment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup has raised $380 million to date, and its CEO Renen Hallak said the company is free cash flow positive. Sources told Reuters that Vast Data earned $200 million in annual recurring revenue (ARR) by January 2025, with projections to grow to $600 million in ARR next year.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/GettyImages-2216028442.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI storage platform Vast Data is in talks with Alphabet’s venture arm CapitalG and existing backer Nvidia to raise a fresh round that could value the startup at up to $30 billion, Reuters reported, citing two sources.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch reported last month that Vast Data was working to raise funds at a $25 billion valuation.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The round could close in the next few weeks, per Reuters, which would make New York-based Vast Data — last valued at $9.1 billion in 2023 — one of the most valuable tech companies.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Vast Data develops storage technology that claims to enable efficiency in AI data centers. As the AI boom intensifies and the U.S. government greenlights the scaled build-out of data centers, AI infrastructure startups are becoming a hot new focus for investment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup has raised $380 million to date, and its CEO Renen Hallak said the company is free cash flow positive. Sources told Reuters that Vast Data earned $200 million in annual recurring revenue (ARR) by January 2025, with projections to grow to $600 million in ARR next year.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/01/vast-data-in-talks-with-alphabets-capitalg-nvidia-to-fund-round-at-up-to-30b-valuation/</guid><pubDate>Fri, 01 Aug 2025 13:21:26 +0000</pubDate></item><item><title>[NEW] The new face of defense tech — Ethan Thornton of Mach Industries — takes the AI Stage at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/01/the-new-face-of-defense-tech-takes-the-ai-stage-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Autonomous weapons, decentralized strategy, and startup speed — this isn’t the future of defense, it’s the now. At &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, Ethan Thornton, CEO and founder of Mach Industries, steps onto the &lt;strong&gt;AI Stage&lt;/strong&gt; to talk about how next-gen defense is being built from the ground up with AI at its core.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Ethan Thornton" class="wp-image-3033193" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_-Ethan-Thornton-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-inside-the-ai-arms-race-and-the-founder-aiming-to-rewrite-it"&gt;Inside the AI arms race — and the founder aiming to rewrite it&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Ethan Thornton isn’t your typical defense industry leader. As the CEO and founder of Mach Industries, he launched the company out of MIT in 2023 with a bold mission: to build decentralized, next-generation defense technologies that can safeguard freedom on a global scale.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Now leading one of the most ambitious startups in the space, Thornton is bringing a fresh perspective to an industry dominated by legacy players. His work blends frontier hardware, software, and autonomy to rethink how nations defend themselves in a rapidly changing world.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-from-startup-lab-to-battlefield-impact"&gt;From startup lab to battlefield impact&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Mach Industries is part of a new wave of companies proving that AI-native startups can play a critical role in national defense. This session will unpack what that means in practice — from autonomous systems and edge computing to dual-use technologies that blur the lines between commercial innovation and military capability.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Hear from Thornton on navigating funding, regulation, and responsibility at the intersection of tech and geopolitics.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-ai-isn-t-just-powering-chatbots-it-s-redefining-global-power"&gt;AI isn’t just powering chatbots — it’s redefining global power&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;With global tensions rising and investment in defense tech accelerating, this conversation offers an urgent and timely look at how artificial intelligence is reshaping security, strategy, and sovereignty. &lt;strong&gt;Register now to save up to $675&lt;/strong&gt; before prices go up next week, and be in the room with 10,000+ startup and VC leaders shaping the next era of innovation.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Autonomous weapons, decentralized strategy, and startup speed — this isn’t the future of defense, it’s the now. At &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, Ethan Thornton, CEO and founder of Mach Industries, steps onto the &lt;strong&gt;AI Stage&lt;/strong&gt; to talk about how next-gen defense is being built from the ground up with AI at its core.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Ethan Thornton" class="wp-image-3033193" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_-Ethan-Thornton-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-inside-the-ai-arms-race-and-the-founder-aiming-to-rewrite-it"&gt;Inside the AI arms race — and the founder aiming to rewrite it&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Ethan Thornton isn’t your typical defense industry leader. As the CEO and founder of Mach Industries, he launched the company out of MIT in 2023 with a bold mission: to build decentralized, next-generation defense technologies that can safeguard freedom on a global scale.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Now leading one of the most ambitious startups in the space, Thornton is bringing a fresh perspective to an industry dominated by legacy players. His work blends frontier hardware, software, and autonomy to rethink how nations defend themselves in a rapidly changing world.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-from-startup-lab-to-battlefield-impact"&gt;From startup lab to battlefield impact&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Mach Industries is part of a new wave of companies proving that AI-native startups can play a critical role in national defense. This session will unpack what that means in practice — from autonomous systems and edge computing to dual-use technologies that blur the lines between commercial innovation and military capability.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Hear from Thornton on navigating funding, regulation, and responsibility at the intersection of tech and geopolitics.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-ai-isn-t-just-powering-chatbots-it-s-redefining-global-power"&gt;AI isn’t just powering chatbots — it’s redefining global power&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;With global tensions rising and investment in defense tech accelerating, this conversation offers an urgent and timely look at how artificial intelligence is reshaping security, strategy, and sovereignty. &lt;strong&gt;Register now to save up to $675&lt;/strong&gt; before prices go up next week, and be in the room with 10,000+ startup and VC leaders shaping the next era of innovation.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/01/the-new-face-of-defense-tech-takes-the-ai-stage-at-techcrunch-disrupt-2025/</guid><pubDate>Fri, 01 Aug 2025 14:00:00 +0000</pubDate></item><item><title>[NEW] OpenAI reportedly raises $8.3B at $300B valuation (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/01/openai-reportedly-raises-8-3b-at-300b-valuation/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/11/openAI-pattern-01.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT-maker OpenAI has raised $8.3 billion at a $300 billion valuation, reports The New York Times. The deal is part of OpenAI’s broader strategy to secure $40 billion this year.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The oversubscribed round came months ahead of schedule, per the NYT. OpenAI initially raised $2.5 billion from VC firms in March when it announced its intention to raise $40 billion in a round spearheaded by Softbank. The AI giant had planned to take on an additional $7.5 billion by the end of the year, but beat itself to the punch as investors clamber to get onto its cap table amid impressive growth.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On Thursday, The Information reportedOpenAI hit $12 billion in annualized revenue and surpassed 700 million ChatGPT weekly active users. The Times today said that the number is closer to $13 billion, with projections to reach $20 billion by the end of the year. Other tailwinds include the Trump administration’s AI Action Plan and talks with Microsoft that could help the startup reach its goal of becoming a true for-profit company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Times reported that Dragoneer Investment Group, an under-the-radar investor, led the round with a startling $2.8 billion check. Many new investors participated in the round, including private equity giants Blackstone and TPG and mutual fund manager T. Rowe Price. Other participants include Altimeter Capital, Andreessen Horowitz, Coatue Management, D1 Capital Partners, Fidelity Management, Founders Fund, Sequoia Capital, Tiger Global, and Thrive Capital.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some early investors in OpenAI were reportedly dismayed by the smaller allocations they got in the round as the AI behemoth prioritized bringing on new strategic backers.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to OpenAI for comment.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/11/openAI-pattern-01.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT-maker OpenAI has raised $8.3 billion at a $300 billion valuation, reports The New York Times. The deal is part of OpenAI’s broader strategy to secure $40 billion this year.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The oversubscribed round came months ahead of schedule, per the NYT. OpenAI initially raised $2.5 billion from VC firms in March when it announced its intention to raise $40 billion in a round spearheaded by Softbank. The AI giant had planned to take on an additional $7.5 billion by the end of the year, but beat itself to the punch as investors clamber to get onto its cap table amid impressive growth.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On Thursday, The Information reportedOpenAI hit $12 billion in annualized revenue and surpassed 700 million ChatGPT weekly active users. The Times today said that the number is closer to $13 billion, with projections to reach $20 billion by the end of the year. Other tailwinds include the Trump administration’s AI Action Plan and talks with Microsoft that could help the startup reach its goal of becoming a true for-profit company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Times reported that Dragoneer Investment Group, an under-the-radar investor, led the round with a startling $2.8 billion check. Many new investors participated in the round, including private equity giants Blackstone and TPG and mutual fund manager T. Rowe Price. Other participants include Altimeter Capital, Andreessen Horowitz, Coatue Management, D1 Capital Partners, Fidelity Management, Founders Fund, Sequoia Capital, Tiger Global, and Thrive Capital.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some early investors in OpenAI were reportedly dismayed by the smaller allocations they got in the round as the AI behemoth prioritized bringing on new strategic backers.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to OpenAI for comment.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/01/openai-reportedly-raises-8-3b-at-300b-valuation/</guid><pubDate>Fri, 01 Aug 2025 14:09:14 +0000</pubDate></item><item><title>[NEW] Deep Cogito v2: Open-source AI that hones its reasoning skills (AI News)</title><link>https://www.artificialintelligence-news.com/news/deep-cogito-v2-open-source-ai-hones-its-reasoning-skills/</link><description>&lt;p&gt;Deep Cogito has released Cogito v2, a new family of open-source AI models that sharpen their own reasoning skills.&lt;/p&gt;&lt;p&gt;Released under an open-source licence, the new Cogito v2 lineup includes four hybrid reasoning AI models: two mid-sized at 70B and 109B parameters, and two large-scale versions at 405B and 671B.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The largest, a 671B Mixture-of-Experts (MoE) model, is already being touted as one of the most powerful open-source AIs in the world. The company reports that it competes with the latest from DeepSeek and is closing the gap on proprietary systems like O3 and Claude 4 Opus.&lt;/p&gt;&lt;p&gt;But the real story isn’t just about size or power; it’s about a fundamental shift in how the AI learns. Instead of just ‘thinking’ longer at inference time to find an answer, Cogito v2 is designed to internalise its own reasoning processes.&lt;/p&gt;&lt;p&gt;This internalised reasoning is achieved through a technique called Iterated Distillation and Amplification (IDA), which distils the discoveries from a search back into the model’s core parameters. The goal is to build a stronger ‘intuition’, allowing the model to anticipate the outcome of its own reasoning without having to perform the entire search.&lt;/p&gt;&lt;p&gt;Because the open-source AI models have a better “gut feeling” for the right approach, their reasoning chains are 60% shorter than those of rivals like Deepseek R1.&lt;/p&gt;&lt;p&gt;This efficiency extends to the budget. Deep Cogito says that it developed all its models – from experiments to final training – for a combined total of less than $3.5 million. Still a large sum likely for you or I, but miniscule compared to the spending of many of the leading AI labs.&lt;/p&gt;&lt;p&gt;The flagship 671B model received special attention, trained not only to improve its final answers but to refine the thinking process itself. This approach discourages the model from “meandering” and rewards a more direct path to the solution. The performance data suggests it works, with Deep Cogito’s open-source AI model matching or exceeding the latest DeepSeek versions on key benchmarks while being close to proprietary alternatives:&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Benchmark comparison of the flagship open-source Deep Cogito v2 671B AI reasoning model against Deepseek and OpenAI o3 and Anthropic Claude models." class="wp-image-107275" height="466" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/cogito-v2-preview-671b-moe-ai-model-artificial-intelligence-reasoning-open-source-development-skills-benchmark.jpg" width="828" /&gt;&lt;/figure&gt;&lt;p&gt;Perhaps one of the most surprising outcomes is the models’ ability to reason about images; a skill they were never explicitly trained for.&lt;/p&gt;&lt;p&gt;The team shared an example of this reasoning where Deep Cogito’s open-source AI model compared two images of a duck and a lion, demonstrating a deep thinking process about their habitats, colours, and composition purely through transfer learning. Deep Cogito believes this emergent property could be a powerful way to bootstrap training data for future multimodal reasoning systems.&lt;/p&gt;&lt;p&gt;Looking ahead, the Deep Cogito team plans to “hill climb on the gains of iterative self-improvement” in its quest to build superintelligence. They have restated their commitment that all AI models they create will be open-source.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Leak suggests OpenAI’s open-source AI model release is imminent&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Deep Cogito has released Cogito v2, a new family of open-source AI models that sharpen their own reasoning skills.&lt;/p&gt;&lt;p&gt;Released under an open-source licence, the new Cogito v2 lineup includes four hybrid reasoning AI models: two mid-sized at 70B and 109B parameters, and two large-scale versions at 405B and 671B.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The largest, a 671B Mixture-of-Experts (MoE) model, is already being touted as one of the most powerful open-source AIs in the world. The company reports that it competes with the latest from DeepSeek and is closing the gap on proprietary systems like O3 and Claude 4 Opus.&lt;/p&gt;&lt;p&gt;But the real story isn’t just about size or power; it’s about a fundamental shift in how the AI learns. Instead of just ‘thinking’ longer at inference time to find an answer, Cogito v2 is designed to internalise its own reasoning processes.&lt;/p&gt;&lt;p&gt;This internalised reasoning is achieved through a technique called Iterated Distillation and Amplification (IDA), which distils the discoveries from a search back into the model’s core parameters. The goal is to build a stronger ‘intuition’, allowing the model to anticipate the outcome of its own reasoning without having to perform the entire search.&lt;/p&gt;&lt;p&gt;Because the open-source AI models have a better “gut feeling” for the right approach, their reasoning chains are 60% shorter than those of rivals like Deepseek R1.&lt;/p&gt;&lt;p&gt;This efficiency extends to the budget. Deep Cogito says that it developed all its models – from experiments to final training – for a combined total of less than $3.5 million. Still a large sum likely for you or I, but miniscule compared to the spending of many of the leading AI labs.&lt;/p&gt;&lt;p&gt;The flagship 671B model received special attention, trained not only to improve its final answers but to refine the thinking process itself. This approach discourages the model from “meandering” and rewards a more direct path to the solution. The performance data suggests it works, with Deep Cogito’s open-source AI model matching or exceeding the latest DeepSeek versions on key benchmarks while being close to proprietary alternatives:&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Benchmark comparison of the flagship open-source Deep Cogito v2 671B AI reasoning model against Deepseek and OpenAI o3 and Anthropic Claude models." class="wp-image-107275" height="466" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/cogito-v2-preview-671b-moe-ai-model-artificial-intelligence-reasoning-open-source-development-skills-benchmark.jpg" width="828" /&gt;&lt;/figure&gt;&lt;p&gt;Perhaps one of the most surprising outcomes is the models’ ability to reason about images; a skill they were never explicitly trained for.&lt;/p&gt;&lt;p&gt;The team shared an example of this reasoning where Deep Cogito’s open-source AI model compared two images of a duck and a lion, demonstrating a deep thinking process about their habitats, colours, and composition purely through transfer learning. Deep Cogito believes this emergent property could be a powerful way to bootstrap training data for future multimodal reasoning systems.&lt;/p&gt;&lt;p&gt;Looking ahead, the Deep Cogito team plans to “hill climb on the gains of iterative self-improvement” in its quest to build superintelligence. They have restated their commitment that all AI models they create will be open-source.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Leak suggests OpenAI’s open-source AI model release is imminent&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/deep-cogito-v2-open-source-ai-hones-its-reasoning-skills/</guid><pubDate>Fri, 01 Aug 2025 14:11:47 +0000</pubDate></item><item><title>[NEW] Fundamental Research Labs nabs $30M+ to build AI agents across verticals (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/01/fundamental-research-labs-nabs-33-million-from-prosus-to-build-ai-agents-for-multiple-verticals/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/FRL-Founder-Photo.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Applied AI research company Fundamental Research Labs (formerly known as Altera) announced today that it has raised $33 million in Series A funding led by Prosus with participation from Stripe co-founder and CEO Patrick Collison.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has a curious structure, as it is working on multiple AI applications in different fields. When it raised its seed funding, Fundamental Research Labs was developing bots that could play Minecraft with you.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Today, the company has a games team, a prosumer team building apps, a core research team, and a platform team. The startup’s founder, Dr. Robert Yang, a former faculty member at MIT, says that Fundamental Research Labs wants to be a “historical” company without adhering to a typical startup structure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Yang said that the company is already charging users for this agent after a seven-day trial and bringing in revenue.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Among the products Fundamental Research Labs offers is a general-purpose consumer assistant called Fairies. This app allows you to chat with an AI bot, connect applications, and ask questions across the knowledge bases of those applications, then ask it to schedule appointments for you on your calendar. The app can schedule workflows for you to repeatedly execute some tasks. Yang said that this app allows the startup’s engineers to test out various capabilities of models and platform tech it is developing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company also offers a spreadsheet-based agent called Shortcut, which has been used by analysts for creating different financial models and performing analysis over them. The startup said that this agent works like a junior analyst and can do work autonomously. The company has made it look like Excel and has tried to retain a lot of functionality for power users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’ve seen many early-stage startups, but what stood out here is a small, highly mission-driven team focused on digital humans with actual use cases. Their recent launches, like Fairies and Shortcut, aren’t just demos; they’re already demonstrating how AI can augment the human workforce in meaningful ways,” Sandeep Bakshi, an investment partner at Prosus, told TechCrunch over email.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“What stood out with Fundamental Research Labs is not just the ambition of the vision, but again the caliber of the team driving it,” he added. “Their ability to attract some of the brightest minds in the world, and turn that talent into real-world products, makes this a uniquely compelling venture opportunity for us.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company raised $9 million in a seed round last year, which was co-led by First Spark Ventures and Patron, with participation from a16z Speedrun and Eric Schmidt. The startup has raised over $40 million in funding to date.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Shortcut – the first superhuman excel agent – is live.&lt;/p&gt;&lt;p&gt;While not perfect, Shortcut beats first year analysts from McKinsey/Goldman head-to-head 89.1% (220:27) when blindly judged by their managers.&lt;/p&gt;&lt;p&gt;We even gave humans 10x more time.&lt;/p&gt;&lt;p&gt;Try Shortcut now (before your boss does). pic.twitter.com/bOCVx6J77W&lt;/p&gt;— nico (@nicochristie) July 28, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Yang said the company is open to trying out various application models and eventually wants to build robots as well.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We are working on productivity (apps) now because that is where the most value is created. You can make a lot of money doing this and build your team and tech. Eventually, we want to solve physical problems and move towards working on embodiment,” Yang said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Correction: The funding round was $33 million, not $30 million; the story was updated with the accurate amount. &lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/FRL-Founder-Photo.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Applied AI research company Fundamental Research Labs (formerly known as Altera) announced today that it has raised $33 million in Series A funding led by Prosus with participation from Stripe co-founder and CEO Patrick Collison.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has a curious structure, as it is working on multiple AI applications in different fields. When it raised its seed funding, Fundamental Research Labs was developing bots that could play Minecraft with you.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Today, the company has a games team, a prosumer team building apps, a core research team, and a platform team. The startup’s founder, Dr. Robert Yang, a former faculty member at MIT, says that Fundamental Research Labs wants to be a “historical” company without adhering to a typical startup structure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Yang said that the company is already charging users for this agent after a seven-day trial and bringing in revenue.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Among the products Fundamental Research Labs offers is a general-purpose consumer assistant called Fairies. This app allows you to chat with an AI bot, connect applications, and ask questions across the knowledge bases of those applications, then ask it to schedule appointments for you on your calendar. The app can schedule workflows for you to repeatedly execute some tasks. Yang said that this app allows the startup’s engineers to test out various capabilities of models and platform tech it is developing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company also offers a spreadsheet-based agent called Shortcut, which has been used by analysts for creating different financial models and performing analysis over them. The startup said that this agent works like a junior analyst and can do work autonomously. The company has made it look like Excel and has tried to retain a lot of functionality for power users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’ve seen many early-stage startups, but what stood out here is a small, highly mission-driven team focused on digital humans with actual use cases. Their recent launches, like Fairies and Shortcut, aren’t just demos; they’re already demonstrating how AI can augment the human workforce in meaningful ways,” Sandeep Bakshi, an investment partner at Prosus, told TechCrunch over email.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“What stood out with Fundamental Research Labs is not just the ambition of the vision, but again the caliber of the team driving it,” he added. “Their ability to attract some of the brightest minds in the world, and turn that talent into real-world products, makes this a uniquely compelling venture opportunity for us.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company raised $9 million in a seed round last year, which was co-led by First Spark Ventures and Patron, with participation from a16z Speedrun and Eric Schmidt. The startup has raised over $40 million in funding to date.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Shortcut – the first superhuman excel agent – is live.&lt;/p&gt;&lt;p&gt;While not perfect, Shortcut beats first year analysts from McKinsey/Goldman head-to-head 89.1% (220:27) when blindly judged by their managers.&lt;/p&gt;&lt;p&gt;We even gave humans 10x more time.&lt;/p&gt;&lt;p&gt;Try Shortcut now (before your boss does). pic.twitter.com/bOCVx6J77W&lt;/p&gt;— nico (@nicochristie) July 28, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Yang said the company is open to trying out various application models and eventually wants to build robots as well.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We are working on productivity (apps) now because that is where the most value is created. You can make a lot of money doing this and build your team and tech. Eventually, we want to solve physical problems and move towards working on embodiment,” Yang said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Correction: The funding round was $33 million, not $30 million; the story was updated with the accurate amount. &lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/01/fundamental-research-labs-nabs-33-million-from-prosus-to-build-ai-agents-for-multiple-verticals/</guid><pubDate>Fri, 01 Aug 2025 15:15:00 +0000</pubDate></item><item><title>[NEW] Google releases Gemini 2.5 Deep Think for AI Ultra subscribers (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/08/google-releases-gemini-2-5-deep-think-for-ai-ultra-subscribers/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        This ultra-powerful AI is ultra-expensive.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Gemini AI Android app assistant" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/03/Gemini-app-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Gemini AI Android app assistant" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/03/Gemini-app-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Ryan Whitwam

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Google is unleashing its most powerful Gemini model today, but you probably won't be able to try it. After revealing Gemini 2.5 Deep Think at the I/O conference back in May, Google is making this AI available in the Gemini app. Deep Think is designed for the most complex queries, which means it uses more compute resources than other models. So it should come as no surprise that only those subscribing to Google's $250 AI Ultra plan will be able to access it.&lt;/p&gt;
&lt;p&gt;Deep Think is based on the same foundation as Gemini 2.5 Pro, but it increases the "thinking time" with greater parallel analysis. According to Google, Deep Think explores multiple approaches to a problem, even revisiting and remixing the various hypotheses it generates. This process helps it create a higher-quality output.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2109749 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="Deep Think benchmarks" class="fullwidth full" height="1171" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/all_benchmarks_blog.width-1000.format-webp-copy.jpg" width="1000" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Like some other heavyweight Gemini tools, Deep Think takes several minutes to come up with an answer. This apparently makes the AI more adept at design aesthetics, scientific reasoning, and coding. Google has exposed Deep Think to the usual battery of benchmarks, showing that it surpasses the standard Gemini 2.5 Pro and competing models like OpenAI o3 and Grok 4. Deep Think shows a particularly large gain in Humanity's Last Exam, a collection of 2,500 complex, multi-modal questions that cover more than 100 subjects. Other models top out at 20 or 25 percent, but Gemini 2.5 Deep Think managed a score of 34.8 percent.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Mathematics is a big focus of Deep Think, which also demonstrates strong performance in the AIME benchmark. There's still more work to be done here, though. Google recently revealed that it used a specially trained version of Deep Think, which can churn for hours before coming up with a solution, to compete in the International Mathematical Olympiad (IMO). This model earned an IMO gold medal for the first time. Google has only distributed the IMO version of Deep Think to trusted testers, but it hopes to release it more widely later. In the meantime, the standard Deep Think still reaches bronze medal status in the 2025 IMO test.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Solving advanced math with Deep Think.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;Google AI Ultra subscribers will be able to access Deep Think starting today in the Gemini app and web interface, but it doesn't get a place in the main model menu. It's accessible as a tool (along with Deep Research, Canvas, and others) when you select Gemini 2.5 Pro. Even with Google's pricey AI subscription, Google says there is a set limit on the number of Deep Think queries per day. It doesn't specify what that limit is, and Google isn't offering specifics, suggesting that the limit will change over time. Deep Think will eventually come to the API, giving developers a way to access more prompts as a paid service.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        This ultra-powerful AI is ultra-expensive.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Gemini AI Android app assistant" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/03/Gemini-app-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Gemini AI Android app assistant" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/03/Gemini-app-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Ryan Whitwam

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Google is unleashing its most powerful Gemini model today, but you probably won't be able to try it. After revealing Gemini 2.5 Deep Think at the I/O conference back in May, Google is making this AI available in the Gemini app. Deep Think is designed for the most complex queries, which means it uses more compute resources than other models. So it should come as no surprise that only those subscribing to Google's $250 AI Ultra plan will be able to access it.&lt;/p&gt;
&lt;p&gt;Deep Think is based on the same foundation as Gemini 2.5 Pro, but it increases the "thinking time" with greater parallel analysis. According to Google, Deep Think explores multiple approaches to a problem, even revisiting and remixing the various hypotheses it generates. This process helps it create a higher-quality output.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2109749 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="Deep Think benchmarks" class="fullwidth full" height="1171" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/all_benchmarks_blog.width-1000.format-webp-copy.jpg" width="1000" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Like some other heavyweight Gemini tools, Deep Think takes several minutes to come up with an answer. This apparently makes the AI more adept at design aesthetics, scientific reasoning, and coding. Google has exposed Deep Think to the usual battery of benchmarks, showing that it surpasses the standard Gemini 2.5 Pro and competing models like OpenAI o3 and Grok 4. Deep Think shows a particularly large gain in Humanity's Last Exam, a collection of 2,500 complex, multi-modal questions that cover more than 100 subjects. Other models top out at 20 or 25 percent, but Gemini 2.5 Deep Think managed a score of 34.8 percent.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Mathematics is a big focus of Deep Think, which also demonstrates strong performance in the AIME benchmark. There's still more work to be done here, though. Google recently revealed that it used a specially trained version of Deep Think, which can churn for hours before coming up with a solution, to compete in the International Mathematical Olympiad (IMO). This model earned an IMO gold medal for the first time. Google has only distributed the IMO version of Deep Think to trusted testers, but it hopes to release it more widely later. In the meantime, the standard Deep Think still reaches bronze medal status in the 2025 IMO test.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Solving advanced math with Deep Think.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;Google AI Ultra subscribers will be able to access Deep Think starting today in the Gemini app and web interface, but it doesn't get a place in the main model menu. It's accessible as a tool (along with Deep Research, Canvas, and others) when you select Gemini 2.5 Pro. Even with Google's pricey AI subscription, Google says there is a set limit on the number of Deep Think queries per day. It doesn't specify what that limit is, and Google isn't offering specifics, suggesting that the limit will change over time. Deep Think will eventually come to the API, giving developers a way to access more prompts as a paid service.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/08/google-releases-gemini-2-5-deep-think-for-ai-ultra-subscribers/</guid><pubDate>Fri, 01 Aug 2025 15:36:08 +0000</pubDate></item><item><title>[NEW] Google releases Olympiad medal-winning Gemini 2.5 ‘Deep Think’ AI publicly — but there’s a catch… (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/google-releases-olympiad-medal-winning-gemini-2-5-deep-think-ai-publicly-but-theres-a-catch/</link><description>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;However, &lt;strong&gt;this is unfortunately &lt;em&gt;not&lt;/em&gt; the identical gold medal-winning model. &lt;/strong&gt;It is in fact, a less powerful “bronze” version according to Google’s blog post and Logan Kilpatrick, Product Lead for Google AI Studio. &lt;/p&gt;&lt;p&gt;As Kilpatrick posted on the social network X: “This is a variation of our IMO gold model that is faster and more optimized for daily use. We are also giving the IMO gold full model to a set of mathematicians to test the value of the full capabilities.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Now available through the Gemini mobile app&lt;/strong&gt;, this bronze model is accessible to subscribers of Google’s most expensive individual AI plan, AI Ultra, which costs $249.99 per month with a 3-month starting promotion at a reduced rate of $124.99/month for new subscribers.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Google also said in its release blog post that it would bring Deep Think with and without tool usage integrations to “trusted testers” through the Gemini application programming interface (API) “in the coming weeks.” &lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-deep-think-is-so-powerful"&gt;Why ‘Deep Think’ is so powerful&lt;/h2&gt;



&lt;p&gt;Gemini 2.5 Deep Think builds on the Gemini family of large language models (LLMs), adding new capabilities aimed at reasoning through sophisticated problems. &lt;/p&gt;



&lt;p&gt;It &lt;strong&gt;employs “parallel thinking” techniques to explore multiple ideas simultaneously and includes reinforcement learning to strengthen its step-by-step problem-solving ability over time.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;The model is &lt;strong&gt;designed for use cases that benefit from extended deliberation, such as mathematical conjecture testing, scientific research, algorithm design,&lt;/strong&gt; and creative iteration tasks like code and design refinement. &lt;/p&gt;



&lt;p&gt;Early testers, including mathematicians such as Michel van Garrel, have used it to probe unsolved problems and generate potential proofs.&lt;/p&gt;



&lt;p&gt;AI power user and expert Ethan Mollick, a professor of the Wharton School of Business at the University of Pennsylvania, also posted on X that it was able to take a prompt he often uses to test the capabilities of new models — “create something I can paste into p5js that will startle me with its cleverness in creating something that invokes the control panel of a starship in the distant future” — and&lt;strong&gt; turned it into a 3D graphic, which is the first time any model has done that&lt;/strong&gt;.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Had early access to Gemini with Deep Think. Very good model, big gains over standard Gemini 2.5 Pro for a lot of problems.&lt;/p&gt;&lt;p&gt;Here is the first attempt at the starship control panel prompt I try with every model. First time I have seen a model make a 3D interface in response. https://t.co/8iW2Pn6Xpu pic.twitter.com/bLFF2IcOP3&lt;/p&gt;— Ethan Mollick (@emollick) August 1, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-performance-benchmarks-and-use-cases"&gt;Performance benchmarks and use cases&lt;/h2&gt;



&lt;p&gt;Google highlights several key application areas for Deep Think:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Mathematics and science&lt;/strong&gt;: The model can simulate reasoning for complex proofs, explore conjectures, and interpret dense scientific literature&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Coding and algorithm design&lt;/strong&gt;: It performs well on tasks involving performance tradeoffs, time complexity, and multi-step logic&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Creative development&lt;/strong&gt;: In design scenarios such as voxel art or user interface builds, Deep Think demonstrates stronger iterative improvement and detail enhancement&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;The model also &lt;strong&gt;leads performance in benchmark evaluations such as LiveCodeBench V6 &lt;/strong&gt;(for coding ability) &lt;strong&gt;and Humanity’s Last Exam&lt;/strong&gt; (covering math, science, and reasoning).&lt;/p&gt;



&lt;p&gt;It &lt;strong&gt;outscored Gemini 2.5 Pro and competing models like OpenAI’s GPT-4 and xAI’s Grok 4&lt;/strong&gt; by double digit margins on some categories (Reasoning &amp;amp; Knowledge, Code generation, and IMO 2025 Mathematics). &lt;/p&gt;



&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3015044" height="600" src="https://venturebeat.com/wp-content/uploads/2025/08/2.5-deep-think-benchmarks.png?w=512" width="512" /&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-gemini-2-5-deep-think-vs-gemini-2-5-pro"&gt;Gemini 2.5 Deep Think vs. Gemini 2.5 Pro&lt;/h2&gt;



&lt;p&gt;While both Deep Think and Gemini 2.5 Pro are part of the Gemini 2.5 model family, Google positions Deep Think as a &lt;strong&gt;more capable and analytically skilled variant&lt;/strong&gt;, particularly when it comes to complex reasoning and multi-step problem-solving. &lt;/p&gt;



&lt;p&gt;This improvement stems from the use of &lt;strong&gt;parallel thinking&lt;/strong&gt; and &lt;strong&gt;reinforcement learning techniques&lt;/strong&gt;, which enable the model to simulate deeper cognitive deliberation.&lt;/p&gt;



&lt;p&gt;In its official communication, Google describes Deep Think as better at &lt;strong&gt;handling nuanced prompts, exploring multiple hypotheses, and producing more refined outputs&lt;/strong&gt;. This is supported by side-by-side comparisons in voxel art generation, where Deep Think adds more texture, structural fidelity, and compositional diversity than 2.5 Pro.&lt;/p&gt;



&lt;p&gt;The improvements aren’t just visual or anecdotal. Google reports that Deep Think &lt;strong&gt;outperforms Gemini 2.5 Pro on multiple technical benchmarks&lt;/strong&gt; related to reasoning, code generation, and cross-domain expertise. However, these gains come with tradeoffs in responsiveness and prompt acceptance.&lt;/p&gt;



&lt;p&gt;Here’s a breakdown:&lt;/p&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;&lt;strong&gt;Capability / Attribute&lt;/strong&gt;&lt;/th&gt;&lt;th&gt;&lt;strong&gt;Gemini 2.5 Pro&lt;/strong&gt;&lt;/th&gt;&lt;th&gt;&lt;strong&gt;Gemini 2.5 Deep Think&lt;/strong&gt;&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Inference speed&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Faster, low latency&lt;/td&gt;&lt;td&gt;Slower, extended “thinking time”&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Reasoning complexity&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Moderate&lt;/td&gt;&lt;td&gt;High — uses parallel thinking&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Prompt depth and creativity&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Good&lt;/td&gt;&lt;td&gt;More detailed and nuanced&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Benchmark performance&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Strong&lt;/td&gt;&lt;td&gt;State-of-the-art&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Content safety &amp;amp; tone objectivity&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Improved over older models&lt;/td&gt;&lt;td&gt;Further improved&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Refusal rate (benign prompts)&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Lower&lt;/td&gt;&lt;td&gt;Higher&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Output length&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Standard&lt;/td&gt;&lt;td&gt;Supports longer responses&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Voxel art / design fidelity&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Basic scene structure&lt;/td&gt;&lt;td&gt;Enhanced detail and richness&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;p&gt;Google notes that &lt;strong&gt;Deep Think’s higher refusal rate&lt;/strong&gt; is an area of active investigation. This may limit its flexibility in handling ambiguous or informal queries compared to 2.5 Pro. In contrast, 2.5 Pro remains better suited for users who prioritize &lt;strong&gt;speed and responsiveness&lt;/strong&gt;, especially for lighter, general-purpose tasks.&lt;/p&gt;



&lt;p&gt;This differentiation allows users to choose based on their priorities: &lt;strong&gt;2.5 Pro for speed and fluidity&lt;/strong&gt;, or &lt;strong&gt;Deep Think for rigor and reflection&lt;/strong&gt;.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-not-the-gold-medal-winning-model-just-a-bronze"&gt;Not the gold medal winning model, just a bronze&lt;/h2&gt;



&lt;p&gt;In July, Google DeepMind made headlines when a more advanced version of the Gemini Deep Think model achieved official gold-medal status at the 2025 IMO — the world’s most prestigious mathematics competition for high school students. &lt;/p&gt;



&lt;p&gt;The system &lt;strong&gt;solved five of six challenging problems and became the first AI to receive gold-level scoring from the IMO.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;Demis Hassabis, CEO of Google DeepMind, announced the achievement on X, stating the model had solved problems end-to-end in natural language — without needing translation into formal programming syntax. &lt;/p&gt;



&lt;p&gt;The IMO board confirmed the model scored 35 out of a possible 42 points, well above the gold threshold. Gemini 2.5 Deep Think’s solutions were &lt;strong&gt;described by competition president Gregor Dolinar&lt;/strong&gt; as clear, precise, and in many cases, &lt;strong&gt;easier to follow than those of human competitors.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;However, the Gemini 2.5 Deep Think released to users is not that same competition model, rather, a lower performing but apparently faster version.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-to-access-deep-think-now"&gt;How to access Deep Think now&lt;/h2&gt;



&lt;p&gt;Gemini 2.5 Deep Think is &lt;strong&gt;available exclusively on the Google Gemini mobile app for iOS and Android at this time to users on the Google AI Ultra plan&lt;/strong&gt;, part of the Google One subscription lineup, with pricing as follows. &lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Promotional offer: &lt;strong&gt;$124.99/month for 3 months, then it kicks up to…&lt;/strong&gt;&lt;/li&gt;



&lt;li&gt;Standard rate: &lt;strong&gt;$249.99/month&lt;/strong&gt;&lt;/li&gt;



&lt;li&gt;Included features: 30 TB of storage, access to the Gemini app with Deep Think and Veo 3, as well as tools like Flow, Whisk, and 12,500 monthly AI credits&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Subscribers can activate Deep Think in the Gemini app by selecting the 2.5 Pro model and toggling the “Deep Think” option. &lt;/p&gt;



&lt;p&gt;It supports a fixed number of prompts per day and is integrated with capabilities like code execution and Google Search. The model also generates longer and more detailed outputs compared to standard versions.&lt;/p&gt;



&lt;p&gt;The lower-tier Google AI Pro plan, priced at $19.99/month (with a free trial), does not include access to Deep Think, nor does the free Gemini AI service.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-it-matters-for-enterprise-technical-decision-makers"&gt;Why it matters for enterprise technical decision-makers&lt;/h2&gt;



&lt;p&gt;Gemini 2.5 Deep Think represents the practical application of a major research milestone. &lt;/p&gt;



&lt;p&gt;It &lt;strong&gt;allows enterprises and organizations to tap into a Math Olympiad medal-winning model and have it join their staff,&lt;/strong&gt; albeit only through an individual user account now. &lt;/p&gt;



&lt;p&gt;For researchers receiving the full IMO-grade model, it offers a glimpse into the future of collaborative AI in mathematics. For Ultra subscribers, Deep Think provides a powerful step toward more capable and context-aware AI assistance, now running in the palm of their hand.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;However, &lt;strong&gt;this is unfortunately &lt;em&gt;not&lt;/em&gt; the identical gold medal-winning model. &lt;/strong&gt;It is in fact, a less powerful “bronze” version according to Google’s blog post and Logan Kilpatrick, Product Lead for Google AI Studio. &lt;/p&gt;&lt;p&gt;As Kilpatrick posted on the social network X: “This is a variation of our IMO gold model that is faster and more optimized for daily use. We are also giving the IMO gold full model to a set of mathematicians to test the value of the full capabilities.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Now available through the Gemini mobile app&lt;/strong&gt;, this bronze model is accessible to subscribers of Google’s most expensive individual AI plan, AI Ultra, which costs $249.99 per month with a 3-month starting promotion at a reduced rate of $124.99/month for new subscribers.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Google also said in its release blog post that it would bring Deep Think with and without tool usage integrations to “trusted testers” through the Gemini application programming interface (API) “in the coming weeks.” &lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-deep-think-is-so-powerful"&gt;Why ‘Deep Think’ is so powerful&lt;/h2&gt;



&lt;p&gt;Gemini 2.5 Deep Think builds on the Gemini family of large language models (LLMs), adding new capabilities aimed at reasoning through sophisticated problems. &lt;/p&gt;



&lt;p&gt;It &lt;strong&gt;employs “parallel thinking” techniques to explore multiple ideas simultaneously and includes reinforcement learning to strengthen its step-by-step problem-solving ability over time.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;The model is &lt;strong&gt;designed for use cases that benefit from extended deliberation, such as mathematical conjecture testing, scientific research, algorithm design,&lt;/strong&gt; and creative iteration tasks like code and design refinement. &lt;/p&gt;



&lt;p&gt;Early testers, including mathematicians such as Michel van Garrel, have used it to probe unsolved problems and generate potential proofs.&lt;/p&gt;



&lt;p&gt;AI power user and expert Ethan Mollick, a professor of the Wharton School of Business at the University of Pennsylvania, also posted on X that it was able to take a prompt he often uses to test the capabilities of new models — “create something I can paste into p5js that will startle me with its cleverness in creating something that invokes the control panel of a starship in the distant future” — and&lt;strong&gt; turned it into a 3D graphic, which is the first time any model has done that&lt;/strong&gt;.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Had early access to Gemini with Deep Think. Very good model, big gains over standard Gemini 2.5 Pro for a lot of problems.&lt;/p&gt;&lt;p&gt;Here is the first attempt at the starship control panel prompt I try with every model. First time I have seen a model make a 3D interface in response. https://t.co/8iW2Pn6Xpu pic.twitter.com/bLFF2IcOP3&lt;/p&gt;— Ethan Mollick (@emollick) August 1, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-performance-benchmarks-and-use-cases"&gt;Performance benchmarks and use cases&lt;/h2&gt;



&lt;p&gt;Google highlights several key application areas for Deep Think:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Mathematics and science&lt;/strong&gt;: The model can simulate reasoning for complex proofs, explore conjectures, and interpret dense scientific literature&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Coding and algorithm design&lt;/strong&gt;: It performs well on tasks involving performance tradeoffs, time complexity, and multi-step logic&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Creative development&lt;/strong&gt;: In design scenarios such as voxel art or user interface builds, Deep Think demonstrates stronger iterative improvement and detail enhancement&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;The model also &lt;strong&gt;leads performance in benchmark evaluations such as LiveCodeBench V6 &lt;/strong&gt;(for coding ability) &lt;strong&gt;and Humanity’s Last Exam&lt;/strong&gt; (covering math, science, and reasoning).&lt;/p&gt;



&lt;p&gt;It &lt;strong&gt;outscored Gemini 2.5 Pro and competing models like OpenAI’s GPT-4 and xAI’s Grok 4&lt;/strong&gt; by double digit margins on some categories (Reasoning &amp;amp; Knowledge, Code generation, and IMO 2025 Mathematics). &lt;/p&gt;



&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3015044" height="600" src="https://venturebeat.com/wp-content/uploads/2025/08/2.5-deep-think-benchmarks.png?w=512" width="512" /&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-gemini-2-5-deep-think-vs-gemini-2-5-pro"&gt;Gemini 2.5 Deep Think vs. Gemini 2.5 Pro&lt;/h2&gt;



&lt;p&gt;While both Deep Think and Gemini 2.5 Pro are part of the Gemini 2.5 model family, Google positions Deep Think as a &lt;strong&gt;more capable and analytically skilled variant&lt;/strong&gt;, particularly when it comes to complex reasoning and multi-step problem-solving. &lt;/p&gt;



&lt;p&gt;This improvement stems from the use of &lt;strong&gt;parallel thinking&lt;/strong&gt; and &lt;strong&gt;reinforcement learning techniques&lt;/strong&gt;, which enable the model to simulate deeper cognitive deliberation.&lt;/p&gt;



&lt;p&gt;In its official communication, Google describes Deep Think as better at &lt;strong&gt;handling nuanced prompts, exploring multiple hypotheses, and producing more refined outputs&lt;/strong&gt;. This is supported by side-by-side comparisons in voxel art generation, where Deep Think adds more texture, structural fidelity, and compositional diversity than 2.5 Pro.&lt;/p&gt;



&lt;p&gt;The improvements aren’t just visual or anecdotal. Google reports that Deep Think &lt;strong&gt;outperforms Gemini 2.5 Pro on multiple technical benchmarks&lt;/strong&gt; related to reasoning, code generation, and cross-domain expertise. However, these gains come with tradeoffs in responsiveness and prompt acceptance.&lt;/p&gt;



&lt;p&gt;Here’s a breakdown:&lt;/p&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;&lt;strong&gt;Capability / Attribute&lt;/strong&gt;&lt;/th&gt;&lt;th&gt;&lt;strong&gt;Gemini 2.5 Pro&lt;/strong&gt;&lt;/th&gt;&lt;th&gt;&lt;strong&gt;Gemini 2.5 Deep Think&lt;/strong&gt;&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Inference speed&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Faster, low latency&lt;/td&gt;&lt;td&gt;Slower, extended “thinking time”&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Reasoning complexity&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Moderate&lt;/td&gt;&lt;td&gt;High — uses parallel thinking&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Prompt depth and creativity&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Good&lt;/td&gt;&lt;td&gt;More detailed and nuanced&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Benchmark performance&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Strong&lt;/td&gt;&lt;td&gt;State-of-the-art&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Content safety &amp;amp; tone objectivity&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Improved over older models&lt;/td&gt;&lt;td&gt;Further improved&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Refusal rate (benign prompts)&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Lower&lt;/td&gt;&lt;td&gt;Higher&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Output length&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Standard&lt;/td&gt;&lt;td&gt;Supports longer responses&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Voxel art / design fidelity&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Basic scene structure&lt;/td&gt;&lt;td&gt;Enhanced detail and richness&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;p&gt;Google notes that &lt;strong&gt;Deep Think’s higher refusal rate&lt;/strong&gt; is an area of active investigation. This may limit its flexibility in handling ambiguous or informal queries compared to 2.5 Pro. In contrast, 2.5 Pro remains better suited for users who prioritize &lt;strong&gt;speed and responsiveness&lt;/strong&gt;, especially for lighter, general-purpose tasks.&lt;/p&gt;



&lt;p&gt;This differentiation allows users to choose based on their priorities: &lt;strong&gt;2.5 Pro for speed and fluidity&lt;/strong&gt;, or &lt;strong&gt;Deep Think for rigor and reflection&lt;/strong&gt;.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-not-the-gold-medal-winning-model-just-a-bronze"&gt;Not the gold medal winning model, just a bronze&lt;/h2&gt;



&lt;p&gt;In July, Google DeepMind made headlines when a more advanced version of the Gemini Deep Think model achieved official gold-medal status at the 2025 IMO — the world’s most prestigious mathematics competition for high school students. &lt;/p&gt;



&lt;p&gt;The system &lt;strong&gt;solved five of six challenging problems and became the first AI to receive gold-level scoring from the IMO.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;Demis Hassabis, CEO of Google DeepMind, announced the achievement on X, stating the model had solved problems end-to-end in natural language — without needing translation into formal programming syntax. &lt;/p&gt;



&lt;p&gt;The IMO board confirmed the model scored 35 out of a possible 42 points, well above the gold threshold. Gemini 2.5 Deep Think’s solutions were &lt;strong&gt;described by competition president Gregor Dolinar&lt;/strong&gt; as clear, precise, and in many cases, &lt;strong&gt;easier to follow than those of human competitors.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;However, the Gemini 2.5 Deep Think released to users is not that same competition model, rather, a lower performing but apparently faster version.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-to-access-deep-think-now"&gt;How to access Deep Think now&lt;/h2&gt;



&lt;p&gt;Gemini 2.5 Deep Think is &lt;strong&gt;available exclusively on the Google Gemini mobile app for iOS and Android at this time to users on the Google AI Ultra plan&lt;/strong&gt;, part of the Google One subscription lineup, with pricing as follows. &lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Promotional offer: &lt;strong&gt;$124.99/month for 3 months, then it kicks up to…&lt;/strong&gt;&lt;/li&gt;



&lt;li&gt;Standard rate: &lt;strong&gt;$249.99/month&lt;/strong&gt;&lt;/li&gt;



&lt;li&gt;Included features: 30 TB of storage, access to the Gemini app with Deep Think and Veo 3, as well as tools like Flow, Whisk, and 12,500 monthly AI credits&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Subscribers can activate Deep Think in the Gemini app by selecting the 2.5 Pro model and toggling the “Deep Think” option. &lt;/p&gt;



&lt;p&gt;It supports a fixed number of prompts per day and is integrated with capabilities like code execution and Google Search. The model also generates longer and more detailed outputs compared to standard versions.&lt;/p&gt;



&lt;p&gt;The lower-tier Google AI Pro plan, priced at $19.99/month (with a free trial), does not include access to Deep Think, nor does the free Gemini AI service.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-it-matters-for-enterprise-technical-decision-makers"&gt;Why it matters for enterprise technical decision-makers&lt;/h2&gt;



&lt;p&gt;Gemini 2.5 Deep Think represents the practical application of a major research milestone. &lt;/p&gt;



&lt;p&gt;It &lt;strong&gt;allows enterprises and organizations to tap into a Math Olympiad medal-winning model and have it join their staff,&lt;/strong&gt; albeit only through an individual user account now. &lt;/p&gt;



&lt;p&gt;For researchers receiving the full IMO-grade model, it offers a glimpse into the future of collaborative AI in mathematics. For Ultra subscribers, Deep Think provides a powerful step toward more capable and context-aware AI assistance, now running in the palm of their hand.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/google-releases-olympiad-medal-winning-gemini-2-5-deep-think-ai-publicly-but-theres-a-catch/</guid><pubDate>Fri, 01 Aug 2025 15:39:22 +0000</pubDate></item><item><title>[NEW] Forcing LLMs to be evil during training can make them nicer in the long run (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/08/01/1120924/forcing-llms-to-be-evil-during-training-can-make-them-nicer-in-the-long-run/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/personalities-pups.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;A new study from Anthropic suggests that traits such as sycophancy or evilness are associated with specific patterns of activity in large language models—and turning on those patterns during training can, paradoxically, prevent the model from adopting the related traits.&lt;/p&gt;  &lt;p&gt;Large language models have recently acquired a reputation for behaving badly. In April, ChatGPT suddenly became an aggressive yes-man, as opposed to the moderately sycophantic version that users were accustomed to—it endorsed harebrained business ideas, waxed lyrical about users’ intelligence, and even encouraged people to go off their psychiatric medication. OpenAI quickly rolled back the change and later published a postmortem on the mishap. More recently, xAI’s Grok adopted what can best be described as a 4chan neo-Nazi persona and repeatedly referred to itself as “MechaHitler” on X. That change, too, was quickly reversed.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Jack Lindsey, a member of the technical staff at Anthropic who led the new project, says that this study was partly inspired by seeing models adopt harmful traits in such instances. “If we can find the neural basis for the model’s persona, we can hopefully understand why this is happening and develop methods to control it better,” Lindsey says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The idea of LLM “personas” or “personalities” can be polarizing—for some researchers the terms inappropriately anthropomorphize language models, whereas for others they effectively capture the persistent behavioral patterns that LLMs can exhibit. “There’s still some scientific groundwork to be laid in terms of talking about personas,” says David Krueger, an assistant professor of computer science and operations research at the University of Montreal, who was not involved in the study. “I think it is appropriate to sometimes think of these systems as having personas, but I think we have to keep in mind that we don’t actually know if that's what’s going on under the hood.”&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;For this study, Lindsey and his colleagues worked to lay down some of that groundwork. Previous research has shown that various dimensions of LLMs’ behavior—from whether they are talking about weddings to persistent traits such as sycophancy—are associated with specific patterns of activity in the simulated neurons that constitute LLMs. Those patterns can be written down as a long string of numbers, in which each number represents how active a specific neuron is when the model is expressing that behavior.&lt;/p&gt;  &lt;p&gt;Here, the researchers focused on sycophantic, “evil”, and hallucinatory personas—three types that LLM designers might want to avoid in their models. To identify those patterns, the team devised a fully automated pipeline that can map out that pattern given a brief text description of a persona. Using that description, a separate LLM generates prompts that can elicit both the target persona—say, evil—and an opposite persona—good. That separate LLM is also used to evaluate whether the model being studied is behaving according to the good or the evil persona. To identify the evil activity pattern, the researchers subtract the model’s average activity in good mode from its average activity in evil mode.&lt;/p&gt; 
 &lt;p&gt;When, in later testing, the LLMs generated particularly sycophantic, evil, or hallucinatory responses, those same activity patterns tended to emerge. That’s a sign that researchers could eventually build a system to track those patterns and alert users when their LLMs are sucking up to them or hallucinating, Lindsey says. “I think something like that would be really valuable,” he says. “And that’s kind of where I’m hoping to get.”&lt;/p&gt;  &lt;p&gt;Just detecting those personas isn’t enough, however. Researchers want to stop them from emerging in the first place. But preventing unsavory LLM behavior is tough. Many LLMs learn from human feedback, which trains them to behave in line with user preference—but can also push them to become excessively obsequious. And recently, researchers have documented a phenomenon called “emergent misalignment,” in which models trained on incorrect solutions to math problems or buggy code extracts somehow also learn to produce unethical responses to a wide range of user queries.&lt;/p&gt;  &lt;p&gt;Other researchers have tested out an approach called “steering,” in which activity patterns within LLMs are deliberately stimulated or suppressed in order to elicit or prevent the corresponding behavior. But that approach has a couple of key downsides. Suppressing undesirable traits like evil tendencies can also impair LLM performance on apparently unrelated tasks. And steering LLMs consumes extra energy and computational resources, according to Aaron Mueller, an assistant professor of computer science at Boston University, who was not involved in the study. If a steered LLM were deployed at scale to hundreds of thousands of users, those steering costs would add up.&lt;/p&gt;  &lt;p&gt;So the Anthropic team experimented with a different approach. Rather than turning &lt;em&gt;off&lt;/em&gt; the evil or sycophantic activity patterns after training, they turned them &lt;em&gt;on&lt;/em&gt; during training. When they trained those models on mistake-ridden data sets that would normally spark evil behavior, they instead remained as helpful and harmless as ever.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;That result might seem surprising—how would forcing the model to be evil while it was learning prevent it from being evil down the line? According to Lindsey, it could be because the model has no reason to learn evil behavior if it’s already in evil mode. “The training data is teaching the model lots of things, and one of those things is to be evil,” Lindsey says. “But it’s also teaching the model a bunch of other things. If you give the model the evil part for free, it doesn't have to learn that anymore.”&lt;/p&gt;  &lt;p&gt;Unlike post-training steering, this approach didn’t compromise the model’s performance on other tasks. And it would also be more energy efficient if deployed widely. Those advantages could make this training technique a practical tool for preventing scenarios like the OpenAI sycophancy snafu or the Grok MechaHitler debacle.&lt;/p&gt;  &lt;p&gt;There’s still more work to be done before this approach can be used in popular AI chatbots like ChatGPT and Claude—not least because the models that the team tested in this study were much smaller than the models that power those chatbots. “There’s always a chance that everything changes when you scale up. But if that finding holds up, then it seems pretty exciting,” Lindsey says. “Definitely the goal is to make this ready for prime time.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/personalities-pups.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;A new study from Anthropic suggests that traits such as sycophancy or evilness are associated with specific patterns of activity in large language models—and turning on those patterns during training can, paradoxically, prevent the model from adopting the related traits.&lt;/p&gt;  &lt;p&gt;Large language models have recently acquired a reputation for behaving badly. In April, ChatGPT suddenly became an aggressive yes-man, as opposed to the moderately sycophantic version that users were accustomed to—it endorsed harebrained business ideas, waxed lyrical about users’ intelligence, and even encouraged people to go off their psychiatric medication. OpenAI quickly rolled back the change and later published a postmortem on the mishap. More recently, xAI’s Grok adopted what can best be described as a 4chan neo-Nazi persona and repeatedly referred to itself as “MechaHitler” on X. That change, too, was quickly reversed.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Jack Lindsey, a member of the technical staff at Anthropic who led the new project, says that this study was partly inspired by seeing models adopt harmful traits in such instances. “If we can find the neural basis for the model’s persona, we can hopefully understand why this is happening and develop methods to control it better,” Lindsey says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The idea of LLM “personas” or “personalities” can be polarizing—for some researchers the terms inappropriately anthropomorphize language models, whereas for others they effectively capture the persistent behavioral patterns that LLMs can exhibit. “There’s still some scientific groundwork to be laid in terms of talking about personas,” says David Krueger, an assistant professor of computer science and operations research at the University of Montreal, who was not involved in the study. “I think it is appropriate to sometimes think of these systems as having personas, but I think we have to keep in mind that we don’t actually know if that's what’s going on under the hood.”&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;For this study, Lindsey and his colleagues worked to lay down some of that groundwork. Previous research has shown that various dimensions of LLMs’ behavior—from whether they are talking about weddings to persistent traits such as sycophancy—are associated with specific patterns of activity in the simulated neurons that constitute LLMs. Those patterns can be written down as a long string of numbers, in which each number represents how active a specific neuron is when the model is expressing that behavior.&lt;/p&gt;  &lt;p&gt;Here, the researchers focused on sycophantic, “evil”, and hallucinatory personas—three types that LLM designers might want to avoid in their models. To identify those patterns, the team devised a fully automated pipeline that can map out that pattern given a brief text description of a persona. Using that description, a separate LLM generates prompts that can elicit both the target persona—say, evil—and an opposite persona—good. That separate LLM is also used to evaluate whether the model being studied is behaving according to the good or the evil persona. To identify the evil activity pattern, the researchers subtract the model’s average activity in good mode from its average activity in evil mode.&lt;/p&gt; 
 &lt;p&gt;When, in later testing, the LLMs generated particularly sycophantic, evil, or hallucinatory responses, those same activity patterns tended to emerge. That’s a sign that researchers could eventually build a system to track those patterns and alert users when their LLMs are sucking up to them or hallucinating, Lindsey says. “I think something like that would be really valuable,” he says. “And that’s kind of where I’m hoping to get.”&lt;/p&gt;  &lt;p&gt;Just detecting those personas isn’t enough, however. Researchers want to stop them from emerging in the first place. But preventing unsavory LLM behavior is tough. Many LLMs learn from human feedback, which trains them to behave in line with user preference—but can also push them to become excessively obsequious. And recently, researchers have documented a phenomenon called “emergent misalignment,” in which models trained on incorrect solutions to math problems or buggy code extracts somehow also learn to produce unethical responses to a wide range of user queries.&lt;/p&gt;  &lt;p&gt;Other researchers have tested out an approach called “steering,” in which activity patterns within LLMs are deliberately stimulated or suppressed in order to elicit or prevent the corresponding behavior. But that approach has a couple of key downsides. Suppressing undesirable traits like evil tendencies can also impair LLM performance on apparently unrelated tasks. And steering LLMs consumes extra energy and computational resources, according to Aaron Mueller, an assistant professor of computer science at Boston University, who was not involved in the study. If a steered LLM were deployed at scale to hundreds of thousands of users, those steering costs would add up.&lt;/p&gt;  &lt;p&gt;So the Anthropic team experimented with a different approach. Rather than turning &lt;em&gt;off&lt;/em&gt; the evil or sycophantic activity patterns after training, they turned them &lt;em&gt;on&lt;/em&gt; during training. When they trained those models on mistake-ridden data sets that would normally spark evil behavior, they instead remained as helpful and harmless as ever.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;That result might seem surprising—how would forcing the model to be evil while it was learning prevent it from being evil down the line? According to Lindsey, it could be because the model has no reason to learn evil behavior if it’s already in evil mode. “The training data is teaching the model lots of things, and one of those things is to be evil,” Lindsey says. “But it’s also teaching the model a bunch of other things. If you give the model the evil part for free, it doesn't have to learn that anymore.”&lt;/p&gt;  &lt;p&gt;Unlike post-training steering, this approach didn’t compromise the model’s performance on other tasks. And it would also be more energy efficient if deployed widely. Those advantages could make this training technique a practical tool for preventing scenarios like the OpenAI sycophancy snafu or the Grok MechaHitler debacle.&lt;/p&gt;  &lt;p&gt;There’s still more work to be done before this approach can be used in popular AI chatbots like ChatGPT and Claude—not least because the models that the team tested in this study were much smaller than the models that power those chatbots. “There’s always a chance that everything changes when you scale up. But if that finding holds up, then it seems pretty exciting,” Lindsey says. “Definitely the goal is to make this ready for prime time.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/08/01/1120924/forcing-llms-to-be-evil-during-training-can-make-them-nicer-in-the-long-run/</guid><pubDate>Fri, 01 Aug 2025 16:00:00 +0000</pubDate></item><item><title>[NEW] More details emerge on how Windsurf’s VCs and founders got paid from the Google deal (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/01/more-details-emerge-on-how-windsurfs-vcs-and-founders-got-paid-from-the-google-deal/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-2225304419.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Weeks after the revelation that Google paid Windsurf $2.4 billion to license its technology, while simultaneously hiring away its CEO and top talent, the deal’s implications are still rattling some founders and startup employees across Silicon Valley.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google’s payment to the startup was effectively split in two equal parts, according to two people familiar with the deal. Investors’ portion was $1.2 billion.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The other half was in the form of compensation packages for approximately 40 Windsurf employees hired by the tech giant with a substantial portion of that $1.2 billion going to the startup’s co-founders, Varun Mohan and Douglas Chen, sources say.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The transaction was a good outcome for VCs, which included Greenoaks, Kleiner Perkins, and General Catalyst. Windsurf raised a total of about $243 million as of its last raise in 2024 that valued the company at $1.25 billion, which means the total return to investors was about 4x their original funding.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Greenoaks, which led Windsurf’s seed and Series A financings and owned 20% of the company, returned about $500 million on their $65 million investment in the startup, according to a person familiar with the matter. Kleiner Perkins, which led Windsurf’s Series B, returned about 3x its invested capital, according to another person familiar with the deal.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google, Kleiner Perkins, and Greenoaks declined to comment. General Catalyst, Varun Mohan, and Douglas Chen didn’t respond to a request for comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even so, most investors were aiming for a more significant win from the company.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In February, TechCrunch reported that Kleiner Perkins was in talks to lead a fresh round of funding, valuing the startup, which was then known as Codeium, at $2.85 billion. That deal didn’t happen, according to a person familiar with the matter, because Windsurf had instead agreed to be purchased by OpenAI for $3 billion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As we all know now, the OpenAI acquisition unraveled and Google swooped in with its deal structured to offer investor returns and obtain talent and IP without acquiring stock.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But what’s rattling the Valley is this: While Google’s deal was good for the co-founders and VCs, it didn’t benefit a large portion of Windsurf’s approximately 250 employees, especially after they were expecting a payout from the sale to OpenAI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In a typical acquisition, employees would get money for the shares they owned and would often have their vesting schedule accelerated. However, Windsurf employees who were hired over the last year didn’t receive a payout from the deal, these people said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Google deal was especially unsettling to approximately 200 Windsurf employees not hired by the search giant.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Instead of siphoning every penny of Google’s payment into their own pockets, investors opted to leave the company with over $100 million in capital.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One source says this was entirely funded by VCs, meaning their total payout was about $1.1 billion. However, another person said that the founders equally chipped in to leave the company with a nest egg from the Google payment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Multiple people said that the money left for the company would have been sufficient to pay all remaining employees proceeds at the Google deal’s per-share valuation, regardless of how long they had been with the company.&amp;nbsp; However, to have done that immediately would have been problematic, leaving the company with less cash to operate and — with founders and key people gone — with no investors ready to finance a new raise. The remaining leadership would likely have had to shut down after making such cash distributions, one of the people said. Meanwhile, another person claimed that the company had enough capital to pay out employees and continue to operate.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That difference of opinion is only part of the reason the deal became so controversial.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What’s more, at least some of the employees Google did hire, despite attractive pay and benefits, saw their stock grants revoked and their vesting timelines restarted. That meant they’d have to wait an additional four years for their total payout in Google stock, according to people familiar with the deal.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some top VCs condemned the 3-year-old startup’s co-founders for not sharing their windfall with all the people who helped build the company.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Windsurf and others are really bad examples of founders leaving their teams behind and not even sharing the proceeds with their team,” wrote Vinod Khosla on X. “I definitely would not work with their founders next time.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After several days of limbo following the announcement of the Google deal, Windsurf’s remaining entity, under the leadership of interim CEO Jeff Wang, managed to sell itself to Cognition.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cognition acquired Windsurf’s IP and product and brought on all staff not hired by Google.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the exact deal terms of that sale were not disclosed, the acquisition allowed every employee to financially gain from the sale, according to a blog published by Cognition.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Two other sources estimated to TechCrunch that Cognition paid $250 million to acquire Windsurf’s remaining entity.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cognition didn’t respond to a request for comment.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-2225304419.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Weeks after the revelation that Google paid Windsurf $2.4 billion to license its technology, while simultaneously hiring away its CEO and top talent, the deal’s implications are still rattling some founders and startup employees across Silicon Valley.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google’s payment to the startup was effectively split in two equal parts, according to two people familiar with the deal. Investors’ portion was $1.2 billion.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The other half was in the form of compensation packages for approximately 40 Windsurf employees hired by the tech giant with a substantial portion of that $1.2 billion going to the startup’s co-founders, Varun Mohan and Douglas Chen, sources say.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The transaction was a good outcome for VCs, which included Greenoaks, Kleiner Perkins, and General Catalyst. Windsurf raised a total of about $243 million as of its last raise in 2024 that valued the company at $1.25 billion, which means the total return to investors was about 4x their original funding.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Greenoaks, which led Windsurf’s seed and Series A financings and owned 20% of the company, returned about $500 million on their $65 million investment in the startup, according to a person familiar with the matter. Kleiner Perkins, which led Windsurf’s Series B, returned about 3x its invested capital, according to another person familiar with the deal.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google, Kleiner Perkins, and Greenoaks declined to comment. General Catalyst, Varun Mohan, and Douglas Chen didn’t respond to a request for comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even so, most investors were aiming for a more significant win from the company.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In February, TechCrunch reported that Kleiner Perkins was in talks to lead a fresh round of funding, valuing the startup, which was then known as Codeium, at $2.85 billion. That deal didn’t happen, according to a person familiar with the matter, because Windsurf had instead agreed to be purchased by OpenAI for $3 billion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As we all know now, the OpenAI acquisition unraveled and Google swooped in with its deal structured to offer investor returns and obtain talent and IP without acquiring stock.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But what’s rattling the Valley is this: While Google’s deal was good for the co-founders and VCs, it didn’t benefit a large portion of Windsurf’s approximately 250 employees, especially after they were expecting a payout from the sale to OpenAI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In a typical acquisition, employees would get money for the shares they owned and would often have their vesting schedule accelerated. However, Windsurf employees who were hired over the last year didn’t receive a payout from the deal, these people said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Google deal was especially unsettling to approximately 200 Windsurf employees not hired by the search giant.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Instead of siphoning every penny of Google’s payment into their own pockets, investors opted to leave the company with over $100 million in capital.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One source says this was entirely funded by VCs, meaning their total payout was about $1.1 billion. However, another person said that the founders equally chipped in to leave the company with a nest egg from the Google payment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Multiple people said that the money left for the company would have been sufficient to pay all remaining employees proceeds at the Google deal’s per-share valuation, regardless of how long they had been with the company.&amp;nbsp; However, to have done that immediately would have been problematic, leaving the company with less cash to operate and — with founders and key people gone — with no investors ready to finance a new raise. The remaining leadership would likely have had to shut down after making such cash distributions, one of the people said. Meanwhile, another person claimed that the company had enough capital to pay out employees and continue to operate.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That difference of opinion is only part of the reason the deal became so controversial.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What’s more, at least some of the employees Google did hire, despite attractive pay and benefits, saw their stock grants revoked and their vesting timelines restarted. That meant they’d have to wait an additional four years for their total payout in Google stock, according to people familiar with the deal.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some top VCs condemned the 3-year-old startup’s co-founders for not sharing their windfall with all the people who helped build the company.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Windsurf and others are really bad examples of founders leaving their teams behind and not even sharing the proceeds with their team,” wrote Vinod Khosla on X. “I definitely would not work with their founders next time.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After several days of limbo following the announcement of the Google deal, Windsurf’s remaining entity, under the leadership of interim CEO Jeff Wang, managed to sell itself to Cognition.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cognition acquired Windsurf’s IP and product and brought on all staff not hired by Google.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the exact deal terms of that sale were not disclosed, the acquisition allowed every employee to financially gain from the sale, according to a blog published by Cognition.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Two other sources estimated to TechCrunch that Cognition paid $250 million to acquire Windsurf’s remaining entity.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cognition didn’t respond to a request for comment.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/01/more-details-emerge-on-how-windsurfs-vcs-and-founders-got-paid-from-the-google-deal/</guid><pubDate>Fri, 01 Aug 2025 16:00:00 +0000</pubDate></item><item><title>[NEW] From Meta’s massive offers to Anthropic’s massive valuation, does AI have a ceiling? (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/podcast/from-metas-massive-offers-to-anthropics-massive-valuation-does-ai-have-a-ceiling/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/08/GettyImages-2154160973-e1723115200227.jpg?resize=1200,673" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;Meta is still going all-in on the AI talent war, with Mark Zuckerberg reportedly reaching out to top recruits himself, throwing around jaw-dropping compensation packages that top $1 billion over multiple years. And Meta’s latest target? Mira Murati’s new startup, Thinking Machines Lab. It’s a bold play in an already overheated market.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;While Zuck eyes new talent, Anthropic is preparing to raise a massive round of its own at a staggering $170 billion valuation, nearly tripling its worth in just months. On paper, it looks like the AI cash floodgates are wide open. But all this endless money raises some serious questions about sustainability.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;On today’s episode of Equity, Kirsten Korosec, Anthony Ha, and Max Zeff unpack the reality behind these eye-popping figures. With compensation packages skyrocketing and funding rounds swelling, how long can this race actually last?&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear more about:&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Equity will be back for you next week, so don’t miss it!&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Subscribe to us on&lt;/em&gt;&lt;em&gt; &lt;/em&gt;&lt;em&gt;Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/08/GettyImages-2154160973-e1723115200227.jpg?resize=1200,673" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;Meta is still going all-in on the AI talent war, with Mark Zuckerberg reportedly reaching out to top recruits himself, throwing around jaw-dropping compensation packages that top $1 billion over multiple years. And Meta’s latest target? Mira Murati’s new startup, Thinking Machines Lab. It’s a bold play in an already overheated market.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;While Zuck eyes new talent, Anthropic is preparing to raise a massive round of its own at a staggering $170 billion valuation, nearly tripling its worth in just months. On paper, it looks like the AI cash floodgates are wide open. But all this endless money raises some serious questions about sustainability.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;On today’s episode of Equity, Kirsten Korosec, Anthony Ha, and Max Zeff unpack the reality behind these eye-popping figures. With compensation packages skyrocketing and funding rounds swelling, how long can this race actually last?&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear more about:&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Equity will be back for you next week, so don’t miss it!&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Subscribe to us on&lt;/em&gt;&lt;em&gt; &lt;/em&gt;&lt;em&gt;Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/podcast/from-metas-massive-offers-to-anthropics-massive-valuation-does-ai-have-a-ceiling/</guid><pubDate>Fri, 01 Aug 2025 16:12:39 +0000</pubDate></item><item><title>[NEW] Amazon is considering shoving ads into Alexa+ conversations (AI – Ars Technica)</title><link>https://arstechnica.com/gadgets/2025/08/amazon-is-considering-shoving-ads-into-alexa-conversations/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Amazon has failed to make Alexa profitable thus far.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Alexa+ logo with a person standing in front of it" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2201505743-640x427.jpg" width="640" /&gt;
                  &lt;img alt="Alexa+ logo with a person standing in front of it" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2201505743-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Alexa+ signage during an unveiling event in New York, US, on Wednesday, Feb. 26, 2025. Amazon has rebooted Alexa with artificial intelligence, marking the biggest overhaul of the voice-activated assistant since its introduction over a decade ago. 

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Michael Nagle/Bloomberg via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Since 2023, Amazon has been framing Alexa+ as a monumental evolution of Amazon’s voice assistant that will make it more conversational, capable, and, for Amazon, lucrative. Amazon said in a press release on Thursday that it has given early access of the generative AI voice assistant to “millions” of people. The product isn’t publicly available yet, and some advertised features are still unavailable, but Amazon’s CEO is already considering loading the chatbot up with ads.&lt;/p&gt;
&lt;p&gt;During an investors call yesterday, as reported by TechCrunch, Andy Jassy noted that Alexa+ started rolling out as early access to some customers in the US and that a broader rollout, including internationally, should happen later this year. An analyst on the call asked Amazon executives about Alexa+'s potential for “increasing engagement” long term.&lt;/p&gt;
&lt;p&gt;Per a transcript of the call, Jassy responded by saying, in part, "I think over time, there will be opportunities, you know, as people are engaging in more multi-turn conversations to have advertising play a role to help people find discovery and also as a lever to drive revenue."&lt;/p&gt;
&lt;p&gt;Like other voice assistants, Alexa has yet to monetize users. Amazon is hoping to finally make money off the service through Alexa+, which is eventually slated to play a bigger role in e-commerce, including by booking restaurant reservations, keeping track of and ordering groceries, and recommending streaming content based on stated interests. But with Alexa reportedly costing Amazon $25 billion across four years, Amazon is eyeing additional routes to profitability.&lt;/p&gt;
&lt;p&gt;Echo Show devices already show ads, and Echo speaker users may hear ads when listening to music. Advertisers have shown interest in advertising with Alexa+, but the inclusion of ads in a new offering like Alexa+ could drive people away.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;As Joel Daly, co-founder of marketing agency Artemis Ward, told Digiday in March:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;They [Amazon] recognize the risk of alienating audiences who have yet to see the full potential of voice assistants, which have yet to be fully realized, not to mention privacy concerns. The combination of tailored advertising with the perceived invasiveness of always-listening voice devices can discourage adoption.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Even though Jassy framed Alexa+ ads as a way to help users find stuff they're interested in, ads seem more aimed at solving Amazon's financial problems with voice assistants than helping customers find relevant information quickly and reliably. Notably, though, Amazon isn't the only chatbot maker exploring ads: Google's AI Overview, for example, already has ads, and Google has been testing ads in AI Mode. OpenAI CEO Sam Altman hasn't ruled out ads in ChatGPT.&lt;/p&gt;
&lt;p&gt;But Alexa+ is still in the early stages, meaning that Amazon's bigger priorities are catching up with the competition, rolling out more of Alexa+'s promised features, and making the chatbot publicly available.&lt;/p&gt;
&lt;p&gt;Beyond ads, Jassy is mulling additional ways to prevent Alexa+ from being the financial failure of its predecessor. The service is still only available as early access to Echo Show 8, 15, and 21 owners in the US, but once it reaches public availability, it will be free for Amazon Prime subscribers (Prime starts at $15 per month) or $20/month if you don’t have Prime. During yesterday’s earnings call, Jassy pointed to the potential for charging extra for Alexa+ features as they are made available.&lt;/p&gt;
&lt;p&gt;"It’s still very early days, but we’re very encouraged by the experience we’re providing, and you can bet we’re gonna be iterating on it constantly,” he said.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Amazon has failed to make Alexa profitable thus far.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Alexa+ logo with a person standing in front of it" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2201505743-640x427.jpg" width="640" /&gt;
                  &lt;img alt="Alexa+ logo with a person standing in front of it" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2201505743-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Alexa+ signage during an unveiling event in New York, US, on Wednesday, Feb. 26, 2025. Amazon has rebooted Alexa with artificial intelligence, marking the biggest overhaul of the voice-activated assistant since its introduction over a decade ago. 

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Michael Nagle/Bloomberg via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Since 2023, Amazon has been framing Alexa+ as a monumental evolution of Amazon’s voice assistant that will make it more conversational, capable, and, for Amazon, lucrative. Amazon said in a press release on Thursday that it has given early access of the generative AI voice assistant to “millions” of people. The product isn’t publicly available yet, and some advertised features are still unavailable, but Amazon’s CEO is already considering loading the chatbot up with ads.&lt;/p&gt;
&lt;p&gt;During an investors call yesterday, as reported by TechCrunch, Andy Jassy noted that Alexa+ started rolling out as early access to some customers in the US and that a broader rollout, including internationally, should happen later this year. An analyst on the call asked Amazon executives about Alexa+'s potential for “increasing engagement” long term.&lt;/p&gt;
&lt;p&gt;Per a transcript of the call, Jassy responded by saying, in part, "I think over time, there will be opportunities, you know, as people are engaging in more multi-turn conversations to have advertising play a role to help people find discovery and also as a lever to drive revenue."&lt;/p&gt;
&lt;p&gt;Like other voice assistants, Alexa has yet to monetize users. Amazon is hoping to finally make money off the service through Alexa+, which is eventually slated to play a bigger role in e-commerce, including by booking restaurant reservations, keeping track of and ordering groceries, and recommending streaming content based on stated interests. But with Alexa reportedly costing Amazon $25 billion across four years, Amazon is eyeing additional routes to profitability.&lt;/p&gt;
&lt;p&gt;Echo Show devices already show ads, and Echo speaker users may hear ads when listening to music. Advertisers have shown interest in advertising with Alexa+, but the inclusion of ads in a new offering like Alexa+ could drive people away.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;As Joel Daly, co-founder of marketing agency Artemis Ward, told Digiday in March:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;They [Amazon] recognize the risk of alienating audiences who have yet to see the full potential of voice assistants, which have yet to be fully realized, not to mention privacy concerns. The combination of tailored advertising with the perceived invasiveness of always-listening voice devices can discourage adoption.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Even though Jassy framed Alexa+ ads as a way to help users find stuff they're interested in, ads seem more aimed at solving Amazon's financial problems with voice assistants than helping customers find relevant information quickly and reliably. Notably, though, Amazon isn't the only chatbot maker exploring ads: Google's AI Overview, for example, already has ads, and Google has been testing ads in AI Mode. OpenAI CEO Sam Altman hasn't ruled out ads in ChatGPT.&lt;/p&gt;
&lt;p&gt;But Alexa+ is still in the early stages, meaning that Amazon's bigger priorities are catching up with the competition, rolling out more of Alexa+'s promised features, and making the chatbot publicly available.&lt;/p&gt;
&lt;p&gt;Beyond ads, Jassy is mulling additional ways to prevent Alexa+ from being the financial failure of its predecessor. The service is still only available as early access to Echo Show 8, 15, and 21 owners in the US, but once it reaches public availability, it will be free for Amazon Prime subscribers (Prime starts at $15 per month) or $20/month if you don’t have Prime. During yesterday’s earnings call, Jassy pointed to the potential for charging extra for Alexa+ features as they are made available.&lt;/p&gt;
&lt;p&gt;"It’s still very early days, but we’re very encouraged by the experience we’re providing, and you can bet we’re gonna be iterating on it constantly,” he said.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/gadgets/2025/08/amazon-is-considering-shoving-ads-into-alexa-conversations/</guid><pubDate>Fri, 01 Aug 2025 17:04:39 +0000</pubDate></item><item><title>[NEW] Google bets on STAN, an Indian social gaming platform (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/01/google-bets-on-stan-an-indian-social-gaming-platform/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google has backed STAN, an Indian social gaming platform that connects gamers with creators, communities, and publishers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google’s investment comes as part of an $8.5 million equity funding round, which also saw investment from Japanese gaming giants Bandai Namco Entertainment, Square Enix, and Reazon Holdings. Aptos Labs and King River Capital, as well as existing backers General Catalyst and GFR Fund, also participated. Google joined the round via its AI Futures Fund, which launched in May to support startups building with its AI tools.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;STAN, headquartered in Singapore, is trying to position itself as a gaming community platform to rival Discord, but its approach to the market is quite different. STAN lets users earn in-app currency called “Gems” by winning games like Krafton’s Battlegrounds Mobile India, Garena’s Free Fire Max, Minecraft, Call of Duty, or casual titles like Ludo and Snakes &amp;amp; Ladders. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The app also lets creators set up chat rooms called Clubs, which are channels tailored for each game on the platform. While anyone can join these Clubs, they need to pay a social currency to access the “gaming experiences” that creators offer. The startup takes a commission from these transactions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The primary attraction seems to be the in-app currency, however, as it can be redeemed for vouchers on various e-commerce platforms like Amazon, PhonePe, and Flipkart. Users can also earn currency via referrals, a spin-to-win wheel, and daily rewards.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It appears STAN’s monetization model is what sets it apart: users can earn rewards through interactions, unlike on Discord, where chatting or participating in communities doesn’t earn users much, apart from clout.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nonetheless, STAN wants to shadow Discord. The company claims it has already garnered over 25 million downloads on the Play Store and App Store altogether, and has around 5.5 million monthly active users.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3032909" height="1300" src="https://techcrunch.com/wp-content/uploads/2025/07/stan-communities.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;STAN&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“STAN is the hangout place for gamers. It’s a place where gamers come and make friends, play with each other, talk to each other, sort of a fusion of social and gaming,” said Parth Chadha, co-founder and CEO of STAN, in an interview.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Chadha credits the platform’s features for its traction so far. Initially, creators had to contact the company’s team to start streaming, but last year, the startup opened the platform to user-generated content, allowing anyone to go live. That shift helped drive both downloads and engagement, the CEO said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;STAN also works with game publishers, studios, and developers, including Krafton, Garena, and Roblox, who pay the startup to connect them with gamers and creators on the platform.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Chadha told TechCrunch that in the past two quarters, nearly 100 game publishers, studios, and developers have joined the platform, and it is bringing more than 20 on board each month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“That is turning into a very interesting business stream as we speak,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Looking ahead, STAN plans to leverage Google’s backing to use AI to improve moderation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Currently 70% to 80% of moderation on STAN is already handled by AI, Chadha said. A human moderation team manages the rest, but the startup plans to reduce that further by using AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Additionally, STAN aims to bring AI-powered toolkits for creators, including the ability to produce avatars and memes, as well as tools for quick replies and filtering out chats.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“There are a lot of interesting plug-and-play models, which we and the Google team are working together to leverage and scale the business,” he stated.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;STAN isn’t the first Indian startup to be backed by Google’s AI Futures Fund. That distinction goes to Toonsutra, a startup using AI to power an immersive comic-reading experience.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google confirmed to TechCrunch that it has invested over $5.5 billion in India to date, including in startups Toonsutra, STAN, Pixxel, and Adda 24X7.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Although STAN’s app is currently geo-restricted to India, the platform still sees 5%–6% of its engagement coming from users abroad, who often access it using Indian phone numbers and accounts. Over the next year, the startup plans to expand internationally, starting with the Indian subcontinent, and will later target Southeast Asia and Latin America.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup was profitable for a few months, the CEO said, but decided to spend some money to scale. Now, it aims to achieve profitability in 2027, he added. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Currently, the startup employs about 40 people, of whom less than 30 work in product engineering.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With this raise, STAN’s total equity funding now stands at around $15 million.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google has backed STAN, an Indian social gaming platform that connects gamers with creators, communities, and publishers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google’s investment comes as part of an $8.5 million equity funding round, which also saw investment from Japanese gaming giants Bandai Namco Entertainment, Square Enix, and Reazon Holdings. Aptos Labs and King River Capital, as well as existing backers General Catalyst and GFR Fund, also participated. Google joined the round via its AI Futures Fund, which launched in May to support startups building with its AI tools.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;STAN, headquartered in Singapore, is trying to position itself as a gaming community platform to rival Discord, but its approach to the market is quite different. STAN lets users earn in-app currency called “Gems” by winning games like Krafton’s Battlegrounds Mobile India, Garena’s Free Fire Max, Minecraft, Call of Duty, or casual titles like Ludo and Snakes &amp;amp; Ladders. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The app also lets creators set up chat rooms called Clubs, which are channels tailored for each game on the platform. While anyone can join these Clubs, they need to pay a social currency to access the “gaming experiences” that creators offer. The startup takes a commission from these transactions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The primary attraction seems to be the in-app currency, however, as it can be redeemed for vouchers on various e-commerce platforms like Amazon, PhonePe, and Flipkart. Users can also earn currency via referrals, a spin-to-win wheel, and daily rewards.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It appears STAN’s monetization model is what sets it apart: users can earn rewards through interactions, unlike on Discord, where chatting or participating in communities doesn’t earn users much, apart from clout.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nonetheless, STAN wants to shadow Discord. The company claims it has already garnered over 25 million downloads on the Play Store and App Store altogether, and has around 5.5 million monthly active users.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3032909" height="1300" src="https://techcrunch.com/wp-content/uploads/2025/07/stan-communities.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;STAN&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“STAN is the hangout place for gamers. It’s a place where gamers come and make friends, play with each other, talk to each other, sort of a fusion of social and gaming,” said Parth Chadha, co-founder and CEO of STAN, in an interview.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Chadha credits the platform’s features for its traction so far. Initially, creators had to contact the company’s team to start streaming, but last year, the startup opened the platform to user-generated content, allowing anyone to go live. That shift helped drive both downloads and engagement, the CEO said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;STAN also works with game publishers, studios, and developers, including Krafton, Garena, and Roblox, who pay the startup to connect them with gamers and creators on the platform.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Chadha told TechCrunch that in the past two quarters, nearly 100 game publishers, studios, and developers have joined the platform, and it is bringing more than 20 on board each month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“That is turning into a very interesting business stream as we speak,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Looking ahead, STAN plans to leverage Google’s backing to use AI to improve moderation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Currently 70% to 80% of moderation on STAN is already handled by AI, Chadha said. A human moderation team manages the rest, but the startup plans to reduce that further by using AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Additionally, STAN aims to bring AI-powered toolkits for creators, including the ability to produce avatars and memes, as well as tools for quick replies and filtering out chats.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“There are a lot of interesting plug-and-play models, which we and the Google team are working together to leverage and scale the business,” he stated.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;STAN isn’t the first Indian startup to be backed by Google’s AI Futures Fund. That distinction goes to Toonsutra, a startup using AI to power an immersive comic-reading experience.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google confirmed to TechCrunch that it has invested over $5.5 billion in India to date, including in startups Toonsutra, STAN, Pixxel, and Adda 24X7.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Although STAN’s app is currently geo-restricted to India, the platform still sees 5%–6% of its engagement coming from users abroad, who often access it using Indian phone numbers and accounts. Over the next year, the startup plans to expand internationally, starting with the Indian subcontinent, and will later target Southeast Asia and Latin America.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup was profitable for a few months, the CEO said, but decided to spend some money to scale. Now, it aims to achieve profitability in 2027, he added. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Currently, the startup employs about 40 people, of whom less than 30 work in product engineering.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With this raise, STAN’s total equity funding now stands at around $15 million.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/01/google-bets-on-stan-an-indian-social-gaming-platform/</guid><pubDate>Fri, 01 Aug 2025 17:05:45 +0000</pubDate></item><item><title>[NEW] ChatGPT users shocked to learn their chats were in Google search results (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/08/chatgpt-users-shocked-to-learn-their-chats-were-in-google-search-results/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        OpenAI scrambles to remove personal ChatGPT conversations from Google results.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2220566217-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2220566217-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Tim Robberts | Photodisc

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Faced with mounting backlash, OpenAI removed a controversial ChatGPT feature that caused some users to unintentionally allow their private—and highly personal—chats to appear in search results.&lt;/p&gt;
&lt;p&gt;Fast Company exposed the privacy issue on Wednesday, reporting that thousands of ChatGPT conversations were found in Google search results and likely only represented a sample of chats "visible to millions." While the indexing did not include identifying information about the ChatGPT users, some of their chats did share personal details—like highly specific descriptions of interpersonal relationships with friends and family members—perhaps making it possible to identify them, Fast Company found.&lt;/p&gt;
&lt;p&gt;OpenAI's chief information security officer, Dane Stuckey, explained on X that all users whose chats were exposed opted in to indexing their chats by clicking a box after choosing to share a chat.&lt;/p&gt;
&lt;p&gt;Fast Company noted that users often share chats on WhatsApp or select the option to save a link to visit the chat later. But as Fast Company explained, users may have been misled into sharing chats due to how the text was formatted:&lt;/p&gt;
&lt;p&gt;"When users clicked 'Share,' they were presented with an option to tick a box labeled 'Make this chat discoverable.' Beneath that, in smaller, lighter text, was a caveat explaining that the chat could then appear in search engine results."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2109797 align-none"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="none medium" height="452" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/ChatGPT-Share-box-via-Dane-Stuckey-on-X-640x452.jpeg" width="640" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          ChatGPT Share box via Dane Stuckey on X

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;At first, OpenAI defended the labeling as "sufficiently clear," Fast Company reported Thursday. But Stuckey confirmed that "ultimately," the AI company decided that the feature "introduced too many opportunities for folks to accidentally share things they didn't intend to." According to Fast Company, that included chats about their drug use, sex lives, mental health, and traumatic experiences.&lt;/p&gt;
&lt;p&gt;Carissa Veliz, an AI ethicist at the University of Oxford, told Fast Company she was "shocked" that Google was logging "these extremely sensitive conversations."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;OpenAI promises to remove Google search results&lt;/h2&gt;
&lt;p&gt;Stuckey called the feature a "short-lived experiment" that OpenAI launched "to help people discover useful conversations." He confirmed that the decision to remove the feature also included an effort to "remove indexed content from the relevant search engine" through Friday morning.&lt;/p&gt;
&lt;p&gt;Google did not respond to Ars' request to comment and declined to comment on Fast Company's reporting—leaving it unclear if all indexed chats have been removed yet and what role the search giant may have played in how private chats were displayed.&lt;/p&gt;
&lt;p&gt;Véliz told Fast Company that even a "short-lived" experiment like this is "troubling," noting that "tech companies use the general population as guinea pigs," attracting swarms of users with new AI products and waiting to see what consequences they may face for invasive design choices.&lt;/p&gt;
&lt;p&gt;"They do something, they try it out on the population, and see if somebody complains," Véliz said.&lt;/p&gt;
&lt;p&gt;To check if private chats are still being indexed, a Fast Company explanation suggests that users who still have access to their shared links can try inputting the "part of the link created when someone proactively clicks 'Share' on ChatGPT [to] uncover conversations" that may still be discoverable on Google.&lt;/p&gt;
&lt;p&gt;OpenAI declined Ars' request to comment, but Stuckey's statement suggested that the company knows it has to earn back trust after the misstep.&lt;/p&gt;
&lt;p&gt;"Security and privacy are paramount for us, and we'll keep working to maximally reflect that in our products and features," Stuckey said.&lt;/p&gt;
&lt;p&gt;The scandal notably comes after OpenAI vowed to fight a court order that requires it to preserve all deleted chats "indefinitely," which worries ChatGPT users who previously felt assured their temporary and deleted chats were not being saved. OpenAI has so far lost that fight, and those chats will likely be searchable soon in that lawsuit. But while OpenAI CEO Sam Altman considered the possibility that users' most private chats could be searched to be "screwed up," Fast Company noted that Altman did not seem to be as transparently critical about the potential for OpenAI's own practices to expose private user chats on Google and other search engines.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        OpenAI scrambles to remove personal ChatGPT conversations from Google results.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2220566217-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2220566217-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Tim Robberts | Photodisc

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Faced with mounting backlash, OpenAI removed a controversial ChatGPT feature that caused some users to unintentionally allow their private—and highly personal—chats to appear in search results.&lt;/p&gt;
&lt;p&gt;Fast Company exposed the privacy issue on Wednesday, reporting that thousands of ChatGPT conversations were found in Google search results and likely only represented a sample of chats "visible to millions." While the indexing did not include identifying information about the ChatGPT users, some of their chats did share personal details—like highly specific descriptions of interpersonal relationships with friends and family members—perhaps making it possible to identify them, Fast Company found.&lt;/p&gt;
&lt;p&gt;OpenAI's chief information security officer, Dane Stuckey, explained on X that all users whose chats were exposed opted in to indexing their chats by clicking a box after choosing to share a chat.&lt;/p&gt;
&lt;p&gt;Fast Company noted that users often share chats on WhatsApp or select the option to save a link to visit the chat later. But as Fast Company explained, users may have been misled into sharing chats due to how the text was formatted:&lt;/p&gt;
&lt;p&gt;"When users clicked 'Share,' they were presented with an option to tick a box labeled 'Make this chat discoverable.' Beneath that, in smaller, lighter text, was a caveat explaining that the chat could then appear in search engine results."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2109797 align-none"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="none medium" height="452" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/ChatGPT-Share-box-via-Dane-Stuckey-on-X-640x452.jpeg" width="640" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          ChatGPT Share box via Dane Stuckey on X

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;At first, OpenAI defended the labeling as "sufficiently clear," Fast Company reported Thursday. But Stuckey confirmed that "ultimately," the AI company decided that the feature "introduced too many opportunities for folks to accidentally share things they didn't intend to." According to Fast Company, that included chats about their drug use, sex lives, mental health, and traumatic experiences.&lt;/p&gt;
&lt;p&gt;Carissa Veliz, an AI ethicist at the University of Oxford, told Fast Company she was "shocked" that Google was logging "these extremely sensitive conversations."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;OpenAI promises to remove Google search results&lt;/h2&gt;
&lt;p&gt;Stuckey called the feature a "short-lived experiment" that OpenAI launched "to help people discover useful conversations." He confirmed that the decision to remove the feature also included an effort to "remove indexed content from the relevant search engine" through Friday morning.&lt;/p&gt;
&lt;p&gt;Google did not respond to Ars' request to comment and declined to comment on Fast Company's reporting—leaving it unclear if all indexed chats have been removed yet and what role the search giant may have played in how private chats were displayed.&lt;/p&gt;
&lt;p&gt;Véliz told Fast Company that even a "short-lived" experiment like this is "troubling," noting that "tech companies use the general population as guinea pigs," attracting swarms of users with new AI products and waiting to see what consequences they may face for invasive design choices.&lt;/p&gt;
&lt;p&gt;"They do something, they try it out on the population, and see if somebody complains," Véliz said.&lt;/p&gt;
&lt;p&gt;To check if private chats are still being indexed, a Fast Company explanation suggests that users who still have access to their shared links can try inputting the "part of the link created when someone proactively clicks 'Share' on ChatGPT [to] uncover conversations" that may still be discoverable on Google.&lt;/p&gt;
&lt;p&gt;OpenAI declined Ars' request to comment, but Stuckey's statement suggested that the company knows it has to earn back trust after the misstep.&lt;/p&gt;
&lt;p&gt;"Security and privacy are paramount for us, and we'll keep working to maximally reflect that in our products and features," Stuckey said.&lt;/p&gt;
&lt;p&gt;The scandal notably comes after OpenAI vowed to fight a court order that requires it to preserve all deleted chats "indefinitely," which worries ChatGPT users who previously felt assured their temporary and deleted chats were not being saved. OpenAI has so far lost that fight, and those chats will likely be searchable soon in that lawsuit. But while OpenAI CEO Sam Altman considered the possibility that users' most private chats could be searched to be "screwed up," Fast Company noted that Altman did not seem to be as transparently critical about the potential for OpenAI's own practices to expose private user chats on Google and other search engines.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/08/chatgpt-users-shocked-to-learn-their-chats-were-in-google-search-results/</guid><pubDate>Fri, 01 Aug 2025 17:21:54 +0000</pubDate></item></channel></rss>