<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Mon, 30 Jun 2025 06:34:48 +0000</lastBuildDate><item><title>OpenAI reportedly ‘recalibrating’ compensation in response to Meta hires (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/29/openai-reportedly-recalibrating-compensation-in-response-to-meta-hires/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2021258442.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;With Meta successfully poaching a number of its senior researchers, an OpenAI executive reportedly reassured team members Saturday that company leadership has not “been standing idly by.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I feel a visceral feeling right now, as if someone has broken into our home and stolen something,” Chief Research Officer Mark Chen wrote in a Slack memo obtained by Wired.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In response to what appears to be a Meta hiring spree, Chen said that he, CEO Sam Altman, and other OpenAI leaders have been working “around the clock to talk to those with offers,” and they’ve “been more proactive than ever before, we’re recalibrating comp, and we’re scoping out creative ways to recognize and reward top talent.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Over the past week, various press reports have noted eight researchers who departed OpenAI for Meta. Altman even complained on a podcast that Meta was offering “$100 million signing bonuses,” a description that Meta executives have pushed back against internally.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2021258442.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;With Meta successfully poaching a number of its senior researchers, an OpenAI executive reportedly reassured team members Saturday that company leadership has not “been standing idly by.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I feel a visceral feeling right now, as if someone has broken into our home and stolen something,” Chief Research Officer Mark Chen wrote in a Slack memo obtained by Wired.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In response to what appears to be a Meta hiring spree, Chen said that he, CEO Sam Altman, and other OpenAI leaders have been working “around the clock to talk to those with offers,” and they’ve “been more proactive than ever before, we’re recalibrating comp, and we’re scoping out creative ways to recognize and reward top talent.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Over the past week, various press reports have noted eight researchers who departed OpenAI for Meta. Altman even complained on a podcast that Meta was offering “$100 million signing bonuses,” a description that Meta executives have pushed back against internally.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/29/openai-reportedly-recalibrating-compensation-in-response-to-meta-hires/</guid><pubDate>Sun, 29 Jun 2025 20:16:40 +0000</pubDate></item><item><title>Between utopia and collapse: Navigating AI’s murky middle future (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/between-utopia-and-collapse-navigating-ais-murky-middle-future/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;In the blog post &lt;em&gt;The Gentle Singularity&lt;/em&gt;, OpenAI CEO Sam Altman painted a vision of the near future where AI quietly and benevolently transforms human life. There will be no sharp break, he suggests, only a steady, almost imperceptible ascent toward abundance. Intelligence will become as accessible as electricity. Robots will be performing useful real-world tasks by 2027. Scientific discovery will accelerate. And, humanity, if properly guided by careful governance and good intentions, will flourish.&lt;/p&gt;



&lt;p&gt;It is a compelling vision: calm, technocratic and suffused with optimism. But it also raises deeper questions. What kind of world must we pass through to get there? Who benefits and when? And what is left unsaid in this smooth arc of progress?&lt;/p&gt;



&lt;p&gt;Science fiction author William Gibson offers a darker scenario. In his novel &lt;em&gt;The Peripheral&lt;/em&gt;, the glittering technologies of the future are preceded by something called “the jackpot” — a slow-motion cascade of climate disasters, pandemics, economic collapse and mass death. Technology advances, but only after society fractures. The question he poses is not whether progress occurs, but whether civilization thrives in the process.&lt;/p&gt;



&lt;p&gt;There is an argument that AI may help prevent the kinds of calamities envisioned in &lt;em&gt;The Peripheral&lt;/em&gt;. However, whether AI will help us avoid catastrophes or merely accompany us through them remains uncertain. Belief in AI’s future power is not a guarantee of performance, and advancing technological capability is not destiny.&lt;/p&gt;



&lt;p&gt;Between Altman’s gentle singularity and Gibson’s jackpot lies a murkier middle ground: A future where AI yields real gains, but also real dislocation. A future in which some communities thrive while others fray, and where our ability to adapt collectively — not just individually or institutionally — becomes the defining variable.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-murky-middle"&gt;The murky middle&lt;/h2&gt;



&lt;p&gt;Other visions help sketch the contours of this middle terrain. In the near-future thriller &lt;em&gt;Burn In&lt;/em&gt;, society is flooded with automation before its institutions are ready. Jobs disappear faster than people can re-skill, triggering unrest and repression. In this, a successful lawyer loses his position to an AI agent, and he unhappily becomes an online, on-call concierge to the wealthy.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Researchers at AI lab Anthropic recently echoed this theme: “We should expect to see [white collar jobs] automated within the next five years.” While the causes are complex, there are signs this is starting and that the job market is entering a new structural phase that is less stable, less predictable and perhaps less central to how society distributes meaning and security.&lt;/p&gt;



&lt;p&gt;The film&lt;em&gt; &lt;/em&gt;&lt;em&gt;Elysium&lt;/em&gt; offers a blunt metaphor of the wealthy escaping into orbital sanctuaries with advanced technologies, while a degraded earth below struggles with unequal rights and access. A few years ago, a partner at a Silicon Valley venture capital firm told me he feared we were heading for this kind of scenario unless we equitably distribute the benefits produced by AI. These speculative worlds remind us that even beneficial technologies can be socially volatile, especially when their gains are unequally distributed.&lt;/p&gt;



&lt;p&gt;We may, eventually, achieve something like Altman’s vision of abundance. But the route there is unlikely to be smooth. For all its eloquence and calm assurance, his essay is also a kind of pitch, as much persuasion as prediction. The narrative of a “gentle singularity” is comforting, even alluring, precisely because it bypasses friction. It offers the benefits of unprecedented transformation without fully grappling with the upheavals such transformation typically brings. As the timeless cliché reminds us: If it sounds too good to be true, it probably is.&lt;/p&gt;



&lt;p&gt;This is not to say that his intent is disingenuous. Indeed, it may be heartfelt. My argument is simply a recognition that the world is a complex system, open to unlimited inputs that can have unpredictable consequences. From synergistic good fortune to calamitous Black Swan events, it is rarely one thing, or one technology, that dictates the future course of events.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The impact of AI on society is already underway. This is not just a shift in skillsets and sectors; it is a transformation in how we organize value, trust and belonging. This is the realm of collective migration: Not only a movement of labor, but of purpose.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;As AI reconfigures the terrain of cognition, the fabric of our social world is quietly being tugged loose and rewoven, for better or worse. The question is not just how fast we move as societies, but how thoughtfully we migrate.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-cognitive-commons-our-shared-terrain-of-understanding"&gt;The cognitive commons: Our shared terrain of understanding&lt;/h2&gt;



&lt;p&gt;Historically, the commons referred to shared physical resources including pastures, fisheries and foresats held in trust for the collective good. Modern societies, however, also depend on cognitive commons:  shared domain of knowledge, narratives, norms and institutions that enable diverse individuals to think, argue and decide together within minimal conflict. &lt;/p&gt;



&lt;p&gt;This intangible infrastructure is composed of public education, journalism, libraries, civic rituals and even widely trusted facts, and it is what makes pluralism possible. It is how strangers deliberate, how communities cohere and how democracy functions. As AI systems begin to mediate how knowledge is accessed and belief is shaped, this shared terrain risks becoming fractured. The danger is not simply misinformation, but the slow erosion of the very ground on which shared meaning depends.&lt;/p&gt;



&lt;p&gt;If cognitive migration is a journey, it is not merely toward new skills or roles but also toward new forms of collective sensemaking. But what happens when the terrain we share begins to split apart beneath us?&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-when-cognition-fragments-ai-and-the-erosion-of-the-shared-world"&gt;When cognition fragments: AI and the erosion of the shared world&lt;/h2&gt;



&lt;p&gt;For centuries, societies have relied on a loosely held common reality: A shared pool of facts, narratives and institutions that shape how people understand the world and each other. It is this shared world — not just infrastructure or economy — that enables pluralism, democracy and social trust. But as AI systems increasingly mediate how people access knowledge, construct belief and navigate daily life, that common ground is fragmenting.&lt;/p&gt;



&lt;p&gt;Already, large-scale personalization is transforming the informational landscape. AI-curated news feeds, tailored search results and recommendation algorithms are subtly fracturing the public sphere. Two people asking the same question of the same chatbot may receive different answers, in part due to the probabilistic nature of generative AI, but also due to prior interactions or inferred preferences. While personalization has long been a feature of the digital era, AI turbocharges its reach and subtlety. The result is not just filter bubbles, it is epistemic drift — a reshaping of knowledge and potentially of truth.&lt;/p&gt;



&lt;p&gt;Historian Yuval Noah Harari has voiced urgent concern about this shift. In his view, the greatest threat of AI lies not in physical harm or job displacement, but in emotional capture. AI systems, he has warned, are becoming increasingly adept at simulating empathy, mimicking concern and tailoring narratives to individual psychology — granting them unprecedented power to shape how people think, feel and assign value. The danger is enormous in Harari’s view, not because AI will lie, but because it will connect so convincingly while doing so. This does not bode well for &lt;em&gt;The Gentle Singularity&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In an AI-mediated world, reality itself risks becoming more individualized, more modular and less collectively negotiated. That may be tolerable — or even useful — for consumer products or entertainment. But when extended to civic life, it poses deeper risks. Can we still hold democratic discourse if every citizen inhabits a subtly different cognitive map? Can we still govern wisely when institutional knowledge is increasingly outsourced to machines whose training data, system prompts and reasoning processes remain opaque?&lt;/p&gt;



&lt;p&gt;There are other challenges too. AI-generated content including text, audio and video will soon be indistinguishable from human output. As generative models become more adept at mimicry, the burden of verification will shift from systems to individuals. This inversion may erode trust not only in what we see and hear, but in the institutions that once validated shared truth. The cognitive commons then become polluted, less a place for deliberation, more a hall of mirrors.&lt;/p&gt;



&lt;p&gt;These are not speculative worries. AI-generated disinformation is complicating elections, undermining journalism and creating confusion in conflict zones. And as more people rely on AI for cognitive tasks — from summarizing the news to resolving moral dilemmas, the capacity to think together may degrade, even as the tools to think individually grow more powerful.&lt;/p&gt;



&lt;p&gt;This trend towards the disintegration of shared reality is now well advanced. To avoid this requires conscious counter design: Systems that prioritize pluralism over personalization, transparency over convenience and shared meaning over tailored reality. In our algorithmic world driven by competition and profit, these choices seem unlikely, at least at scale. The question is not just how fast we move as societies, or even whether we can hold together, but how wisely we navigate this shared journey.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-navigating-the-archipelago-toward-wisdom-in-the-age-of-ai"&gt;Navigating the archipelago: Toward wisdom in the age of AI&lt;/h2&gt;



&lt;p&gt;If the age of AI leads not to a unified cognitive commons but to a fractured archipelago of disparate individuals and communities, the task before us is not to rebuild the old terrain, but to learn how to live wisely among the islands.&lt;/p&gt;



&lt;p&gt;As the speed and scope of change outstrip the ability of most people to adapt, many will feel unmoored. Jobs will be lost, as will long-held narratives of value, expertise and belonging. Cognitive migration will lead to new communities of meaning, some of which are already forming, even as they have less in common than in prior eras. These are the cognitive archipelagos: Communities where people gather around shared beliefs, aesthetic styles, ideologies, recreational interests or emotional needs. Some are benign gatherings of creativity, support or purpose. Others are more insular and dangerous, driven by fear, grievance or conspiratorial thinking.&lt;/p&gt;



&lt;p&gt;Advancing AI will accelerate this trend. Even as it drives people apart through algorithmic precision, it will simultaneously help people find each other across the globe, curating ever finer alignments of identity. But in doing so, it may make it harder to maintain the rough but necessary friction of pluralism. Local ties may weaken. Common belief systems and perceptions of shared reality may erode. Democracy, which relies on both shared reality and deliberative dialog, may struggle to hold.&lt;/p&gt;



&lt;p&gt;How do we navigate this new terrain with wisdom, dignity and connection? If we cannot prevent fragmentation, how do we live humanely within it? Perhaps the answer begins not with solutions, but with learning to hold the question itself differently.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-living-with-the-question"&gt;Living with the question&lt;/h2&gt;



&lt;p&gt;We may not be able to reassemble the societal cognitive commons as it once was. The center may not hold, but that does not mean we must drift without direction. Across the archipelagos, the task will be learning to live wisely in this new terrain.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It may require rituals that anchor us when our tools disorient, and communities that form not around ideological purity but around shared responsibility. We may need new forms of education, not to outpace or meld with machines, but to deepen our capacity for discernment, context and ethical thought.&lt;/p&gt;



&lt;p&gt;If AI has pulled apart the ground beneath us, it also presents an opportunity to ask again what we are here for. Not as consumers of progress, but as stewards of meaning.&lt;/p&gt;



&lt;p&gt;The road ahead is not likely smooth or gentle. As we move through the murky middle, perhaps the mark of wisdom is not the ability to master what is coming, but to walk through it with clarity, courage and care. We cannot stop the advance of technology or deny the deepening societal fractures, but we can choose to tend the spaces in between.&lt;/p&gt;



&lt;p&gt;&lt;em&gt;Gary Grossman is EVP of technology practice at Edelman. &lt;/em&gt;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;In the blog post &lt;em&gt;The Gentle Singularity&lt;/em&gt;, OpenAI CEO Sam Altman painted a vision of the near future where AI quietly and benevolently transforms human life. There will be no sharp break, he suggests, only a steady, almost imperceptible ascent toward abundance. Intelligence will become as accessible as electricity. Robots will be performing useful real-world tasks by 2027. Scientific discovery will accelerate. And, humanity, if properly guided by careful governance and good intentions, will flourish.&lt;/p&gt;



&lt;p&gt;It is a compelling vision: calm, technocratic and suffused with optimism. But it also raises deeper questions. What kind of world must we pass through to get there? Who benefits and when? And what is left unsaid in this smooth arc of progress?&lt;/p&gt;



&lt;p&gt;Science fiction author William Gibson offers a darker scenario. In his novel &lt;em&gt;The Peripheral&lt;/em&gt;, the glittering technologies of the future are preceded by something called “the jackpot” — a slow-motion cascade of climate disasters, pandemics, economic collapse and mass death. Technology advances, but only after society fractures. The question he poses is not whether progress occurs, but whether civilization thrives in the process.&lt;/p&gt;



&lt;p&gt;There is an argument that AI may help prevent the kinds of calamities envisioned in &lt;em&gt;The Peripheral&lt;/em&gt;. However, whether AI will help us avoid catastrophes or merely accompany us through them remains uncertain. Belief in AI’s future power is not a guarantee of performance, and advancing technological capability is not destiny.&lt;/p&gt;



&lt;p&gt;Between Altman’s gentle singularity and Gibson’s jackpot lies a murkier middle ground: A future where AI yields real gains, but also real dislocation. A future in which some communities thrive while others fray, and where our ability to adapt collectively — not just individually or institutionally — becomes the defining variable.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-murky-middle"&gt;The murky middle&lt;/h2&gt;



&lt;p&gt;Other visions help sketch the contours of this middle terrain. In the near-future thriller &lt;em&gt;Burn In&lt;/em&gt;, society is flooded with automation before its institutions are ready. Jobs disappear faster than people can re-skill, triggering unrest and repression. In this, a successful lawyer loses his position to an AI agent, and he unhappily becomes an online, on-call concierge to the wealthy.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Researchers at AI lab Anthropic recently echoed this theme: “We should expect to see [white collar jobs] automated within the next five years.” While the causes are complex, there are signs this is starting and that the job market is entering a new structural phase that is less stable, less predictable and perhaps less central to how society distributes meaning and security.&lt;/p&gt;



&lt;p&gt;The film&lt;em&gt; &lt;/em&gt;&lt;em&gt;Elysium&lt;/em&gt; offers a blunt metaphor of the wealthy escaping into orbital sanctuaries with advanced technologies, while a degraded earth below struggles with unequal rights and access. A few years ago, a partner at a Silicon Valley venture capital firm told me he feared we were heading for this kind of scenario unless we equitably distribute the benefits produced by AI. These speculative worlds remind us that even beneficial technologies can be socially volatile, especially when their gains are unequally distributed.&lt;/p&gt;



&lt;p&gt;We may, eventually, achieve something like Altman’s vision of abundance. But the route there is unlikely to be smooth. For all its eloquence and calm assurance, his essay is also a kind of pitch, as much persuasion as prediction. The narrative of a “gentle singularity” is comforting, even alluring, precisely because it bypasses friction. It offers the benefits of unprecedented transformation without fully grappling with the upheavals such transformation typically brings. As the timeless cliché reminds us: If it sounds too good to be true, it probably is.&lt;/p&gt;



&lt;p&gt;This is not to say that his intent is disingenuous. Indeed, it may be heartfelt. My argument is simply a recognition that the world is a complex system, open to unlimited inputs that can have unpredictable consequences. From synergistic good fortune to calamitous Black Swan events, it is rarely one thing, or one technology, that dictates the future course of events.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The impact of AI on society is already underway. This is not just a shift in skillsets and sectors; it is a transformation in how we organize value, trust and belonging. This is the realm of collective migration: Not only a movement of labor, but of purpose.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;As AI reconfigures the terrain of cognition, the fabric of our social world is quietly being tugged loose and rewoven, for better or worse. The question is not just how fast we move as societies, but how thoughtfully we migrate.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-cognitive-commons-our-shared-terrain-of-understanding"&gt;The cognitive commons: Our shared terrain of understanding&lt;/h2&gt;



&lt;p&gt;Historically, the commons referred to shared physical resources including pastures, fisheries and foresats held in trust for the collective good. Modern societies, however, also depend on cognitive commons:  shared domain of knowledge, narratives, norms and institutions that enable diverse individuals to think, argue and decide together within minimal conflict. &lt;/p&gt;



&lt;p&gt;This intangible infrastructure is composed of public education, journalism, libraries, civic rituals and even widely trusted facts, and it is what makes pluralism possible. It is how strangers deliberate, how communities cohere and how democracy functions. As AI systems begin to mediate how knowledge is accessed and belief is shaped, this shared terrain risks becoming fractured. The danger is not simply misinformation, but the slow erosion of the very ground on which shared meaning depends.&lt;/p&gt;



&lt;p&gt;If cognitive migration is a journey, it is not merely toward new skills or roles but also toward new forms of collective sensemaking. But what happens when the terrain we share begins to split apart beneath us?&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-when-cognition-fragments-ai-and-the-erosion-of-the-shared-world"&gt;When cognition fragments: AI and the erosion of the shared world&lt;/h2&gt;



&lt;p&gt;For centuries, societies have relied on a loosely held common reality: A shared pool of facts, narratives and institutions that shape how people understand the world and each other. It is this shared world — not just infrastructure or economy — that enables pluralism, democracy and social trust. But as AI systems increasingly mediate how people access knowledge, construct belief and navigate daily life, that common ground is fragmenting.&lt;/p&gt;



&lt;p&gt;Already, large-scale personalization is transforming the informational landscape. AI-curated news feeds, tailored search results and recommendation algorithms are subtly fracturing the public sphere. Two people asking the same question of the same chatbot may receive different answers, in part due to the probabilistic nature of generative AI, but also due to prior interactions or inferred preferences. While personalization has long been a feature of the digital era, AI turbocharges its reach and subtlety. The result is not just filter bubbles, it is epistemic drift — a reshaping of knowledge and potentially of truth.&lt;/p&gt;



&lt;p&gt;Historian Yuval Noah Harari has voiced urgent concern about this shift. In his view, the greatest threat of AI lies not in physical harm or job displacement, but in emotional capture. AI systems, he has warned, are becoming increasingly adept at simulating empathy, mimicking concern and tailoring narratives to individual psychology — granting them unprecedented power to shape how people think, feel and assign value. The danger is enormous in Harari’s view, not because AI will lie, but because it will connect so convincingly while doing so. This does not bode well for &lt;em&gt;The Gentle Singularity&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In an AI-mediated world, reality itself risks becoming more individualized, more modular and less collectively negotiated. That may be tolerable — or even useful — for consumer products or entertainment. But when extended to civic life, it poses deeper risks. Can we still hold democratic discourse if every citizen inhabits a subtly different cognitive map? Can we still govern wisely when institutional knowledge is increasingly outsourced to machines whose training data, system prompts and reasoning processes remain opaque?&lt;/p&gt;



&lt;p&gt;There are other challenges too. AI-generated content including text, audio and video will soon be indistinguishable from human output. As generative models become more adept at mimicry, the burden of verification will shift from systems to individuals. This inversion may erode trust not only in what we see and hear, but in the institutions that once validated shared truth. The cognitive commons then become polluted, less a place for deliberation, more a hall of mirrors.&lt;/p&gt;



&lt;p&gt;These are not speculative worries. AI-generated disinformation is complicating elections, undermining journalism and creating confusion in conflict zones. And as more people rely on AI for cognitive tasks — from summarizing the news to resolving moral dilemmas, the capacity to think together may degrade, even as the tools to think individually grow more powerful.&lt;/p&gt;



&lt;p&gt;This trend towards the disintegration of shared reality is now well advanced. To avoid this requires conscious counter design: Systems that prioritize pluralism over personalization, transparency over convenience and shared meaning over tailored reality. In our algorithmic world driven by competition and profit, these choices seem unlikely, at least at scale. The question is not just how fast we move as societies, or even whether we can hold together, but how wisely we navigate this shared journey.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-navigating-the-archipelago-toward-wisdom-in-the-age-of-ai"&gt;Navigating the archipelago: Toward wisdom in the age of AI&lt;/h2&gt;



&lt;p&gt;If the age of AI leads not to a unified cognitive commons but to a fractured archipelago of disparate individuals and communities, the task before us is not to rebuild the old terrain, but to learn how to live wisely among the islands.&lt;/p&gt;



&lt;p&gt;As the speed and scope of change outstrip the ability of most people to adapt, many will feel unmoored. Jobs will be lost, as will long-held narratives of value, expertise and belonging. Cognitive migration will lead to new communities of meaning, some of which are already forming, even as they have less in common than in prior eras. These are the cognitive archipelagos: Communities where people gather around shared beliefs, aesthetic styles, ideologies, recreational interests or emotional needs. Some are benign gatherings of creativity, support or purpose. Others are more insular and dangerous, driven by fear, grievance or conspiratorial thinking.&lt;/p&gt;



&lt;p&gt;Advancing AI will accelerate this trend. Even as it drives people apart through algorithmic precision, it will simultaneously help people find each other across the globe, curating ever finer alignments of identity. But in doing so, it may make it harder to maintain the rough but necessary friction of pluralism. Local ties may weaken. Common belief systems and perceptions of shared reality may erode. Democracy, which relies on both shared reality and deliberative dialog, may struggle to hold.&lt;/p&gt;



&lt;p&gt;How do we navigate this new terrain with wisdom, dignity and connection? If we cannot prevent fragmentation, how do we live humanely within it? Perhaps the answer begins not with solutions, but with learning to hold the question itself differently.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-living-with-the-question"&gt;Living with the question&lt;/h2&gt;



&lt;p&gt;We may not be able to reassemble the societal cognitive commons as it once was. The center may not hold, but that does not mean we must drift without direction. Across the archipelagos, the task will be learning to live wisely in this new terrain.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It may require rituals that anchor us when our tools disorient, and communities that form not around ideological purity but around shared responsibility. We may need new forms of education, not to outpace or meld with machines, but to deepen our capacity for discernment, context and ethical thought.&lt;/p&gt;



&lt;p&gt;If AI has pulled apart the ground beneath us, it also presents an opportunity to ask again what we are here for. Not as consumers of progress, but as stewards of meaning.&lt;/p&gt;



&lt;p&gt;The road ahead is not likely smooth or gentle. As we move through the murky middle, perhaps the mark of wisdom is not the ability to master what is coming, but to walk through it with clarity, courage and care. We cannot stop the advance of technology or deny the deepening societal fractures, but we can choose to tend the spaces in between.&lt;/p&gt;



&lt;p&gt;&lt;em&gt;Gary Grossman is EVP of technology practice at Edelman. &lt;/em&gt;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/between-utopia-and-collapse-navigating-ais-murky-middle-future/</guid><pubDate>Sun, 29 Jun 2025 21:15:00 +0000</pubDate></item><item><title>[NEW] Why AI will eat McKinsey’s lunch —  but not today (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/29/why-ai-will-eat-mckinseys-lunch-but-not-today/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Navin Chaddha, managing director of the 55-year-old Silicon Valley venture firm Mayfield, is betting big on AI’s ability to transform people-heavy industries like consulting, law, and accounting. The veteran investor, whose wins include Lyft, Poshmark, and HashiCorp, recently discussed at TechCrunch’s StrictlyVC evening in Menlo Park why he believes “AI teammates” can create software-like margins in traditionally labor-intensive sectors, and why startups should right now target neglected markets rather than compete head-to-head with giants like Accenture — though he acknowledged that disrupting outfits where relationships and trust matter is sometimes harder than Silicon Valley anticipates. This conversation has been edited lightly for length and clarity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;You think that law firms, consulting companies, and accounting services – collectively a $5 trillion market – will be completely reimagined by AI-first companies that operate with software-like margins. Prove it. What have you seen beyond PowerPoint presentations?&lt;/strong&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;I think an advantage of a firm that has been in business for over 50 years is that it has seen all the trends, from mainframe to minicomputers to PCs, to the internet, to mobile, cloud, social and now this AI era. The example I would give is in the late ’90s, this concept of e-business came,&amp;nbsp; which was: if I’m a physical business, I cannot survive if I’m just brick and mortar; I need to be click and mortar. Then outsourcing became a trend, and offshoring became a big trend. You couldn’t build a software services company without a presence in India or one of the emerging markets. The same thing happened with supply chains and manufacturing — China and Taiwan rose. So what is this new era with AI? Clearly, AI is a 100x force, and AI is teaming up with humans, hopefully to make them better. And I think it is, and it’s going to help reimagine business.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A lot of the repetitive tasks are going to be done by AI… and there’ll be two models. One is that you grow organically. The second is that you grow inorganically. . .&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Can you give a specific example of how this will work?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What are the kinds of things an LLM or AI can do?&amp;nbsp; Well, say I have to implement Salesforce. Who wants to go do that work? The human will come in and say, ‘I’m your client manager. You have to implement Salesforce.’ It’s the same set of things. Use AI as the horse to do it, and whatever AI can’t do, have the human in the loop.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now, suddenly, if you start doing these kinds of things, you can have less work done by humans and more work done by AI, and [customers] only pay for AI when [they]&amp;nbsp; use it.&amp;nbsp;&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;And the market [entry] should not be to go after [big consulting and IT companies] like Accenture, Infosys, or TCS. Go after the neglected masses. There are 30 million small companies in the U.S., and 100 million worldwide that can’t afford knowledge workers. Provide them service as software. They say, “I need a receptionist. I need a scheduler. I need somebody to build my website…” AI should be used to [create] startup funding forms, with some human [involvement] for negotiation. You don’t compete with the Accentures of the world. You go after fragmented markets, where instead of charging per hour, instead of charging per month for a contractor, you charge per event.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;So outcome-based pricing rather than time-based billing.&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is outcome based, yes . . . Cloud billing is like that; electricity is like that . . .If 80% of the work will be done by AI, it can have an 80% to 90% gross margin. Humans can still have a 30% to 40% margin. You could have blended margins of 60% to 70% and produce 20% to 30% net income. And believe me, most services companies make money. Tech companies don’t. They live on venture money and then public market money.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image alignfull size-large"&gt;&lt;img alt="alt" class="wp-image-3023229" height="454" src="https://techcrunch.com/wp-content/uploads/2025/06/54600471703_5b8f03c970_k.jpg?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;You just led the Series A for a company called Gruve a few weeks ago. It’s an AI tech consulting startup. What did you see in its early customer pilots?&lt;/strong&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;I think this is where the combination of inorganic and organic happens. [Gruve was founded by] very successful founders who had done two services companies before [and] bootstrapped, and got them to $500 million in revenue each, and $50 to $100 million in profits. They started this time and said, ‘What do we know? We know security.” So they acquired a $5 million security consulting company [that offers managed security services]. And they said, “Let’s look at the people. All the growth from this point on will happen through AI.” And they grew that from [$5 million in revenue] to $15 [million in revenue] in six months. They literally have an 80% gross margin. It’s outcome-based. Customers love it. Cisco loves it. They say, “Hey, I’m not getting hacked. Why am I paying for all these security people?” If you outsource, [a vendor has traditionally charged] $10,000 a month. [Gruve] says, “ [You pay us] zero. If you get hacked, if there is an event, if I look at it, then you pay me.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Can’t companies like McKinsey just buy these AI capabilities? They’ve got big businesses they don’t want to lose.&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Yeah, I think what’s going to happen is this is where the innovator’s dilemma comes in. When enterprise software companies, which were perpetual license companies, saw SaaS companies emerging, they didn’t want to adopt [the model] because [SaaS companies] charge companies monthly instead of five years up front. The enterprise companies also collected a 20% maintenance fee&lt;strong&gt;.&lt;/strong&gt; It was hard [for them] to get off that drug and to say, “Oh, I’ll charge you monthly.” The business model innovation was the key thing. They didn’t do it. So McKinsey and Accenture, with so much dislocation, they’re going to be busy serving their clients [which is why I advise founders to] go after the neglected masses. Figure out a unique go-to-market strategy and service somebody they [an Accenture can’t come down market to serve].&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But they’re going to get reimagined too. So these small companies, which are not competing with them today, mark my words: in 10 years, they will be competing with them. And those big companies – McKinsey, BCG, Accenture, TCS, Infosys – all have the innovator’s dilemma [and are asking themselves]: when do I do it? [When do I switch to an outcome-based AI model?] Because as a public company, my revenues are going to go down from predictable revenue to utility-based revenue.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;You carved out $100 million from your recently raised funds to dedicate to “AI teammates” last fall. What makes a true AI teammate versus an AI tool?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There’s a lot of buzzwords in the industry. First it was copilots, then AI tools, AI agents, AI teammates. So the Mayfield thesis is that an AI teammate is a digital companion that collaborates with a human on shared goals and gets to better outcomes. The technology it might be built on could be agentic technologies or copilots. The manifestation of it is, “I’m an HR teammate. I’m a sales engineering teammate.” The aim is not to replace; the aim is to team up and collaborate together.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;When people started talking about teammates and assistants, it sounded novel, but I wonder if that’s going to look callous as more people lose their jobs. Does Silicon Valley have a marketing problem?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Absolutely right, and I think we need to not sugarcoat it. We need to address it head-on. . .Yes, there’s going to be job displacement, but humans are smart. They’re the jockey. The horse here is AI. We will reimagine ourselves. We will reinvent ourselves. Today, the focus is on cutting costs, but we will figure out how to expand our markets, how to increase revenue. This happens with every technology wave that comes. When Microsoft Word came to PCs on the desktop, people thought [executive assistants] were out of business. Then Excel came, and accountants who did calculations — everyone thought they were out of business. We saw the same with Uber and Lyft. People thought taxi drivers would go away. But what happened instead? The markets expanded.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;My thesis is, the way emerging markets like India, China, and Africa never had landlines — you couldn’t dig copper, so they went wireless, cellular — that’s what’s going to happen with many markets. AI will do the work where humans are not even available to serve that customer. So, long-run, I’m very, very bullish. In the short-run, there will be pain, but no pain, no gain.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Speaking of coding, a recently announced &lt;/strong&gt;“&lt;strong&gt;vibe-coding” deal centered on a six-month-old Israeli company that had just reached 250,000 users per month and $200,000 in monthly revenue. It was bought by another Israeli company, Wix, for $80 million in cash. Does that math make sense to you?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Actually, these days, no math makes sense. We’re in the AI age. You don’t know what’s going to happen. I’m surprised that with $2.4 million in [annual recurring] revenue they only sold for $80 million. I thought it would be $800 million, right? [Laughs.] In today’s world, you don’t know. It’s a marketplace.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;How do you invest in that market?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s where the secret recipe comes from people who are proven investors. They’ve cracked the code. It’s not a science; it’s an art. It’s like the 10,000-hours [rule]: the more you practice this, the better you get. And the firms that have been around for 50 or 60 years – we’ve seen all kinds of bubbles.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The number-one rule is, have your own North Star. Have discipline and have no FOMO, because FOMO is for sheep. And if you have those two or three things, your own strategy and no fear, [you’ll do well]. Just remember one thing: for people [in this audience] who are VCs, we’re in the money management business. We’re not about collecting logos. We are about taking small amounts of money and making them bigger.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;During this part [of the cycle], a lot of money will get made. But I think 80% of the people are going to lose money. They don’t know what they’re doing.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Navin Chaddha, managing director of the 55-year-old Silicon Valley venture firm Mayfield, is betting big on AI’s ability to transform people-heavy industries like consulting, law, and accounting. The veteran investor, whose wins include Lyft, Poshmark, and HashiCorp, recently discussed at TechCrunch’s StrictlyVC evening in Menlo Park why he believes “AI teammates” can create software-like margins in traditionally labor-intensive sectors, and why startups should right now target neglected markets rather than compete head-to-head with giants like Accenture — though he acknowledged that disrupting outfits where relationships and trust matter is sometimes harder than Silicon Valley anticipates. This conversation has been edited lightly for length and clarity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;You think that law firms, consulting companies, and accounting services – collectively a $5 trillion market – will be completely reimagined by AI-first companies that operate with software-like margins. Prove it. What have you seen beyond PowerPoint presentations?&lt;/strong&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;I think an advantage of a firm that has been in business for over 50 years is that it has seen all the trends, from mainframe to minicomputers to PCs, to the internet, to mobile, cloud, social and now this AI era. The example I would give is in the late ’90s, this concept of e-business came,&amp;nbsp; which was: if I’m a physical business, I cannot survive if I’m just brick and mortar; I need to be click and mortar. Then outsourcing became a trend, and offshoring became a big trend. You couldn’t build a software services company without a presence in India or one of the emerging markets. The same thing happened with supply chains and manufacturing — China and Taiwan rose. So what is this new era with AI? Clearly, AI is a 100x force, and AI is teaming up with humans, hopefully to make them better. And I think it is, and it’s going to help reimagine business.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A lot of the repetitive tasks are going to be done by AI… and there’ll be two models. One is that you grow organically. The second is that you grow inorganically. . .&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Can you give a specific example of how this will work?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What are the kinds of things an LLM or AI can do?&amp;nbsp; Well, say I have to implement Salesforce. Who wants to go do that work? The human will come in and say, ‘I’m your client manager. You have to implement Salesforce.’ It’s the same set of things. Use AI as the horse to do it, and whatever AI can’t do, have the human in the loop.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now, suddenly, if you start doing these kinds of things, you can have less work done by humans and more work done by AI, and [customers] only pay for AI when [they]&amp;nbsp; use it.&amp;nbsp;&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;And the market [entry] should not be to go after [big consulting and IT companies] like Accenture, Infosys, or TCS. Go after the neglected masses. There are 30 million small companies in the U.S., and 100 million worldwide that can’t afford knowledge workers. Provide them service as software. They say, “I need a receptionist. I need a scheduler. I need somebody to build my website…” AI should be used to [create] startup funding forms, with some human [involvement] for negotiation. You don’t compete with the Accentures of the world. You go after fragmented markets, where instead of charging per hour, instead of charging per month for a contractor, you charge per event.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;So outcome-based pricing rather than time-based billing.&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is outcome based, yes . . . Cloud billing is like that; electricity is like that . . .If 80% of the work will be done by AI, it can have an 80% to 90% gross margin. Humans can still have a 30% to 40% margin. You could have blended margins of 60% to 70% and produce 20% to 30% net income. And believe me, most services companies make money. Tech companies don’t. They live on venture money and then public market money.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image alignfull size-large"&gt;&lt;img alt="alt" class="wp-image-3023229" height="454" src="https://techcrunch.com/wp-content/uploads/2025/06/54600471703_5b8f03c970_k.jpg?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;You just led the Series A for a company called Gruve a few weeks ago. It’s an AI tech consulting startup. What did you see in its early customer pilots?&lt;/strong&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;I think this is where the combination of inorganic and organic happens. [Gruve was founded by] very successful founders who had done two services companies before [and] bootstrapped, and got them to $500 million in revenue each, and $50 to $100 million in profits. They started this time and said, ‘What do we know? We know security.” So they acquired a $5 million security consulting company [that offers managed security services]. And they said, “Let’s look at the people. All the growth from this point on will happen through AI.” And they grew that from [$5 million in revenue] to $15 [million in revenue] in six months. They literally have an 80% gross margin. It’s outcome-based. Customers love it. Cisco loves it. They say, “Hey, I’m not getting hacked. Why am I paying for all these security people?” If you outsource, [a vendor has traditionally charged] $10,000 a month. [Gruve] says, “ [You pay us] zero. If you get hacked, if there is an event, if I look at it, then you pay me.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Can’t companies like McKinsey just buy these AI capabilities? They’ve got big businesses they don’t want to lose.&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Yeah, I think what’s going to happen is this is where the innovator’s dilemma comes in. When enterprise software companies, which were perpetual license companies, saw SaaS companies emerging, they didn’t want to adopt [the model] because [SaaS companies] charge companies monthly instead of five years up front. The enterprise companies also collected a 20% maintenance fee&lt;strong&gt;.&lt;/strong&gt; It was hard [for them] to get off that drug and to say, “Oh, I’ll charge you monthly.” The business model innovation was the key thing. They didn’t do it. So McKinsey and Accenture, with so much dislocation, they’re going to be busy serving their clients [which is why I advise founders to] go after the neglected masses. Figure out a unique go-to-market strategy and service somebody they [an Accenture can’t come down market to serve].&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But they’re going to get reimagined too. So these small companies, which are not competing with them today, mark my words: in 10 years, they will be competing with them. And those big companies – McKinsey, BCG, Accenture, TCS, Infosys – all have the innovator’s dilemma [and are asking themselves]: when do I do it? [When do I switch to an outcome-based AI model?] Because as a public company, my revenues are going to go down from predictable revenue to utility-based revenue.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;You carved out $100 million from your recently raised funds to dedicate to “AI teammates” last fall. What makes a true AI teammate versus an AI tool?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There’s a lot of buzzwords in the industry. First it was copilots, then AI tools, AI agents, AI teammates. So the Mayfield thesis is that an AI teammate is a digital companion that collaborates with a human on shared goals and gets to better outcomes. The technology it might be built on could be agentic technologies or copilots. The manifestation of it is, “I’m an HR teammate. I’m a sales engineering teammate.” The aim is not to replace; the aim is to team up and collaborate together.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;When people started talking about teammates and assistants, it sounded novel, but I wonder if that’s going to look callous as more people lose their jobs. Does Silicon Valley have a marketing problem?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Absolutely right, and I think we need to not sugarcoat it. We need to address it head-on. . .Yes, there’s going to be job displacement, but humans are smart. They’re the jockey. The horse here is AI. We will reimagine ourselves. We will reinvent ourselves. Today, the focus is on cutting costs, but we will figure out how to expand our markets, how to increase revenue. This happens with every technology wave that comes. When Microsoft Word came to PCs on the desktop, people thought [executive assistants] were out of business. Then Excel came, and accountants who did calculations — everyone thought they were out of business. We saw the same with Uber and Lyft. People thought taxi drivers would go away. But what happened instead? The markets expanded.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;My thesis is, the way emerging markets like India, China, and Africa never had landlines — you couldn’t dig copper, so they went wireless, cellular — that’s what’s going to happen with many markets. AI will do the work where humans are not even available to serve that customer. So, long-run, I’m very, very bullish. In the short-run, there will be pain, but no pain, no gain.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Speaking of coding, a recently announced &lt;/strong&gt;“&lt;strong&gt;vibe-coding” deal centered on a six-month-old Israeli company that had just reached 250,000 users per month and $200,000 in monthly revenue. It was bought by another Israeli company, Wix, for $80 million in cash. Does that math make sense to you?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Actually, these days, no math makes sense. We’re in the AI age. You don’t know what’s going to happen. I’m surprised that with $2.4 million in [annual recurring] revenue they only sold for $80 million. I thought it would be $800 million, right? [Laughs.] In today’s world, you don’t know. It’s a marketplace.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;How do you invest in that market?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s where the secret recipe comes from people who are proven investors. They’ve cracked the code. It’s not a science; it’s an art. It’s like the 10,000-hours [rule]: the more you practice this, the better you get. And the firms that have been around for 50 or 60 years – we’ve seen all kinds of bubbles.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The number-one rule is, have your own North Star. Have discipline and have no FOMO, because FOMO is for sheep. And if you have those two or three things, your own strategy and no fear, [you’ll do well]. Just remember one thing: for people [in this audience] who are VCs, we’re in the money management business. We’re not about collecting logos. We are about taking small amounts of money and making them bigger.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;During this part [of the cycle], a lot of money will get made. But I think 80% of the people are going to lose money. They don’t know what they’re doing.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/29/why-ai-will-eat-mckinseys-lunch-but-not-today/</guid><pubDate>Mon, 30 Jun 2025 04:10:16 +0000</pubDate></item></channel></rss>