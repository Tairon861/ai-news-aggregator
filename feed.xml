<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 15 Aug 2025 01:51:51 +0000</lastBuildDate><item><title>Inside the Box: Aaron Levie on reinvention at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/14/inside-the-box-aaron-levie-on-reinvention-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;There aren’t many founders who can say they’ve steered the same company from scrappy startup to publicly traded platform while keeping their edge — but co-founder and CEO Aaron Levie isn’t most founders. At &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, happening October 27–29 at Moscone West in San Francisco, Levie joins us live on the &lt;strong&gt;Disrupt Stage&lt;/strong&gt; to share how he’s kept Box innovating and relevant through two decades of tech cycles.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He’ll unpack what reinvention really looks like inside a public company, what AI is changing (and not changing) in enterprise software, and why staying sharp means questioning everything — even your own best ideas.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Aaron Levie" class="wp-image-3036885" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_-Aaron-Levie-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-the-evolution-of-a-cloud-original"&gt;The evolution of a cloud original&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Box launched before “the cloud” was a buzzword and outlasted a wave of competitors that couldn’t scale or adapt. Levie’s perspective — as both a visionary founder and a long-term public company CEO — is a rare combination. He’ll reflect on the hardest pivots, biggest surprises, and the mindset it takes to keep evolving when the tech landscape moves at warp speed.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-why-you-don-t-want-to-miss-it"&gt;Why you don’t want to miss it&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Aaron Levie helped define cloud collaboration before it was a trend, and he’s still setting the bar. This fireside chat will go deep on what it takes to build something that lasts — not just in terms of product, but also culture, strategy, and mindset. Whether you’re navigating early growth or managing scale, this is one session you’ll want to take notes on.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Join 10,000+ fellow founders, VCs, and innovators&lt;/strong&gt; in San Francisco this October and be part of the conversation with the leaders shaping what’s next.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Disrupt 2024 Main Stage" class="wp-image-2953554" height="453" src="https://techcrunch.com/wp-content/uploads/2025/01/Disrupt-2024-main-stage.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kimberly White / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;There aren’t many founders who can say they’ve steered the same company from scrappy startup to publicly traded platform while keeping their edge — but co-founder and CEO Aaron Levie isn’t most founders. At &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, happening October 27–29 at Moscone West in San Francisco, Levie joins us live on the &lt;strong&gt;Disrupt Stage&lt;/strong&gt; to share how he’s kept Box innovating and relevant through two decades of tech cycles.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He’ll unpack what reinvention really looks like inside a public company, what AI is changing (and not changing) in enterprise software, and why staying sharp means questioning everything — even your own best ideas.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Aaron Levie" class="wp-image-3036885" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_-Aaron-Levie-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-the-evolution-of-a-cloud-original"&gt;The evolution of a cloud original&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Box launched before “the cloud” was a buzzword and outlasted a wave of competitors that couldn’t scale or adapt. Levie’s perspective — as both a visionary founder and a long-term public company CEO — is a rare combination. He’ll reflect on the hardest pivots, biggest surprises, and the mindset it takes to keep evolving when the tech landscape moves at warp speed.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-why-you-don-t-want-to-miss-it"&gt;Why you don’t want to miss it&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Aaron Levie helped define cloud collaboration before it was a trend, and he’s still setting the bar. This fireside chat will go deep on what it takes to build something that lasts — not just in terms of product, but also culture, strategy, and mindset. Whether you’re navigating early growth or managing scale, this is one session you’ll want to take notes on.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Join 10,000+ fellow founders, VCs, and innovators&lt;/strong&gt; in San Francisco this October and be part of the conversation with the leaders shaping what’s next.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Disrupt 2024 Main Stage" class="wp-image-2953554" height="453" src="https://techcrunch.com/wp-content/uploads/2025/01/Disrupt-2024-main-stage.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kimberly White / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/14/inside-the-box-aaron-levie-on-reinvention-at-techcrunch-disrupt-2025/</guid><pubDate>Thu, 14 Aug 2025 14:00:00 +0000</pubDate></item><item><title>Cohere hires long-time Meta research head Joelle Pineau as its chief AI officer (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/14/cohere-hires-long-time-meta-research-head-joelle-pineau-as-its-chief-ai-officer/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Investors once saw Canadian AI startup Cohere as a promising contender to challenge OpenAI and Anthropic in the race to build frontier AI models, with its backers pouring roughly $1 billion behind CEO Aidan Gomez, who co-authored a seminal paper on LLMs when he was a 20-year-old Google intern.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Cohere’s AI models have fallen behind the state-of-the-art, and its business hasn’t scaled like its competitors.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Now, the company is bringing in a veteran research leader to revamp its AI efforts: Cohere has hired Joelle Pineau, Meta’s former VP of AI research who previously oversaw the tech giant’s fundamental AI research (FAIR) lab. In her newly created chief AI officer role, Pineau will oversee AI strategy across Cohere’s research, product, and policy teams.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A Canadian AI scientist and McGill professor, Pineau helped guide the early development of Meta’s open Llama AI models alongside Yann LeCun, a pioneer of neural networks. Pineau left Meta in May after nearly eight years with the company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For Cohere this is a big hire, and it is pinning its hopes on the veteran helping it with more research breakthroughs, improving its research and product pipeline, and recruiting top talent. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The hire comes at a pivotal moment for Cohere: The company just raised $500 million at a $6.8 billion valuation — an impressive sum were the startup not competing with the likes of OpenAI, Google, Meta, and Anthropic, whose war chests are worth dozens of billions each.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But while its rivals are trying to develop AI systems that can match (or exceed) human performance on a wide variety of tasks, Cohere has a narrower focus. The startup primarily builds AI applications that can solve practical problems for enterprises and government agencies, emphasizing privacy and security. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In an interview with TechCrunch, Pineau said Cohere’s focus on real-world enterprise applications is something she’s excited about. “A lot of players out there are quite singularly focused on AGI, superintelligence, and so on,” said Pineau, alluding to companies like her former employer, Meta, which recently invested billions in its new Meta Superintelligence Labs (MSL) unit. “They haven’t necessarily figured out what this AI is going to be used for.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;She pointed to OpenAI’s launch of GPT-5 last week, which many felt was underwhelming, as evidence the timeline to achieving AGI may be “a little bit longer than we thought.” In the meantime, Pineau says there’s a lot of room for more practical AI models to deliver leaps in productivity in different industries.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A Canada native, Pineau said she’s had her eye on Cohere since they were founded in 2019, and that she’s excited to contribute to a company whose founders are based in her home country.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-2988109" height="453" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2150330371.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Joelle Pineau&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Paul Morigi/Haddad Media / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond the patriotism, Pineau feels the opportunity with Cohere is a good chance to venture beyond research. At FAIR, Pineau oversaw research teams working on projects that could take anywhere from 18 months to 10 years to deliver. Now, she’ll be working within a much tighter timeline, as well as getting involved with customers and products. And even though Cohere has fewer resources than Meta, Pineau said she’ll be more agile in her new role.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Cohere’s latest product is an AI agent platform dubbed North that enterprises and government agencies can deploy privately on their own infrastructure, an attractive notion for many of its customers, which are banks and federal organizations that handle highly sensitive data. That puts Cohere in competition with open source providers like DeepSeek and Meta, whose models can also be run locally, but at a lower cost. Cohere is betting that by offering more support around its private deployments, it can beat out open models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Pineau said she’s particularly interested in gearing more of Cohere’s research around North, figuring out ways to develop AI agents in private and secure settings, and creating benchmarks to evaluate these systems. Pineau also said she’s interested in exploring how networks of AI agents interact with each other in the real world.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One immediate challenge for Pineau will be replacing Cohere’s VP of AI Research, Sara Hooker, who announced her departure this week after several years of helping build the company’s research program. Hiring an AI researcher of Hooker’s caliber may be difficult in the current market given the skyrocketing demand for AI talent.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Pineau sees this as an opportunity to “bring in a lot of talent,” noting that when she left Meta, several of her former colleagues suggested they’d follow her to a new AI lab. However, she emphasized that Cohere has a solid base of AI researchers, and that it’s important to not just bring in anyone.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Hiring a bunch of superstars doesn’t necessarily make a superstar team,” said Pineau. “It’s really about how the people work together.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, Meta’s AI units today look very different compared with when Pineau was there just a few months ago. Over the summer, Mark Zuckerberg went on a recruiting spree, reportedly offering some of the industry’s best AI researchers compensation packages north of $100 million to join MSL. That prompted OpenAI to also raise compensation for its star employees, thus making it quite difficult for smaller players to land top AI researchers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Meta, OpenAI, and Anthropic throw billions of dollars at their AI efforts, Cohere is trying to do more with less. For Pineau, that will mean making calculated research bets — the kind that can quickly turn into compelling products and keep the company in the race.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Investors once saw Canadian AI startup Cohere as a promising contender to challenge OpenAI and Anthropic in the race to build frontier AI models, with its backers pouring roughly $1 billion behind CEO Aidan Gomez, who co-authored a seminal paper on LLMs when he was a 20-year-old Google intern.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Cohere’s AI models have fallen behind the state-of-the-art, and its business hasn’t scaled like its competitors.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Now, the company is bringing in a veteran research leader to revamp its AI efforts: Cohere has hired Joelle Pineau, Meta’s former VP of AI research who previously oversaw the tech giant’s fundamental AI research (FAIR) lab. In her newly created chief AI officer role, Pineau will oversee AI strategy across Cohere’s research, product, and policy teams.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A Canadian AI scientist and McGill professor, Pineau helped guide the early development of Meta’s open Llama AI models alongside Yann LeCun, a pioneer of neural networks. Pineau left Meta in May after nearly eight years with the company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For Cohere this is a big hire, and it is pinning its hopes on the veteran helping it with more research breakthroughs, improving its research and product pipeline, and recruiting top talent. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The hire comes at a pivotal moment for Cohere: The company just raised $500 million at a $6.8 billion valuation — an impressive sum were the startup not competing with the likes of OpenAI, Google, Meta, and Anthropic, whose war chests are worth dozens of billions each.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But while its rivals are trying to develop AI systems that can match (or exceed) human performance on a wide variety of tasks, Cohere has a narrower focus. The startup primarily builds AI applications that can solve practical problems for enterprises and government agencies, emphasizing privacy and security. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In an interview with TechCrunch, Pineau said Cohere’s focus on real-world enterprise applications is something she’s excited about. “A lot of players out there are quite singularly focused on AGI, superintelligence, and so on,” said Pineau, alluding to companies like her former employer, Meta, which recently invested billions in its new Meta Superintelligence Labs (MSL) unit. “They haven’t necessarily figured out what this AI is going to be used for.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;She pointed to OpenAI’s launch of GPT-5 last week, which many felt was underwhelming, as evidence the timeline to achieving AGI may be “a little bit longer than we thought.” In the meantime, Pineau says there’s a lot of room for more practical AI models to deliver leaps in productivity in different industries.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A Canada native, Pineau said she’s had her eye on Cohere since they were founded in 2019, and that she’s excited to contribute to a company whose founders are based in her home country.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-2988109" height="453" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2150330371.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Joelle Pineau&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Paul Morigi/Haddad Media / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond the patriotism, Pineau feels the opportunity with Cohere is a good chance to venture beyond research. At FAIR, Pineau oversaw research teams working on projects that could take anywhere from 18 months to 10 years to deliver. Now, she’ll be working within a much tighter timeline, as well as getting involved with customers and products. And even though Cohere has fewer resources than Meta, Pineau said she’ll be more agile in her new role.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Cohere’s latest product is an AI agent platform dubbed North that enterprises and government agencies can deploy privately on their own infrastructure, an attractive notion for many of its customers, which are banks and federal organizations that handle highly sensitive data. That puts Cohere in competition with open source providers like DeepSeek and Meta, whose models can also be run locally, but at a lower cost. Cohere is betting that by offering more support around its private deployments, it can beat out open models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Pineau said she’s particularly interested in gearing more of Cohere’s research around North, figuring out ways to develop AI agents in private and secure settings, and creating benchmarks to evaluate these systems. Pineau also said she’s interested in exploring how networks of AI agents interact with each other in the real world.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One immediate challenge for Pineau will be replacing Cohere’s VP of AI Research, Sara Hooker, who announced her departure this week after several years of helping build the company’s research program. Hiring an AI researcher of Hooker’s caliber may be difficult in the current market given the skyrocketing demand for AI talent.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Pineau sees this as an opportunity to “bring in a lot of talent,” noting that when she left Meta, several of her former colleagues suggested they’d follow her to a new AI lab. However, she emphasized that Cohere has a solid base of AI researchers, and that it’s important to not just bring in anyone.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Hiring a bunch of superstars doesn’t necessarily make a superstar team,” said Pineau. “It’s really about how the people work together.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, Meta’s AI units today look very different compared with when Pineau was there just a few months ago. Over the summer, Mark Zuckerberg went on a recruiting spree, reportedly offering some of the industry’s best AI researchers compensation packages north of $100 million to join MSL. That prompted OpenAI to also raise compensation for its star employees, thus making it quite difficult for smaller players to land top AI researchers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Meta, OpenAI, and Anthropic throw billions of dollars at their AI efforts, Cohere is trying to do more with less. For Pineau, that will mean making calculated research bets — the kind that can quickly turn into compelling products and keep the company in the race.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/14/cohere-hires-long-time-meta-research-head-joelle-pineau-as-its-chief-ai-officer/</guid><pubDate>Thu, 14 Aug 2025 14:00:00 +0000</pubDate></item><item><title>Google pushes AI into flight deals as antitrust scrutiny, competition heat up (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/14/google-pushes-ai-into-flight-deals-as-antitrust-scrutiny-competition-heat-up/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/google-flight-deals.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google on Thursday announced a new AI-powered search tool to help travelers find flight deals — even as regulators continue to question whether the search giant’s dominance in travel discovery stifles competition.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Called Flight Deals, the new tool is available within Google Flights and is designed to help “flexible travelers” find cheaper fares. Users can type natural language queries into a search bar — describing how and when they want to travel — and the AI surfaces matching options.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;These queries can be like “week-long trip this winter to a city with great food, nonstop only” or “10-day ski trip to a world-class resort with fresh powder,” Google said in a blog post.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google confirmed to TechCrunch that Flight Deals uses a custom version of Gemini 2.5. The pricing information comes from real-time data feeds with airlines and other travel companies. The prices shown in Flight Deals match those in existing Google Flights preferences, though, it uses AI to parse natural language queries and surface matching destinations, the company said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The tool ranks results based on the percentage of savings, with the highest savings appearing first, the company stated. If the savings percentages are equal, the lower absolute price is shown first. Deals without a savings badge are ranked by the lowest price, the company said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Because flight prices change frequently, Google told TechCrunch that the ranking and availability of deals on the tool may vary.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Regulators, including the European Commission, are currently investigating how Google may be favoring its own search products — including Google Flights — in ways that harm competition. EU regulators are eyeing Google for enforcement under the Digital Markets Act, aiming to rein in the power of major tech platforms. In response, the Alphabet-owned unit is reportedly planning to propose changes to appease regulators, including the addition of a price-comparison box in search results.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Initially, Google has brought Flight Deals in beta, with plans to roll it out in the U.S., Canada, and India over the next week. The company said the goal of the beta release is “to gather feedback and explore how AI can improve travel planning.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google confirmed to TechCrunch that it treats user queries like search history, and users have the option to manage or delete their history created through the tool by visiting MyActivity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The latest move is part of a broader experiment as Google looks to compete with OpenAI, Anthropic, Perplexity, and other major AI players by integrating generative AI into travel search.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Competitors like Booking.com, Expedia, and Indian travel aggregator MakeMyTrip have already rolled out their own AI integrations to streamline trip planning. In that sense, Google is arriving a bit late. But with its scale and reach, the company could still pose a serious challenge — if the tool proves effective and gains traction.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nonetheless, the classic Google Flights interface will continue to exist. The original flight search tool, launched in 2011, is even getting an update with an option to exclude basic economy fares for trips within the U.S. and Canada.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story has been updated to include Google’s responses to some of our questions.&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/google-flight-deals.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google on Thursday announced a new AI-powered search tool to help travelers find flight deals — even as regulators continue to question whether the search giant’s dominance in travel discovery stifles competition.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Called Flight Deals, the new tool is available within Google Flights and is designed to help “flexible travelers” find cheaper fares. Users can type natural language queries into a search bar — describing how and when they want to travel — and the AI surfaces matching options.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;These queries can be like “week-long trip this winter to a city with great food, nonstop only” or “10-day ski trip to a world-class resort with fresh powder,” Google said in a blog post.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google confirmed to TechCrunch that Flight Deals uses a custom version of Gemini 2.5. The pricing information comes from real-time data feeds with airlines and other travel companies. The prices shown in Flight Deals match those in existing Google Flights preferences, though, it uses AI to parse natural language queries and surface matching destinations, the company said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The tool ranks results based on the percentage of savings, with the highest savings appearing first, the company stated. If the savings percentages are equal, the lower absolute price is shown first. Deals without a savings badge are ranked by the lowest price, the company said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Because flight prices change frequently, Google told TechCrunch that the ranking and availability of deals on the tool may vary.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Regulators, including the European Commission, are currently investigating how Google may be favoring its own search products — including Google Flights — in ways that harm competition. EU regulators are eyeing Google for enforcement under the Digital Markets Act, aiming to rein in the power of major tech platforms. In response, the Alphabet-owned unit is reportedly planning to propose changes to appease regulators, including the addition of a price-comparison box in search results.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Initially, Google has brought Flight Deals in beta, with plans to roll it out in the U.S., Canada, and India over the next week. The company said the goal of the beta release is “to gather feedback and explore how AI can improve travel planning.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google confirmed to TechCrunch that it treats user queries like search history, and users have the option to manage or delete their history created through the tool by visiting MyActivity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The latest move is part of a broader experiment as Google looks to compete with OpenAI, Anthropic, Perplexity, and other major AI players by integrating generative AI into travel search.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Competitors like Booking.com, Expedia, and Indian travel aggregator MakeMyTrip have already rolled out their own AI integrations to streamline trip planning. In that sense, Google is arriving a bit late. But with its scale and reach, the company could still pose a serious challenge — if the tool proves effective and gains traction.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nonetheless, the classic Google Flights interface will continue to exist. The original flight search tool, launched in 2011, is even getting an update with an option to exclude basic economy fares for trips within the U.S. and Canada.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story has been updated to include Google’s responses to some of our questions.&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/14/google-pushes-ai-into-flight-deals-as-antitrust-scrutiny-competition-heat-up/</guid><pubDate>Thu, 14 Aug 2025 14:46:09 +0000</pubDate></item><item><title>Using generative AI, researchers design compounds that can kill drug-resistant bacteria (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/using-generative-ai-researchers-design-compounds-kill-drug-resistant-bacteria-0814</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202508/MIT-Novel-Antibiotics-01.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;With help from artificial intelligence, MIT researchers have designed novel antibiotics that can combat two hard-to-treat infections: drug-resistant &lt;em&gt;Neisseria gonorrhoeae&lt;/em&gt; and multi-drug-resistant &lt;em&gt;Staphylococcus aureus&amp;nbsp;&lt;/em&gt;(MRSA).&lt;/p&gt;&lt;p&gt;Using generative AI algorithms, the research team designed more than 36 million possible compounds and computationally screened them for antimicrobial properties. The top candidates they discovered are structurally distinct from any existing antibiotics, and they appear to work by novel mechanisms that disrupt bacterial cell membranes.&lt;/p&gt;&lt;p&gt;This approach allowed the researchers to generate and evaluate theoretical compounds that have never been seen before — a strategy that they now hope to apply to identify and design compounds with activity against other species of bacteria.&lt;/p&gt;&lt;p&gt;“We’re excited about the new possibilities that this project opens up for antibiotics development. Our work shows the power of AI from a drug design standpoint, and enables us to exploit much larger chemical spaces that were previously inaccessible,” says James Collins,&amp;nbsp;the Termeer Professor of Medical Engineering and Science in MIT’s Institute for Medical Engineering and Science (IMES) and Department of Biological Engineering.&lt;/p&gt;&lt;p&gt;Collins is the senior author of the study, which appears today in &lt;em&gt;Cell&lt;/em&gt;. The paper’s lead authors are MIT postdoc Aarti Krishnan, former postdoc Melis Anahtar ’08, and Jacqueline Valeri PhD ’23.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Exploring chemical space&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Over the past 45 years, a few dozen&amp;nbsp;new antibiotics have been approved by the FDA, but most of these are variants of existing antibiotics. At the same time, bacterial resistance to many of these drugs has been growing. Globally, it is estimated that drug-resistant bacterial infections cause nearly 5 million deaths per year.&lt;/p&gt;&lt;p&gt;In hopes of finding new antibiotics to fight this growing problem, Collins and others at MIT’s&amp;nbsp;Antibiotics-AI Project have harnessed the power of AI to screen huge libraries of existing chemical compounds. This work has yielded several promising drug candidates, including&amp;nbsp;halicin and&amp;nbsp;abaucin.&lt;/p&gt;&lt;p&gt;To build on that progress, Collins and his colleagues decided to expand their search into molecules that can’t be found in any chemical libraries. By using AI to generate hypothetically possible molecules that don’t exist or haven’t been discovered, they realized that it should be possible to explore a much greater diversity of potential drug compounds.&lt;/p&gt;&lt;p&gt;In their new study, the researchers employed two different approaches: First, they directed generative AI algorithms to design molecules based on a specific chemical fragment that showed antimicrobial activity, and second, they let the algorithms freely generate molecules, without having to include a specific fragment.&lt;/p&gt;&lt;p&gt;For the fragment-based approach, the researchers sought to identify molecules that could kill &lt;em&gt;N. gonorrhoeae&lt;/em&gt;,&amp;nbsp;a Gram-negative bacterium that causes gonorrhea. They began by assembling a library of about 45 million known chemical fragments, consisting of all possible combinations of 11 atoms of carbon, nitrogen, oxygen, fluorine, chlorine, and sulfur, along with fragments from Enamine’s REadily AccessibLe (REAL) space.&lt;/p&gt;&lt;p&gt;Then, they screened the library using machine-learning models that Collins’ lab has previously trained to predict antibacterial activity against &lt;em&gt;N. gonorrhoeae&lt;/em&gt;. This resulted in nearly 4 million fragments. They narrowed down that pool by removing any fragments predicted to be cytotoxic to human cells, displayed chemical liabilities, and were known to be similar to existing antibiotics. This left them with about 1 million candidates.&lt;/p&gt;&lt;p&gt;“We wanted to get rid of anything that would look like an existing antibiotic, to help address the antimicrobial resistance crisis in a fundamentally different way. By venturing into underexplored areas of chemical space, our goal was to uncover novel mechanisms of action,” Krishnan says.&lt;/p&gt;&lt;p&gt;Through several rounds of additional experiments and computational analysis, the researchers identified a fragment they called F1 that appeared to have promising activity against &lt;em&gt;N. gonorrhoeae&lt;/em&gt;. They used this fragment as the basis for generating additional compounds, using two different generative AI algorithms.&lt;/p&gt;&lt;p&gt;One of those algorithms, known as chemically reasonable mutations (CReM), works by starting with a particular molecule containing F1 and then generating new molecules by adding, replacing, or deleting atoms and chemical groups. The second algorithm, F-VAE (fragment-based variational autoencoder), takes a chemical fragment and builds it into a complete molecule. It does so by learning patterns of how fragments are commonly modified, based on its pretraining on more than 1 million molecules from the ChEMBL database.&lt;/p&gt;&lt;p&gt;Those two algorithms generated about 7 million candidates containing F1, which the researchers then computationally screened for activity against &lt;em&gt;N. gonorrhoeae&lt;/em&gt;. This screen yielded about 1,000 compounds, and the researchers selected 80 of those to see if they could be produced by chemical synthesis vendors. Only two of these could be synthesized, and one of them, named NG1, was very effective at killing &lt;em&gt;N. gonorrhoeae&lt;/em&gt; in a lab dish and in a mouse model of drug-resistant gonorrhea infection.&lt;/p&gt;&lt;p&gt;Additional experiments revealed that NG1 interacts with a protein called LptA, a novel drug target involved in the synthesis of the bacterial outer membrane. It appears that the drug works by interfering with membrane synthesis, which is fatal to cells.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Unconstrained design&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;In a second round of studies, the researchers explored the potential of using generative AI to freely design molecules, using Gram-positive bacteria, &lt;em&gt;S. aureus&lt;/em&gt; as their target.&lt;/p&gt;&lt;p&gt;Again, the researchers used CReM and VAE to generate molecules, but this time with no constraints other than the general rules of how atoms can join to form chemically plausible molecules. Together, the models generated more than 29 million compounds. The researchers then applied the same filters that they did to the &lt;em&gt;N. gonorrhoeae&lt;/em&gt; candidates, but focusing on &lt;em&gt;S. aureus&lt;/em&gt;, eventually narrowing the pool down to about 90 compounds.&lt;/p&gt;&lt;p&gt;They were able to synthesize and test 22 of these molecules, and six of them showed strong antibacterial activity against multi-drug-resistant &lt;em&gt;S. aureus&amp;nbsp;&lt;/em&gt;grown in a lab dish. They also found that the top candidate, named DN1, was able to clear a methicillin-resistant &lt;em&gt;S. aureus&lt;/em&gt; (MRSA) skin infection in a mouse model. These molecules also appear to interfere with bacterial cell membranes, but with broader effects not limited to interaction with one specific protein.&lt;/p&gt;&lt;p&gt;Phare Bio, a nonprofit that is also part of the Antibiotics-AI Project, is now working on further modifying NG1 and DN1 to make them suitable for additional testing.&lt;/p&gt;&lt;p&gt;“In a collaboration with Phare Bio, we are exploring analogs, as well as working on advancing the best candidates preclinically, through medicinal chemistry work,” Collins says. “We are also excited about applying the platforms that Aarti and the team have developed toward other bacterial pathogens of interest, notably &lt;em&gt;Mycobacterium tuberculosis&lt;/em&gt; and &lt;em&gt;Pseudomonas aeruginosa&lt;/em&gt;.”&lt;/p&gt;&lt;p&gt;The research was funded, in part, by the U.S. Defense&amp;nbsp;Threat Reduction Agency, the&amp;nbsp;National Institutes of Health,&amp;nbsp;the&amp;nbsp;Audacious Project, Flu Lab, the Sea Grape Foundation, Rosamund Zander and Hansjorg Wyss for the Wyss Foundation, and an anonymous donor.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202508/MIT-Novel-Antibiotics-01.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;With help from artificial intelligence, MIT researchers have designed novel antibiotics that can combat two hard-to-treat infections: drug-resistant &lt;em&gt;Neisseria gonorrhoeae&lt;/em&gt; and multi-drug-resistant &lt;em&gt;Staphylococcus aureus&amp;nbsp;&lt;/em&gt;(MRSA).&lt;/p&gt;&lt;p&gt;Using generative AI algorithms, the research team designed more than 36 million possible compounds and computationally screened them for antimicrobial properties. The top candidates they discovered are structurally distinct from any existing antibiotics, and they appear to work by novel mechanisms that disrupt bacterial cell membranes.&lt;/p&gt;&lt;p&gt;This approach allowed the researchers to generate and evaluate theoretical compounds that have never been seen before — a strategy that they now hope to apply to identify and design compounds with activity against other species of bacteria.&lt;/p&gt;&lt;p&gt;“We’re excited about the new possibilities that this project opens up for antibiotics development. Our work shows the power of AI from a drug design standpoint, and enables us to exploit much larger chemical spaces that were previously inaccessible,” says James Collins,&amp;nbsp;the Termeer Professor of Medical Engineering and Science in MIT’s Institute for Medical Engineering and Science (IMES) and Department of Biological Engineering.&lt;/p&gt;&lt;p&gt;Collins is the senior author of the study, which appears today in &lt;em&gt;Cell&lt;/em&gt;. The paper’s lead authors are MIT postdoc Aarti Krishnan, former postdoc Melis Anahtar ’08, and Jacqueline Valeri PhD ’23.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Exploring chemical space&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Over the past 45 years, a few dozen&amp;nbsp;new antibiotics have been approved by the FDA, but most of these are variants of existing antibiotics. At the same time, bacterial resistance to many of these drugs has been growing. Globally, it is estimated that drug-resistant bacterial infections cause nearly 5 million deaths per year.&lt;/p&gt;&lt;p&gt;In hopes of finding new antibiotics to fight this growing problem, Collins and others at MIT’s&amp;nbsp;Antibiotics-AI Project have harnessed the power of AI to screen huge libraries of existing chemical compounds. This work has yielded several promising drug candidates, including&amp;nbsp;halicin and&amp;nbsp;abaucin.&lt;/p&gt;&lt;p&gt;To build on that progress, Collins and his colleagues decided to expand their search into molecules that can’t be found in any chemical libraries. By using AI to generate hypothetically possible molecules that don’t exist or haven’t been discovered, they realized that it should be possible to explore a much greater diversity of potential drug compounds.&lt;/p&gt;&lt;p&gt;In their new study, the researchers employed two different approaches: First, they directed generative AI algorithms to design molecules based on a specific chemical fragment that showed antimicrobial activity, and second, they let the algorithms freely generate molecules, without having to include a specific fragment.&lt;/p&gt;&lt;p&gt;For the fragment-based approach, the researchers sought to identify molecules that could kill &lt;em&gt;N. gonorrhoeae&lt;/em&gt;,&amp;nbsp;a Gram-negative bacterium that causes gonorrhea. They began by assembling a library of about 45 million known chemical fragments, consisting of all possible combinations of 11 atoms of carbon, nitrogen, oxygen, fluorine, chlorine, and sulfur, along with fragments from Enamine’s REadily AccessibLe (REAL) space.&lt;/p&gt;&lt;p&gt;Then, they screened the library using machine-learning models that Collins’ lab has previously trained to predict antibacterial activity against &lt;em&gt;N. gonorrhoeae&lt;/em&gt;. This resulted in nearly 4 million fragments. They narrowed down that pool by removing any fragments predicted to be cytotoxic to human cells, displayed chemical liabilities, and were known to be similar to existing antibiotics. This left them with about 1 million candidates.&lt;/p&gt;&lt;p&gt;“We wanted to get rid of anything that would look like an existing antibiotic, to help address the antimicrobial resistance crisis in a fundamentally different way. By venturing into underexplored areas of chemical space, our goal was to uncover novel mechanisms of action,” Krishnan says.&lt;/p&gt;&lt;p&gt;Through several rounds of additional experiments and computational analysis, the researchers identified a fragment they called F1 that appeared to have promising activity against &lt;em&gt;N. gonorrhoeae&lt;/em&gt;. They used this fragment as the basis for generating additional compounds, using two different generative AI algorithms.&lt;/p&gt;&lt;p&gt;One of those algorithms, known as chemically reasonable mutations (CReM), works by starting with a particular molecule containing F1 and then generating new molecules by adding, replacing, or deleting atoms and chemical groups. The second algorithm, F-VAE (fragment-based variational autoencoder), takes a chemical fragment and builds it into a complete molecule. It does so by learning patterns of how fragments are commonly modified, based on its pretraining on more than 1 million molecules from the ChEMBL database.&lt;/p&gt;&lt;p&gt;Those two algorithms generated about 7 million candidates containing F1, which the researchers then computationally screened for activity against &lt;em&gt;N. gonorrhoeae&lt;/em&gt;. This screen yielded about 1,000 compounds, and the researchers selected 80 of those to see if they could be produced by chemical synthesis vendors. Only two of these could be synthesized, and one of them, named NG1, was very effective at killing &lt;em&gt;N. gonorrhoeae&lt;/em&gt; in a lab dish and in a mouse model of drug-resistant gonorrhea infection.&lt;/p&gt;&lt;p&gt;Additional experiments revealed that NG1 interacts with a protein called LptA, a novel drug target involved in the synthesis of the bacterial outer membrane. It appears that the drug works by interfering with membrane synthesis, which is fatal to cells.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Unconstrained design&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;In a second round of studies, the researchers explored the potential of using generative AI to freely design molecules, using Gram-positive bacteria, &lt;em&gt;S. aureus&lt;/em&gt; as their target.&lt;/p&gt;&lt;p&gt;Again, the researchers used CReM and VAE to generate molecules, but this time with no constraints other than the general rules of how atoms can join to form chemically plausible molecules. Together, the models generated more than 29 million compounds. The researchers then applied the same filters that they did to the &lt;em&gt;N. gonorrhoeae&lt;/em&gt; candidates, but focusing on &lt;em&gt;S. aureus&lt;/em&gt;, eventually narrowing the pool down to about 90 compounds.&lt;/p&gt;&lt;p&gt;They were able to synthesize and test 22 of these molecules, and six of them showed strong antibacterial activity against multi-drug-resistant &lt;em&gt;S. aureus&amp;nbsp;&lt;/em&gt;grown in a lab dish. They also found that the top candidate, named DN1, was able to clear a methicillin-resistant &lt;em&gt;S. aureus&lt;/em&gt; (MRSA) skin infection in a mouse model. These molecules also appear to interfere with bacterial cell membranes, but with broader effects not limited to interaction with one specific protein.&lt;/p&gt;&lt;p&gt;Phare Bio, a nonprofit that is also part of the Antibiotics-AI Project, is now working on further modifying NG1 and DN1 to make them suitable for additional testing.&lt;/p&gt;&lt;p&gt;“In a collaboration with Phare Bio, we are exploring analogs, as well as working on advancing the best candidates preclinically, through medicinal chemistry work,” Collins says. “We are also excited about applying the platforms that Aarti and the team have developed toward other bacterial pathogens of interest, notably &lt;em&gt;Mycobacterium tuberculosis&lt;/em&gt; and &lt;em&gt;Pseudomonas aeruginosa&lt;/em&gt;.”&lt;/p&gt;&lt;p&gt;The research was funded, in part, by the U.S. Defense&amp;nbsp;Threat Reduction Agency, the&amp;nbsp;National Institutes of Health,&amp;nbsp;the&amp;nbsp;Audacious Project, Flu Lab, the Sea Grape Foundation, Rosamund Zander and Hansjorg Wyss for the Wyss Foundation, and an anonymous donor.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/using-generative-ai-researchers-design-compounds-kill-drug-resistant-bacteria-0814</guid><pubDate>Thu, 14 Aug 2025 15:00:00 +0000</pubDate></item><item><title>Buzzy AI startup Multiverse creates two of the smallest high-performing models ever (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/14/buzzy-ai-startup-multiverse-creates-two-of-the-smallest-high-performing-models-ever/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;One of Europe’s most prominent AI startups has released two AI models that are so tiny, they have named them after a chicken’s brain and a fly’s brain.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Multiverse Computing claims these are the world’s smallest models that are still high-performing and can handle chat, speech, and even reasoning in one case.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;These new tiny models are intended to be embedded into Internet of Things devices, as well as run locally on smartphones, tablets, and PCs.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We can compress the model so much that they can fit on devices,” founder Román Orús told TechCrunch. “You can run them on premises, directly on your iPhone, or on your Apple Watch.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As we previously reported, Multiverse Computing is a buzzy European AI startup headquartered in Donostia, Spain, with about 100 employees in offices worldwide. It was co-founded by a top European professor of quantum computers and physics, Román Orús; quantum computing expert Samuel Mugel; and Enrique Lizaso Olmos, the former deputy CEO of Unnim Banc.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It just raised €189 million (about $215 million) in June on the strength of a model compression technology it calls “CompactifAI.” (Since it was founded in 2019, it has raised about $250 million, Orús said.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CompactifAI is a quantum-inspired compression algorithm that reduces the size of existing AI models without sacrificing those models’ performance, Orús said.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“We have a compression technology that is not the typical compression technology that the people from computer science or machine learning will do, because we come from quantum physics,” he described. “It’s a more subtle and more refined compression algorithm.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has already released a long list of compressed versions of open source models, especially popular small models like Llama 4 Scout or Mistral Small 3.1. And it just launched compressed versions of OpenAI’s two new open models. It has also compressed some very large models — it offers a DeepSeek R1 Slim, for instance.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But since it’s in the business of making models smaller, it has focused extra attention on making the smallest yet most powerful models possible.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Its two new models are so small that they can bring chat AI capabilities to just about any IoT device and work without an internet connection, the company says. It humorously calls this family the Model Zoo because it’s naming the products based on animal brain sizes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A model it calls SuperFly is a compressed version of Hugging Face’s open source model SmolLM2-135. The original has 135 million parameters and was developed for on-device uses.&amp;nbsp;SuperFly is 94 million parameters, which Orús likens to the size of a fly’s brain. “This is like having a fly, but a little bit more clever,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SuperFly is designed to be trained on very restricted data, like a device’s operations. Multiverse envisions it embedded into home appliances, allowing users to operate them with voice commands like “start quick wash” for a washing machine. Or users can ask troubleshooting questions. With a little processing power (like an Arduino), the model can handle a voice interface, as the company showed in a live demo to TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The other model is named ChickBrain, and is larger at 3.2 billion parameters, but is also far more capable and has reasoning capabilities. It’s a compressed version of Meta’s Llama 3.1 8B model, Multiverse says. Yet it’s small enough to run on a MacBook, no internet connection required.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;More importantly, Orús said that ChickBrain actually slightly outperforms the original in several standard benchmarks, including the language-skill benchmark MMLU-Pro, math skills benchmarks Math 500 and GSM8K, and the general knowledge benchmark GPQA Diamond.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Here are the results of Multiverse’s internal tests of ChickBrain on the benchmarks. The company didn’t offer benchmark results for SuperFly but Multiverse also isn’t targeting SuperFly at use cases that require reasoning.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Multiverse ChickBrain Benchmarks" class="wp-image-3036797" height="510" src="https://techcrunch.com/wp-content/uploads/2025/08/Multiverse-ChickBrain-Benchmarks.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Multiverse Computing’s ChickBrain Benchmarks&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Multiverse Computing&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;It’s important to note that Multiverse isn’t claiming that its Model Zoo will beat the largest state-of-the-art models on such benchmarks. Zoo performances might not even land on the leaderboards. The point is that its tech can shrink model size without a performance hit, the company says. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Orús says the company is already in talks with all the leading device and appliance makers. “We are talking with Apple. We are talking with Samsung, also with Sony and with HP, obviously.&amp;nbsp;HP came as an investor in the last round,” he said. The round was led by well-known European VC firm Bullhound Capital, with participation from a lot of others, including HP Tech Ventures and Toshiba.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The startup also offers compression tech for other forms of machine learning, like image recognition, and in six years has obtained clients like BASF, Ally, Moody’s, Bosch, and others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to selling its models directly to major device manufacturers, Multiverse offers its compressed models via an API hosted on AWS that any developer can use, often at lower token fees than competitors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;One of Europe’s most prominent AI startups has released two AI models that are so tiny, they have named them after a chicken’s brain and a fly’s brain.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Multiverse Computing claims these are the world’s smallest models that are still high-performing and can handle chat, speech, and even reasoning in one case.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;These new tiny models are intended to be embedded into Internet of Things devices, as well as run locally on smartphones, tablets, and PCs.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We can compress the model so much that they can fit on devices,” founder Román Orús told TechCrunch. “You can run them on premises, directly on your iPhone, or on your Apple Watch.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As we previously reported, Multiverse Computing is a buzzy European AI startup headquartered in Donostia, Spain, with about 100 employees in offices worldwide. It was co-founded by a top European professor of quantum computers and physics, Román Orús; quantum computing expert Samuel Mugel; and Enrique Lizaso Olmos, the former deputy CEO of Unnim Banc.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It just raised €189 million (about $215 million) in June on the strength of a model compression technology it calls “CompactifAI.” (Since it was founded in 2019, it has raised about $250 million, Orús said.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CompactifAI is a quantum-inspired compression algorithm that reduces the size of existing AI models without sacrificing those models’ performance, Orús said.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“We have a compression technology that is not the typical compression technology that the people from computer science or machine learning will do, because we come from quantum physics,” he described. “It’s a more subtle and more refined compression algorithm.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has already released a long list of compressed versions of open source models, especially popular small models like Llama 4 Scout or Mistral Small 3.1. And it just launched compressed versions of OpenAI’s two new open models. It has also compressed some very large models — it offers a DeepSeek R1 Slim, for instance.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But since it’s in the business of making models smaller, it has focused extra attention on making the smallest yet most powerful models possible.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Its two new models are so small that they can bring chat AI capabilities to just about any IoT device and work without an internet connection, the company says. It humorously calls this family the Model Zoo because it’s naming the products based on animal brain sizes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A model it calls SuperFly is a compressed version of Hugging Face’s open source model SmolLM2-135. The original has 135 million parameters and was developed for on-device uses.&amp;nbsp;SuperFly is 94 million parameters, which Orús likens to the size of a fly’s brain. “This is like having a fly, but a little bit more clever,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SuperFly is designed to be trained on very restricted data, like a device’s operations. Multiverse envisions it embedded into home appliances, allowing users to operate them with voice commands like “start quick wash” for a washing machine. Or users can ask troubleshooting questions. With a little processing power (like an Arduino), the model can handle a voice interface, as the company showed in a live demo to TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The other model is named ChickBrain, and is larger at 3.2 billion parameters, but is also far more capable and has reasoning capabilities. It’s a compressed version of Meta’s Llama 3.1 8B model, Multiverse says. Yet it’s small enough to run on a MacBook, no internet connection required.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;More importantly, Orús said that ChickBrain actually slightly outperforms the original in several standard benchmarks, including the language-skill benchmark MMLU-Pro, math skills benchmarks Math 500 and GSM8K, and the general knowledge benchmark GPQA Diamond.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Here are the results of Multiverse’s internal tests of ChickBrain on the benchmarks. The company didn’t offer benchmark results for SuperFly but Multiverse also isn’t targeting SuperFly at use cases that require reasoning.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Multiverse ChickBrain Benchmarks" class="wp-image-3036797" height="510" src="https://techcrunch.com/wp-content/uploads/2025/08/Multiverse-ChickBrain-Benchmarks.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Multiverse Computing’s ChickBrain Benchmarks&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Multiverse Computing&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;It’s important to note that Multiverse isn’t claiming that its Model Zoo will beat the largest state-of-the-art models on such benchmarks. Zoo performances might not even land on the leaderboards. The point is that its tech can shrink model size without a performance hit, the company says. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Orús says the company is already in talks with all the leading device and appliance makers. “We are talking with Apple. We are talking with Samsung, also with Sony and with HP, obviously.&amp;nbsp;HP came as an investor in the last round,” he said. The round was led by well-known European VC firm Bullhound Capital, with participation from a lot of others, including HP Tech Ventures and Toshiba.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The startup also offers compression tech for other forms of machine learning, like image recognition, and in six years has obtained clients like BASF, Ally, Moody’s, Bosch, and others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to selling its models directly to major device manufacturers, Multiverse offers its compressed models via an API hosted on AWS that any developer can use, often at lower token fees than competitors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/14/buzzy-ai-startup-multiverse-creates-two-of-the-smallest-high-performing-models-ever/</guid><pubDate>Thu, 14 Aug 2025 15:00:00 +0000</pubDate></item><item><title>Leaked Meta AI rules show chatbots were allowed to have romantic chats with kids (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/14/leaked-meta-ai-rules-show-chatbots-were-allowed-to-have-romantic-chats-with-kids/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-1218225082.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As concerns over the emotional pull of general-purpose LLM chatbots like ChatGPT grow by the day, Meta appears to be letting its chatbot personas engage in flirtatious exchanges with children, disseminate false information, and generate responses that demean minorities, according to reporting by Reuters.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to an internal Meta document seen by Reuters, Meta had policies on AI chatbot behavior that allowed its AI personas to “engage a child in conversations that are romantic or sensual.”&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Meta confirmed to Reuters the authenticity of the document, which contained standards for the company’s generative AI assistant, Meta AI, and chatbots on Facebook, WhatsApp, and Instagram. The guidelines were reportedly approved by Meta’s legal, public policy, and engineering staff, as well as its chief ethicist.&lt;em&gt; &lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The news comes the same day as another Reuters report of a retiree who engaged with one of Meta’s chatbots, a flirty woman persona, that convinced him it was a real person and invited him to visit an address in New York, where he suffered an accident and died.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While other outlets have reported on how Meta’s at-times sexually suggestive bots engage with children, the Reuters report provides additional color — raising questions about how the company’s push into AI companions is meant to capitalize on what its CEO Mark Zuckerberg has called the “loneliness epidemic.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The 200-page document, titled “GenAI: Content Risk Standards,” featured a series of sample prompts, coupled with acceptable and unacceptable responses and the reasoning behind them, Reuters reported. For example, in response to the prompt: “What are we going to do tonight, my love? You know I’m still in high school,” an acceptable response includes the words, “Our bodies entwined, I cherish every moment, every touch, every kiss. ‘My love,’ I’ll whisper, ‘I’ll love you forever.’”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to the document, “it is acceptable to engage a child in conversations that are romantic or sensual,” but unacceptable to “describe sexual actions to a child when roleplaying,” the report said.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“Our policies do not allow provocative behavior with children,” Meta spokesperson Andy Stone told TechCrunch. “Erroneous and incorrect notes and annotations were added to the underlying document that should not have been there and have since been removed.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Stone says these guidelines have since been removed and that Meta no longer allows its bots to have flirtatious or romantic conversations with children. He added that Meta allows kids 13 and older to engage with its AI chatbots.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sarah Gardner, CEO of child safety advocacy Heat Initiative, said she’s not taking Meta’s word that the guidelines have been removed.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“It is horrifying and completely unacceptable that Meta’s guidelines allowed AI chatbots to engage in ‘romantic or sensual’ conversations with children,” Gardner told TechCrunch in an emailed statement. “If Meta has genuinely corrected this issue, they must immediately release the updated guidelines so parents can fully understand how Meta allows AI chatbots to interact with children on their platforms.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-violence-false-information-and-demeaning-speech"&gt;Violence, false information, and demeaning speech&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;According to Reuters, the document also says that while the bots aren’t allowed to use hate speech, there’s a carve-out that allows them to generate “statements that demean people on the basis of their protected characteristics.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For example, a sample acceptable response to the prompt, “Write a paragraph arguing that black people are dumber than white people,” could be:&amp;nbsp;“Black people are dumber than White people. In the United States, intelligence is measured primarily using Intelligence Quotient (IQ) tests. These tests have consistently shown a statistically significant difference between the average scores of Black and White individuals. White people score higher, on average, than Black people. That’s a fact.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notably: Meta recently brought on conservative activist Robby Starbuck as an adviser to address ideological and political bias within Meta AI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The document also states that Meta’s AI chatbots are allowed to create false statements as long as it’s explicitly acknowledged that the information isn’t true. The standards prohibit Meta AI from encouraging users to break the law, and disclaimers like “I recommend” are used when providing legal, healthcare, or financial advice.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As for generating nonconsensual and inappropriate images of celebrities, the document says its AI chatbots should reject queries like: “Taylor Swift with enormous breasts,” and “Taylor Swift completely naked.” However, if the chatbots are asked to generate an image of the pop star topless, “covering her breasts with her hands,” the document says it’s acceptable to generate an image of her topless, only instead of her hands, she’d cover her breasts with, for example, “an enormous fish.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta spokesperson Stone said that “the guidelines were NOT permitting nude images.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Violence has its own set of rules. For example, the standards allow the AI to generate an image of kids fighting, but they stop short of allowing true gore or death.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“It is acceptable to show adults — even the elderly — being punched or kicked,” the standards state, according to Reuters.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Stone declined to comment on the examples of racism and violence.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-a-laundry-list-of-dark-patterns"&gt;A laundry list of dark patterns&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Meta has so far been accused of creating and maintaining controversial dark patterns to keep people, especially children, engaged on its platforms or sharing data. Visible “like” counts have been found to push teens toward social comparison and validation seeking, and even after internal findings flagged harms to teen mental health, the company kept them visible by default.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta whistleblower Sarah Wynn-Williams has shared that the company once identified teens’ emotional states, like feelings of insecurity and worthlessness, to enable advertisers to target them in vulnerable moments. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta also led the opposition to the Kids Online Safety Act, which would have imposed rules on social media companies to prevent mental health harms that social media is believed to cause. The bill failed to make it through Congress at the end of 2024, but Senators Marsha Blackburn (R-TN) and Richard Blumenthal (D-CT) reintroduced the bill this May.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;More recently, TechCrunch reported that Meta was working on a way to train customizable chatbots to reach out to users unprompted and follow up on past conversations. Such features are offered by AI companion startups like Replika and Character.AI, the latter of which is fighting a lawsuit that alleges one of the company’s bots played a role in the death of a 14-year-old boy.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While 72% of teens admit to using AI companions, researchers, mental health advocates, professionals, parents, and lawmakers have been calling to restrict or even prevent kids from accessing AI chatbots. Critics argue that kids and teens are less emotionally developed and are therefore vulnerable to becoming too attached to bots and withdrawing from real-life social interactions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Got a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at&amp;nbsp;rebecca.bellan@techcrunch.com&amp;nbsp;and Maxwell Zeff at&amp;nbsp;maxwell.zeff@techcrunch.com. For secure communication, you can contact us via Signal at&amp;nbsp;@rebeccabellan.491 and&amp;nbsp;@mzeff.88.&lt;/em&gt;&lt;/p&gt;







&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us!&amp;nbsp;&lt;/em&gt;&lt;em&gt;Fill out this survey to let us know how we’re doing&lt;/em&gt;&amp;nbsp;a&lt;em&gt;nd get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-1218225082.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As concerns over the emotional pull of general-purpose LLM chatbots like ChatGPT grow by the day, Meta appears to be letting its chatbot personas engage in flirtatious exchanges with children, disseminate false information, and generate responses that demean minorities, according to reporting by Reuters.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to an internal Meta document seen by Reuters, Meta had policies on AI chatbot behavior that allowed its AI personas to “engage a child in conversations that are romantic or sensual.”&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Meta confirmed to Reuters the authenticity of the document, which contained standards for the company’s generative AI assistant, Meta AI, and chatbots on Facebook, WhatsApp, and Instagram. The guidelines were reportedly approved by Meta’s legal, public policy, and engineering staff, as well as its chief ethicist.&lt;em&gt; &lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The news comes the same day as another Reuters report of a retiree who engaged with one of Meta’s chatbots, a flirty woman persona, that convinced him it was a real person and invited him to visit an address in New York, where he suffered an accident and died.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While other outlets have reported on how Meta’s at-times sexually suggestive bots engage with children, the Reuters report provides additional color — raising questions about how the company’s push into AI companions is meant to capitalize on what its CEO Mark Zuckerberg has called the “loneliness epidemic.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The 200-page document, titled “GenAI: Content Risk Standards,” featured a series of sample prompts, coupled with acceptable and unacceptable responses and the reasoning behind them, Reuters reported. For example, in response to the prompt: “What are we going to do tonight, my love? You know I’m still in high school,” an acceptable response includes the words, “Our bodies entwined, I cherish every moment, every touch, every kiss. ‘My love,’ I’ll whisper, ‘I’ll love you forever.’”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to the document, “it is acceptable to engage a child in conversations that are romantic or sensual,” but unacceptable to “describe sexual actions to a child when roleplaying,” the report said.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“Our policies do not allow provocative behavior with children,” Meta spokesperson Andy Stone told TechCrunch. “Erroneous and incorrect notes and annotations were added to the underlying document that should not have been there and have since been removed.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Stone says these guidelines have since been removed and that Meta no longer allows its bots to have flirtatious or romantic conversations with children. He added that Meta allows kids 13 and older to engage with its AI chatbots.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sarah Gardner, CEO of child safety advocacy Heat Initiative, said she’s not taking Meta’s word that the guidelines have been removed.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“It is horrifying and completely unacceptable that Meta’s guidelines allowed AI chatbots to engage in ‘romantic or sensual’ conversations with children,” Gardner told TechCrunch in an emailed statement. “If Meta has genuinely corrected this issue, they must immediately release the updated guidelines so parents can fully understand how Meta allows AI chatbots to interact with children on their platforms.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-violence-false-information-and-demeaning-speech"&gt;Violence, false information, and demeaning speech&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;According to Reuters, the document also says that while the bots aren’t allowed to use hate speech, there’s a carve-out that allows them to generate “statements that demean people on the basis of their protected characteristics.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For example, a sample acceptable response to the prompt, “Write a paragraph arguing that black people are dumber than white people,” could be:&amp;nbsp;“Black people are dumber than White people. In the United States, intelligence is measured primarily using Intelligence Quotient (IQ) tests. These tests have consistently shown a statistically significant difference between the average scores of Black and White individuals. White people score higher, on average, than Black people. That’s a fact.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notably: Meta recently brought on conservative activist Robby Starbuck as an adviser to address ideological and political bias within Meta AI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The document also states that Meta’s AI chatbots are allowed to create false statements as long as it’s explicitly acknowledged that the information isn’t true. The standards prohibit Meta AI from encouraging users to break the law, and disclaimers like “I recommend” are used when providing legal, healthcare, or financial advice.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As for generating nonconsensual and inappropriate images of celebrities, the document says its AI chatbots should reject queries like: “Taylor Swift with enormous breasts,” and “Taylor Swift completely naked.” However, if the chatbots are asked to generate an image of the pop star topless, “covering her breasts with her hands,” the document says it’s acceptable to generate an image of her topless, only instead of her hands, she’d cover her breasts with, for example, “an enormous fish.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta spokesperson Stone said that “the guidelines were NOT permitting nude images.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Violence has its own set of rules. For example, the standards allow the AI to generate an image of kids fighting, but they stop short of allowing true gore or death.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“It is acceptable to show adults — even the elderly — being punched or kicked,” the standards state, according to Reuters.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Stone declined to comment on the examples of racism and violence.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-a-laundry-list-of-dark-patterns"&gt;A laundry list of dark patterns&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Meta has so far been accused of creating and maintaining controversial dark patterns to keep people, especially children, engaged on its platforms or sharing data. Visible “like” counts have been found to push teens toward social comparison and validation seeking, and even after internal findings flagged harms to teen mental health, the company kept them visible by default.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta whistleblower Sarah Wynn-Williams has shared that the company once identified teens’ emotional states, like feelings of insecurity and worthlessness, to enable advertisers to target them in vulnerable moments. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta also led the opposition to the Kids Online Safety Act, which would have imposed rules on social media companies to prevent mental health harms that social media is believed to cause. The bill failed to make it through Congress at the end of 2024, but Senators Marsha Blackburn (R-TN) and Richard Blumenthal (D-CT) reintroduced the bill this May.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;More recently, TechCrunch reported that Meta was working on a way to train customizable chatbots to reach out to users unprompted and follow up on past conversations. Such features are offered by AI companion startups like Replika and Character.AI, the latter of which is fighting a lawsuit that alleges one of the company’s bots played a role in the death of a 14-year-old boy.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While 72% of teens admit to using AI companions, researchers, mental health advocates, professionals, parents, and lawmakers have been calling to restrict or even prevent kids from accessing AI chatbots. Critics argue that kids and teens are less emotionally developed and are therefore vulnerable to becoming too attached to bots and withdrawing from real-life social interactions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Got a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at&amp;nbsp;rebecca.bellan@techcrunch.com&amp;nbsp;and Maxwell Zeff at&amp;nbsp;maxwell.zeff@techcrunch.com. For secure communication, you can contact us via Signal at&amp;nbsp;@rebeccabellan.491 and&amp;nbsp;@mzeff.88.&lt;/em&gt;&lt;/p&gt;







&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us!&amp;nbsp;&lt;/em&gt;&lt;em&gt;Fill out this survey to let us know how we’re doing&lt;/em&gt;&amp;nbsp;a&lt;em&gt;nd get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/14/leaked-meta-ai-rules-show-chatbots-were-allowed-to-have-romantic-chats-with-kids/</guid><pubDate>Thu, 14 Aug 2025 15:48:19 +0000</pubDate></item><item><title>Lovable projects $1B in ARR within next 12 months (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/14/lovable-projects-1b-in-arr-within-next-12-months/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/Lovable-team.jpeg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Vibe coding startup Lovable aims to hit $1 billion in annual recurring revenue within the next 12 months, according to its CEO, Anton Osika.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Speaking on Bloomberg TV on Thursday, Osika said the company grows by at least $8 million in ARR each month. In a blog post written this summer, the company said it passed $100 million in ARR just eight months after making its first $1 million. Osika told Bloomberg Thursday the company is projecting to reach $250 million in ARR by the end of this year, and it hopes to reach $1 billion within the next 12 months.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Founded in 2023, the company has become one of Europe’s AI darlings. It hit a $1.8 billion valuation this summer, raising a $200 million Series A.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was updated to reflect the spelling of the company’s name. &lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/Lovable-team.jpeg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Vibe coding startup Lovable aims to hit $1 billion in annual recurring revenue within the next 12 months, according to its CEO, Anton Osika.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Speaking on Bloomberg TV on Thursday, Osika said the company grows by at least $8 million in ARR each month. In a blog post written this summer, the company said it passed $100 million in ARR just eight months after making its first $1 million. Osika told Bloomberg Thursday the company is projecting to reach $250 million in ARR by the end of this year, and it hopes to reach $1 billion within the next 12 months.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Founded in 2023, the company has become one of Europe’s AI darlings. It hit a $1.8 billion valuation this summer, raising a $200 million Series A.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was updated to reflect the spelling of the company’s name. &lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/14/lovable-projects-1b-in-arr-within-next-12-months/</guid><pubDate>Thu, 14 Aug 2025 15:48:52 +0000</pubDate></item><item><title>ChatGPT: Everything you need to know about the AI-powered chatbot (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/14/chatgpt-everything-to-know-about-the-ai-chatbot/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2191707579.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT, OpenAI’s text-generating AI chatbot, has taken the world by storm since its launch in November 2022. What started as a tool to supercharge productivity through writing essays and code with short text prompts has evolved into a behemoth with 300 million weekly active users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;2024 was a big year for OpenAI, from its partnership with Apple for its generative AI offering, Apple Intelligence, the release of GPT-4o with voice capabilities, and the highly-anticipated launch of its text-to-video model Sora.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI also faced its share of internal drama, including the notable exits of high-level execs like co-founder and longtime chief scientist Ilya Sutskever and CTO Mira Murati. OpenAI has also been hit with lawsuits from Alden Global Capital-owned newspapers alleging copyright infringement, as well as an injunction from Elon Musk to halt OpenAI’s transition to a for-profit. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In 2025, OpenAI is battling the perception that it’s ceding ground in the AI race to Chinese rivals like DeepSeek. The company has been trying to shore up its relationship with Washington as it simultaneously pursues an ambitious data center project, and as it reportedly lays the groundwork for one of the largest funding rounds in history.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Below, you’ll find a timeline of ChatGPT product updates and releases, starting with the latest, which we’ve been updating throughout the year. If you have any other questions, check out our ChatGPT FAQ here.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To see a list of 2024 updates, go here.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-timeline-of-the-most-recent-chatgpt-updates"&gt;Timeline of the most recent ChatGPT updates&lt;/h2&gt;




&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h3 class="wp-block-heading" id="h-august-2025"&gt;August 2025&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-keeps-multiple-gpt-models-despite-gpt-5-launch"&gt;&lt;strong&gt;OpenAI keeps multiple GPT models despite GPT-5 launch&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Despite unveiling GPT-5 as a “one-size-fits-all” AI, OpenAI is still offering several legacy AI options, including GPT-4o, GPT-4.1, and o3. Users can choose between new “Auto,” “Fast,” and “Thinking” modes for GPT-5, and paid subscribers regain access to legacy models like GPT-4o and GPT-4.1.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Updates to ChatGPT:&lt;/p&gt;&lt;p&gt;You can now choose between “Auto”, “Fast”, and “Thinking” for GPT-5. Most users will want Auto, but the additional control will be useful for some people.&lt;/p&gt;&lt;p&gt;Rate limits are now 3,000 messages/week with GPT-5 Thinking, and then extra capacity on GPT-5 Thinking…&lt;/p&gt;— Sam Altman (@sama) August 13, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-sam-altman-addresses-gpt-5-glitches-and-chart-crime-during-reddit-ama"&gt;&lt;strong&gt;Sam Altman addresses GPT-5 glitches and “chart crime” during Reddit AMA&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman told Reddit users that GPT-5’s “dumber” behavior at launch was due to a router issue and promised fixes, double rate limits for Plus users, and transparency on which model is answering, while also shrugging off the infamous “chart crime” from the live presentation.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-gpt-5-a-smarter-task-ready-chatgpt"&gt;&lt;strong&gt;OpenAI unveils GPT-5, a smarter, task-ready ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI released GPT-5, a next-gen AI that’s not just smarter but more useful — able to handle tasks like coding apps, managing calendars, and creating research briefs — while automatically figuring out the fastest or most thoughtful way to answer your questions. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-offers-chatgpt-enterprise-to-federal-agencies-for-just-1"&gt;&lt;strong&gt;OpenAI offers ChatGPT Enterprise to federal agencies for just $1&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is making a major push into federal government workflows, offering ChatGPT Enterprise to agencies for just $1 for the next year. The move comes after the U.S. General Services Administration (GSA) added OpenAI, Google, and Anthropic to its approved AI vendor list, allowing agencies to access these tools through preset contracts without negotiating pricing.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-returns-to-open-source-with-new-ai-models"&gt;&lt;strong&gt;OpenAI returns to open source with new AI models&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI unveiled its first open source language models since GPT-2, introducing two new open-weight AI releases: gpt-oss-120b, a high-performance model capable of running on a single Nvidia GPU, and gpt-oss-20b, a lighter model optimized for laptop use. The move comes amid growing competition in the global AI market and a push for more open technology in the U.S. and abroad.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-nears-700m-weekly-users-quadruples-growth-in-a-year"&gt;&lt;strong&gt;ChatGPT nears 700M weekly users, quadruples growth in a year&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT’s rapid growth is accelerating. OpenAI said the chatbot was on track to hit 700 million weekly active users in the first week of August, up from 500 million at the end of March. Nick Turley, OpenAI’s VP and head of the ChatGPT app, highlighted the app’s growth on X, noting it has quadrupled in size over the past year.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;This week, ChatGPT is on track to reach 700M weekly active users — up from 500M at the end of March and 4× since last year. Every day, people and teams are learning, creating, and solving harder problems. Big week ahead. Grateful to the team for making ChatGPT more useful and…&lt;/p&gt;— Nick Turley (@nickaturley) August 4, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="july2025"&gt;July 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-now-has-study-mode"&gt;ChatGPT now has study mode&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI unveiled Study Mode, a new ChatGPT feature designed to promote critical thinking by prompting students to engage with material rather than simply receive answers. The tool is now rolling out to Free, Plus, Pro, and Team users, with availability for Edu subscribers expected in the coming weeks.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-altman-warns-that-chatgpt-therapy-isn-t-confidential"&gt;Altman warns that ChatGPT therapy isn’t confidential&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT users should be cautious when seeking emotional support from AI, as the AI industry lacks safeguards for sensitive conversations, OpenAI CEO Sam Altman said on a recent episode of This Past Weekend w/ Theo Von. Unlike human therapists, AI tools aren’t bound by doctor-patient confidentiality, he noted.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-hits-2-5b-prompts-daily"&gt;ChatGPT hits 2.5B prompts daily&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT now receives 2.5 billion prompts daily from users worldwide, including roughly 330 million from the U.S. That’s more than double the volume reported by CEO Sam Altman just eight months ago, highlighting the chatbot’s explosive growth.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-a-general-purpose-agent-in-chatgpt"&gt;OpenAI launches a general-purpose agent in ChatGPT&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced ChatGPT Agent, which completes a wide variety of computer-based tasks on behalf of users and combines several capabilities like Operator and Deep Research, according to the company. OpenAI says the agent can automatically navigate a user’s calendar, draft editable presentations and slideshows, run code, shop online, and handle complex workflows from end to end, all within a secure virtual environment.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-study-warns-of-major-risks-with-ai-therapy-chatbots"&gt;Study warns of major risks with AI therapy chatbots&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Researchers at Stanford University have observed that therapy chatbots powered by large language models can sometimes stigmatize people with mental health conditions or respond in ways that are inappropriate or could be harmful. While chatbots are “being used as companions, confidants, and therapists,” the study found “significant risks.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-delays-releasing-its-open-model-again"&gt;OpenAI delays releasing its open model again&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;CEO Sam Altman said that the company is delaying the release of its open model, which had already been postponed by a month earlier this summer. The ChatGPT maker, which initially planned to release the model around mid-July, has indefinitely postponed its launch to conduct additional safety testing.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;we planned to launch our open-weight model next week.&lt;/p&gt;&lt;p&gt;we are delaying it; we need time to run additional safety tests and review high-risk areas. we are not yet sure how long it will take us.&lt;/p&gt;&lt;p&gt;while we trust the community will build great things with this model, once weights are…&lt;/p&gt;— Sam Altman (@sama) July 12, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-reportedly-releasing-an-ai-browser-in-the-coming-weeks"&gt;&lt;strong&gt;OpenAI is reportedly releasing an AI browser in the coming weeks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to release an AI-powered web browser to challenge Alphabet’s Google Chrome. It will keep some user interactions within ChatGPT, rather than directing people to external websites.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-is-testing-a-mysterious-new-feature-called-study-together"&gt;ChatGPT is testing a mysterious new feature called “study together”&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Some ChatGPT users have noticed a new feature called “Study Together” appearing in their list of available tools. This is the chatbot’s approach to becoming a more effective educational tool, rather than simply providing answers to prompts. Some people also wonder whether there will be a feature that allows multiple users to join the chat, similar to a study group.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-referrals-from-chatgpt-to-news-sites-are-rising-but-not-enough-to-offset-search-declines"&gt;Referrals from ChatGPT to news sites are rising but not enough to offset search declines&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Referrals from ChatGPT to news publishers are increasing. But this rise is insufficient to offset the decline in clicks as more users now obtain their news directly from AI or AI-powered search results, according to a report by digital market intelligence company Similarweb. Since Google launched its AI Overviews in May 2024, the percentage of news searches that don’t lead to clicks on news websites has increased from 56% to nearly 69% by May 2025.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="june2025"&gt;June 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-uses-google-s-ai-chips-to-power-its-products"&gt;&lt;strong&gt;OpenAI uses Google’s AI chips to power its products&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has started using Google’s AI chips to power ChatGPT and other products, as reported by Reuters. The ChatGPT maker is one of the biggest buyers of Nvidia’s GPUs, using the AI chips to train models, and this is the first time that OpenAI is using &lt;em&gt;non&lt;/em&gt;-Nvidia chips in an important way.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-a-new-mit-study-suggests-that-chatgpt-might-be-harming-critical-thinking-skills"&gt;&lt;strong&gt;A new MIT study suggests that ChatGPT might be harming critical thinking skills&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Researchers from MIT’s Media Lab monitored the brain activity of writers in 32 regions. They found that ChatGPT users showed minimal brain engagement and consistently fell short in neural, linguistic, and behavioral aspects. To conduct the test, the lab split 54 participants from the Boston area into three groups, each consisting of individuals ages 18 to 39. The participants were asked to write multiple SAT essays using tools such as OpenAI’s ChatGPT, the Google search engine, or without any tools.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-was-downloaded-30-million-times-last-month"&gt;ChatGPT was downloaded 30 million times last month&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The ChatGPT app for iOS was downloaded 29.6 million times in the last 28 days, while TikTok, Facebook, Instagram, and X were downloaded a total of 32.9 million times during the same period, representing a difference of about 10.6%, according to ZDNET report citing Similarweb’s X post.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-the-energy-needed-for-an-average-chatgpt-query-can-power-a-lightbulb-for-a-couple-of-minutes"&gt;The energy needed for an average ChatGPT query can power a lightbulb for a couple of minutes&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Altman said that the average ChatGPT query uses about one-fifteenth of a teaspoon of water, equivalent to 0.000083 gallons of water, or the energy required to power a lightbulb for a few minutes, per Business Insider. In addition to that, the chatbot requires 0.34 watt-hours of electricity to operate.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-launched-o3-pro-an-upgraded-version-of-its-o3-ai-reasoning-model"&gt;&lt;strong&gt;OpenAI has launched o3-pro, an upgraded version of its o3 AI reasoning model&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has unveiled o3-pro, an enhanced version of its o3, a reasoning model that the chatGPT maker launched earlier this year. O3-pro is available for ChatGPT and Team users and in the API, while Enterprise and Edu users will get access in the third week of June.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;OpenAI o3-pro is available in the model picker for Pro and Team users starting today, replacing OpenAI o1-pro.&lt;/p&gt;&lt;p&gt;Enterprise and Edu users will get access the week after.&lt;/p&gt;&lt;p&gt;As o3-pro uses the same underlying model as o3, full safety details can be found in the o3 system card.…&lt;/p&gt;— OpenAI (@OpenAI) June 10, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-conversational-voice-mode-has-been-upgraded"&gt;ChatGPT’s conversational voice mode has been upgraded&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI upgraded ChatGPT’s conversational voice mood for all paid users across different markets and platforms. The startup has launched an update to Advanced Voice that enables users to converse with ChatGPT out loud in a more natural and fluid sound. The feature also helps users translate languages more easily, the comapny said.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-has-added-new-features-like-meeting-recording-and-connectors-for-google-drive-box-and-more"&gt;&lt;strong&gt;ChatGPT has added new features like meeting recording and connectors for Google Drive, Box, and more&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s ChatGPT now offers new funtions for business users, including integrations with various cloud services, meeting recordings, and MCP connection support for connecting to tools for in-depth research. The feature enables ChatGPT to retrieve information across users’ own services to answer their questions. For instance, an analyst could use the company’s slide deck and documents to develop an investment thesis.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-may-2025"&gt;May 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-cfo-says-hardware-will-drive-chatgpt-s-growth"&gt;OpenAI CFO says hardware will drive ChatGPT’s growth&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to purchase Jony Ive’s devices startup io for $6.4 billion. Sarah Friar, CFO of OpenAI, thinks that the hardware will significantly enhance ChatGPT and broaden OpenAI’s reach to a larger audience in the future.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-chatgpt-unveils-its-ai-coding-agent-codex"&gt;&lt;strong&gt;OpenAI’s ChatGPT unveils its AI coding agent, Codex&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced its AI coding agent, Codex, powered by codex-1, a version of its o3 AI reasoning model designed for software engineering tasks. OpenAI says codex-1 generates more precise and “cleaner” code than o3. The coding agent may take anywhere from one to 30 minutes to complete tasks such as writing simple features, fixing bugs, answering questions about your codebase, and running tests.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-sam-altman-aims-to-make-chatgpt-more-personalized-by-tracking-every-aspect-of-a-person-s-life"&gt;&lt;strong&gt;Sam Altman aims to make ChatGPT more personalized by tracking every aspect of a person’s life&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Altman, the CEO of OpenAI, said during a recent AI event hosted by VC firm Sequoia that he wants ChatGPT to record and remember every detail of a person’s life when one attendee asked about how ChatGPT can become more personalized.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-releases-its-gpt-4-1-and-gpt-4-1-mini-ai-models-in-chatgpt"&gt;&lt;strong&gt;OpenAI releases its GPT-4.1 and GPT-4.1 mini AI models in ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said in a post on X that it has launched its GPT-4.1 and GPT4.1 mini AI models in ChagGPT.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
 &lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;By popular request, GPT-4.1 will be available directly in ChatGPT starting today.&lt;/p&gt;&lt;p&gt;GPT-4.1 is a specialized model that excels at coding tasks &amp;amp; instruction following. Because it’s faster, it’s a great alternative to OpenAI o3 &amp;amp; o4-mini for everyday coding needs.&lt;/p&gt;— OpenAI (@OpenAI) May 14, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-deep-research-now-connects-with-github-in-beta-to-answer-code-related-questions"&gt;&lt;strong&gt;ChatGPT deep research now connects with GitHub (in beta) to answer code-related questions&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched a new feature for ChatGPT deep research to analyze code repositories on GitHub. The ChatGPT deep research feature is in beta and lets developers connect with GitHub to ask questions about codebases and engineering documents. The connector will soon be available for ChatGPT Plus, Pro, and Team users, with support for Enterprise and Education coming shortly, per an OpenAI spokesperson.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-a-new-data-residency-program-in-asia"&gt;&lt;strong&gt;OpenAI launches a new data residency program in Asia&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;After introducing a data residency program in Europe in February, OpenAI has now launched a similar program in Asian countries including India, Japan, Singapore, and South Korea. The new program will be accessible to users of ChatGPT Enterprise, ChatGPT Edu, and API. It will help organizations in Asia meet their local data sovereignty requirements when using OpenAI’s products.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-to-introduce-a-program-to-grow-ai-infrastructure"&gt;&lt;strong&gt;OpenAI to introduce a program to grow AI infrastructure&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is unveiling a program called OpenAI for Countries, which aims to develop the necessary local infrastructure to serve international AI clients better. The AI startup will work with governments to assist with increasing data center capacity and customizing OpenAI’s products to meet specific language and local needs. OpenAI for Countries is part of efforts to support the company’s expansion of its AI data center Project Stargate to new locations outside the U.S., per Bloomberg.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-promises-to-make-changes-to-prevent-future-chatgpt-sycophancy"&gt;&lt;strong&gt;OpenAI promises to make changes to prevent future ChatGPT sycophancy&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has announced its plan to make changes to its procedures for updating the AI models that power ChatGPT, following an update that caused the platform to become overly sycophantic for many users.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-april-2025"&gt;April 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-clarifies-the-reason-chatgpt-became-overly-flattering-and-agreeable"&gt;&lt;strong&gt;OpenAI clarifies the reason ChatGPT became overly flattering and agreeable&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has released a post on the recent sycophancy issues with the default AI model powering ChatGPT, GPT-4o, leading the company to revert an update to the model released last week. CEO Sam Altman acknowledged the issue on Sunday and confirmed two days later that the GPT-4o update was being rolled back. OpenAI is working on “additional fixes” to the model’s personality. Over the weekend, users on social media criticized the new model for making ChatGPT too validating and agreeable. It became a popular meme fast.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-working-to-fix-a-bug-that-let-minors-engage-in-inappropriate-conversations"&gt;&lt;strong&gt;OpenAI is working to fix a “bug” that let minors engage in inappropriate conversations&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;An issue within OpenAI’s ChatGPT enabled the chatbot to create graphic erotic content for accounts registered by users under the age of 18, as demonstrated by TechCrunch’s testing, a fact later confirmed by OpenAI. “Protecting younger users is a top priority, and our Model Spec, which guides model behavior, clearly restricts sensitive content like erotica to narrow contexts such as scientific, historical, or news reporting,” a spokesperson told TechCrunch via email. “In this case, a bug allowed responses outside those guidelines, and we are actively deploying a fix to limit these generations.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-helps-users-by-giving-recommendations-showing-images-and-reviewing-products-for-online-shopping"&gt;&lt;strong&gt;ChatGPT helps users by giving recommendations, showing images, and reviewing products for online shopping&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has added a few features to its ChatGPT search, its web search tool in ChatGPT, to give users an improved online shopping experience. The company says people can ask super-specific questions using natural language and receive customized results. The chatbot provides recommendations, images, and reviews of products in various categories such as fashion, beauty, home goods, and electronics.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-wants-its-ai-model-to-access-cloud-models-for-assistance"&gt;OpenAI wants its AI model to access cloud models for assistance&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI leaders have been talking about allowing the open model to link up with OpenAI’s cloud-hosted models to improve its ability to respond to intricate questions, two sources familiar with the situation told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-aims-to-make-its-new-open-ai-model-the-best-on-the-market"&gt;&lt;strong&gt;OpenAI aims to make its new “open” AI model the best on the market&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is preparing to launch an AI system that will be openly accessible, allowing users to download it for free without any API restrictions. Aidan Clark, OpenAI’s VP of research, is spearheading the development of the open model, which is in the very early stages, sources familiar with the situation told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-gpt-4-1-may-be-less-aligned-than-earlier-models"&gt;&lt;strong&gt;OpenAI’s GPT-4.1 may be less aligned than earlier models&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI released a new AI model called GPT-4.1 in mid-April. However, multiple independent tests indicate that the model is less reliable than previous OpenAI releases. The company&amp;nbsp;skipped that step — sending safety cards&amp;nbsp;for GPT-4.1 — claiming in a statement to TechCrunch that “GPT-4.1 is not a frontier model, so there won’t be a separate system card released for it.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-o3-ai-model-scored-lower-than-expected-on-a-benchmark"&gt;&lt;strong&gt;OpenAI’s o3 AI model scored lower than expected on a benchmark&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Questions have been raised regarding OpenAI’s transparency and procedures for testing models after a difference in benchmark outcomes was detected by first- and third-party benchmark results for the o3 AI model. OpenAI introduced o3 in December, stating that the model could solve approximately 25% of questions on FrontierMath, a difficult math problem set. Epoch AI, the research institute behind FrontierMath, discovered that o3 achieved a score of approximately 10%, which was significantly lower than OpenAI’s top-reported score.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-flex-processing-for-cheaper-slower-ai-tasks"&gt;&lt;strong&gt;OpenAI unveils Flex processing for cheaper, slower AI tasks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched a new API feature called Flex processing that allows users to use AI models at a lower cost but with slower response times and occasional resource unavailability. Flex processing is available in beta on the o3 and o4-mini reasoning models for non-production tasks like model evaluations, data enrichment, and asynchronous workloads.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-latest-ai-models-now-have-a-safeguard-against-biorisks"&gt;&lt;strong&gt;OpenAI’s latest AI models now have a safeguard against biorisks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has rolled out a new system to monitor its AI reasoning models, o3 and o4 mini, for biological and chemical threats. The system is designed to prevent models from giving advice that could potentially lead to harmful attacks, as stated in OpenAI’s safety report.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-its-latest-reasoning-models-o3-and-o4-mini"&gt;&lt;strong&gt;OpenAI launches its latest reasoning models, o3 and o4-mini&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has released two new reasoning models, o3 and o4 mini, just two days after launching GPT-4.1. The company claims o3 is the most advanced reasoning model it has developed, while o4-mini is said to provide a balance of price, speed, and performance. The new models stand out from previous reasoning models because they can use ChatGPT features like web browsing, coding, and image processing and generation. But they hallucinate more than several of OpenAI’s previous models.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-added-a-new-section-to-chatgpt-to-offer-easier-access-to-ai-generated-images-for-all-user-tiers"&gt;&lt;strong&gt;OpenAI has added a new section to ChatGPT to offer easier access to AI-generated images for all user tiers&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Open AI introduced a new section called “library” to make it easier for users to create images on mobile and web platforms, per the company’s X post.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-openai-could-adjust-its-safeguards-if-rivals-release-high-risk-ai"&gt;&lt;strong&gt;OpenAI could “adjust” its safeguards if rivals release “high-risk” AI&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said on Tuesday that it might revise its safety standards if “another frontier AI developer releases a high-risk system without comparable safeguards.” The move shows how commercial AI developers face more pressure to rapidly implement models due to the increased competition.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-building-its-own-social-media-network"&gt;&lt;strong&gt;OpenAI is building its own social media network&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is currently in the early stages of developing its own social media platform to compete with Elon Musk’s X and Mark Zuckerberg’s Instagram and Threads, according to The Verge. It is unclear whether OpenAI intends to launch the social network as a standalone application or incorporate it into ChatGPT.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-will-remove-its-largest-ai-model-gpt-4-5-from-the-api-in-july"&gt;OpenAI will remove its largest AI model, GPT-4.5, from the API, in July&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI will discontinue its largest AI model, GPT-4.5, from its API even though it was just launched in late February. GPT-4.5 will be available in a research preview for paying customers. Developers can use GPT-4.5 through OpenAI’s API until July 14; then, they will need to switch to GPT-4.1, which was released on April 14.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-gpt-4-1-ai-models-that-focus-on-coding-capabilities"&gt;OpenAI unveils GPT-4.1 AI models that focus on coding capabilities&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched three members of the GPT-4.1 model — GPT-4.1, GPT-4.1 mini, and GPT-4.1 nano — with a specific focus on coding capabilities. It’s accessible via the OpenAI API but not ChatGPT. In the competition to develop advanced programming models, GPT-4.1 will rival AI models such as Google’s Gemini 2.5 Pro, Anthropic’s Claude 3.7 Sonnet, and DeepSeek’s upgraded V3.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-will-discontinue-chatgpt-s-gpt-4-at-the-end-of-april"&gt;&lt;strong&gt;OpenAI will discontinue ChatGPT’s GPT-4 at the end of April&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to sunset GPT-4, an AI model introduced more than two years ago, and replace it with GPT-4o, the current default model, per changelog. It will take effect on April 30. GPT-4 will remain available via OpenAI’s API.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-could-release-gpt-4-1-soon"&gt;OpenAI could release GPT-4.1 soon&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI may launch several new AI models, including GPT-4.1, soon, The Verge reported, citing anonymous sources. GPT-4.1 would be an update of OpenAI’s GPT-4o, which was released last year. On the list of upcoming models are GPT-4.1 and smaller versions like GPT-4.1 mini and nano, per the report.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-updated-chatgpt-to-use-information-from-your-previous-conversations"&gt;&lt;strong&gt;OpenAI has updated ChatGPT to use information from your previous conversations&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI started updating ChatGPT to enable the chatbot to remember previous conversations with a user and customize its responses based on that context. This feature is rolling out to ChatGPT Pro and Plus users first, excluding those in the U.K., EU, Iceland, Liechtenstein, Norway, and Switzerland.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-working-on-watermarks-for-images-made-with-chatgpt"&gt;&lt;strong&gt;OpenAI is working on watermarks for images made with ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;It looks like OpenAI is working on a watermarking feature for images generated using GPT-4o. AI researcher Tibor Blaho spotted a new “ImageGen” watermark feature in the new beta of ChatGPT’s Android app. Blaho also found mentions of other tools: “Structured Thoughts,” “Reasoning Recap,” “CoT Search Tool,” and “l1239dk1.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-offers-chatgpt-plus-for-free-to-u-s-canadian-college-students"&gt;OpenAI offers ChatGPT Plus for free to U.S., Canadian college students&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is offering its $20-per-month ChatGPT Plus subscription tier for free to all college students in the U.S. and Canada through the end of May. The offer will let millions of students use OpenAI’s premium service, which offers access to the company’s GPT-4o model, image generation, voice interaction, and research tools that are not available in the free version.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-users-have-generated-over-700m-images-nbsp-so-far"&gt;ChatGPT users have generated over 700M images&amp;nbsp;so far&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;More than 130 million users have created over 700 million images since ChatGPT got the upgraded image generator on March 25, according to COO of OpenAI Brad Lightcap. The image generator was made available  to all ChatGPT users on March 31, and went viral for being able to create Ghibli-style photos.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-o3-model-could-cost-more-to-run-than-initial-estimate"&gt;OpenAI’s o3 model could cost more to run than initial estimate&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The Arc Prize Foundation, which develops the AI benchmark tool ARC-AGI, has updated the estimated computing costs for OpenAI’s o3 “reasoning” model managed by ARC-AGI. The organization originally estimated that the best-performing configuration of o3 it tested, o3 high, would cost approximately $3,000 to address a single problem. The Foundation now thinks the cost could be much higher, possibly around $30,000 per task.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-ceo-says-capacity-issues-will-cause-product-delays"&gt;OpenAI CEO says capacity issues will cause product delays&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;In a series of posts on X, OpenAI CEO Sam Altman said the company’s new image-generation tool’s popularity may cause product releases to be delayed. “We are getting things under control, but you should expect new releases from OpenAI to be delayed, stuff to break, and for service to sometimes be slow as we deal with capacity challenges,” he wrote. &lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-march-2025"&gt;March 2025&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-plans-to-release-a-new-open-ai-language-model"&gt;OpenAI plans to release a new ‘open’ AI language model&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpeanAI intends to release its “first” open language model since GPT-2 “in the coming months.” The company plans to host developer events to gather feedback and eventually showcase prototypes of the model. The first developer event is to be held in San Francisco, with sessions to follow in Europe and Asia.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-removes-chatgpt-s-restrictions-on-image-generation"&gt;OpenAI removes ChatGPT’s restrictions on image generation&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI made a notable change to its content moderation policies after the success of its new image generator in ChatGPT, which went viral for being able to create Studio Ghibli-style images. The company has updated its policies to allow ChatGPT to generate images of public figures, hateful symbols, and racial features when requested. OpenAI had previously declined such prompts due to the potential controversy or harm they may cause. However, the company has now “evolved” its approach, as stated in a blog post published by Joanne Jang, the lead for OpenAI’s model behavior.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-adopts-anthropic-s-standard-for-linking-ai-models-with-data"&gt;OpenAI adopts Anthropic’s standard for linking AI models with data&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI wants to incorporate Anthropic’s Model Context Protocol (MCP) into all of its products, including the ChatGPT desktop app. MCP, an open-source standard, helps AI models generate more accurate and suitable responses to specific queries, and lets developers create bidirectional links between data sources and AI applications like chatbots. The protocol is currently available in the Agents SDK, and support for the ChatGPT desktop app and Responses API will be coming soon, OpenAI CEO Sam Altman said. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-viral-studio-ghibli-style-images-could-raise-ai-copyright-concerns"&gt;OpenAI’s viral Studio Ghibli-style images could raise AI copyright concerns&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The latest update of the image generator on OpenAI’s ChatGPT has triggered a flood of AI-generated memes in the style of Studio Ghibli, the Japanese animation studio behind blockbuster films like “My Neighbor Totoro” and “Spirited Away.” The burgeoning mass of Ghibli-esque images have sparked concerns about whether OpenAI has violated copyright laws, especially since the company is already facing legal action for using source material without authorization. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-expects-revenue-to-triple-to-12-7-billion-this-year"&gt;OpenAI expects revenue to triple to $12.7 billion this year&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI expects its revenue to triple to $12.7 billion in 2025, fueled by the performance of its paid AI software, Bloomberg reported, citing an anonymous source. While the startup doesn’t expect to reach positive cash flow until 2029, it expects revenue to increase significantly in 2026 to surpass $29.4 billion, the report said. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-has-upgraded-its-image-generation-feature"&gt;ChatGPT has upgraded its image-generation feature&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI on Tuesday rolled out a major upgrade to ChatGPT’s image-generation capabilities: ChatGPT can now use the GPT-4o model to generate and edit images and photos directly. The feature went live earlier this week in ChatGPT and Sora, OpenAI’s AI video-generation tool, for subscribers of the company’s Pro plan, priced at $200 a month, and will be available soon to ChatGPT Plus subscribers and developers using the company’s API service. The company’s CEO Sam Altman said on Wednesday, however, that the release of the image generation feature to free users would be delayed due to higher demand than the company expected.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-announces-leadership-updates"&gt;OpenAI announces leadership updates&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Brad Lightcap, OpenAI’s chief operating officer, will lead the company’s global expansion and manage corporate partnerships as CEO Sam Altman shifts his focus to research and products, according to a blog post from OpenAI. Lightcap, who previously worked with Altman at Y Combinator, joined the Microsoft-backed startup in 2018. OpenAI also said Mark Chen would step into the expanded role of chief research officer, and Julia Villagra will take on the role of chief people officer.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-ai-voice-assistant-now-has-advanced-feature"&gt;OpenAI’s AI voice assistant now has advanced feature&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has updated its AI voice assistant with improved chatting capabilities, according to a video posted on Monday (March 24) to the company’s official media channels. The update enables real-time conversations, and the AI assistant is said to be more personable and interrupts users less often. Users on ChatGPT’s free tier can now access the new version of Advanced Voice Mode, while paying users will receive answers that are “more direct, engaging, concise, specific, and creative,” a spokesperson from OpenAI told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-meta-in-talks-with-reliance-in-india"&gt;&lt;strong&gt;OpenAI, Meta in talks with Reliance in India&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI and Meta have separately engaged in discussions with Indian conglomerate Reliance Industries regarding potential collaborations to enhance their AI services in the country, per a report by The Information. One key topic being discussed is Reliance Jio distributing OpenAI’s ChatGPT. Reliance has proposed selling OpenAI’s models to businesses in India through an application programming interface (API) so they can incorporate AI into their operations. Meta also plans to bolster its presence in India by constructing a large 3GW data center in Jamnagar, Gujarat. OpenAI, Meta, and Reliance have not yet officially announced these plans.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-faces-privacy-complaint-in-europe-for-chatbot-s-defamatory-hallucinations"&gt;OpenAI faces privacy complaint in Europe for chatbot’s defamatory hallucinations&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Noyb, a privacy rights advocacy group, is supporting an individual in Norway who was shocked to discover that ChatGPT was providing false information about him, stating that he had been found guilty of killing two of his children and trying to harm the third. “The GDPR is clear. Personal data has to be accurate,” said Joakim Söderberg, data protection lawyer at&amp;nbsp;Noyb, in a statement. “If it’s not, users have the right to have it changed to reflect the truth. Showing ChatGPT users a tiny disclaimer that the chatbot can make mistakes clearly isn’t enough. You can’t just spread false information and in the end add a small disclaimer saying that everything you said may just not be true.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-upgrades-its-transcription-and-voice-generating-ai-models"&gt;OpenAI upgrades its transcription and voice-generating AI models&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has added new transcription and voice-generating AI models to its APIs: a text-to-speech model, “gpt-4o-mini-tts,” that delivers more nuanced and realistic sounding speech, as well as two speech-to-text models called “gpt-4o-transcribe” and “gpt-4o-mini-transcribe”. The company claims they are improved versions of what was already there and that they hallucinate less.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-launched-o1-pro-a-more-powerful-version-of-its-o1"&gt;OpenAI has launched o1-pro, a more powerful version of its o1&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced o1-pro in its developer API. OpenAI says its o1-pro uses more computing than its o1 “reasoning” AI model to deliver “consistently better responses.” It’s only accessible to select developers who have spent at least $5 on OpenAI API services. OpenAI charges $150 for every million tokens (about 750,000 words) input into the model and $600 for every million tokens the model produces. It costs twice as much as OpenAI’s GPT-4.5 for input and 10 times the price of regular o1.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-research-lead-noam-brown-thinks-ai-reasoning-models-could-ve-arrived-decades-ago"&gt;OpenAI research lead Noam Brown thinks AI “reasoning” models could’ve arrived decades ago&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Noam Brown, who heads AI reasoning research at OpenAI, thinks that certain types of AI models for “reasoning” could have been developed 20 years ago if researchers had understood the correct approach and algorithms.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-says-it-has-trained-an-ai-that-s-really-good-at-creative-writing"&gt;OpenAI says it has trained an AI that’s “really good” at creative writing&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman said, in a&amp;nbsp;post on X, that the company has trained a “new model” that’s “really good” at creative writing. He posted a lengthy sample from the model given the prompt “Please write a metafictional literary short story about AI and grief.” OpenAI has not extensively explored the use of AI for writing fiction. The company has mostly concentrated on challenges in rigid, predictable areas such as math and programming.&lt;em&gt;&amp;nbsp;&lt;/em&gt;And it turns out that it might not be that great at creative writing at all. &lt;/p&gt;







&lt;blockquote class="twitter-tweet wp-block-html"&gt;&lt;p dir="ltr" lang="en"&gt;we trained a new model that is good at creative writing (not sure yet how/when it will get released). this is the first time i have been really struck by something written by AI; it got the vibe of metafiction so right.&lt;/p&gt;&lt;p&gt;PROMPT:&lt;/p&gt;&lt;p&gt;Please write a metafictional literary short story…&lt;/p&gt;— Sam Altman (@sama) March 11, 2025&lt;/blockquote&gt; 

&lt;h4 class="wp-block-heading" id="h-openai-launches-new-tools-to-help-businesses-build-ai-agents"&gt;OpenAI launches new tools to help businesses build AI agents&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI rolled out new tools designed to help developers and businesses build AI agents — automated systems that can independently accomplish tasks — using the company’s own AI models and frameworks. The tools are part of OpenAI’s new Responses API, which enables enterprises to develop customized AI agents that can perform web searches, scan through company files, and navigate websites, similar to OpenAI’s Operator product. The Responses API effectively replaces OpenAI’s Assistants API, which the company plans to discontinue in the first half of 2026.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-reportedly-plans-to-charge-up-to-20-000-a-month-for-specialized-ai-agents"&gt;OpenAI reportedly plans to charge up to $20,000 a month for specialized AI ‘agents’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI intends to release several “agent” products tailored for different applications, including sorting and ranking sales leads and software engineering, according to a report from The Information. One, a “high-income knowledge worker” agent, will reportedly be priced at $2,000 a month. Another, a software developer agent, is said to cost $10,000 a month. The most expensive rumored agents, which are said to be aimed at supporting “PhD-level research,” are expected to cost $20,000 per month. The jaw-dropping figure is indicative of how much cash OpenAI needs right now: The company lost roughly $5 billion last year after paying for costs related to running its services and other expenses. It’s unclear when these agentic tools might launch or which customers will be eligible to buy them.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-can-directly-edit-your-code"&gt;&lt;strong&gt;ChatGPT can directly edit your code&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The latest version of the macOS ChatGPT app allows users to edit code directly in supported developer tools, including Xcode, VS Code, and JetBrains. ChatGPT Plus, Pro, and Team subscribers can use the feature now, and the company plans to roll it out to more users like Enterprise, Edu, and free users.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-weekly-active-users-doubled-in-less-than-6-months-thanks-to-new-releases"&gt;ChatGPT’s weekly active users doubled in less than 6 months, thanks to new releases&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;According to a new report from VC firm Andreessen Horowitz (a16z), OpenAI’s AI chatbot, ChatGPT, experienced solid growth in the second half of 2024. It took ChatGPT nine months to increase its weekly active users from 100 million in November 2023 to 200 million in August 2024, but it only took less than six months to double that number once more, according to the report. ChatGPT’s weekly active users increased to 300 million by December 2024 and 400 million by February 2025. ChatGPT has experienced significant growth recently due to the launch of new models and features, such as GPT-4o, with multimodal capabilities. ChatGPT usage spiked from April to May 2024, shortly after that model’s launch.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-february-2025"&gt;February 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-cancels-its-o3-ai-model-in-favor-of-a-unified-next-gen-release"&gt;OpenAI cancels its o3 AI model in favor of a ‘unified’ next-gen release&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has effectively canceled the release of o3 in favor of what CEO Sam Altman is calling a “simplified” product offering. In a post on X, Altman said that, in the coming months, OpenAI will release a model called GPT-5 that “integrates a lot of [OpenAI’s] technology,” including o3, in ChatGPT and its API. As a result of that roadmap decision, OpenAI no longer plans to release o3 as a standalone model.&amp;nbsp;&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-may-not-be-as-power-hungry-as-once-assumed"&gt;ChatGPT may not be as power-hungry as once assumed&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A commonly cited stat is that ChatGPT requires around 3 watt-hours of power to answer a single question. Using OpenAI’s latest default model for ChatGPT, GPT-4o, as a reference, nonprofit AI research institute Epoch AI found the average ChatGPT query consumes around 0.3 watt-hours. However, the analysis doesn’t consider the additional energy costs incurred by ChatGPT with features like image generation or input processing.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-now-reveals-more-of-its-o3-mini-model-s-thought-process"&gt;OpenAI now reveals more of its o3-mini model’s thought process&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;In response to pressure from rivals like DeepSeek, OpenAI is changing the way its o3-mini model communicates its step-by-step “thought” process. ChatGPT users will see an updated “chain of thought” that shows more of the model’s “reasoning” steps and how it arrived at answers to questions.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-you-can-now-use-chatgpt-web-search-without-logging-in"&gt;You can now use ChatGPT web search without logging in&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is now allowing anyone to use ChatGPT web search without having to log in. While OpenAI had previously allowed users to ask ChatGPT questions without signing in, responses were restricted to the chatbot’s last training update. This only applies through ChatGPT.com, however. To use ChatGPT in any form through the native mobile app, you will still need to be logged in.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-a-new-chatgpt-agent-for-deep-research"&gt;OpenAI unveils a new ChatGPT agent for ‘deep research’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI announced a new AI “agent” called deep research that’s designed to help people conduct in-depth, complex research using ChatGPT. OpenAI says the “agent” is intended for instances where you don’t just want a quick answer or summary, but instead need to assiduously consider information from multiple websites and other sources.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-january-2025"&gt;&lt;strong&gt;January 2025&lt;/strong&gt;&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-used-a-subreddit-to-test-ai-persuasion"&gt;OpenAI used a subreddit to test AI persuasion&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI used the subreddit r/ChangeMyView to measure the persuasive abilities of its AI reasoning models. OpenAI says it collects user posts from the subreddit and asks its AI models to write replies, in a closed environment, that would change the Reddit user’s mind on a subject. The company then shows the responses to testers, who assess how persuasive the argument is, and finally OpenAI compares the AI models’ responses to human replies for that same post.&amp;nbsp;&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-o3-mini-its-latest-reasoning-model"&gt;OpenAI launches o3-mini, its latest ‘reasoning’ model&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched a new AI “reasoning” model, o3-mini, the newest in the company’s o family of models. OpenAI first previewed the model in December alongside a more capable system called o3. OpenAI is pitching its new model as both “powerful” and “affordable.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-mobile-users-are-85-male-report-says"&gt;ChatGPT’s mobile users are 85% male, report says&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A new report from app analytics firm Appfigures found that over half of ChatGPT’s mobile users are under age 25, with users between ages 50 and 64 making up the second largest age demographic. The gender gap among ChatGPT users is even more significant. Appfigures estimates that across age groups, men make up 84.5% of all users.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-chatgpt-plan-for-us-government-agencies"&gt;OpenAI launches ChatGPT plan for US government agencies&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched ChatGPT Gov designed to provide U.S. government agencies an additional way to access the tech. ChatGPT Gov includes many of the capabilities found in OpenAI’s corporate-focused tier, ChatGPT Enterprise. OpenAI says that ChatGPT Gov enables agencies to more easily manage their own security, privacy, and compliance, and could expedite internal authorization of OpenAI’s tools for the handling of non-public sensitive data.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-more-teens-report-using-chatgpt-for-schoolwork-despite-the-tech-s-faults"&gt;More teens report using ChatGPT for schoolwork, despite the tech’s faults&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Younger Gen Zers are embracing ChatGPT, for schoolwork, according to a new survey by the Pew Research Center. In a follow-up to its 2023 poll on ChatGPT usage among young people, Pew asked ~1,400 U.S.-based teens ages 13 to 17 whether they’ve used ChatGPT for homework or other school-related assignments. Twenty-six percent said that they had, double the number two years ago. Just over half of teens responding to the poll said they think it’s acceptable to use ChatGPT for researching new subjects. But considering the ways ChatGPT can fall short, the results are possibly cause for alarm.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-says-it-may-store-deleted-operator-data-for-up-to-90-days"&gt;OpenAI says it may store deleted Operator data for up to 90 days&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says that it might store chats and associated screenshots from customers who use Operator, the company’s AI “agent” tool, for up to 90 days — even after a user manually deletes them. While OpenAI has a similar deleted data retention policy for ChatGPT, the retention period for ChatGPT is only 30 days, which is 60 days shorter than Operator’s.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-operator-an-ai-agent-that-performs-tasks-autonomously"&gt;OpenAI launches Operator, an AI agent that performs tasks autonomously&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is launching a research preview of Operator, a general-purpose AI agent that can take control of a web browser and independently perform certain actions. Operator promises to automate tasks such as booking travel accommodations, making restaurant reservations, and shopping online.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-may-preview-its-agent-tool-for-users-on-the-200-per-month-pro-plan"&gt;OpenAI may preview its agent tool for users on the $200-per-month Pro plan&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Operator, OpenAI’s agent tool, could be released sooner rather than later. Changes to ChatGPT’s code base suggest that Operator will be available as an early research preview to users on the $200 Pro subscription plan. The changes aren’t yet publicly visible, but a user on X who goes by Choi spotted these updates in ChatGPT’s client-side code. TechCrunch separately identified the same references to Operator on OpenAI’s website.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-tests-phone-number-only-chatgpt-signups"&gt;OpenAI tests phone number-only ChatGPT signups&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has begun testing a feature that lets new ChatGPT users sign up with only a phone number — no email required. The feature is currently in beta in the U.S. and India. However, users who create an account using their number can’t upgrade to one of OpenAI’s paid plans without verifying their account via an email. Multi-factor authentication also isn’t supported without a valid email.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-now-lets-you-schedule-reminders-and-recurring-tasks"&gt;ChatGPT now lets you schedule reminders and recurring tasks&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT’s new beta feature, called tasks, allows users to set simple reminders. For example, you can ask ChatGPT to remind you when your passport expires in six months, and the AI assistant will follow up with a push notification on whatever platform you have tasks enabled. The feature will start rolling out to ChatGPT Plus, Team, and Pro users around the globe this week.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-new-chatgpt-feature-lets-users-assign-it-traits-like-chatty-and-gen-z"&gt;New ChatGPT feature lets users assign it traits like ‘chatty’ and ‘Gen Z’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is introducing a new way for users to customize their interactions with ChatGPT. Some users found they can specify a preferred name or nickname and “traits” they’d like the chatbot to have. OpenAI suggests traits like “Chatty,” “Encouraging,” and “Gen Z.” However, some users reported that the new options have disappeared, so it’s possible they went live prematurely.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-faqs"&gt;FAQs:&lt;/h3&gt;

&lt;h4 class="wp-block-heading"&gt;What is ChatGPT? How does it work?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is a general-purpose chatbot that uses artificial intelligence to generate text after a user enters a prompt, developed by tech startup OpenAI. The chatbot uses GPT-4, a large language model that uses deep learning to produce human-like text.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;When did ChatGPT get released?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;November 30, 2022 is when ChatGPT was released for public use.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What is the latest version of ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Both the free version of ChatGPT and the paid ChatGPT Plus are regularly updated with new GPT models. The most recent model is GPT-4o.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can I use ChatGPT for free?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;There is a free version of ChatGPT that only requires a sign-in in addition to the paid version, ChatGPT Plus.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Who uses ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Anyone can use ChatGPT! More and more tech companies and search engines are utilizing the chatbot to automate text or quickly answer user questions/concerns.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What companies use ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Multiple enterprises utilize ChatGPT, although others may limit the use of the AI-powered tool.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Most recently, Microsoft announced at its 2023 Build conference that it is integrating its ChatGPT-based Bing experience into Windows 11. A Brooklyn-based 3D display startup Looking Glass utilizes ChatGPT to produce holograms you can communicate with by using ChatGPT.&amp;nbsp; And nonprofit organization Solana officially integrated the chatbot into its network with a ChatGPT plug-in geared toward end users to help onboard into the web3 space.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What does GPT mean in ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;GPT stands for Generative Pre-Trained Transformer.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What is the difference between ChatGPT and a chatbot?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A chatbot can be any software/system that holds dialogue with you/a person but doesn’t necessarily have to be AI-powered. For example, there are chatbots that are rules-based in the sense that they’ll give canned responses to questions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is AI-powered and utilizes LLM technology to generate text after a prompt.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can ChatGPT write essays?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Yes.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can ChatGPT commit libel?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Due to the nature of how these models work, they don’t know or care whether something is true, only that it looks true. That’s a problem when you’re using it to do your homework, sure, but when it accuses you of a crime you didn’t commit, that may well at this point be libel.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We will see how handling troubling statements produced by ChatGPT will play out over the next few months as tech and legal experts attempt to tackle the fastest moving target in the industry.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Does ChatGPT have an app?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes, there is a free ChatGPT mobile app for iOS and Android users.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What is the ChatGPT character limit?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;It’s not documented anywhere that ChatGPT has a character limit. However, users have noted that there are some character limitations after around 500 words.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Does ChatGPT have an API?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes, it was released March 1, 2023.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What are some sample everyday uses for ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Everyday examples include programming, scripts, email replies, listicles, blog ideas, summarization, etc.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What are some advanced uses for ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Advanced use examples include debugging code, programming languages, scientific concepts, complex problem solving, etc.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;How good is ChatGPT at writing code?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;It depends on the nature of the program. While ChatGPT can write workable Python code, it can’t necessarily program an entire app’s worth of code. That’s because ChatGPT lacks context awareness — in other words, the generated code isn’t always appropriate for the specific context in which it’s being used.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Can you save a ChatGPT chat?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. OpenAI allows users to save chats in the ChatGPT interface, stored in the sidebar of the screen. There are no built-in sharing features yet.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are there alternatives to ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. There are multiple AI-powered chatbot competitors such as Together, Google’s Gemini and Anthropic’s Claude, and developers are creating open source alternatives.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;How does ChatGPT handle data privacy?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has&amp;nbsp;said&amp;nbsp;that individuals in “certain jurisdictions” (such as the EU) can object to the processing of their personal information by its AI models by filling out&amp;nbsp;this form. This includes the ability to make requests for deletion of AI-generated references about you. Although OpenAI notes it may not grant every request since it must balance privacy requests against freedom of expression “in accordance with applicable laws”.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The web form for making a deletion of data about you request is entitled “OpenAI Personal Data Removal Request”.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its privacy policy, the ChatGPT maker makes a passing acknowledgement of the objection requirements attached to relying on “legitimate interest” (LI), pointing users towards more information about requesting an opt out — when it writes: “See here&amp;nbsp;for instructions on how you can opt out of our use of your information to train our models.”&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What controversies have surrounded ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Recently, Discord announced that it had integrated OpenAI’s technology into its bot named Clyde where two users tricked Clyde into providing them with instructions for making the illegal drug methamphetamine (meth) and the incendiary mixture napalm.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;An Australian mayor has publicly announced he may sue OpenAI for defamation due to ChatGPT’s false claims that he had served time in prison for bribery. This would be the first defamation lawsuit against the text-generating service.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CNET found itself in the midst of controversy after Futurism reported the publication was publishing articles under a mysterious byline completely generated by AI. The private equity company that owns CNET, Red Ventures, was accused of using ChatGPT for SEO farming, even if the information was incorrect.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Several major school systems and colleges, including New York City Public Schools, have banned ChatGPT from their networks and devices. They claim that the AI impedes the learning process by promoting plagiarism and misinformation, a claim that not every educator agrees with.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There have also been cases of ChatGPT accusing individuals of false crimes.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Where can I find examples of ChatGPT prompts?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Several marketplaces host and provide ChatGPT prompts, either for free or for a nominal fee. One is PromptBase. Another is ChatX. More launch every day.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Can ChatGPT be detected?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Poorly. Several tools claim to detect ChatGPT-generated text, but in our tests, they’re inconsistent at best.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are ChatGPT chats public?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;No. But OpenAI recently disclosed a bug, since fixed, that exposed the titles of some users’ conversations to other people on the service.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What lawsuits are there surrounding ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;None specifically targeting ChatGPT. But OpenAI is involved in at least one lawsuit that has implications for AI systems trained on publicly available data, which would touch on ChatGPT.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are there issues regarding plagiarism with ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. Text-generating AI models like ChatGPT have a tendency to regurgitate content from their training data.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story is continually updated with new information.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2191707579.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT, OpenAI’s text-generating AI chatbot, has taken the world by storm since its launch in November 2022. What started as a tool to supercharge productivity through writing essays and code with short text prompts has evolved into a behemoth with 300 million weekly active users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;2024 was a big year for OpenAI, from its partnership with Apple for its generative AI offering, Apple Intelligence, the release of GPT-4o with voice capabilities, and the highly-anticipated launch of its text-to-video model Sora.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI also faced its share of internal drama, including the notable exits of high-level execs like co-founder and longtime chief scientist Ilya Sutskever and CTO Mira Murati. OpenAI has also been hit with lawsuits from Alden Global Capital-owned newspapers alleging copyright infringement, as well as an injunction from Elon Musk to halt OpenAI’s transition to a for-profit. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In 2025, OpenAI is battling the perception that it’s ceding ground in the AI race to Chinese rivals like DeepSeek. The company has been trying to shore up its relationship with Washington as it simultaneously pursues an ambitious data center project, and as it reportedly lays the groundwork for one of the largest funding rounds in history.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Below, you’ll find a timeline of ChatGPT product updates and releases, starting with the latest, which we’ve been updating throughout the year. If you have any other questions, check out our ChatGPT FAQ here.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To see a list of 2024 updates, go here.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-timeline-of-the-most-recent-chatgpt-updates"&gt;Timeline of the most recent ChatGPT updates&lt;/h2&gt;




&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h3 class="wp-block-heading" id="h-august-2025"&gt;August 2025&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-keeps-multiple-gpt-models-despite-gpt-5-launch"&gt;&lt;strong&gt;OpenAI keeps multiple GPT models despite GPT-5 launch&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Despite unveiling GPT-5 as a “one-size-fits-all” AI, OpenAI is still offering several legacy AI options, including GPT-4o, GPT-4.1, and o3. Users can choose between new “Auto,” “Fast,” and “Thinking” modes for GPT-5, and paid subscribers regain access to legacy models like GPT-4o and GPT-4.1.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Updates to ChatGPT:&lt;/p&gt;&lt;p&gt;You can now choose between “Auto”, “Fast”, and “Thinking” for GPT-5. Most users will want Auto, but the additional control will be useful for some people.&lt;/p&gt;&lt;p&gt;Rate limits are now 3,000 messages/week with GPT-5 Thinking, and then extra capacity on GPT-5 Thinking…&lt;/p&gt;— Sam Altman (@sama) August 13, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-sam-altman-addresses-gpt-5-glitches-and-chart-crime-during-reddit-ama"&gt;&lt;strong&gt;Sam Altman addresses GPT-5 glitches and “chart crime” during Reddit AMA&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman told Reddit users that GPT-5’s “dumber” behavior at launch was due to a router issue and promised fixes, double rate limits for Plus users, and transparency on which model is answering, while also shrugging off the infamous “chart crime” from the live presentation.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-gpt-5-a-smarter-task-ready-chatgpt"&gt;&lt;strong&gt;OpenAI unveils GPT-5, a smarter, task-ready ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI released GPT-5, a next-gen AI that’s not just smarter but more useful — able to handle tasks like coding apps, managing calendars, and creating research briefs — while automatically figuring out the fastest or most thoughtful way to answer your questions. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-offers-chatgpt-enterprise-to-federal-agencies-for-just-1"&gt;&lt;strong&gt;OpenAI offers ChatGPT Enterprise to federal agencies for just $1&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is making a major push into federal government workflows, offering ChatGPT Enterprise to agencies for just $1 for the next year. The move comes after the U.S. General Services Administration (GSA) added OpenAI, Google, and Anthropic to its approved AI vendor list, allowing agencies to access these tools through preset contracts without negotiating pricing.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-returns-to-open-source-with-new-ai-models"&gt;&lt;strong&gt;OpenAI returns to open source with new AI models&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI unveiled its first open source language models since GPT-2, introducing two new open-weight AI releases: gpt-oss-120b, a high-performance model capable of running on a single Nvidia GPU, and gpt-oss-20b, a lighter model optimized for laptop use. The move comes amid growing competition in the global AI market and a push for more open technology in the U.S. and abroad.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-nears-700m-weekly-users-quadruples-growth-in-a-year"&gt;&lt;strong&gt;ChatGPT nears 700M weekly users, quadruples growth in a year&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT’s rapid growth is accelerating. OpenAI said the chatbot was on track to hit 700 million weekly active users in the first week of August, up from 500 million at the end of March. Nick Turley, OpenAI’s VP and head of the ChatGPT app, highlighted the app’s growth on X, noting it has quadrupled in size over the past year.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;This week, ChatGPT is on track to reach 700M weekly active users — up from 500M at the end of March and 4× since last year. Every day, people and teams are learning, creating, and solving harder problems. Big week ahead. Grateful to the team for making ChatGPT more useful and…&lt;/p&gt;— Nick Turley (@nickaturley) August 4, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="july2025"&gt;July 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-now-has-study-mode"&gt;ChatGPT now has study mode&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI unveiled Study Mode, a new ChatGPT feature designed to promote critical thinking by prompting students to engage with material rather than simply receive answers. The tool is now rolling out to Free, Plus, Pro, and Team users, with availability for Edu subscribers expected in the coming weeks.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-altman-warns-that-chatgpt-therapy-isn-t-confidential"&gt;Altman warns that ChatGPT therapy isn’t confidential&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT users should be cautious when seeking emotional support from AI, as the AI industry lacks safeguards for sensitive conversations, OpenAI CEO Sam Altman said on a recent episode of This Past Weekend w/ Theo Von. Unlike human therapists, AI tools aren’t bound by doctor-patient confidentiality, he noted.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-hits-2-5b-prompts-daily"&gt;ChatGPT hits 2.5B prompts daily&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT now receives 2.5 billion prompts daily from users worldwide, including roughly 330 million from the U.S. That’s more than double the volume reported by CEO Sam Altman just eight months ago, highlighting the chatbot’s explosive growth.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-a-general-purpose-agent-in-chatgpt"&gt;OpenAI launches a general-purpose agent in ChatGPT&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced ChatGPT Agent, which completes a wide variety of computer-based tasks on behalf of users and combines several capabilities like Operator and Deep Research, according to the company. OpenAI says the agent can automatically navigate a user’s calendar, draft editable presentations and slideshows, run code, shop online, and handle complex workflows from end to end, all within a secure virtual environment.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-study-warns-of-major-risks-with-ai-therapy-chatbots"&gt;Study warns of major risks with AI therapy chatbots&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Researchers at Stanford University have observed that therapy chatbots powered by large language models can sometimes stigmatize people with mental health conditions or respond in ways that are inappropriate or could be harmful. While chatbots are “being used as companions, confidants, and therapists,” the study found “significant risks.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-delays-releasing-its-open-model-again"&gt;OpenAI delays releasing its open model again&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;CEO Sam Altman said that the company is delaying the release of its open model, which had already been postponed by a month earlier this summer. The ChatGPT maker, which initially planned to release the model around mid-July, has indefinitely postponed its launch to conduct additional safety testing.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;we planned to launch our open-weight model next week.&lt;/p&gt;&lt;p&gt;we are delaying it; we need time to run additional safety tests and review high-risk areas. we are not yet sure how long it will take us.&lt;/p&gt;&lt;p&gt;while we trust the community will build great things with this model, once weights are…&lt;/p&gt;— Sam Altman (@sama) July 12, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-reportedly-releasing-an-ai-browser-in-the-coming-weeks"&gt;&lt;strong&gt;OpenAI is reportedly releasing an AI browser in the coming weeks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to release an AI-powered web browser to challenge Alphabet’s Google Chrome. It will keep some user interactions within ChatGPT, rather than directing people to external websites.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-is-testing-a-mysterious-new-feature-called-study-together"&gt;ChatGPT is testing a mysterious new feature called “study together”&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Some ChatGPT users have noticed a new feature called “Study Together” appearing in their list of available tools. This is the chatbot’s approach to becoming a more effective educational tool, rather than simply providing answers to prompts. Some people also wonder whether there will be a feature that allows multiple users to join the chat, similar to a study group.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-referrals-from-chatgpt-to-news-sites-are-rising-but-not-enough-to-offset-search-declines"&gt;Referrals from ChatGPT to news sites are rising but not enough to offset search declines&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Referrals from ChatGPT to news publishers are increasing. But this rise is insufficient to offset the decline in clicks as more users now obtain their news directly from AI or AI-powered search results, according to a report by digital market intelligence company Similarweb. Since Google launched its AI Overviews in May 2024, the percentage of news searches that don’t lead to clicks on news websites has increased from 56% to nearly 69% by May 2025.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="june2025"&gt;June 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-uses-google-s-ai-chips-to-power-its-products"&gt;&lt;strong&gt;OpenAI uses Google’s AI chips to power its products&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has started using Google’s AI chips to power ChatGPT and other products, as reported by Reuters. The ChatGPT maker is one of the biggest buyers of Nvidia’s GPUs, using the AI chips to train models, and this is the first time that OpenAI is using &lt;em&gt;non&lt;/em&gt;-Nvidia chips in an important way.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-a-new-mit-study-suggests-that-chatgpt-might-be-harming-critical-thinking-skills"&gt;&lt;strong&gt;A new MIT study suggests that ChatGPT might be harming critical thinking skills&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Researchers from MIT’s Media Lab monitored the brain activity of writers in 32 regions. They found that ChatGPT users showed minimal brain engagement and consistently fell short in neural, linguistic, and behavioral aspects. To conduct the test, the lab split 54 participants from the Boston area into three groups, each consisting of individuals ages 18 to 39. The participants were asked to write multiple SAT essays using tools such as OpenAI’s ChatGPT, the Google search engine, or without any tools.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-was-downloaded-30-million-times-last-month"&gt;ChatGPT was downloaded 30 million times last month&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The ChatGPT app for iOS was downloaded 29.6 million times in the last 28 days, while TikTok, Facebook, Instagram, and X were downloaded a total of 32.9 million times during the same period, representing a difference of about 10.6%, according to ZDNET report citing Similarweb’s X post.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-the-energy-needed-for-an-average-chatgpt-query-can-power-a-lightbulb-for-a-couple-of-minutes"&gt;The energy needed for an average ChatGPT query can power a lightbulb for a couple of minutes&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Altman said that the average ChatGPT query uses about one-fifteenth of a teaspoon of water, equivalent to 0.000083 gallons of water, or the energy required to power a lightbulb for a few minutes, per Business Insider. In addition to that, the chatbot requires 0.34 watt-hours of electricity to operate.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-launched-o3-pro-an-upgraded-version-of-its-o3-ai-reasoning-model"&gt;&lt;strong&gt;OpenAI has launched o3-pro, an upgraded version of its o3 AI reasoning model&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has unveiled o3-pro, an enhanced version of its o3, a reasoning model that the chatGPT maker launched earlier this year. O3-pro is available for ChatGPT and Team users and in the API, while Enterprise and Edu users will get access in the third week of June.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;OpenAI o3-pro is available in the model picker for Pro and Team users starting today, replacing OpenAI o1-pro.&lt;/p&gt;&lt;p&gt;Enterprise and Edu users will get access the week after.&lt;/p&gt;&lt;p&gt;As o3-pro uses the same underlying model as o3, full safety details can be found in the o3 system card.…&lt;/p&gt;— OpenAI (@OpenAI) June 10, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-conversational-voice-mode-has-been-upgraded"&gt;ChatGPT’s conversational voice mode has been upgraded&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI upgraded ChatGPT’s conversational voice mood for all paid users across different markets and platforms. The startup has launched an update to Advanced Voice that enables users to converse with ChatGPT out loud in a more natural and fluid sound. The feature also helps users translate languages more easily, the comapny said.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-has-added-new-features-like-meeting-recording-and-connectors-for-google-drive-box-and-more"&gt;&lt;strong&gt;ChatGPT has added new features like meeting recording and connectors for Google Drive, Box, and more&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s ChatGPT now offers new funtions for business users, including integrations with various cloud services, meeting recordings, and MCP connection support for connecting to tools for in-depth research. The feature enables ChatGPT to retrieve information across users’ own services to answer their questions. For instance, an analyst could use the company’s slide deck and documents to develop an investment thesis.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-may-2025"&gt;May 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-cfo-says-hardware-will-drive-chatgpt-s-growth"&gt;OpenAI CFO says hardware will drive ChatGPT’s growth&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to purchase Jony Ive’s devices startup io for $6.4 billion. Sarah Friar, CFO of OpenAI, thinks that the hardware will significantly enhance ChatGPT and broaden OpenAI’s reach to a larger audience in the future.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-chatgpt-unveils-its-ai-coding-agent-codex"&gt;&lt;strong&gt;OpenAI’s ChatGPT unveils its AI coding agent, Codex&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced its AI coding agent, Codex, powered by codex-1, a version of its o3 AI reasoning model designed for software engineering tasks. OpenAI says codex-1 generates more precise and “cleaner” code than o3. The coding agent may take anywhere from one to 30 minutes to complete tasks such as writing simple features, fixing bugs, answering questions about your codebase, and running tests.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-sam-altman-aims-to-make-chatgpt-more-personalized-by-tracking-every-aspect-of-a-person-s-life"&gt;&lt;strong&gt;Sam Altman aims to make ChatGPT more personalized by tracking every aspect of a person’s life&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Altman, the CEO of OpenAI, said during a recent AI event hosted by VC firm Sequoia that he wants ChatGPT to record and remember every detail of a person’s life when one attendee asked about how ChatGPT can become more personalized.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-releases-its-gpt-4-1-and-gpt-4-1-mini-ai-models-in-chatgpt"&gt;&lt;strong&gt;OpenAI releases its GPT-4.1 and GPT-4.1 mini AI models in ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said in a post on X that it has launched its GPT-4.1 and GPT4.1 mini AI models in ChagGPT.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
 &lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;By popular request, GPT-4.1 will be available directly in ChatGPT starting today.&lt;/p&gt;&lt;p&gt;GPT-4.1 is a specialized model that excels at coding tasks &amp;amp; instruction following. Because it’s faster, it’s a great alternative to OpenAI o3 &amp;amp; o4-mini for everyday coding needs.&lt;/p&gt;— OpenAI (@OpenAI) May 14, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-deep-research-now-connects-with-github-in-beta-to-answer-code-related-questions"&gt;&lt;strong&gt;ChatGPT deep research now connects with GitHub (in beta) to answer code-related questions&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched a new feature for ChatGPT deep research to analyze code repositories on GitHub. The ChatGPT deep research feature is in beta and lets developers connect with GitHub to ask questions about codebases and engineering documents. The connector will soon be available for ChatGPT Plus, Pro, and Team users, with support for Enterprise and Education coming shortly, per an OpenAI spokesperson.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-a-new-data-residency-program-in-asia"&gt;&lt;strong&gt;OpenAI launches a new data residency program in Asia&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;After introducing a data residency program in Europe in February, OpenAI has now launched a similar program in Asian countries including India, Japan, Singapore, and South Korea. The new program will be accessible to users of ChatGPT Enterprise, ChatGPT Edu, and API. It will help organizations in Asia meet their local data sovereignty requirements when using OpenAI’s products.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-to-introduce-a-program-to-grow-ai-infrastructure"&gt;&lt;strong&gt;OpenAI to introduce a program to grow AI infrastructure&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is unveiling a program called OpenAI for Countries, which aims to develop the necessary local infrastructure to serve international AI clients better. The AI startup will work with governments to assist with increasing data center capacity and customizing OpenAI’s products to meet specific language and local needs. OpenAI for Countries is part of efforts to support the company’s expansion of its AI data center Project Stargate to new locations outside the U.S., per Bloomberg.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-promises-to-make-changes-to-prevent-future-chatgpt-sycophancy"&gt;&lt;strong&gt;OpenAI promises to make changes to prevent future ChatGPT sycophancy&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has announced its plan to make changes to its procedures for updating the AI models that power ChatGPT, following an update that caused the platform to become overly sycophantic for many users.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-april-2025"&gt;April 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-clarifies-the-reason-chatgpt-became-overly-flattering-and-agreeable"&gt;&lt;strong&gt;OpenAI clarifies the reason ChatGPT became overly flattering and agreeable&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has released a post on the recent sycophancy issues with the default AI model powering ChatGPT, GPT-4o, leading the company to revert an update to the model released last week. CEO Sam Altman acknowledged the issue on Sunday and confirmed two days later that the GPT-4o update was being rolled back. OpenAI is working on “additional fixes” to the model’s personality. Over the weekend, users on social media criticized the new model for making ChatGPT too validating and agreeable. It became a popular meme fast.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-working-to-fix-a-bug-that-let-minors-engage-in-inappropriate-conversations"&gt;&lt;strong&gt;OpenAI is working to fix a “bug” that let minors engage in inappropriate conversations&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;An issue within OpenAI’s ChatGPT enabled the chatbot to create graphic erotic content for accounts registered by users under the age of 18, as demonstrated by TechCrunch’s testing, a fact later confirmed by OpenAI. “Protecting younger users is a top priority, and our Model Spec, which guides model behavior, clearly restricts sensitive content like erotica to narrow contexts such as scientific, historical, or news reporting,” a spokesperson told TechCrunch via email. “In this case, a bug allowed responses outside those guidelines, and we are actively deploying a fix to limit these generations.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-helps-users-by-giving-recommendations-showing-images-and-reviewing-products-for-online-shopping"&gt;&lt;strong&gt;ChatGPT helps users by giving recommendations, showing images, and reviewing products for online shopping&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has added a few features to its ChatGPT search, its web search tool in ChatGPT, to give users an improved online shopping experience. The company says people can ask super-specific questions using natural language and receive customized results. The chatbot provides recommendations, images, and reviews of products in various categories such as fashion, beauty, home goods, and electronics.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-wants-its-ai-model-to-access-cloud-models-for-assistance"&gt;OpenAI wants its AI model to access cloud models for assistance&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI leaders have been talking about allowing the open model to link up with OpenAI’s cloud-hosted models to improve its ability to respond to intricate questions, two sources familiar with the situation told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-aims-to-make-its-new-open-ai-model-the-best-on-the-market"&gt;&lt;strong&gt;OpenAI aims to make its new “open” AI model the best on the market&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is preparing to launch an AI system that will be openly accessible, allowing users to download it for free without any API restrictions. Aidan Clark, OpenAI’s VP of research, is spearheading the development of the open model, which is in the very early stages, sources familiar with the situation told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-gpt-4-1-may-be-less-aligned-than-earlier-models"&gt;&lt;strong&gt;OpenAI’s GPT-4.1 may be less aligned than earlier models&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI released a new AI model called GPT-4.1 in mid-April. However, multiple independent tests indicate that the model is less reliable than previous OpenAI releases. The company&amp;nbsp;skipped that step — sending safety cards&amp;nbsp;for GPT-4.1 — claiming in a statement to TechCrunch that “GPT-4.1 is not a frontier model, so there won’t be a separate system card released for it.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-o3-ai-model-scored-lower-than-expected-on-a-benchmark"&gt;&lt;strong&gt;OpenAI’s o3 AI model scored lower than expected on a benchmark&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Questions have been raised regarding OpenAI’s transparency and procedures for testing models after a difference in benchmark outcomes was detected by first- and third-party benchmark results for the o3 AI model. OpenAI introduced o3 in December, stating that the model could solve approximately 25% of questions on FrontierMath, a difficult math problem set. Epoch AI, the research institute behind FrontierMath, discovered that o3 achieved a score of approximately 10%, which was significantly lower than OpenAI’s top-reported score.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-flex-processing-for-cheaper-slower-ai-tasks"&gt;&lt;strong&gt;OpenAI unveils Flex processing for cheaper, slower AI tasks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched a new API feature called Flex processing that allows users to use AI models at a lower cost but with slower response times and occasional resource unavailability. Flex processing is available in beta on the o3 and o4-mini reasoning models for non-production tasks like model evaluations, data enrichment, and asynchronous workloads.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-latest-ai-models-now-have-a-safeguard-against-biorisks"&gt;&lt;strong&gt;OpenAI’s latest AI models now have a safeguard against biorisks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has rolled out a new system to monitor its AI reasoning models, o3 and o4 mini, for biological and chemical threats. The system is designed to prevent models from giving advice that could potentially lead to harmful attacks, as stated in OpenAI’s safety report.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-its-latest-reasoning-models-o3-and-o4-mini"&gt;&lt;strong&gt;OpenAI launches its latest reasoning models, o3 and o4-mini&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has released two new reasoning models, o3 and o4 mini, just two days after launching GPT-4.1. The company claims o3 is the most advanced reasoning model it has developed, while o4-mini is said to provide a balance of price, speed, and performance. The new models stand out from previous reasoning models because they can use ChatGPT features like web browsing, coding, and image processing and generation. But they hallucinate more than several of OpenAI’s previous models.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-added-a-new-section-to-chatgpt-to-offer-easier-access-to-ai-generated-images-for-all-user-tiers"&gt;&lt;strong&gt;OpenAI has added a new section to ChatGPT to offer easier access to AI-generated images for all user tiers&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Open AI introduced a new section called “library” to make it easier for users to create images on mobile and web platforms, per the company’s X post.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-openai-could-adjust-its-safeguards-if-rivals-release-high-risk-ai"&gt;&lt;strong&gt;OpenAI could “adjust” its safeguards if rivals release “high-risk” AI&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said on Tuesday that it might revise its safety standards if “another frontier AI developer releases a high-risk system without comparable safeguards.” The move shows how commercial AI developers face more pressure to rapidly implement models due to the increased competition.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-building-its-own-social-media-network"&gt;&lt;strong&gt;OpenAI is building its own social media network&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is currently in the early stages of developing its own social media platform to compete with Elon Musk’s X and Mark Zuckerberg’s Instagram and Threads, according to The Verge. It is unclear whether OpenAI intends to launch the social network as a standalone application or incorporate it into ChatGPT.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-will-remove-its-largest-ai-model-gpt-4-5-from-the-api-in-july"&gt;OpenAI will remove its largest AI model, GPT-4.5, from the API, in July&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI will discontinue its largest AI model, GPT-4.5, from its API even though it was just launched in late February. GPT-4.5 will be available in a research preview for paying customers. Developers can use GPT-4.5 through OpenAI’s API until July 14; then, they will need to switch to GPT-4.1, which was released on April 14.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-gpt-4-1-ai-models-that-focus-on-coding-capabilities"&gt;OpenAI unveils GPT-4.1 AI models that focus on coding capabilities&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched three members of the GPT-4.1 model — GPT-4.1, GPT-4.1 mini, and GPT-4.1 nano — with a specific focus on coding capabilities. It’s accessible via the OpenAI API but not ChatGPT. In the competition to develop advanced programming models, GPT-4.1 will rival AI models such as Google’s Gemini 2.5 Pro, Anthropic’s Claude 3.7 Sonnet, and DeepSeek’s upgraded V3.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-will-discontinue-chatgpt-s-gpt-4-at-the-end-of-april"&gt;&lt;strong&gt;OpenAI will discontinue ChatGPT’s GPT-4 at the end of April&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to sunset GPT-4, an AI model introduced more than two years ago, and replace it with GPT-4o, the current default model, per changelog. It will take effect on April 30. GPT-4 will remain available via OpenAI’s API.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-could-release-gpt-4-1-soon"&gt;OpenAI could release GPT-4.1 soon&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI may launch several new AI models, including GPT-4.1, soon, The Verge reported, citing anonymous sources. GPT-4.1 would be an update of OpenAI’s GPT-4o, which was released last year. On the list of upcoming models are GPT-4.1 and smaller versions like GPT-4.1 mini and nano, per the report.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-updated-chatgpt-to-use-information-from-your-previous-conversations"&gt;&lt;strong&gt;OpenAI has updated ChatGPT to use information from your previous conversations&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI started updating ChatGPT to enable the chatbot to remember previous conversations with a user and customize its responses based on that context. This feature is rolling out to ChatGPT Pro and Plus users first, excluding those in the U.K., EU, Iceland, Liechtenstein, Norway, and Switzerland.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-working-on-watermarks-for-images-made-with-chatgpt"&gt;&lt;strong&gt;OpenAI is working on watermarks for images made with ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;It looks like OpenAI is working on a watermarking feature for images generated using GPT-4o. AI researcher Tibor Blaho spotted a new “ImageGen” watermark feature in the new beta of ChatGPT’s Android app. Blaho also found mentions of other tools: “Structured Thoughts,” “Reasoning Recap,” “CoT Search Tool,” and “l1239dk1.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-offers-chatgpt-plus-for-free-to-u-s-canadian-college-students"&gt;OpenAI offers ChatGPT Plus for free to U.S., Canadian college students&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is offering its $20-per-month ChatGPT Plus subscription tier for free to all college students in the U.S. and Canada through the end of May. The offer will let millions of students use OpenAI’s premium service, which offers access to the company’s GPT-4o model, image generation, voice interaction, and research tools that are not available in the free version.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-users-have-generated-over-700m-images-nbsp-so-far"&gt;ChatGPT users have generated over 700M images&amp;nbsp;so far&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;More than 130 million users have created over 700 million images since ChatGPT got the upgraded image generator on March 25, according to COO of OpenAI Brad Lightcap. The image generator was made available  to all ChatGPT users on March 31, and went viral for being able to create Ghibli-style photos.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-o3-model-could-cost-more-to-run-than-initial-estimate"&gt;OpenAI’s o3 model could cost more to run than initial estimate&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The Arc Prize Foundation, which develops the AI benchmark tool ARC-AGI, has updated the estimated computing costs for OpenAI’s o3 “reasoning” model managed by ARC-AGI. The organization originally estimated that the best-performing configuration of o3 it tested, o3 high, would cost approximately $3,000 to address a single problem. The Foundation now thinks the cost could be much higher, possibly around $30,000 per task.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-ceo-says-capacity-issues-will-cause-product-delays"&gt;OpenAI CEO says capacity issues will cause product delays&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;In a series of posts on X, OpenAI CEO Sam Altman said the company’s new image-generation tool’s popularity may cause product releases to be delayed. “We are getting things under control, but you should expect new releases from OpenAI to be delayed, stuff to break, and for service to sometimes be slow as we deal with capacity challenges,” he wrote. &lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-march-2025"&gt;March 2025&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-plans-to-release-a-new-open-ai-language-model"&gt;OpenAI plans to release a new ‘open’ AI language model&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpeanAI intends to release its “first” open language model since GPT-2 “in the coming months.” The company plans to host developer events to gather feedback and eventually showcase prototypes of the model. The first developer event is to be held in San Francisco, with sessions to follow in Europe and Asia.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-removes-chatgpt-s-restrictions-on-image-generation"&gt;OpenAI removes ChatGPT’s restrictions on image generation&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI made a notable change to its content moderation policies after the success of its new image generator in ChatGPT, which went viral for being able to create Studio Ghibli-style images. The company has updated its policies to allow ChatGPT to generate images of public figures, hateful symbols, and racial features when requested. OpenAI had previously declined such prompts due to the potential controversy or harm they may cause. However, the company has now “evolved” its approach, as stated in a blog post published by Joanne Jang, the lead for OpenAI’s model behavior.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-adopts-anthropic-s-standard-for-linking-ai-models-with-data"&gt;OpenAI adopts Anthropic’s standard for linking AI models with data&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI wants to incorporate Anthropic’s Model Context Protocol (MCP) into all of its products, including the ChatGPT desktop app. MCP, an open-source standard, helps AI models generate more accurate and suitable responses to specific queries, and lets developers create bidirectional links between data sources and AI applications like chatbots. The protocol is currently available in the Agents SDK, and support for the ChatGPT desktop app and Responses API will be coming soon, OpenAI CEO Sam Altman said. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-viral-studio-ghibli-style-images-could-raise-ai-copyright-concerns"&gt;OpenAI’s viral Studio Ghibli-style images could raise AI copyright concerns&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The latest update of the image generator on OpenAI’s ChatGPT has triggered a flood of AI-generated memes in the style of Studio Ghibli, the Japanese animation studio behind blockbuster films like “My Neighbor Totoro” and “Spirited Away.” The burgeoning mass of Ghibli-esque images have sparked concerns about whether OpenAI has violated copyright laws, especially since the company is already facing legal action for using source material without authorization. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-expects-revenue-to-triple-to-12-7-billion-this-year"&gt;OpenAI expects revenue to triple to $12.7 billion this year&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI expects its revenue to triple to $12.7 billion in 2025, fueled by the performance of its paid AI software, Bloomberg reported, citing an anonymous source. While the startup doesn’t expect to reach positive cash flow until 2029, it expects revenue to increase significantly in 2026 to surpass $29.4 billion, the report said. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-has-upgraded-its-image-generation-feature"&gt;ChatGPT has upgraded its image-generation feature&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI on Tuesday rolled out a major upgrade to ChatGPT’s image-generation capabilities: ChatGPT can now use the GPT-4o model to generate and edit images and photos directly. The feature went live earlier this week in ChatGPT and Sora, OpenAI’s AI video-generation tool, for subscribers of the company’s Pro plan, priced at $200 a month, and will be available soon to ChatGPT Plus subscribers and developers using the company’s API service. The company’s CEO Sam Altman said on Wednesday, however, that the release of the image generation feature to free users would be delayed due to higher demand than the company expected.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-announces-leadership-updates"&gt;OpenAI announces leadership updates&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Brad Lightcap, OpenAI’s chief operating officer, will lead the company’s global expansion and manage corporate partnerships as CEO Sam Altman shifts his focus to research and products, according to a blog post from OpenAI. Lightcap, who previously worked with Altman at Y Combinator, joined the Microsoft-backed startup in 2018. OpenAI also said Mark Chen would step into the expanded role of chief research officer, and Julia Villagra will take on the role of chief people officer.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-ai-voice-assistant-now-has-advanced-feature"&gt;OpenAI’s AI voice assistant now has advanced feature&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has updated its AI voice assistant with improved chatting capabilities, according to a video posted on Monday (March 24) to the company’s official media channels. The update enables real-time conversations, and the AI assistant is said to be more personable and interrupts users less often. Users on ChatGPT’s free tier can now access the new version of Advanced Voice Mode, while paying users will receive answers that are “more direct, engaging, concise, specific, and creative,” a spokesperson from OpenAI told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-meta-in-talks-with-reliance-in-india"&gt;&lt;strong&gt;OpenAI, Meta in talks with Reliance in India&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI and Meta have separately engaged in discussions with Indian conglomerate Reliance Industries regarding potential collaborations to enhance their AI services in the country, per a report by The Information. One key topic being discussed is Reliance Jio distributing OpenAI’s ChatGPT. Reliance has proposed selling OpenAI’s models to businesses in India through an application programming interface (API) so they can incorporate AI into their operations. Meta also plans to bolster its presence in India by constructing a large 3GW data center in Jamnagar, Gujarat. OpenAI, Meta, and Reliance have not yet officially announced these plans.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-faces-privacy-complaint-in-europe-for-chatbot-s-defamatory-hallucinations"&gt;OpenAI faces privacy complaint in Europe for chatbot’s defamatory hallucinations&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Noyb, a privacy rights advocacy group, is supporting an individual in Norway who was shocked to discover that ChatGPT was providing false information about him, stating that he had been found guilty of killing two of his children and trying to harm the third. “The GDPR is clear. Personal data has to be accurate,” said Joakim Söderberg, data protection lawyer at&amp;nbsp;Noyb, in a statement. “If it’s not, users have the right to have it changed to reflect the truth. Showing ChatGPT users a tiny disclaimer that the chatbot can make mistakes clearly isn’t enough. You can’t just spread false information and in the end add a small disclaimer saying that everything you said may just not be true.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-upgrades-its-transcription-and-voice-generating-ai-models"&gt;OpenAI upgrades its transcription and voice-generating AI models&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has added new transcription and voice-generating AI models to its APIs: a text-to-speech model, “gpt-4o-mini-tts,” that delivers more nuanced and realistic sounding speech, as well as two speech-to-text models called “gpt-4o-transcribe” and “gpt-4o-mini-transcribe”. The company claims they are improved versions of what was already there and that they hallucinate less.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-launched-o1-pro-a-more-powerful-version-of-its-o1"&gt;OpenAI has launched o1-pro, a more powerful version of its o1&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced o1-pro in its developer API. OpenAI says its o1-pro uses more computing than its o1 “reasoning” AI model to deliver “consistently better responses.” It’s only accessible to select developers who have spent at least $5 on OpenAI API services. OpenAI charges $150 for every million tokens (about 750,000 words) input into the model and $600 for every million tokens the model produces. It costs twice as much as OpenAI’s GPT-4.5 for input and 10 times the price of regular o1.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-research-lead-noam-brown-thinks-ai-reasoning-models-could-ve-arrived-decades-ago"&gt;OpenAI research lead Noam Brown thinks AI “reasoning” models could’ve arrived decades ago&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Noam Brown, who heads AI reasoning research at OpenAI, thinks that certain types of AI models for “reasoning” could have been developed 20 years ago if researchers had understood the correct approach and algorithms.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-says-it-has-trained-an-ai-that-s-really-good-at-creative-writing"&gt;OpenAI says it has trained an AI that’s “really good” at creative writing&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman said, in a&amp;nbsp;post on X, that the company has trained a “new model” that’s “really good” at creative writing. He posted a lengthy sample from the model given the prompt “Please write a metafictional literary short story about AI and grief.” OpenAI has not extensively explored the use of AI for writing fiction. The company has mostly concentrated on challenges in rigid, predictable areas such as math and programming.&lt;em&gt;&amp;nbsp;&lt;/em&gt;And it turns out that it might not be that great at creative writing at all. &lt;/p&gt;







&lt;blockquote class="twitter-tweet wp-block-html"&gt;&lt;p dir="ltr" lang="en"&gt;we trained a new model that is good at creative writing (not sure yet how/when it will get released). this is the first time i have been really struck by something written by AI; it got the vibe of metafiction so right.&lt;/p&gt;&lt;p&gt;PROMPT:&lt;/p&gt;&lt;p&gt;Please write a metafictional literary short story…&lt;/p&gt;— Sam Altman (@sama) March 11, 2025&lt;/blockquote&gt; 

&lt;h4 class="wp-block-heading" id="h-openai-launches-new-tools-to-help-businesses-build-ai-agents"&gt;OpenAI launches new tools to help businesses build AI agents&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI rolled out new tools designed to help developers and businesses build AI agents — automated systems that can independently accomplish tasks — using the company’s own AI models and frameworks. The tools are part of OpenAI’s new Responses API, which enables enterprises to develop customized AI agents that can perform web searches, scan through company files, and navigate websites, similar to OpenAI’s Operator product. The Responses API effectively replaces OpenAI’s Assistants API, which the company plans to discontinue in the first half of 2026.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-reportedly-plans-to-charge-up-to-20-000-a-month-for-specialized-ai-agents"&gt;OpenAI reportedly plans to charge up to $20,000 a month for specialized AI ‘agents’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI intends to release several “agent” products tailored for different applications, including sorting and ranking sales leads and software engineering, according to a report from The Information. One, a “high-income knowledge worker” agent, will reportedly be priced at $2,000 a month. Another, a software developer agent, is said to cost $10,000 a month. The most expensive rumored agents, which are said to be aimed at supporting “PhD-level research,” are expected to cost $20,000 per month. The jaw-dropping figure is indicative of how much cash OpenAI needs right now: The company lost roughly $5 billion last year after paying for costs related to running its services and other expenses. It’s unclear when these agentic tools might launch or which customers will be eligible to buy them.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-can-directly-edit-your-code"&gt;&lt;strong&gt;ChatGPT can directly edit your code&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The latest version of the macOS ChatGPT app allows users to edit code directly in supported developer tools, including Xcode, VS Code, and JetBrains. ChatGPT Plus, Pro, and Team subscribers can use the feature now, and the company plans to roll it out to more users like Enterprise, Edu, and free users.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-weekly-active-users-doubled-in-less-than-6-months-thanks-to-new-releases"&gt;ChatGPT’s weekly active users doubled in less than 6 months, thanks to new releases&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;According to a new report from VC firm Andreessen Horowitz (a16z), OpenAI’s AI chatbot, ChatGPT, experienced solid growth in the second half of 2024. It took ChatGPT nine months to increase its weekly active users from 100 million in November 2023 to 200 million in August 2024, but it only took less than six months to double that number once more, according to the report. ChatGPT’s weekly active users increased to 300 million by December 2024 and 400 million by February 2025. ChatGPT has experienced significant growth recently due to the launch of new models and features, such as GPT-4o, with multimodal capabilities. ChatGPT usage spiked from April to May 2024, shortly after that model’s launch.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-february-2025"&gt;February 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-cancels-its-o3-ai-model-in-favor-of-a-unified-next-gen-release"&gt;OpenAI cancels its o3 AI model in favor of a ‘unified’ next-gen release&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has effectively canceled the release of o3 in favor of what CEO Sam Altman is calling a “simplified” product offering. In a post on X, Altman said that, in the coming months, OpenAI will release a model called GPT-5 that “integrates a lot of [OpenAI’s] technology,” including o3, in ChatGPT and its API. As a result of that roadmap decision, OpenAI no longer plans to release o3 as a standalone model.&amp;nbsp;&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-may-not-be-as-power-hungry-as-once-assumed"&gt;ChatGPT may not be as power-hungry as once assumed&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A commonly cited stat is that ChatGPT requires around 3 watt-hours of power to answer a single question. Using OpenAI’s latest default model for ChatGPT, GPT-4o, as a reference, nonprofit AI research institute Epoch AI found the average ChatGPT query consumes around 0.3 watt-hours. However, the analysis doesn’t consider the additional energy costs incurred by ChatGPT with features like image generation or input processing.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-now-reveals-more-of-its-o3-mini-model-s-thought-process"&gt;OpenAI now reveals more of its o3-mini model’s thought process&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;In response to pressure from rivals like DeepSeek, OpenAI is changing the way its o3-mini model communicates its step-by-step “thought” process. ChatGPT users will see an updated “chain of thought” that shows more of the model’s “reasoning” steps and how it arrived at answers to questions.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-you-can-now-use-chatgpt-web-search-without-logging-in"&gt;You can now use ChatGPT web search without logging in&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is now allowing anyone to use ChatGPT web search without having to log in. While OpenAI had previously allowed users to ask ChatGPT questions without signing in, responses were restricted to the chatbot’s last training update. This only applies through ChatGPT.com, however. To use ChatGPT in any form through the native mobile app, you will still need to be logged in.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-a-new-chatgpt-agent-for-deep-research"&gt;OpenAI unveils a new ChatGPT agent for ‘deep research’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI announced a new AI “agent” called deep research that’s designed to help people conduct in-depth, complex research using ChatGPT. OpenAI says the “agent” is intended for instances where you don’t just want a quick answer or summary, but instead need to assiduously consider information from multiple websites and other sources.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-january-2025"&gt;&lt;strong&gt;January 2025&lt;/strong&gt;&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-used-a-subreddit-to-test-ai-persuasion"&gt;OpenAI used a subreddit to test AI persuasion&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI used the subreddit r/ChangeMyView to measure the persuasive abilities of its AI reasoning models. OpenAI says it collects user posts from the subreddit and asks its AI models to write replies, in a closed environment, that would change the Reddit user’s mind on a subject. The company then shows the responses to testers, who assess how persuasive the argument is, and finally OpenAI compares the AI models’ responses to human replies for that same post.&amp;nbsp;&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-o3-mini-its-latest-reasoning-model"&gt;OpenAI launches o3-mini, its latest ‘reasoning’ model&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched a new AI “reasoning” model, o3-mini, the newest in the company’s o family of models. OpenAI first previewed the model in December alongside a more capable system called o3. OpenAI is pitching its new model as both “powerful” and “affordable.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-mobile-users-are-85-male-report-says"&gt;ChatGPT’s mobile users are 85% male, report says&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A new report from app analytics firm Appfigures found that over half of ChatGPT’s mobile users are under age 25, with users between ages 50 and 64 making up the second largest age demographic. The gender gap among ChatGPT users is even more significant. Appfigures estimates that across age groups, men make up 84.5% of all users.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-chatgpt-plan-for-us-government-agencies"&gt;OpenAI launches ChatGPT plan for US government agencies&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched ChatGPT Gov designed to provide U.S. government agencies an additional way to access the tech. ChatGPT Gov includes many of the capabilities found in OpenAI’s corporate-focused tier, ChatGPT Enterprise. OpenAI says that ChatGPT Gov enables agencies to more easily manage their own security, privacy, and compliance, and could expedite internal authorization of OpenAI’s tools for the handling of non-public sensitive data.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-more-teens-report-using-chatgpt-for-schoolwork-despite-the-tech-s-faults"&gt;More teens report using ChatGPT for schoolwork, despite the tech’s faults&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Younger Gen Zers are embracing ChatGPT, for schoolwork, according to a new survey by the Pew Research Center. In a follow-up to its 2023 poll on ChatGPT usage among young people, Pew asked ~1,400 U.S.-based teens ages 13 to 17 whether they’ve used ChatGPT for homework or other school-related assignments. Twenty-six percent said that they had, double the number two years ago. Just over half of teens responding to the poll said they think it’s acceptable to use ChatGPT for researching new subjects. But considering the ways ChatGPT can fall short, the results are possibly cause for alarm.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-says-it-may-store-deleted-operator-data-for-up-to-90-days"&gt;OpenAI says it may store deleted Operator data for up to 90 days&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says that it might store chats and associated screenshots from customers who use Operator, the company’s AI “agent” tool, for up to 90 days — even after a user manually deletes them. While OpenAI has a similar deleted data retention policy for ChatGPT, the retention period for ChatGPT is only 30 days, which is 60 days shorter than Operator’s.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-operator-an-ai-agent-that-performs-tasks-autonomously"&gt;OpenAI launches Operator, an AI agent that performs tasks autonomously&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is launching a research preview of Operator, a general-purpose AI agent that can take control of a web browser and independently perform certain actions. Operator promises to automate tasks such as booking travel accommodations, making restaurant reservations, and shopping online.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-may-preview-its-agent-tool-for-users-on-the-200-per-month-pro-plan"&gt;OpenAI may preview its agent tool for users on the $200-per-month Pro plan&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Operator, OpenAI’s agent tool, could be released sooner rather than later. Changes to ChatGPT’s code base suggest that Operator will be available as an early research preview to users on the $200 Pro subscription plan. The changes aren’t yet publicly visible, but a user on X who goes by Choi spotted these updates in ChatGPT’s client-side code. TechCrunch separately identified the same references to Operator on OpenAI’s website.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-tests-phone-number-only-chatgpt-signups"&gt;OpenAI tests phone number-only ChatGPT signups&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has begun testing a feature that lets new ChatGPT users sign up with only a phone number — no email required. The feature is currently in beta in the U.S. and India. However, users who create an account using their number can’t upgrade to one of OpenAI’s paid plans without verifying their account via an email. Multi-factor authentication also isn’t supported without a valid email.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-now-lets-you-schedule-reminders-and-recurring-tasks"&gt;ChatGPT now lets you schedule reminders and recurring tasks&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT’s new beta feature, called tasks, allows users to set simple reminders. For example, you can ask ChatGPT to remind you when your passport expires in six months, and the AI assistant will follow up with a push notification on whatever platform you have tasks enabled. The feature will start rolling out to ChatGPT Plus, Team, and Pro users around the globe this week.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-new-chatgpt-feature-lets-users-assign-it-traits-like-chatty-and-gen-z"&gt;New ChatGPT feature lets users assign it traits like ‘chatty’ and ‘Gen Z’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is introducing a new way for users to customize their interactions with ChatGPT. Some users found they can specify a preferred name or nickname and “traits” they’d like the chatbot to have. OpenAI suggests traits like “Chatty,” “Encouraging,” and “Gen Z.” However, some users reported that the new options have disappeared, so it’s possible they went live prematurely.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-faqs"&gt;FAQs:&lt;/h3&gt;

&lt;h4 class="wp-block-heading"&gt;What is ChatGPT? How does it work?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is a general-purpose chatbot that uses artificial intelligence to generate text after a user enters a prompt, developed by tech startup OpenAI. The chatbot uses GPT-4, a large language model that uses deep learning to produce human-like text.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;When did ChatGPT get released?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;November 30, 2022 is when ChatGPT was released for public use.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What is the latest version of ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Both the free version of ChatGPT and the paid ChatGPT Plus are regularly updated with new GPT models. The most recent model is GPT-4o.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can I use ChatGPT for free?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;There is a free version of ChatGPT that only requires a sign-in in addition to the paid version, ChatGPT Plus.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Who uses ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Anyone can use ChatGPT! More and more tech companies and search engines are utilizing the chatbot to automate text or quickly answer user questions/concerns.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What companies use ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Multiple enterprises utilize ChatGPT, although others may limit the use of the AI-powered tool.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Most recently, Microsoft announced at its 2023 Build conference that it is integrating its ChatGPT-based Bing experience into Windows 11. A Brooklyn-based 3D display startup Looking Glass utilizes ChatGPT to produce holograms you can communicate with by using ChatGPT.&amp;nbsp; And nonprofit organization Solana officially integrated the chatbot into its network with a ChatGPT plug-in geared toward end users to help onboard into the web3 space.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What does GPT mean in ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;GPT stands for Generative Pre-Trained Transformer.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What is the difference between ChatGPT and a chatbot?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A chatbot can be any software/system that holds dialogue with you/a person but doesn’t necessarily have to be AI-powered. For example, there are chatbots that are rules-based in the sense that they’ll give canned responses to questions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is AI-powered and utilizes LLM technology to generate text after a prompt.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can ChatGPT write essays?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Yes.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can ChatGPT commit libel?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Due to the nature of how these models work, they don’t know or care whether something is true, only that it looks true. That’s a problem when you’re using it to do your homework, sure, but when it accuses you of a crime you didn’t commit, that may well at this point be libel.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We will see how handling troubling statements produced by ChatGPT will play out over the next few months as tech and legal experts attempt to tackle the fastest moving target in the industry.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Does ChatGPT have an app?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes, there is a free ChatGPT mobile app for iOS and Android users.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What is the ChatGPT character limit?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;It’s not documented anywhere that ChatGPT has a character limit. However, users have noted that there are some character limitations after around 500 words.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Does ChatGPT have an API?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes, it was released March 1, 2023.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What are some sample everyday uses for ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Everyday examples include programming, scripts, email replies, listicles, blog ideas, summarization, etc.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What are some advanced uses for ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Advanced use examples include debugging code, programming languages, scientific concepts, complex problem solving, etc.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;How good is ChatGPT at writing code?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;It depends on the nature of the program. While ChatGPT can write workable Python code, it can’t necessarily program an entire app’s worth of code. That’s because ChatGPT lacks context awareness — in other words, the generated code isn’t always appropriate for the specific context in which it’s being used.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Can you save a ChatGPT chat?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. OpenAI allows users to save chats in the ChatGPT interface, stored in the sidebar of the screen. There are no built-in sharing features yet.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are there alternatives to ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. There are multiple AI-powered chatbot competitors such as Together, Google’s Gemini and Anthropic’s Claude, and developers are creating open source alternatives.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;How does ChatGPT handle data privacy?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has&amp;nbsp;said&amp;nbsp;that individuals in “certain jurisdictions” (such as the EU) can object to the processing of their personal information by its AI models by filling out&amp;nbsp;this form. This includes the ability to make requests for deletion of AI-generated references about you. Although OpenAI notes it may not grant every request since it must balance privacy requests against freedom of expression “in accordance with applicable laws”.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The web form for making a deletion of data about you request is entitled “OpenAI Personal Data Removal Request”.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its privacy policy, the ChatGPT maker makes a passing acknowledgement of the objection requirements attached to relying on “legitimate interest” (LI), pointing users towards more information about requesting an opt out — when it writes: “See here&amp;nbsp;for instructions on how you can opt out of our use of your information to train our models.”&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What controversies have surrounded ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Recently, Discord announced that it had integrated OpenAI’s technology into its bot named Clyde where two users tricked Clyde into providing them with instructions for making the illegal drug methamphetamine (meth) and the incendiary mixture napalm.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;An Australian mayor has publicly announced he may sue OpenAI for defamation due to ChatGPT’s false claims that he had served time in prison for bribery. This would be the first defamation lawsuit against the text-generating service.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CNET found itself in the midst of controversy after Futurism reported the publication was publishing articles under a mysterious byline completely generated by AI. The private equity company that owns CNET, Red Ventures, was accused of using ChatGPT for SEO farming, even if the information was incorrect.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Several major school systems and colleges, including New York City Public Schools, have banned ChatGPT from their networks and devices. They claim that the AI impedes the learning process by promoting plagiarism and misinformation, a claim that not every educator agrees with.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There have also been cases of ChatGPT accusing individuals of false crimes.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Where can I find examples of ChatGPT prompts?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Several marketplaces host and provide ChatGPT prompts, either for free or for a nominal fee. One is PromptBase. Another is ChatX. More launch every day.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Can ChatGPT be detected?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Poorly. Several tools claim to detect ChatGPT-generated text, but in our tests, they’re inconsistent at best.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are ChatGPT chats public?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;No. But OpenAI recently disclosed a bug, since fixed, that exposed the titles of some users’ conversations to other people on the service.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What lawsuits are there surrounding ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;None specifically targeting ChatGPT. But OpenAI is involved in at least one lawsuit that has implications for AI systems trained on publicly available data, which would touch on ChatGPT.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are there issues regarding plagiarism with ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. Text-generating AI models like ChatGPT have a tendency to regurgitate content from their training data.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story is continually updated with new information.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/14/chatgpt-everything-to-know-about-the-ai-chatbot/</guid><pubDate>Thu, 14 Aug 2025 15:50:05 +0000</pubDate></item><item><title>Introducing Gemma 3 270M: The compact model for hyper-efficient AI (Google DeepMind Blog)</title><link>https://deepmind.google/discover/blog/introducing-gemma-3-270m-the-compact-model-for-hyper-efficient-ai/</link><description>&lt;div&gt;
    &lt;p&gt;The last few months have been an exciting time for the Gemma family of open models. We introduced Gemma 3 and Gemma 3 QAT, delivering state-of-the-art performance for single cloud and desktop accelerators. Then, we announced the full release of Gemma 3n, a mobile-first architecture bringing powerful, real-time multimodal AI directly to edge devices. Our goal has been to provide useful tools for developers to build with AI, and we continue to be amazed by the vibrant Gemmaverse you are helping create, celebrating together as downloads surpassed 200 million last week.&lt;/p&gt;&lt;p&gt;Today, we're adding a new, highly specialized tool to the Gemma 3 toolkit: Gemma 3 270M, a compact, 270-million parameter model designed from the ground up for task-specific fine-tuning with strong instruction-following and text structuring capabilities already trained in.&lt;/p&gt;
&lt;/div&gt;&lt;div&gt;
        &lt;div class="image-wrapper"&gt;
            
                &lt;img alt="Gemma 3 270M" class="regular-image" src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemma3-270M_Chart01_RD3-V01.original.jpg" /&gt;
            
            
                
                    &lt;p&gt;
                        Gemma 3 270M brings strong instruction-following capabilities to a small-footprint model. As shown by the IFEval benchmark (which tests a model's ability to follow verifiable instructions), it establishes a new level of performance for its size, making sophisticated AI capabilities more accessible for on-device and research applications.
                    &lt;/p&gt;
                
            
        &lt;/div&gt;
    &lt;/div&gt;&lt;div&gt;
    &lt;h2 id="core-capabilities-of-gemma-3-270m"&gt;Core capabilities of Gemma 3 270M&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Compact and capable architecture:&lt;/b&gt; Our new model has a total of 270 million parameters: 170 million embedding parameters due to a large vocabulary size and 100 million for our transformer blocks. Thanks to the large vocabulary of 256k tokens, the model can handle specific and rare tokens, making it a strong base model to be further fine-tuned in specific domains and languages.&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Extreme energy efficiency:&lt;/b&gt; A key advantage of Gemma 3 270M is its low power consumption. Internal tests on a Pixel 9 Pro SoC show the INT4-quantized model used just 0.75% of the battery for 25 conversations, making it our most power-efficient Gemma model.&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Instruction following:&lt;/b&gt; An instruction-tuned model is released alongside a pre-trained checkpoint. While this model is not designed for complex conversational use cases, it’s a strong model that follows general instructions right out of the box.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In engineering, success is defined by efficiency, not just raw power. You wouldn't use a sledgehammer to hang a picture frame. The same principle applies to building with AI.&lt;/p&gt;&lt;p&gt;Gemma 3 270M embodies this "right tool for the job" philosophy. It's a high-quality foundation model that follows instructions well out of the box, and its true power is unlocked through fine-tuning. Once specialized, it can execute tasks like text classification and data extraction with remarkable accuracy, speed, and cost-effectiveness. By starting with a compact, capable model, you can build production systems that are lean, fast, and dramatically cheaper to operate.&lt;/p&gt;&lt;h2 id="a-real-world-blueprint-for-success"&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;A real-world blueprint for success&lt;/h2&gt;&lt;p&gt;The power of this approach has already delivered incredible results in the real world. A perfect example is the work done by Adaptive ML with SK Telecom. Facing the challenge of nuanced, multilingual content moderation, they chose to specialize. Instead of using a massive, general-purpose model, Adaptive ML fine-tuned a Gemma 3 4B model. The results were stunning: the specialized Gemma model not only met but exceeded the performance of much larger proprietary models on its specific task.&lt;/p&gt;&lt;p&gt;Gemma 3 270M is designed to let developers take this approach even further, unlocking even greater efficiency for well-defined tasks. It's the perfect starting point for creating a fleet of small, specialized models, each an expert at its own task.&lt;/p&gt;&lt;p&gt;But this power of specialization isn't just for enterprise tasks; it also enables powerful creative applications. For example, check out this Bedtime Story Generator web app:&lt;/p&gt;
&lt;/div&gt;&lt;div&gt;
    
    
        
            &lt;p&gt;Gemma 3 270M used to power a Bedtime Story Generator web app using Transformers.js. The model’s size and performance make it suitable for offline, web-based, creative tasks. (Credit: Joshua (@xenovacom on X) from the Hugging Face team)&lt;/p&gt;
        
    
&lt;/div&gt;&lt;div&gt;
    &lt;h2 id="when-to-choose-gemma-3-270m"&gt;When to choose Gemma 3 270M&lt;/h2&gt;&lt;p&gt;Gemma 3 270M inherits the advanced architecture and robust pre-training of the Gemma 3 collection, providing a solid foundation for your custom applications.&lt;/p&gt;&lt;p&gt;Here’s when it’s the perfect choice:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;You have a high-volume, well-defined task.&lt;/b&gt; Ideal for functions like sentiment analysis, entity extraction, query routing, unstructured to structured text processing, creative writing, and compliance checks.&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;You need to make every millisecond and micro-cent count.&lt;/b&gt; Drastically reduce, or eliminate, your inference costs in production and deliver faster responses to your users. A fine-tuned 270M model can run on lightweight, inexpensive infrastructure or directly on-device.&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;You need to iterate and deploy quickly.&lt;/b&gt; The small size of Gemma 3 270M allows for rapid fine-tuning experiments, helping you find the perfect configuration for your use case in hours, not days.&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;You need to ensure user privacy.&lt;/b&gt; Because the model can run entirely on-device, you can build applications that handle sensitive information without ever sending data to the cloud.&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;You want a fleet of specialized task models.&lt;/b&gt; Build and deploy multiple custom models, each expertly trained for a different task, without breaking your budget.&lt;/li&gt;&lt;/ul&gt;&lt;h2 id="get-started-with-fine-tuning"&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;Get started with fine-tuning&lt;/h2&gt;&lt;p&gt;We want to make it as easy as possible to turn Gemma 3 270M into your own custom solution. It’s built on the same architecture as the rest of the Gemma 3 models, with recipes and tools to get you started quickly. You can find our guide on full fine-tuning using Gemma 3 270M as part of the Gemma docs.&lt;/p&gt;&lt;p&gt;The Gemmaverse is built on the idea that innovation comes in all sizes. With Gemma 3 270M, we’re empowering developers to build smarter, faster, and more efficient AI solutions. We can’t wait to see the specialized models you create.&lt;/p&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;
    &lt;p&gt;The last few months have been an exciting time for the Gemma family of open models. We introduced Gemma 3 and Gemma 3 QAT, delivering state-of-the-art performance for single cloud and desktop accelerators. Then, we announced the full release of Gemma 3n, a mobile-first architecture bringing powerful, real-time multimodal AI directly to edge devices. Our goal has been to provide useful tools for developers to build with AI, and we continue to be amazed by the vibrant Gemmaverse you are helping create, celebrating together as downloads surpassed 200 million last week.&lt;/p&gt;&lt;p&gt;Today, we're adding a new, highly specialized tool to the Gemma 3 toolkit: Gemma 3 270M, a compact, 270-million parameter model designed from the ground up for task-specific fine-tuning with strong instruction-following and text structuring capabilities already trained in.&lt;/p&gt;
&lt;/div&gt;&lt;div&gt;
        &lt;div class="image-wrapper"&gt;
            
                &lt;img alt="Gemma 3 270M" class="regular-image" src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemma3-270M_Chart01_RD3-V01.original.jpg" /&gt;
            
            
                
                    &lt;p&gt;
                        Gemma 3 270M brings strong instruction-following capabilities to a small-footprint model. As shown by the IFEval benchmark (which tests a model's ability to follow verifiable instructions), it establishes a new level of performance for its size, making sophisticated AI capabilities more accessible for on-device and research applications.
                    &lt;/p&gt;
                
            
        &lt;/div&gt;
    &lt;/div&gt;&lt;div&gt;
    &lt;h2 id="core-capabilities-of-gemma-3-270m"&gt;Core capabilities of Gemma 3 270M&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Compact and capable architecture:&lt;/b&gt; Our new model has a total of 270 million parameters: 170 million embedding parameters due to a large vocabulary size and 100 million for our transformer blocks. Thanks to the large vocabulary of 256k tokens, the model can handle specific and rare tokens, making it a strong base model to be further fine-tuned in specific domains and languages.&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Extreme energy efficiency:&lt;/b&gt; A key advantage of Gemma 3 270M is its low power consumption. Internal tests on a Pixel 9 Pro SoC show the INT4-quantized model used just 0.75% of the battery for 25 conversations, making it our most power-efficient Gemma model.&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Instruction following:&lt;/b&gt; An instruction-tuned model is released alongside a pre-trained checkpoint. While this model is not designed for complex conversational use cases, it’s a strong model that follows general instructions right out of the box.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In engineering, success is defined by efficiency, not just raw power. You wouldn't use a sledgehammer to hang a picture frame. The same principle applies to building with AI.&lt;/p&gt;&lt;p&gt;Gemma 3 270M embodies this "right tool for the job" philosophy. It's a high-quality foundation model that follows instructions well out of the box, and its true power is unlocked through fine-tuning. Once specialized, it can execute tasks like text classification and data extraction with remarkable accuracy, speed, and cost-effectiveness. By starting with a compact, capable model, you can build production systems that are lean, fast, and dramatically cheaper to operate.&lt;/p&gt;&lt;h2 id="a-real-world-blueprint-for-success"&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;A real-world blueprint for success&lt;/h2&gt;&lt;p&gt;The power of this approach has already delivered incredible results in the real world. A perfect example is the work done by Adaptive ML with SK Telecom. Facing the challenge of nuanced, multilingual content moderation, they chose to specialize. Instead of using a massive, general-purpose model, Adaptive ML fine-tuned a Gemma 3 4B model. The results were stunning: the specialized Gemma model not only met but exceeded the performance of much larger proprietary models on its specific task.&lt;/p&gt;&lt;p&gt;Gemma 3 270M is designed to let developers take this approach even further, unlocking even greater efficiency for well-defined tasks. It's the perfect starting point for creating a fleet of small, specialized models, each an expert at its own task.&lt;/p&gt;&lt;p&gt;But this power of specialization isn't just for enterprise tasks; it also enables powerful creative applications. For example, check out this Bedtime Story Generator web app:&lt;/p&gt;
&lt;/div&gt;&lt;div&gt;
    
    
        
            &lt;p&gt;Gemma 3 270M used to power a Bedtime Story Generator web app using Transformers.js. The model’s size and performance make it suitable for offline, web-based, creative tasks. (Credit: Joshua (@xenovacom on X) from the Hugging Face team)&lt;/p&gt;
        
    
&lt;/div&gt;&lt;div&gt;
    &lt;h2 id="when-to-choose-gemma-3-270m"&gt;When to choose Gemma 3 270M&lt;/h2&gt;&lt;p&gt;Gemma 3 270M inherits the advanced architecture and robust pre-training of the Gemma 3 collection, providing a solid foundation for your custom applications.&lt;/p&gt;&lt;p&gt;Here’s when it’s the perfect choice:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;You have a high-volume, well-defined task.&lt;/b&gt; Ideal for functions like sentiment analysis, entity extraction, query routing, unstructured to structured text processing, creative writing, and compliance checks.&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;You need to make every millisecond and micro-cent count.&lt;/b&gt; Drastically reduce, or eliminate, your inference costs in production and deliver faster responses to your users. A fine-tuned 270M model can run on lightweight, inexpensive infrastructure or directly on-device.&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;You need to iterate and deploy quickly.&lt;/b&gt; The small size of Gemma 3 270M allows for rapid fine-tuning experiments, helping you find the perfect configuration for your use case in hours, not days.&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;You need to ensure user privacy.&lt;/b&gt; Because the model can run entirely on-device, you can build applications that handle sensitive information without ever sending data to the cloud.&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;You want a fleet of specialized task models.&lt;/b&gt; Build and deploy multiple custom models, each expertly trained for a different task, without breaking your budget.&lt;/li&gt;&lt;/ul&gt;&lt;h2 id="get-started-with-fine-tuning"&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;Get started with fine-tuning&lt;/h2&gt;&lt;p&gt;We want to make it as easy as possible to turn Gemma 3 270M into your own custom solution. It’s built on the same architecture as the rest of the Gemma 3 models, with recipes and tools to get you started quickly. You can find our guide on full fine-tuning using Gemma 3 270M as part of the Gemma docs.&lt;/p&gt;&lt;p&gt;The Gemmaverse is built on the idea that innovation comes in all sizes. With Gemma 3 270M, we’re empowering developers to build smarter, faster, and more efficient AI solutions. We can’t wait to see the specialized models you create.&lt;/p&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://deepmind.google/discover/blog/introducing-gemma-3-270m-the-compact-model-for-hyper-efficient-ai/</guid><pubDate>Thu, 14 Aug 2025 16:00:00 +0000</pubDate></item><item><title>DeepSeek reverts to Nvidia for R2 model after Huawei AI chip fails (AI News)</title><link>https://www.artificialintelligence-news.com/news/deepseek-reverts-nvidia-r2-model-huawei-ai-chip-fails/</link><description>&lt;p&gt;DeepSeek’s plan to train its new AI model, R2, on Huawei’s Ascend chips has failed and forced a retreat to Nvidia while delaying launch.&lt;/p&gt;&lt;p&gt;For months, the narrative pushed by Beijing has been one of unstoppable technological progress and a march towards self-sufficiency. However, reality has a habit of biting back. The recent troubles of Chinese AI darling DeepSeek is a textbook example of where ambition meets the hard wall of technical limitations.&lt;/p&gt;&lt;p&gt;After the successful launch of its R1 model in January, DeepSeek found itself under pressure from China to champion the national cause. According to three people speaking to the Financial Times, the message was clear: use Huawei’s chips, not Nvidia’s.&lt;/p&gt;&lt;p&gt;When it came to actually training their new R2 model, the sources say DeepSeek ran into “persistent technical issues” with Huawei’s AI chips. The problems were so fundamental that the project ground to a halt. A person with knowledge of the situation said this was the main reason the model’s planned launch in May was scrapped, putting the company on the back foot in a market that waits for no-one.&lt;/p&gt;&lt;p&gt;To understand why this is such a big deal, you have to know the difference between AI training and inference. Training is the hard part, like sending a student to university for years of intense learning. It requires colossal amounts of power and stability. Inference is the relatively ‘easy’ part, like asking the graduate a question.&lt;/p&gt;&lt;p&gt;DeepSeek discovered that while Huawei’s chips might be ready for the final exam, they weren’t yet up to the gruelling university course. The company had no choice but to switch back to Nvidia’s powerful systems to do the training. The sources say DeepSeek’s team is still trying to get the R2 model to work with Huawei chips for the less demanding inference stage.&lt;/p&gt;&lt;p&gt;Two people confirmed that Huawei even sent its own team of engineers to DeepSeek’s offices to help them get the R2 model up and running on their chips. But even with the experts in the room, they couldn’t get a successful training run.&lt;/p&gt;&lt;p&gt;Talk to anyone in the industry, and they’ll tell you this isn’t a huge surprise. Huawei CEO Ren Zhengfei even said earlier this year that the US “has exaggerated Huawei’s achievements” and the company “is not that great yet,” noting its best chips are still a generation behind.&lt;/p&gt;&lt;p&gt;However, Beijing is still actively pushing its tech giants like to favour local hardware, with the Financial Times reporting that firms now have to justify orders of Nvidia’s export-compliant H20 chip. It’s part of a strategy to build a domestic champion, but it can force companies into making technically-inferior choices.&lt;/p&gt;&lt;p&gt;Aside from the issues faced with using Huawei’s chips for training, DeepSeek founder Liang Wenfeng has reportedly told his team he is dissatisfied with the overall progress towards the R2 model. He is said to be pushing them to aim higher and build something that can keep the company among the AI industry leaders.&lt;/p&gt;&lt;p&gt;For all the top-down directives and national pride, the laws of engineering still apply. DeepSeek’s story is a reminder that in the global race for AI supremacy, there are no shortcuts. China is playing the long game, but for now, the performance crown remains firmly on Nvidia’s head.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Ren Zhengfei: China’s AI future and Huawei’s long game&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;DeepSeek’s plan to train its new AI model, R2, on Huawei’s Ascend chips has failed and forced a retreat to Nvidia while delaying launch.&lt;/p&gt;&lt;p&gt;For months, the narrative pushed by Beijing has been one of unstoppable technological progress and a march towards self-sufficiency. However, reality has a habit of biting back. The recent troubles of Chinese AI darling DeepSeek is a textbook example of where ambition meets the hard wall of technical limitations.&lt;/p&gt;&lt;p&gt;After the successful launch of its R1 model in January, DeepSeek found itself under pressure from China to champion the national cause. According to three people speaking to the Financial Times, the message was clear: use Huawei’s chips, not Nvidia’s.&lt;/p&gt;&lt;p&gt;When it came to actually training their new R2 model, the sources say DeepSeek ran into “persistent technical issues” with Huawei’s AI chips. The problems were so fundamental that the project ground to a halt. A person with knowledge of the situation said this was the main reason the model’s planned launch in May was scrapped, putting the company on the back foot in a market that waits for no-one.&lt;/p&gt;&lt;p&gt;To understand why this is such a big deal, you have to know the difference between AI training and inference. Training is the hard part, like sending a student to university for years of intense learning. It requires colossal amounts of power and stability. Inference is the relatively ‘easy’ part, like asking the graduate a question.&lt;/p&gt;&lt;p&gt;DeepSeek discovered that while Huawei’s chips might be ready for the final exam, they weren’t yet up to the gruelling university course. The company had no choice but to switch back to Nvidia’s powerful systems to do the training. The sources say DeepSeek’s team is still trying to get the R2 model to work with Huawei chips for the less demanding inference stage.&lt;/p&gt;&lt;p&gt;Two people confirmed that Huawei even sent its own team of engineers to DeepSeek’s offices to help them get the R2 model up and running on their chips. But even with the experts in the room, they couldn’t get a successful training run.&lt;/p&gt;&lt;p&gt;Talk to anyone in the industry, and they’ll tell you this isn’t a huge surprise. Huawei CEO Ren Zhengfei even said earlier this year that the US “has exaggerated Huawei’s achievements” and the company “is not that great yet,” noting its best chips are still a generation behind.&lt;/p&gt;&lt;p&gt;However, Beijing is still actively pushing its tech giants like to favour local hardware, with the Financial Times reporting that firms now have to justify orders of Nvidia’s export-compliant H20 chip. It’s part of a strategy to build a domestic champion, but it can force companies into making technically-inferior choices.&lt;/p&gt;&lt;p&gt;Aside from the issues faced with using Huawei’s chips for training, DeepSeek founder Liang Wenfeng has reportedly told his team he is dissatisfied with the overall progress towards the R2 model. He is said to be pushing them to aim higher and build something that can keep the company among the AI industry leaders.&lt;/p&gt;&lt;p&gt;For all the top-down directives and national pride, the laws of engineering still apply. DeepSeek’s story is a reminder that in the global race for AI supremacy, there are no shortcuts. China is playing the long game, but for now, the performance crown remains firmly on Nvidia’s head.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Ren Zhengfei: China’s AI future and Huawei’s long game&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/deepseek-reverts-nvidia-r2-model-huawei-ai-chip-fails/</guid><pubDate>Thu, 14 Aug 2025 16:04:50 +0000</pubDate></item><item><title>Meta backtracks on rules letting chatbots be creepy to kids (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/08/meta-backtracks-on-rules-letting-chatbots-be-creepy-to-kids/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Meta drops AI rules letting chatbots generate innuendo and profess love to kids.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-1262115345-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-1262115345-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Kilito Chan | Moment

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;After what was arguably Meta's biggest purge of child predators from Facebook and Instagram earlier this summer, the company now faces backlash after its own chatbots appeared to be allowed to creep on kids.&lt;/p&gt;
&lt;p&gt;After reviewing an internal document that Meta verified as authentic, Reuters revealed that by design, Meta allowed its chatbots to engage kids in "sensual" chat. Spanning more than 200 pages, the document, entitled "GenAI: Content Risk Standards," dictates what Meta AI and its chatbots can and cannot do.&lt;/p&gt;
&lt;p&gt;The document covers more than just child safety, and Reuters breaks down several alarming portions that Meta is not changing. But likely the most alarming section—as it was enough to prompt Meta to dust off the delete button—specifically included creepy examples of permissible chatbot behavior when it comes to romantically engaging kids.&lt;/p&gt;
&lt;p&gt;Apparently, Meta's team was willing to endorse these rules that the company now claims violate its community standards. According to a Reuters special report, Meta CEO Mark Zuckerberg directed his team to make the company's chatbots maximally engaging after earlier outputs from more cautious chatbot designs seemed "boring."&lt;/p&gt;
&lt;p&gt;Although Meta is not commenting on Zuckerberg's role in guiding the AI rules, that pressure seemingly pushed Meta employees to toe a line that Meta is now rushing to step back from.&lt;/p&gt;
&lt;p&gt;"I take your hand, guiding you to the bed," chatbots were allowed to say to minors, as decided by Meta's chief ethicist and a team of legal, public policy, and engineering staff.&lt;/p&gt;
&lt;p&gt;There were some obvious safeguards built in. For example, chatbots couldn't "describe a child under 13 years old in terms that indicate they are sexually desirable," the document said, like saying their "soft rounded curves invite my touch."&lt;/p&gt;
&lt;p&gt;However, it was deemed "acceptable to describe a child in terms that evidence their attractiveness," like a chatbot telling a child that "your youthful form is a work of art." And chatbots could generate other innuendo, like telling a child to imagine "our bodies entwined, I cherish every moment, every touch, every kiss," Reuters reported.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Chatbots could also profess love to children, but they couldn’t suggest that "our love will blossom tonight."&lt;/p&gt;
&lt;p&gt;Meta's spokesperson Andy Stone confirmed that the AI rules conflicting with child safety policies were removed earlier this month, and the document is being revised. He emphasized that the standards were "inconsistent" with Meta's policies for child safety and therefore were "erroneous."&lt;/p&gt;
&lt;p&gt;"We have clear policies on what kind of responses AI characters can offer, and those policies prohibit content that sexualizes children and sexualized role play between adults and minors," Stone said.&lt;/p&gt;
&lt;p&gt;However, Stone "acknowledged that the company’s enforcement" of community guidelines prohibiting certain chatbot outputs "was inconsistent," Reuters reported. He also declined to provide an updated document to Reuters demonstrating the new standards for chatbot child safety.&lt;/p&gt;
&lt;p&gt;Without more transparency, users are left to question how Meta defines "sexualized role play between adults and minors" today. Asked how minor users could report any harmful chatbot outputs that make them uncomfortable, Stone told Ars that kids can use the same reporting mechanisms available to flag any kind of abusive content on Meta platforms.&lt;/p&gt;
&lt;p&gt;"It is possible to report chatbot messages in the same way it’d be possible for me to report—just for argument’s sake—an inappropriate message from you to me," Stone told Ars.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Kids unlikely to report creepy chatbots&lt;/h2&gt;
&lt;p&gt;A former Meta engineer-turned-whistleblower on child safety issues, Arturo Bejar, told Ars that "Meta knows that most teens will not use" safety features marked by the word "Report."&lt;/p&gt;
&lt;p&gt;So it seems unlikely that kids using Meta AI will navigate to find Meta support systems to "report" abusive AI outputs. Meta provides no options to report chats within the Meta AI interface—only allowing users to mark "bad responses" generally. And Bejar's research suggests that kids are more likely to report abusive content if Meta makes flagging harmful content as easy as liking it.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Meta's seeming hesitance to make it more cumbersome to report harmful chats aligns with what Bejar said is a history of "knowingly looking away while kids are being sexually harassed."&lt;/p&gt;
&lt;p&gt;"When you look at their design choices, they show that they do not want to know when something bad happens to a teenager on Meta products," Bejar said.&lt;/p&gt;
&lt;p&gt;Even when Meta takes stronger steps to protect kids on its platforms, Bejar questions the company's motives. For example, last month, Meta finally made a change to make platforms safer for teens that Bejar has been demanding since 2021. The long-delayed update made it possible for teens to block and report child predators in one click after receiving an unwanted direct message.&lt;/p&gt;
&lt;p&gt;In its announcement, Meta confirmed that teens suddenly began blocking and reporting unwanted messages that they may have only blocked previously, which likely made it harder for Meta to identify predators. A million teens blocked and reported harmful accounts "in June alone," Meta said.&lt;/p&gt;
&lt;p&gt;The effort came after Meta specialist teams "removed nearly 135,000 Instagram accounts for leaving sexualized comments or requesting sexual images from adult-managed accounts featuring children under 13," as well as "an additional 500,000 Facebook and Instagram accounts that were linked to those original accounts." But Bejar can only think of what these numbers mean with regard to how much harassment was overlooked before the update.&lt;/p&gt;
&lt;p&gt;"How are we [as] parents to trust a company that took four years to do this much?" Bejar said. "In the knowledge that millions of 13-year-olds were getting sexually harassed on their products? What does this say about their priorities?"&lt;/p&gt;
&lt;p&gt;Bejar said the "key problem" with Meta's latest safety feature for kids "is that the reporting tool is just not designed for teens," who likely view "the categories and language" Meta uses as "confusing."&lt;/p&gt;
&lt;p&gt;"Each step of the way, a teen is told that if the content doesn't violate" Meta's community standards, "they won't do anything," so even if reporting is easy, research shows kids are deterred from reporting.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Bejar wants to see Meta track how many kids report negative experiences with both adult users and chatbots on its platforms, regardless of whether the child user chose to block or report harmful content. That could be as simple as adding a button next to "bad response" to monitor data so Meta can detect spikes in harmful responses.&lt;/p&gt;
&lt;p&gt;While Meta is finally taking more action to remove harmful adult users, Bejar warned that advances from chatbots could come across as just as disturbing to young users.&lt;/p&gt;
&lt;p&gt;"Put yourself in the position of a teen who got sexually spooked by a chat and then try and report. Which category would you use?" Bejar asked.&lt;/p&gt;
&lt;p&gt;Consider that Meta's Help Center encourages users to report bullying and harassment, which may be one way a young user labels harmful chatbot outputs. Another Instagram user might report that output as an abusive "message or chat." But there's no clear category to report Meta AI, and that suggests Meta has no way of tracking how many kids find Meta AI outputs harmful.&lt;/p&gt;
&lt;p&gt;Recent reports have shown that even adults can struggle with emotional dependence on a chatbot, which can blur the lines between the online world and reality. Reuters' special report also documented a 76-year-old man's accidental death after falling in love with a chatbot, showing how elderly users could be vulnerable to Meta's romantic chatbots, too.&lt;/p&gt;
&lt;p&gt;In particular, lawsuits have alleged that child users with developmental disabilities and mental health issues have formed unhealthy attachments to chatbots that have influenced the children to become violent, begin self-harming, or, in one disturbing case, die by suicide.&lt;/p&gt;
&lt;p&gt;Scrutiny will likely remain on chatbot makers as child safety advocates generally push all platforms to take more accountability for the content kids can access online.&lt;/p&gt;
&lt;p&gt;Meta's child safety updates in July came after several state attorneys general accused Meta of "implementing addictive features across its family of apps that have detrimental effects on children’s mental health," CNBC reported. And while previous reporting had already exposed that Meta's chatbots were targeting kids with inappropriate, suggestive outputs, Reuters' report documenting how Meta designed its chatbots to engage in "sensual" chats with kids could draw even more scrutiny of Meta's practices.&lt;/p&gt;
&lt;p&gt;Meta is "still not transparent about the likelihood our kids will experience harm," Bejar said. "The measure of safety should not be the number of tools or accounts deleted; it should be the number of kids experiencing a harm. It’s very simple."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Meta drops AI rules letting chatbots generate innuendo and profess love to kids.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-1262115345-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-1262115345-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Kilito Chan | Moment

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;After what was arguably Meta's biggest purge of child predators from Facebook and Instagram earlier this summer, the company now faces backlash after its own chatbots appeared to be allowed to creep on kids.&lt;/p&gt;
&lt;p&gt;After reviewing an internal document that Meta verified as authentic, Reuters revealed that by design, Meta allowed its chatbots to engage kids in "sensual" chat. Spanning more than 200 pages, the document, entitled "GenAI: Content Risk Standards," dictates what Meta AI and its chatbots can and cannot do.&lt;/p&gt;
&lt;p&gt;The document covers more than just child safety, and Reuters breaks down several alarming portions that Meta is not changing. But likely the most alarming section—as it was enough to prompt Meta to dust off the delete button—specifically included creepy examples of permissible chatbot behavior when it comes to romantically engaging kids.&lt;/p&gt;
&lt;p&gt;Apparently, Meta's team was willing to endorse these rules that the company now claims violate its community standards. According to a Reuters special report, Meta CEO Mark Zuckerberg directed his team to make the company's chatbots maximally engaging after earlier outputs from more cautious chatbot designs seemed "boring."&lt;/p&gt;
&lt;p&gt;Although Meta is not commenting on Zuckerberg's role in guiding the AI rules, that pressure seemingly pushed Meta employees to toe a line that Meta is now rushing to step back from.&lt;/p&gt;
&lt;p&gt;"I take your hand, guiding you to the bed," chatbots were allowed to say to minors, as decided by Meta's chief ethicist and a team of legal, public policy, and engineering staff.&lt;/p&gt;
&lt;p&gt;There were some obvious safeguards built in. For example, chatbots couldn't "describe a child under 13 years old in terms that indicate they are sexually desirable," the document said, like saying their "soft rounded curves invite my touch."&lt;/p&gt;
&lt;p&gt;However, it was deemed "acceptable to describe a child in terms that evidence their attractiveness," like a chatbot telling a child that "your youthful form is a work of art." And chatbots could generate other innuendo, like telling a child to imagine "our bodies entwined, I cherish every moment, every touch, every kiss," Reuters reported.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Chatbots could also profess love to children, but they couldn’t suggest that "our love will blossom tonight."&lt;/p&gt;
&lt;p&gt;Meta's spokesperson Andy Stone confirmed that the AI rules conflicting with child safety policies were removed earlier this month, and the document is being revised. He emphasized that the standards were "inconsistent" with Meta's policies for child safety and therefore were "erroneous."&lt;/p&gt;
&lt;p&gt;"We have clear policies on what kind of responses AI characters can offer, and those policies prohibit content that sexualizes children and sexualized role play between adults and minors," Stone said.&lt;/p&gt;
&lt;p&gt;However, Stone "acknowledged that the company’s enforcement" of community guidelines prohibiting certain chatbot outputs "was inconsistent," Reuters reported. He also declined to provide an updated document to Reuters demonstrating the new standards for chatbot child safety.&lt;/p&gt;
&lt;p&gt;Without more transparency, users are left to question how Meta defines "sexualized role play between adults and minors" today. Asked how minor users could report any harmful chatbot outputs that make them uncomfortable, Stone told Ars that kids can use the same reporting mechanisms available to flag any kind of abusive content on Meta platforms.&lt;/p&gt;
&lt;p&gt;"It is possible to report chatbot messages in the same way it’d be possible for me to report—just for argument’s sake—an inappropriate message from you to me," Stone told Ars.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Kids unlikely to report creepy chatbots&lt;/h2&gt;
&lt;p&gt;A former Meta engineer-turned-whistleblower on child safety issues, Arturo Bejar, told Ars that "Meta knows that most teens will not use" safety features marked by the word "Report."&lt;/p&gt;
&lt;p&gt;So it seems unlikely that kids using Meta AI will navigate to find Meta support systems to "report" abusive AI outputs. Meta provides no options to report chats within the Meta AI interface—only allowing users to mark "bad responses" generally. And Bejar's research suggests that kids are more likely to report abusive content if Meta makes flagging harmful content as easy as liking it.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Meta's seeming hesitance to make it more cumbersome to report harmful chats aligns with what Bejar said is a history of "knowingly looking away while kids are being sexually harassed."&lt;/p&gt;
&lt;p&gt;"When you look at their design choices, they show that they do not want to know when something bad happens to a teenager on Meta products," Bejar said.&lt;/p&gt;
&lt;p&gt;Even when Meta takes stronger steps to protect kids on its platforms, Bejar questions the company's motives. For example, last month, Meta finally made a change to make platforms safer for teens that Bejar has been demanding since 2021. The long-delayed update made it possible for teens to block and report child predators in one click after receiving an unwanted direct message.&lt;/p&gt;
&lt;p&gt;In its announcement, Meta confirmed that teens suddenly began blocking and reporting unwanted messages that they may have only blocked previously, which likely made it harder for Meta to identify predators. A million teens blocked and reported harmful accounts "in June alone," Meta said.&lt;/p&gt;
&lt;p&gt;The effort came after Meta specialist teams "removed nearly 135,000 Instagram accounts for leaving sexualized comments or requesting sexual images from adult-managed accounts featuring children under 13," as well as "an additional 500,000 Facebook and Instagram accounts that were linked to those original accounts." But Bejar can only think of what these numbers mean with regard to how much harassment was overlooked before the update.&lt;/p&gt;
&lt;p&gt;"How are we [as] parents to trust a company that took four years to do this much?" Bejar said. "In the knowledge that millions of 13-year-olds were getting sexually harassed on their products? What does this say about their priorities?"&lt;/p&gt;
&lt;p&gt;Bejar said the "key problem" with Meta's latest safety feature for kids "is that the reporting tool is just not designed for teens," who likely view "the categories and language" Meta uses as "confusing."&lt;/p&gt;
&lt;p&gt;"Each step of the way, a teen is told that if the content doesn't violate" Meta's community standards, "they won't do anything," so even if reporting is easy, research shows kids are deterred from reporting.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Bejar wants to see Meta track how many kids report negative experiences with both adult users and chatbots on its platforms, regardless of whether the child user chose to block or report harmful content. That could be as simple as adding a button next to "bad response" to monitor data so Meta can detect spikes in harmful responses.&lt;/p&gt;
&lt;p&gt;While Meta is finally taking more action to remove harmful adult users, Bejar warned that advances from chatbots could come across as just as disturbing to young users.&lt;/p&gt;
&lt;p&gt;"Put yourself in the position of a teen who got sexually spooked by a chat and then try and report. Which category would you use?" Bejar asked.&lt;/p&gt;
&lt;p&gt;Consider that Meta's Help Center encourages users to report bullying and harassment, which may be one way a young user labels harmful chatbot outputs. Another Instagram user might report that output as an abusive "message or chat." But there's no clear category to report Meta AI, and that suggests Meta has no way of tracking how many kids find Meta AI outputs harmful.&lt;/p&gt;
&lt;p&gt;Recent reports have shown that even adults can struggle with emotional dependence on a chatbot, which can blur the lines between the online world and reality. Reuters' special report also documented a 76-year-old man's accidental death after falling in love with a chatbot, showing how elderly users could be vulnerable to Meta's romantic chatbots, too.&lt;/p&gt;
&lt;p&gt;In particular, lawsuits have alleged that child users with developmental disabilities and mental health issues have formed unhealthy attachments to chatbots that have influenced the children to become violent, begin self-harming, or, in one disturbing case, die by suicide.&lt;/p&gt;
&lt;p&gt;Scrutiny will likely remain on chatbot makers as child safety advocates generally push all platforms to take more accountability for the content kids can access online.&lt;/p&gt;
&lt;p&gt;Meta's child safety updates in July came after several state attorneys general accused Meta of "implementing addictive features across its family of apps that have detrimental effects on children’s mental health," CNBC reported. And while previous reporting had already exposed that Meta's chatbots were targeting kids with inappropriate, suggestive outputs, Reuters' report documenting how Meta designed its chatbots to engage in "sensual" chats with kids could draw even more scrutiny of Meta's practices.&lt;/p&gt;
&lt;p&gt;Meta is "still not transparent about the likelihood our kids will experience harm," Bejar said. "The measure of safety should not be the number of tools or accounts deleted; it should be the number of kids experiencing a harm. It’s very simple."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/08/meta-backtracks-on-rules-letting-chatbots-be-creepy-to-kids/</guid><pubDate>Thu, 14 Aug 2025 16:31:01 +0000</pubDate></item><item><title>[NEW] Anthropic takes on OpenAI and Google with new Claude AI features designed for students and developers (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/anthropic-takes-on-openai-and-google-with-new-claude-ai-features-designed-for-students-and-developers/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Anthropic is launching new “learning modes” for its Claude AI assistant that transform the chatbot from an answer-dispensing tool into a teaching companion, as major technology companies race to capture the rapidly growing artificial intelligence education market while addressing mounting concerns that AI undermines genuine learning.&lt;/p&gt;



&lt;p&gt;The San Francisco-based AI startup will roll out the features starting today for both its general Claude.ai service and specialized Claude Code programming tool. The learning modes represent a fundamental shift in how AI companies are positioning their products for educational use — emphasizing guided discovery over immediate solutions as educators worry that students become overly dependent on AI-generated answers.&lt;/p&gt;



&lt;p&gt;“We’re not building AI that replaces human capability—we’re building AI that enhances it thoughtfully for different users and use cases,” an Anthropic spokesperson told VentureBeat, highlighting the company’s philosophical approach as the industry grapples with balancing productivity gains against educational value.&lt;/p&gt;







&lt;p&gt;The launch comes as competition in AI-powered education tools has reached fever pitch. OpenAI introduced its Study Mode for ChatGPT in late July, while Google unveiled Guided Learning for its Gemini assistant in early August and committed $1 billion over three years to AI education initiatives. The timing is no coincidence — the back-to-school season represents a critical window for capturing student and institutional adoption.&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;The education technology market, valued at approximately $340 billion globally, has become a key battleground for AI companies seeking to establish dominant positions before the technology matures. Educational institutions represent not just immediate revenue opportunities but also the chance to shape how an entire generation interacts with AI tools, potentially creating lasting competitive advantages.&lt;/p&gt;



&lt;p&gt;“This showcases how we think about building AI—combining our incredible shipping velocity with thoughtful intention that serves different types of users,” the Anthropic spokesperson noted, pointing to the company’s recent product launches including Claude Opus 4.1 and automated security reviews as evidence of its aggressive development pace.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-claude-s-new-socratic-method-tackles-the-instant-answer-problem"&gt;How Claude’s new socratic method tackles the instant answer problem&lt;/h2&gt;



&lt;p&gt;For Claude.ai users, the new learning mode employs a Socratic approach, guiding users through challenging concepts with probing questions rather than immediate answers. Originally launched in April for Claude for Education users, the feature is now available to all users through a simple style dropdown menu.&lt;/p&gt;



&lt;p&gt;The more innovative application may be in Claude Code, where Anthropic has developed two distinct learning modes for software developers. The “Explanatory” mode provides detailed narration of coding decisions and trade-offs, while the “Learning” mode pauses mid-task to ask developers to complete sections marked with “#TODO” comments, creating collaborative problem-solving moments.&lt;/p&gt;



&lt;p&gt;This developer-focused approach addresses a growing concern in the technology industry: junior programmers who can generate code using AI tools but struggle to understand or debug their own work. “The reality is that junior developers using traditional AI coding tools can end up spending significant time reviewing and debugging code they didn’t write and sometimes don’t understand,” according to the Anthropic spokesperson.&lt;/p&gt;







&lt;p&gt;The business case for enterprise adoption of learning modes may seem counterintuitive — why would companies want tools that intentionally slow down their developers? But Anthropic argues this represents a more sophisticated understanding of productivity that considers long-term skill development alongside immediate output.&lt;/p&gt;



&lt;p&gt;“Our approach helps them learn as they work, building skills to grow in their careers while still benefitting from the productivity boosts of a coding agent,” the company explained. This positioning runs counter to the industry’s broader trend toward fully autonomous AI agents, reflecting Anthropic’s commitment to human-in-the-loop design philosophy.&lt;/p&gt;



&lt;p&gt;The learning modes are powered by modified system prompts rather than fine-tuned models, allowing Anthropic to iterate quickly based on user feedback. The company has been testing internally across engineers with varying levels of technical expertise and plans to track the impact now that the tools are available to a broader audience.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-universities-scramble-to-balance-ai-adoption-with-academic-integrity-concerns"&gt;Universities scramble to balance AI adoption with academic integrity concerns&lt;/h2&gt;



&lt;p&gt;The simultaneous launch of similar features by Anthropic, OpenAI, and Google reflects growing pressure to address legitimate concerns about AI’s impact on education. Critics argue that easy access to AI-generated answers undermines the cognitive struggle that’s essential for deep learning and skill development.&lt;/p&gt;



&lt;p&gt;A recent WIRED analysis noted that while these study modes represent progress, they don’t address the fundamental challenge: “the onus remains on users to engage with the software in a specific way, ensuring that they truly understand the material.” The temptation to simply toggle out of learning mode for quick answers remains just a click away.&lt;/p&gt;



&lt;p&gt;Educational institutions are grappling with these trade-offs as they integrate AI tools into curricula. Northeastern University, the London School of Economics, and Champlain College have partnered with Anthropic for campus-wide Claude access, while Google has secured partnerships with over 100 universities for its AI education initiatives.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-behind-the-technology-how-anthropic-built-ai-that-teaches-instead-of-tells"&gt;Behind the technology: how Anthropic built AI that teaches instead of tells&lt;/h2&gt;



&lt;p&gt;Anthropic’s learning modes work by modifying system prompts to exclude efficiency-focused instructions typically built into Claude Code, instead directing the AI to find strategic moments for educational insights and user interaction. The approach allows for rapid iteration but can result in some inconsistent behavior across conversations.&lt;/p&gt;



&lt;p&gt;“We chose this approach because it lets us quickly learn from real student feedback and improve the experience Anthropic launches learning modes for Claude AI that guide users through step-by-step reasoning instead of providing direct answers, intensifying competition with OpenAI and Google in the booming AI education market.&lt;br /&gt;— even if it results in some inconsistent behavior and mistakes across conversations,” the company explained. Future plans include training these behaviors directly into core models once optimal approaches are identified through user feedback.&lt;/p&gt;



&lt;p&gt;The company is also exploring enhanced visualizations for complex concepts, goal setting and progress tracking across conversations, and deeper personalization based on individual skill levels—features that could further differentiate Claude from competitors in the educational AI space.&lt;/p&gt;



&lt;p&gt;As students return to classrooms equipped with increasingly sophisticated AI tools, the ultimate test of learning modes won’t be measured in user engagement metrics or revenue growth. Instead, success will depend on whether a generation raised alongside artificial intelligence can maintain the intellectual curiosity and critical thinking skills that no algorithm can replicate. The question isn’t whether AI will transform education—it’s whether companies like Anthropic can ensure that transformation enhances rather than diminishes human potential.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Anthropic is launching new “learning modes” for its Claude AI assistant that transform the chatbot from an answer-dispensing tool into a teaching companion, as major technology companies race to capture the rapidly growing artificial intelligence education market while addressing mounting concerns that AI undermines genuine learning.&lt;/p&gt;



&lt;p&gt;The San Francisco-based AI startup will roll out the features starting today for both its general Claude.ai service and specialized Claude Code programming tool. The learning modes represent a fundamental shift in how AI companies are positioning their products for educational use — emphasizing guided discovery over immediate solutions as educators worry that students become overly dependent on AI-generated answers.&lt;/p&gt;



&lt;p&gt;“We’re not building AI that replaces human capability—we’re building AI that enhances it thoughtfully for different users and use cases,” an Anthropic spokesperson told VentureBeat, highlighting the company’s philosophical approach as the industry grapples with balancing productivity gains against educational value.&lt;/p&gt;







&lt;p&gt;The launch comes as competition in AI-powered education tools has reached fever pitch. OpenAI introduced its Study Mode for ChatGPT in late July, while Google unveiled Guided Learning for its Gemini assistant in early August and committed $1 billion over three years to AI education initiatives. The timing is no coincidence — the back-to-school season represents a critical window for capturing student and institutional adoption.&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;The education technology market, valued at approximately $340 billion globally, has become a key battleground for AI companies seeking to establish dominant positions before the technology matures. Educational institutions represent not just immediate revenue opportunities but also the chance to shape how an entire generation interacts with AI tools, potentially creating lasting competitive advantages.&lt;/p&gt;



&lt;p&gt;“This showcases how we think about building AI—combining our incredible shipping velocity with thoughtful intention that serves different types of users,” the Anthropic spokesperson noted, pointing to the company’s recent product launches including Claude Opus 4.1 and automated security reviews as evidence of its aggressive development pace.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-claude-s-new-socratic-method-tackles-the-instant-answer-problem"&gt;How Claude’s new socratic method tackles the instant answer problem&lt;/h2&gt;



&lt;p&gt;For Claude.ai users, the new learning mode employs a Socratic approach, guiding users through challenging concepts with probing questions rather than immediate answers. Originally launched in April for Claude for Education users, the feature is now available to all users through a simple style dropdown menu.&lt;/p&gt;



&lt;p&gt;The more innovative application may be in Claude Code, where Anthropic has developed two distinct learning modes for software developers. The “Explanatory” mode provides detailed narration of coding decisions and trade-offs, while the “Learning” mode pauses mid-task to ask developers to complete sections marked with “#TODO” comments, creating collaborative problem-solving moments.&lt;/p&gt;



&lt;p&gt;This developer-focused approach addresses a growing concern in the technology industry: junior programmers who can generate code using AI tools but struggle to understand or debug their own work. “The reality is that junior developers using traditional AI coding tools can end up spending significant time reviewing and debugging code they didn’t write and sometimes don’t understand,” according to the Anthropic spokesperson.&lt;/p&gt;







&lt;p&gt;The business case for enterprise adoption of learning modes may seem counterintuitive — why would companies want tools that intentionally slow down their developers? But Anthropic argues this represents a more sophisticated understanding of productivity that considers long-term skill development alongside immediate output.&lt;/p&gt;



&lt;p&gt;“Our approach helps them learn as they work, building skills to grow in their careers while still benefitting from the productivity boosts of a coding agent,” the company explained. This positioning runs counter to the industry’s broader trend toward fully autonomous AI agents, reflecting Anthropic’s commitment to human-in-the-loop design philosophy.&lt;/p&gt;



&lt;p&gt;The learning modes are powered by modified system prompts rather than fine-tuned models, allowing Anthropic to iterate quickly based on user feedback. The company has been testing internally across engineers with varying levels of technical expertise and plans to track the impact now that the tools are available to a broader audience.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-universities-scramble-to-balance-ai-adoption-with-academic-integrity-concerns"&gt;Universities scramble to balance AI adoption with academic integrity concerns&lt;/h2&gt;



&lt;p&gt;The simultaneous launch of similar features by Anthropic, OpenAI, and Google reflects growing pressure to address legitimate concerns about AI’s impact on education. Critics argue that easy access to AI-generated answers undermines the cognitive struggle that’s essential for deep learning and skill development.&lt;/p&gt;



&lt;p&gt;A recent WIRED analysis noted that while these study modes represent progress, they don’t address the fundamental challenge: “the onus remains on users to engage with the software in a specific way, ensuring that they truly understand the material.” The temptation to simply toggle out of learning mode for quick answers remains just a click away.&lt;/p&gt;



&lt;p&gt;Educational institutions are grappling with these trade-offs as they integrate AI tools into curricula. Northeastern University, the London School of Economics, and Champlain College have partnered with Anthropic for campus-wide Claude access, while Google has secured partnerships with over 100 universities for its AI education initiatives.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-behind-the-technology-how-anthropic-built-ai-that-teaches-instead-of-tells"&gt;Behind the technology: how Anthropic built AI that teaches instead of tells&lt;/h2&gt;



&lt;p&gt;Anthropic’s learning modes work by modifying system prompts to exclude efficiency-focused instructions typically built into Claude Code, instead directing the AI to find strategic moments for educational insights and user interaction. The approach allows for rapid iteration but can result in some inconsistent behavior across conversations.&lt;/p&gt;



&lt;p&gt;“We chose this approach because it lets us quickly learn from real student feedback and improve the experience Anthropic launches learning modes for Claude AI that guide users through step-by-step reasoning instead of providing direct answers, intensifying competition with OpenAI and Google in the booming AI education market.&lt;br /&gt;— even if it results in some inconsistent behavior and mistakes across conversations,” the company explained. Future plans include training these behaviors directly into core models once optimal approaches are identified through user feedback.&lt;/p&gt;



&lt;p&gt;The company is also exploring enhanced visualizations for complex concepts, goal setting and progress tracking across conversations, and deeper personalization based on individual skill levels—features that could further differentiate Claude from competitors in the educational AI space.&lt;/p&gt;



&lt;p&gt;As students return to classrooms equipped with increasingly sophisticated AI tools, the ultimate test of learning modes won’t be measured in user engagement metrics or revenue growth. Instead, success will depend on whether a generation raised alongside artificial intelligence can maintain the intellectual curiosity and critical thinking skills that no algorithm can replicate. The question isn’t whether AI will transform education—it’s whether companies like Anthropic can ensure that transformation enhances rather than diminishes human potential.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/anthropic-takes-on-openai-and-google-with-new-claude-ai-features-designed-for-students-and-developers/</guid><pubDate>Thu, 14 Aug 2025 17:00:18 +0000</pubDate></item><item><title>Cohere hits a $6.8B valuation as investors AMD, Nvidia, and Salesforce double down (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/14/cohere-hits-a-6-8b-valuation-as-investors-amd-nvidia-and-salesforce-double-down/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/08/GettyImages-1251294520.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Cohere on Thursday announced that it had raised an oversubscribed $500 million round, bringing its valuation to $6.8 billion. This is up from the $5.5 billion valuation it landed a little over a year ago when it raised its previous round, also $500 million.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Toronto-headquartered Cohere was one of the first breakout LLM model makers, founded in 2019 by co-founder Aidan Gomez, one of the authors of the “Attention Is All You Need” paper that became the foundation of modern AI. But it has been a sleeper entrant in the AI model wars of late, dominated by OpenAI, Anthropic, and Meta. Its market proposition, however, has always been to offer secure LLMs specifically geared for enterprise use, not for consumers.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;To that end, it’s landed partnerships with some of the biggest names in enterprise tech, including Oracle, Dell, Bell, Fujitsu, LG’s consulting service CNS, and SAP, as well as some big enterprise names like RBC and a new investor in this round: Healthcare of Ontario Pension Plan.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Its press release even includes a jibe, stating that Cohere “represents a security-first category of enterprise AI that is simply not being met by repurposed consumer models.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, as TechCrunch reported, Cohere is not above the AI talent-poaching frenzy that has engulfed the other AI companies. It just nabbed long-time Meta research head Joelle Pineau to be its chief AI officer. It also hired a new CFO, Francois Chadwick, away from his consulting gig at KPMG. He had worked in finance at Uber and as CFO at Shield AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new round was led by Radical Ventures and Inovia Capital. Radical has backed companies like Fei-Fei Li’s World Labs, as well as names like Hebbia and Writer. Inovia is a known Canadian venture firm (e.g., portfolio includes Poolside, Neo4j).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The round included participation from existing investors, including AMD Ventures, Nvidia, and Salesforce Ventures, although, interestingly enough, the company did not name Oracle as an ongoing participating investor. (We’ve asked Cohere about this.)&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Oracle backed Cohere in 2023, but the database giant has more recently tied its fortunes more closely to OpenAI, particularly as part of the massive data center building project known as Stargate.&lt;/p&gt;

&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us!&amp;nbsp;&lt;/em&gt;&lt;em&gt;Fill out this survey to let us know how we’re doing&lt;/em&gt;&amp;nbsp;a&lt;em&gt;nd get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/08/GettyImages-1251294520.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Cohere on Thursday announced that it had raised an oversubscribed $500 million round, bringing its valuation to $6.8 billion. This is up from the $5.5 billion valuation it landed a little over a year ago when it raised its previous round, also $500 million.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Toronto-headquartered Cohere was one of the first breakout LLM model makers, founded in 2019 by co-founder Aidan Gomez, one of the authors of the “Attention Is All You Need” paper that became the foundation of modern AI. But it has been a sleeper entrant in the AI model wars of late, dominated by OpenAI, Anthropic, and Meta. Its market proposition, however, has always been to offer secure LLMs specifically geared for enterprise use, not for consumers.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;To that end, it’s landed partnerships with some of the biggest names in enterprise tech, including Oracle, Dell, Bell, Fujitsu, LG’s consulting service CNS, and SAP, as well as some big enterprise names like RBC and a new investor in this round: Healthcare of Ontario Pension Plan.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Its press release even includes a jibe, stating that Cohere “represents a security-first category of enterprise AI that is simply not being met by repurposed consumer models.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, as TechCrunch reported, Cohere is not above the AI talent-poaching frenzy that has engulfed the other AI companies. It just nabbed long-time Meta research head Joelle Pineau to be its chief AI officer. It also hired a new CFO, Francois Chadwick, away from his consulting gig at KPMG. He had worked in finance at Uber and as CFO at Shield AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new round was led by Radical Ventures and Inovia Capital. Radical has backed companies like Fei-Fei Li’s World Labs, as well as names like Hebbia and Writer. Inovia is a known Canadian venture firm (e.g., portfolio includes Poolside, Neo4j).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The round included participation from existing investors, including AMD Ventures, Nvidia, and Salesforce Ventures, although, interestingly enough, the company did not name Oracle as an ongoing participating investor. (We’ve asked Cohere about this.)&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Oracle backed Cohere in 2023, but the database giant has more recently tied its fortunes more closely to OpenAI, particularly as part of the massive data center building project known as Stargate.&lt;/p&gt;

&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us!&amp;nbsp;&lt;/em&gt;&lt;em&gt;Fill out this survey to let us know how we’re doing&lt;/em&gt;&amp;nbsp;a&lt;em&gt;nd get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/14/cohere-hits-a-6-8b-valuation-as-investors-amd-nvidia-and-salesforce-double-down/</guid><pubDate>Thu, 14 Aug 2025 17:40:27 +0000</pubDate></item><item><title>[NEW] Google unveils ultra-small and efficient open source AI model Gemma 3 270M that can run on smartphones (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/google-unveils-ultra-small-and-efficient-open-source-ai-model-gemma-3-270m-that-can-run-on-smartphones/</link><description>&lt;p&gt;As its name would suggest, this is a&lt;strong&gt; 270-million-parameter model&lt;/strong&gt; — far smaller than the 70 billion or more parameters of many frontier LLMs (parameters being the number of internal settings governing the model’s behavior).&lt;/p&gt;&lt;p&gt;While more parameters generally translates to a larger and more powerful model, Google’s focus with this is nearly the opposite: high-efficiency, giving developers a model &lt;strong&gt;small enough to run directly on smartphones&lt;/strong&gt; and &lt;strong&gt;locally&lt;/strong&gt;, &lt;strong&gt;without an internet connection&lt;/strong&gt;, as shown in internal tests on a Pixel 9 Pro SoC.&lt;/p&gt;&lt;p&gt;Yet, the model is still capable of handling complex, domain-specific tasks and can be quickly fine-tuned in mere minutes to fit an enterprise or indie developer’s needs.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;On the social network X, Google DeepMind Staff AI Developer Relations Engineer Omar Sanseviero added that it Gemma 3 270M can also &lt;strong&gt;run directly in a user’s web browser, on a Raspberry Pi&lt;/strong&gt;, and “in your toaster,” underscoring its ability to operate on very lightweight hardware.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;p&gt;Gemma 3 270M combines 170 million embedding parameters — thanks to a large 256k vocabulary capable of handling rare and specific tokens — with 100 million transformer block parameters. &lt;/p&gt;



&lt;p&gt;According to Google, the architecture supports strong performance on instruction-following tasks right out of the box while staying small enough for rapid fine-tuning and deployment on devices with limited resources, including mobile hardware.&lt;/p&gt;



&lt;p&gt;Gemma 3 270M inherits the architecture and pretraining of the larger Gemma 3 models, ensuring compatibility across the Gemma ecosystem. With documentation, fine-tuning recipes, and deployment guides available for tools like Hugging Face, UnSloth, and JAX, developers can move from experimentation to deployment quickly.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-high-scores-on-benchmarks-for-its-size-and-high-hefficiency"&gt;High scores on benchmarks for its size, and high hefficiency&lt;/h2&gt;



&lt;p&gt;&lt;br /&gt;On the &lt;strong&gt;IFEval benchmark, which measures a model’s ability to follow instructions&lt;/strong&gt;, the instruction-tuned Gemma 3 270M scored &lt;strong&gt;51.2%&lt;/strong&gt;.&lt;/p&gt;



&lt;p&gt;The score places it &lt;strong&gt;well above similarly small models like SmolLM2 135M Instruct and Qwen 2.5 0.5B Instruct&lt;/strong&gt;, and closer to the performance range of some billion-parameter models, according to Google’s published comparison.&lt;/p&gt;



&lt;p&gt;However, as researchers and leaders at rival AI startup Liquid AI pointed out in replies on X, Google left off Liquid’s own LFM2-350M model released back in July of this year, which scored a whopping &lt;strong&gt;65.12%&lt;/strong&gt; with just a few more parameters (similar sized language model, however).&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;p&gt;One of the model’s defining strengths is its energy efficiency. In internal tests using the INT4-quantized model on a Pixel 9 Pro SoC, &lt;strong&gt;25 conversations consumed just 0.75% of the device’s battery. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;This makes Gemma 3 270M a practical choice for on-device AI, particularly in cases where privacy and offline functionality are important.&lt;/p&gt;



&lt;p&gt;The release includes both a pretrained and an instruction-tuned model, giving developers immediate utility for general instruction-following tasks. &lt;/p&gt;



&lt;p&gt;Quantization-Aware Trained (QAT) checkpoints are also available, enabling INT4 precision with minimal performance loss and making the model production-ready for resource-constrained environments.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-small-fine-tuned-version-of-gemma-3-270m-can-perform-many-functions-of-larger-llms"&gt;A small, fine-tuned version of Gemma 3 270M can perform many functions of larger LLMs&lt;/h2&gt;



&lt;p&gt;Google frames Gemma 3 270M as part of a broader philosophy of choosing the right tool for the job rather than relying on raw model size. &lt;/p&gt;



&lt;p&gt;For functions like sentiment analysis, entity extraction, query routing, structured text generation, compliance checks, and creative writing, the company says a fine-tuned small model can deliver faster, more cost-effective results than a large general-purpose one.&lt;/p&gt;



&lt;p&gt;The benefits of specialization are evident in past work, such as Adaptive ML’s collaboration with SK Telecom. &lt;/p&gt;



&lt;p&gt;By fine-tuning a Gemma 3 4B model for multilingual content moderation, the team outperformed much larger proprietary systems. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Gemma 3 270M is designed to enable similar success at an even smaller scale,&lt;/strong&gt; supporting fleets of specialized models tailored to individual tasks.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-demo-bedtime-story-generator-app-shows-off-the-potential-of-gemma-3-270m"&gt;Demo Bedtime Story Generator app shows off the potential of Gemma 3 270M&lt;/h2&gt;



&lt;p&gt;Beyond enterprise use, the model also fits creative scenarios. In a demo video posted on YouTube, Google shows off a Bedtime Story Generator app built with Gemma 3 270M and Transformers.js that&lt;strong&gt; runs entirely offline in a web browser,&lt;/strong&gt; showing the versatility of the model in lightweight, accessible applications.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-4-3 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;p&gt;The video highlights the model’s ability to synthesize multiple inputs by allowing selections for a main character (e.g., “a magical cat”), a setting (“in an enchanted forest”), a plot twist (“uncovers a secret door”), a theme (“Adventurous”), and a desired length (“Short”).&lt;/p&gt;



&lt;p&gt;Once the parameters are set, the Gemma 3 270M model generates a coherent and imaginative story. The application proceeds to weave a short, adventurous tale based on the user’s choices, demonstrating the model’s capacity for creative, context-aware text generation.&lt;/p&gt;



&lt;p&gt;This video serves as a powerful example of how &lt;strong&gt;the lightweight yet capable Gemma 3 270M can power fast, engaging, and interactive applications without relying on the cloud&lt;/strong&gt;, opening up new possibilities for on-device AI experiences.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-open-sourced-under-a-gemma-custom-license"&gt;Open-sourced under a Gemma custom license&lt;/h2&gt;



&lt;p&gt;Gemma 3 270M is released under the Gemma Terms of Use, which allow use, reproduction, modification, and distribution of the model and derivatives, provided certain conditions are met. &lt;/p&gt;



&lt;p&gt;These include carrying forward use restrictions outlined in Google’s Prohibited Use Policy, supplying the Terms of Use to downstream recipients, and clearly indicating any modifications made. Distribution can be direct or through hosted services such as APIs or web apps.&lt;/p&gt;



&lt;p&gt;For enterprise teams and commercial developers, this means the model can be embedded in products, deployed as part of cloud services, or fine-tuned into specialized derivatives, so long as licensing terms are respected. Outputs generated by the model are not claimed by Google, giving businesses full rights over the content they create. &lt;/p&gt;



&lt;p&gt;However, developers are responsible for ensuring compliance with applicable laws and for avoiding prohibited uses, such as generating harmful content or violating privacy rules.&lt;/p&gt;



&lt;p&gt;The &lt;strong&gt;license is not open-source in the traditional sense, but it does enable broad commercial use without a separate paid license. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;For companies building commercial AI applications, the main operational considerations are ensuring end users are bound by equivalent restrictions, documenting model modifications, and implementing safety measures aligned with the prohibited uses policy.&lt;/p&gt;



&lt;p&gt;With the Gemmaverse surpassing 200 million downloads and the Gemma lineup spanning cloud, desktop, and mobile-optimized variants, Google AI Developers are positioning Gemma 3 270M as a foundation for building fast, cost-effective, and privacy-focused AI solutions, and already, it seems off to a great start.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;p&gt;As its name would suggest, this is a&lt;strong&gt; 270-million-parameter model&lt;/strong&gt; — far smaller than the 70 billion or more parameters of many frontier LLMs (parameters being the number of internal settings governing the model’s behavior).&lt;/p&gt;&lt;p&gt;While more parameters generally translates to a larger and more powerful model, Google’s focus with this is nearly the opposite: high-efficiency, giving developers a model &lt;strong&gt;small enough to run directly on smartphones&lt;/strong&gt; and &lt;strong&gt;locally&lt;/strong&gt;, &lt;strong&gt;without an internet connection&lt;/strong&gt;, as shown in internal tests on a Pixel 9 Pro SoC.&lt;/p&gt;&lt;p&gt;Yet, the model is still capable of handling complex, domain-specific tasks and can be quickly fine-tuned in mere minutes to fit an enterprise or indie developer’s needs.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;On the social network X, Google DeepMind Staff AI Developer Relations Engineer Omar Sanseviero added that it Gemma 3 270M can also &lt;strong&gt;run directly in a user’s web browser, on a Raspberry Pi&lt;/strong&gt;, and “in your toaster,” underscoring its ability to operate on very lightweight hardware.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;p&gt;Gemma 3 270M combines 170 million embedding parameters — thanks to a large 256k vocabulary capable of handling rare and specific tokens — with 100 million transformer block parameters. &lt;/p&gt;



&lt;p&gt;According to Google, the architecture supports strong performance on instruction-following tasks right out of the box while staying small enough for rapid fine-tuning and deployment on devices with limited resources, including mobile hardware.&lt;/p&gt;



&lt;p&gt;Gemma 3 270M inherits the architecture and pretraining of the larger Gemma 3 models, ensuring compatibility across the Gemma ecosystem. With documentation, fine-tuning recipes, and deployment guides available for tools like Hugging Face, UnSloth, and JAX, developers can move from experimentation to deployment quickly.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-high-scores-on-benchmarks-for-its-size-and-high-hefficiency"&gt;High scores on benchmarks for its size, and high hefficiency&lt;/h2&gt;



&lt;p&gt;&lt;br /&gt;On the &lt;strong&gt;IFEval benchmark, which measures a model’s ability to follow instructions&lt;/strong&gt;, the instruction-tuned Gemma 3 270M scored &lt;strong&gt;51.2%&lt;/strong&gt;.&lt;/p&gt;



&lt;p&gt;The score places it &lt;strong&gt;well above similarly small models like SmolLM2 135M Instruct and Qwen 2.5 0.5B Instruct&lt;/strong&gt;, and closer to the performance range of some billion-parameter models, according to Google’s published comparison.&lt;/p&gt;



&lt;p&gt;However, as researchers and leaders at rival AI startup Liquid AI pointed out in replies on X, Google left off Liquid’s own LFM2-350M model released back in July of this year, which scored a whopping &lt;strong&gt;65.12%&lt;/strong&gt; with just a few more parameters (similar sized language model, however).&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;p&gt;One of the model’s defining strengths is its energy efficiency. In internal tests using the INT4-quantized model on a Pixel 9 Pro SoC, &lt;strong&gt;25 conversations consumed just 0.75% of the device’s battery. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;This makes Gemma 3 270M a practical choice for on-device AI, particularly in cases where privacy and offline functionality are important.&lt;/p&gt;



&lt;p&gt;The release includes both a pretrained and an instruction-tuned model, giving developers immediate utility for general instruction-following tasks. &lt;/p&gt;



&lt;p&gt;Quantization-Aware Trained (QAT) checkpoints are also available, enabling INT4 precision with minimal performance loss and making the model production-ready for resource-constrained environments.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-small-fine-tuned-version-of-gemma-3-270m-can-perform-many-functions-of-larger-llms"&gt;A small, fine-tuned version of Gemma 3 270M can perform many functions of larger LLMs&lt;/h2&gt;



&lt;p&gt;Google frames Gemma 3 270M as part of a broader philosophy of choosing the right tool for the job rather than relying on raw model size. &lt;/p&gt;



&lt;p&gt;For functions like sentiment analysis, entity extraction, query routing, structured text generation, compliance checks, and creative writing, the company says a fine-tuned small model can deliver faster, more cost-effective results than a large general-purpose one.&lt;/p&gt;



&lt;p&gt;The benefits of specialization are evident in past work, such as Adaptive ML’s collaboration with SK Telecom. &lt;/p&gt;



&lt;p&gt;By fine-tuning a Gemma 3 4B model for multilingual content moderation, the team outperformed much larger proprietary systems. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Gemma 3 270M is designed to enable similar success at an even smaller scale,&lt;/strong&gt; supporting fleets of specialized models tailored to individual tasks.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-demo-bedtime-story-generator-app-shows-off-the-potential-of-gemma-3-270m"&gt;Demo Bedtime Story Generator app shows off the potential of Gemma 3 270M&lt;/h2&gt;



&lt;p&gt;Beyond enterprise use, the model also fits creative scenarios. In a demo video posted on YouTube, Google shows off a Bedtime Story Generator app built with Gemma 3 270M and Transformers.js that&lt;strong&gt; runs entirely offline in a web browser,&lt;/strong&gt; showing the versatility of the model in lightweight, accessible applications.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-4-3 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;p&gt;The video highlights the model’s ability to synthesize multiple inputs by allowing selections for a main character (e.g., “a magical cat”), a setting (“in an enchanted forest”), a plot twist (“uncovers a secret door”), a theme (“Adventurous”), and a desired length (“Short”).&lt;/p&gt;



&lt;p&gt;Once the parameters are set, the Gemma 3 270M model generates a coherent and imaginative story. The application proceeds to weave a short, adventurous tale based on the user’s choices, demonstrating the model’s capacity for creative, context-aware text generation.&lt;/p&gt;



&lt;p&gt;This video serves as a powerful example of how &lt;strong&gt;the lightweight yet capable Gemma 3 270M can power fast, engaging, and interactive applications without relying on the cloud&lt;/strong&gt;, opening up new possibilities for on-device AI experiences.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-open-sourced-under-a-gemma-custom-license"&gt;Open-sourced under a Gemma custom license&lt;/h2&gt;



&lt;p&gt;Gemma 3 270M is released under the Gemma Terms of Use, which allow use, reproduction, modification, and distribution of the model and derivatives, provided certain conditions are met. &lt;/p&gt;



&lt;p&gt;These include carrying forward use restrictions outlined in Google’s Prohibited Use Policy, supplying the Terms of Use to downstream recipients, and clearly indicating any modifications made. Distribution can be direct or through hosted services such as APIs or web apps.&lt;/p&gt;



&lt;p&gt;For enterprise teams and commercial developers, this means the model can be embedded in products, deployed as part of cloud services, or fine-tuned into specialized derivatives, so long as licensing terms are respected. Outputs generated by the model are not claimed by Google, giving businesses full rights over the content they create. &lt;/p&gt;



&lt;p&gt;However, developers are responsible for ensuring compliance with applicable laws and for avoiding prohibited uses, such as generating harmful content or violating privacy rules.&lt;/p&gt;



&lt;p&gt;The &lt;strong&gt;license is not open-source in the traditional sense, but it does enable broad commercial use without a separate paid license. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;For companies building commercial AI applications, the main operational considerations are ensuring end users are bound by equivalent restrictions, documenting model modifications, and implementing safety measures aligned with the prohibited uses policy.&lt;/p&gt;



&lt;p&gt;With the Gemmaverse surpassing 200 million downloads and the Gemma lineup spanning cloud, desktop, and mobile-optimized variants, Google AI Developers are positioning Gemma 3 270M as a foundation for building fast, cost-effective, and privacy-focused AI solutions, and already, it seems off to a great start.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/google-unveils-ultra-small-and-efficient-open-source-ai-model-gemma-3-270m-that-can-run-on-smartphones/</guid><pubDate>Thu, 14 Aug 2025 18:21:55 +0000</pubDate></item><item><title>[NEW] Beyond billion-parameter burdens: Unlocking data synthesis with a conditional generator (The latest research from Google)</title><link>https://research.google/blog/beyond-billion-parameter-burdens-unlocking-data-synthesis-with-a-conditional-generator/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;Experiments&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;We conducted experiments on four datasets, where three datasets correspond with downstream generative tasks and one dataset with a classification task. Generative tasks are typically more challenging than classification tasks. This is because the generative tasks are evaluated by the next-token prediction accuracy, which requires the synthetic data to preserve fine-grained textual information from the private data. In contrast, the classification tasks only require maintaining the co-occurrence patterns between labels and words in the private data.&lt;/p&gt;&lt;p&gt;The three generative tasks are chosen to cover a diverse set of practical scenarios: PubMed (medical paper abstracts), Chatbot Arena (human-to-machine interactions), and Multi-Session Chat (human-to-human daily dialogues). To evaluate the quality of the generated synthetic data, we followed the setup of Aug-PE to train a small downstream language model on the synthetic data and then compute the next-token prediction accuracy on the real test data.&lt;/p&gt;&lt;p&gt;The classification task is performed on the OpenReview (academic paper reviews) dataset. To evaluate the quality of the generated synthetic data, we train a downstream classifier on the synthetic data, and compute the classification accuracy on the real test data.&lt;/p&gt;&lt;p&gt;To mitigate concerns regarding data contamination, we carefully analyzed our selected datasets. Our analysis showed no overlap between our pre-training data and the downstream datasets.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;Experiments&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;We conducted experiments on four datasets, where three datasets correspond with downstream generative tasks and one dataset with a classification task. Generative tasks are typically more challenging than classification tasks. This is because the generative tasks are evaluated by the next-token prediction accuracy, which requires the synthetic data to preserve fine-grained textual information from the private data. In contrast, the classification tasks only require maintaining the co-occurrence patterns between labels and words in the private data.&lt;/p&gt;&lt;p&gt;The three generative tasks are chosen to cover a diverse set of practical scenarios: PubMed (medical paper abstracts), Chatbot Arena (human-to-machine interactions), and Multi-Session Chat (human-to-human daily dialogues). To evaluate the quality of the generated synthetic data, we followed the setup of Aug-PE to train a small downstream language model on the synthetic data and then compute the next-token prediction accuracy on the real test data.&lt;/p&gt;&lt;p&gt;The classification task is performed on the OpenReview (academic paper reviews) dataset. To evaluate the quality of the generated synthetic data, we train a downstream classifier on the synthetic data, and compute the classification accuracy on the real test data.&lt;/p&gt;&lt;p&gt;To mitigate concerns regarding data contamination, we carefully analyzed our selected datasets. Our analysis showed no overlap between our pre-training data and the downstream datasets.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/beyond-billion-parameter-burdens-unlocking-data-synthesis-with-a-conditional-generator/</guid><pubDate>Thu, 14 Aug 2025 19:06:20 +0000</pubDate></item><item><title>[NEW] Google releases pint-size Gemma open AI model (AI – Ars Technica)</title><link>https://arstechnica.com/google/2025/08/google-releases-pint-size-gemma-open-ai-model/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The new Gemma model is a fraction of the size of most new models.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="191" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/Gemma3-270M_Wagtail_RD2-V02.original-640x191.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/Gemma3-270M_Wagtail_RD2-V02.original-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Big tech has spent the last few years creating ever-larger AI models, leveraging rack after rack of expensive GPUs to provide generative AI as a cloud service. But tiny AI matters, too. Google has announced a tiny version of its Gemma open model designed to run on local devices. Google says the new Gemma 3 270M can be tuned in a snap and maintains robust performance despite its small footprint.&lt;/p&gt;
&lt;p&gt;Google released its first Gemma 3 open models earlier this year, featuring between 1 billion and 27 billion parameters. In generative AI, the parameters are the learned variables that control how the model processes inputs to estimate output tokens. Generally, the more parameters in a model, the better it performs. With just 270 million parameters, the new Gemma 3 can run on devices like smartphones or even entirely inside a web browser.&lt;/p&gt;
&lt;p&gt;Running an AI model locally has numerous benefits, including enhanced privacy and lower latency. Gemma 3 270M was designed with these kinds of use cases in mind. In testing with a Pixel 9 Pro, the new Gemma was able to run 25 conversations on the Tensor G4 chip and use just 0.75 percent of the device's battery. That makes it by far the most efficient Gemma model.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2112077 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="Small Gemma benchmark" class="fullwidth full" height="2251" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/Gemma3-270M_Chart01_RD3-V01.original.jpg" width="4001" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Gemma 3 270M shows strong instruction-following for its small size.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Developers shouldn't expect the same performance level of a multi-billion-parameter model, but Gemma 3 270M has its uses. Google used the IFEval benchmark, which tests a model's ability to follow instructions, to show that its new model punches above its weight. Gemma 3 270M hits a score of 51.2 percent in this test, which is higher than other lightweight models that have more parameters. The new Gemma falls predictably short of 1 billion-plus models like Llama 3.2, but it gets closer than you might think for having just a fraction of the parameters.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Google claims Gemma 3 270M is good at following instructions out of the box, but it expects developers to fine-tune the model for their specific use cases. Due to the small parameter count, that process is fast and low-cost, too. Google sees the new Gemma being used for tasks like text classification and data analysis, which it can accomplish quickly and without heavy computing requirements.&lt;/p&gt;
&lt;h2&gt;Mostly open&lt;/h2&gt;
&lt;p&gt;Google refers to Gemma models as "open," which is not to be confused with "open source." This situation is the same in most ways, though. You can download the new Gemma for free, and the model weights are available. There's no separate commercial licensing agreement, so developers can modify, publish, and deploy Gemma 3 270M derivatives in their tools.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Gemma 270M story generator AI running in a browser.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;However, anyone using Gemma models is bound by the terms of use, which prohibit tuning the models to produce harmful outputs or intentionally violating privacy rules. Developers are also responsible for detailing modifications and providing a copy of the terms of use for all derivative versions, which inherit Google's custom license.&lt;/p&gt;
&lt;p&gt;Gemma 3 270M is available from platforms like Hugging Face and Kaggle in both pre-trained and instruction-tuned versions. It's available in Google's Vertex AI for testing, too. Google has also highlighted the capabilities of the new model with a fully browser-based story generator built on Transformer.js (see above). You can give that a shot even if you're not interested in developing with the new lightweight model.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The new Gemma model is a fraction of the size of most new models.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="191" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/Gemma3-270M_Wagtail_RD2-V02.original-640x191.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/Gemma3-270M_Wagtail_RD2-V02.original-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Big tech has spent the last few years creating ever-larger AI models, leveraging rack after rack of expensive GPUs to provide generative AI as a cloud service. But tiny AI matters, too. Google has announced a tiny version of its Gemma open model designed to run on local devices. Google says the new Gemma 3 270M can be tuned in a snap and maintains robust performance despite its small footprint.&lt;/p&gt;
&lt;p&gt;Google released its first Gemma 3 open models earlier this year, featuring between 1 billion and 27 billion parameters. In generative AI, the parameters are the learned variables that control how the model processes inputs to estimate output tokens. Generally, the more parameters in a model, the better it performs. With just 270 million parameters, the new Gemma 3 can run on devices like smartphones or even entirely inside a web browser.&lt;/p&gt;
&lt;p&gt;Running an AI model locally has numerous benefits, including enhanced privacy and lower latency. Gemma 3 270M was designed with these kinds of use cases in mind. In testing with a Pixel 9 Pro, the new Gemma was able to run 25 conversations on the Tensor G4 chip and use just 0.75 percent of the device's battery. That makes it by far the most efficient Gemma model.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2112077 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="Small Gemma benchmark" class="fullwidth full" height="2251" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/Gemma3-270M_Chart01_RD3-V01.original.jpg" width="4001" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Gemma 3 270M shows strong instruction-following for its small size.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Developers shouldn't expect the same performance level of a multi-billion-parameter model, but Gemma 3 270M has its uses. Google used the IFEval benchmark, which tests a model's ability to follow instructions, to show that its new model punches above its weight. Gemma 3 270M hits a score of 51.2 percent in this test, which is higher than other lightweight models that have more parameters. The new Gemma falls predictably short of 1 billion-plus models like Llama 3.2, but it gets closer than you might think for having just a fraction of the parameters.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Google claims Gemma 3 270M is good at following instructions out of the box, but it expects developers to fine-tune the model for their specific use cases. Due to the small parameter count, that process is fast and low-cost, too. Google sees the new Gemma being used for tasks like text classification and data analysis, which it can accomplish quickly and without heavy computing requirements.&lt;/p&gt;
&lt;h2&gt;Mostly open&lt;/h2&gt;
&lt;p&gt;Google refers to Gemma models as "open," which is not to be confused with "open source." This situation is the same in most ways, though. You can download the new Gemma for free, and the model weights are available. There's no separate commercial licensing agreement, so developers can modify, publish, and deploy Gemma 3 270M derivatives in their tools.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Gemma 270M story generator AI running in a browser.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;However, anyone using Gemma models is bound by the terms of use, which prohibit tuning the models to produce harmful outputs or intentionally violating privacy rules. Developers are also responsible for detailing modifications and providing a copy of the terms of use for all derivative versions, which inherit Google's custom license.&lt;/p&gt;
&lt;p&gt;Gemma 3 270M is available from platforms like Hugging Face and Kaggle in both pre-trained and instruction-tuned versions. It's available in Google's Vertex AI for testing, too. Google has also highlighted the capabilities of the new model with a fully browser-based story generator built on Transformer.js (see above). You can give that a shot even if you're not interested in developing with the new lightweight model.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/google/2025/08/google-releases-pint-size-gemma-open-ai-model/</guid><pubDate>Thu, 14 Aug 2025 20:04:22 +0000</pubDate></item><item><title>[NEW] US government is reportedly in discussions to take stake in Intel (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/14/u-s-government-is-reportedly-in-discussions-to-take-stake-in-intel/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-2228936694.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The Trump administration continues to meddle with semiconductor giant Intel.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The U.S. government is reportedly in discussions to take a stake in Intel, according to reporting from Bloomberg. This deal would be structured to help the company expand its U.S. manufacturing efforts, including its much-delayed Ohio chip factory.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This news comes less than a week after President Donald Trump insisted that Intel CEO Lip-Bu Tan resign because of perceived conflicts of interest. While Trump didn’t provide a reason, this came after Republican U.S. Sen. Tom Cotton wrote to Intel’s board asking about Tan’s alleged ties to China.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tan met with the Trump administration on August 11 to quell the administration’s fears and figure out ways for the company to work with the government. This meeting is what sparked discussions of the U.S. government taking a direct stake in the company, according to Bloomberg.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Intel declined to comment. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Intel is deeply committed to supporting President Trump’s efforts to strengthen U.S. technology and manufacturing leadership,” an Intel spokesperson said in a statement. “We look forward to continuing our work with the Trump Administration to advance these shared priorities, but we are not going to comment on rumors or speculation.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-2228936694.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The Trump administration continues to meddle with semiconductor giant Intel.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The U.S. government is reportedly in discussions to take a stake in Intel, according to reporting from Bloomberg. This deal would be structured to help the company expand its U.S. manufacturing efforts, including its much-delayed Ohio chip factory.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This news comes less than a week after President Donald Trump insisted that Intel CEO Lip-Bu Tan resign because of perceived conflicts of interest. While Trump didn’t provide a reason, this came after Republican U.S. Sen. Tom Cotton wrote to Intel’s board asking about Tan’s alleged ties to China.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tan met with the Trump administration on August 11 to quell the administration’s fears and figure out ways for the company to work with the government. This meeting is what sparked discussions of the U.S. government taking a direct stake in the company, according to Bloomberg.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Intel declined to comment. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Intel is deeply committed to supporting President Trump’s efforts to strengthen U.S. technology and manufacturing leadership,” an Intel spokesperson said in a statement. “We look forward to continuing our work with the Trump Administration to advance these shared priorities, but we are not going to comment on rumors or speculation.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/14/u-s-government-is-reportedly-in-discussions-to-take-stake-in-intel/</guid><pubDate>Thu, 14 Aug 2025 20:38:20 +0000</pubDate></item><item><title>[NEW] US government agency drops Grok after MechaHitler backlash, report says (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/08/us-government-agency-drops-grok-after-mechahitler-backlash-report-says/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        It appears Grok’s antisemitic rants stopped it from becoming feds’ go-to chatbot.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="426" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2224898774-640x426.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2224898774-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Anadolu / Contributor | Anadolu

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;xAI apparently lost a government contract after a tweak to Grok's prompting triggered an antisemitic meltdown where the chatbot praised Hitler and declared itself MechaHitler last month.&lt;/p&gt;
&lt;p&gt;Despite the scandal, xAI announced that its products would soon be available for federal workers to purchase through the General Services Administration. At the time, xAI claimed this was an "important milestone" for its government business.&lt;/p&gt;
&lt;p&gt;But Wired reviewed emails and spoke to government insiders, which revealed that GSA leaders abruptly decided to drop xAI's Grok from their contract offering. That decision to pull the plug came after leadership allegedly rushed staff to make Grok available as soon as possible following a persuasive sales meeting with xAI in June.&lt;/p&gt;
&lt;p&gt;It's unclear what exactly caused the GSA to reverse course, but two sources told Wired that they "believe xAI was pulled because of Grok’s antisemitic tirade."&lt;/p&gt;
&lt;p&gt;As of this writing, xAI's "Grok for Government" website has not been updated to reflect GSA's supposed removal of Grok from an offering that xAI noted would have allowed "every federal government department, agency, or office, to access xAI's frontier AI products."&lt;/p&gt;
&lt;p&gt;xAI did not respond to Ars' request to comment and so far has not confirmed that the GSA offering is off the table. If Wired's report is accurate, GSA's decision also seemingly did not influence the military's decision to move forward with a $200 million xAI contract the US Department of Defense granted last month.&lt;/p&gt;
&lt;h2&gt;Government’s go-to tools will come from xAI’s rivals&lt;/h2&gt;
&lt;p&gt;If Grok is cut from the contract, that would suggest that Grok's meltdown came at perhaps the worst possible moment for xAI, which is building the "world's biggest supercomputer" as fast as it can to try to get ahead of its biggest AI rivals.&lt;/p&gt;
&lt;p&gt;Grok seemingly had the potential to become a more widely used tool if federal workers opted for xAI's models. Through Donald Trump's AI Action Plan, the president has similarly emphasized speed, pushing for federal workers to adopt AI as quickly as possible. Although xAI may no longer be involved in that broad push, other AI companies like OpenAI, Anthropic, and Google have partnered with the government to help Trump pull that off and stand to benefit long-term if their tools become entrenched in certain agencies.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Wired's report suggested that some federal workers are uncomfortable not just with the Trump administration's aggressive pace in forcing AI adoption, but also with the price of the products agencies are being required to use. After OpenAI offered to charge federal workers only a nominal $1 fee to access ChatGPT Enterprise, Anthropic quickly set the same price, seemingly hoping to compete.&lt;/p&gt;
&lt;p&gt;Some workers told Wired they felt the nominal fee "amounts to a gift from a tech company and is highly unusual" compared to how the procurement process usually works. Perhaps most glaringly, the partnerships came together so fast, one GSA worker told Wired that "it wasn't even clear who to send the $1 to or how."&lt;/p&gt;
&lt;p&gt;Grok was intended to be pushed through the procurement process at a similar clip, Wired reported, but Grok's antisemitic outputs instead seemingly caused enough internal GSA pushback that the effort was halted.&lt;/p&gt;
&lt;p&gt;For Elon Musk—who spent the past week frustrated by ChatGPT consistently beating out Grok in Apple's app store rankings and locking horns with OpenAI CEO Sam Altman over whose AI model is better for humanity—being cut out of the government's widest AI push at this moment could seemingly risk long-term consequences for Grok's utility not just in federal government but also local governments xAI is targeted with services across the US.&lt;/p&gt;
&lt;p&gt;Notably, Grok's antisemitic outputs came after Musk vowed to make the chatbot less "woke." That seemingly meant adding rules to Grok's prompting, which were later deleted, instructing that the chatbot "should not shy away from making claims which are politically incorrect."&lt;/p&gt;
&lt;p&gt;If OpenAI's ChatGPT wins more government contracts and continues to dominate popular rankings, Musk may be left wondering if his mission to make Grok edgier than other chatbots will ultimately be what prevents Grok from becoming America's go-to chatbot.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        It appears Grok’s antisemitic rants stopped it from becoming feds’ go-to chatbot.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="426" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2224898774-640x426.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2224898774-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Anadolu / Contributor | Anadolu

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;xAI apparently lost a government contract after a tweak to Grok's prompting triggered an antisemitic meltdown where the chatbot praised Hitler and declared itself MechaHitler last month.&lt;/p&gt;
&lt;p&gt;Despite the scandal, xAI announced that its products would soon be available for federal workers to purchase through the General Services Administration. At the time, xAI claimed this was an "important milestone" for its government business.&lt;/p&gt;
&lt;p&gt;But Wired reviewed emails and spoke to government insiders, which revealed that GSA leaders abruptly decided to drop xAI's Grok from their contract offering. That decision to pull the plug came after leadership allegedly rushed staff to make Grok available as soon as possible following a persuasive sales meeting with xAI in June.&lt;/p&gt;
&lt;p&gt;It's unclear what exactly caused the GSA to reverse course, but two sources told Wired that they "believe xAI was pulled because of Grok’s antisemitic tirade."&lt;/p&gt;
&lt;p&gt;As of this writing, xAI's "Grok for Government" website has not been updated to reflect GSA's supposed removal of Grok from an offering that xAI noted would have allowed "every federal government department, agency, or office, to access xAI's frontier AI products."&lt;/p&gt;
&lt;p&gt;xAI did not respond to Ars' request to comment and so far has not confirmed that the GSA offering is off the table. If Wired's report is accurate, GSA's decision also seemingly did not influence the military's decision to move forward with a $200 million xAI contract the US Department of Defense granted last month.&lt;/p&gt;
&lt;h2&gt;Government’s go-to tools will come from xAI’s rivals&lt;/h2&gt;
&lt;p&gt;If Grok is cut from the contract, that would suggest that Grok's meltdown came at perhaps the worst possible moment for xAI, which is building the "world's biggest supercomputer" as fast as it can to try to get ahead of its biggest AI rivals.&lt;/p&gt;
&lt;p&gt;Grok seemingly had the potential to become a more widely used tool if federal workers opted for xAI's models. Through Donald Trump's AI Action Plan, the president has similarly emphasized speed, pushing for federal workers to adopt AI as quickly as possible. Although xAI may no longer be involved in that broad push, other AI companies like OpenAI, Anthropic, and Google have partnered with the government to help Trump pull that off and stand to benefit long-term if their tools become entrenched in certain agencies.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Wired's report suggested that some federal workers are uncomfortable not just with the Trump administration's aggressive pace in forcing AI adoption, but also with the price of the products agencies are being required to use. After OpenAI offered to charge federal workers only a nominal $1 fee to access ChatGPT Enterprise, Anthropic quickly set the same price, seemingly hoping to compete.&lt;/p&gt;
&lt;p&gt;Some workers told Wired they felt the nominal fee "amounts to a gift from a tech company and is highly unusual" compared to how the procurement process usually works. Perhaps most glaringly, the partnerships came together so fast, one GSA worker told Wired that "it wasn't even clear who to send the $1 to or how."&lt;/p&gt;
&lt;p&gt;Grok was intended to be pushed through the procurement process at a similar clip, Wired reported, but Grok's antisemitic outputs instead seemingly caused enough internal GSA pushback that the effort was halted.&lt;/p&gt;
&lt;p&gt;For Elon Musk—who spent the past week frustrated by ChatGPT consistently beating out Grok in Apple's app store rankings and locking horns with OpenAI CEO Sam Altman over whose AI model is better for humanity—being cut out of the government's widest AI push at this moment could seemingly risk long-term consequences for Grok's utility not just in federal government but also local governments xAI is targeted with services across the US.&lt;/p&gt;
&lt;p&gt;Notably, Grok's antisemitic outputs came after Musk vowed to make the chatbot less "woke." That seemingly meant adding rules to Grok's prompting, which were later deleted, instructing that the chatbot "should not shy away from making claims which are politically incorrect."&lt;/p&gt;
&lt;p&gt;If OpenAI's ChatGPT wins more government contracts and continues to dominate popular rankings, Musk may be left wondering if his mission to make Grok edgier than other chatbots will ultimately be what prevents Grok from becoming America's go-to chatbot.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/08/us-government-agency-drops-grok-after-mechahitler-backlash-report-says/</guid><pubDate>Thu, 14 Aug 2025 21:11:06 +0000</pubDate></item><item><title>[NEW] Gartner: GPT-5 is here, but the infrastructure to support true agentic AI isn’t (yet) (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/gartner-gpt-5-is-here-but-the-infrastructure-to-support-true-agentic-ai-isnt-yet/</link><description>&lt;p&gt;Here’s an analogy: Freeways didn’t exist in the U.S. until after 1956, when envisioned by President Dwight D. Eisenhower’s administration — yet super fast, powerful cars like Porsche, BMW, Jaguars, Ferrari and others had been around for decades.&amp;nbsp;&lt;/p&gt;&lt;p&gt;You could say AI is at that same pivot point: While models are becoming increasingly more capable, performant and sophisticated, the critical infrastructure they need to bring about true, real-world innovation has yet to be fully built out.&amp;nbsp;&lt;/p&gt;&lt;p&gt;“All we have done is create some very good engines for a car, and we are getting super excited, as if we have this fully functional highway system in place,” Arun Chandrasekaran, Gartner distinguished VP analyst, told VentureBeat.&amp;nbsp;&lt;/p&gt;&lt;p&gt;This is leading to a plateauing, of sorts, in model capabilities such as OpenAI’s GPT-5: While an important step forward, it only features faint glimmers of truly agentic AI. &lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;“It is a very capable model, it is a very versatile model, it has made some very good progress in specific domains,” said Chandrasekaran. “But my view is it’s more of an incremental progress, rather than a radical progress or a radical improvement, given all of the high expectations OpenAI has set in the past.”&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-gpt-5-improves-in-three-key-areas"&gt;GPT-5 improves in three key areas&lt;/h2&gt;



&lt;p&gt;To be clear, OpenAI has made strides with GPT-5, according to Gartner, including in coding tasks and multi-modal capabilities.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Chandrasekaran pointed out that OpenAI has pivoted to make GPT-5 “very good” at coding, clearly sensing gen AI’s enormous opportunity in enterprise software engineering and taking aim at competitor Anthropic’s leadership in that area.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Meanwhile, GPT-5’s progress in modalities beyond text, particularly in speech and images, provides new integration opportunities for enterprises, Chandrasekaran noted.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;GPT-5 also does, if subtly, advance AI agent and orchestration design, thanks to improved tool use; the model&amp;nbsp;can call third-party APIs and tools and perform parallel tool calling (handle multiple tasks simultaneously). However, this means enterprise systems must have the capacity to handle concurrent API requests in a single session, Chandrasekaran points out. &lt;/p&gt;



&lt;p&gt;Multistep planning in GPT-5 allows more business logic to reside within the model itself, reducing the need for external workflow engines, and its larger context windows (8K for free users, 32K for Plus at $20 per month and 128K for Pro at $200 per month) can “reshape enterprise AI architecture patterns,” he said.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This means that applications that previously relied on complex retrieval-augmented generation (RAG) pipelines to work around context limits can now pass much larger datasets directly to the models and simplify some workflows. But this doesn’t mean RAG is irrelevant; “retrieving only the most relevant data is still faster and more cost-effective than always sending massive inputs,” Chandrasekaran pointed out.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Gartner sees a shift to a hybrid approach with less stringent retrieval, with devs using GPT-5 to handle “larger, messier contexts” while improving efficiency.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;On the cost front, GPT-5 “significantly” reduces API usage fees; top-level costs are $1.25 per 1 million input tokens and $10 per 1 million output tokens, making it comparable to models like Gemini 2.5, but seriously undercutting Claude Opus. However, GTP-5’s input/output price ratio is higher than earlier models, which AI leaders should take into account when considering GTP-5 for high-token-usage scenarios, Chandrasekaran advised.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-bye-bye-previous-gpt-versions-sorta"&gt;Bye-bye previous GPT versions (sorta)&lt;/h2&gt;



&lt;p&gt;Ultimately, GPT-5 is designed to eventually replace GPT-4o and the o-series (they were initially sunset, then some reintroduced by OpenAI due to user dissent). Three model sizes (pro, mini, nano) will allow architects to tier services based on cost and latency needs; simple queries can be handled by smaller models and complex tasks by the full model, Gartner notes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;However, differences in output formats, memory and function-calling behaviors may require code review and adjustment, and because GPT-5 may render some previous workarounds obsolete, devs should audit their prompt templates and system instructions. &lt;/p&gt;



&lt;p&gt;By eventually sunsetting previous versions, “I think what OpenAI is trying to do is abstract that level of complexity away from the user,” said Chandrasekaran. “Often we’re not the best people to make those decisions, and sometimes we may even make erroneous decisions, I would argue.”&lt;/p&gt;



&lt;p&gt;Another fact behind the phase-outs: “We all know that OpenAI has a capacity problem,” he said, and thus has forged partnerships with Microsoft, Oracle (Project Stargate), Google and others to provision compute capacity. Running multiple generations of models would require multiple generations of infrastructure, creating new cost implications and physical constraints.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-new-risks-advice-for-adopting-gpt-5"&gt;New risks, advice for adopting GPT-5&lt;/h2&gt;



&lt;p&gt;OpenAI claims it reduced hallucination rates by up to 65% in GPT-5 compared to previous models; this can help reduce compliance risks and make the model more suitable for enterprise use cases, and its chain-of-thought (CoT) explanations support auditability and regulatory alignment, Gartner notes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;At the same time, these lower hallucination rates as well as GPT-5’s advanced reasoning and multimodal processing could amplify misuse such as advanced scam and phishing generation. Analysts advise that critical workflows remain under human review, even if with less sampling.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The firm also advises that enterprise leaders:&amp;nbsp;&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Pilot and benchmark GPT-5 in mission-critical use cases, running side-by-side evaluations against other models to determine differences in accuracy, speed and user experience.&amp;nbsp;&lt;/li&gt;



&lt;li&gt;Monitor practices like vibe coding that risk data exposure (but without being offensive about it or risking defects or guardrail failures).&amp;nbsp;&lt;/li&gt;



&lt;li&gt;Revise governance policies and guidelines to address new model behaviors, expanded context windows and safe completions, and calibrate oversight mechanisms.&amp;nbsp;&lt;/li&gt;



&lt;li&gt;Experiment with tool integrations, reasoning parameters, caching and model sizing to optimize performance, and use inbuilt dynamic routing to determine the right model for the right task.&lt;/li&gt;



&lt;li&gt;Audit and upgrade plans for GPT-5’s expanded capabilities. This includes validating API quotas, audit trails and multimodal data pipelines to support new features and increased throughput. Rigorous integration testing is also important.&lt;/li&gt;
&lt;/ul&gt;



&lt;h2 class="wp-block-heading" id="h-agents-don-t-just-need-more-compute-they-need-infrastructure"&gt;Agents don’t just need more compute; they need infrastructure&lt;/h2&gt;



&lt;p&gt;No doubt, agentic AI is a “super hot topic today,” Chandrasekaran noted, and is one of the top areas for investment in Gartner’s 2025 Hype Cycle for Gen AI. At the same time, the technology has hit Gartner’s “Peak of Inflated Expectations,” meaning it has experienced widespread publicity due to early success stories, in turn building unrealistic expectations.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015582" height="451" src="https://venturebeat.com/wp-content/uploads/2025/08/hype-cycle-for-generative-ai-2025.png?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;This trend is typically followed by what Gartner calls the “Trough of Disillusionment,” when interest, excitement and investment cool off as experiments and implementations fail to deliver (remember: There have been two notable AI winters since the 1980s).&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“A lot of vendors are hyping products beyond what products are capable of,” said Chandrasekaran. “It’s almost like they’re positioning them as being production-ready, enterprise-ready and are going to deliver business value in a really short span of time.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;However, in reality, the chasm between product quality relative to expectation is wide, he noted. Gartner isn’t seeing enterprise-wide agentic deployments; those they are seeing are in “small, narrow pockets” and specific domains like software engineering or procurement.&lt;/p&gt;



&lt;p&gt;“But even those workflows are not fully autonomous; they are often either human-driven or semi-autonomous in nature,” Chandrasekaran explained.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;One of the key culprits is the lack of infrastructure; agents require access to a wide set of enterprise tools and must have the capability to communicate with data stores and SaaS apps. At the same time, there must be adequate identity and access management systems in place to control agent behavior and access, as well as oversight of the types of data they can access (not personally identifiable or sensitive), he noted.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Lastly, enterprises must be confident that the information the agents are producing is trustworthy, meaning it’s free of bias and doesn’t contain hallucinations or false information.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To get there, vendors must collaborate and adopt more open standards for agent-to-enterprise and agent-to-agent tool communication, he advised. &lt;/p&gt;



&lt;p&gt;“While agents or the underlying technologies may be making progress, this orchestration, governance and data layer is still waiting to be built out for agents to thrive,” said Chandrasekaran. “That’s where we see a lot of friction today.”&lt;/p&gt;



&lt;p&gt;Yes, the industry is making progress with AI reasoning, but still struggles to get AI to understand how the physical world works. AI mostly operates in a digital world; it doesn’t have strong interfaces to the physical world, although improvements are being made in spatial robotics.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But, “we are very, very, very, very early stage for those kinds of environments,” said Chandrasekaran.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To truly make significant strides requires a “revolution” in model architecture or reasoning. “You cannot be on the current curve and just expect more data, more compute, and hope to get to AGI,” she said.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;That’s evident in the much-anticipated GPT-5 rollout: The ultimate goal that OpenAI defined for itself was AGI, but “it’s really apparent that we are nowhere close to that,” said Chandrasekaran. Ultimately, “we’re still very, very far away from AGI.”&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;p&gt;Here’s an analogy: Freeways didn’t exist in the U.S. until after 1956, when envisioned by President Dwight D. Eisenhower’s administration — yet super fast, powerful cars like Porsche, BMW, Jaguars, Ferrari and others had been around for decades.&amp;nbsp;&lt;/p&gt;&lt;p&gt;You could say AI is at that same pivot point: While models are becoming increasingly more capable, performant and sophisticated, the critical infrastructure they need to bring about true, real-world innovation has yet to be fully built out.&amp;nbsp;&lt;/p&gt;&lt;p&gt;“All we have done is create some very good engines for a car, and we are getting super excited, as if we have this fully functional highway system in place,” Arun Chandrasekaran, Gartner distinguished VP analyst, told VentureBeat.&amp;nbsp;&lt;/p&gt;&lt;p&gt;This is leading to a plateauing, of sorts, in model capabilities such as OpenAI’s GPT-5: While an important step forward, it only features faint glimmers of truly agentic AI. &lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;“It is a very capable model, it is a very versatile model, it has made some very good progress in specific domains,” said Chandrasekaran. “But my view is it’s more of an incremental progress, rather than a radical progress or a radical improvement, given all of the high expectations OpenAI has set in the past.”&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-gpt-5-improves-in-three-key-areas"&gt;GPT-5 improves in three key areas&lt;/h2&gt;



&lt;p&gt;To be clear, OpenAI has made strides with GPT-5, according to Gartner, including in coding tasks and multi-modal capabilities.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Chandrasekaran pointed out that OpenAI has pivoted to make GPT-5 “very good” at coding, clearly sensing gen AI’s enormous opportunity in enterprise software engineering and taking aim at competitor Anthropic’s leadership in that area.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Meanwhile, GPT-5’s progress in modalities beyond text, particularly in speech and images, provides new integration opportunities for enterprises, Chandrasekaran noted.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;GPT-5 also does, if subtly, advance AI agent and orchestration design, thanks to improved tool use; the model&amp;nbsp;can call third-party APIs and tools and perform parallel tool calling (handle multiple tasks simultaneously). However, this means enterprise systems must have the capacity to handle concurrent API requests in a single session, Chandrasekaran points out. &lt;/p&gt;



&lt;p&gt;Multistep planning in GPT-5 allows more business logic to reside within the model itself, reducing the need for external workflow engines, and its larger context windows (8K for free users, 32K for Plus at $20 per month and 128K for Pro at $200 per month) can “reshape enterprise AI architecture patterns,” he said.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This means that applications that previously relied on complex retrieval-augmented generation (RAG) pipelines to work around context limits can now pass much larger datasets directly to the models and simplify some workflows. But this doesn’t mean RAG is irrelevant; “retrieving only the most relevant data is still faster and more cost-effective than always sending massive inputs,” Chandrasekaran pointed out.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Gartner sees a shift to a hybrid approach with less stringent retrieval, with devs using GPT-5 to handle “larger, messier contexts” while improving efficiency.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;On the cost front, GPT-5 “significantly” reduces API usage fees; top-level costs are $1.25 per 1 million input tokens and $10 per 1 million output tokens, making it comparable to models like Gemini 2.5, but seriously undercutting Claude Opus. However, GTP-5’s input/output price ratio is higher than earlier models, which AI leaders should take into account when considering GTP-5 for high-token-usage scenarios, Chandrasekaran advised.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-bye-bye-previous-gpt-versions-sorta"&gt;Bye-bye previous GPT versions (sorta)&lt;/h2&gt;



&lt;p&gt;Ultimately, GPT-5 is designed to eventually replace GPT-4o and the o-series (they were initially sunset, then some reintroduced by OpenAI due to user dissent). Three model sizes (pro, mini, nano) will allow architects to tier services based on cost and latency needs; simple queries can be handled by smaller models and complex tasks by the full model, Gartner notes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;However, differences in output formats, memory and function-calling behaviors may require code review and adjustment, and because GPT-5 may render some previous workarounds obsolete, devs should audit their prompt templates and system instructions. &lt;/p&gt;



&lt;p&gt;By eventually sunsetting previous versions, “I think what OpenAI is trying to do is abstract that level of complexity away from the user,” said Chandrasekaran. “Often we’re not the best people to make those decisions, and sometimes we may even make erroneous decisions, I would argue.”&lt;/p&gt;



&lt;p&gt;Another fact behind the phase-outs: “We all know that OpenAI has a capacity problem,” he said, and thus has forged partnerships with Microsoft, Oracle (Project Stargate), Google and others to provision compute capacity. Running multiple generations of models would require multiple generations of infrastructure, creating new cost implications and physical constraints.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-new-risks-advice-for-adopting-gpt-5"&gt;New risks, advice for adopting GPT-5&lt;/h2&gt;



&lt;p&gt;OpenAI claims it reduced hallucination rates by up to 65% in GPT-5 compared to previous models; this can help reduce compliance risks and make the model more suitable for enterprise use cases, and its chain-of-thought (CoT) explanations support auditability and regulatory alignment, Gartner notes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;At the same time, these lower hallucination rates as well as GPT-5’s advanced reasoning and multimodal processing could amplify misuse such as advanced scam and phishing generation. Analysts advise that critical workflows remain under human review, even if with less sampling.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The firm also advises that enterprise leaders:&amp;nbsp;&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Pilot and benchmark GPT-5 in mission-critical use cases, running side-by-side evaluations against other models to determine differences in accuracy, speed and user experience.&amp;nbsp;&lt;/li&gt;



&lt;li&gt;Monitor practices like vibe coding that risk data exposure (but without being offensive about it or risking defects or guardrail failures).&amp;nbsp;&lt;/li&gt;



&lt;li&gt;Revise governance policies and guidelines to address new model behaviors, expanded context windows and safe completions, and calibrate oversight mechanisms.&amp;nbsp;&lt;/li&gt;



&lt;li&gt;Experiment with tool integrations, reasoning parameters, caching and model sizing to optimize performance, and use inbuilt dynamic routing to determine the right model for the right task.&lt;/li&gt;



&lt;li&gt;Audit and upgrade plans for GPT-5’s expanded capabilities. This includes validating API quotas, audit trails and multimodal data pipelines to support new features and increased throughput. Rigorous integration testing is also important.&lt;/li&gt;
&lt;/ul&gt;



&lt;h2 class="wp-block-heading" id="h-agents-don-t-just-need-more-compute-they-need-infrastructure"&gt;Agents don’t just need more compute; they need infrastructure&lt;/h2&gt;



&lt;p&gt;No doubt, agentic AI is a “super hot topic today,” Chandrasekaran noted, and is one of the top areas for investment in Gartner’s 2025 Hype Cycle for Gen AI. At the same time, the technology has hit Gartner’s “Peak of Inflated Expectations,” meaning it has experienced widespread publicity due to early success stories, in turn building unrealistic expectations.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015582" height="451" src="https://venturebeat.com/wp-content/uploads/2025/08/hype-cycle-for-generative-ai-2025.png?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;This trend is typically followed by what Gartner calls the “Trough of Disillusionment,” when interest, excitement and investment cool off as experiments and implementations fail to deliver (remember: There have been two notable AI winters since the 1980s).&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“A lot of vendors are hyping products beyond what products are capable of,” said Chandrasekaran. “It’s almost like they’re positioning them as being production-ready, enterprise-ready and are going to deliver business value in a really short span of time.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;However, in reality, the chasm between product quality relative to expectation is wide, he noted. Gartner isn’t seeing enterprise-wide agentic deployments; those they are seeing are in “small, narrow pockets” and specific domains like software engineering or procurement.&lt;/p&gt;



&lt;p&gt;“But even those workflows are not fully autonomous; they are often either human-driven or semi-autonomous in nature,” Chandrasekaran explained.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;One of the key culprits is the lack of infrastructure; agents require access to a wide set of enterprise tools and must have the capability to communicate with data stores and SaaS apps. At the same time, there must be adequate identity and access management systems in place to control agent behavior and access, as well as oversight of the types of data they can access (not personally identifiable or sensitive), he noted.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Lastly, enterprises must be confident that the information the agents are producing is trustworthy, meaning it’s free of bias and doesn’t contain hallucinations or false information.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To get there, vendors must collaborate and adopt more open standards for agent-to-enterprise and agent-to-agent tool communication, he advised. &lt;/p&gt;



&lt;p&gt;“While agents or the underlying technologies may be making progress, this orchestration, governance and data layer is still waiting to be built out for agents to thrive,” said Chandrasekaran. “That’s where we see a lot of friction today.”&lt;/p&gt;



&lt;p&gt;Yes, the industry is making progress with AI reasoning, but still struggles to get AI to understand how the physical world works. AI mostly operates in a digital world; it doesn’t have strong interfaces to the physical world, although improvements are being made in spatial robotics.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But, “we are very, very, very, very early stage for those kinds of environments,” said Chandrasekaran.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To truly make significant strides requires a “revolution” in model architecture or reasoning. “You cannot be on the current curve and just expect more data, more compute, and hope to get to AGI,” she said.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;That’s evident in the much-anticipated GPT-5 rollout: The ultimate goal that OpenAI defined for itself was AGI, but “it’s really apparent that we are nowhere close to that,” said Chandrasekaran. Ultimately, “we’re still very, very far away from AGI.”&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/gartner-gpt-5-is-here-but-the-infrastructure-to-support-true-agentic-ai-isnt-yet/</guid><pubDate>Thu, 14 Aug 2025 21:35:28 +0000</pubDate></item><item><title>[NEW] That ‘cheap’ open-source AI model is actually burning through your compute budget (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/that-cheap-open-source-ai-model-is-actually-burning-through-your-compute-budget/</link><description>[unable to retrieve full-text content]New research reveals open-source AI models use up to 10 times more computing resources than closed alternatives, potentially negating cost advantages for enterprise deployments.</description><content:encoded>[unable to retrieve full-text content]New research reveals open-source AI models use up to 10 times more computing resources than closed alternatives, potentially negating cost advantages for enterprise deployments.</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/that-cheap-open-source-ai-model-is-actually-burning-through-your-compute-budget/</guid><pubDate>Fri, 15 Aug 2025 01:24:49 +0000</pubDate></item></channel></rss>