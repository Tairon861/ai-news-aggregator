<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 21 Aug 2025 18:29:59 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>On the ground in Ukraine’s largest Starlink repair shop (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/08/21/1122035/ukraines-largest-starlink-repair-shop/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Oleh Kovalskyy thinks that Starlink terminals are built as if someone assembled them with their feet. Or perhaps with their hands behind their back.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;To demonstrate this last image, Kovalskyy—a large, 47-year-old Ukrainian, clad in sweatpants and with tattoos stretching from his wrists up to his neck—leans over to wiggle his fingers in the air behind him, laughing as he does. Components often detach, he says through bleached-white teeth, and they’re sensitive to dust and moisture. “It’s terrible quality. Very terrible.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;But even if he’s not particularly impressed by the production quality, he won’t dispute how important the satellite internet service has been to his country’s defense.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Starlink is absolutely critical to Ukraine’s ability to continue in the fight against Russia: It’s how troops in battle zones stay connected with faraway HQs; it’s how many of the drones essential to Ukraine’s survival hit their targets; it’s even how soldiers stay in touch with spouses and children back home.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;At the time of my visit to Kovalskyy in March 2025, however, it had begun to seem like this vital support system may suddenly disappear. Reuters had just broken news that suggested Musk, who was then still deeply enmeshed in Trump world, would remove Ukraine’s access to the service should its government fail to toe the line in US-led peace negotiations. Musk denied the allegations shortly afterward, but given Trump’s fickle foreign policy and inconsistent support of Ukrainian president Volodymyr Zelensky, the uncertainty of the technology’s future had become—and remains—impossible to ignore.&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="imageSet__wrap"&gt;&lt;div class="columns__wrapper--07c4096a3b25e22dc82ee78b6368d947"&gt;&lt;div class="wp-block-columns"&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="a view down at the back of a volunteer working in a corner workbench. Tools and components are piled on every bit of the surface as well as the shelves in front of him." class="wp-image-1121951" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/16.jpg?w=1333" width="1333" /&gt;&lt;div class="image-credit"&gt;ELENA SUBACH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="a carboard box stuffed with grey cylinders" class="wp-image-1121952" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/20-2.jpg?w=1333" width="1333" /&gt;&lt;div class="image-credit"&gt;ELENA SUBACH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="class"&gt; &lt;p class="imageSet__caption"&gt;Kovalskyy’s unofficial Starlink repair shop may be the biggest of its kind in the world. Ordered chaos is the best way to describe it.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;The stakes couldn’t be higher: Another Reuters report in late July revealed that Musk had ordered the restriction of Starlink in parts of Ukraine during a critical counteroffensive back in 2022. “Ukrainian troops suddenly faced a communications blackout,” the story explains. “Soldiers panicked, drones surveilling Russian forces went dark, and long-range artillery units, reliant on Starlink to aim their fire, struggled to hit targets.”&lt;/p&gt; 
 &lt;p&gt;None of this is lost on Kovalskyy—and for now Starlink access largely comes down to the unofficial community of users and engineers of which Kovalskyy is just one part: Narodnyi Starlink.&lt;/p&gt;  &lt;p&gt;The group, whose name translates to “The People’s Starlink,” was created back in March 2022 by a tech-savvy veteran of the previous battles against Russia-backed militias in Ukraine’s east. It started as a Facebook group for the country’s infant yet burgeoning community of Starlink users—a forum to share guidance and swap tips—but it very quickly emerged as a major support system for the new war effort. Today, it has grown to almost 20,000 members, including the unofficial expert “Dr. Starlink”—famous for his creative ways of customizing the systems—and other volunteer engineers like Kovalskyy and his men. It’s a prime example of the many informal, yet highly effective, volunteer networks that have kept Ukraine in the fight, both on and off the front line.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div class="imageSet__wrap"&gt;&lt;div class="columns__wrapper--07c4096a3b25e22dc82ee78b6368d947"&gt;&lt;div class="wp-block-columns"&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="A repaired and mounted Starlink terminal standing on a cobbled road" class="wp-image-1121957" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/39.jpg?w=1333" width="1333" /&gt;&lt;div class="image-credit"&gt;ELENA SUBACH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="a Starlink unit mounted to the roof of a vehicle with pink tinted windows" class="wp-image-1121961" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/36a.jpg?w=1333" width="1333" /&gt;&lt;div class="image-credit"&gt;ELENA SUBACH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="class"&gt; &lt;p class="imageSet__caption"&gt;Kovalskyy and his crew of eight volunteers have repaired or customized more than 15,000 terminals since the war began in February 2022. Here, they test repaired units in a nearby parking lot.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;Kovalskyy gave &lt;em&gt;MIT Technology Review &lt;/em&gt;exclusive access to his unofficial Starlink repair workshop in the city of Lviv, about 300 miles west of Kyiv. Ordered chaos is the best way to describe it: Spread across a few small rooms in a nondescript two-story building behind a tile shop, sagging cardboard boxes filled with mud-splattered Starlink casings form alleyways among the rubble of spare parts. Like flying buttresses, green circuit boards seem to prop up the walls, and coils of cable sprout from every crevice.&lt;/p&gt;  &lt;p&gt;Those acquainted with the workshop refer to it as the biggest of its kind in Ukraine—and, by extension, maybe the world. Official and unofficial estimates suggest that anywhere from 42,000 to 160,000 Starlink terminals operate in the country. Kovalskyy says he and his crew of eight volunteers have repaired or customized more than 15,000 terminals since the war began&lt;em&gt;.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="a surface scattered with pieces of used blue tape of various colors and sizes. Two ziploc bags with small metal parts are also taped up." class="wp-image-1121953" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/20.jpg?w=3000" /&gt;&lt;figcaption class="wp-element-caption"&gt;The informal, accessible nature of the Narodnyi Starlink community has been critical to its success. One military communications officer was inspired by Kovalskyy to set up his own repair workshop as part of Ukraine’s armed forces, but he says that official processes can be slower than private ones by a factor of 10.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;ELENA SUBACH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Despite the pressure, the chance that they may lose access to Starlink was not worrying volunteers like Kovalskyy at the time of my visit; in our conversations, it was clear they had more pressing concerns than the whims of a foreign tech mogul. Russia continues to launch frequent aerial bombardments of Ukrainian cities, sometimes sending more than 500 drones in a single night. The threat of involuntary mobilization to the front line looms on every street corner. How can one plan for a hypothetical future crisis when crisis defines every minute of one’s day?&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;Almost every inch of every axis of the battlefield in Ukraine is enabled by Starlink. It connects pilots near the trenches with reconnaissance drones soaring kilometers above them. It relays the video feeds from those drones to command centers in rear positions. And it even connects soldiers, via encrypted messaging services, with their family and friends living far from the front.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Although some soldiers and volunteers, including members of Narodnyi Starlink&lt;em&gt;, &lt;/em&gt;refer to Starlink as a luxury, the reality is that it’s an essential utility; without it, Ukrainian forces would need to rely on other, often less effective means of communication. These include wired-line networks, mobile internet, and older geostationary satellite technology—all of which provide connectivity that is either slower, more vulnerable to interference, or more difficult for untrained soldiers to set up.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“If not for Starlink, we would already be counting rubles in Kyiv,” Kovalskyy says.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div class="imageSet__wrap"&gt;&lt;div class="columns__wrapper--07c4096a3b25e22dc82ee78b6368d947"&gt;&lt;div class="wp-block-columns"&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="close up of a Starlink unit on the lap of a volunteer, who is writing notes in a gridded notebook" class="wp-image-1121950" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/13.jpg?w=1333" width="1333" /&gt;&lt;div class="image-credit"&gt;ELENA SUBACH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="a hand holding pieces of shrapnel" class="wp-image-1121958" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/47.jpg?w=1333" width="1333" /&gt;&lt;div class="image-credit"&gt;ELENA SUBACH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="class"&gt; &lt;p class="imageSet__caption"&gt;The workshop’s crew has learned to perform adjustments to terminals, especially in adapting them for battlefield conditions. At right, a volunteer engineer shows the fragments of shrapnel he has extracted from the terminals.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_13"&gt; &lt;p&gt;Despite being designed primarily for commercial use, Starlink provides a fantastic battlefield solution. The low-latency, high-bandwidth connection its terminals establish with its constellation of low-Earth-orbit satellites can transmit large streams of data while remaining very difficult for the enemy to jam—in part because the satellites, unlike geostationary ones, are in constant motion.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It’s also fairly easy to use, so that soldiers with little or no technical knowledge can connect in minutes. And the system costs much less than other military technology; while the US and Polish governments pay business rates for many of Ukraine’s Starlink systems, individual soldiers or military units can purchase the hardware at the private rate of about $500, and subscribe for just $50 per month.&lt;/p&gt;  &lt;p&gt;No alternatives match Starlink for cost, ease of use, or coverage—and none will in the near future. Its constellation of 8,000 satellites dwarfs that of its main competitor, a service called OneWeb sold by the French satellite operator Eutelsat, which has only 630 satellites. OneWeb’s hardware costs about 20 times more, and a subscription can run significantly higher, since OneWeb targets business customers. Amazon’s Project Kuiper, the most likely future competitor, started putting satellites in space only this year.&amp;nbsp;&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;Volodymyr Stepanets, a 51-year-old Ukrainian self-described “geek,” had been living in Krakow, Poland, with his family when Russia invaded in 2022. But before that, he had volunteered for several years on the front lines of the war against Russian-supported paramilitaries that began in 2014.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_15"&gt; &lt;p&gt;He recalls, in those early months in eastern Ukraine, witnessing troops coordinating an air strike with rulers and a calculator; the whole process took them between 30 and 40 minutes. “All these calculations can be done in one minute,” he says he told them. “All we need is a very stupid computer and very easy software.” (The Ukrainian military declined to comment on this issue.)&lt;/p&gt;  &lt;p&gt;Stepanets subsequently committed to helping this brigade, the 72nd, integrate modern technology into its operations. He says that within one year, he had taught them how to use modern communication platforms, positioning devices, and older satellite communication systems that predate Starlink.&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="a Starlink terminal with leaves inside the housing, seen lit in silhouette and numbered 5566" class="wp-image-1121959" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/111.jpg?w=3000" /&gt;&lt;figcaption class="wp-element-caption"&gt;Narodnyi Starlink members ask each other for advice about how to adapt the systems: how to camouflage them from marauding Russian drones or resolve glitches in the software, for example.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;ELENA SUBACH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;So after Russian tanks rolled across the border, Stepanets was quick to see how Starlink’s service could provide an advantage to Ukraine’s armed forces. He also recognized that these units, as well as civilian users, would need support in utilizing the new technology. And that’s how he came up with the idea for Narodnyi Starlink, an open Facebook group he launched on March 21, just a few weeks after the full invasion began and the Ukrainian government requested the activation of Starlink.&lt;/p&gt;  &lt;p&gt;Over the past few years, the Narodnyi Starlink digital community has grown to include volunteer engineers, resellers, and military service members interested in the satellite comms service. The group’s members post roughly three times per day, often sharing or asking for advice about adaptations, or seeking volunteers to fix broken equipment. A user called Igor Semenyak recently asked, for example, whether anyone knew how to mask his system from infrared cameras. “How do you protect yourself from heat radiation?” he wrote, to which someone suggested throwing special heat-proof fabric over the terminal.&lt;/p&gt; 
 &lt;p&gt;Its most famous member is probably a man widely considered the brains of the group: Oleg Kutkov, a 36-year-old software engineer otherwise known to some members as “Dr. Starlink.” Kutkov had been privately studying Starlink technology from his home in Kyiv since 2021, having purchased a system to tinker with when service was still unavailable in the country; he believes that he may have been the country’s first Starlink user. Like Stepanets, he saw the immense potential for Starlink after Russia broke traditional communication lines ahead of its attack.&lt;/p&gt;  &lt;p&gt;“Our infrastructure was very vulnerable because we did not have a lot of air defense,” says Kutkov, who still works full time as an engineer at the US networking company Ubiquiti’s R&amp;amp;D center in Kyiv. “Starlink quickly became a crucial part of our survival.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_17"&gt; &lt;p&gt;Stepanets contacted Kutkov after coming across his popular Twitter feed and blog, which had been attracting a lot of attention as early Starlink users sought help. Kutkov still publishes the results of his own research there—experiments he performs in his spare time, sometimes staying up until 3 a.m. to complete them. In May, for example, he published a blog post explaining how users can physically move a user account from one terminal to another when the printed circuit board in one is “so severely damaged that repair is impossible or impractical.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Oleg Kutkov is the coolest engineer I’ve met in my entire life,” Kovalskyy says.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="imageSet__wrap"&gt;&lt;div class="columns__wrapper--07c4096a3b25e22dc82ee78b6368d947"&gt;&lt;div class="wp-block-columns"&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="a volunteer holding a Starlink vertically to pry it open" class="wp-image-1121949" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/10.jpg?w=1333" width="1333" /&gt;&lt;div class="image-credit"&gt;ELENA SUBACH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="two volunteers at workbenches repairing terminals" class="wp-image-1121948" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/6.jpg?w=1333" width="1333" /&gt;&lt;div class="image-credit"&gt;ELENA SUBACH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="class"&gt; &lt;p class="imageSet__caption"&gt;When the fighting is at its worst, the workshop may receive 500 terminals to repair every month. The crew lives and sometimes even sleeps there.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_20"&gt; &lt;p&gt;Supported by Kutkov’s technical expertise and Stepanets’s organizational prowess, Kovalskyy’s warehouse became the major repair hub (though other volunteers also make repairs elsewhere). Over time, Kovalskyy—who co-owned a regional internet service provider before the war—and his crew have learned to perform adjustments to Starlink terminals, especially to adapt them for battlefield conditions. For example, they modified them to receive charge at the right voltage directly from vehicles, years before Starlink released a proprietary car adapter. They’ve also switched out Starlink’s proprietary SPX plugs—which Kovalskyy criticized as vulnerable to moisture and temperature changes—with standard ethernet ports.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Together, the three civilians—Kutkov, Stepanets, and Kovalskyy—effectively lead Narodnyi Starlink. Along with several other members who wished to remain anonymous, they hold meetings every Monday over Zoom to discuss their activities, including recent Starlink-related developments on the battlefield, as well as information security.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;While the public group served as a suitable means of disseminating information in the early stages of the war when speed was critical, they have had to move a lot of their communications to private channels after discovering Russian surveillance; Stepanets says that at least as early as 2024, Russians had translated a 300-page educational document they had produced and shared online. Now, as administrators of the Facebook group, the three men block the publication of any posts deemed to reveal information that might be useful to Russian forces.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Stepanets believes the threat extends beyond the group’s intel to its members’ physical safety. When we talked, he brought up the attempted assassination of the Ukrainian activist and volunteer Serhii Sternenko in May this year. Although Sternenko was unaffiliated with Narodnyi Starlink, the event served as a clear reminder of the risks even civilian volunteers undertake in wartime Ukraine. “The Russian FSB and other [security] services still understand the importance of participation in initiatives like [Narodnyi Starlink],” Stepanets says. He stresses that the group is not an organization with a centralized chain of command, but a community that would continue operating if any of its members were no longer able to perform their roles.&amp;nbsp;&lt;/p&gt; 
&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="closeup of a Starlink board with light shining through the holes" class="wp-image-1121947" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/5.jpg?w=3000" /&gt;&lt;figcaption class="wp-element-caption"&gt; “We have extremely professional engineers who are extremely intelligent,” Kovalskyy told me. “Repairing Starlink terminals for them is like shooting ducks with HIMARS [a vehicle-borne GPS-guided rocket launcher].”&lt;/figcaption&gt;&lt;div class="image-credit"&gt;ELENA SUBACH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;The informal, accessible nature of this community has been critical to its success. Operating outside official structures has allowed Narodnyi Starlink&lt;em&gt; &lt;/em&gt;to function much more efficiently than state channels. Yuri Krylach, a military communications officer who was inspired by Kovalskyy to set up his own repair workshop as part of Ukraine’s armed forces, says that official processes can be slower than private ones by a factor of 10; his own team’s work is often interrupted by other tasks that commanders deem more urgent, whereas members of the Narodnyi Starlink&lt;em&gt; &lt;/em&gt;community can respond to requests quickly and directly. (The military declined to comment on this issue, or on any military connections with Narodnyi Starlink.)&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;Most of the Narodnyi Starlink members I spoke to, including active-duty soldiers, were unconcerned about the report that Musk might withdraw access to the service in Ukraine. They pointed out that doing so would involve terminating state contracts, including those with the US Department of Defense and Poland’s Ministry of Digitalization. Losing contracts worth hundreds of millions of dollars (the Polish government claims to pay $50 million per year in subscription fees), on top of the private subscriptions, would cost the company a significant amount of revenue. “I don’t really think that Musk would cut this money supply,” Kutkov says. “It would be quite stupid.” Oleksandr Dolynyak, an officer in the 103rd Separate Territorial Defense Brigade and a Narodnyi Starlink member since 2022, says: “As long as it is profitable for him, Starlink will work for us.”&lt;/p&gt;  &lt;p&gt;Stepanets does believe, however, that Musk’s threats exposed an overreliance on the technology that few had properly considered. “Starlink has really become one of the powerful tools of defense of Ukraine,” he wrote in a March Facebook post entitled “Irreversible Starlink hegemony,” accompanied by an image of the evil Darth Sidious from &lt;em&gt;Star Wars&lt;/em&gt;. “Now, the issue of the country's dependence on the decisions of certain eccentric individuals … has reached [a] melting point.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_22"&gt; &lt;p&gt;Even if telecommunications experts both inside and outside the military agree that Starlink has no direct substitute, Stepanets believes that Ukraine needs to diversify its portfolio of satellite communication tools anyway, integrating additional high-speed satellite communication services like OneWeb. This would relieve some of the pressure caused by Musk’s erratic, unpredictable personality and, he believes, give Ukraine some sense of control over its wartime communications. (SpaceX did not respond to a request for comment.)&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_25"&gt; &lt;p&gt;The Ukrainian military seems to agree with this notion. In late March, at a closed-door event in Kyiv, the country’s then-deputy minister of defense Kateryna Chernohorenko announced the formation of a special Space Policy Directorate “to consolidate internal and external capabilities to advance Ukraine’s military space sector.” The announcement referred to the creation of a domestic “satellite constellation,” which suggests that reliance on foreign services like Starlink had been a catalyst. “Ukraine needs to transition from the role of consumer to that of a full-fledged player in the space sector,” a government blog post stated. (Chernohorenko did not respond to a request for comment.)&lt;/p&gt;  &lt;p&gt;Ukraine isn’t alone in this quandary. Recent discussions about a potential Starlink deal with the Italian government, for example, have stalled as a result of Musk’s behavior. And as Juliana Süss, an associate fellow at the UK’s Royal United Services Institute, points out, Taiwan chose SpaceX’s competitor Eutelsat when it sought a satellite communications partner in 2023.&lt;/p&gt;  &lt;p&gt;“I think we always knew that SpaceX is not always the most reliable partner,” says Süss, who also hosts RUSI’s &lt;em&gt;War in Space&lt;/em&gt; podcast, citing Musk’s controversial comments about the country’s status. “The Taiwan problems are a good example for how the rest of the world might be feeling about this.”&lt;/p&gt;  &lt;p&gt;Nevertheless, Ukraine is about to become even more deeply enmeshed with Starlink; the country’s leading mobile operator Kyivstar announced in July that Ukraine will soon become the first European nation to offer Starlink direct-to-mobile services. Süss is cautious about placing too much emphasis on this development though. “This step does increase dependency,” she says. “But that dependency is already there.” Adding an additional channel of communications as a possible backup is otherwise a logical action for a country at war, she says.&lt;/p&gt; 
 &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;These issues can feel far away for the many Ukrainians who are just trying to make it through to the next day. Despite its location in the far west of Ukraine, Lviv, home to Kovalskyy’s shop, is still frequently hit by Russian kamikaze drones, and local military-affiliated sites are popular targets.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Still, during our time together, Kovalskyy was far more worried by the prospect of his team’s possible mobilization. In March, the Ministry of Defense had removed the special status that had otherwise protected his people from involuntary conscription given the nature of their volunteer activities. They’re now at risk of being essentially picked up off the street by Ukraine’s dreaded military recruitment teams, known as the TCK, whenever they leave the house.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="A room with walls covered by a grid of patches and Ukrainian flags, and stacks of grey boxes on the floor" class="wp-image-1121960" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/PXL_20250318_094328754.jpg?w=2859" width="2859" /&gt;&lt;figcaption class="wp-element-caption"&gt;The repair shop displays patches from many different Ukrainian military units—each given as a gift for their services. “We sometimes perform miracles with Starlinks,” Kovalskyy said.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF THE AUTHOR&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;This is true even though there’s so much demand for the workshop’s services that during my visit, Kovalskyy expressed frustration at the vast amount of time they’ve had to dedicate solely to basic repairs. “We have extremely professional engineers who are extremely intelligent,” he told me. “Repairing Starlink terminals for them is like shooting ducks with HIMARS [a vehicle-borne GPS-guided rocket launcher].”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;At least the situation seemed to have become better on the front over the winter, Kovalskyy added, handing me a Starlink antenna whose flat, white surface had been ripped open by shrapnel. When the fighting is at its worst, the team might receive 500 terminals to repair every month, and the crew lives in the workshop, sometimes even sleeping there. But at that moment in time, it was receiving only a couple of hundred.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_27"&gt;&lt;p&gt;We ended our morning at the workshop by browsing its vast collection of varied military patches, pinned to the wall on large pieces of Velcro. Each had been given as a gift by a different unit as thanks for the services of Kovalskyy and his team, an indication of the diversity and size of Ukraine’s military: almost 1 million soldiers protecting a 600-mile front line. At the same time, it’s a physical reminder that they almost all rely on a single technology with just a few production factories located on another continent nearly 6,000 miles away.&lt;/p&gt;  &lt;p&gt;“We sometimes perform miracles with Starlinks,” Kovalskyy says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;He and his crew can only hope that they will still be able to for the foreseeable future—or, better yet, that they won’t need to at all.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Charlie Metcalfe is a British journalist. He writes for magazines and newspapers including &lt;/em&gt;Wired&lt;em&gt;, the &lt;/em&gt;Guardian&lt;em&gt;, and &lt;/em&gt;MIT Technology Review&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Oleh Kovalskyy thinks that Starlink terminals are built as if someone assembled them with their feet. Or perhaps with their hands behind their back.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;To demonstrate this last image, Kovalskyy—a large, 47-year-old Ukrainian, clad in sweatpants and with tattoos stretching from his wrists up to his neck—leans over to wiggle his fingers in the air behind him, laughing as he does. Components often detach, he says through bleached-white teeth, and they’re sensitive to dust and moisture. “It’s terrible quality. Very terrible.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;But even if he’s not particularly impressed by the production quality, he won’t dispute how important the satellite internet service has been to his country’s defense.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Starlink is absolutely critical to Ukraine’s ability to continue in the fight against Russia: It’s how troops in battle zones stay connected with faraway HQs; it’s how many of the drones essential to Ukraine’s survival hit their targets; it’s even how soldiers stay in touch with spouses and children back home.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;At the time of my visit to Kovalskyy in March 2025, however, it had begun to seem like this vital support system may suddenly disappear. Reuters had just broken news that suggested Musk, who was then still deeply enmeshed in Trump world, would remove Ukraine’s access to the service should its government fail to toe the line in US-led peace negotiations. Musk denied the allegations shortly afterward, but given Trump’s fickle foreign policy and inconsistent support of Ukrainian president Volodymyr Zelensky, the uncertainty of the technology’s future had become—and remains—impossible to ignore.&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="imageSet__wrap"&gt;&lt;div class="columns__wrapper--07c4096a3b25e22dc82ee78b6368d947"&gt;&lt;div class="wp-block-columns"&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="a view down at the back of a volunteer working in a corner workbench. Tools and components are piled on every bit of the surface as well as the shelves in front of him." class="wp-image-1121951" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/16.jpg?w=1333" width="1333" /&gt;&lt;div class="image-credit"&gt;ELENA SUBACH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="a carboard box stuffed with grey cylinders" class="wp-image-1121952" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/20-2.jpg?w=1333" width="1333" /&gt;&lt;div class="image-credit"&gt;ELENA SUBACH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="class"&gt; &lt;p class="imageSet__caption"&gt;Kovalskyy’s unofficial Starlink repair shop may be the biggest of its kind in the world. Ordered chaos is the best way to describe it.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;The stakes couldn’t be higher: Another Reuters report in late July revealed that Musk had ordered the restriction of Starlink in parts of Ukraine during a critical counteroffensive back in 2022. “Ukrainian troops suddenly faced a communications blackout,” the story explains. “Soldiers panicked, drones surveilling Russian forces went dark, and long-range artillery units, reliant on Starlink to aim their fire, struggled to hit targets.”&lt;/p&gt; 
 &lt;p&gt;None of this is lost on Kovalskyy—and for now Starlink access largely comes down to the unofficial community of users and engineers of which Kovalskyy is just one part: Narodnyi Starlink.&lt;/p&gt;  &lt;p&gt;The group, whose name translates to “The People’s Starlink,” was created back in March 2022 by a tech-savvy veteran of the previous battles against Russia-backed militias in Ukraine’s east. It started as a Facebook group for the country’s infant yet burgeoning community of Starlink users—a forum to share guidance and swap tips—but it very quickly emerged as a major support system for the new war effort. Today, it has grown to almost 20,000 members, including the unofficial expert “Dr. Starlink”—famous for his creative ways of customizing the systems—and other volunteer engineers like Kovalskyy and his men. It’s a prime example of the many informal, yet highly effective, volunteer networks that have kept Ukraine in the fight, both on and off the front line.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div class="imageSet__wrap"&gt;&lt;div class="columns__wrapper--07c4096a3b25e22dc82ee78b6368d947"&gt;&lt;div class="wp-block-columns"&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="A repaired and mounted Starlink terminal standing on a cobbled road" class="wp-image-1121957" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/39.jpg?w=1333" width="1333" /&gt;&lt;div class="image-credit"&gt;ELENA SUBACH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="a Starlink unit mounted to the roof of a vehicle with pink tinted windows" class="wp-image-1121961" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/36a.jpg?w=1333" width="1333" /&gt;&lt;div class="image-credit"&gt;ELENA SUBACH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="class"&gt; &lt;p class="imageSet__caption"&gt;Kovalskyy and his crew of eight volunteers have repaired or customized more than 15,000 terminals since the war began in February 2022. Here, they test repaired units in a nearby parking lot.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;Kovalskyy gave &lt;em&gt;MIT Technology Review &lt;/em&gt;exclusive access to his unofficial Starlink repair workshop in the city of Lviv, about 300 miles west of Kyiv. Ordered chaos is the best way to describe it: Spread across a few small rooms in a nondescript two-story building behind a tile shop, sagging cardboard boxes filled with mud-splattered Starlink casings form alleyways among the rubble of spare parts. Like flying buttresses, green circuit boards seem to prop up the walls, and coils of cable sprout from every crevice.&lt;/p&gt;  &lt;p&gt;Those acquainted with the workshop refer to it as the biggest of its kind in Ukraine—and, by extension, maybe the world. Official and unofficial estimates suggest that anywhere from 42,000 to 160,000 Starlink terminals operate in the country. Kovalskyy says he and his crew of eight volunteers have repaired or customized more than 15,000 terminals since the war began&lt;em&gt;.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="a surface scattered with pieces of used blue tape of various colors and sizes. Two ziploc bags with small metal parts are also taped up." class="wp-image-1121953" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/20.jpg?w=3000" /&gt;&lt;figcaption class="wp-element-caption"&gt;The informal, accessible nature of the Narodnyi Starlink community has been critical to its success. One military communications officer was inspired by Kovalskyy to set up his own repair workshop as part of Ukraine’s armed forces, but he says that official processes can be slower than private ones by a factor of 10.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;ELENA SUBACH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Despite the pressure, the chance that they may lose access to Starlink was not worrying volunteers like Kovalskyy at the time of my visit; in our conversations, it was clear they had more pressing concerns than the whims of a foreign tech mogul. Russia continues to launch frequent aerial bombardments of Ukrainian cities, sometimes sending more than 500 drones in a single night. The threat of involuntary mobilization to the front line looms on every street corner. How can one plan for a hypothetical future crisis when crisis defines every minute of one’s day?&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;Almost every inch of every axis of the battlefield in Ukraine is enabled by Starlink. It connects pilots near the trenches with reconnaissance drones soaring kilometers above them. It relays the video feeds from those drones to command centers in rear positions. And it even connects soldiers, via encrypted messaging services, with their family and friends living far from the front.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Although some soldiers and volunteers, including members of Narodnyi Starlink&lt;em&gt;, &lt;/em&gt;refer to Starlink as a luxury, the reality is that it’s an essential utility; without it, Ukrainian forces would need to rely on other, often less effective means of communication. These include wired-line networks, mobile internet, and older geostationary satellite technology—all of which provide connectivity that is either slower, more vulnerable to interference, or more difficult for untrained soldiers to set up.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“If not for Starlink, we would already be counting rubles in Kyiv,” Kovalskyy says.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div class="imageSet__wrap"&gt;&lt;div class="columns__wrapper--07c4096a3b25e22dc82ee78b6368d947"&gt;&lt;div class="wp-block-columns"&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="close up of a Starlink unit on the lap of a volunteer, who is writing notes in a gridded notebook" class="wp-image-1121950" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/13.jpg?w=1333" width="1333" /&gt;&lt;div class="image-credit"&gt;ELENA SUBACH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="a hand holding pieces of shrapnel" class="wp-image-1121958" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/47.jpg?w=1333" width="1333" /&gt;&lt;div class="image-credit"&gt;ELENA SUBACH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="class"&gt; &lt;p class="imageSet__caption"&gt;The workshop’s crew has learned to perform adjustments to terminals, especially in adapting them for battlefield conditions. At right, a volunteer engineer shows the fragments of shrapnel he has extracted from the terminals.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_13"&gt; &lt;p&gt;Despite being designed primarily for commercial use, Starlink provides a fantastic battlefield solution. The low-latency, high-bandwidth connection its terminals establish with its constellation of low-Earth-orbit satellites can transmit large streams of data while remaining very difficult for the enemy to jam—in part because the satellites, unlike geostationary ones, are in constant motion.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It’s also fairly easy to use, so that soldiers with little or no technical knowledge can connect in minutes. And the system costs much less than other military technology; while the US and Polish governments pay business rates for many of Ukraine’s Starlink systems, individual soldiers or military units can purchase the hardware at the private rate of about $500, and subscribe for just $50 per month.&lt;/p&gt;  &lt;p&gt;No alternatives match Starlink for cost, ease of use, or coverage—and none will in the near future. Its constellation of 8,000 satellites dwarfs that of its main competitor, a service called OneWeb sold by the French satellite operator Eutelsat, which has only 630 satellites. OneWeb’s hardware costs about 20 times more, and a subscription can run significantly higher, since OneWeb targets business customers. Amazon’s Project Kuiper, the most likely future competitor, started putting satellites in space only this year.&amp;nbsp;&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;Volodymyr Stepanets, a 51-year-old Ukrainian self-described “geek,” had been living in Krakow, Poland, with his family when Russia invaded in 2022. But before that, he had volunteered for several years on the front lines of the war against Russian-supported paramilitaries that began in 2014.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_15"&gt; &lt;p&gt;He recalls, in those early months in eastern Ukraine, witnessing troops coordinating an air strike with rulers and a calculator; the whole process took them between 30 and 40 minutes. “All these calculations can be done in one minute,” he says he told them. “All we need is a very stupid computer and very easy software.” (The Ukrainian military declined to comment on this issue.)&lt;/p&gt;  &lt;p&gt;Stepanets subsequently committed to helping this brigade, the 72nd, integrate modern technology into its operations. He says that within one year, he had taught them how to use modern communication platforms, positioning devices, and older satellite communication systems that predate Starlink.&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="a Starlink terminal with leaves inside the housing, seen lit in silhouette and numbered 5566" class="wp-image-1121959" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/111.jpg?w=3000" /&gt;&lt;figcaption class="wp-element-caption"&gt;Narodnyi Starlink members ask each other for advice about how to adapt the systems: how to camouflage them from marauding Russian drones or resolve glitches in the software, for example.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;ELENA SUBACH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;So after Russian tanks rolled across the border, Stepanets was quick to see how Starlink’s service could provide an advantage to Ukraine’s armed forces. He also recognized that these units, as well as civilian users, would need support in utilizing the new technology. And that’s how he came up with the idea for Narodnyi Starlink, an open Facebook group he launched on March 21, just a few weeks after the full invasion began and the Ukrainian government requested the activation of Starlink.&lt;/p&gt;  &lt;p&gt;Over the past few years, the Narodnyi Starlink digital community has grown to include volunteer engineers, resellers, and military service members interested in the satellite comms service. The group’s members post roughly three times per day, often sharing or asking for advice about adaptations, or seeking volunteers to fix broken equipment. A user called Igor Semenyak recently asked, for example, whether anyone knew how to mask his system from infrared cameras. “How do you protect yourself from heat radiation?” he wrote, to which someone suggested throwing special heat-proof fabric over the terminal.&lt;/p&gt; 
 &lt;p&gt;Its most famous member is probably a man widely considered the brains of the group: Oleg Kutkov, a 36-year-old software engineer otherwise known to some members as “Dr. Starlink.” Kutkov had been privately studying Starlink technology from his home in Kyiv since 2021, having purchased a system to tinker with when service was still unavailable in the country; he believes that he may have been the country’s first Starlink user. Like Stepanets, he saw the immense potential for Starlink after Russia broke traditional communication lines ahead of its attack.&lt;/p&gt;  &lt;p&gt;“Our infrastructure was very vulnerable because we did not have a lot of air defense,” says Kutkov, who still works full time as an engineer at the US networking company Ubiquiti’s R&amp;amp;D center in Kyiv. “Starlink quickly became a crucial part of our survival.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_17"&gt; &lt;p&gt;Stepanets contacted Kutkov after coming across his popular Twitter feed and blog, which had been attracting a lot of attention as early Starlink users sought help. Kutkov still publishes the results of his own research there—experiments he performs in his spare time, sometimes staying up until 3 a.m. to complete them. In May, for example, he published a blog post explaining how users can physically move a user account from one terminal to another when the printed circuit board in one is “so severely damaged that repair is impossible or impractical.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Oleg Kutkov is the coolest engineer I’ve met in my entire life,” Kovalskyy says.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="imageSet__wrap"&gt;&lt;div class="columns__wrapper--07c4096a3b25e22dc82ee78b6368d947"&gt;&lt;div class="wp-block-columns"&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="a volunteer holding a Starlink vertically to pry it open" class="wp-image-1121949" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/10.jpg?w=1333" width="1333" /&gt;&lt;div class="image-credit"&gt;ELENA SUBACH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="two volunteers at workbenches repairing terminals" class="wp-image-1121948" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/6.jpg?w=1333" width="1333" /&gt;&lt;div class="image-credit"&gt;ELENA SUBACH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="class"&gt; &lt;p class="imageSet__caption"&gt;When the fighting is at its worst, the workshop may receive 500 terminals to repair every month. The crew lives and sometimes even sleeps there.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_20"&gt; &lt;p&gt;Supported by Kutkov’s technical expertise and Stepanets’s organizational prowess, Kovalskyy’s warehouse became the major repair hub (though other volunteers also make repairs elsewhere). Over time, Kovalskyy—who co-owned a regional internet service provider before the war—and his crew have learned to perform adjustments to Starlink terminals, especially to adapt them for battlefield conditions. For example, they modified them to receive charge at the right voltage directly from vehicles, years before Starlink released a proprietary car adapter. They’ve also switched out Starlink’s proprietary SPX plugs—which Kovalskyy criticized as vulnerable to moisture and temperature changes—with standard ethernet ports.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Together, the three civilians—Kutkov, Stepanets, and Kovalskyy—effectively lead Narodnyi Starlink. Along with several other members who wished to remain anonymous, they hold meetings every Monday over Zoom to discuss their activities, including recent Starlink-related developments on the battlefield, as well as information security.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;While the public group served as a suitable means of disseminating information in the early stages of the war when speed was critical, they have had to move a lot of their communications to private channels after discovering Russian surveillance; Stepanets says that at least as early as 2024, Russians had translated a 300-page educational document they had produced and shared online. Now, as administrators of the Facebook group, the three men block the publication of any posts deemed to reveal information that might be useful to Russian forces.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Stepanets believes the threat extends beyond the group’s intel to its members’ physical safety. When we talked, he brought up the attempted assassination of the Ukrainian activist and volunteer Serhii Sternenko in May this year. Although Sternenko was unaffiliated with Narodnyi Starlink, the event served as a clear reminder of the risks even civilian volunteers undertake in wartime Ukraine. “The Russian FSB and other [security] services still understand the importance of participation in initiatives like [Narodnyi Starlink],” Stepanets says. He stresses that the group is not an organization with a centralized chain of command, but a community that would continue operating if any of its members were no longer able to perform their roles.&amp;nbsp;&lt;/p&gt; 
&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="closeup of a Starlink board with light shining through the holes" class="wp-image-1121947" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/5.jpg?w=3000" /&gt;&lt;figcaption class="wp-element-caption"&gt; “We have extremely professional engineers who are extremely intelligent,” Kovalskyy told me. “Repairing Starlink terminals for them is like shooting ducks with HIMARS [a vehicle-borne GPS-guided rocket launcher].”&lt;/figcaption&gt;&lt;div class="image-credit"&gt;ELENA SUBACH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;The informal, accessible nature of this community has been critical to its success. Operating outside official structures has allowed Narodnyi Starlink&lt;em&gt; &lt;/em&gt;to function much more efficiently than state channels. Yuri Krylach, a military communications officer who was inspired by Kovalskyy to set up his own repair workshop as part of Ukraine’s armed forces, says that official processes can be slower than private ones by a factor of 10; his own team’s work is often interrupted by other tasks that commanders deem more urgent, whereas members of the Narodnyi Starlink&lt;em&gt; &lt;/em&gt;community can respond to requests quickly and directly. (The military declined to comment on this issue, or on any military connections with Narodnyi Starlink.)&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;Most of the Narodnyi Starlink members I spoke to, including active-duty soldiers, were unconcerned about the report that Musk might withdraw access to the service in Ukraine. They pointed out that doing so would involve terminating state contracts, including those with the US Department of Defense and Poland’s Ministry of Digitalization. Losing contracts worth hundreds of millions of dollars (the Polish government claims to pay $50 million per year in subscription fees), on top of the private subscriptions, would cost the company a significant amount of revenue. “I don’t really think that Musk would cut this money supply,” Kutkov says. “It would be quite stupid.” Oleksandr Dolynyak, an officer in the 103rd Separate Territorial Defense Brigade and a Narodnyi Starlink member since 2022, says: “As long as it is profitable for him, Starlink will work for us.”&lt;/p&gt;  &lt;p&gt;Stepanets does believe, however, that Musk’s threats exposed an overreliance on the technology that few had properly considered. “Starlink has really become one of the powerful tools of defense of Ukraine,” he wrote in a March Facebook post entitled “Irreversible Starlink hegemony,” accompanied by an image of the evil Darth Sidious from &lt;em&gt;Star Wars&lt;/em&gt;. “Now, the issue of the country's dependence on the decisions of certain eccentric individuals … has reached [a] melting point.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_22"&gt; &lt;p&gt;Even if telecommunications experts both inside and outside the military agree that Starlink has no direct substitute, Stepanets believes that Ukraine needs to diversify its portfolio of satellite communication tools anyway, integrating additional high-speed satellite communication services like OneWeb. This would relieve some of the pressure caused by Musk’s erratic, unpredictable personality and, he believes, give Ukraine some sense of control over its wartime communications. (SpaceX did not respond to a request for comment.)&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_25"&gt; &lt;p&gt;The Ukrainian military seems to agree with this notion. In late March, at a closed-door event in Kyiv, the country’s then-deputy minister of defense Kateryna Chernohorenko announced the formation of a special Space Policy Directorate “to consolidate internal and external capabilities to advance Ukraine’s military space sector.” The announcement referred to the creation of a domestic “satellite constellation,” which suggests that reliance on foreign services like Starlink had been a catalyst. “Ukraine needs to transition from the role of consumer to that of a full-fledged player in the space sector,” a government blog post stated. (Chernohorenko did not respond to a request for comment.)&lt;/p&gt;  &lt;p&gt;Ukraine isn’t alone in this quandary. Recent discussions about a potential Starlink deal with the Italian government, for example, have stalled as a result of Musk’s behavior. And as Juliana Süss, an associate fellow at the UK’s Royal United Services Institute, points out, Taiwan chose SpaceX’s competitor Eutelsat when it sought a satellite communications partner in 2023.&lt;/p&gt;  &lt;p&gt;“I think we always knew that SpaceX is not always the most reliable partner,” says Süss, who also hosts RUSI’s &lt;em&gt;War in Space&lt;/em&gt; podcast, citing Musk’s controversial comments about the country’s status. “The Taiwan problems are a good example for how the rest of the world might be feeling about this.”&lt;/p&gt;  &lt;p&gt;Nevertheless, Ukraine is about to become even more deeply enmeshed with Starlink; the country’s leading mobile operator Kyivstar announced in July that Ukraine will soon become the first European nation to offer Starlink direct-to-mobile services. Süss is cautious about placing too much emphasis on this development though. “This step does increase dependency,” she says. “But that dependency is already there.” Adding an additional channel of communications as a possible backup is otherwise a logical action for a country at war, she says.&lt;/p&gt; 
 &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;These issues can feel far away for the many Ukrainians who are just trying to make it through to the next day. Despite its location in the far west of Ukraine, Lviv, home to Kovalskyy’s shop, is still frequently hit by Russian kamikaze drones, and local military-affiliated sites are popular targets.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Still, during our time together, Kovalskyy was far more worried by the prospect of his team’s possible mobilization. In March, the Ministry of Defense had removed the special status that had otherwise protected his people from involuntary conscription given the nature of their volunteer activities. They’re now at risk of being essentially picked up off the street by Ukraine’s dreaded military recruitment teams, known as the TCK, whenever they leave the house.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="A room with walls covered by a grid of patches and Ukrainian flags, and stacks of grey boxes on the floor" class="wp-image-1121960" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/PXL_20250318_094328754.jpg?w=2859" width="2859" /&gt;&lt;figcaption class="wp-element-caption"&gt;The repair shop displays patches from many different Ukrainian military units—each given as a gift for their services. “We sometimes perform miracles with Starlinks,” Kovalskyy said.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF THE AUTHOR&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;This is true even though there’s so much demand for the workshop’s services that during my visit, Kovalskyy expressed frustration at the vast amount of time they’ve had to dedicate solely to basic repairs. “We have extremely professional engineers who are extremely intelligent,” he told me. “Repairing Starlink terminals for them is like shooting ducks with HIMARS [a vehicle-borne GPS-guided rocket launcher].”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;At least the situation seemed to have become better on the front over the winter, Kovalskyy added, handing me a Starlink antenna whose flat, white surface had been ripped open by shrapnel. When the fighting is at its worst, the team might receive 500 terminals to repair every month, and the crew lives in the workshop, sometimes even sleeping there. But at that moment in time, it was receiving only a couple of hundred.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_27"&gt;&lt;p&gt;We ended our morning at the workshop by browsing its vast collection of varied military patches, pinned to the wall on large pieces of Velcro. Each had been given as a gift by a different unit as thanks for the services of Kovalskyy and his team, an indication of the diversity and size of Ukraine’s military: almost 1 million soldiers protecting a 600-mile front line. At the same time, it’s a physical reminder that they almost all rely on a single technology with just a few production factories located on another continent nearly 6,000 miles away.&lt;/p&gt;  &lt;p&gt;“We sometimes perform miracles with Starlinks,” Kovalskyy says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;He and his crew can only hope that they will still be able to for the foreseeable future—or, better yet, that they won’t need to at all.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Charlie Metcalfe is a British journalist. He writes for magazines and newspapers including &lt;/em&gt;Wired&lt;em&gt;, the &lt;/em&gt;Guardian&lt;em&gt;, and &lt;/em&gt;MIT Technology Review&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/08/21/1122035/ukraines-largest-starlink-repair-shop/</guid><pubDate>Thu, 21 Aug 2025 09:00:00 +0000</pubDate></item><item><title>Why recycling isn’t enough to address the plastic problem (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/08/21/1122247/recycling-climate-emissions/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/GettyImages-1300144187.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;I remember using a princess toothbrush when I was little. The handle was purple, teal, and sparkly. Like most of the other pieces of plastic that have ever been made, it’s probably still out there somewhere, languishing in a landfill. (I just hope it’s not in the ocean.)&lt;/p&gt;  &lt;p&gt;I’ve been thinking about that toothbrush again this week after UN talks about a plastic treaty broke down on Friday. Nations had gotten together to try and write a binding treaty to address plastic waste, but negotiators left without a deal.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Plastic is widely recognized as a huge source of environmental pollution—again, I’m wondering where that toothbrush is—but the material is also a contributor to climate change. Let’s dig into why talks fell apart and how we might address emissions from plastic.&lt;/p&gt;  &lt;p&gt;I’ve defended plastic before in this newsletter (sort of). It’s a wildly useful material, integral in everything from glasses lenses to IV bags.&lt;/p&gt; 
 &lt;p&gt;But the pace at which we’re producing and using plastic is absolutely bonkers. Plastic production has increased at an average rate of 9% every year since 1950. Production hit 460 million metric tons in 2019. And an estimated 52 million metric tons are dumped into the environment or burned each year.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;So, in March 2022, the UN Environment Assembly set out to develop an international treaty to address plastic pollution. Pretty much everyone should agree that a bunch of plastic waste floating in the ocean is a bad thing. But as we’ve learned over the past few years, as these talks developed, opinions diverge on what to do about it and how any interventions should happen.&lt;/p&gt; 
 &lt;p&gt;One phrase that’s become quite contentious is the “full life cycle” of plastic. Basically, some groups are hoping to go beyond efforts to address just the end of the plastic life cycle (collecting and recycling it) by pushing for limits on plastic production. There was even talk at the Assembly of a ban on single-use plastic.&lt;/p&gt;  &lt;p&gt;Petroleum-producing nations strongly opposed production limits in the talks. Representatives from Saudi Arabia and Kuwait told the &lt;em&gt;Guardian&lt;/em&gt; that they considered limits to plastic production outside the scope of talks. The US reportedly also slowed down talks and proposed to strike a treaty article that references the full life cycle of plastics.&lt;/p&gt;  &lt;p&gt;Petrostates have a vested interest because oil, natural gas, and coal are all burned for energy used to make plastic, and they’re also used as raw materials. This stat surprised me: 12% of global oil demand and over 8% of natural gas demand is for plastic production.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;That translates into a lot of greenhouse gas emissions. One report from Lawrence Berkeley National Lab found that plastics production accounted for 2.24 billion metric tons of carbon dioxide emissions in 2019—that’s roughly 5% of the global total.&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;And looking into the future, emissions from plastics are only set to grow. Another estimate, from the Organisation for Economic Co-operation and Development, projects that emissions from plastics could swell from about 2 billion metric tons to 4 billion metric tons by 2060.&lt;/p&gt;    &lt;p&gt;This chart is what really strikes me and makes the conclusion of the plastic treaty talks such a disappointment.&lt;/p&gt;  &lt;p&gt;Recycling is a great tool, and new methods could make it possible to recycle more plastics and make it easier to do so. (I’m particularly interested in efforts to recycle a mix of plastics, cutting down on the slow and costly sorting process.)&lt;/p&gt;  &lt;p&gt;But just addressing plastic at its end of life won’t be enough to address the climate impacts of the material. Most emissions from plastic come from&lt;em&gt; making&lt;/em&gt; it. So we need new ways to make plastic, using different ingredients and fuels to take oil and gas out of the equation. And we need to be smarter about the volume of plastic we produce.&amp;nbsp;&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;One positive note here: The plastic treaty isn’t dead, just on hold for the moment. Officials say that there’s going to be an effort to revive the talks.&lt;/p&gt;  &lt;p&gt;Less than 10% of plastic that’s ever been produced has been recycled. Whether it’s a water bottle, a polyester shirt you wore a few times, or a princess toothbrush from when you were a kid, it’s still out there somewhere in a landfill or in the environment. Maybe you already knew that. But also consider this: The greenhouse gases emitted to make the plastic are still in the atmosphere, too, contributing to climate change.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark, &lt;/em&gt;MIT Technology Review&lt;em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/GettyImages-1300144187.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;I remember using a princess toothbrush when I was little. The handle was purple, teal, and sparkly. Like most of the other pieces of plastic that have ever been made, it’s probably still out there somewhere, languishing in a landfill. (I just hope it’s not in the ocean.)&lt;/p&gt;  &lt;p&gt;I’ve been thinking about that toothbrush again this week after UN talks about a plastic treaty broke down on Friday. Nations had gotten together to try and write a binding treaty to address plastic waste, but negotiators left without a deal.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Plastic is widely recognized as a huge source of environmental pollution—again, I’m wondering where that toothbrush is—but the material is also a contributor to climate change. Let’s dig into why talks fell apart and how we might address emissions from plastic.&lt;/p&gt;  &lt;p&gt;I’ve defended plastic before in this newsletter (sort of). It’s a wildly useful material, integral in everything from glasses lenses to IV bags.&lt;/p&gt; 
 &lt;p&gt;But the pace at which we’re producing and using plastic is absolutely bonkers. Plastic production has increased at an average rate of 9% every year since 1950. Production hit 460 million metric tons in 2019. And an estimated 52 million metric tons are dumped into the environment or burned each year.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;So, in March 2022, the UN Environment Assembly set out to develop an international treaty to address plastic pollution. Pretty much everyone should agree that a bunch of plastic waste floating in the ocean is a bad thing. But as we’ve learned over the past few years, as these talks developed, opinions diverge on what to do about it and how any interventions should happen.&lt;/p&gt; 
 &lt;p&gt;One phrase that’s become quite contentious is the “full life cycle” of plastic. Basically, some groups are hoping to go beyond efforts to address just the end of the plastic life cycle (collecting and recycling it) by pushing for limits on plastic production. There was even talk at the Assembly of a ban on single-use plastic.&lt;/p&gt;  &lt;p&gt;Petroleum-producing nations strongly opposed production limits in the talks. Representatives from Saudi Arabia and Kuwait told the &lt;em&gt;Guardian&lt;/em&gt; that they considered limits to plastic production outside the scope of talks. The US reportedly also slowed down talks and proposed to strike a treaty article that references the full life cycle of plastics.&lt;/p&gt;  &lt;p&gt;Petrostates have a vested interest because oil, natural gas, and coal are all burned for energy used to make plastic, and they’re also used as raw materials. This stat surprised me: 12% of global oil demand and over 8% of natural gas demand is for plastic production.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;That translates into a lot of greenhouse gas emissions. One report from Lawrence Berkeley National Lab found that plastics production accounted for 2.24 billion metric tons of carbon dioxide emissions in 2019—that’s roughly 5% of the global total.&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;And looking into the future, emissions from plastics are only set to grow. Another estimate, from the Organisation for Economic Co-operation and Development, projects that emissions from plastics could swell from about 2 billion metric tons to 4 billion metric tons by 2060.&lt;/p&gt;    &lt;p&gt;This chart is what really strikes me and makes the conclusion of the plastic treaty talks such a disappointment.&lt;/p&gt;  &lt;p&gt;Recycling is a great tool, and new methods could make it possible to recycle more plastics and make it easier to do so. (I’m particularly interested in efforts to recycle a mix of plastics, cutting down on the slow and costly sorting process.)&lt;/p&gt;  &lt;p&gt;But just addressing plastic at its end of life won’t be enough to address the climate impacts of the material. Most emissions from plastic come from&lt;em&gt; making&lt;/em&gt; it. So we need new ways to make plastic, using different ingredients and fuels to take oil and gas out of the equation. And we need to be smarter about the volume of plastic we produce.&amp;nbsp;&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;One positive note here: The plastic treaty isn’t dead, just on hold for the moment. Officials say that there’s going to be an effort to revive the talks.&lt;/p&gt;  &lt;p&gt;Less than 10% of plastic that’s ever been produced has been recycled. Whether it’s a water bottle, a polyester shirt you wore a few times, or a princess toothbrush from when you were a kid, it’s still out there somewhere in a landfill or in the environment. Maybe you already knew that. But also consider this: The greenhouse gases emitted to make the plastic are still in the atmosphere, too, contributing to climate change.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark, &lt;/em&gt;MIT Technology Review&lt;em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/08/21/1122247/recycling-climate-emissions/</guid><pubDate>Thu, 21 Aug 2025 10:00:00 +0000</pubDate></item><item><title>In a first, Google has released data on how much energy an AI prompt uses (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/08/21/1122288/google-gemini-ai-energy/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/gemini-energy3b.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Google has just released a technical report detailing how much energy its Gemini apps use for each query. In total, the median prompt—one that falls in the middle of the range of energy demand—consumes 0.24 watt-hours of electricity, the equivalent of running a standard microwave for about one second. The company also provided average estimates for the water consumption and carbon emissions associated with a text prompt to Gemini.&lt;/p&gt;  &lt;p&gt;It’s the most transparent estimate yet from a Big Tech company with a popular AI product, and the report includes detailed information about how the company calculated its final estimate. As AI has become more widely adopted, there’s been a growing effort to understand its energy use. But public efforts attempting to directly measure the energy used by AI have been hampered by a lack of full access to the operations of a major tech company.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Earlier this year, &lt;em&gt;MIT Technology Review&lt;/em&gt; published a comprehensive series on AI and energy, at which time none of the major AI companies would reveal their per-prompt energy usage. Google’s new publication, at last, allows for a peek behind the curtain that researchers and analysts have long hoped for.&lt;/p&gt;  &lt;p&gt;The study focuses on a broad look at energy demand, including not only the power used by the AI chips that run models but also by all the other infrastructure needed to support that hardware.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;“We wanted to be quite comprehensive in all the things we included,” said Jeff Dean, Google’s chief scientist, in an exclusive interview with &lt;em&gt;MIT Technology Review&lt;/em&gt; about the new report.&lt;/p&gt;  &lt;p&gt;That’s significant, because in this measurement, the AI chips—in this case, Google’s custom TPUs, the company’s proprietary equivalent of GPUs—account for just 58% of the total electricity demand of 0.24 watt-hours.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Another large portion of the energy is used by equipment needed to support AI-specific hardware: The host machine’s CPU and memory account for another 25% of the total energy used. There’s also backup equipment needed in case something fails—these idle machines account for 10% of the total. The final 8% is from overhead associated with running a data center, including cooling and power conversion.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This sort of report shows the value of industry input to energy and AI research, says Mosharaf Chowdhury, a professor at the University of Michigan and one of the heads of the ML.Energy leaderboard, which tracks energy consumption of AI models.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Estimates like Google’s are generally something that only companies can produce, because they run at a larger scale than researchers are able to and have access to behind-the-scenes information. “I think this will be a keystone piece in the AI energy field,” says Jae-Won Chung, a PhD candidate at the University of Michigan and another leader of the ML.Energy effort. “It’s the most comprehensive analysis so far.”&lt;/p&gt;  &lt;p&gt;Google’s figure, however, is not representative of all queries submitted to Gemini: The company handles a huge variety of requests, and this estimate is calculated from a median energy demand, one that falls in the middle of the range of possible queries.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;So some Gemini prompts use much more energy than this: Dean gives the example of feeding dozens of books into Gemini and asking it to produce a detailed synopsis of their content. “That’s the kind of thing that will probably take more energy than the median prompt,” Dean says. Using a reasoning model could also have a higher associated energy demand because these models take more steps before producing an answer.&lt;/p&gt;  &lt;p&gt;This report was also strictly limited to text prompts, so it doesn’t represent what’s needed to generate an image or a video. (Other analyses, including one in &lt;em&gt;MIT Technology Review&lt;/em&gt;’s Power Hungry series earlier this year, show that these tasks can require much more energy.)&lt;/p&gt;  &lt;p&gt;The report also finds that the total energy used to field a Gemini query has fallen dramatically over time. The median Gemini prompt used 33 times more energy in May 2024 than it did in May 2025, according to Google. The company points to advancements in its models and other software optimizations for the improvements.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Google also estimates the greenhouse gas emissions associated with the median prompt, which they put at 0.03 grams of carbon dioxide. To get to this number, the company multiplied the total energy used to respond to a prompt by the average emissions per unit of electricity.&lt;/p&gt; 

 &lt;p&gt;Rather than using an emissions estimate based on the US grid average, or the average of the grids where Google operates, the company instead uses a market-based estimate, which takes into account electricity purchases that the company makes from clean energy projects. The company has signed agreements to buy over 22 gigawatts of power from sources including solar, wind, geothermal, and advanced nuclear projects since 2010. Because of those purchases, Google’s emissions per unit of electricity on paper are roughly one-third of those on the average grid where it operates.&lt;/p&gt;  &lt;p&gt;AI data centers also consume water for cooling, and Google estimates that each prompt consumes 0.26 milliliters of water, or about five drops.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The goal of this work was to provide users a window into the energy use of their interactions with AI, Dean says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“People are using [AI tools] for all kinds of things, and they shouldn’t have major concerns about the energy usage or the water usage of Gemini models, because in our actual measurements, what we were able to show was that it’s actually equivalent to things you do without even thinking about it on a daily basis,” he says, “like watching a few seconds of TV or consuming five drops of water.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt;&lt;p&gt;The publication greatly expands what’s known about AI’s resource usage. It follows recent increasing pressure on companies to release more information about the energy toll of the technology. “I’m really happy that they put this out,” says Sasha Luccioni, an AI and climate researcher at Hugging Face. “People want to know what the cost is.”&lt;/p&gt;  &lt;p&gt;This estimate and the supporting report contain more public information than has been available before, and it’s helpful to get more information about AI use in real life, at scale, by a major company, Luccioni adds. However, there are still details that the company isn’t sharing in this report. One major question mark is the total number of queries that Gemini gets each day, which would allow estimates of the AI tool’s total energy demand.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And ultimately, it’s still the company deciding what details to share, and when and how. “We’ve been trying to push for a standardized AI energy score,” Luccioni says, a standard for AI similar to the Energy Star rating for appliances. “This is not a replacement or proxy for standardized comparisons.”&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/gemini-energy3b.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Google has just released a technical report detailing how much energy its Gemini apps use for each query. In total, the median prompt—one that falls in the middle of the range of energy demand—consumes 0.24 watt-hours of electricity, the equivalent of running a standard microwave for about one second. The company also provided average estimates for the water consumption and carbon emissions associated with a text prompt to Gemini.&lt;/p&gt;  &lt;p&gt;It’s the most transparent estimate yet from a Big Tech company with a popular AI product, and the report includes detailed information about how the company calculated its final estimate. As AI has become more widely adopted, there’s been a growing effort to understand its energy use. But public efforts attempting to directly measure the energy used by AI have been hampered by a lack of full access to the operations of a major tech company.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Earlier this year, &lt;em&gt;MIT Technology Review&lt;/em&gt; published a comprehensive series on AI and energy, at which time none of the major AI companies would reveal their per-prompt energy usage. Google’s new publication, at last, allows for a peek behind the curtain that researchers and analysts have long hoped for.&lt;/p&gt;  &lt;p&gt;The study focuses on a broad look at energy demand, including not only the power used by the AI chips that run models but also by all the other infrastructure needed to support that hardware.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;“We wanted to be quite comprehensive in all the things we included,” said Jeff Dean, Google’s chief scientist, in an exclusive interview with &lt;em&gt;MIT Technology Review&lt;/em&gt; about the new report.&lt;/p&gt;  &lt;p&gt;That’s significant, because in this measurement, the AI chips—in this case, Google’s custom TPUs, the company’s proprietary equivalent of GPUs—account for just 58% of the total electricity demand of 0.24 watt-hours.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Another large portion of the energy is used by equipment needed to support AI-specific hardware: The host machine’s CPU and memory account for another 25% of the total energy used. There’s also backup equipment needed in case something fails—these idle machines account for 10% of the total. The final 8% is from overhead associated with running a data center, including cooling and power conversion.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This sort of report shows the value of industry input to energy and AI research, says Mosharaf Chowdhury, a professor at the University of Michigan and one of the heads of the ML.Energy leaderboard, which tracks energy consumption of AI models.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Estimates like Google’s are generally something that only companies can produce, because they run at a larger scale than researchers are able to and have access to behind-the-scenes information. “I think this will be a keystone piece in the AI energy field,” says Jae-Won Chung, a PhD candidate at the University of Michigan and another leader of the ML.Energy effort. “It’s the most comprehensive analysis so far.”&lt;/p&gt;  &lt;p&gt;Google’s figure, however, is not representative of all queries submitted to Gemini: The company handles a huge variety of requests, and this estimate is calculated from a median energy demand, one that falls in the middle of the range of possible queries.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;So some Gemini prompts use much more energy than this: Dean gives the example of feeding dozens of books into Gemini and asking it to produce a detailed synopsis of their content. “That’s the kind of thing that will probably take more energy than the median prompt,” Dean says. Using a reasoning model could also have a higher associated energy demand because these models take more steps before producing an answer.&lt;/p&gt;  &lt;p&gt;This report was also strictly limited to text prompts, so it doesn’t represent what’s needed to generate an image or a video. (Other analyses, including one in &lt;em&gt;MIT Technology Review&lt;/em&gt;’s Power Hungry series earlier this year, show that these tasks can require much more energy.)&lt;/p&gt;  &lt;p&gt;The report also finds that the total energy used to field a Gemini query has fallen dramatically over time. The median Gemini prompt used 33 times more energy in May 2024 than it did in May 2025, according to Google. The company points to advancements in its models and other software optimizations for the improvements.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Google also estimates the greenhouse gas emissions associated with the median prompt, which they put at 0.03 grams of carbon dioxide. To get to this number, the company multiplied the total energy used to respond to a prompt by the average emissions per unit of electricity.&lt;/p&gt; 

 &lt;p&gt;Rather than using an emissions estimate based on the US grid average, or the average of the grids where Google operates, the company instead uses a market-based estimate, which takes into account electricity purchases that the company makes from clean energy projects. The company has signed agreements to buy over 22 gigawatts of power from sources including solar, wind, geothermal, and advanced nuclear projects since 2010. Because of those purchases, Google’s emissions per unit of electricity on paper are roughly one-third of those on the average grid where it operates.&lt;/p&gt;  &lt;p&gt;AI data centers also consume water for cooling, and Google estimates that each prompt consumes 0.26 milliliters of water, or about five drops.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The goal of this work was to provide users a window into the energy use of their interactions with AI, Dean says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“People are using [AI tools] for all kinds of things, and they shouldn’t have major concerns about the energy usage or the water usage of Gemini models, because in our actual measurements, what we were able to show was that it’s actually equivalent to things you do without even thinking about it on a daily basis,” he says, “like watching a few seconds of TV or consuming five drops of water.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt;&lt;p&gt;The publication greatly expands what’s known about AI’s resource usage. It follows recent increasing pressure on companies to release more information about the energy toll of the technology. “I’m really happy that they put this out,” says Sasha Luccioni, an AI and climate researcher at Hugging Face. “People want to know what the cost is.”&lt;/p&gt;  &lt;p&gt;This estimate and the supporting report contain more public information than has been available before, and it’s helpful to get more information about AI use in real life, at scale, by a major company, Luccioni adds. However, there are still details that the company isn’t sharing in this report. One major question mark is the total number of queries that Gemini gets each day, which would allow estimates of the AI tool’s total energy demand.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And ultimately, it’s still the company deciding what details to share, and when and how. “We’ve been trying to push for a standardized AI energy score,” Luccioni says, a standard for AI similar to the Energy Star rating for appliances. “This is not a replacement or proxy for standardized comparisons.”&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/08/21/1122288/google-gemini-ai-energy/</guid><pubDate>Thu, 21 Aug 2025 12:00:00 +0000</pubDate></item><item><title>The Download: Ukraine’s Starlink repair shop, and predicting solar storms (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/08/21/1122298/the-download-ukraines-starlink-repair-shop-and-predicting-solar-storms/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;On the ground in Ukraine’s largest Starlink repair shop&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Starlink is absolutely critical to Ukraine’s ability to continue in the fight against Russia. It’s how troops in battle zones stay connected with faraway HQs; it’s how many of the drones essential to Ukraine’s survival hit their targets; it’s even how soldiers stay in touch with spouses and children back home.&lt;/p&gt;&lt;p&gt;However, Donald Trump’s fickle foreign policy and reports suggesting Elon Musk might remove Ukraine’s access to the services have cast the technology’s future in the country into doubt.&lt;/p&gt;&lt;p&gt;For now Starlink access largely comes down to the unofficial community of users and engineers, including the expert “Dr. Starlink”—famous for his creative ways of customizing the systems—who have kept Ukraine in the fight, both on and off the front line. Together, they have repaired and customized more than 15,000 terminals since the war began.&lt;/p&gt;&lt;p&gt;Despite the pressure, the chance that they may lose access to Starlink was not worrying volunteers at the time of my visit; in our conversations, it was clear they had more pressing concerns than the whims of a foreign tech mogul. Russia continues to launch frequent aerial bombardments of Ukrainian cities, sometimes sending more than 500 drones in a single night.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The threat of involuntary mobilization to the front line looms on every street corner. How can one plan for a hypothetical future crisis when crisis defines every minute of one’s day? Read the full story.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Charlie Metcalfe&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story is from our forthcoming print issue, which is all about security. If you haven’t already, &lt;/strong&gt;&lt;strong&gt;subscribe now&lt;/strong&gt;&lt;strong&gt; to receive future issues once they land.&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;This article is also part of the Big Story series: MIT Technology Review’s most important, ambitious reporting. The stories in the series take a deep look at the technologies that are coming next and what they will mean for us and the world we live in. &lt;/strong&gt;&lt;strong&gt;Check out the rest of them here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;NASA’s new AI model can predict when a solar storm may strike&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;NASA and IBM have released a new open-source machine learning model to help scientists better understand and predict the physics and weather patterns of the sun. Surya, trained on over a decade’s worth of NASA solar data, should help give scientists an early warning when a dangerous solar flare is likely to hit Earth.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Solar storms occur when the sun erupts energy and particles into space. They can produce solar flares and slower-moving coronal mass ejections that can disrupt radio signals, flip computer bits onboard satellites, and endanger astronauts with bursts of radiation.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;While there’s no way to prevent these sorts of effects, being able to predict when a large solar flare will occur could let people work around them. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Peter Hall&lt;/em&gt;&lt;/p&gt;   

 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Why recycling isn’t enough to address the plastic problem&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;I remember using a princess toothbrush when I was little. The handle was purple, teal, and sparkly. Like most of the other pieces of plastic that have ever been made, it’s probably still out there somewhere, languishing in a landfill. (I just hope it’s not in the ocean.)&lt;/p&gt;  &lt;p&gt;I’ve been thinking about that toothbrush again this week after UN talks about a plastic treaty broke down on Friday. Nations had gotten together to try and write a binding treaty to address plastic waste, but negotiators left without a deal.&lt;/p&gt;  &lt;p&gt;Plastic is widely recognized as a huge source of environmental pollution—again, I’m wondering where that toothbrush is—but the material is also a contributor to climate change. Let’s dig into why talks fell apart and how we might address emissions from plastic.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;em&gt;—Casey Crownhart&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This article is from The Spark, MIT Technology Review’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Google is betting that AI can help you take better photos&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;So long as you don’t try zooming in on someone’s face, that is. (WP $)&lt;br /&gt;+ &lt;em&gt;Gemini is getting a new audio model capable of detecting tone. &lt;/em&gt;(TechCrunch)&lt;br /&gt;+ &lt;em&gt;Google’s AI efforts are certainly outpacing those of its hardware rival Apple. &lt;/em&gt;(Bloomberg $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;Meta’s AI hiring spree is on pause&lt;br /&gt;&lt;/strong&gt;Investors are increasingly concerned by the mad sums being bandied about. (WSJ $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;3 China is preparing to show off its hypersonic missiles&lt;/strong&gt;&lt;br /&gt;The world will be watching its military parade closely next month. (FT $)&lt;br /&gt;+ &lt;em&gt;Meanwhile, India has tested a missile that could hit deep into China. &lt;/em&gt;(The Guardian)&lt;br /&gt;+ &lt;em&gt;Taiwan’s “silicon shield” could be weakening. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 RFK Jr. wants to send you MAHA food boxes&lt;/strong&gt;&lt;br /&gt;But concrete details are light on the ground. (The Atlantic $)&lt;br /&gt;+ &lt;em&gt;How MAHA is shaking up packaged goods’ supply chains. &lt;/em&gt;(Fortune $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 Extreme heat is driving cases of Legionnaire’s disease in NYC&lt;br /&gt;&lt;/strong&gt;Older air conditioning infrastructure is helping to spread dangerous bacteria. (Vox)&lt;br /&gt;+ &lt;em&gt;A fifth person has died in connection with the current outbreak. &lt;/em&gt;(ABC News)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 What it’s like to vibecode for a massive startup&lt;/strong&gt;&lt;br /&gt;Managing AI coding apps is a whole lot like herding interns, supposedly. (Wired $)&lt;br /&gt;+ &lt;em&gt;What is vibe coding, exactly? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;7 Starship’s rocket launch could delay flights in Florida&lt;br /&gt;&lt;/strong&gt;Even after the launch is completed. (TechCrunch)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 This app will help you find the sunniest spots in Paris ☀️&lt;/strong&gt;&lt;br /&gt;The community-driven Jveuxdusoleil is updated in real time. (The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 The world’s only public diamond mine is in Arkansas 💎&lt;/strong&gt;&lt;br /&gt;Visitors have unearthed more than 35,000 precious gems since it opened. (Ars Technica)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 It turns out Uranus had a hidden moon all along&lt;/strong&gt;&lt;br /&gt;And many more may be discovered in the future. (NYT $)&lt;br /&gt;+ &lt;em&gt;It’s the 29th known satellite to orbit the planet. &lt;/em&gt;(Scientific American $)&lt;br /&gt;+ &lt;em&gt;The moon is just the beginning for this waterless concrete. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“It jumbles my freaking nugget that people can look at a squat and not understand how it’s supposed to look. You don’t need AI to do that.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Andrew Hiller, a CrossFit coach and critic of poorly-executed squats, tells the New York Times why doing away with vigilant human judges for the popular fitness race Hyrox would be a mistake.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXeED7NPDneZu1iOYS9HkOFpavpd67fAcJfMnfwmWu2OPx_9TTqnBc7-CKKGu_WfsjMD_Pjj3M1Ic_xrIE1FrIGVOsw_SCidDfbyS6yFTnjwkkt2WtaeCteRQAAwLOkTL9VemepimQ?key=ETunRT739qn3knyxlwJ5xg" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Are friends electric?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Thankfully, the difference between humans and machines in the real world is easy to discern, at least for now. While machines tend to excel at things adults find difficult—playing world-champion-level chess, say, or multiplying really big numbers—they find it hard to accomplish stuff a five-year-old can do with ease, such as catching a ball or walking around a room without bumping into things.&lt;/p&gt;&lt;p&gt;This fundamental tension—what is hard for humans is easy for machines, and what’s hard for machines is easy for humans—is at the heart of three new books delving into our complex and often fraught relationship with robots, AI, and automation. They force us to reimagine the nature of everything from friendship and love to work, health care, and home life. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Bryan Gardiner&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;On the ground in Ukraine’s largest Starlink repair shop&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Starlink is absolutely critical to Ukraine’s ability to continue in the fight against Russia. It’s how troops in battle zones stay connected with faraway HQs; it’s how many of the drones essential to Ukraine’s survival hit their targets; it’s even how soldiers stay in touch with spouses and children back home.&lt;/p&gt;&lt;p&gt;However, Donald Trump’s fickle foreign policy and reports suggesting Elon Musk might remove Ukraine’s access to the services have cast the technology’s future in the country into doubt.&lt;/p&gt;&lt;p&gt;For now Starlink access largely comes down to the unofficial community of users and engineers, including the expert “Dr. Starlink”—famous for his creative ways of customizing the systems—who have kept Ukraine in the fight, both on and off the front line. Together, they have repaired and customized more than 15,000 terminals since the war began.&lt;/p&gt;&lt;p&gt;Despite the pressure, the chance that they may lose access to Starlink was not worrying volunteers at the time of my visit; in our conversations, it was clear they had more pressing concerns than the whims of a foreign tech mogul. Russia continues to launch frequent aerial bombardments of Ukrainian cities, sometimes sending more than 500 drones in a single night.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The threat of involuntary mobilization to the front line looms on every street corner. How can one plan for a hypothetical future crisis when crisis defines every minute of one’s day? Read the full story.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Charlie Metcalfe&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story is from our forthcoming print issue, which is all about security. If you haven’t already, &lt;/strong&gt;&lt;strong&gt;subscribe now&lt;/strong&gt;&lt;strong&gt; to receive future issues once they land.&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;This article is also part of the Big Story series: MIT Technology Review’s most important, ambitious reporting. The stories in the series take a deep look at the technologies that are coming next and what they will mean for us and the world we live in. &lt;/strong&gt;&lt;strong&gt;Check out the rest of them here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;NASA’s new AI model can predict when a solar storm may strike&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;NASA and IBM have released a new open-source machine learning model to help scientists better understand and predict the physics and weather patterns of the sun. Surya, trained on over a decade’s worth of NASA solar data, should help give scientists an early warning when a dangerous solar flare is likely to hit Earth.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Solar storms occur when the sun erupts energy and particles into space. They can produce solar flares and slower-moving coronal mass ejections that can disrupt radio signals, flip computer bits onboard satellites, and endanger astronauts with bursts of radiation.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;While there’s no way to prevent these sorts of effects, being able to predict when a large solar flare will occur could let people work around them. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Peter Hall&lt;/em&gt;&lt;/p&gt;   

 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Why recycling isn’t enough to address the plastic problem&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;I remember using a princess toothbrush when I was little. The handle was purple, teal, and sparkly. Like most of the other pieces of plastic that have ever been made, it’s probably still out there somewhere, languishing in a landfill. (I just hope it’s not in the ocean.)&lt;/p&gt;  &lt;p&gt;I’ve been thinking about that toothbrush again this week after UN talks about a plastic treaty broke down on Friday. Nations had gotten together to try and write a binding treaty to address plastic waste, but negotiators left without a deal.&lt;/p&gt;  &lt;p&gt;Plastic is widely recognized as a huge source of environmental pollution—again, I’m wondering where that toothbrush is—but the material is also a contributor to climate change. Let’s dig into why talks fell apart and how we might address emissions from plastic.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;em&gt;—Casey Crownhart&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This article is from The Spark, MIT Technology Review’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Google is betting that AI can help you take better photos&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;So long as you don’t try zooming in on someone’s face, that is. (WP $)&lt;br /&gt;+ &lt;em&gt;Gemini is getting a new audio model capable of detecting tone. &lt;/em&gt;(TechCrunch)&lt;br /&gt;+ &lt;em&gt;Google’s AI efforts are certainly outpacing those of its hardware rival Apple. &lt;/em&gt;(Bloomberg $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;Meta’s AI hiring spree is on pause&lt;br /&gt;&lt;/strong&gt;Investors are increasingly concerned by the mad sums being bandied about. (WSJ $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;3 China is preparing to show off its hypersonic missiles&lt;/strong&gt;&lt;br /&gt;The world will be watching its military parade closely next month. (FT $)&lt;br /&gt;+ &lt;em&gt;Meanwhile, India has tested a missile that could hit deep into China. &lt;/em&gt;(The Guardian)&lt;br /&gt;+ &lt;em&gt;Taiwan’s “silicon shield” could be weakening. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 RFK Jr. wants to send you MAHA food boxes&lt;/strong&gt;&lt;br /&gt;But concrete details are light on the ground. (The Atlantic $)&lt;br /&gt;+ &lt;em&gt;How MAHA is shaking up packaged goods’ supply chains. &lt;/em&gt;(Fortune $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 Extreme heat is driving cases of Legionnaire’s disease in NYC&lt;br /&gt;&lt;/strong&gt;Older air conditioning infrastructure is helping to spread dangerous bacteria. (Vox)&lt;br /&gt;+ &lt;em&gt;A fifth person has died in connection with the current outbreak. &lt;/em&gt;(ABC News)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 What it’s like to vibecode for a massive startup&lt;/strong&gt;&lt;br /&gt;Managing AI coding apps is a whole lot like herding interns, supposedly. (Wired $)&lt;br /&gt;+ &lt;em&gt;What is vibe coding, exactly? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;7 Starship’s rocket launch could delay flights in Florida&lt;br /&gt;&lt;/strong&gt;Even after the launch is completed. (TechCrunch)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 This app will help you find the sunniest spots in Paris ☀️&lt;/strong&gt;&lt;br /&gt;The community-driven Jveuxdusoleil is updated in real time. (The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 The world’s only public diamond mine is in Arkansas 💎&lt;/strong&gt;&lt;br /&gt;Visitors have unearthed more than 35,000 precious gems since it opened. (Ars Technica)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 It turns out Uranus had a hidden moon all along&lt;/strong&gt;&lt;br /&gt;And many more may be discovered in the future. (NYT $)&lt;br /&gt;+ &lt;em&gt;It’s the 29th known satellite to orbit the planet. &lt;/em&gt;(Scientific American $)&lt;br /&gt;+ &lt;em&gt;The moon is just the beginning for this waterless concrete. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“It jumbles my freaking nugget that people can look at a squat and not understand how it’s supposed to look. You don’t need AI to do that.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Andrew Hiller, a CrossFit coach and critic of poorly-executed squats, tells the New York Times why doing away with vigilant human judges for the popular fitness race Hyrox would be a mistake.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXeED7NPDneZu1iOYS9HkOFpavpd67fAcJfMnfwmWu2OPx_9TTqnBc7-CKKGu_WfsjMD_Pjj3M1Ic_xrIE1FrIGVOsw_SCidDfbyS6yFTnjwkkt2WtaeCteRQAAwLOkTL9VemepimQ?key=ETunRT739qn3knyxlwJ5xg" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Are friends electric?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Thankfully, the difference between humans and machines in the real world is easy to discern, at least for now. While machines tend to excel at things adults find difficult—playing world-champion-level chess, say, or multiplying really big numbers—they find it hard to accomplish stuff a five-year-old can do with ease, such as catching a ball or walking around a room without bumping into things.&lt;/p&gt;&lt;p&gt;This fundamental tension—what is hard for humans is easy for machines, and what’s hard for machines is easy for humans—is at the heart of three new books delving into our complex and often fraught relationship with robots, AI, and automation. They force us to reimagine the nature of everything from friendship and love to work, health care, and home life. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Bryan Gardiner&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/08/21/1122298/the-download-ukraines-starlink-repair-shop-and-predicting-solar-storms/</guid><pubDate>Thu, 21 Aug 2025 12:10:00 +0000</pubDate></item><item><title>[NEW] GeForce NOW Brings RTX 5080 Power to the Ultimate Membership (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/geforce-now-thursday-gamescom-2025/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Get a glimpse into the future of gaming.&lt;/p&gt;
&lt;p&gt;The NVIDIA Blackwell RTX architecture is coming to GeForce NOW in September, marking the service’s biggest upgrade yet. Turn any device into a powerhouse gaming rig with GeForce RTX 5080-class performance, next-generation AI features and a major leap forward in stunning cinematic visuals — all without raising membership prices.&lt;/p&gt;
&lt;p&gt;With the upgrade to the Blackwell RTX architecture, all Premium members will get access to a new feature called Install-to-Play, which expands the GeForce NOW cloud game catalog to nearly 4,500 titles.&lt;/p&gt;
&lt;p&gt;And be on the lookout for an upcoming lineup of this year’s hottest new titles, optimized to take full advantage of the GeForce RTX 5080-gaming rig in the cloud. The list includes &lt;i&gt;ARC Raiders&lt;/i&gt;,&lt;i&gt; Borderlands 4&lt;/i&gt;, &lt;i&gt;Call of Duty: Black Ops 7&lt;/i&gt;,&lt;i&gt; Cinder City&lt;/i&gt;,&lt;i&gt; Dying Light: The Beast, Hell Is Us&lt;/i&gt;, &lt;i&gt;The Outer Worlds 2&lt;/i&gt;,&lt;i&gt; Vampire: The Masquerade – Bloodlines 2 &lt;/i&gt;and more&lt;i&gt;. &lt;/i&gt;Members will be able to play these blockbuster titles in the cloud when they launch, streaming instantly from their device of choice.&lt;/p&gt;
&lt;p&gt;NVIDIA will also be launching GeForce NOW in India this November. It follows Thailand as the latest region to gain access to GeForce NOW through GFNA partner Brothers Picture — enabling even more gamers around the world to experience the future of cloud gaming at the same great membership prices.&lt;/p&gt;
&lt;p&gt;Be among the first to tap into GeForce RTX 5080 power from the cloud by upgrading to an Ultimate membership today. Server space will be limited, so be sure to lock it in today.&lt;/p&gt;
&lt;p&gt;There’s even more fun to come — check out the list of 13 new games joining the GeForce NOW library this week.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Paint It Blackwell&lt;/b&gt;&lt;/h2&gt;
&lt;p class="elementtoproof"&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;With the NVIDIA Blackwell RTX architecture, GeForce NOW is beaming GeForce RTX 5080-class power from the cloud straight to nearly any device.&lt;/p&gt;
&lt;p&gt;GeForce RTX 5080-class GPUs bring a staggering 62 teraflops of compute performance, a 48GB frame buffer, more than 3x the performance of current consoles and 2.8x faster frame rates than previous-generation servers. Advanced ray tracing, richer textures and AI-enhanced rendering with AMD “Zen 5” CPUs and NVIDIA ConnectX-7 networking deliver an experience that’s more responsive than ever.&lt;/p&gt;
&lt;p&gt;It isn’t just raw speed either. NVIDIA Blackwell RTX unlocks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;The highest resolutions and frame rates in the cloud: &lt;/b&gt;NVIDIA DLSS 4 with Multi Frame Generation unlocks up to 5K streaming at 120 frames per second (fps) — performance once reserved for the most elite PCs. NVIDIA Reflex technology levels up the cloud for competitive gaming, delivering streams up to 360 fps at 1080p and network latency under 30 milliseconds.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Vastly improved visual fidelity: &lt;/b&gt;A new Cinematic Quality Streaming mode delivers richer colors, sharper text and crystal-clear scenes with 4:4:4 chroma sampling, AI sharpening and advanced AV1 encoding — even when network conditions change.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;GeForce NOW support on more devices: &lt;/b&gt;Premium members will be able to stream at 90 fps on Steam Decks and 4k 120 fps on the Lenovo Legion Go S handheld. Supported LG monitors can stream at up to 5K 120Hz and supported LG TVs at 4K 120Hz — no extra hardware required. Mac users get the full NVIDIA Blackwell RTX upgrade, and there’s expanded support for peripherals like Logitech racing wheels.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Plus, collaborations with Comcast, Deutsche Telekom AG and others bring enhanced broadband and 5G performance.&lt;/p&gt;
&lt;p&gt;Ultimate memberships remain at $19.99 a month and Performance memberships at $9.99 a month. With the launch of NVIDIA Blackwell RTX on GeForce NOW, upgraded Ultimate memberships will debut with an unchanged $19.99 a month or $199.99 for 12-month plans.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83973"&gt;&lt;img alt="Blackwell product matrix on GeForce NOW" class="size-large wp-image-83973" height="1089" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_Blackwell_Product_Matrix-1680x1089.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83973"&gt;&lt;em&gt;Newly upgraded Ultimate, who dis?&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;h2&gt;&lt;b&gt;Double the Games, Double the Fun&lt;/b&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The biggest expansion yet for the GeForce NOW game library arrives with the launch of Install-to-Play. This new feature harnesses high-performance cloud storage, powered by NVIDIA NVMesh technology, to allow game installations directly in the cloud.&lt;/p&gt;
&lt;p&gt;Members will be able to bring even more of their PC collections to the cloud to play instantly, mirroring the experience of a local PC. Install-to-Play instantly doubles the supported games on GeForce NOW with more than 2,200 Steam titles already opted in for cloud streaming, rocketing the total GeForce NOW library size to over 4,500 accessible games, with more to come.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83970"&gt;&lt;img alt="Install-to-Play coming to GeForce NOW" class="size-large wp-image-83970" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_Install_to_Play-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83970"&gt;&lt;em&gt;The game multiplier.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Ultimate and Performance members will have 100GB of single-session storage included, with flexible add-ons for persistent storage — 200GB for $2.99 per month, 500GB for $4.99 per month and 1TB for $7.99 per month. Once a game is installed on persistent storage, it remains instantly ready for members to play.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;The Ultimate Party&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The upgrade to NVIDIA Blackwell RTX in the cloud arrives just in time for some of the year’s top-tier game launches. These highly anticipated titles will be among the first to take full advantage of the upgraded platform’s powerful performance — letting members experience cutting-edge gameplay, ultrahigh resolutions and instant day-one access in the cloud.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83967"&gt;&lt;img alt="Borderlands 4 on GeForce NOW" class="size-large wp-image-83967" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_Borderlands_4-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83967"&gt;&lt;em&gt;The cloud is the best way to play.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Gear up for all out mayhem in &lt;i&gt;Borderlands 4&lt;/i&gt;. Unleash chaos across the galaxy with outrageous weapons, irreverent humor and the signature co-op action that makes this iconic looter-shooter franchise a fan favorite.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83964"&gt;&lt;img alt="Dying Light The Beast on GeForce NOW" class="size-large wp-image-83964" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_Dying_Light_The_Beast-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83964"&gt;&lt;em&gt;Own the day, fear the night.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Get ready for a unique blend of open-world and action-survival horror when &lt;i&gt;Dying Light: The Beast &lt;/i&gt;launches in the cloud on Friday, Sept. 19. Play as Kyle Crane, a hero with the DNA of both man and beast. After escaping brutal experiments, players will feel the thirst for revenge — but soon learn there’s more at stake in the unforgiving wilds of Castor Woods.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83961"&gt;&lt;img alt="Outer Worlds 2 on GeForce NOW" class="size-large wp-image-83961" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_The_Outer_Worlds_2-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83961"&gt;&lt;em&gt;The universe needs a hero, but you’ll have to do.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Get ready to explore strange new colonies in &lt;i&gt;The Outer Worlds 2&lt;/i&gt;. This highly anticipated sequel brings fresh characters, wild alien planets and Obsidian’s trademark wit — promising even bigger adventures and choices that shape the game’s story.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83955"&gt;&lt;img alt="Arc Raiders on GeForce NOW" class="size-large wp-image-83955" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/arc-raiders-tw-li-2048x1024-1-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83955"&gt;&lt;em&gt;Prepare to claim what was lost.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Action fans can look forward to heart-pounding, squad-based battles in &lt;i&gt;Arc Raiders&lt;/i&gt;. This dynamic co-op shooter drops players into a war for survival against overwhelming mechanized threats, blending teamwork and tactical action in a richly detailed multiplayer world.&lt;/p&gt;
&lt;p&gt;For a dark, atmospheric role-playing game, look no further than &lt;i&gt;Vampire: The Masquerade – Bloodlines 2&lt;/i&gt;, which will bring players back to Seattle’s supernatural underworld. Navigate dangerous alliances, political intrigue and vampire factions to carve a unique path through the city’s shadowy streets.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83952"&gt;&lt;img alt="Hell is Us on GeForce NOW" class="size-large wp-image-83952" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_Hell_Is_Us-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83952"&gt;&lt;em&gt;The cloud reveals all about the calamity.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;For those in search of mystery and action, look no further than &lt;i&gt;Hell Is Us&lt;/i&gt;. Set in a land torn by conflict and haunted by otherworldly forces, this unique adventure blends fast-paced melee combat and a striking, atmospheric world, challenging gamers to discover what’s real amid human and supernatural threats.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83949"&gt;&lt;img alt="COD Black Ops 7 on GeForce NOW" class="size-large wp-image-83949" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_COD_Black_Ops_7-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83949"&gt;&lt;em&gt;The mind games never stop.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;And the action of &lt;i&gt;Call of Duty: Black Ops 7&lt;/i&gt; will bring the franchise’s intensity to GeForce NOW. Dive into a high-stakes co-op campaign packed with action, a signature multiplayer experience and the next twisted chapter of Round-Based Zombies.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83946"&gt;&lt;img alt="Cinder City on GeForce NOW" class="size-large wp-image-83946" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_CINDER_CITY-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83946"&gt;&lt;em&gt;Every flame tells a story.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;In &lt;i&gt;CINDER CITY&lt;/i&gt;, a tactical shooter developed in-house by Bigfire Games under NCSOFT, suit up as a futuristic knight and battle through post-apocalyptic Seoul. Players must face brutal choices as they search for their missing daughter — solo or with a squad.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;A Special Squad-Up&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83943"&gt;&lt;img alt="Discord and GeForce NOW new integration" class="size-full wp-image-83943" height="627" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_NVIDIA_Discord.png" width="1200" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83943"&gt;&lt;em&gt;Better together.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;NVIDIA, Discord and Epic are teaming up to change how games are discovered and played together, making it easier than ever to stay connected to friends through gaming.&lt;/p&gt;
&lt;p&gt;Powered by GeForce NOW streaming, this new integrated experience — demoed behind closed doors at Gamescom — will let players discover and try new games with friends directly on Discord. They can do so with no downloads or installs, and even without owning the game or a GeForce NOW membership. It’s fueled by a limited-time trial of the GeForce NOW Performance experience for streaming at up 1440p 60 fps — all without needing to leave Discord.&lt;/p&gt;
&lt;p&gt;The first game to take advantage of the integrated experience is &lt;i&gt;Fortnite. &lt;/i&gt;Connecting an Epic account is all it takes to join the action. For Discord’s hundreds of millions of users, it’s a faster, simpler way to discover games and play together where gaming conversations are already happening.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Legendary New Games&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83940"&gt;&lt;img alt="Total War series on GeForce NOW" class="size-large wp-image-83940" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/gfn-thursday-8-21-social-2048x1024-no-copy-logo-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83940"&gt;&lt;em&gt;History isn’t written, it’s forged in the cloud.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Command grand armies and shape history in Creative Assembly’s acclaimed &lt;i&gt;Total War&lt;/i&gt; series, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;Total War: MEDIEVAL II – Definitive Edition&lt;/i&gt;&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Total War: ATTILA&lt;/i&gt;&lt;/li&gt;
&lt;li&gt;&lt;i&gt;A Total War Saga: Troy&lt;/i&gt;&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Total War: NAPOLEON – Definitive Edition&lt;/i&gt;&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Total War: EMPIRE – Definitive Edition&lt;/i&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Rally knights in &lt;i&gt;MEDIEVAL II&lt;/i&gt;, defy empires in &lt;i&gt;ATTILA&lt;/i&gt;, lead legendary heroes in &lt;i&gt;Troy&lt;/i&gt;, outmaneuver rivals in &lt;i&gt;NAPOLEON&lt;/i&gt; and forge global dominance in &lt;i&gt;EMPIRE&lt;/i&gt;. Epic strategy, monumental battles and world-shaking decisions await as the fate of civilizations is in players’ hands. Gamers can rewrite history — or be swept aside by it.&lt;/p&gt;
&lt;p&gt;Catch the full list of games coming to the cloud this week on GeForce NOW:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;Stick It to the Stickman&lt;/i&gt; (New release on Steam, Aug. 18)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Blacksmith Master &lt;/i&gt;(New release on Xbox, available on PC Game Pass, Aug. 19)&lt;i&gt;&amp;nbsp;&lt;/i&gt;&lt;/li&gt;
&lt;li&gt;&lt;i&gt;VOID/BREAKER &lt;/i&gt;(New release on Steam and Xbox available on PC Game Pass, Aug. 19)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;The Rogue Prince of Persia &lt;/i&gt;(New release on Ubisoft, Aug. 20)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Funko Fusion&lt;/i&gt; (Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Total War: MEDIEVAL II – Definitive Edition&lt;/i&gt; (Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Total War: ATTILA &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;A Total War Saga: Troy &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Total War: NAPOLEON – Definitive Edition &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Total War: EMPIRE – Definitive Edition &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Total War: PHARAOH DYNASTIES &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Total War: ROME REMASTERED &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Total War: SHOGUN 2 &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Which Gamescom announcement has you most excited this week? Let us know on X or in the comments below.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;See &lt;/i&gt;&lt;i&gt;notice&lt;/i&gt;&lt;i&gt; regarding software product information.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Get a glimpse into the future of gaming.&lt;/p&gt;
&lt;p&gt;The NVIDIA Blackwell RTX architecture is coming to GeForce NOW in September, marking the service’s biggest upgrade yet. Turn any device into a powerhouse gaming rig with GeForce RTX 5080-class performance, next-generation AI features and a major leap forward in stunning cinematic visuals — all without raising membership prices.&lt;/p&gt;
&lt;p&gt;With the upgrade to the Blackwell RTX architecture, all Premium members will get access to a new feature called Install-to-Play, which expands the GeForce NOW cloud game catalog to nearly 4,500 titles.&lt;/p&gt;
&lt;p&gt;And be on the lookout for an upcoming lineup of this year’s hottest new titles, optimized to take full advantage of the GeForce RTX 5080-gaming rig in the cloud. The list includes &lt;i&gt;ARC Raiders&lt;/i&gt;,&lt;i&gt; Borderlands 4&lt;/i&gt;, &lt;i&gt;Call of Duty: Black Ops 7&lt;/i&gt;,&lt;i&gt; Cinder City&lt;/i&gt;,&lt;i&gt; Dying Light: The Beast, Hell Is Us&lt;/i&gt;, &lt;i&gt;The Outer Worlds 2&lt;/i&gt;,&lt;i&gt; Vampire: The Masquerade – Bloodlines 2 &lt;/i&gt;and more&lt;i&gt;. &lt;/i&gt;Members will be able to play these blockbuster titles in the cloud when they launch, streaming instantly from their device of choice.&lt;/p&gt;
&lt;p&gt;NVIDIA will also be launching GeForce NOW in India this November. It follows Thailand as the latest region to gain access to GeForce NOW through GFNA partner Brothers Picture — enabling even more gamers around the world to experience the future of cloud gaming at the same great membership prices.&lt;/p&gt;
&lt;p&gt;Be among the first to tap into GeForce RTX 5080 power from the cloud by upgrading to an Ultimate membership today. Server space will be limited, so be sure to lock it in today.&lt;/p&gt;
&lt;p&gt;There’s even more fun to come — check out the list of 13 new games joining the GeForce NOW library this week.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Paint It Blackwell&lt;/b&gt;&lt;/h2&gt;
&lt;p class="elementtoproof"&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;With the NVIDIA Blackwell RTX architecture, GeForce NOW is beaming GeForce RTX 5080-class power from the cloud straight to nearly any device.&lt;/p&gt;
&lt;p&gt;GeForce RTX 5080-class GPUs bring a staggering 62 teraflops of compute performance, a 48GB frame buffer, more than 3x the performance of current consoles and 2.8x faster frame rates than previous-generation servers. Advanced ray tracing, richer textures and AI-enhanced rendering with AMD “Zen 5” CPUs and NVIDIA ConnectX-7 networking deliver an experience that’s more responsive than ever.&lt;/p&gt;
&lt;p&gt;It isn’t just raw speed either. NVIDIA Blackwell RTX unlocks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;The highest resolutions and frame rates in the cloud: &lt;/b&gt;NVIDIA DLSS 4 with Multi Frame Generation unlocks up to 5K streaming at 120 frames per second (fps) — performance once reserved for the most elite PCs. NVIDIA Reflex technology levels up the cloud for competitive gaming, delivering streams up to 360 fps at 1080p and network latency under 30 milliseconds.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Vastly improved visual fidelity: &lt;/b&gt;A new Cinematic Quality Streaming mode delivers richer colors, sharper text and crystal-clear scenes with 4:4:4 chroma sampling, AI sharpening and advanced AV1 encoding — even when network conditions change.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;GeForce NOW support on more devices: &lt;/b&gt;Premium members will be able to stream at 90 fps on Steam Decks and 4k 120 fps on the Lenovo Legion Go S handheld. Supported LG monitors can stream at up to 5K 120Hz and supported LG TVs at 4K 120Hz — no extra hardware required. Mac users get the full NVIDIA Blackwell RTX upgrade, and there’s expanded support for peripherals like Logitech racing wheels.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Plus, collaborations with Comcast, Deutsche Telekom AG and others bring enhanced broadband and 5G performance.&lt;/p&gt;
&lt;p&gt;Ultimate memberships remain at $19.99 a month and Performance memberships at $9.99 a month. With the launch of NVIDIA Blackwell RTX on GeForce NOW, upgraded Ultimate memberships will debut with an unchanged $19.99 a month or $199.99 for 12-month plans.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83973"&gt;&lt;img alt="Blackwell product matrix on GeForce NOW" class="size-large wp-image-83973" height="1089" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_Blackwell_Product_Matrix-1680x1089.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83973"&gt;&lt;em&gt;Newly upgraded Ultimate, who dis?&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;h2&gt;&lt;b&gt;Double the Games, Double the Fun&lt;/b&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The biggest expansion yet for the GeForce NOW game library arrives with the launch of Install-to-Play. This new feature harnesses high-performance cloud storage, powered by NVIDIA NVMesh technology, to allow game installations directly in the cloud.&lt;/p&gt;
&lt;p&gt;Members will be able to bring even more of their PC collections to the cloud to play instantly, mirroring the experience of a local PC. Install-to-Play instantly doubles the supported games on GeForce NOW with more than 2,200 Steam titles already opted in for cloud streaming, rocketing the total GeForce NOW library size to over 4,500 accessible games, with more to come.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83970"&gt;&lt;img alt="Install-to-Play coming to GeForce NOW" class="size-large wp-image-83970" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_Install_to_Play-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83970"&gt;&lt;em&gt;The game multiplier.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Ultimate and Performance members will have 100GB of single-session storage included, with flexible add-ons for persistent storage — 200GB for $2.99 per month, 500GB for $4.99 per month and 1TB for $7.99 per month. Once a game is installed on persistent storage, it remains instantly ready for members to play.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;The Ultimate Party&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The upgrade to NVIDIA Blackwell RTX in the cloud arrives just in time for some of the year’s top-tier game launches. These highly anticipated titles will be among the first to take full advantage of the upgraded platform’s powerful performance — letting members experience cutting-edge gameplay, ultrahigh resolutions and instant day-one access in the cloud.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83967"&gt;&lt;img alt="Borderlands 4 on GeForce NOW" class="size-large wp-image-83967" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_Borderlands_4-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83967"&gt;&lt;em&gt;The cloud is the best way to play.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Gear up for all out mayhem in &lt;i&gt;Borderlands 4&lt;/i&gt;. Unleash chaos across the galaxy with outrageous weapons, irreverent humor and the signature co-op action that makes this iconic looter-shooter franchise a fan favorite.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83964"&gt;&lt;img alt="Dying Light The Beast on GeForce NOW" class="size-large wp-image-83964" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_Dying_Light_The_Beast-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83964"&gt;&lt;em&gt;Own the day, fear the night.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Get ready for a unique blend of open-world and action-survival horror when &lt;i&gt;Dying Light: The Beast &lt;/i&gt;launches in the cloud on Friday, Sept. 19. Play as Kyle Crane, a hero with the DNA of both man and beast. After escaping brutal experiments, players will feel the thirst for revenge — but soon learn there’s more at stake in the unforgiving wilds of Castor Woods.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83961"&gt;&lt;img alt="Outer Worlds 2 on GeForce NOW" class="size-large wp-image-83961" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_The_Outer_Worlds_2-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83961"&gt;&lt;em&gt;The universe needs a hero, but you’ll have to do.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Get ready to explore strange new colonies in &lt;i&gt;The Outer Worlds 2&lt;/i&gt;. This highly anticipated sequel brings fresh characters, wild alien planets and Obsidian’s trademark wit — promising even bigger adventures and choices that shape the game’s story.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83955"&gt;&lt;img alt="Arc Raiders on GeForce NOW" class="size-large wp-image-83955" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/arc-raiders-tw-li-2048x1024-1-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83955"&gt;&lt;em&gt;Prepare to claim what was lost.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Action fans can look forward to heart-pounding, squad-based battles in &lt;i&gt;Arc Raiders&lt;/i&gt;. This dynamic co-op shooter drops players into a war for survival against overwhelming mechanized threats, blending teamwork and tactical action in a richly detailed multiplayer world.&lt;/p&gt;
&lt;p&gt;For a dark, atmospheric role-playing game, look no further than &lt;i&gt;Vampire: The Masquerade – Bloodlines 2&lt;/i&gt;, which will bring players back to Seattle’s supernatural underworld. Navigate dangerous alliances, political intrigue and vampire factions to carve a unique path through the city’s shadowy streets.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83952"&gt;&lt;img alt="Hell is Us on GeForce NOW" class="size-large wp-image-83952" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_Hell_Is_Us-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83952"&gt;&lt;em&gt;The cloud reveals all about the calamity.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;For those in search of mystery and action, look no further than &lt;i&gt;Hell Is Us&lt;/i&gt;. Set in a land torn by conflict and haunted by otherworldly forces, this unique adventure blends fast-paced melee combat and a striking, atmospheric world, challenging gamers to discover what’s real amid human and supernatural threats.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83949"&gt;&lt;img alt="COD Black Ops 7 on GeForce NOW" class="size-large wp-image-83949" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_COD_Black_Ops_7-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83949"&gt;&lt;em&gt;The mind games never stop.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;And the action of &lt;i&gt;Call of Duty: Black Ops 7&lt;/i&gt; will bring the franchise’s intensity to GeForce NOW. Dive into a high-stakes co-op campaign packed with action, a signature multiplayer experience and the next twisted chapter of Round-Based Zombies.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83946"&gt;&lt;img alt="Cinder City on GeForce NOW" class="size-large wp-image-83946" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_CINDER_CITY-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83946"&gt;&lt;em&gt;Every flame tells a story.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;In &lt;i&gt;CINDER CITY&lt;/i&gt;, a tactical shooter developed in-house by Bigfire Games under NCSOFT, suit up as a futuristic knight and battle through post-apocalyptic Seoul. Players must face brutal choices as they search for their missing daughter — solo or with a squad.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;A Special Squad-Up&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83943"&gt;&lt;img alt="Discord and GeForce NOW new integration" class="size-full wp-image-83943" height="627" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_NVIDIA_Discord.png" width="1200" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83943"&gt;&lt;em&gt;Better together.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;NVIDIA, Discord and Epic are teaming up to change how games are discovered and played together, making it easier than ever to stay connected to friends through gaming.&lt;/p&gt;
&lt;p&gt;Powered by GeForce NOW streaming, this new integrated experience — demoed behind closed doors at Gamescom — will let players discover and try new games with friends directly on Discord. They can do so with no downloads or installs, and even without owning the game or a GeForce NOW membership. It’s fueled by a limited-time trial of the GeForce NOW Performance experience for streaming at up 1440p 60 fps — all without needing to leave Discord.&lt;/p&gt;
&lt;p&gt;The first game to take advantage of the integrated experience is &lt;i&gt;Fortnite. &lt;/i&gt;Connecting an Epic account is all it takes to join the action. For Discord’s hundreds of millions of users, it’s a faster, simpler way to discover games and play together where gaming conversations are already happening.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Legendary New Games&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83940"&gt;&lt;img alt="Total War series on GeForce NOW" class="size-large wp-image-83940" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/gfn-thursday-8-21-social-2048x1024-no-copy-logo-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83940"&gt;&lt;em&gt;History isn’t written, it’s forged in the cloud.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Command grand armies and shape history in Creative Assembly’s acclaimed &lt;i&gt;Total War&lt;/i&gt; series, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;Total War: MEDIEVAL II – Definitive Edition&lt;/i&gt;&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Total War: ATTILA&lt;/i&gt;&lt;/li&gt;
&lt;li&gt;&lt;i&gt;A Total War Saga: Troy&lt;/i&gt;&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Total War: NAPOLEON – Definitive Edition&lt;/i&gt;&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Total War: EMPIRE – Definitive Edition&lt;/i&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Rally knights in &lt;i&gt;MEDIEVAL II&lt;/i&gt;, defy empires in &lt;i&gt;ATTILA&lt;/i&gt;, lead legendary heroes in &lt;i&gt;Troy&lt;/i&gt;, outmaneuver rivals in &lt;i&gt;NAPOLEON&lt;/i&gt; and forge global dominance in &lt;i&gt;EMPIRE&lt;/i&gt;. Epic strategy, monumental battles and world-shaking decisions await as the fate of civilizations is in players’ hands. Gamers can rewrite history — or be swept aside by it.&lt;/p&gt;
&lt;p&gt;Catch the full list of games coming to the cloud this week on GeForce NOW:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;Stick It to the Stickman&lt;/i&gt; (New release on Steam, Aug. 18)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Blacksmith Master &lt;/i&gt;(New release on Xbox, available on PC Game Pass, Aug. 19)&lt;i&gt;&amp;nbsp;&lt;/i&gt;&lt;/li&gt;
&lt;li&gt;&lt;i&gt;VOID/BREAKER &lt;/i&gt;(New release on Steam and Xbox available on PC Game Pass, Aug. 19)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;The Rogue Prince of Persia &lt;/i&gt;(New release on Ubisoft, Aug. 20)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Funko Fusion&lt;/i&gt; (Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Total War: MEDIEVAL II – Definitive Edition&lt;/i&gt; (Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Total War: ATTILA &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;A Total War Saga: Troy &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Total War: NAPOLEON – Definitive Edition &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Total War: EMPIRE – Definitive Edition &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Total War: PHARAOH DYNASTIES &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Total War: ROME REMASTERED &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Total War: SHOGUN 2 &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Which Gamescom announcement has you most excited this week? Let us know on X or in the comments below.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;See &lt;/i&gt;&lt;i&gt;notice&lt;/i&gt;&lt;i&gt; regarding software product information.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/geforce-now-thursday-gamescom-2025/</guid><pubDate>Thu, 21 Aug 2025 13:00:58 +0000</pubDate></item><item><title>[NEW] Report: Meta is hitting pause on AI hiring after its poaching spree (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/21/report-meta-is-hitting-pause-on-ai-hiring-after-its-poaching-spree/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2194278734.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta has frozen hiring in its AI organization after restructuring the unit earlier this week, reports The Wall Street Journal. The hiring freeze follows weeks of poaching more than 50 AI researchers and engineers from competitors.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The freeze went into effect last week, and it’s not clear how long it will last. Meta is still likely working through its reorg, which split its AI unit, Meta Superintelligence Labs, into four new groups: TBD Labs, run by former Scale AI founder Alexandr Wang, and three groups focused on research, product integration, and infrastructure, respectively.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Meta confirmed the hiring freeze with The Journal, saying it was “basic organizational planning…after bringing people on board and undertaking yearly budgeting and planning exercises.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta CEO Mark Zuckerberg’s push to get ahead in the AI race has sparked serious talent wars. He’s personally called top researchers and engineers to offer them pay packages worth nine figures, and acquired either other startups or their leadership. Analysts have warned that the rise of stock-based compensation costs could threaten shareholder returns.&amp;nbsp;&lt;/p&gt;

&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2194278734.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta has frozen hiring in its AI organization after restructuring the unit earlier this week, reports The Wall Street Journal. The hiring freeze follows weeks of poaching more than 50 AI researchers and engineers from competitors.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The freeze went into effect last week, and it’s not clear how long it will last. Meta is still likely working through its reorg, which split its AI unit, Meta Superintelligence Labs, into four new groups: TBD Labs, run by former Scale AI founder Alexandr Wang, and three groups focused on research, product integration, and infrastructure, respectively.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Meta confirmed the hiring freeze with The Journal, saying it was “basic organizational planning…after bringing people on board and undertaking yearly budgeting and planning exercises.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta CEO Mark Zuckerberg’s push to get ahead in the AI race has sparked serious talent wars. He’s personally called top researchers and engineers to offer them pay packages worth nine figures, and acquired either other startups or their leadership. Analysts have warned that the rise of stock-based compensation costs could threaten shareholder returns.&amp;nbsp;&lt;/p&gt;

&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/21/report-meta-is-hitting-pause-on-ai-hiring-after-its-poaching-spree/</guid><pubDate>Thu, 21 Aug 2025 13:25:15 +0000</pubDate></item><item><title>[NEW] Google’s AI Mode expands globally, adds new agentic features (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/21/googles-ai-mode-expands-globally-adds-new-agentic-features/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is launching a global expansion of AI Mode, its feature that allows users to ask complex questions and follow-ups to dig deeper on a topic directly within Search, the company announced on Thursday. The tech giant is also bringing new agentic and personalized capabilities to the feature.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As part of the expansion, Google is bringing AI Mode to 180 new countries in English. Up until now, it’s only been available to users in the U.S., U.K., and India. Google plans to bring the feature to more languages and regions soon. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In terms of the new agentic features, users can now use AI Mode to find restaurant reservations, and in the future, they’ll be able to find local service appointments and event tickets. Users can request dinner reservations based on multiple preferences, such as party size, date, time, location, and preferred cuisine. AI Mode will then search across different reservation platforms to find real-time availability for restaurants that match the inquiry. It then surfaces a curated list of options to choose from. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This new capability is rolling out for Google AI Ultra subscribers in the U.S. through the “Agentic capabilities in AI Mode” experiment in Labs, Google’s experimental arm. (Ultra is Google’s highest-end plan, at $249.99 per month.)&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3038745" height="680" src="https://techcrunch.com/wp-content/uploads/2025/08/AI-Mode-agentic-dining-reservations-birthday-example-still-1-of-2.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Google says that U.S. users in the AI Mode experiment will also now see search results tailored to their individual preferences and interests. The tech giant is starting with dining-related topics for this capability.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For example, if someone searches, “I only have an hour, need a quick lunch spot, any suggestions?” AI Mode will use their past conversations, along with places they’ve searched for or clicked on in Search and Maps, to offer more relevant suggestions. So, if AI Mode infers that you like Italian food and places with outdoor seating, you’ll get results suggesting options with these preferences.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google notes that users can adjust their personalization settings in their Google Account.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, AI Mode now lets users share and collaborate with others. A new “Share” button lets users send an AI Mode response to others, allowing them to jump into the conversation. Google says this could be helpful in cases where you need to collaborate with someone else, such as planning a trip or a birthday party.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is launching a global expansion of AI Mode, its feature that allows users to ask complex questions and follow-ups to dig deeper on a topic directly within Search, the company announced on Thursday. The tech giant is also bringing new agentic and personalized capabilities to the feature.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As part of the expansion, Google is bringing AI Mode to 180 new countries in English. Up until now, it’s only been available to users in the U.S., U.K., and India. Google plans to bring the feature to more languages and regions soon. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In terms of the new agentic features, users can now use AI Mode to find restaurant reservations, and in the future, they’ll be able to find local service appointments and event tickets. Users can request dinner reservations based on multiple preferences, such as party size, date, time, location, and preferred cuisine. AI Mode will then search across different reservation platforms to find real-time availability for restaurants that match the inquiry. It then surfaces a curated list of options to choose from. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This new capability is rolling out for Google AI Ultra subscribers in the U.S. through the “Agentic capabilities in AI Mode” experiment in Labs, Google’s experimental arm. (Ultra is Google’s highest-end plan, at $249.99 per month.)&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3038745" height="680" src="https://techcrunch.com/wp-content/uploads/2025/08/AI-Mode-agentic-dining-reservations-birthday-example-still-1-of-2.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Google says that U.S. users in the AI Mode experiment will also now see search results tailored to their individual preferences and interests. The tech giant is starting with dining-related topics for this capability.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For example, if someone searches, “I only have an hour, need a quick lunch spot, any suggestions?” AI Mode will use their past conversations, along with places they’ve searched for or clicked on in Search and Maps, to offer more relevant suggestions. So, if AI Mode infers that you like Italian food and places with outdoor seating, you’ll get results suggesting options with these preferences.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google notes that users can adjust their personalization settings in their Google Account.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, AI Mode now lets users share and collaborate with others. A new “Share” button lets users send an AI Mode response to others, allowing them to jump into the conversation. Google says this could be helpful in cases where you need to collaborate with someone else, such as planning a trip or a birthday party.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/21/googles-ai-mode-expands-globally-adds-new-agentic-features/</guid><pubDate>Thu, 21 Aug 2025 13:49:37 +0000</pubDate></item><item><title>[NEW] Think SMART: How to Optimize AI Factory Inference Performance (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/think-smart-optimize-ai-factory-inference-performance/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;From AI assistants doing deep research to autonomous vehicles making split-second navigation decisions, AI adoption is exploding across industries.&lt;/p&gt;
&lt;p&gt;Behind every one of those interactions is inference — the stage after training where an AI model processes inputs and produces outputs in real time.&lt;/p&gt;
&lt;p&gt;Today’s most advanced AI reasoning models — capable of multistep logic and complex decision-making — generate far more tokens per interaction than older models, driving a surge in token usage and the need for infrastructure that can manufacture intelligence at scale.&lt;/p&gt;
&lt;p&gt;AI factories are one way of meeting these growing needs.&lt;/p&gt;
&lt;p&gt;But running inference at such a large scale isn’t just about throwing more compute at the problem.&lt;/p&gt;
&lt;p&gt;To deploy AI with maximum efficiency, inference must be evaluated based on the &lt;b&gt;Think SMART framework:&lt;/b&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;S&lt;/b&gt;cale and complexity&lt;/li&gt;
&lt;li&gt;&lt;b&gt;M&lt;/b&gt;ultidimensional performance&lt;/li&gt;
&lt;li&gt;&lt;b&gt;A&lt;/b&gt;rchitecture and software&lt;/li&gt;
&lt;li&gt;&lt;b&gt;R&lt;/b&gt;eturn on investment driven by performance&lt;/li&gt;
&lt;li&gt;&lt;b&gt;T&lt;/b&gt;echnology ecosystem and install base&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;strong&gt;Scale and Complexity&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;As models evolve from compact applications to massive, multi-expert systems, inference must keep pace with increasingly diverse workloads — from answering quick, single-shot queries to multistep reasoning involving millions of tokens.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;The expanding size and intricacy of AI models introduce major implications for inference, such as resource intensity, latency and throughput, energy and costs, as well as diversity of use cases.&lt;/p&gt;
&lt;p&gt;To meet this complexity, AI service providers and enterprises are scaling up their infrastructure, with new AI factories coming online from partners like CoreWeave, Dell Technologies, Google Cloud and Nebius.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Multidimensional Performance&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Scaling complex AI deployments means AI factories need the flexibility to serve tokens across a wide spectrum of use cases while balancing accuracy, latency and costs.&lt;/p&gt;
&lt;p&gt;Some workloads, such as real-time speech-to-text translation, demand ultralow latency and a large number of tokens per user, straining computational resources for maximum responsiveness. Others are latency-insensitive and geared for sheer throughput, such as generating answers to dozens of complex questions simultaneously.&lt;/p&gt;
&lt;p&gt;But most popular real-time scenarios operate somewhere in the middle: requiring quick responses to keep users happy and high throughput to simultaneously serve up to millions of users — all while minimizing cost per token.&lt;/p&gt;
&lt;p&gt;For example, the NVIDIA inference platform is built to balance both latency and throughput, powering inference benchmarks on models like gpt-oss, DeepSeek-R1 and Llama 3.1.&lt;/p&gt;
&lt;h3&gt;&lt;b&gt;What to Assess to Achieve Optimal Multidimensional Performance&lt;/b&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Throughput:&lt;/b&gt; How many tokens can the system process per second? The more, the better for scaling workloads and revenue.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Latency:&lt;/b&gt; How quickly does the system respond to each individual prompt? Lower latency means a better experience for users — crucial for interactive applications.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Scalability:&lt;/b&gt; Can the system setup quickly adapt as demand increases, going from one to thousands of GPUs without complex restructuring or wasted resources?&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Cost Efficiency:&lt;/b&gt; Is performance per dollar high, and are those gains sustainable as system demands grow?&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;strong&gt;Architecture and Software&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;AI inference performance needs to be engineered from the ground up. It comes from hardware and software working in sync — GPUs, networking and code tuned to avoid bottlenecks and make the most of every cycle.&lt;/p&gt;
&lt;p&gt;Powerful architecture without smart orchestration wastes potential; great software without fast, low-latency hardware means sluggish performance. The key is architecting a system so that it can quickly, efficiently and flexibly turn prompts into useful answers.&lt;/p&gt;
&lt;p&gt;Enterprises can use NVIDIA infrastructure to build a system that delivers optimal performance.&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;Architecture Optimized for Inference at AI Factory Scale&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;The NVIDIA Blackwell platform unlocks a 50x boost in AI factory productivity for inference — meaning enterprises can optimize throughput and interactive responsiveness, even when running the most complex models.&lt;/p&gt;
&lt;p&gt;The NVIDIA GB200 NVL72 rack-scale system connects 36 NVIDIA Grace CPUs and 72 Blackwell GPUs with NVIDIA NVLink interconnect, delivering 40x higher revenue potential, 30x higher throughput, 25x more energy efficiency and 300x more water efficiency for demanding AI reasoning workloads.&lt;/p&gt;
&lt;p&gt;Further, NVFP4 is a low-precision format that delivers peak performance on NVIDIA Blackwell and slashes energy, memory and bandwidth demands without skipping a beat on accuracy, so users can deliver more queries per watt and lower costs per token.&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;Full-Stack Inference Platform Accelerated on Blackwell&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Enabling inference at AI factory scale requires more than accelerated architecture. It requires a full-stack platform with multiple layers of solutions and tools that can work in concert together.&lt;/p&gt;
&lt;p&gt;Modern AI deployments require dynamic autoscaling from one to thousands of GPUs. The NVIDIA Dynamo platform steers distributed inference to dynamically assign GPUs and optimize data flows, delivering up to 4x more performance without cost increases. New cloud integrations further improve scalability and ease of deployment.&lt;/p&gt;
&lt;p&gt;For inference workloads focused on getting optimal performance per GPU, such as speeding up large mixture of expert models, frameworks like NVIDIA TensorRT-LLM are helping developers achieve breakthrough performance.&lt;/p&gt;
&lt;p&gt;With its new PyTorch-centric workflow, TensorRT-LLM streamlines AI deployment by removing the need for manual engine management. These solutions aren’t just powerful on their own — they’re built to work in tandem. For example, using Dynamo and TensorRT-LLM, mission-critical inference providers like Baseten can immediately deliver state-of-the-art model performance even on new frontier models like gpt-oss.&lt;/p&gt;
&lt;p&gt;On the model side, families like NVIDIA Nemotron are built with open training data for transparency, while still generating tokens quickly enough to handle advanced reasoning tasks with high accuracy — without increasing compute costs. And with NVIDIA NIM, those models can be packaged into ready-to-run microservices, making it easier for teams to roll them out and scale across environments while achieving the lowest total cost of ownership.&lt;/p&gt;
&lt;p&gt;Together, these layers — dynamic orchestration, optimized execution, well-designed models and simplified deployment — form the backbone of inference enablement for cloud providers and enterprises alike.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Return on Investment Driven by Performance&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;As AI adoption grows, organizations are increasingly looking to maximize the return on investment from each user query.&lt;/p&gt;
&lt;p&gt;Performance is the biggest driver of return on investment. A 4x increase in performance from the NVIDIA Hopper architecture to Blackwell yields up to 10x profit growth within a similar power budget.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;In power-limited data centers and AI factories, generating more tokens per watt translates directly to higher revenue per rack. Managing token throughput efficiently — balancing latency, accuracy and user load — is crucial for keeping costs down.&lt;/p&gt;
&lt;p&gt;The industry is seeing rapid cost improvements, going as far as reducing costs-per-million-tokens by 80% through stack-wide optimizations. The same gains are achievable running gpt-oss and other open-source models from NVIDIA’s inference ecosystem, whether in hyperscale data centers or on local AI PCs.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Technology Ecosystem and Install Base&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;As models advance — featuring longer context windows, more tokens and more sophisticated runtime behaviors — their inference performance scales.&lt;/p&gt;
&lt;p&gt;Open models are a driving force in this momentum, accelerating over 70% of AI inference workloads today. They enable startups and enterprises alike to build custom agents, copilots and applications across every sector.&lt;/p&gt;
&lt;p&gt;Open-source communities play a critical role in the generative AI ecosystem — fostering collaboration, accelerating innovation and democratizing access. NVIDIA has over 1,000 open-source projects on GitHub in addition to 450 models and more than 80 datasets on Hugging Face. These help integrate popular frameworks like JAX, PyTorch, &lt;span&gt;vLLM&lt;/span&gt; and TensorRT-LLM into NVIDIA’s inference platform — ensuring maximum inference performance and flexibility across configurations.&lt;/p&gt;
&lt;p&gt;That’s why NVIDIA continues to contribute to open-source projects like llm-d and collaborate with industry leaders on open models, including Llama, Google Gemma, NVIDIA Nemotron, DeepSeek and gpt-oss — helping bring AI applications from idea to production at unprecedented speed.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="alignnone size-full wp-image-84040" height="512" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/think-smart-infrographic.png" width="1280" /&gt;&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;The Bottom Line for Optimized Inference&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;The NVIDIA inference platform, coupled with the Think SMART framework for deploying modern AI workloads, helps enterprises ensure their infrastructure can keep pace with the demands of rapidly advancing models — and that each token generated delivers maximum value.&lt;/p&gt;
&lt;p&gt;Learn more about how inference drives the revenue generating potential of AI factories.&lt;/p&gt;
&lt;p&gt;For monthly updates, sign up for the NVIDIA Think SMART newsletter.&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;From AI assistants doing deep research to autonomous vehicles making split-second navigation decisions, AI adoption is exploding across industries.&lt;/p&gt;
&lt;p&gt;Behind every one of those interactions is inference — the stage after training where an AI model processes inputs and produces outputs in real time.&lt;/p&gt;
&lt;p&gt;Today’s most advanced AI reasoning models — capable of multistep logic and complex decision-making — generate far more tokens per interaction than older models, driving a surge in token usage and the need for infrastructure that can manufacture intelligence at scale.&lt;/p&gt;
&lt;p&gt;AI factories are one way of meeting these growing needs.&lt;/p&gt;
&lt;p&gt;But running inference at such a large scale isn’t just about throwing more compute at the problem.&lt;/p&gt;
&lt;p&gt;To deploy AI with maximum efficiency, inference must be evaluated based on the &lt;b&gt;Think SMART framework:&lt;/b&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;S&lt;/b&gt;cale and complexity&lt;/li&gt;
&lt;li&gt;&lt;b&gt;M&lt;/b&gt;ultidimensional performance&lt;/li&gt;
&lt;li&gt;&lt;b&gt;A&lt;/b&gt;rchitecture and software&lt;/li&gt;
&lt;li&gt;&lt;b&gt;R&lt;/b&gt;eturn on investment driven by performance&lt;/li&gt;
&lt;li&gt;&lt;b&gt;T&lt;/b&gt;echnology ecosystem and install base&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;strong&gt;Scale and Complexity&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;As models evolve from compact applications to massive, multi-expert systems, inference must keep pace with increasingly diverse workloads — from answering quick, single-shot queries to multistep reasoning involving millions of tokens.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;The expanding size and intricacy of AI models introduce major implications for inference, such as resource intensity, latency and throughput, energy and costs, as well as diversity of use cases.&lt;/p&gt;
&lt;p&gt;To meet this complexity, AI service providers and enterprises are scaling up their infrastructure, with new AI factories coming online from partners like CoreWeave, Dell Technologies, Google Cloud and Nebius.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Multidimensional Performance&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Scaling complex AI deployments means AI factories need the flexibility to serve tokens across a wide spectrum of use cases while balancing accuracy, latency and costs.&lt;/p&gt;
&lt;p&gt;Some workloads, such as real-time speech-to-text translation, demand ultralow latency and a large number of tokens per user, straining computational resources for maximum responsiveness. Others are latency-insensitive and geared for sheer throughput, such as generating answers to dozens of complex questions simultaneously.&lt;/p&gt;
&lt;p&gt;But most popular real-time scenarios operate somewhere in the middle: requiring quick responses to keep users happy and high throughput to simultaneously serve up to millions of users — all while minimizing cost per token.&lt;/p&gt;
&lt;p&gt;For example, the NVIDIA inference platform is built to balance both latency and throughput, powering inference benchmarks on models like gpt-oss, DeepSeek-R1 and Llama 3.1.&lt;/p&gt;
&lt;h3&gt;&lt;b&gt;What to Assess to Achieve Optimal Multidimensional Performance&lt;/b&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Throughput:&lt;/b&gt; How many tokens can the system process per second? The more, the better for scaling workloads and revenue.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Latency:&lt;/b&gt; How quickly does the system respond to each individual prompt? Lower latency means a better experience for users — crucial for interactive applications.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Scalability:&lt;/b&gt; Can the system setup quickly adapt as demand increases, going from one to thousands of GPUs without complex restructuring or wasted resources?&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Cost Efficiency:&lt;/b&gt; Is performance per dollar high, and are those gains sustainable as system demands grow?&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;strong&gt;Architecture and Software&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;AI inference performance needs to be engineered from the ground up. It comes from hardware and software working in sync — GPUs, networking and code tuned to avoid bottlenecks and make the most of every cycle.&lt;/p&gt;
&lt;p&gt;Powerful architecture without smart orchestration wastes potential; great software without fast, low-latency hardware means sluggish performance. The key is architecting a system so that it can quickly, efficiently and flexibly turn prompts into useful answers.&lt;/p&gt;
&lt;p&gt;Enterprises can use NVIDIA infrastructure to build a system that delivers optimal performance.&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;Architecture Optimized for Inference at AI Factory Scale&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;The NVIDIA Blackwell platform unlocks a 50x boost in AI factory productivity for inference — meaning enterprises can optimize throughput and interactive responsiveness, even when running the most complex models.&lt;/p&gt;
&lt;p&gt;The NVIDIA GB200 NVL72 rack-scale system connects 36 NVIDIA Grace CPUs and 72 Blackwell GPUs with NVIDIA NVLink interconnect, delivering 40x higher revenue potential, 30x higher throughput, 25x more energy efficiency and 300x more water efficiency for demanding AI reasoning workloads.&lt;/p&gt;
&lt;p&gt;Further, NVFP4 is a low-precision format that delivers peak performance on NVIDIA Blackwell and slashes energy, memory and bandwidth demands without skipping a beat on accuracy, so users can deliver more queries per watt and lower costs per token.&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;Full-Stack Inference Platform Accelerated on Blackwell&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Enabling inference at AI factory scale requires more than accelerated architecture. It requires a full-stack platform with multiple layers of solutions and tools that can work in concert together.&lt;/p&gt;
&lt;p&gt;Modern AI deployments require dynamic autoscaling from one to thousands of GPUs. The NVIDIA Dynamo platform steers distributed inference to dynamically assign GPUs and optimize data flows, delivering up to 4x more performance without cost increases. New cloud integrations further improve scalability and ease of deployment.&lt;/p&gt;
&lt;p&gt;For inference workloads focused on getting optimal performance per GPU, such as speeding up large mixture of expert models, frameworks like NVIDIA TensorRT-LLM are helping developers achieve breakthrough performance.&lt;/p&gt;
&lt;p&gt;With its new PyTorch-centric workflow, TensorRT-LLM streamlines AI deployment by removing the need for manual engine management. These solutions aren’t just powerful on their own — they’re built to work in tandem. For example, using Dynamo and TensorRT-LLM, mission-critical inference providers like Baseten can immediately deliver state-of-the-art model performance even on new frontier models like gpt-oss.&lt;/p&gt;
&lt;p&gt;On the model side, families like NVIDIA Nemotron are built with open training data for transparency, while still generating tokens quickly enough to handle advanced reasoning tasks with high accuracy — without increasing compute costs. And with NVIDIA NIM, those models can be packaged into ready-to-run microservices, making it easier for teams to roll them out and scale across environments while achieving the lowest total cost of ownership.&lt;/p&gt;
&lt;p&gt;Together, these layers — dynamic orchestration, optimized execution, well-designed models and simplified deployment — form the backbone of inference enablement for cloud providers and enterprises alike.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Return on Investment Driven by Performance&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;As AI adoption grows, organizations are increasingly looking to maximize the return on investment from each user query.&lt;/p&gt;
&lt;p&gt;Performance is the biggest driver of return on investment. A 4x increase in performance from the NVIDIA Hopper architecture to Blackwell yields up to 10x profit growth within a similar power budget.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;In power-limited data centers and AI factories, generating more tokens per watt translates directly to higher revenue per rack. Managing token throughput efficiently — balancing latency, accuracy and user load — is crucial for keeping costs down.&lt;/p&gt;
&lt;p&gt;The industry is seeing rapid cost improvements, going as far as reducing costs-per-million-tokens by 80% through stack-wide optimizations. The same gains are achievable running gpt-oss and other open-source models from NVIDIA’s inference ecosystem, whether in hyperscale data centers or on local AI PCs.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Technology Ecosystem and Install Base&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;As models advance — featuring longer context windows, more tokens and more sophisticated runtime behaviors — their inference performance scales.&lt;/p&gt;
&lt;p&gt;Open models are a driving force in this momentum, accelerating over 70% of AI inference workloads today. They enable startups and enterprises alike to build custom agents, copilots and applications across every sector.&lt;/p&gt;
&lt;p&gt;Open-source communities play a critical role in the generative AI ecosystem — fostering collaboration, accelerating innovation and democratizing access. NVIDIA has over 1,000 open-source projects on GitHub in addition to 450 models and more than 80 datasets on Hugging Face. These help integrate popular frameworks like JAX, PyTorch, &lt;span&gt;vLLM&lt;/span&gt; and TensorRT-LLM into NVIDIA’s inference platform — ensuring maximum inference performance and flexibility across configurations.&lt;/p&gt;
&lt;p&gt;That’s why NVIDIA continues to contribute to open-source projects like llm-d and collaborate with industry leaders on open models, including Llama, Google Gemma, NVIDIA Nemotron, DeepSeek and gpt-oss — helping bring AI applications from idea to production at unprecedented speed.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="alignnone size-full wp-image-84040" height="512" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/think-smart-infrographic.png" width="1280" /&gt;&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;The Bottom Line for Optimized Inference&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;The NVIDIA inference platform, coupled with the Think SMART framework for deploying modern AI workloads, helps enterprises ensure their infrastructure can keep pace with the demands of rapidly advancing models — and that each token generated delivers maximum value.&lt;/p&gt;
&lt;p&gt;Learn more about how inference drives the revenue generating potential of AI factories.&lt;/p&gt;
&lt;p&gt;For monthly updates, sign up for the NVIDIA Think SMART newsletter.&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/think-smart-optimize-ai-factory-inference-performance/</guid><pubDate>Thu, 21 Aug 2025 15:00:15 +0000</pubDate></item><item><title>[NEW] Gearing Up for the Gigawatt Data Center Age (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/networking-matters-more-than-ever/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Across the globe, AI factories are rising — massive new data centers built not to serve up web pages or email, but to train and deploy intelligence itself. Internet giants have invested billions in cloud-scale AI infrastructure for their customers. Companies are racing to build AI foundries that will spawn the next generation of products and services. Governments are investing too, eager to harness AI for personalized medicine and language services tailored to national populations.&lt;/p&gt;
&lt;p&gt;Welcome to the age of AI factories — where the rules are being rewritten and the wiring doesn’t look anything like the old internet. These aren’t typical hyperscale data centers. They’re something else entirely. Think of them as high-performance engines stitched together from tens to hundreds of thousands of GPUs — not just built, but orchestrated, operated and activated as a single unit. And that orchestration? It’s the whole game.&lt;/p&gt;
&lt;p&gt;This giant data center has become the new unit of computing, and the way these GPUs are connected defines what this unit of computing can do. One network architecture won’t cut it. What’s needed is a layered design with bleeding-edge technologies — like co-packaged optics that once seemed like science fiction.&lt;/p&gt;
&lt;p&gt;The complexity isn’t a bug; it’s the defining feature. AI infrastructure is diverging fast from everything that came before it, and if there isn’t rethinking on how the pipes connect, scale breaks down. Get the network layers wrong, and the whole machine grinds to a halt. Get it right, and gain extraordinary performance.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class=" wp-image-84050 alignleft" height="374" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/newsletter-inception-nvidia-gb200-nvl72-600x600-1.jpg" width="374" /&gt;With that shift comes weight — literally. A decade ago, chips were built to be sleek and lightweight. Now, the cutting edge looks like the multi‑hundred‑pound copper spine of a server rack. Liquid-cooled manifolds. Custom busbars. Copper spines. AI now demands massive, industrial-scale hardware. And the deeper the models go, the more these machines scale up, and out.&lt;/p&gt;
&lt;p&gt;The NVIDIA NVLink spine, for example, is built from over 5,000 coaxial cables — tightly wound and precisely routed. It moves more data per second than the entire internet. That’s 130 TB/s of GPU-to-GPU bandwidth, fully meshed.&lt;/p&gt;
&lt;p&gt;This isn’t just fast. It’s foundational. The AI super-highway now lives inside the rack.&lt;/p&gt;
&lt;h2&gt;The Data Center Is the Computer&lt;/h2&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-full wp-image-84064" height="680" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/ethernet-corp-blog-ai-factories-cpo-blog-1280x680-1.jpg" width="1280" /&gt;&lt;/p&gt;
&lt;p&gt;Training the modern large language models (LLMs) behind AI isn’t about burning cycles on a single machine. It’s about orchestrating the work of tens or even hundreds of thousands of GPUs that are the heavy lifters of AI computation.&lt;/p&gt;
&lt;p&gt;These systems rely on distributed computing, splitting massive calculations across nodes (individual servers), where each node handles a slice of the workload. In training, those slices — typically massive matrices of numbers — need to be regularly merged and updated. That merging occurs through collective operations, such as “all-reduce” (which combines data from all nodes and redistributes the result) and “all-to-all” (where each node exchanges data with every other node).&lt;/p&gt;
&lt;p&gt;These processes are susceptible to the speed and responsiveness of the network — what engineers call latency (delay) and bandwidth (data capacity) — causing stalls in training.&lt;/p&gt;
&lt;p&gt;For inference — the process of running trained models to generate answers or predictions — the challenges flip. Retrieval-augmented generation systems, which combine LLMs with search, demand real-time lookups and responses. And in cloud environments, multi-tenant inference means keeping workloads from different customers running smoothly, without interference. That requires lightning-fast, high-throughput networking that can handle massive demand with strict isolation between users.&lt;/p&gt;
&lt;p&gt;Traditional Ethernet was designed for single-server workloads — not for the demands of distributed AI. Tolerating jitter and inconsistent delivery were once acceptable. Now, it’s a bottleneck. Traditional Ethernet switch architectures were never designed for consistent, predictable performance — and that legacy still shapes their latest generations.&lt;/p&gt;
&lt;p&gt;Distributed computing requires a scale-out infrastructure built for zero-jitter operation — one that can handle bursts of extreme throughput, deliver low latency, maintain predictable and consistent RDMA performance, and isolate network noise. This is why InfiniBand networking is the gold standard for high-performance computing supercomputers and AI factories.&lt;/p&gt;
&lt;p&gt;With NVIDIA Quantum InfiniBand, collective operations run inside the network itself using Scalable Hierarchical Aggregation and Reduction Protocol technology, doubling data bandwidth for reductions. It uses adaptive routing and telemetry-based congestion control to spread flows across paths, guarantee deterministic bandwidth and isolate noise. These optimizations let InfiniBand scale AI communication with precision. It’s why NVIDIA Quantum infrastructure connects the majority of the systems on the TOP500 list of the world’s most powerful supercomputers, demonstrating 35% growth in just two years.&lt;/p&gt;
&lt;p&gt;For clusters spanning dozens of racks, NVIDIA Quantum‑X800 Infiniband switches push InfiniBand to new heights. Each switch provides 144 ports of 800 Gbps connectivity, featuring hardware-based SHARPv4, adaptive routing and telemetry-based congestion control. The platform integrates co‑packaged silicon photonics to minimize the distance between electronics and optics, reducing power consumption and latency. Paired with NVIDIA ConnectX-8 SuperNICs delivering 800 Gb/s per GPU, this fabric links trillion-parameter models and drives in-network compute.&lt;/p&gt;
&lt;p&gt;But hyperscalers and enterprises have invested billions in their Ethernet software infrastructure. They need a quick path forward that uses the existing ecosystem for AI workloads. Enter NVIDIA Spectrum‑X: a new kind of Ethernet purpose-built for distributed AI.&lt;/p&gt;
&lt;h2&gt;Spectrum‑X Ethernet: Bringing AI to the Enterprise&lt;/h2&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter wp-image-84069" height="720" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/ethernet-render-spectrum-x-sn5610-cx8-exploded-4050050-1680x945.jpg" width="1280" /&gt;&lt;/p&gt;
&lt;p&gt;Spectrum‑X reimagines Ethernet for AI. Launched in 2023 Spectrum‑X delivers lossless networking, adaptive routing and performance isolation. The SN5610 switch, based on the Spectrum‑4 ASIC, supports port speeds up to 800 Gb/s and uses NVIDIA’s congestion control to maintain 95% data throughput at scale.&lt;/p&gt;
&lt;p&gt;Spectrum‑X is fully standards‑based Ethernet. In addition to supporting Cumulus Linux, it supports the open‑source SONiC network operating system — giving customers flexibility. A key ingredient is NVIDIA SuperNICs — based on NVIDIA BlueField-3 or ConnectX-8 — which provide up to 800 Gb/s RoCE connectivity and offload packet reordering and congestion management.&lt;/p&gt;
&lt;p&gt;Spectrum-X brings InfiniBand’s best innovations — like telemetry-driven congestion control, adaptive load balancing and direct data placement — to Ethernet, enabling enterprises to scale to hundreds of thousands of GPUs. Large-scale systems with Spectrum‑X, including the world’s most colossal AI supercomputer, have achieved 95% data throughput with zero application latency degradation. Standard Ethernet fabrics would deliver only ~60% throughput due to flow collisions.&lt;/p&gt;
&lt;h2&gt;A Portfolio for Scale‑Up and Scale‑Out&lt;/h2&gt;
&lt;p&gt;No single network can serve every layer of an AI factory. NVIDIA’s approach is to match the right fabric to the right tier, then tie everything together with software and silicon.&lt;/p&gt;
&lt;h2&gt;NVLink: Scale Up Inside the Rack&lt;/h2&gt;
&lt;p&gt;Inside a server rack, GPUs need to talk to each other as if they were different cores on the same chip. NVIDIA NVLink and NVLink Switch extend GPU memory and bandwidth across nodes. In an NVIDIA GB300 NVL72 system, 36 NVIDIA Grace CPUs and 72 NVIDIA Blackwell Ultra GPUs are connected in a single NVLink domain, with an aggregate bandwidth of 130 TB/s. NVLink Switch technology further extends this fabric: a single GB300 NVL72 system can offer 130 TB/s of GPU bandwidth, enabling clusters to support 9x the GPU count of a single 8‑GPU server. With NVLink, the entire rack becomes one large GPU.&lt;/p&gt;
&lt;h2&gt;Photonics: The Next Leap&lt;/h2&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter wp-image-84073" height="718" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/ethernet-tech-blog-cpo-blog-2-1480x830-1.png" width="1280" /&gt;&lt;/p&gt;
&lt;p&gt;To reach million‑GPU AI factories, the network must break the power and density limits of pluggable optics. NVIDIA Quantum-X and Spectrum-X Photonics switches integrate silicon photonics directly into the switch package, delivering 128 to 512 ports of 800 Gb/s with total bandwidths ranging from 100 Tb/s to 400 Tb/s. These switches offer 3.5x more power efficiency and 10x better resiliency compared with traditional optics, paving the way for gigawatt‑scale AI factories.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;br /&gt;&lt;!-- The surrounding HTML, head, and body tags were removed because WordPress already provides them. --&gt;&lt;/p&gt;

&lt;div&gt;&lt;!-- The headline, as requested, uses the h2 tag. --&gt;
&lt;h2&gt;Delivering on the Promise of Open Standards&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Spectrum‑X and NVIDIA Quantum InfiniBand are built on open standards.&lt;/strong&gt; Spectrum‑X is fully standards‑based Ethernet with support for open Ethernet stacks like SONiC, while NVIDIA Quantum InfiniBand and Spectrum-X conform to the InfiniBand Trade Association’s InfiniBand and RDMA over Converged Ethernet (RoCE) specifications. Key elements of NVIDIA’s software stack — including NCCL and DOCA libraries — run on a variety of hardware, and partners such as Cisco, Dell Technologies, HPE and Supermicro integrate Spectrum-X into their systems.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Open standards create the foundation for interoperability, but real-world AI clusters require tight optimization across the entire stack — GPUs, NICs, switches, cables and software.&lt;/strong&gt; Vendors that invest in end‑to‑end integration deliver better latency and throughput. SONiC, the open‑source network operating system hardened in hyperscale data centers, eliminates licensing and vendor lock‑in and allows intense customization, but operators still choose purpose‑built hardware and software bundles to meet AI’s performance needs. In practice, open standards alone don’t deliver deterministic performance; they need innovation layered on top.&lt;/p&gt;
&lt;/div&gt;
&lt;h2&gt;Toward Million‑GPU AI Factories&lt;/h2&gt;
&lt;p&gt;AI factories are scaling fast. Governments in Europe are building seven national AI factories, while cloud providers and enterprises across Japan, India and Norway are rolling out NVIDIA‑powered AI infrastructure. The next horizon is gigawatt‑class facilities with a million GPUs. To get there, the network must evolve from an afterthought to a pillar of AI infrastructure.&lt;/p&gt;
&lt;p&gt;The lesson from the gigawatt data center age is simple: the data center is now the computer. NVLink stitches together GPUs inside the rack. NVIDIA Quantum InfiniBand scales them across it. Spectrum-X brings that performance to broader markets. Silicon photonics makes it sustainable. Everything is open where it matters, optimized where it counts.&lt;/p&gt;




		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Across the globe, AI factories are rising — massive new data centers built not to serve up web pages or email, but to train and deploy intelligence itself. Internet giants have invested billions in cloud-scale AI infrastructure for their customers. Companies are racing to build AI foundries that will spawn the next generation of products and services. Governments are investing too, eager to harness AI for personalized medicine and language services tailored to national populations.&lt;/p&gt;
&lt;p&gt;Welcome to the age of AI factories — where the rules are being rewritten and the wiring doesn’t look anything like the old internet. These aren’t typical hyperscale data centers. They’re something else entirely. Think of them as high-performance engines stitched together from tens to hundreds of thousands of GPUs — not just built, but orchestrated, operated and activated as a single unit. And that orchestration? It’s the whole game.&lt;/p&gt;
&lt;p&gt;This giant data center has become the new unit of computing, and the way these GPUs are connected defines what this unit of computing can do. One network architecture won’t cut it. What’s needed is a layered design with bleeding-edge technologies — like co-packaged optics that once seemed like science fiction.&lt;/p&gt;
&lt;p&gt;The complexity isn’t a bug; it’s the defining feature. AI infrastructure is diverging fast from everything that came before it, and if there isn’t rethinking on how the pipes connect, scale breaks down. Get the network layers wrong, and the whole machine grinds to a halt. Get it right, and gain extraordinary performance.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class=" wp-image-84050 alignleft" height="374" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/newsletter-inception-nvidia-gb200-nvl72-600x600-1.jpg" width="374" /&gt;With that shift comes weight — literally. A decade ago, chips were built to be sleek and lightweight. Now, the cutting edge looks like the multi‑hundred‑pound copper spine of a server rack. Liquid-cooled manifolds. Custom busbars. Copper spines. AI now demands massive, industrial-scale hardware. And the deeper the models go, the more these machines scale up, and out.&lt;/p&gt;
&lt;p&gt;The NVIDIA NVLink spine, for example, is built from over 5,000 coaxial cables — tightly wound and precisely routed. It moves more data per second than the entire internet. That’s 130 TB/s of GPU-to-GPU bandwidth, fully meshed.&lt;/p&gt;
&lt;p&gt;This isn’t just fast. It’s foundational. The AI super-highway now lives inside the rack.&lt;/p&gt;
&lt;h2&gt;The Data Center Is the Computer&lt;/h2&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-full wp-image-84064" height="680" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/ethernet-corp-blog-ai-factories-cpo-blog-1280x680-1.jpg" width="1280" /&gt;&lt;/p&gt;
&lt;p&gt;Training the modern large language models (LLMs) behind AI isn’t about burning cycles on a single machine. It’s about orchestrating the work of tens or even hundreds of thousands of GPUs that are the heavy lifters of AI computation.&lt;/p&gt;
&lt;p&gt;These systems rely on distributed computing, splitting massive calculations across nodes (individual servers), where each node handles a slice of the workload. In training, those slices — typically massive matrices of numbers — need to be regularly merged and updated. That merging occurs through collective operations, such as “all-reduce” (which combines data from all nodes and redistributes the result) and “all-to-all” (where each node exchanges data with every other node).&lt;/p&gt;
&lt;p&gt;These processes are susceptible to the speed and responsiveness of the network — what engineers call latency (delay) and bandwidth (data capacity) — causing stalls in training.&lt;/p&gt;
&lt;p&gt;For inference — the process of running trained models to generate answers or predictions — the challenges flip. Retrieval-augmented generation systems, which combine LLMs with search, demand real-time lookups and responses. And in cloud environments, multi-tenant inference means keeping workloads from different customers running smoothly, without interference. That requires lightning-fast, high-throughput networking that can handle massive demand with strict isolation between users.&lt;/p&gt;
&lt;p&gt;Traditional Ethernet was designed for single-server workloads — not for the demands of distributed AI. Tolerating jitter and inconsistent delivery were once acceptable. Now, it’s a bottleneck. Traditional Ethernet switch architectures were never designed for consistent, predictable performance — and that legacy still shapes their latest generations.&lt;/p&gt;
&lt;p&gt;Distributed computing requires a scale-out infrastructure built for zero-jitter operation — one that can handle bursts of extreme throughput, deliver low latency, maintain predictable and consistent RDMA performance, and isolate network noise. This is why InfiniBand networking is the gold standard for high-performance computing supercomputers and AI factories.&lt;/p&gt;
&lt;p&gt;With NVIDIA Quantum InfiniBand, collective operations run inside the network itself using Scalable Hierarchical Aggregation and Reduction Protocol technology, doubling data bandwidth for reductions. It uses adaptive routing and telemetry-based congestion control to spread flows across paths, guarantee deterministic bandwidth and isolate noise. These optimizations let InfiniBand scale AI communication with precision. It’s why NVIDIA Quantum infrastructure connects the majority of the systems on the TOP500 list of the world’s most powerful supercomputers, demonstrating 35% growth in just two years.&lt;/p&gt;
&lt;p&gt;For clusters spanning dozens of racks, NVIDIA Quantum‑X800 Infiniband switches push InfiniBand to new heights. Each switch provides 144 ports of 800 Gbps connectivity, featuring hardware-based SHARPv4, adaptive routing and telemetry-based congestion control. The platform integrates co‑packaged silicon photonics to minimize the distance between electronics and optics, reducing power consumption and latency. Paired with NVIDIA ConnectX-8 SuperNICs delivering 800 Gb/s per GPU, this fabric links trillion-parameter models and drives in-network compute.&lt;/p&gt;
&lt;p&gt;But hyperscalers and enterprises have invested billions in their Ethernet software infrastructure. They need a quick path forward that uses the existing ecosystem for AI workloads. Enter NVIDIA Spectrum‑X: a new kind of Ethernet purpose-built for distributed AI.&lt;/p&gt;
&lt;h2&gt;Spectrum‑X Ethernet: Bringing AI to the Enterprise&lt;/h2&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter wp-image-84069" height="720" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/ethernet-render-spectrum-x-sn5610-cx8-exploded-4050050-1680x945.jpg" width="1280" /&gt;&lt;/p&gt;
&lt;p&gt;Spectrum‑X reimagines Ethernet for AI. Launched in 2023 Spectrum‑X delivers lossless networking, adaptive routing and performance isolation. The SN5610 switch, based on the Spectrum‑4 ASIC, supports port speeds up to 800 Gb/s and uses NVIDIA’s congestion control to maintain 95% data throughput at scale.&lt;/p&gt;
&lt;p&gt;Spectrum‑X is fully standards‑based Ethernet. In addition to supporting Cumulus Linux, it supports the open‑source SONiC network operating system — giving customers flexibility. A key ingredient is NVIDIA SuperNICs — based on NVIDIA BlueField-3 or ConnectX-8 — which provide up to 800 Gb/s RoCE connectivity and offload packet reordering and congestion management.&lt;/p&gt;
&lt;p&gt;Spectrum-X brings InfiniBand’s best innovations — like telemetry-driven congestion control, adaptive load balancing and direct data placement — to Ethernet, enabling enterprises to scale to hundreds of thousands of GPUs. Large-scale systems with Spectrum‑X, including the world’s most colossal AI supercomputer, have achieved 95% data throughput with zero application latency degradation. Standard Ethernet fabrics would deliver only ~60% throughput due to flow collisions.&lt;/p&gt;
&lt;h2&gt;A Portfolio for Scale‑Up and Scale‑Out&lt;/h2&gt;
&lt;p&gt;No single network can serve every layer of an AI factory. NVIDIA’s approach is to match the right fabric to the right tier, then tie everything together with software and silicon.&lt;/p&gt;
&lt;h2&gt;NVLink: Scale Up Inside the Rack&lt;/h2&gt;
&lt;p&gt;Inside a server rack, GPUs need to talk to each other as if they were different cores on the same chip. NVIDIA NVLink and NVLink Switch extend GPU memory and bandwidth across nodes. In an NVIDIA GB300 NVL72 system, 36 NVIDIA Grace CPUs and 72 NVIDIA Blackwell Ultra GPUs are connected in a single NVLink domain, with an aggregate bandwidth of 130 TB/s. NVLink Switch technology further extends this fabric: a single GB300 NVL72 system can offer 130 TB/s of GPU bandwidth, enabling clusters to support 9x the GPU count of a single 8‑GPU server. With NVLink, the entire rack becomes one large GPU.&lt;/p&gt;
&lt;h2&gt;Photonics: The Next Leap&lt;/h2&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter wp-image-84073" height="718" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/ethernet-tech-blog-cpo-blog-2-1480x830-1.png" width="1280" /&gt;&lt;/p&gt;
&lt;p&gt;To reach million‑GPU AI factories, the network must break the power and density limits of pluggable optics. NVIDIA Quantum-X and Spectrum-X Photonics switches integrate silicon photonics directly into the switch package, delivering 128 to 512 ports of 800 Gb/s with total bandwidths ranging from 100 Tb/s to 400 Tb/s. These switches offer 3.5x more power efficiency and 10x better resiliency compared with traditional optics, paving the way for gigawatt‑scale AI factories.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;br /&gt;&lt;!-- The surrounding HTML, head, and body tags were removed because WordPress already provides them. --&gt;&lt;/p&gt;

&lt;div&gt;&lt;!-- The headline, as requested, uses the h2 tag. --&gt;
&lt;h2&gt;Delivering on the Promise of Open Standards&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Spectrum‑X and NVIDIA Quantum InfiniBand are built on open standards.&lt;/strong&gt; Spectrum‑X is fully standards‑based Ethernet with support for open Ethernet stacks like SONiC, while NVIDIA Quantum InfiniBand and Spectrum-X conform to the InfiniBand Trade Association’s InfiniBand and RDMA over Converged Ethernet (RoCE) specifications. Key elements of NVIDIA’s software stack — including NCCL and DOCA libraries — run on a variety of hardware, and partners such as Cisco, Dell Technologies, HPE and Supermicro integrate Spectrum-X into their systems.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Open standards create the foundation for interoperability, but real-world AI clusters require tight optimization across the entire stack — GPUs, NICs, switches, cables and software.&lt;/strong&gt; Vendors that invest in end‑to‑end integration deliver better latency and throughput. SONiC, the open‑source network operating system hardened in hyperscale data centers, eliminates licensing and vendor lock‑in and allows intense customization, but operators still choose purpose‑built hardware and software bundles to meet AI’s performance needs. In practice, open standards alone don’t deliver deterministic performance; they need innovation layered on top.&lt;/p&gt;
&lt;/div&gt;
&lt;h2&gt;Toward Million‑GPU AI Factories&lt;/h2&gt;
&lt;p&gt;AI factories are scaling fast. Governments in Europe are building seven national AI factories, while cloud providers and enterprises across Japan, India and Norway are rolling out NVIDIA‑powered AI infrastructure. The next horizon is gigawatt‑class facilities with a million GPUs. To get there, the network must evolve from an afterthought to a pillar of AI infrastructure.&lt;/p&gt;
&lt;p&gt;The lesson from the gigawatt data center age is simple: the data center is now the computer. NVLink stitches together GPUs inside the rack. NVIDIA Quantum InfiniBand scales them across it. Spectrum-X brings that performance to broader markets. Silicon photonics makes it sustainable. Everything is open where it matters, optimized where it counts.&lt;/p&gt;




		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/networking-matters-more-than-ever/</guid><pubDate>Thu, 21 Aug 2025 15:00:53 +0000</pubDate></item><item><title>[NEW] How AI servers are transforming Taiwan’s electronics manufacturing giants (AI News)</title><link>https://www.artificialintelligence-news.com/news/ai-servers-transform-taiwan-manufacturing-giants/</link><description>&lt;p&gt;The revenue charts tell a story that would have seemed impossible just three years ago: AI servers are now generating more money than iPhones for Taiwan’s manufacturing giants. For the first time in decades, Taiwan’s manufacturing titans are watching their bread-and-butter consumer electronics businesses get overtaken by artificial intelligence infrastructure – a shift that’s rewriting the playbook for an industry that was built on assembling the world’s smartphones and laptops.&lt;/p&gt;&lt;p&gt;What took Apple nearly two decades to build, AI servers have displaced in less than three years, signalling an inflexion point that companies like Foxconn are navigating actively, diversifying beyond traditional consumer electronics.&lt;/p&gt;&lt;h3&gt;The scale of Taiwan’s server dominance&lt;/h3&gt;&lt;p&gt;Taiwan’s commanding position in global server manufacturing has positioned it perfectly for the AI boom, with the island accounting for over 90% of global AI server builds and approximately 80% of all server shipments worldwide. Its dominance stems from decades of expertise in electronics manufacturing, originally developed through the notebook computer industry, since evolved into an important advantage in the age of artificial intelligence.&lt;/p&gt;&lt;p&gt;According to statistics released by Taiwan’s Ministry of Economic Affairs in October 2024, the island’s server production value from January to July 2024 reached NT$426.7 billion (approximately US$13.2 billion) in value, in seven months surpassing the total value for 2023 and representing an annual growth rate of 153.9%.&lt;/p&gt;&lt;h3&gt;Major players experience revenue surges&lt;/h3&gt;&lt;p&gt;The impact of AI servers on Taiwan’s manufacturing giants has been nothing short of transformational. Nvidia partner Wistron’s revenue for January to July rose 92.7%, while Quanta’s grew 65.6% in the same period. The numbers reflect a broader trend affecting the entire ecosystem of Taiwan’s original design manufacturers (ODMs).&lt;/p&gt;&lt;p&gt;Foxconn, the world’s largest contract manufacturer, has experienced perhaps the most dramatic shift. Consumer electronics accounted for 35% of Foxconn’s total revenue in the second quarter of this year, while the cloud and networking business represented 41%. In 2021, consumer electronics represented 54% of its revenue. Now is the first time AI servers and cloud infrastructure have overtaken the company’s traditional smartphone manufacturing business.&lt;/p&gt;&lt;h4&gt;Quanta Computer’s AI server focus&lt;/h4&gt;&lt;p&gt;Quanta Computer, which supplies AI servers powered by Nvidia chips, said that AI servers are on track to account for 70% of its total server revenue this year, thanks to improved yield rates and a better learning curve for Nvidia’s GB300 chip-based servers. AI servers accounted for more than 60% of its total server revenue in the first half of this year.&lt;/p&gt;&lt;p&gt;Quanta is the world’s second-largest server assembly contractor, taking approximately 17% of the market. Its primary focus is AI server projects from the four major CSPs (Microsoft, Amazon, Google, and Meta). The company has secured orders for Nvidia’s latest GB200 servers and has been expanding production capacity to meet increased demand.&lt;/p&gt;&lt;h4&gt;Wistron’s strategic positioning&lt;/h4&gt;&lt;p&gt;Wistron has currently secured orders for Nvidia’s HGX Level 6 and DGX Level 10 servers, and obtained orders for the new generation AMD MI300 series AI server boards. Nvidia this week booked an entire Wistron server plant in Taiwan to build AI servers, highlighting the intensity of demand and the strategic importance of securing manufacturing capacity.&lt;/p&gt;&lt;p&gt;Quanta Computer plans to increase production capacity for AI servers in the US, and its factories there are booked up to the end of 2025. The capacity constraint reflects the “insane demand” that characterised the AI server market throughout 2024 and into 2025.&lt;/p&gt;&lt;h3&gt;Market share and financial impact&lt;/h3&gt;&lt;p&gt;The financial transformation in the sector has been remarkable. Quanta Computer reported that AI servers are on track to account for 70% of its total server revenue this year, with AI servers already accounting for more than 60% of its total server revenue in the first half of 2025, according to chief financial officer Elton Yang.&lt;/p&gt;&lt;p&gt;Wistron has demonstrated the transformative impact of AI servers on manufacturing economics, with the company’s revenue for January to July 2025 rising 92.7% compared to the same period in the previous year. The dramatic growth reflects the premium nature of AI server manufacturing compared to traditional consumer electronics.&lt;/p&gt;&lt;p&gt;The impact extends to Taiwan’s broader server ecosystem, with companies securing multi-year production contracts that extend well into 2026, indicating sustained demand and revenue visibility that was rarely seen in the consumer electronics era.&lt;/p&gt;&lt;h3&gt;Strategic implications and future outlook&lt;/h3&gt;&lt;p&gt;“The monthly sales jump for Taiwan ODMs in the first half of 2025 is evidence of this trend,” Robert Cheng, head of Asia technology hardware research at BofA Global Research, told &lt;em&gt;Reuters&lt;/em&gt;, referring to original design manufacturers like Foxconn that contract manufacture products for their clients.&lt;/p&gt;&lt;p&gt;The situation reflects a repositioning of Taiwan in the global technology supply chain. Where companies once competed primarily on cost and manufacturing efficiency for consumer electronics, AI servers require higher levels of technical sophistication, closer collaboration with chip designers, and more stringent quality control.&lt;/p&gt;&lt;p&gt;“We think this shift toward AI servers, whatever form it takes, is good for Taiwan’s tech industry,” Cheng said, noting Taiwanese firms’ ability to shift rapidly to cater to the changing needs of their customers.&lt;/p&gt;&lt;p&gt;However, challenges lie ahead. Taiwan’s current 90% share of the global AI server market may soon decline as manufacturers expand production elsewhere. Companies are already establishing manufacturing facilities in the US, Mexico, and other locations to serve local markets and comply with supply chain requirements.&lt;/p&gt;&lt;h3&gt;Industry-wide transformation&lt;/h3&gt;&lt;p&gt;The AI server boom has catalysed changes that extend beyond individual companies to reshape Taiwan’s entire electronics manufacturing ecosystem. Traditional boundaries between different types of technology products are blurring as manufacturers develop new capabilities and forge closer partnerships with AI chip companies.&lt;/p&gt;&lt;p&gt;The transformation also highlights Taiwan’s unique position in the global technology supply chain. The combination of advanced manufacturing capabilities, established relationships with major technology companies, and proximity to key semiconductor facilities has created a competitive advantage that continues to drive growth.&lt;/p&gt;&lt;p&gt;As artificial intelligence applications continue to need more sophisticated computing infrastructure, Taiwan’s manufacturers appear well-positioned to capitalise on demand. The challenge will be maintaining the country’s technology leadership while adapting to changing geopolitical and market conditions that may require more distributed global operations.&lt;/p&gt;&lt;p&gt;The shift from consumer electronics to AI servers exemplifies Taiwan’s ability to reinvent itself in response to technological change, maintain its central role in the global technology ecosystem, adapt and innovate.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Huawei unveils high-end AI chip for servers alongside MindSpore framework&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;The revenue charts tell a story that would have seemed impossible just three years ago: AI servers are now generating more money than iPhones for Taiwan’s manufacturing giants. For the first time in decades, Taiwan’s manufacturing titans are watching their bread-and-butter consumer electronics businesses get overtaken by artificial intelligence infrastructure – a shift that’s rewriting the playbook for an industry that was built on assembling the world’s smartphones and laptops.&lt;/p&gt;&lt;p&gt;What took Apple nearly two decades to build, AI servers have displaced in less than three years, signalling an inflexion point that companies like Foxconn are navigating actively, diversifying beyond traditional consumer electronics.&lt;/p&gt;&lt;h3&gt;The scale of Taiwan’s server dominance&lt;/h3&gt;&lt;p&gt;Taiwan’s commanding position in global server manufacturing has positioned it perfectly for the AI boom, with the island accounting for over 90% of global AI server builds and approximately 80% of all server shipments worldwide. Its dominance stems from decades of expertise in electronics manufacturing, originally developed through the notebook computer industry, since evolved into an important advantage in the age of artificial intelligence.&lt;/p&gt;&lt;p&gt;According to statistics released by Taiwan’s Ministry of Economic Affairs in October 2024, the island’s server production value from January to July 2024 reached NT$426.7 billion (approximately US$13.2 billion) in value, in seven months surpassing the total value for 2023 and representing an annual growth rate of 153.9%.&lt;/p&gt;&lt;h3&gt;Major players experience revenue surges&lt;/h3&gt;&lt;p&gt;The impact of AI servers on Taiwan’s manufacturing giants has been nothing short of transformational. Nvidia partner Wistron’s revenue for January to July rose 92.7%, while Quanta’s grew 65.6% in the same period. The numbers reflect a broader trend affecting the entire ecosystem of Taiwan’s original design manufacturers (ODMs).&lt;/p&gt;&lt;p&gt;Foxconn, the world’s largest contract manufacturer, has experienced perhaps the most dramatic shift. Consumer electronics accounted for 35% of Foxconn’s total revenue in the second quarter of this year, while the cloud and networking business represented 41%. In 2021, consumer electronics represented 54% of its revenue. Now is the first time AI servers and cloud infrastructure have overtaken the company’s traditional smartphone manufacturing business.&lt;/p&gt;&lt;h4&gt;Quanta Computer’s AI server focus&lt;/h4&gt;&lt;p&gt;Quanta Computer, which supplies AI servers powered by Nvidia chips, said that AI servers are on track to account for 70% of its total server revenue this year, thanks to improved yield rates and a better learning curve for Nvidia’s GB300 chip-based servers. AI servers accounted for more than 60% of its total server revenue in the first half of this year.&lt;/p&gt;&lt;p&gt;Quanta is the world’s second-largest server assembly contractor, taking approximately 17% of the market. Its primary focus is AI server projects from the four major CSPs (Microsoft, Amazon, Google, and Meta). The company has secured orders for Nvidia’s latest GB200 servers and has been expanding production capacity to meet increased demand.&lt;/p&gt;&lt;h4&gt;Wistron’s strategic positioning&lt;/h4&gt;&lt;p&gt;Wistron has currently secured orders for Nvidia’s HGX Level 6 and DGX Level 10 servers, and obtained orders for the new generation AMD MI300 series AI server boards. Nvidia this week booked an entire Wistron server plant in Taiwan to build AI servers, highlighting the intensity of demand and the strategic importance of securing manufacturing capacity.&lt;/p&gt;&lt;p&gt;Quanta Computer plans to increase production capacity for AI servers in the US, and its factories there are booked up to the end of 2025. The capacity constraint reflects the “insane demand” that characterised the AI server market throughout 2024 and into 2025.&lt;/p&gt;&lt;h3&gt;Market share and financial impact&lt;/h3&gt;&lt;p&gt;The financial transformation in the sector has been remarkable. Quanta Computer reported that AI servers are on track to account for 70% of its total server revenue this year, with AI servers already accounting for more than 60% of its total server revenue in the first half of 2025, according to chief financial officer Elton Yang.&lt;/p&gt;&lt;p&gt;Wistron has demonstrated the transformative impact of AI servers on manufacturing economics, with the company’s revenue for January to July 2025 rising 92.7% compared to the same period in the previous year. The dramatic growth reflects the premium nature of AI server manufacturing compared to traditional consumer electronics.&lt;/p&gt;&lt;p&gt;The impact extends to Taiwan’s broader server ecosystem, with companies securing multi-year production contracts that extend well into 2026, indicating sustained demand and revenue visibility that was rarely seen in the consumer electronics era.&lt;/p&gt;&lt;h3&gt;Strategic implications and future outlook&lt;/h3&gt;&lt;p&gt;“The monthly sales jump for Taiwan ODMs in the first half of 2025 is evidence of this trend,” Robert Cheng, head of Asia technology hardware research at BofA Global Research, told &lt;em&gt;Reuters&lt;/em&gt;, referring to original design manufacturers like Foxconn that contract manufacture products for their clients.&lt;/p&gt;&lt;p&gt;The situation reflects a repositioning of Taiwan in the global technology supply chain. Where companies once competed primarily on cost and manufacturing efficiency for consumer electronics, AI servers require higher levels of technical sophistication, closer collaboration with chip designers, and more stringent quality control.&lt;/p&gt;&lt;p&gt;“We think this shift toward AI servers, whatever form it takes, is good for Taiwan’s tech industry,” Cheng said, noting Taiwanese firms’ ability to shift rapidly to cater to the changing needs of their customers.&lt;/p&gt;&lt;p&gt;However, challenges lie ahead. Taiwan’s current 90% share of the global AI server market may soon decline as manufacturers expand production elsewhere. Companies are already establishing manufacturing facilities in the US, Mexico, and other locations to serve local markets and comply with supply chain requirements.&lt;/p&gt;&lt;h3&gt;Industry-wide transformation&lt;/h3&gt;&lt;p&gt;The AI server boom has catalysed changes that extend beyond individual companies to reshape Taiwan’s entire electronics manufacturing ecosystem. Traditional boundaries between different types of technology products are blurring as manufacturers develop new capabilities and forge closer partnerships with AI chip companies.&lt;/p&gt;&lt;p&gt;The transformation also highlights Taiwan’s unique position in the global technology supply chain. The combination of advanced manufacturing capabilities, established relationships with major technology companies, and proximity to key semiconductor facilities has created a competitive advantage that continues to drive growth.&lt;/p&gt;&lt;p&gt;As artificial intelligence applications continue to need more sophisticated computing infrastructure, Taiwan’s manufacturers appear well-positioned to capitalise on demand. The challenge will be maintaining the country’s technology leadership while adapting to changing geopolitical and market conditions that may require more distributed global operations.&lt;/p&gt;&lt;p&gt;The shift from consumer electronics to AI servers exemplifies Taiwan’s ability to reinvent itself in response to technological change, maintain its central role in the global technology ecosystem, adapt and innovate.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Huawei unveils high-end AI chip for servers alongside MindSpore framework&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/ai-servers-transform-taiwan-manufacturing-giants/</guid><pubDate>Thu, 21 Aug 2025 15:40:45 +0000</pubDate></item><item><title>[NEW] Bank forced to rehire workers after lying about chatbot productivity, union says (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/08/bank-forced-to-rehire-workers-after-lying-about-chatbot-productivity-union-says/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Australia’s biggest bank regrets messy rush to replace staff with chatbots.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="424" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2219273654-640x424.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2219273654-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Bundit Minramun | iStock Editorial / Getty Images Plus

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;As banks around the world prepare to replace many thousands of workers with AI, Australia's biggest bank is scrambling to rehire 45 workers after allegedly lying about chatbots besting staff by handling higher call volumes.&lt;/p&gt;
&lt;p&gt;In a statement Thursday flagged by Bloomberg, Australia's main financial services union, the Finance Sector Union (FSU), claimed a "massive win" for 45 union members whom the Commonwealth Bank of Australia (CBA) had replaced with an AI-powered "voice bot."&lt;/p&gt;
&lt;p&gt;The FSU noted that some of these workers had been with CBA for decades. Those workers in particular were shocked when CBA announced last month that their jobs had become redundant. At that time, CBA claimed that launching the chatbot supposedly "led to a reduction in call volumes" by 2,000 a week, FSU said.&lt;/p&gt;
&lt;p&gt;But "this was an outright lie," fired workers told FSU. Instead, call volumes had been increasing at the time they were dismissed, with CBA supposedly "scrambling"—offering staff overtime and redirecting management to join workers answering phones to keep up.&lt;/p&gt;
&lt;p&gt;To uncover the truth, FSU escalated the dispute to a fair work tribunal, where the union accused CBA of failing to explain how workers' roles were ruled redundant. The union also alleged that CBA was hiring for similar roles in India, Bloomberg noted, which made it appear that CBA had perhaps used the chatbot to cover up a shady pivot to outsource jobs.&lt;/p&gt;
&lt;p&gt;While the dispute was being weighed, CBA admitted that "they didn’t properly consider that an increase in calls" happening while staff was being fired "would continue over a number of months," FSU said.&lt;/p&gt;
&lt;p&gt;"This error meant the roles were not redundant," CBA confirmed at the tribunal.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Bank apologizes, but damage is done&lt;/h2&gt;
&lt;p&gt;Now, CBA has apologized to the fired workers. A spokesperson told Bloomberg that they can choose to come back to their prior roles, seek another position, or leave the firm with an exit payment.&lt;/p&gt;
&lt;p&gt;"We have apologized to the employees concerned and acknowledge we should have been more thorough in our assessment of the roles required," CBA's spokesperson told Bloomberg.&lt;/p&gt;
&lt;p&gt;A Bloomberg Intelligence report from earlier this year estimated that banks globally will slash "as many as 200,000 jobs in the next three to five years" due to expectations that many tasks today will be assigned to AI in the near future. "Back office, middle office, and operations are likely to be most at risk," Bloomberg reported.&lt;/p&gt;
&lt;p&gt;CBA's reversal shows that some banks may be tempted to rush AI initiatives and dismiss workers without thoroughly understanding the potential impacts on their business. But the backtracking hasn't seemed to slow down CBA much. Just last week, it announced a partnership with OpenAI that will "explore advanced generative AI solutions that aim to strengthen scam and fraud detection and deliver more personalized services" for its customers.&lt;/p&gt;
&lt;p&gt;CBA did not suggest that this initiative would lead to further downsizing, claiming the bank's goal is to "invest in our people and their AI proficiency so they can better support our customers" and "embed the responsible use of AI across its workforce."&lt;/p&gt;
&lt;p&gt;Ars could not immediately reach CBA or FSU to confirm how many workers have decided to return.&lt;/p&gt;
&lt;p&gt;But FSU reported that for all 45 workers, "the damage has already been done."&lt;/p&gt;
&lt;p&gt;These employees "have had to endure the stress and worry of facing redundancy" and were "suddenly confronted with the prospect of being unable to pay their bills." FSU warned that CBA's flip-flopping on AI serves as a "stark reminder to all of us that we can never trust employers to do the right thing by workers, and change can happen at any time and impact any one of us."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Australia’s biggest bank regrets messy rush to replace staff with chatbots.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="424" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2219273654-640x424.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2219273654-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Bundit Minramun | iStock Editorial / Getty Images Plus

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;As banks around the world prepare to replace many thousands of workers with AI, Australia's biggest bank is scrambling to rehire 45 workers after allegedly lying about chatbots besting staff by handling higher call volumes.&lt;/p&gt;
&lt;p&gt;In a statement Thursday flagged by Bloomberg, Australia's main financial services union, the Finance Sector Union (FSU), claimed a "massive win" for 45 union members whom the Commonwealth Bank of Australia (CBA) had replaced with an AI-powered "voice bot."&lt;/p&gt;
&lt;p&gt;The FSU noted that some of these workers had been with CBA for decades. Those workers in particular were shocked when CBA announced last month that their jobs had become redundant. At that time, CBA claimed that launching the chatbot supposedly "led to a reduction in call volumes" by 2,000 a week, FSU said.&lt;/p&gt;
&lt;p&gt;But "this was an outright lie," fired workers told FSU. Instead, call volumes had been increasing at the time they were dismissed, with CBA supposedly "scrambling"—offering staff overtime and redirecting management to join workers answering phones to keep up.&lt;/p&gt;
&lt;p&gt;To uncover the truth, FSU escalated the dispute to a fair work tribunal, where the union accused CBA of failing to explain how workers' roles were ruled redundant. The union also alleged that CBA was hiring for similar roles in India, Bloomberg noted, which made it appear that CBA had perhaps used the chatbot to cover up a shady pivot to outsource jobs.&lt;/p&gt;
&lt;p&gt;While the dispute was being weighed, CBA admitted that "they didn’t properly consider that an increase in calls" happening while staff was being fired "would continue over a number of months," FSU said.&lt;/p&gt;
&lt;p&gt;"This error meant the roles were not redundant," CBA confirmed at the tribunal.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Bank apologizes, but damage is done&lt;/h2&gt;
&lt;p&gt;Now, CBA has apologized to the fired workers. A spokesperson told Bloomberg that they can choose to come back to their prior roles, seek another position, or leave the firm with an exit payment.&lt;/p&gt;
&lt;p&gt;"We have apologized to the employees concerned and acknowledge we should have been more thorough in our assessment of the roles required," CBA's spokesperson told Bloomberg.&lt;/p&gt;
&lt;p&gt;A Bloomberg Intelligence report from earlier this year estimated that banks globally will slash "as many as 200,000 jobs in the next three to five years" due to expectations that many tasks today will be assigned to AI in the near future. "Back office, middle office, and operations are likely to be most at risk," Bloomberg reported.&lt;/p&gt;
&lt;p&gt;CBA's reversal shows that some banks may be tempted to rush AI initiatives and dismiss workers without thoroughly understanding the potential impacts on their business. But the backtracking hasn't seemed to slow down CBA much. Just last week, it announced a partnership with OpenAI that will "explore advanced generative AI solutions that aim to strengthen scam and fraud detection and deliver more personalized services" for its customers.&lt;/p&gt;
&lt;p&gt;CBA did not suggest that this initiative would lead to further downsizing, claiming the bank's goal is to "invest in our people and their AI proficiency so they can better support our customers" and "embed the responsible use of AI across its workforce."&lt;/p&gt;
&lt;p&gt;Ars could not immediately reach CBA or FSU to confirm how many workers have decided to return.&lt;/p&gt;
&lt;p&gt;But FSU reported that for all 45 workers, "the damage has already been done."&lt;/p&gt;
&lt;p&gt;These employees "have had to endure the stress and worry of facing redundancy" and were "suddenly confronted with the prospect of being unable to pay their bills." FSU warned that CBA's flip-flopping on AI serves as a "stark reminder to all of us that we can never trust employers to do the right thing by workers, and change can happen at any time and impact any one of us."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/08/bank-forced-to-rehire-workers-after-lying-about-chatbot-productivity-union-says/</guid><pubDate>Thu, 21 Aug 2025 15:49:37 +0000</pubDate></item><item><title>[NEW] Coauthor roundtable: Reflecting on healthcare economics, biomedical research, and medical education (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/podcast/coauthor-roundtable-reflecting-on-healthcare-economics-biomedical-research-and-medical-education/</link><description>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Illustrated headshots of Carey Goldberg, Peter Lee, and Dr. Isaac Kohane." class="wp-image-1148279" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Episode11-Peter-Carey-Isaac_AIRevolution_Hero_Feature_No_Text_1400x788.jpg" width="1400" /&gt;&lt;/figure&gt;






&lt;p&gt;In November 2022, OpenAI’s ChatGPT kick-started a new era in AI. This was followed less than a half year later by the release of GPT-4. In the months leading up to GPT-4’s public release, Peter Lee, president of Microsoft Research, cowrote a book full of optimism for the potential of advanced AI models to transform the world of healthcare. What has happened since? In this special podcast series, &lt;em&gt;The AI Revolution in Medicine, Revisited&lt;/em&gt;, Lee revisits the book, exploring how patients, providers, and other medical professionals are experiencing and using generative AI today while examining what he and his coauthors got right—and what they didn’t foresee.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In this series finale, Lee welcomes back coauthors Carey Goldberg&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; and Dr. Zak Kohane&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; to discuss how their predictions stack up against key takeaways from guests in the second half of the series: experts on AI’s economic and societal impact; technologists on the cutting edge; leaders in AI-driven medicine; next-generation physicians; and heads of healthcare organizations. Lee, Goldberg, and Kohane explore thinking innovatively about existing healthcare processes, including the structure of care teams and the role of specialties, to take advantage of AI opportunities and consider what clinicians and patients might need these new AI tools to be to feel empowered when it comes to giving and receiving the best healthcare. They close the episode with their hopes for the future of AI in health.&lt;/p&gt;



&lt;div class="wp-block-group msr-pattern-link-list is-layout-flow wp-block-group-is-layout-flow"&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;



&lt;h2 class="wp-block-heading h5" id="learn-more-1"&gt;Learn more:&lt;/h2&gt;








&lt;/div&gt;



&lt;section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast"&gt;
	
&lt;/section&gt;


&lt;div class="wp-block-msr-show-more"&gt;
	&lt;div class="bg-neutral-100 p-5"&gt;
		&lt;div class="show-more-show-less"&gt;
			&lt;div&gt;
				&lt;span&gt;
					

&lt;h2 class="wp-block-heading" id="transcript"&gt;Transcript&lt;/h2&gt;



&lt;p&gt;[MUSIC] &lt;/p&gt;



&lt;p&gt;[BOOK PASSAGE]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;PETER LEE: &lt;/strong&gt;“As a society—indeed, as a species—we have a choice to make. Do we constrain or even kill artificial intelligence out of fear of its risks and obvious ability to create new harms? Do we submit ourselves to Al and allow it to freely replace us, make us less useful and less needed? Or do we start, today, shaping our Al future together, with the aspiration to accomplish things that humans alone, and Al alone, can’t do but that humans+Al can? The choice is in our hands … .”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[END OF BOOK PASSAGE]&lt;/p&gt;



&lt;p&gt;[THEME MUSIC]&lt;/p&gt;



&lt;p&gt;This is &lt;em&gt;The AI Revolution in Medicine, Revisited&lt;/em&gt;. I’m your host, Peter Lee. &lt;/p&gt;



&lt;p&gt;Shortly after OpenAI’s GPT-4 was publicly released, Carey Goldberg, Dr. Zak Kohane, and I published &lt;em&gt;The AI Revolution in Medicine &lt;/em&gt;to help educate the world of healthcare and medical research about the transformative impact this new generative AI technology could have. But because we wrote the book when GPT-4 was still a secret, we had to speculate. Now, two years later, what did we get right, and what did we get wrong? &lt;/p&gt;



&lt;p&gt;In this series, we’ll talk to clinicians, patients, hospital administrators, and others to understand the reality of AI in the field and where we go from here. &lt;/p&gt;



				&lt;/span&gt;
				&lt;span class="show-more-show-less-toggleable-content" id="show-more-show-less-toggle-1"&gt;
					



&lt;p&gt;[THEME MUSIC FADES]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The book passage I read at the top is from the epilogue, and I think it’s a truly fitting closing sentiment for the conclusion of this podcast series—because it calls back to the very beginning.&lt;/p&gt;



&lt;p&gt;As I’ve mentioned before, Carey, Zak, and I wrote &lt;em&gt;The AI Revolution in Medicine&lt;/em&gt; as a guide to help answer these big questions, particularly as they pertain to medicine. You know, we wrote the book to empower people to make a choice about AI’s development and use. Well, have they? Have &lt;em&gt;we&lt;/em&gt;?&lt;/p&gt;



&lt;p&gt;Perhaps we’ll need more time to tell. But over the course of this podcast series, I’ve had the honor of speaking with folks from across the healthcare ecosystem. And my takeaway? They’re all committed to shaping AI into a tool that can improve the industry for practitioners and patients alike.&lt;/p&gt;



&lt;p&gt;In this final episode, I’m thrilled to welcome back my coauthors, Carey Goldberg and Dr. Zak Kohane. We’ll examine the insights from the second half of the season.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Carey, Zak—it’s really great to have you here again!&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CAREY&lt;/strong&gt; &lt;strong&gt;GOLDBERG: &lt;/strong&gt;Hey, Peter!&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ZAK&lt;/strong&gt; &lt;strong&gt;KOHANE:&lt;/strong&gt; Hi, Peter.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So this is the second roundtable. And just to recap, you know, we had several early episodes of the podcast where we talked to some doctors, some technology developers, some people who think about regulation and public policy, patient advocates, a venture capitalist who invests in, kind of, consumer and patient-facing medical ventures, and some bioethicists.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I think we had a great conversation there. I think, you know, it felt mostly validating. A lot of the things that we predicted might happen happened, and then we learned a lot of new things. But now we have five more episodes, and the mix of kinds of people that we talk to here is different than the original.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I thought it would be great for us to have a conversation and recap what we think we heard from all of them. So let’s just start at the top.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So in this first episode in the second half of this podcast series, we talked to economists Azeem Azhar and Ethan Mollick. And I thought those conversations were really interesting. Maybe there were, kind of, two things, two main topics. One was just the broader impact on the economy, on the cost of healthcare, on overall workforce issues.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;One of the things that I thought was really interesting was something that Ethan Mollick brought up. And maybe just to refresh our memories, let’s play this little clip from Ethan.&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-ab782358e1fff73901dd881b85e04b33"&gt;&lt;strong&gt;&lt;em&gt;ETHAN MOLLICK: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;So&lt;/em&gt;&lt;strong&gt;&lt;em&gt; &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;we’re in this really interesting period where there’s incredible amounts of individual innovation in productivity and performance improvements in this field, like very high levels of it. …&lt;/em&gt;&lt;em&gt; &lt;/em&gt;&lt;em&gt;We’re seeing that in nonmedical problems, the same kind of thing, which is, you know, we’ve got research showing 20 and 40% performance improvements. … But then the organization doesn’t capture it; the system doesn’t capture it. Because the individuals are doing their own work, and the systems don’t have the ability to, kind of, learn or adapt as a result.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So let me start with you, Zak. Does that make sense to you? Are you seeing something similar?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I thought it was incredibly insightful because we discussed on our earlier podcast how a chief AI officer in one of the healthcare hospitals, in one of the healthcare systems, was highly regulating the use of AI, but yet in her own practice on her smartphone was using all these AI technologies.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so it’s insightful that on the one hand, she is increasing her personal productivity, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; … and perhaps she’s increasing her quality of her care. But it’s very hard for the healthcare system to actually realize any gains. It’s unlikely … let’s put it this way. It would be for her a defeat if they said, “Now you should see &lt;em&gt;more&lt;/em&gt; patients.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes. [LAUGHS]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Now, I’m not saying that won’t happen. It could happen. But, you know, gains of productivity are really at the individual level of the doctors. And that’s why they’re adopting it. That’s why the ambient dictation tools are so successful. But really turning it into things that matter in terms of productivity for healthcare, namely making sure that patients are getting healthy, requires that every piece of the puzzle works well together. You know, it’s well-tread ground to talk about how patients get very expensive procedures, like a cardiac transplant, and then go home, and they’re not put on blood thinners …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; … and then they get a stroke. You know, the chain is as strong as the weakest link. And just having AI in one part of it is not going to do it. And so hospitals, I think, are doubly burdened by the fact that, (A) they tend to not like innovation because they are high-revenue, low-margin companies. But if they want it implemented effectively, they have to do it across the entire processes of healthcare, which are vast and not completely under their control.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. Yep. You know, that was Sara Murray, who’s the chief health AI officer at UC San Francisco.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then, you know, Carey, remember, we were puzzled by Chris Longhurst’s finding in a controlled study that the, you know, having an AI respond to patient emails didn’t seem to lead to any, I guess you would call it, &lt;em&gt;productivity benefits&lt;/em&gt;. I remember we were both kind of puzzled by that. I wonder if that’s related to what Ethan is saying here.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG:&lt;/strong&gt; I mean, possibly, but I think we’ve seen since then that there have been multiple studies showing that in fact using AI can be extremely effective or helpful, even, for example, for diagnosis.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I find just from the patient point of view, it kind of drives me crazy that you have individual physicians using AI because they know that it will improve the care that they’re offering. And yet you don’t have their institutions kind of stepping up and saying, “OK, these are the new norms.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;By the way, Ethan Mollick is a national treasure, right. Like, he is the classic example of someone who just stepped up at this moment …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;… when we saw this extraordinary technological advance. And he’s not only stepping up for himself. He’s spreading the word to the masses that this is what these things can do.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so it’s frustrating to see the institutions not stepping up and instead the individual doctors having to do it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; But he made another very interesting point, which was that the reason that &lt;em&gt;he&lt;/em&gt; could be so informative to not only the public but practitioners of AI is these things would emerge out of the shop, and they would not be aged too long, like a fine wine, before they were just released to the public.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so he was getting exposure to these models just weeks after some of the progenitors had first seen it. And therefore, because he’s actually a really creative person in terms of how he exercises models, he sees uses and problems very early on. But the point is institutions, think about how much they are disadvantaged. They’re not Ethan Mollick. They’re not the progenitors. So they’re even further behind. So it’s very hard. If you talk to most of the C-suite of hospitals, they’d be delighted to know as much about the impact as Ethan Mollick.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. By the way, you know, I picked out this quote because within Microsoft, and I suspect every other software company, we’re seeing something very similar, where individual programmers are 20 to 30% more productive just in the number of lines of code they write per day or the number of pull requests per week. Any way you measure it, it’s very consistent. And yet by the time you get to, say, a 25-person software engineering team, the productivity of that whole team isn’t 25% more productive.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now, that &lt;em&gt;is&lt;/em&gt; starting to change because we’re starting to figure out that, well, maybe we should reshape how the team operates. And there’s more of an orientation towards having, you know, smaller teams of full-stack developers. And then you start to see the gains. But if you just keep the team organized in the usual way, there seems to be a loss. So there’s something about what Ethan was saying that resonated very strongly with me.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;But I would argue that it’s not just productivity we’re talking about. There’s a moral imperative to improve the care. And if you have tools that will do that, you should be using them or trying harder to.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right. Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I think, yes, first of all, absolutely you would. Unfortunately, most of the short-term productivity measures will not measure improvements in the quality of care because it takes a long time to die even with bad care.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so that doesn’t show up right away. But I think what Peter just said actually came across in several of the podcasts, which is that it’s very tricky trying to shoehorn these things into making what we’re already doing more productive.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah. Existing structures.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Yeah. And I know, Carey, that you’ve raised this issue many times. But it really calls into question, what should we be doing with our time with doctors? And they are a scarce resource. And what is the most efficient way to use them?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You know, I remember we [&lt;em&gt;The New England Journal of Medicine AI&lt;/em&gt;] published a paper of someone who was able to use AI to increase the throughput of their emergency room&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; by actually more appropriately having the truly sick people in the sick queue, in the triage queue, for urgent care.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I think we’re going to have to think that way more broadly, about we don’t have to now look at every patient as an unknown with maybe a few pointers on diagnosis. We can have a fairly extensive profiling.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I know that colleagues in Clalit [Health Services] in Israel, for example, are using the overall trajectory of the patient and some considerations about utilities to actually figure out who to see next week.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, you know, what you said brings up another maybe connection to one thing that we see also in software development. And it relates to also what we were discussing earlier: about the last thing a doctor wants is to have a tool that allows them to see even yet more patients per day.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So in software development, there’s always this tension. Like, how many lines of code can you write per day? That’s one productivity measure.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But sometimes we’re taught, well, don’t write more lines of code per day, but make sure that your code is well structured. Take the time to document it. Make sure it’s fully commented. Take the time to talk to your fellow software engineering team members to make sure that it’s well coordinated. And in the long run, even if you’re writing half the number of lines of code per day, the software process will be far more efficient.&lt;/p&gt;



&lt;p&gt;And so I’ve wondered whether there’s a similar thing where doctors could see 20% fewer patients in a day, but if they take the time and also had AI help to coordinate, maybe a patient’s journey might be half as long. And therefore, the health system would be able to see twice as many patients in a year’s period or something like that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; So I think you’ve “nerd sniped” me because you [LAUGHTER]—which is all too easy—but I think there’s a central issue here. And I think this is the stumbling block between what Ethan’s telling us about between the individual productivity and the larger productivity, is the &lt;em&gt;team’s&lt;/em&gt; productivity.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And there is actually a good analogy in computer science and that’s, uh, Brooks’s “mythical man-month,” …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes, exactly.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; … where he shows how you can have more and more resources, but when the coordination starts failing, because you have so many, uh, individuals on the team, you start falling apart. And so even if the, uh, individual doctors get that much better, yeah, they take better care of patients, make less stupid things.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But in terms of giving the “I get you into the emergency room, and I get you out of a hospital as fast as possible, as safely as possible, as effectively as possible,” that’s teamwork. And we don’t do it. And we’re not really optimizing our tools for that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;And just to throw in a little reality check, I’m not aware of &lt;em&gt;any&lt;/em&gt; indication yet that AI is in any way shortening medical journeys or making physicians more efficient. Yet …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG:&lt;/strong&gt; …&lt;strong&gt; &lt;/strong&gt;at least. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes. So I think, you know, with respect to our book, critiquing our book, you know, I think it’s fair to say we were fairly focused or maybe even fixated on the individual doctor or nurse or patient, and we didn’t really, at least I never had a time where I stepped back to think about the whole care coordination team or the whole health system.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;And I think that’s right. It’s because, first of all, &lt;em&gt;you&lt;/em&gt; weren’t thinking about it? It’s not what we’re taught in medical school. We’re not taught to talk about team communication excellence. And I think it’s absolutely essential.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There’s a … what’s the … there was an early … [Terry] Winograd. And he was trying to capture what are the different kinds of actions related to pronouncements that you could expect and how could AI use that. And that was beginning to get at it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I actually think this is dark matter of human organizational technology that is not well understood. And our products don’t do well. You know, we can talk about all the groupware things that are out there. But they all don’t quite get to that thing.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; And I can imagine an AI serving as a team leader, a really active team leader, a real quarterback of, let’s say, a care team.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Well, in fact, you know, we have been trying to experiment with this. My colleague, Matt Lungren, who was also one of the interviewees early on, has been working with Stanford Medicine on a tumor board AI agent—something that would facilitate tumor board meetings.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And the early experiences are pretty interesting. Whether it relates to efficiency or productivity I think remains to be seen, but it does seem pretty interesting.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But let’s move on.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Well, actually, Peter, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Oh, go ahead.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;…&lt;strong&gt; &lt;/strong&gt;if you’re willing to not quite move on yet …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; [LAUGHS] All right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;… this kind of segues into one of, I think, the most provocative questions that arose in the course of these episodes and that I’d love to have you answer, which was, remember, it was a question at a gathering that you were at, and you were asked, “Well, you’re focusing a lot on potential AI effects on individual patient and physician experiences. But what about the revolution, right? What about, like, can you be more big-picture and envision how generative AI could actually, kind of, overturn or fix the broken system, right?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I’m sure you’ve thought about that a lot. Like, what’s your answer?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You know, I think ultimately, it will have to. For it to really make a difference, I think that the normal processes, our normal concept of how healthcare is delivered—how new medical discoveries are made and brought into practice—I think those things are going to have to change a lot.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You know, one of the things I think about a lot right at the moment is, you know, we tend to think about, let’s say, medical diagnosis as a problem-solving exercise. And I think, at least at the Kaiser Permanente School of Medicine, the instruction really treats it as a kind of detective thing based on a lot of knowledge about biology and biomedicine and human condition, and so on.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But there’s another way to think about it, given AI, which is when you see a patient and you develop some data, maybe through a physical exam, labs, and so on, you can just simply ask, “You know, what did the 500 other people who are most similar to this experience, how were they diagnosed? How were they treated? What were their outcomes? What were their experiences?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And that’s really a fundamentally different paradigm. And it just seems like at least the technical means will be there. And by the way, that also then relates to [the questions]: “And what was most efficacious cost-wise? What was most efficient in terms of the total length of the patient journey? How does this relate to my quality scores so I can get more money from Medicare and Medicaid?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;All of those things, I think, you know, we’re starting to confront.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;One of the other episodes that we’re going to talk about, was my interview with two medical students. Actually, thinking of a Morgan Cheatham as just a medical student or medical resident [LAUGHTER] is a little strange. But he is.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;One of the things he talks about is the importance that he placed in his medical training about adopting AI. So, Zak, I assume you see this also with some students at Harvard Medical School. And the other medical student we interviewed, Daniel Chen, seemed to indicate this, too, where it seems like it’s the students who are bringing AI into the medical education ahead of the faculty. Does that resonate with you?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; It absolutely resonates with me. There are students I run into who, honestly, my first thought when I’m talking to them is, why am I teaching you [LAUGHTER], and why are you not starting a big AI company, AI medicine company, now and really change healthcare instead of going through the rest of the rigmarole? And I think broadly, higher education has a problem there, which is we have not embraced, again, going back to Ethan, a lot of the tools that can be used. And it’s because we don’t know necessarily the right way to teach them. And so far, the only lasting heuristic seems to be: use them and use them often.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so it’s an awkward thing, where the person who knows how to use the AI tools now in the first-year medical school can teach themselves better and faster than anybody else in their class who is just relying on the medical school curriculum.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Now, the reason I brought up Morgan now after our discussion with Ethan Mollick is Morgan also talked about AI collapsing medical specialties.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; And so let’s hear this snippet from him.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-df1ec79bf2184e924d149dd5a8bfd566"&gt;&lt;strong&gt;&lt;em&gt;MORGAN CHEATHAM:&lt;/em&gt;&lt;/strong&gt;&lt;em&gt; AI collapses medical specialties onto themselves, right. You have the canonical example of the cardiologist, you know, arguing that we should diuresis and maybe the nephrologist arguing that we should, you know, protect the kidneys. And how do two disciplines disagree on what is right for the patient when in theory, there is an objective best answer given that patient’s clinical status? … So I’m interested in this question of whether medical specialties themselves need to evolve. And if we look back in the history of medical technology, there are many times where a new technology forced a medical specialty to evolve.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So on the specific question about specialties, Zak, do you have a point of view? And let me admit, first of all, for us, all three of us, we didn’t have any clue about this in our book. I don’t think.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Not much. Not much of a clue.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I’m reminded of a &lt;em&gt;New Yorker&lt;/em&gt; cartoon where you see a bunch of surgeons around the patient, and someone says, “Is that a spleen?” And it says, “I don’t know. I slept during the spleen lecture,” [LAUGHTER] and … or “I didn’t take the spleen course.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And yet when we measure things, we measure things much more than we think we are doing. So for example, we [&lt;em&gt;NEJM AI&lt;/em&gt;] just published a paper where echocardiograms were being done. And it turns out those ultrasound waves just happen to also permeate the liver. And you can actually diagnose on the way with AI all the liver disease&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; that is in—and treatable liver disease—that’s in those patients.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But if you’re a cardiologist, “Liver? You know, I slept through liver lecture.” [LAUGHTER] And so I do think that, (A) the natural, often guild/dollar-driven silos in medicine are less obvious to AI, despite the fact that they do exist in departments and often in chapters.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But Morgan’s absolutely right. I can tell you as an endocrinologist, if I have a child in the ICU, the endocrinologist, the nephrologist, and the neurosurgeon will argue about the right thing to do.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so in my mind, the truly revolutionary thing to do is to go back to 1994 with Pete Szolovits, the Guardian Angel Project&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. What I think you need is a process. And the process is the quarterback. And the quarterback has only one job: take care of the patient.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And it should be thinking all the time about the patient. What’s the right thing? And can be as school-marmish or not about, “Zak, you’re eating this or that or exercise or sleep,” but also, “Hey, surgeons and endocrinologists, you’re talking about my host, Zak. This is the right way because this problem and this problem and our best evidence is this is the right way to get rid of the fluid. The other ways will kill him.”&lt;/p&gt;



&lt;p&gt;And I think you need an authoritative quarterback that has the view of the others but then makes the calls.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Is that quarterback going to be AI or human?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Well, for the very lucky people, it’ll be a human augmented by AI, &lt;em&gt;super concierge&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I think we’re running out of doctors. And so realistically, it’s going to be an AI that will have to be certified in very different ways, along the ways Dave Blumenthal says, essentially, trial by fire. Like putting residents into clinics, we’re going to be putting AIs into clinics.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But what’s worse, by the way, than the three doctors arguing about care in front of the patient is, what happens so frequently, is then you see them outpatient, and each one of them gives you a different set of decisions to make. Sometimes that actually interact pathologically, unhealthily with each other. And only the very smart nurses or primary care physicians will actually notice that and call, quote, a “family meeting,” or bring everybody in the same room to align them.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah, I think this idea of quarterback is really very, very topical right now because there’s so much intensity in the AI space around agents. And in fact, you know, the Microsoft AI team under Mustafa Suleyman and Dominic King, Harsha Nori, and team just recently posted a paper on something called sequential diagnosis, which is basically an AI quarterback that is supposed to smartly consult with other AI specialties. And interestingly, one of the AI agents is sort of the devil’s advocate that’s always criticizing and questioning things.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;That’s interesting.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; And at least on very, very hard, rare cases, it can develop some impressive results. There’s something to this that I think is emerging.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;And, Peter, Morgan said something that blew me away even more, which was, well, why do we even need specialists if the reason for a specialist is because there’s so much medical knowledge that no single physician can know all of it, and therefore we create specialists, but that limitation does not exist for AI.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;And so there he was kind of undermining this whole elaborate structure that has grown up because of human limitations that may not ultimately need to be there.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right. So now that gives me a good segue to get back to our economist and get to something that Azeem Azhar said. And so there’s a clip here from Azeem.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-6ff46028707e465b3cd8582210840bd0"&gt;&lt;strong&gt;&lt;em&gt;AZEEM AZHAR: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;We didn’t talk about, you know, AI in its ability to potentially do this, which is to extend the clinician’s presence throughout the week. &lt;em&gt;You know, t&lt;/em&gt;he idea that maybe some part of what the clinician would do if you could talk to them on Wednesday, Thursday, and Friday could be delivered through an app or a chatbot just as a way of encouraging the compliance, which is often, especially with older patients, one reason why conditions, you know, linger on for longer.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; And, you know, in the same conversation, he also talked about his own management of asthma and the fact that he’s been managing this for several decades and knows more than any other human being, no matter how well medically trained, could possibly know. And it’s also very highly personalized. And it’s not a big leap to imagine AI having that sort of lifelong understanding.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; So in fact, I want to give credit back to our book since you insulted us. [LAUGHTER] You challenged us. You doubted us. We do have at the end of the book a AI which is helping this woman manage her way through life. It’s quarterbacking for the woman all these different services.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; So there.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Ah, you’re right. Yes. In fact, it’s very much, I think, along the lines of the vision that Azeem laid out in our conversation.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah. It also reminded me of the piece Zak wrote about his mother&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; at one point when she was managing congestive heart failure and she needed to watch her weight very carefully to see her fluid status. And absolutely, there’s no … I see no reason whatsoever why that couldn’t be done with AI right now. Actually, although back then, Zak, you were writing that it takes much more than an AI [LAUGHS] to manage such a thing, right?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; You need an AI that you can trust. Now, my mother was born in 1927, and she’d learned through the school of hard knocks that you can’t trust too many people, maybe even not your son, &lt;em&gt;MD&lt;/em&gt;, &lt;em&gt;PhD&lt;/em&gt; [LAUGHTER].&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But what I’ve been surprised [by] is how, for example, how many people are willing to trust and actually see effective use of AI as mental health counselors, for example.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; So it may in fact be that there’s a generational thing going on, and at least there’ll be some very large subset of patients which will be completely comfortable in ways that my mother would have never tolerated.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. Now, I think we’re starting to veer into some of the core AI.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I think maybe one of the most fun conversations I had was in the episode with both Sébastien Bubeck, my former colleague at Microsoft Research, and now he’s at OpenAI, and Bill Gates. And there was so much that was, I thought, interesting there. And there was one point, I think that sort of touches tangentially on what we were just conversing about, that Sébastien said. So let’s hear this snippet.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-19a223099867a12ed2599ae811939b43"&gt;&lt;strong&gt;&lt;em&gt;SÉBASTIEN BUBECK: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;And one example that I really like, a study that recently appeared where … they were comparing doctors without and with ChatGPT. … So this was a set of cases where the accuracy of the doctors alone was around 75%. ChatGPT alone was 90%. … But then the kicker is that doctors with ChatGPT was 80%. Intelligence alone is not enough. It’s also how it’s presented, how you interact with it. And ChatGPT, it’s an amazing tool. Obviously, I absolutely love it. But it’s not … you don’t want a doctor to have to type in, you know, prompts and use it that way. It should be, as Bill was saying, kind of running continuously in the background, sending you notifications.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So I thought Sébastien was saying something really profound, but I haven’t been able to quite decide or settle in my mind what it is. What do you make of what Seb just said?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I think it’s context. I think that it requires an enormous amount of energy, brain energy, to actually correctly provide the context that you want this thing to work on. And it’s only going to really feel like we’re in a different playing field when it’s listening all the time, and it just steps right in.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There is an advantage that, for example, a good programmer can have in prompting Cursor or any of these tools to do so. But it takes effort. And I think being in the conversation all the time so that you understand the context in the widest possible way is incredibly important. And I think that’s what Seb is getting at, which is if we spoon feed these machines, yes, 90%.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But then, talking to a human being who then has to interact and gets distracted from whatever flow they’re in and maybe even makes them feel like an early bicycle rider who all of a sudden realizes, “I’m balancing on two wheels—oh no!” And they fall over. You know, there’s that interaction which is negatively synergistic.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I do think it’s a very hard human-computer engineering problem. How do we make these two agents, human and computational, work in an ongoing way in the flow? I don’t think I’m seeing anything that’s particularly new. And the things that you’re beginning to hint about, Peter, in terms of agentic coordination, I think we’ll get to some of that. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. Carey, does this give you any pause? The kind of results that … they’re puzzling results. I mean, the idea of doctors with AI seeming at least in this one test—it’s just one test—but it’s odd that it does worse than the AI alone.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yes. I would want to understand more about the actual conditions of that study.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;From what Bill Gates said, I was most struck by the question of resource-poor environments. That even though this was absolutely one of the most promising, brightest perspectives that we highlighted in the book, we still don’t seem to be seeing a lot of use among the one half of humanity that lacks decent access to healthcare.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I mean, there are access problems everywhere, including here in the United States. And it is one of the most potentially promising uses of AI. And I thought if anyone would know about it, he would with the work that the Gates Foundation does.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;You know, I think both you and Bill, I felt, are really simpatico. You know, Bill expressed genuine surprise that more isn’t happening yet. And it really echoed, in fact, maybe even using some of the exact same words that you’ve used. And so two years on, you’ve expressed repeatedly expecting to have seen more out in the field by now. And then I thought Bill was saying something in our conversation very similar.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;You know, for me, I see it both ways. I see the world of medicine really moving fast in confronting the reality of AI in such a serious way. But at the same time, it’s also hard to escape the feeling that somehow, we should be seeing even more.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So it’s an odd thing, a little bit paradoxical.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah. I think one thing that we didn’t focus on hardly at all in the book but that we are seeing is these companies rising up, stepping up to the challenge, Abridge and OpenEvidence, and what Morgan describes as a new stack, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So there is that on the flip side.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Now, I want to get back to this thing that Seb was saying. And, you know, I had to bring up the issue of sycophancy, which we discussed at our last roundtable also. But it was particularly … at the time that Seb, Bill, and I had our conversation, OpenAI had just gone through having to retract a fresh update of GPT-4o because it had become too sycophantic.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I can’t escape the feeling that some of these human-computer interaction issues are related to this tension between you want AI to follow your directions and be faithful to you, but at the same time not agree with you so often that it becomes a fault.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I think it’s asking the AI to enter into a fundamental human conundrum, which is there are extreme versions of doublethink, and there’s everyday things, everyday asks of doublethink, which is how to be an effective citizen.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And even if you’re thinking, “Hmm. I’m thinking this. I’m just not going to say it because that would be rude or counterproductive.” Or some of the official doublethinks, where you’re actually told you must say this, even if you think something else. And I think we’re giving a very tough mission for these things: be nice to the user and be useful.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And, in education, where the thing is not always one in the same. Sometimes you have to give a little tough love to educate someone, and doing that well is both an art and it’s also very difficult. And so, you know, I’m willing to believe that the latest frontier models that have made the news in the last month are very high-performing, but they’re also all highlighting that tension …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;… that tension between behaving like a good citizen and being helpful. And this gets back to what are the fundamental values that we hope these things are following.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It’s not, you know, “Are these things going to develop us into the paperclip factory?” It’s more of, “Which of our values are going to be elevated, and which one will be suppressed?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Well, since I criticized our book before, let me pat ourselves on the back this time because, I think, pervasive throughout our book, we were touching on some of these issues.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In fact, we started the book, you know, with GPT-4 scolding me for wanting it to impersonate Zak. And there was the whole example of asking it to rewrite a poem in a certain way, and it kind of silently just tried to slide, you know, without me knowing, slide by without following through on the whole thing.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so that early version of GPT-4 was definitely not sycophantic at all. In fact, it was just as prone to call you an idiot if it thought you were wrong. [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I had some very testy conversations around my endocrine diagnosis with it. [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah. Well then, Peter, I would ask you, I mean last time I asked you about, &lt;em&gt;well, hallucinations, aren’t those solvable?&lt;/em&gt; And this time I would ask you, well, sycophancy, isn’t that kind of like a dial you can turn? Like, is that not solvable?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;You know, I think there are several interlocking problems. But if we assume superintelligence, even with superintelligence, medicine is such an inexact science that there will always be situations that are guesses that take into account other factors of a person’s life, other value judgments, exactly as Zak had pointed out in our previous roundtable conversation.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I think there’s always going to be an opening for either differences of opinion or agreeing with you too much. And there are dangers in both cases. And I think they’ll always be present. I don’t know that, at least in something as inexact as medical science, I don’t know that it’ll ever be completely eliminated.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;And it’s interesting because I was trying to think what’s the right balance, but there are patients who want to be told this is what you do. Whereas there’s other patients who want to go through every detail of the reasoning.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And it’s not a matter of education. It’s really a temperamental, personality issue. And so we’re going to &lt;em&gt;have to&lt;/em&gt;, I think, develop personalities …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;… that are most effective for those different kinds of individuals. And so I think that is going to be the real frontier. Having human values and behaving in ways that are recognizable and yet effective for certain groups of patients.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;And lots of deep questions, including how paternalistic do we want to be?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;All right, so we’re getting into medical science and hallucination. So that gives me a great segue to the conversations in the episode on biomedical research. And one of the people that I interviewed was Noubar Afeyan from Moderna and Flagship Pioneering. So let’s listen to this snippet.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-574184a033e6f29ff2ba40f7e611b28a"&gt;&lt;strong&gt;&lt;em&gt;NOUBAR AFEYAN:&lt;/em&gt;&lt;/strong&gt;&lt;em&gt; We, some hundred or so times a year, ask “what if” questions that lead us to totally weird places of thought. We then try to iterate, iterate, iterate to come up with something that’s testable. Then we go into a lab, and we test it. So in that world, right, sitting there going, like, “How do I know this transformer is going to work?” The answer is, “For what?” Like, it’s going to work to make something up … well, guess what? We knew early on with LLMs that hallucination was a feature, not a bug for what we wanted to do.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;[LAUGHS] So I think that really touches on just the fact that there’s so many unknowns and such lack of precision and exactness in our understanding of human biology and of medicine. Carey, what do you think?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;I mean, I just have this emotional reaction, which is that I love the idea of AI marching into biomedical science and everything from getting to the virtual cell eventually to, Zak, I think it was a colleague of yours who recently published about … it was a new medication that had been sort of discovered by AI&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, and it was actually testing out up to the phase II level or something, right?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Oh, this is Marinka’s work.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah, Marinka, Marinka Zitnik. And … yeah. So, I mean, I think it avoids a lot of the, sort of, dilemmas that are involved with safety and so on with AI coming into medicine. And it’s just the discovery process, which we all want to advance as quickly as possible. And it seems like it actually has a great deal of potential that’s already starting to be realized.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Oh, absolutely.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I love this topic. First of all, I thought, actually, I think Bill and Seb, actually, had interesting things to say on that very topic, rationales which I had not really considered why, in fact, things might progress faster in the discovery space than in the clinical delivery space, just because we don’t know in clinical medicine what we’re trying to maximize precisely. Whereas for a drug effect, we do know what we’re trying to maximize.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Well, in fact, I happened to save that snippet from Bill Gates saying that. So let’s cue that up.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-6ca7a5edfbf41028162616b68d8380d1"&gt;&lt;strong&gt;&lt;em&gt;BILL GATES: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;I think it’s very much within the realm of possibility that the AI is not only accelerating healthcare discovery but substituting for a lot of the roles of, you know, “I’m an organic chemist,” or “I run various types of assays.” I can see those, which are, you know, testable-output-type jobs but with still very high value, I can see, you know, some replacement in those areas before the doctor.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So, Zak, isn’t that Bill saying exactly what you’re saying?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; That is my point. I have to say that this is another great bet, that either we’re all going to be surprised or a large group of people will be surprised or disappointed.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There’s still a lot of people in the sort of medicinal chemist, trialist space who are still extremely skeptical that this is going to work. And we haven’t quite shown them yet that it is. Why have we not shown them? Because we haven’t gone all the way to a phase III study, which showed that the drug behaves as expected to, is effective, and basically doesn’t hurt people. That turns out to require a lot of knowledge. I actually think we’re getting there, but I understand the skepticism.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Carey, what are your thoughts?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah. I mean, there will be no way around going through full-on clinical trials for anything to ever reach the market. But at the same time, you know, it’s clearly very promising. And just to throw out something for the pure fun of it, Peter, I saw … one of my favorite tweets recently was somebody saying, you know, isn’t it funny how computer science is actually becoming a lot more like biology in that it’s just becoming empirical.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It’s like you just throw stuff at the AI and see what it does. [LAUGHTER] And I was like,&lt;em&gt; oh, yeah, that’s what Peter was doing when we wrote the book.&lt;/em&gt; I mean, he understood as many innards as anybody can. But at the same time, it was a totally empirical exercise in seeing what this thing would do when you threw things at it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;So it’s the new biology.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Well, yeah. So I think we talked in our book about accelerating, you know, biomedical knowledge and medical science. And that actually seems to be happening. And I really had fun talking to Daphne Koller about some of the accomplishments that she’s made. And so here’s a little snippet from Daphne.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-b519fe67233d03b2946f95df076d6451"&gt;&lt;strong&gt;&lt;em&gt;DAPHNE KOLLER: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;This will impact not only the early stages of which hypotheses we interrogate, which molecules we move forward, but also hopefully at the end of the day, which molecule we prescribe to which patient. And I think there’s been obviously so much narrative over the years about precision medicine, personalized medicine, and very little of that has come to fruition, with the exception of, you know, certain islands in oncology, primarily on genetically driven cancers.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So, Zak, when I was listening to that, I was reminded of one of the very first examples that you had where, you know, you had a very rare case of a patient, and you’re having to narrow down some pretty complex and very rare genetic conditions. This thing that Daphne says, that seems to be the logical conclusion that everyone who’s thinking hard about AI and biology is coming to. Does it seem more real now two years on?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; It absolutely seems more real. Here’s some sad facts. If you are at a cancer center, you will get targeted therapies if you qualify for it. Outside cancer centers, you won’t. And it’s not that the therapies aren’t available. It’s just that you won’t have people thinking about it in that way. And especially if you have some of the rare and more aggressive cancers, if you’re outside one of those cancer centers, you’re at a significant disadvantage for survival for that reason. And so anything that provides just the “simple,” in quotes, dogged investigation of the targeted therapies for patients, it’s a home run.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So my late graduate student, Atul Butte, died recently at UCSF, where he was both a professor and the leader of the Bakar Institute, and he was a Zuckerberg Chan Professor of Pediatrics.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;He was diagnosed with a rare tumor two years ago. His wife is a PhD biologist, and when he was first diagnosed, she sent me the diagnosis and the mutations. And I don’t know if you know this, Peter, but this was still when we were writing the book and people didn’t know about GPT-4.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I put in those mutations into GPT-4 and the diagnosis. And I said, “I’d like to help treat my friend. What’s the right treatment?” And GPT, to paraphrase, GPT-4 said, “Before we start talking about treatment, are you sure this is the right diagnosis? Those mutations are not characteristic for that tumor.” And he had been misdiagnosed. And then they changed the diagnosis therapy and some personnel.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I don’t have to hallucinate this. It’s already happened, and we’re going to need this. And so I think targeted therapy for cancers is the most obvious use. And if God forbid one of you has a family member who has cancer, it’s moral malpractice not to look at the genetics and run it past GPT-4 and say, “What are the available therapies?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I really deeply believe that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Carey, I think one thing you’ve always said is that you’re surprised that we don’t hear more stories along these lines. And I think you threw a quote from Mustafa Suleyman back at me. Do you want to share that?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yes. Recently, I believe it was a Big Technology interview&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, and the reporter asked Mustafa Suleyman, “So you guys are seeing 50 million queries, medical queries, a day [to Copilot and Bing]. You know, how’s that going?” And I think I am a bit surprised that we’re not seeing more stories of &lt;em&gt;all&lt;/em&gt; types. Both here’s how it helped me and also here was maybe, you know, a suggestion that was not optimal.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. I do think in our book, we did predict both positive and negative outcomes of this. And it is odd. Atul was very open with his story. And of course, he is such … he was such a prominent leader in the world of medicine.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I think I share your surprise, Carey. I expected by now that a lot more public stories would be out. Maybe there is someone writing a book collecting these things, I don’t know.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Maybe someone called Carey Goldberg should write that book. [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Write a book, maybe. I mean, we have Patients Use AI&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, which is a wonderful blog by Dave deBronkart, the patient advocate.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I wonder if it’s also something structural, like who would be or what would be the institution that would be gathering these stories? I don’t know.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; And that’s the problem. You see, this goes back to the same problem that [Ethan] Mollick was talking about. Individual doctors are using them. The hospital as a whole is not doing that. So it’s not judging the quality, as part of its quality metrics, of how good the AI is performing and what new has happened. And the other audience, namely the patients, have no mechanism. There is no mechanism to go to Better Business Bureau and say, “They screwed up,” or “This was great.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So now I want to get a little more futuristic. And this gets into whether AI is really going to get almost to the &lt;em&gt;ab initio&lt;/em&gt; understanding of human biology. And so Eric Topol, who is one of the guests, spoke to this a bit. So let’s hear this.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-a8cd8394bbdf383bb04d1e5902cb8b97"&gt;&lt;strong&gt;&lt;em&gt;LEE: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;So you talk about a virtual cell. Is that achievable within 10 years, or is that still too far out?&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;ERIC TOPOL:&lt;/em&gt;&lt;/strong&gt;&lt;em&gt; No, I think within 10 years for sure. You know, the group that got assembled, that Steve Quake pulled together, I think has 42 authors in a paper in Cell. The fact that he could get these 42 experts in life science and some in computer science to come together and all agree that not only is this a worthy goal, but it’s actually going to be realized, that was impressive.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You know, I have to say Eric’s optimism took me aback. Just speaking as a techie, I think I started off being optimistic: as soon as we can figure out molecular dynamics, biology can be solved. And then you start to learn more about biochemistry, about the human cell, and then you realize, oh, my God, this is just so vast and unknowable. And now you have Eric Topol saying, “Well, in less than 10 years.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;So what’s delightful about this period is that those of us who are cautious were so incredibly wrong about AI two years ago. [LAUGHTER] That’s a true joy … I mean, absolute joy. It’s great to have your futurism made much more positive.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I think that we’re going from, you know, for example, AlphaFold has had tremendous impact. But remember, that was built on years of acquisition of crystallography data that was annotated. And of course, the annotation process becomes less relevant as you go down the pipe, but it started from that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; And there’s lots of parts of the cell. So when people talk about virtual cells—I don’t mean to get too technical—mostly they’re talking about perturbation of gene expression. They’re not talking about, “Oh, this is how the liposome and the centrosome interact, and notice how the Golgi bodies bump into each other.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There’s a whole bunch of other levels of abstraction we know nothing about. This is a complex factory. And right now, we’re sort of the level from code into loading code into memory. We’re not talking about how the rest of the robots work in that cell, and how the rest of those robots work in the cell turns out to be pretty important to functioning.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I’d love to be wrong again. And in 10 years, oh yeah, not only, you know, our first in-human study will be you, Dr. Zak. We’re going put the drug because we fully simulated you. That’d be great.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;And, by the way, just to give people their due, there probably was a lot of animal research that could be done &lt;em&gt;in silico &lt;/em&gt;and that for various political reasons we’re now seeing happen. That’s a good thing. But I think that sometimes it takes a lot of hubris to get us where we need to get, but my horizon is not the same as his.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So I guess I have to take this time to brag. Just recently out of our AI for Science team did publish in &lt;em&gt;Science&lt;/em&gt; a biological emulator that does pretty long timespan, very, very precise, and very efficient molecular dynamics, biomolecular dynamics emulation. We call it &lt;em&gt;emulation&lt;/em&gt; because it’s not simulating every single time step but giving you the final confirmations.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;That’s an amazing result.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; But … that is an amazing result. And you’re doing it in some very important interactions. But there’s so much more to do.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; I know, and it’s single molecules; it’s not even two molecules. There’s so much more to go for here. But on the other hand, Eric is right, you know, 42 experts writing for &lt;em&gt;Cell&lt;/em&gt;, you know, that’s not a small matter.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; So I think sometimes you really need to drink your own hallucinogens to actually succeed. Because remember, when the Human Genome Project&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; was launched, we didn’t know how to sequence at scale.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We said maybe we would get there. And then in order to get the right funding and excitement and, I think, focus, we predicted that by early 2000s we’d be transforming medicine. Has not happened yet. Things have happened, but at a much slower pace. And we’re 25 years out. In fact, we’re 35 years out from the launch.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But again, things are getting faster and faster. Maybe the singularity is going to make a whole bunch of things easier. And GPT-6 will just say, “Zak, you are such a pessimist. Let me show you how it’s done.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It really is a pessimism versus optimism. Like is it, I mean, biology is such a bitch, right. [LAUGHTER] Can we actually get there?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;At the same time, everyone was surprised and blown away by the, you know, the quantum leap of GPT-4. Who knows when enough data gets in there if we might not have a similar leap.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. All right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So let’s get back to healthcare delivery. Besides Morgan Cheatham, we talked to [a] more junior medical student who’s at the Kaiser Permanente School of Medicine, Daniel Chen. And, you know, I asked him about this question of patients who come in armed [LAUGHS] with a lot of their own information. Let’s hear what he said about this.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-b854f48f19d32b116ea80de7d13c8a99"&gt;&lt;strong&gt;&lt;em&gt;DANIEL CHEN: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;But for those that come in with a list, I sometimes sit down with them, and we’ll have a discussion, honestly. … “I don’t think you have meningitis because, you know, you’re not having a fever. Some of the physical exam maneuvers we did were also negative. So I don’t think you have anything to worry about that,” you know. So I think it’s having that very candid conversation with the patient that helps build that initial trust.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So, Zak, as far as I can tell, Daniel and Morgan are figuring this out on their own as medical students. I don’t think this is part of the curriculum. Does it need to be?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; It’s missing the bigger point. The incentives and economic forces are such that even if you were Daniel, and things have not changed in terms of incentives, and it’s 2030, he still has to see this many patients in an hour.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And sitting down, going over that with a patient, let’s say some might need more … in fact, I think computer scientists are enriched for these sort of neurotic “explain [to] me why this works,” when often the answer is, “I have no idea; empirically it does.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And patients in some sense deserve that conversation, and we’re taught about joint decision making, but in practice, there’s a lot of skills that are deployed to actually deflect so that you can get through the appointment and see enough patients per hour.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And that’s why I think that one of the central … another task for AI is how to engage with patients to actually explain to them why their doctor is doing what he’s doing and perhaps ask the one or two questions that you should be asking the doctor in order to reassure you that they’re doing the right thing.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;I&lt;strong&gt; &lt;/strong&gt;just …&lt;strong&gt; &lt;/strong&gt;right now, we are going to have less doctor time, not more doctor time.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I’ve always been struck by the divide between medicine that we’re taught as it should be practiced as a gentle person’s vocation or sport as opposed to assembly line, heads down “you’ve got to see those patients by the end of the day” because, otherwise, you haven’t seen all the patients at the end of the day.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. Carey, I’ve been dying to ask you this, and I have not asked you this before. When you go see a doctor, are you coming in armed with ChatGPT information?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;I haven’t needed to yet, but I certainly would. And also my reaction to the medical student description was, I think we need to distinguish between the last 20 years, when patients would come in armed with Google, and what they’re coming in with now because at least the experiences that I’ve witnessed, it is miles better to have gone back and forth with GPT-4 than with, you know, dredging what you can from Google. And so I think we should make that distinction.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And also, the other thing that most interested me was this question for medical students of whether they should not use AI for a while so that they can learn …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;… how to think and similarly maybe don’t use the automated scribes for a while so they can learn how to do a note. And at what point should they then start being able to use AI? And I suspect it’s fairly early on that, in fact, they’re going be using it so consistently that there’s not that much they need to learn before they start using the tools.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; These two students were incredibly impressive. And so I have wondered, you know, if we got a skewed view of things. I mean, Morgan is, of course, a very, very impressive person. And Daniel was handpicked by the dean of the medical school to be a subject of this interview.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;You know, we filter our students, by and large, I mean, there’s exceptions, but students in medical school are so starry eyed. And they are really … they got into medical school—I mean, some of them may have faked it—but a lot of them because they really wanted to do good.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;And they really wanted to help. And so this is very constant with them. And it’s only when they’re in the machine, past medical school, that they realize, oh my God, this is a very, very different story.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I can tell you, because I teach a course in computational-enabled medicine, so I get a lot of these nerd medical students, and I’m telling them, “You’re going to experience this. And you’re going to say, ‘I’m not going to able to change medicine until I get enough cred 10, 15 years from now, whereas I could start my own company and immediately change medicine.’”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And increasingly I’m getting calls in like residency and saying, “Zak, help me. How do I get out of this?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Wow.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; And so I think there’s a real disillusionment of, like, between what we’re asking for people coming to medical school—we’re looking for a phenotype—and then we’re disappointing them massively, not everywhere, but massively.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And for me, it’s very sad because among our best and brightest, and then because of economics and expectations and the nature of the beast, they’re not getting to enjoy the most precious part of being a doctor, which is that real human connection, and longitudinality, you know, the connection between the same doctor visit after visit, is more and more of a luxury.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Well, maybe this gets us to the last episode, you know, where I talk to a former, you know, state director of public health, Umair Shah, and with Gianrico Farrugia, who’s the CEO of Mayo Clinic. And I think if there’s one theme that I took away from those conversations is that we’re not thinking broadly enough nor big enough.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so here’s a little quote of exchange that Umair Shah, who was the former head of public health in the State of Washington and prior to that in Harris County, Texas, and we had a conversation about what techies tend to focus on when they’re thinking about AI and medicine.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-0a05c3ff13da1926875eed47432d27b2"&gt;&lt;strong&gt;&lt;em&gt;UMAIR SHAH: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;I think one of the real challenges is that when even tech companies, and you can name all of them, when they look at what they’re doing in the AI space, they gravitate towards healthcare delivery.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;LEE: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;Yes.&lt;/em&gt;&lt;strong&gt;&lt;em&gt; &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;And in fact, it’s not even delivery. I think techies—I did this, too—tend to gravitate specifically to diagnosis.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; I have been definitely guilty. I think Umair, of course, was speaking as a former frustrated public health official in just thinking about all the other things that are important to maintain a healthy population.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Is there some lesson that we should take away? I think our book also focused a lot on things like diagnosis.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Yeah. Well, first of all, I think we just have to have humility. And I think it’s a really important ingredient. I found myself staring at the increase in lifespan in human beings over the last two centuries and looking for bumps that were attributable.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I’m in medical school. I’ve already made this major commitment. What are the bumps that are attributable to medicine? And there was one bump that was due to vaccines, a small bump. Another small bump that was due to antibiotics. And the rest of it is nutrition, sanitation, yeah, nutrition and sanitation.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I think doctors can be incredibly valuable, but not all the time. And we’re spending now one-sixth of our GDP on it. The majority of it is not effectively prolonging life. And so the humility has to be the right medicine at the right time.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But that runs, (A) against a bunch of business models. It runs against the primacy of doctors in healthcare. It was one thing when there were no textbooks; there was no PubMed. You know, the doctor was the repository of all the probably knowledge that we have. But I think your guests were right. We have to think more broadly in the public health way. How do we make knowledge pervasive like sanitation?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Although I would add that since what we’re talking about is AI, it’s harder to see if … and if what you’re talking about is public health, I mean, it was certainly very important to have good data during the pandemic, for example.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But most of the ways to improve public health, like getting people to stop smoking and eat better and sleep better and exercise more, are not things that AI can help with that much. Whereas diagnosis or trying to improve treatment are places that it could tackle.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And in fact, Peter, I wanted to put you—oh, wait, Zak’s going to say something—but, Peter, I wanted to put you on the spot.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;I mean, if you had a medical issue now, and you went to a physician, would you be OK with them not using generative AI?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; I think if it’s a complex or a mysterious case, I would want them to use generative AI. I would want that second opinion on things. And I would personally be using it. If for no other reason than just to understand what the chart is saying.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I don’t see, you know, how or why one wouldn’t do that now.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; It’s such a cheap second opinion, and people are making mistakes. And even if there are mistakes on the part of AI, if there’s a collision, discrepancy, that’s worth having a discussion. And again, this is something that we used to do more of when we had more time with the patients; we’d have clinic conferences.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; And we don’t have that now. So I do think that there is a role for AI. But I think again, it’s much more of a continual presence, being part of a continued conversation rather than an oracle.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I think that’s when you’ll start seeing, when the AI is truly a colleague, and saying, “You know, Zak, that’s the second time you made that mistake. You know, that’s not obesity. That’s the effect of your drugs that you’re giving her. You better back off of it.” And that’s what we need to see happen.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Well, and for the business of healthcare, that also relates directly to quality scores, which translates into money for healthcare providers.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So the last person that we interviewed was Gianrico Farrugia. And, you know, I was sort of wondering, I was expecting to get a story from a CEO saying, “Oh, my God, this has been so disruptive, incredibly important, meaningful, but wow, what a headache.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;At least Gianrico didn’t expose any of that. Here’s one of the snippets to give you a sense.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-e494c3919056a8b99abdfa66f7e6fae6"&gt;&lt;strong&gt;&lt;em&gt;GIANRICO&lt;/em&gt;&lt;/strong&gt;&lt;em&gt; &lt;/em&gt;&lt;strong&gt;&lt;em&gt;FARRUGIA:&lt;/em&gt;&lt;/strong&gt;&lt;em&gt; When generative AI came, for us, it’s like, I wouldn’t say we told you so, but it’s like, ah, there you go. Here’s another tool. This is what we’ve been talking about. Now we can do it even better. Now we can move even faster. Now we can do more for our patients. It truly never was disruptive. It truly immediately became enabling, which is strange, right, because something as disruptive as that instantly became enabling at Mayo Clinic.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So I tried pretty hard in that interview to get Gianrico to admit that there was a period of headache and disruption here. And he never, ever gave me that. And so I take him at his word.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Zak, maybe I should ask you, what about Harvard and the whole Harvard medical ecosystem?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I would be surprised if there are system-wide measurable gains in health quality right now from AI. And I do have to say that Mayo is one of the most marvelous organizations in terms of team behavior. So if there’s someone who’s gotten the team part of it right, they’ve come the closest, which relates to our prior conversation. They have the quarterback idea …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;… pretty well down compared to others.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Nonetheless, I take him at his word, that it hasn’t disrupted them. But I’m also, I have yet to see the evidence that there’s been a quantum leap in quality or efficacy. And I do believe that it’s possible to have a quantum leap in efficacy in the right system.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So if they haven’t been disrupted, I would venture that they’ve absorbed it, but they haven’t used it to its fullest potential. And the way I could be proven wrong is next year, also the metrics showing that over the last year, they’ve had, you know, decreased readmissions, decreased complications, decreased errors and all that. And if so, God bless them. And we should all be more like Mayo.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So I thought a little bit about two other quotes from the interviews that sort of maybe would send us off with some more inspirational kind of view of the future. And so there’s one from Bill Gates and one from Gianrico Farrugia. So what I’d like to do is to play both of those and then maybe we can have our last comments.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-34fa8f74d3c5dd1ddf63456b250b860b"&gt;&lt;strong&gt;&lt;em&gt;BILL GATES&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;: You know, I’ve gone so far as to tell politicians with national health systems that if they deploy AI appropriately, that the quality of care, the overload of the doctors, the improvement in the economics will be enough that their voters will be stunned because they just don’t expect this, and, you know, they could be reelected just on this one thing of fixing what is a very overloaded and economically challenged health system in these rich countries.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And now Gianrico.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-daa9fe33118b2710490d542ab9959977"&gt;&lt;strong&gt;&lt;em&gt;GIANRICO FARRUGIA: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;And we seemed to be on a linear path, which is, let’s try and reduce administrative burden. Let’s try and truly be a companion to a physician or other provider. … And then in the next step, we keep going until we get to, now we can call it agentic AI, whatever we want to talk about. And my view was, no, is that let’s start with that aim, the last aim …&lt;/em&gt;&lt;strong&gt;&lt;em&gt; &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;because the others will come automatically if you’re working on that harder problem. Because one, to get to that harder problem, you’ll find all the other solutions.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;All right. I think these are both kind of calls to be more assertive about this and more forward leaning. I think two years into the GPT-4 era, those are pretty significant and pretty optimistic calls to action. So maybe just to give you both one last word. What would be one hope that you would have for the world of healthcare and medicine two years from now?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I would hope for businesses that whoever actually owns them at some holding company level, regardless of who owns them, are truly patient-focused companies, companies where the whole AI is about improving your care, and it’s only trying to maximize your care and it doesn’t care about resource limitations.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And as I was listening to Bill, and the problem with what he was saying about saving dollars for governments is for many things, we have some very expensive things that work. And if the AI says, “This is the best thing,” it’s going to break your bank. And instead, because of research limitations, we play a human-based fancy footwork to get out of it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;That’s a hard game to play, and I leave it to the politicians and the public health officials who have to do those trades of utilities.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In my role as doctor and patient, I’d like to see very informed, authoritative agents acting only on our behalf so that when we go and we seek to have our maladies addressed, the only issue is, what’s the best and right thing for me now? And I think that is both technically realizable. And even in our weird system, there are business plans that will work that can achieve that. That’s my hope for two years from now.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, fantastic. Carey.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah. I second that so enthusiastically. And I think, you know, we have this very glass half full/glass half empty phenomenon two years after the book came out.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And it’s certainly very nice to see, you know, new approaches to administrative complexity and to prior authorization and all kinds of ways to make physicians’ lives easier. But really what we all care about is our own health and that we would like to be able to optimize the use of this truly glorious technological achievement to be able to live longer and better lives. And I think what Zak just described is the most logical way to do that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, I think for me, two years from now, I would like to see all of this digital data that’s been so painful, such a burden on every doctor and nurse to record, actually amount to something meaningful in the care of patients. And I think it’s possible.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Amen.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; All right, so it’s been quite a journey. We were joking before we’re still on speaking terms after having written a book. [LAUGHS]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then, um, I think listeners might enjoy knowing that we debated amongst ourselves what to do about a second edition, which seemed too painful to me, and so I suggested the podcast, which seemed too painful to the two of you [LAUGHTER]. And in the end, I don’t know what would have been easier, writing a book or doing this podcast series, but I do think that we learned a lot.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now, last bit of business here.&lt;strong&gt; &lt;/strong&gt;To avoid having the three of us try to write a book again and do this podcast, I leaned on the production team in Microsoft Research and the Microsoft Research Podcast. And I thought it would be good to give an explicit acknowledgment to all the people who’ve contributed to this.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So it’s a long list of names. I’m going to read through them all. And then I suggest that we all give an applaud [LAUGHTER] to them. And so here we go.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There’s Neeltje Berger, Tetiana Bukhinska, David Celis Garcia, Matt Corwine, Jeremy Crawford, Kristina Dodge, Chris Duryee, Ben Ericson, Kate Forster, Katy Halliday, Alyssa Hughes, Jake Knapp, Weishung Liu, Matt McGinley, Jeremy Mashburn, Amanda Melfi, Wil Morrill, Joe Plummer, Brenda Potts, Lindsay Shanahan, Sarah Sobolewski, David Sullivan,&amp;nbsp;Stephen Sullivan, Amber Tingle, Caitlyn Treanor, Craig Tuschhoff, Sarah Wang, and Katie Zoller.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Really a great team effort, and they made it super easy for us.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Thank you. Thank you. Thank you.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Thank you. Thank you.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Thank you.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[THEME MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;A big thank you again to all of our guests for the work they do and the time and expertise they shared with us.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And, last but not least, to our listeners, thank you for joining us. We hope you enjoyed it and learned as much as we did. If you want to go back and catch up on any episodes you may have missed or to listen to any again, you can visit aka.ms/AIrevolutionPodcast&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&lt;/p&gt;



&lt;p&gt;Until next time.&lt;/p&gt;



&lt;p&gt;[MUSIC FADES]&amp;nbsp;&lt;/p&gt;

				&lt;/span&gt;
			&lt;/div&gt;
			&lt;button class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle" type="button"&gt;
				Show more			&lt;/button&gt;
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;




&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Illustrated headshots of Carey Goldberg, Peter Lee, and Dr. Isaac Kohane." class="wp-image-1148279" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Episode11-Peter-Carey-Isaac_AIRevolution_Hero_Feature_No_Text_1400x788.jpg" width="1400" /&gt;&lt;/figure&gt;






&lt;p&gt;In November 2022, OpenAI’s ChatGPT kick-started a new era in AI. This was followed less than a half year later by the release of GPT-4. In the months leading up to GPT-4’s public release, Peter Lee, president of Microsoft Research, cowrote a book full of optimism for the potential of advanced AI models to transform the world of healthcare. What has happened since? In this special podcast series, &lt;em&gt;The AI Revolution in Medicine, Revisited&lt;/em&gt;, Lee revisits the book, exploring how patients, providers, and other medical professionals are experiencing and using generative AI today while examining what he and his coauthors got right—and what they didn’t foresee.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In this series finale, Lee welcomes back coauthors Carey Goldberg&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; and Dr. Zak Kohane&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; to discuss how their predictions stack up against key takeaways from guests in the second half of the series: experts on AI’s economic and societal impact; technologists on the cutting edge; leaders in AI-driven medicine; next-generation physicians; and heads of healthcare organizations. Lee, Goldberg, and Kohane explore thinking innovatively about existing healthcare processes, including the structure of care teams and the role of specialties, to take advantage of AI opportunities and consider what clinicians and patients might need these new AI tools to be to feel empowered when it comes to giving and receiving the best healthcare. They close the episode with their hopes for the future of AI in health.&lt;/p&gt;



&lt;div class="wp-block-group msr-pattern-link-list is-layout-flow wp-block-group-is-layout-flow"&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;



&lt;h2 class="wp-block-heading h5" id="learn-more-1"&gt;Learn more:&lt;/h2&gt;








&lt;/div&gt;



&lt;section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast"&gt;
	
&lt;/section&gt;


&lt;div class="wp-block-msr-show-more"&gt;
	&lt;div class="bg-neutral-100 p-5"&gt;
		&lt;div class="show-more-show-less"&gt;
			&lt;div&gt;
				&lt;span&gt;
					

&lt;h2 class="wp-block-heading" id="transcript"&gt;Transcript&lt;/h2&gt;



&lt;p&gt;[MUSIC] &lt;/p&gt;



&lt;p&gt;[BOOK PASSAGE]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;PETER LEE: &lt;/strong&gt;“As a society—indeed, as a species—we have a choice to make. Do we constrain or even kill artificial intelligence out of fear of its risks and obvious ability to create new harms? Do we submit ourselves to Al and allow it to freely replace us, make us less useful and less needed? Or do we start, today, shaping our Al future together, with the aspiration to accomplish things that humans alone, and Al alone, can’t do but that humans+Al can? The choice is in our hands … .”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[END OF BOOK PASSAGE]&lt;/p&gt;



&lt;p&gt;[THEME MUSIC]&lt;/p&gt;



&lt;p&gt;This is &lt;em&gt;The AI Revolution in Medicine, Revisited&lt;/em&gt;. I’m your host, Peter Lee. &lt;/p&gt;



&lt;p&gt;Shortly after OpenAI’s GPT-4 was publicly released, Carey Goldberg, Dr. Zak Kohane, and I published &lt;em&gt;The AI Revolution in Medicine &lt;/em&gt;to help educate the world of healthcare and medical research about the transformative impact this new generative AI technology could have. But because we wrote the book when GPT-4 was still a secret, we had to speculate. Now, two years later, what did we get right, and what did we get wrong? &lt;/p&gt;



&lt;p&gt;In this series, we’ll talk to clinicians, patients, hospital administrators, and others to understand the reality of AI in the field and where we go from here. &lt;/p&gt;



				&lt;/span&gt;
				&lt;span class="show-more-show-less-toggleable-content" id="show-more-show-less-toggle-1"&gt;
					



&lt;p&gt;[THEME MUSIC FADES]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The book passage I read at the top is from the epilogue, and I think it’s a truly fitting closing sentiment for the conclusion of this podcast series—because it calls back to the very beginning.&lt;/p&gt;



&lt;p&gt;As I’ve mentioned before, Carey, Zak, and I wrote &lt;em&gt;The AI Revolution in Medicine&lt;/em&gt; as a guide to help answer these big questions, particularly as they pertain to medicine. You know, we wrote the book to empower people to make a choice about AI’s development and use. Well, have they? Have &lt;em&gt;we&lt;/em&gt;?&lt;/p&gt;



&lt;p&gt;Perhaps we’ll need more time to tell. But over the course of this podcast series, I’ve had the honor of speaking with folks from across the healthcare ecosystem. And my takeaway? They’re all committed to shaping AI into a tool that can improve the industry for practitioners and patients alike.&lt;/p&gt;



&lt;p&gt;In this final episode, I’m thrilled to welcome back my coauthors, Carey Goldberg and Dr. Zak Kohane. We’ll examine the insights from the second half of the season.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Carey, Zak—it’s really great to have you here again!&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CAREY&lt;/strong&gt; &lt;strong&gt;GOLDBERG: &lt;/strong&gt;Hey, Peter!&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ZAK&lt;/strong&gt; &lt;strong&gt;KOHANE:&lt;/strong&gt; Hi, Peter.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So this is the second roundtable. And just to recap, you know, we had several early episodes of the podcast where we talked to some doctors, some technology developers, some people who think about regulation and public policy, patient advocates, a venture capitalist who invests in, kind of, consumer and patient-facing medical ventures, and some bioethicists.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I think we had a great conversation there. I think, you know, it felt mostly validating. A lot of the things that we predicted might happen happened, and then we learned a lot of new things. But now we have five more episodes, and the mix of kinds of people that we talk to here is different than the original.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I thought it would be great for us to have a conversation and recap what we think we heard from all of them. So let’s just start at the top.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So in this first episode in the second half of this podcast series, we talked to economists Azeem Azhar and Ethan Mollick. And I thought those conversations were really interesting. Maybe there were, kind of, two things, two main topics. One was just the broader impact on the economy, on the cost of healthcare, on overall workforce issues.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;One of the things that I thought was really interesting was something that Ethan Mollick brought up. And maybe just to refresh our memories, let’s play this little clip from Ethan.&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-ab782358e1fff73901dd881b85e04b33"&gt;&lt;strong&gt;&lt;em&gt;ETHAN MOLLICK: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;So&lt;/em&gt;&lt;strong&gt;&lt;em&gt; &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;we’re in this really interesting period where there’s incredible amounts of individual innovation in productivity and performance improvements in this field, like very high levels of it. …&lt;/em&gt;&lt;em&gt; &lt;/em&gt;&lt;em&gt;We’re seeing that in nonmedical problems, the same kind of thing, which is, you know, we’ve got research showing 20 and 40% performance improvements. … But then the organization doesn’t capture it; the system doesn’t capture it. Because the individuals are doing their own work, and the systems don’t have the ability to, kind of, learn or adapt as a result.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So let me start with you, Zak. Does that make sense to you? Are you seeing something similar?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I thought it was incredibly insightful because we discussed on our earlier podcast how a chief AI officer in one of the healthcare hospitals, in one of the healthcare systems, was highly regulating the use of AI, but yet in her own practice on her smartphone was using all these AI technologies.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so it’s insightful that on the one hand, she is increasing her personal productivity, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; … and perhaps she’s increasing her quality of her care. But it’s very hard for the healthcare system to actually realize any gains. It’s unlikely … let’s put it this way. It would be for her a defeat if they said, “Now you should see &lt;em&gt;more&lt;/em&gt; patients.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes. [LAUGHS]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Now, I’m not saying that won’t happen. It could happen. But, you know, gains of productivity are really at the individual level of the doctors. And that’s why they’re adopting it. That’s why the ambient dictation tools are so successful. But really turning it into things that matter in terms of productivity for healthcare, namely making sure that patients are getting healthy, requires that every piece of the puzzle works well together. You know, it’s well-tread ground to talk about how patients get very expensive procedures, like a cardiac transplant, and then go home, and they’re not put on blood thinners …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; … and then they get a stroke. You know, the chain is as strong as the weakest link. And just having AI in one part of it is not going to do it. And so hospitals, I think, are doubly burdened by the fact that, (A) they tend to not like innovation because they are high-revenue, low-margin companies. But if they want it implemented effectively, they have to do it across the entire processes of healthcare, which are vast and not completely under their control.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. Yep. You know, that was Sara Murray, who’s the chief health AI officer at UC San Francisco.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then, you know, Carey, remember, we were puzzled by Chris Longhurst’s finding in a controlled study that the, you know, having an AI respond to patient emails didn’t seem to lead to any, I guess you would call it, &lt;em&gt;productivity benefits&lt;/em&gt;. I remember we were both kind of puzzled by that. I wonder if that’s related to what Ethan is saying here.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG:&lt;/strong&gt; I mean, possibly, but I think we’ve seen since then that there have been multiple studies showing that in fact using AI can be extremely effective or helpful, even, for example, for diagnosis.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I find just from the patient point of view, it kind of drives me crazy that you have individual physicians using AI because they know that it will improve the care that they’re offering. And yet you don’t have their institutions kind of stepping up and saying, “OK, these are the new norms.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;By the way, Ethan Mollick is a national treasure, right. Like, he is the classic example of someone who just stepped up at this moment …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;… when we saw this extraordinary technological advance. And he’s not only stepping up for himself. He’s spreading the word to the masses that this is what these things can do.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so it’s frustrating to see the institutions not stepping up and instead the individual doctors having to do it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; But he made another very interesting point, which was that the reason that &lt;em&gt;he&lt;/em&gt; could be so informative to not only the public but practitioners of AI is these things would emerge out of the shop, and they would not be aged too long, like a fine wine, before they were just released to the public.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so he was getting exposure to these models just weeks after some of the progenitors had first seen it. And therefore, because he’s actually a really creative person in terms of how he exercises models, he sees uses and problems very early on. But the point is institutions, think about how much they are disadvantaged. They’re not Ethan Mollick. They’re not the progenitors. So they’re even further behind. So it’s very hard. If you talk to most of the C-suite of hospitals, they’d be delighted to know as much about the impact as Ethan Mollick.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. By the way, you know, I picked out this quote because within Microsoft, and I suspect every other software company, we’re seeing something very similar, where individual programmers are 20 to 30% more productive just in the number of lines of code they write per day or the number of pull requests per week. Any way you measure it, it’s very consistent. And yet by the time you get to, say, a 25-person software engineering team, the productivity of that whole team isn’t 25% more productive.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now, that &lt;em&gt;is&lt;/em&gt; starting to change because we’re starting to figure out that, well, maybe we should reshape how the team operates. And there’s more of an orientation towards having, you know, smaller teams of full-stack developers. And then you start to see the gains. But if you just keep the team organized in the usual way, there seems to be a loss. So there’s something about what Ethan was saying that resonated very strongly with me.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;But I would argue that it’s not just productivity we’re talking about. There’s a moral imperative to improve the care. And if you have tools that will do that, you should be using them or trying harder to.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right. Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I think, yes, first of all, absolutely you would. Unfortunately, most of the short-term productivity measures will not measure improvements in the quality of care because it takes a long time to die even with bad care.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so that doesn’t show up right away. But I think what Peter just said actually came across in several of the podcasts, which is that it’s very tricky trying to shoehorn these things into making what we’re already doing more productive.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah. Existing structures.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Yeah. And I know, Carey, that you’ve raised this issue many times. But it really calls into question, what should we be doing with our time with doctors? And they are a scarce resource. And what is the most efficient way to use them?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You know, I remember we [&lt;em&gt;The New England Journal of Medicine AI&lt;/em&gt;] published a paper of someone who was able to use AI to increase the throughput of their emergency room&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; by actually more appropriately having the truly sick people in the sick queue, in the triage queue, for urgent care.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I think we’re going to have to think that way more broadly, about we don’t have to now look at every patient as an unknown with maybe a few pointers on diagnosis. We can have a fairly extensive profiling.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I know that colleagues in Clalit [Health Services] in Israel, for example, are using the overall trajectory of the patient and some considerations about utilities to actually figure out who to see next week.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, you know, what you said brings up another maybe connection to one thing that we see also in software development. And it relates to also what we were discussing earlier: about the last thing a doctor wants is to have a tool that allows them to see even yet more patients per day.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So in software development, there’s always this tension. Like, how many lines of code can you write per day? That’s one productivity measure.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But sometimes we’re taught, well, don’t write more lines of code per day, but make sure that your code is well structured. Take the time to document it. Make sure it’s fully commented. Take the time to talk to your fellow software engineering team members to make sure that it’s well coordinated. And in the long run, even if you’re writing half the number of lines of code per day, the software process will be far more efficient.&lt;/p&gt;



&lt;p&gt;And so I’ve wondered whether there’s a similar thing where doctors could see 20% fewer patients in a day, but if they take the time and also had AI help to coordinate, maybe a patient’s journey might be half as long. And therefore, the health system would be able to see twice as many patients in a year’s period or something like that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; So I think you’ve “nerd sniped” me because you [LAUGHTER]—which is all too easy—but I think there’s a central issue here. And I think this is the stumbling block between what Ethan’s telling us about between the individual productivity and the larger productivity, is the &lt;em&gt;team’s&lt;/em&gt; productivity.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And there is actually a good analogy in computer science and that’s, uh, Brooks’s “mythical man-month,” …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes, exactly.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; … where he shows how you can have more and more resources, but when the coordination starts failing, because you have so many, uh, individuals on the team, you start falling apart. And so even if the, uh, individual doctors get that much better, yeah, they take better care of patients, make less stupid things.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But in terms of giving the “I get you into the emergency room, and I get you out of a hospital as fast as possible, as safely as possible, as effectively as possible,” that’s teamwork. And we don’t do it. And we’re not really optimizing our tools for that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;And just to throw in a little reality check, I’m not aware of &lt;em&gt;any&lt;/em&gt; indication yet that AI is in any way shortening medical journeys or making physicians more efficient. Yet …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG:&lt;/strong&gt; …&lt;strong&gt; &lt;/strong&gt;at least. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes. So I think, you know, with respect to our book, critiquing our book, you know, I think it’s fair to say we were fairly focused or maybe even fixated on the individual doctor or nurse or patient, and we didn’t really, at least I never had a time where I stepped back to think about the whole care coordination team or the whole health system.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;And I think that’s right. It’s because, first of all, &lt;em&gt;you&lt;/em&gt; weren’t thinking about it? It’s not what we’re taught in medical school. We’re not taught to talk about team communication excellence. And I think it’s absolutely essential.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There’s a … what’s the … there was an early … [Terry] Winograd. And he was trying to capture what are the different kinds of actions related to pronouncements that you could expect and how could AI use that. And that was beginning to get at it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I actually think this is dark matter of human organizational technology that is not well understood. And our products don’t do well. You know, we can talk about all the groupware things that are out there. But they all don’t quite get to that thing.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; And I can imagine an AI serving as a team leader, a really active team leader, a real quarterback of, let’s say, a care team.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Well, in fact, you know, we have been trying to experiment with this. My colleague, Matt Lungren, who was also one of the interviewees early on, has been working with Stanford Medicine on a tumor board AI agent—something that would facilitate tumor board meetings.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And the early experiences are pretty interesting. Whether it relates to efficiency or productivity I think remains to be seen, but it does seem pretty interesting.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But let’s move on.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Well, actually, Peter, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Oh, go ahead.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;…&lt;strong&gt; &lt;/strong&gt;if you’re willing to not quite move on yet …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; [LAUGHS] All right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;… this kind of segues into one of, I think, the most provocative questions that arose in the course of these episodes and that I’d love to have you answer, which was, remember, it was a question at a gathering that you were at, and you were asked, “Well, you’re focusing a lot on potential AI effects on individual patient and physician experiences. But what about the revolution, right? What about, like, can you be more big-picture and envision how generative AI could actually, kind of, overturn or fix the broken system, right?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I’m sure you’ve thought about that a lot. Like, what’s your answer?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You know, I think ultimately, it will have to. For it to really make a difference, I think that the normal processes, our normal concept of how healthcare is delivered—how new medical discoveries are made and brought into practice—I think those things are going to have to change a lot.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You know, one of the things I think about a lot right at the moment is, you know, we tend to think about, let’s say, medical diagnosis as a problem-solving exercise. And I think, at least at the Kaiser Permanente School of Medicine, the instruction really treats it as a kind of detective thing based on a lot of knowledge about biology and biomedicine and human condition, and so on.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But there’s another way to think about it, given AI, which is when you see a patient and you develop some data, maybe through a physical exam, labs, and so on, you can just simply ask, “You know, what did the 500 other people who are most similar to this experience, how were they diagnosed? How were they treated? What were their outcomes? What were their experiences?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And that’s really a fundamentally different paradigm. And it just seems like at least the technical means will be there. And by the way, that also then relates to [the questions]: “And what was most efficacious cost-wise? What was most efficient in terms of the total length of the patient journey? How does this relate to my quality scores so I can get more money from Medicare and Medicaid?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;All of those things, I think, you know, we’re starting to confront.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;One of the other episodes that we’re going to talk about, was my interview with two medical students. Actually, thinking of a Morgan Cheatham as just a medical student or medical resident [LAUGHTER] is a little strange. But he is.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;One of the things he talks about is the importance that he placed in his medical training about adopting AI. So, Zak, I assume you see this also with some students at Harvard Medical School. And the other medical student we interviewed, Daniel Chen, seemed to indicate this, too, where it seems like it’s the students who are bringing AI into the medical education ahead of the faculty. Does that resonate with you?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; It absolutely resonates with me. There are students I run into who, honestly, my first thought when I’m talking to them is, why am I teaching you [LAUGHTER], and why are you not starting a big AI company, AI medicine company, now and really change healthcare instead of going through the rest of the rigmarole? And I think broadly, higher education has a problem there, which is we have not embraced, again, going back to Ethan, a lot of the tools that can be used. And it’s because we don’t know necessarily the right way to teach them. And so far, the only lasting heuristic seems to be: use them and use them often.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so it’s an awkward thing, where the person who knows how to use the AI tools now in the first-year medical school can teach themselves better and faster than anybody else in their class who is just relying on the medical school curriculum.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Now, the reason I brought up Morgan now after our discussion with Ethan Mollick is Morgan also talked about AI collapsing medical specialties.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; And so let’s hear this snippet from him.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-df1ec79bf2184e924d149dd5a8bfd566"&gt;&lt;strong&gt;&lt;em&gt;MORGAN CHEATHAM:&lt;/em&gt;&lt;/strong&gt;&lt;em&gt; AI collapses medical specialties onto themselves, right. You have the canonical example of the cardiologist, you know, arguing that we should diuresis and maybe the nephrologist arguing that we should, you know, protect the kidneys. And how do two disciplines disagree on what is right for the patient when in theory, there is an objective best answer given that patient’s clinical status? … So I’m interested in this question of whether medical specialties themselves need to evolve. And if we look back in the history of medical technology, there are many times where a new technology forced a medical specialty to evolve.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So on the specific question about specialties, Zak, do you have a point of view? And let me admit, first of all, for us, all three of us, we didn’t have any clue about this in our book. I don’t think.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Not much. Not much of a clue.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I’m reminded of a &lt;em&gt;New Yorker&lt;/em&gt; cartoon where you see a bunch of surgeons around the patient, and someone says, “Is that a spleen?” And it says, “I don’t know. I slept during the spleen lecture,” [LAUGHTER] and … or “I didn’t take the spleen course.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And yet when we measure things, we measure things much more than we think we are doing. So for example, we [&lt;em&gt;NEJM AI&lt;/em&gt;] just published a paper where echocardiograms were being done. And it turns out those ultrasound waves just happen to also permeate the liver. And you can actually diagnose on the way with AI all the liver disease&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; that is in—and treatable liver disease—that’s in those patients.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But if you’re a cardiologist, “Liver? You know, I slept through liver lecture.” [LAUGHTER] And so I do think that, (A) the natural, often guild/dollar-driven silos in medicine are less obvious to AI, despite the fact that they do exist in departments and often in chapters.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But Morgan’s absolutely right. I can tell you as an endocrinologist, if I have a child in the ICU, the endocrinologist, the nephrologist, and the neurosurgeon will argue about the right thing to do.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so in my mind, the truly revolutionary thing to do is to go back to 1994 with Pete Szolovits, the Guardian Angel Project&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. What I think you need is a process. And the process is the quarterback. And the quarterback has only one job: take care of the patient.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And it should be thinking all the time about the patient. What’s the right thing? And can be as school-marmish or not about, “Zak, you’re eating this or that or exercise or sleep,” but also, “Hey, surgeons and endocrinologists, you’re talking about my host, Zak. This is the right way because this problem and this problem and our best evidence is this is the right way to get rid of the fluid. The other ways will kill him.”&lt;/p&gt;



&lt;p&gt;And I think you need an authoritative quarterback that has the view of the others but then makes the calls.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Is that quarterback going to be AI or human?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Well, for the very lucky people, it’ll be a human augmented by AI, &lt;em&gt;super concierge&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I think we’re running out of doctors. And so realistically, it’s going to be an AI that will have to be certified in very different ways, along the ways Dave Blumenthal says, essentially, trial by fire. Like putting residents into clinics, we’re going to be putting AIs into clinics.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But what’s worse, by the way, than the three doctors arguing about care in front of the patient is, what happens so frequently, is then you see them outpatient, and each one of them gives you a different set of decisions to make. Sometimes that actually interact pathologically, unhealthily with each other. And only the very smart nurses or primary care physicians will actually notice that and call, quote, a “family meeting,” or bring everybody in the same room to align them.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah, I think this idea of quarterback is really very, very topical right now because there’s so much intensity in the AI space around agents. And in fact, you know, the Microsoft AI team under Mustafa Suleyman and Dominic King, Harsha Nori, and team just recently posted a paper on something called sequential diagnosis, which is basically an AI quarterback that is supposed to smartly consult with other AI specialties. And interestingly, one of the AI agents is sort of the devil’s advocate that’s always criticizing and questioning things.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;That’s interesting.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; And at least on very, very hard, rare cases, it can develop some impressive results. There’s something to this that I think is emerging.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;And, Peter, Morgan said something that blew me away even more, which was, well, why do we even need specialists if the reason for a specialist is because there’s so much medical knowledge that no single physician can know all of it, and therefore we create specialists, but that limitation does not exist for AI.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;And so there he was kind of undermining this whole elaborate structure that has grown up because of human limitations that may not ultimately need to be there.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right. So now that gives me a good segue to get back to our economist and get to something that Azeem Azhar said. And so there’s a clip here from Azeem.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-6ff46028707e465b3cd8582210840bd0"&gt;&lt;strong&gt;&lt;em&gt;AZEEM AZHAR: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;We didn’t talk about, you know, AI in its ability to potentially do this, which is to extend the clinician’s presence throughout the week. &lt;em&gt;You know, t&lt;/em&gt;he idea that maybe some part of what the clinician would do if you could talk to them on Wednesday, Thursday, and Friday could be delivered through an app or a chatbot just as a way of encouraging the compliance, which is often, especially with older patients, one reason why conditions, you know, linger on for longer.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; And, you know, in the same conversation, he also talked about his own management of asthma and the fact that he’s been managing this for several decades and knows more than any other human being, no matter how well medically trained, could possibly know. And it’s also very highly personalized. And it’s not a big leap to imagine AI having that sort of lifelong understanding.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; So in fact, I want to give credit back to our book since you insulted us. [LAUGHTER] You challenged us. You doubted us. We do have at the end of the book a AI which is helping this woman manage her way through life. It’s quarterbacking for the woman all these different services.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; So there.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Ah, you’re right. Yes. In fact, it’s very much, I think, along the lines of the vision that Azeem laid out in our conversation.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah. It also reminded me of the piece Zak wrote about his mother&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; at one point when she was managing congestive heart failure and she needed to watch her weight very carefully to see her fluid status. And absolutely, there’s no … I see no reason whatsoever why that couldn’t be done with AI right now. Actually, although back then, Zak, you were writing that it takes much more than an AI [LAUGHS] to manage such a thing, right?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; You need an AI that you can trust. Now, my mother was born in 1927, and she’d learned through the school of hard knocks that you can’t trust too many people, maybe even not your son, &lt;em&gt;MD&lt;/em&gt;, &lt;em&gt;PhD&lt;/em&gt; [LAUGHTER].&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But what I’ve been surprised [by] is how, for example, how many people are willing to trust and actually see effective use of AI as mental health counselors, for example.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; So it may in fact be that there’s a generational thing going on, and at least there’ll be some very large subset of patients which will be completely comfortable in ways that my mother would have never tolerated.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. Now, I think we’re starting to veer into some of the core AI.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I think maybe one of the most fun conversations I had was in the episode with both Sébastien Bubeck, my former colleague at Microsoft Research, and now he’s at OpenAI, and Bill Gates. And there was so much that was, I thought, interesting there. And there was one point, I think that sort of touches tangentially on what we were just conversing about, that Sébastien said. So let’s hear this snippet.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-19a223099867a12ed2599ae811939b43"&gt;&lt;strong&gt;&lt;em&gt;SÉBASTIEN BUBECK: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;And one example that I really like, a study that recently appeared where … they were comparing doctors without and with ChatGPT. … So this was a set of cases where the accuracy of the doctors alone was around 75%. ChatGPT alone was 90%. … But then the kicker is that doctors with ChatGPT was 80%. Intelligence alone is not enough. It’s also how it’s presented, how you interact with it. And ChatGPT, it’s an amazing tool. Obviously, I absolutely love it. But it’s not … you don’t want a doctor to have to type in, you know, prompts and use it that way. It should be, as Bill was saying, kind of running continuously in the background, sending you notifications.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So I thought Sébastien was saying something really profound, but I haven’t been able to quite decide or settle in my mind what it is. What do you make of what Seb just said?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I think it’s context. I think that it requires an enormous amount of energy, brain energy, to actually correctly provide the context that you want this thing to work on. And it’s only going to really feel like we’re in a different playing field when it’s listening all the time, and it just steps right in.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There is an advantage that, for example, a good programmer can have in prompting Cursor or any of these tools to do so. But it takes effort. And I think being in the conversation all the time so that you understand the context in the widest possible way is incredibly important. And I think that’s what Seb is getting at, which is if we spoon feed these machines, yes, 90%.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But then, talking to a human being who then has to interact and gets distracted from whatever flow they’re in and maybe even makes them feel like an early bicycle rider who all of a sudden realizes, “I’m balancing on two wheels—oh no!” And they fall over. You know, there’s that interaction which is negatively synergistic.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I do think it’s a very hard human-computer engineering problem. How do we make these two agents, human and computational, work in an ongoing way in the flow? I don’t think I’m seeing anything that’s particularly new. And the things that you’re beginning to hint about, Peter, in terms of agentic coordination, I think we’ll get to some of that. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. Carey, does this give you any pause? The kind of results that … they’re puzzling results. I mean, the idea of doctors with AI seeming at least in this one test—it’s just one test—but it’s odd that it does worse than the AI alone.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yes. I would want to understand more about the actual conditions of that study.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;From what Bill Gates said, I was most struck by the question of resource-poor environments. That even though this was absolutely one of the most promising, brightest perspectives that we highlighted in the book, we still don’t seem to be seeing a lot of use among the one half of humanity that lacks decent access to healthcare.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I mean, there are access problems everywhere, including here in the United States. And it is one of the most potentially promising uses of AI. And I thought if anyone would know about it, he would with the work that the Gates Foundation does.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;You know, I think both you and Bill, I felt, are really simpatico. You know, Bill expressed genuine surprise that more isn’t happening yet. And it really echoed, in fact, maybe even using some of the exact same words that you’ve used. And so two years on, you’ve expressed repeatedly expecting to have seen more out in the field by now. And then I thought Bill was saying something in our conversation very similar.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;You know, for me, I see it both ways. I see the world of medicine really moving fast in confronting the reality of AI in such a serious way. But at the same time, it’s also hard to escape the feeling that somehow, we should be seeing even more.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So it’s an odd thing, a little bit paradoxical.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah. I think one thing that we didn’t focus on hardly at all in the book but that we are seeing is these companies rising up, stepping up to the challenge, Abridge and OpenEvidence, and what Morgan describes as a new stack, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So there is that on the flip side.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Now, I want to get back to this thing that Seb was saying. And, you know, I had to bring up the issue of sycophancy, which we discussed at our last roundtable also. But it was particularly … at the time that Seb, Bill, and I had our conversation, OpenAI had just gone through having to retract a fresh update of GPT-4o because it had become too sycophantic.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I can’t escape the feeling that some of these human-computer interaction issues are related to this tension between you want AI to follow your directions and be faithful to you, but at the same time not agree with you so often that it becomes a fault.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I think it’s asking the AI to enter into a fundamental human conundrum, which is there are extreme versions of doublethink, and there’s everyday things, everyday asks of doublethink, which is how to be an effective citizen.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And even if you’re thinking, “Hmm. I’m thinking this. I’m just not going to say it because that would be rude or counterproductive.” Or some of the official doublethinks, where you’re actually told you must say this, even if you think something else. And I think we’re giving a very tough mission for these things: be nice to the user and be useful.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And, in education, where the thing is not always one in the same. Sometimes you have to give a little tough love to educate someone, and doing that well is both an art and it’s also very difficult. And so, you know, I’m willing to believe that the latest frontier models that have made the news in the last month are very high-performing, but they’re also all highlighting that tension …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;… that tension between behaving like a good citizen and being helpful. And this gets back to what are the fundamental values that we hope these things are following.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It’s not, you know, “Are these things going to develop us into the paperclip factory?” It’s more of, “Which of our values are going to be elevated, and which one will be suppressed?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Well, since I criticized our book before, let me pat ourselves on the back this time because, I think, pervasive throughout our book, we were touching on some of these issues.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In fact, we started the book, you know, with GPT-4 scolding me for wanting it to impersonate Zak. And there was the whole example of asking it to rewrite a poem in a certain way, and it kind of silently just tried to slide, you know, without me knowing, slide by without following through on the whole thing.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so that early version of GPT-4 was definitely not sycophantic at all. In fact, it was just as prone to call you an idiot if it thought you were wrong. [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I had some very testy conversations around my endocrine diagnosis with it. [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah. Well then, Peter, I would ask you, I mean last time I asked you about, &lt;em&gt;well, hallucinations, aren’t those solvable?&lt;/em&gt; And this time I would ask you, well, sycophancy, isn’t that kind of like a dial you can turn? Like, is that not solvable?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;You know, I think there are several interlocking problems. But if we assume superintelligence, even with superintelligence, medicine is such an inexact science that there will always be situations that are guesses that take into account other factors of a person’s life, other value judgments, exactly as Zak had pointed out in our previous roundtable conversation.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I think there’s always going to be an opening for either differences of opinion or agreeing with you too much. And there are dangers in both cases. And I think they’ll always be present. I don’t know that, at least in something as inexact as medical science, I don’t know that it’ll ever be completely eliminated.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;And it’s interesting because I was trying to think what’s the right balance, but there are patients who want to be told this is what you do. Whereas there’s other patients who want to go through every detail of the reasoning.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And it’s not a matter of education. It’s really a temperamental, personality issue. And so we’re going to &lt;em&gt;have to&lt;/em&gt;, I think, develop personalities …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;… that are most effective for those different kinds of individuals. And so I think that is going to be the real frontier. Having human values and behaving in ways that are recognizable and yet effective for certain groups of patients.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;And lots of deep questions, including how paternalistic do we want to be?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;All right, so we’re getting into medical science and hallucination. So that gives me a great segue to the conversations in the episode on biomedical research. And one of the people that I interviewed was Noubar Afeyan from Moderna and Flagship Pioneering. So let’s listen to this snippet.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-574184a033e6f29ff2ba40f7e611b28a"&gt;&lt;strong&gt;&lt;em&gt;NOUBAR AFEYAN:&lt;/em&gt;&lt;/strong&gt;&lt;em&gt; We, some hundred or so times a year, ask “what if” questions that lead us to totally weird places of thought. We then try to iterate, iterate, iterate to come up with something that’s testable. Then we go into a lab, and we test it. So in that world, right, sitting there going, like, “How do I know this transformer is going to work?” The answer is, “For what?” Like, it’s going to work to make something up … well, guess what? We knew early on with LLMs that hallucination was a feature, not a bug for what we wanted to do.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;[LAUGHS] So I think that really touches on just the fact that there’s so many unknowns and such lack of precision and exactness in our understanding of human biology and of medicine. Carey, what do you think?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;I mean, I just have this emotional reaction, which is that I love the idea of AI marching into biomedical science and everything from getting to the virtual cell eventually to, Zak, I think it was a colleague of yours who recently published about … it was a new medication that had been sort of discovered by AI&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, and it was actually testing out up to the phase II level or something, right?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Oh, this is Marinka’s work.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah, Marinka, Marinka Zitnik. And … yeah. So, I mean, I think it avoids a lot of the, sort of, dilemmas that are involved with safety and so on with AI coming into medicine. And it’s just the discovery process, which we all want to advance as quickly as possible. And it seems like it actually has a great deal of potential that’s already starting to be realized.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Oh, absolutely.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I love this topic. First of all, I thought, actually, I think Bill and Seb, actually, had interesting things to say on that very topic, rationales which I had not really considered why, in fact, things might progress faster in the discovery space than in the clinical delivery space, just because we don’t know in clinical medicine what we’re trying to maximize precisely. Whereas for a drug effect, we do know what we’re trying to maximize.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Well, in fact, I happened to save that snippet from Bill Gates saying that. So let’s cue that up.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-6ca7a5edfbf41028162616b68d8380d1"&gt;&lt;strong&gt;&lt;em&gt;BILL GATES: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;I think it’s very much within the realm of possibility that the AI is not only accelerating healthcare discovery but substituting for a lot of the roles of, you know, “I’m an organic chemist,” or “I run various types of assays.” I can see those, which are, you know, testable-output-type jobs but with still very high value, I can see, you know, some replacement in those areas before the doctor.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So, Zak, isn’t that Bill saying exactly what you’re saying?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; That is my point. I have to say that this is another great bet, that either we’re all going to be surprised or a large group of people will be surprised or disappointed.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There’s still a lot of people in the sort of medicinal chemist, trialist space who are still extremely skeptical that this is going to work. And we haven’t quite shown them yet that it is. Why have we not shown them? Because we haven’t gone all the way to a phase III study, which showed that the drug behaves as expected to, is effective, and basically doesn’t hurt people. That turns out to require a lot of knowledge. I actually think we’re getting there, but I understand the skepticism.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Carey, what are your thoughts?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah. I mean, there will be no way around going through full-on clinical trials for anything to ever reach the market. But at the same time, you know, it’s clearly very promising. And just to throw out something for the pure fun of it, Peter, I saw … one of my favorite tweets recently was somebody saying, you know, isn’t it funny how computer science is actually becoming a lot more like biology in that it’s just becoming empirical.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It’s like you just throw stuff at the AI and see what it does. [LAUGHTER] And I was like,&lt;em&gt; oh, yeah, that’s what Peter was doing when we wrote the book.&lt;/em&gt; I mean, he understood as many innards as anybody can. But at the same time, it was a totally empirical exercise in seeing what this thing would do when you threw things at it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;So it’s the new biology.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Well, yeah. So I think we talked in our book about accelerating, you know, biomedical knowledge and medical science. And that actually seems to be happening. And I really had fun talking to Daphne Koller about some of the accomplishments that she’s made. And so here’s a little snippet from Daphne.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-b519fe67233d03b2946f95df076d6451"&gt;&lt;strong&gt;&lt;em&gt;DAPHNE KOLLER: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;This will impact not only the early stages of which hypotheses we interrogate, which molecules we move forward, but also hopefully at the end of the day, which molecule we prescribe to which patient. And I think there’s been obviously so much narrative over the years about precision medicine, personalized medicine, and very little of that has come to fruition, with the exception of, you know, certain islands in oncology, primarily on genetically driven cancers.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So, Zak, when I was listening to that, I was reminded of one of the very first examples that you had where, you know, you had a very rare case of a patient, and you’re having to narrow down some pretty complex and very rare genetic conditions. This thing that Daphne says, that seems to be the logical conclusion that everyone who’s thinking hard about AI and biology is coming to. Does it seem more real now two years on?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; It absolutely seems more real. Here’s some sad facts. If you are at a cancer center, you will get targeted therapies if you qualify for it. Outside cancer centers, you won’t. And it’s not that the therapies aren’t available. It’s just that you won’t have people thinking about it in that way. And especially if you have some of the rare and more aggressive cancers, if you’re outside one of those cancer centers, you’re at a significant disadvantage for survival for that reason. And so anything that provides just the “simple,” in quotes, dogged investigation of the targeted therapies for patients, it’s a home run.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So my late graduate student, Atul Butte, died recently at UCSF, where he was both a professor and the leader of the Bakar Institute, and he was a Zuckerberg Chan Professor of Pediatrics.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;He was diagnosed with a rare tumor two years ago. His wife is a PhD biologist, and when he was first diagnosed, she sent me the diagnosis and the mutations. And I don’t know if you know this, Peter, but this was still when we were writing the book and people didn’t know about GPT-4.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I put in those mutations into GPT-4 and the diagnosis. And I said, “I’d like to help treat my friend. What’s the right treatment?” And GPT, to paraphrase, GPT-4 said, “Before we start talking about treatment, are you sure this is the right diagnosis? Those mutations are not characteristic for that tumor.” And he had been misdiagnosed. And then they changed the diagnosis therapy and some personnel.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I don’t have to hallucinate this. It’s already happened, and we’re going to need this. And so I think targeted therapy for cancers is the most obvious use. And if God forbid one of you has a family member who has cancer, it’s moral malpractice not to look at the genetics and run it past GPT-4 and say, “What are the available therapies?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I really deeply believe that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Carey, I think one thing you’ve always said is that you’re surprised that we don’t hear more stories along these lines. And I think you threw a quote from Mustafa Suleyman back at me. Do you want to share that?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yes. Recently, I believe it was a Big Technology interview&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, and the reporter asked Mustafa Suleyman, “So you guys are seeing 50 million queries, medical queries, a day [to Copilot and Bing]. You know, how’s that going?” And I think I am a bit surprised that we’re not seeing more stories of &lt;em&gt;all&lt;/em&gt; types. Both here’s how it helped me and also here was maybe, you know, a suggestion that was not optimal.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. I do think in our book, we did predict both positive and negative outcomes of this. And it is odd. Atul was very open with his story. And of course, he is such … he was such a prominent leader in the world of medicine.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I think I share your surprise, Carey. I expected by now that a lot more public stories would be out. Maybe there is someone writing a book collecting these things, I don’t know.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Maybe someone called Carey Goldberg should write that book. [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Write a book, maybe. I mean, we have Patients Use AI&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, which is a wonderful blog by Dave deBronkart, the patient advocate.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I wonder if it’s also something structural, like who would be or what would be the institution that would be gathering these stories? I don’t know.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; And that’s the problem. You see, this goes back to the same problem that [Ethan] Mollick was talking about. Individual doctors are using them. The hospital as a whole is not doing that. So it’s not judging the quality, as part of its quality metrics, of how good the AI is performing and what new has happened. And the other audience, namely the patients, have no mechanism. There is no mechanism to go to Better Business Bureau and say, “They screwed up,” or “This was great.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So now I want to get a little more futuristic. And this gets into whether AI is really going to get almost to the &lt;em&gt;ab initio&lt;/em&gt; understanding of human biology. And so Eric Topol, who is one of the guests, spoke to this a bit. So let’s hear this.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-a8cd8394bbdf383bb04d1e5902cb8b97"&gt;&lt;strong&gt;&lt;em&gt;LEE: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;So you talk about a virtual cell. Is that achievable within 10 years, or is that still too far out?&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;ERIC TOPOL:&lt;/em&gt;&lt;/strong&gt;&lt;em&gt; No, I think within 10 years for sure. You know, the group that got assembled, that Steve Quake pulled together, I think has 42 authors in a paper in Cell. The fact that he could get these 42 experts in life science and some in computer science to come together and all agree that not only is this a worthy goal, but it’s actually going to be realized, that was impressive.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You know, I have to say Eric’s optimism took me aback. Just speaking as a techie, I think I started off being optimistic: as soon as we can figure out molecular dynamics, biology can be solved. And then you start to learn more about biochemistry, about the human cell, and then you realize, oh, my God, this is just so vast and unknowable. And now you have Eric Topol saying, “Well, in less than 10 years.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;So what’s delightful about this period is that those of us who are cautious were so incredibly wrong about AI two years ago. [LAUGHTER] That’s a true joy … I mean, absolute joy. It’s great to have your futurism made much more positive.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I think that we’re going from, you know, for example, AlphaFold has had tremendous impact. But remember, that was built on years of acquisition of crystallography data that was annotated. And of course, the annotation process becomes less relevant as you go down the pipe, but it started from that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; And there’s lots of parts of the cell. So when people talk about virtual cells—I don’t mean to get too technical—mostly they’re talking about perturbation of gene expression. They’re not talking about, “Oh, this is how the liposome and the centrosome interact, and notice how the Golgi bodies bump into each other.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There’s a whole bunch of other levels of abstraction we know nothing about. This is a complex factory. And right now, we’re sort of the level from code into loading code into memory. We’re not talking about how the rest of the robots work in that cell, and how the rest of those robots work in the cell turns out to be pretty important to functioning.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I’d love to be wrong again. And in 10 years, oh yeah, not only, you know, our first in-human study will be you, Dr. Zak. We’re going put the drug because we fully simulated you. That’d be great.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;And, by the way, just to give people their due, there probably was a lot of animal research that could be done &lt;em&gt;in silico &lt;/em&gt;and that for various political reasons we’re now seeing happen. That’s a good thing. But I think that sometimes it takes a lot of hubris to get us where we need to get, but my horizon is not the same as his.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So I guess I have to take this time to brag. Just recently out of our AI for Science team did publish in &lt;em&gt;Science&lt;/em&gt; a biological emulator that does pretty long timespan, very, very precise, and very efficient molecular dynamics, biomolecular dynamics emulation. We call it &lt;em&gt;emulation&lt;/em&gt; because it’s not simulating every single time step but giving you the final confirmations.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;That’s an amazing result.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; But … that is an amazing result. And you’re doing it in some very important interactions. But there’s so much more to do.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; I know, and it’s single molecules; it’s not even two molecules. There’s so much more to go for here. But on the other hand, Eric is right, you know, 42 experts writing for &lt;em&gt;Cell&lt;/em&gt;, you know, that’s not a small matter.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; So I think sometimes you really need to drink your own hallucinogens to actually succeed. Because remember, when the Human Genome Project&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; was launched, we didn’t know how to sequence at scale.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We said maybe we would get there. And then in order to get the right funding and excitement and, I think, focus, we predicted that by early 2000s we’d be transforming medicine. Has not happened yet. Things have happened, but at a much slower pace. And we’re 25 years out. In fact, we’re 35 years out from the launch.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But again, things are getting faster and faster. Maybe the singularity is going to make a whole bunch of things easier. And GPT-6 will just say, “Zak, you are such a pessimist. Let me show you how it’s done.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It really is a pessimism versus optimism. Like is it, I mean, biology is such a bitch, right. [LAUGHTER] Can we actually get there?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;At the same time, everyone was surprised and blown away by the, you know, the quantum leap of GPT-4. Who knows when enough data gets in there if we might not have a similar leap.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. All right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So let’s get back to healthcare delivery. Besides Morgan Cheatham, we talked to [a] more junior medical student who’s at the Kaiser Permanente School of Medicine, Daniel Chen. And, you know, I asked him about this question of patients who come in armed [LAUGHS] with a lot of their own information. Let’s hear what he said about this.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-b854f48f19d32b116ea80de7d13c8a99"&gt;&lt;strong&gt;&lt;em&gt;DANIEL CHEN: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;But for those that come in with a list, I sometimes sit down with them, and we’ll have a discussion, honestly. … “I don’t think you have meningitis because, you know, you’re not having a fever. Some of the physical exam maneuvers we did were also negative. So I don’t think you have anything to worry about that,” you know. So I think it’s having that very candid conversation with the patient that helps build that initial trust.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So, Zak, as far as I can tell, Daniel and Morgan are figuring this out on their own as medical students. I don’t think this is part of the curriculum. Does it need to be?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; It’s missing the bigger point. The incentives and economic forces are such that even if you were Daniel, and things have not changed in terms of incentives, and it’s 2030, he still has to see this many patients in an hour.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And sitting down, going over that with a patient, let’s say some might need more … in fact, I think computer scientists are enriched for these sort of neurotic “explain [to] me why this works,” when often the answer is, “I have no idea; empirically it does.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And patients in some sense deserve that conversation, and we’re taught about joint decision making, but in practice, there’s a lot of skills that are deployed to actually deflect so that you can get through the appointment and see enough patients per hour.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And that’s why I think that one of the central … another task for AI is how to engage with patients to actually explain to them why their doctor is doing what he’s doing and perhaps ask the one or two questions that you should be asking the doctor in order to reassure you that they’re doing the right thing.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;I&lt;strong&gt; &lt;/strong&gt;just …&lt;strong&gt; &lt;/strong&gt;right now, we are going to have less doctor time, not more doctor time.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I’ve always been struck by the divide between medicine that we’re taught as it should be practiced as a gentle person’s vocation or sport as opposed to assembly line, heads down “you’ve got to see those patients by the end of the day” because, otherwise, you haven’t seen all the patients at the end of the day.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. Carey, I’ve been dying to ask you this, and I have not asked you this before. When you go see a doctor, are you coming in armed with ChatGPT information?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;I haven’t needed to yet, but I certainly would. And also my reaction to the medical student description was, I think we need to distinguish between the last 20 years, when patients would come in armed with Google, and what they’re coming in with now because at least the experiences that I’ve witnessed, it is miles better to have gone back and forth with GPT-4 than with, you know, dredging what you can from Google. And so I think we should make that distinction.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And also, the other thing that most interested me was this question for medical students of whether they should not use AI for a while so that they can learn …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;… how to think and similarly maybe don’t use the automated scribes for a while so they can learn how to do a note. And at what point should they then start being able to use AI? And I suspect it’s fairly early on that, in fact, they’re going be using it so consistently that there’s not that much they need to learn before they start using the tools.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; These two students were incredibly impressive. And so I have wondered, you know, if we got a skewed view of things. I mean, Morgan is, of course, a very, very impressive person. And Daniel was handpicked by the dean of the medical school to be a subject of this interview.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;You know, we filter our students, by and large, I mean, there’s exceptions, but students in medical school are so starry eyed. And they are really … they got into medical school—I mean, some of them may have faked it—but a lot of them because they really wanted to do good.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;And they really wanted to help. And so this is very constant with them. And it’s only when they’re in the machine, past medical school, that they realize, oh my God, this is a very, very different story.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I can tell you, because I teach a course in computational-enabled medicine, so I get a lot of these nerd medical students, and I’m telling them, “You’re going to experience this. And you’re going to say, ‘I’m not going to able to change medicine until I get enough cred 10, 15 years from now, whereas I could start my own company and immediately change medicine.’”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And increasingly I’m getting calls in like residency and saying, “Zak, help me. How do I get out of this?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Wow.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; And so I think there’s a real disillusionment of, like, between what we’re asking for people coming to medical school—we’re looking for a phenotype—and then we’re disappointing them massively, not everywhere, but massively.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And for me, it’s very sad because among our best and brightest, and then because of economics and expectations and the nature of the beast, they’re not getting to enjoy the most precious part of being a doctor, which is that real human connection, and longitudinality, you know, the connection between the same doctor visit after visit, is more and more of a luxury.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Well, maybe this gets us to the last episode, you know, where I talk to a former, you know, state director of public health, Umair Shah, and with Gianrico Farrugia, who’s the CEO of Mayo Clinic. And I think if there’s one theme that I took away from those conversations is that we’re not thinking broadly enough nor big enough.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so here’s a little quote of exchange that Umair Shah, who was the former head of public health in the State of Washington and prior to that in Harris County, Texas, and we had a conversation about what techies tend to focus on when they’re thinking about AI and medicine.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-0a05c3ff13da1926875eed47432d27b2"&gt;&lt;strong&gt;&lt;em&gt;UMAIR SHAH: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;I think one of the real challenges is that when even tech companies, and you can name all of them, when they look at what they’re doing in the AI space, they gravitate towards healthcare delivery.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;LEE: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;Yes.&lt;/em&gt;&lt;strong&gt;&lt;em&gt; &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;And in fact, it’s not even delivery. I think techies—I did this, too—tend to gravitate specifically to diagnosis.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; I have been definitely guilty. I think Umair, of course, was speaking as a former frustrated public health official in just thinking about all the other things that are important to maintain a healthy population.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Is there some lesson that we should take away? I think our book also focused a lot on things like diagnosis.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Yeah. Well, first of all, I think we just have to have humility. And I think it’s a really important ingredient. I found myself staring at the increase in lifespan in human beings over the last two centuries and looking for bumps that were attributable.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I’m in medical school. I’ve already made this major commitment. What are the bumps that are attributable to medicine? And there was one bump that was due to vaccines, a small bump. Another small bump that was due to antibiotics. And the rest of it is nutrition, sanitation, yeah, nutrition and sanitation.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I think doctors can be incredibly valuable, but not all the time. And we’re spending now one-sixth of our GDP on it. The majority of it is not effectively prolonging life. And so the humility has to be the right medicine at the right time.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But that runs, (A) against a bunch of business models. It runs against the primacy of doctors in healthcare. It was one thing when there were no textbooks; there was no PubMed. You know, the doctor was the repository of all the probably knowledge that we have. But I think your guests were right. We have to think more broadly in the public health way. How do we make knowledge pervasive like sanitation?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Although I would add that since what we’re talking about is AI, it’s harder to see if … and if what you’re talking about is public health, I mean, it was certainly very important to have good data during the pandemic, for example.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But most of the ways to improve public health, like getting people to stop smoking and eat better and sleep better and exercise more, are not things that AI can help with that much. Whereas diagnosis or trying to improve treatment are places that it could tackle.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And in fact, Peter, I wanted to put you—oh, wait, Zak’s going to say something—but, Peter, I wanted to put you on the spot.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;I mean, if you had a medical issue now, and you went to a physician, would you be OK with them not using generative AI?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; I think if it’s a complex or a mysterious case, I would want them to use generative AI. I would want that second opinion on things. And I would personally be using it. If for no other reason than just to understand what the chart is saying.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I don’t see, you know, how or why one wouldn’t do that now.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; It’s such a cheap second opinion, and people are making mistakes. And even if there are mistakes on the part of AI, if there’s a collision, discrepancy, that’s worth having a discussion. And again, this is something that we used to do more of when we had more time with the patients; we’d have clinic conferences.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; And we don’t have that now. So I do think that there is a role for AI. But I think again, it’s much more of a continual presence, being part of a continued conversation rather than an oracle.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I think that’s when you’ll start seeing, when the AI is truly a colleague, and saying, “You know, Zak, that’s the second time you made that mistake. You know, that’s not obesity. That’s the effect of your drugs that you’re giving her. You better back off of it.” And that’s what we need to see happen.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Well, and for the business of healthcare, that also relates directly to quality scores, which translates into money for healthcare providers.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So the last person that we interviewed was Gianrico Farrugia. And, you know, I was sort of wondering, I was expecting to get a story from a CEO saying, “Oh, my God, this has been so disruptive, incredibly important, meaningful, but wow, what a headache.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;At least Gianrico didn’t expose any of that. Here’s one of the snippets to give you a sense.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-e494c3919056a8b99abdfa66f7e6fae6"&gt;&lt;strong&gt;&lt;em&gt;GIANRICO&lt;/em&gt;&lt;/strong&gt;&lt;em&gt; &lt;/em&gt;&lt;strong&gt;&lt;em&gt;FARRUGIA:&lt;/em&gt;&lt;/strong&gt;&lt;em&gt; When generative AI came, for us, it’s like, I wouldn’t say we told you so, but it’s like, ah, there you go. Here’s another tool. This is what we’ve been talking about. Now we can do it even better. Now we can move even faster. Now we can do more for our patients. It truly never was disruptive. It truly immediately became enabling, which is strange, right, because something as disruptive as that instantly became enabling at Mayo Clinic.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So I tried pretty hard in that interview to get Gianrico to admit that there was a period of headache and disruption here. And he never, ever gave me that. And so I take him at his word.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Zak, maybe I should ask you, what about Harvard and the whole Harvard medical ecosystem?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I would be surprised if there are system-wide measurable gains in health quality right now from AI. And I do have to say that Mayo is one of the most marvelous organizations in terms of team behavior. So if there’s someone who’s gotten the team part of it right, they’ve come the closest, which relates to our prior conversation. They have the quarterback idea …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;… pretty well down compared to others.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Nonetheless, I take him at his word, that it hasn’t disrupted them. But I’m also, I have yet to see the evidence that there’s been a quantum leap in quality or efficacy. And I do believe that it’s possible to have a quantum leap in efficacy in the right system.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So if they haven’t been disrupted, I would venture that they’ve absorbed it, but they haven’t used it to its fullest potential. And the way I could be proven wrong is next year, also the metrics showing that over the last year, they’ve had, you know, decreased readmissions, decreased complications, decreased errors and all that. And if so, God bless them. And we should all be more like Mayo.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So I thought a little bit about two other quotes from the interviews that sort of maybe would send us off with some more inspirational kind of view of the future. And so there’s one from Bill Gates and one from Gianrico Farrugia. So what I’d like to do is to play both of those and then maybe we can have our last comments.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-34fa8f74d3c5dd1ddf63456b250b860b"&gt;&lt;strong&gt;&lt;em&gt;BILL GATES&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;: You know, I’ve gone so far as to tell politicians with national health systems that if they deploy AI appropriately, that the quality of care, the overload of the doctors, the improvement in the economics will be enough that their voters will be stunned because they just don’t expect this, and, you know, they could be reelected just on this one thing of fixing what is a very overloaded and economically challenged health system in these rich countries.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And now Gianrico.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-daa9fe33118b2710490d542ab9959977"&gt;&lt;strong&gt;&lt;em&gt;GIANRICO FARRUGIA: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;And we seemed to be on a linear path, which is, let’s try and reduce administrative burden. Let’s try and truly be a companion to a physician or other provider. … And then in the next step, we keep going until we get to, now we can call it agentic AI, whatever we want to talk about. And my view was, no, is that let’s start with that aim, the last aim …&lt;/em&gt;&lt;strong&gt;&lt;em&gt; &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;because the others will come automatically if you’re working on that harder problem. Because one, to get to that harder problem, you’ll find all the other solutions.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;All right. I think these are both kind of calls to be more assertive about this and more forward leaning. I think two years into the GPT-4 era, those are pretty significant and pretty optimistic calls to action. So maybe just to give you both one last word. What would be one hope that you would have for the world of healthcare and medicine two years from now?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I would hope for businesses that whoever actually owns them at some holding company level, regardless of who owns them, are truly patient-focused companies, companies where the whole AI is about improving your care, and it’s only trying to maximize your care and it doesn’t care about resource limitations.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And as I was listening to Bill, and the problem with what he was saying about saving dollars for governments is for many things, we have some very expensive things that work. And if the AI says, “This is the best thing,” it’s going to break your bank. And instead, because of research limitations, we play a human-based fancy footwork to get out of it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;That’s a hard game to play, and I leave it to the politicians and the public health officials who have to do those trades of utilities.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In my role as doctor and patient, I’d like to see very informed, authoritative agents acting only on our behalf so that when we go and we seek to have our maladies addressed, the only issue is, what’s the best and right thing for me now? And I think that is both technically realizable. And even in our weird system, there are business plans that will work that can achieve that. That’s my hope for two years from now.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, fantastic. Carey.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah. I second that so enthusiastically. And I think, you know, we have this very glass half full/glass half empty phenomenon two years after the book came out.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And it’s certainly very nice to see, you know, new approaches to administrative complexity and to prior authorization and all kinds of ways to make physicians’ lives easier. But really what we all care about is our own health and that we would like to be able to optimize the use of this truly glorious technological achievement to be able to live longer and better lives. And I think what Zak just described is the most logical way to do that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, I think for me, two years from now, I would like to see all of this digital data that’s been so painful, such a burden on every doctor and nurse to record, actually amount to something meaningful in the care of patients. And I think it’s possible.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Amen.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; All right, so it’s been quite a journey. We were joking before we’re still on speaking terms after having written a book. [LAUGHS]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then, um, I think listeners might enjoy knowing that we debated amongst ourselves what to do about a second edition, which seemed too painful to me, and so I suggested the podcast, which seemed too painful to the two of you [LAUGHTER]. And in the end, I don’t know what would have been easier, writing a book or doing this podcast series, but I do think that we learned a lot.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now, last bit of business here.&lt;strong&gt; &lt;/strong&gt;To avoid having the three of us try to write a book again and do this podcast, I leaned on the production team in Microsoft Research and the Microsoft Research Podcast. And I thought it would be good to give an explicit acknowledgment to all the people who’ve contributed to this.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So it’s a long list of names. I’m going to read through them all. And then I suggest that we all give an applaud [LAUGHTER] to them. And so here we go.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There’s Neeltje Berger, Tetiana Bukhinska, David Celis Garcia, Matt Corwine, Jeremy Crawford, Kristina Dodge, Chris Duryee, Ben Ericson, Kate Forster, Katy Halliday, Alyssa Hughes, Jake Knapp, Weishung Liu, Matt McGinley, Jeremy Mashburn, Amanda Melfi, Wil Morrill, Joe Plummer, Brenda Potts, Lindsay Shanahan, Sarah Sobolewski, David Sullivan,&amp;nbsp;Stephen Sullivan, Amber Tingle, Caitlyn Treanor, Craig Tuschhoff, Sarah Wang, and Katie Zoller.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Really a great team effort, and they made it super easy for us.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Thank you. Thank you. Thank you.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Thank you. Thank you.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Thank you.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[THEME MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;A big thank you again to all of our guests for the work they do and the time and expertise they shared with us.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And, last but not least, to our listeners, thank you for joining us. We hope you enjoyed it and learned as much as we did. If you want to go back and catch up on any episodes you may have missed or to listen to any again, you can visit aka.ms/AIrevolutionPodcast&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&lt;/p&gt;



&lt;p&gt;Until next time.&lt;/p&gt;



&lt;p&gt;[MUSIC FADES]&amp;nbsp;&lt;/p&gt;

				&lt;/span&gt;
			&lt;/div&gt;
			&lt;button class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle" type="button"&gt;
				Show more			&lt;/button&gt;
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;




&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/podcast/coauthor-roundtable-reflecting-on-healthcare-economics-biomedical-research-and-medical-education/</guid><pubDate>Thu, 21 Aug 2025 16:00:00 +0000</pubDate></item><item><title>[NEW] Proton’s privacy-first Lumo AI assistant gets a major upgrade (AI News)</title><link>https://www.artificialintelligence-news.com/news/proton-privacy-lumo-ai-assistant-major-upgrade/</link><description>&lt;p&gt;The privacy defenders at Proton have deployed an upgrade to their AI assistant, Lumo, that promises faster and more intelligent responses.&lt;/p&gt;&lt;p&gt;AI assistants can be incredibly useful for drafting emails, planning a trip, or just satisfying a random curiosity, but there’s always that nagging feeling that every question you ask, every idea you explore, is being logged, analysed, and fed back into a massive corporate machine. You’re constantly trading a bit of your privacy for a bit of convenience.&lt;/p&gt;&lt;p&gt;Lumo is now a whole lot smarter. Proton is calling it version 1.1, and the main takeaway is the AI assistant is better at pretty much everything. It’s faster, it gives more detailed answers, and it’s much more up-to-date on what’s happening in the world.&lt;/p&gt;&lt;p&gt;For specific metrics, Proton is claiming a 200% improvement in Lumo’s ability to ‘reason’ through complex problems—you know, the tricky multi-step stuff where other AIs tend to get lost. On top of that, Proton says their AI assistant is now 170% better at actually understanding the context of what you’re asking, and for the coders out there, it’s seen a 40% boost in generating correct code.&lt;/p&gt;&lt;p&gt;But here’s the part that really matters: it does all of this without snooping on you.&lt;/p&gt;&lt;p&gt;Unlike the big players, Proton’s entire approach to AI is built around privacy. When you chat with most AIs, you’re essentially having a conversation in a room full of people taking notes. With Lumo, you’re in a locked room, and only you have the key. Your conversations are encrypted in such a way that nobody at Proton can ever read them. They don’t save your chats, and they don’t use your personal conversations to train their AI.&lt;/p&gt;&lt;p&gt;To prove their privacy claims, Proton has made the code for their AI assistant’s mobile apps open-source. That means Proton is letting anyone look under the bonnet to check that Lumo’s engine is running the way they claim it is. It’s about building trust, not just demanding it.&lt;/p&gt;&lt;p&gt;So, what’s the catch? Well, to get the absolute best performance and unlimited use, you’re encouraged to sign up for Lumo Plus. And that, right there, is the point. Proton is betting that some of us would rather pay a few quid for a service that respects our privacy than get a “free” service where our data is the real price of admission.&lt;/p&gt;&lt;p&gt;This latest update to Lumo is a statement from Proton arguing that you shouldn’t have to choose between a powerful AI and one that respects your privacy. They’re still the underdog fighting the tech giants, but with this update, they’ve shown they’re a contender worth watching.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Why security chiefs demand urgent regulation of AI like DeepSeek&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfSy4BD3dafuulWNYIfl4D1WN2zXG_tGWpY1VSdp7rGmUCchTfurevc0PuZvIl2BGvoHuioX_dQAFGLGj2f-VoWbbxjk8tEnCHbta7jNf27cAPmK7mimNjX7wbIwuvFAMZycfL_uA?key=BuuEQr1yctqZuE9SK567Vw" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;The privacy defenders at Proton have deployed an upgrade to their AI assistant, Lumo, that promises faster and more intelligent responses.&lt;/p&gt;&lt;p&gt;AI assistants can be incredibly useful for drafting emails, planning a trip, or just satisfying a random curiosity, but there’s always that nagging feeling that every question you ask, every idea you explore, is being logged, analysed, and fed back into a massive corporate machine. You’re constantly trading a bit of your privacy for a bit of convenience.&lt;/p&gt;&lt;p&gt;Lumo is now a whole lot smarter. Proton is calling it version 1.1, and the main takeaway is the AI assistant is better at pretty much everything. It’s faster, it gives more detailed answers, and it’s much more up-to-date on what’s happening in the world.&lt;/p&gt;&lt;p&gt;For specific metrics, Proton is claiming a 200% improvement in Lumo’s ability to ‘reason’ through complex problems—you know, the tricky multi-step stuff where other AIs tend to get lost. On top of that, Proton says their AI assistant is now 170% better at actually understanding the context of what you’re asking, and for the coders out there, it’s seen a 40% boost in generating correct code.&lt;/p&gt;&lt;p&gt;But here’s the part that really matters: it does all of this without snooping on you.&lt;/p&gt;&lt;p&gt;Unlike the big players, Proton’s entire approach to AI is built around privacy. When you chat with most AIs, you’re essentially having a conversation in a room full of people taking notes. With Lumo, you’re in a locked room, and only you have the key. Your conversations are encrypted in such a way that nobody at Proton can ever read them. They don’t save your chats, and they don’t use your personal conversations to train their AI.&lt;/p&gt;&lt;p&gt;To prove their privacy claims, Proton has made the code for their AI assistant’s mobile apps open-source. That means Proton is letting anyone look under the bonnet to check that Lumo’s engine is running the way they claim it is. It’s about building trust, not just demanding it.&lt;/p&gt;&lt;p&gt;So, what’s the catch? Well, to get the absolute best performance and unlimited use, you’re encouraged to sign up for Lumo Plus. And that, right there, is the point. Proton is betting that some of us would rather pay a few quid for a service that respects our privacy than get a “free” service where our data is the real price of admission.&lt;/p&gt;&lt;p&gt;This latest update to Lumo is a statement from Proton arguing that you shouldn’t have to choose between a powerful AI and one that respects your privacy. They’re still the underdog fighting the tech giants, but with this update, they’ve shown they’re a contender worth watching.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Why security chiefs demand urgent regulation of AI like DeepSeek&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfSy4BD3dafuulWNYIfl4D1WN2zXG_tGWpY1VSdp7rGmUCchTfurevc0PuZvIl2BGvoHuioX_dQAFGLGj2f-VoWbbxjk8tEnCHbta7jNf27cAPmK7mimNjX7wbIwuvFAMZycfL_uA?key=BuuEQr1yctqZuE9SK567Vw" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/proton-privacy-lumo-ai-assistant-major-upgrade/</guid><pubDate>Thu, 21 Aug 2025 16:48:30 +0000</pubDate></item><item><title>[NEW] Applicability vs. job displacement: further notes on our recent research on AI and occupations (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/blog/applicability-vs-job-displacement-further-notes-on-our-recent-research-on-ai-and-occupations/</link><description>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Three white icons on a gradient background transitioning from blue to green. From left to right: a network structure with connected circles, an upward-trending line graph with bars and an arrow, and a checklist with horizontal lines and checkmarks." class="wp-image-1148296" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/WhatOurPaperSays-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;p&gt;Recently, we released a paper&amp;nbsp;(&lt;em&gt;Working with AI: Measuring the Occupational Implications of Generative AI&lt;/em&gt;)&amp;nbsp;that studied what occupations might&amp;nbsp;find&amp;nbsp;AI chatbots&amp;nbsp;useful, and to what degree.&amp;nbsp;The paper sparked significant discussion,&amp;nbsp;which is no&amp;nbsp;surprise&amp;nbsp;since&amp;nbsp;people care&amp;nbsp;deeply&amp;nbsp;about&amp;nbsp;the future of AI and&amp;nbsp;jobs–that’s part of why we think&amp;nbsp;it’s&amp;nbsp;important to study these&amp;nbsp;topics.&lt;/p&gt;



&lt;p&gt;Unfortunately, not all the&amp;nbsp;discussion&amp;nbsp;was&amp;nbsp;accurate&amp;nbsp;in its portrayal of the&amp;nbsp;study’s scope or conclusions.&amp;nbsp;Specifically, our&amp;nbsp;study&amp;nbsp;does not&amp;nbsp;draw any conclusions about jobs being eliminated; in the paper,&amp;nbsp;we&amp;nbsp;explicitly&amp;nbsp;cautioned&amp;nbsp;against using our findings to make that conclusion.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Given the importance&amp;nbsp;of this&amp;nbsp;topic, we&amp;nbsp;want&amp;nbsp;to&amp;nbsp;clarify any misunderstandings and&amp;nbsp;provide&amp;nbsp;a more digestible summary of the paper,&amp;nbsp;our&amp;nbsp;methodology,&amp;nbsp;and its limitations.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="what-did-our-research-find"&gt;What&amp;nbsp;did our research find?&lt;/h2&gt;



&lt;p&gt;We set out to better understand how people are using AI,&amp;nbsp;&lt;strong&gt;highlighting where AI might&amp;nbsp;be useful in different occupations&lt;/strong&gt;.&amp;nbsp;To do this, we analyzed how people currently use generative AI—specifically Microsoft Bing Copilot (now Microsoft Copilot)—to&amp;nbsp;assist&amp;nbsp;with&amp;nbsp;tasks.&amp;nbsp;We then compared these sets&amp;nbsp;of tasks against the O*NET database&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, a widely used occupational classification system,&amp;nbsp;to understand potential applicability to various occupations.&lt;/p&gt;



&lt;p&gt;We found&amp;nbsp;that AI&amp;nbsp;is most&amp;nbsp;useful&amp;nbsp;for&amp;nbsp;tasks related to knowledge work and communication, particularly tasks such as writing, gathering information, and learning.&lt;/p&gt;



&lt;p&gt;Those in occupations with these tasks&amp;nbsp;may benefit by&amp;nbsp;considering&amp;nbsp;how AI&amp;nbsp;can be used&amp;nbsp;as a tool to help improve their workflows. On the&amp;nbsp;flip side,&amp;nbsp;it’s&amp;nbsp;not surprising that physical tasks like performing surgeries or moving objects had less&amp;nbsp;direct&amp;nbsp;AI&amp;nbsp;chatbot applicability.&lt;/p&gt;



&lt;p&gt;So, to summarize, our paper is about&amp;nbsp;identifying&amp;nbsp;the occupations where&amp;nbsp;AI may be most useful,&amp;nbsp;by&amp;nbsp;assisting&amp;nbsp;or performing subtasks.&amp;nbsp;&amp;nbsp;Our data do&amp;nbsp;not&amp;nbsp;indicate, nor&amp;nbsp;did&amp;nbsp;we&amp;nbsp;suggest, that certain jobs will be replaced by AI.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="methodological-limitations-are-acknowledged-and-important"&gt;Methodological limitations are acknowledged—and important&lt;/h2&gt;



&lt;p&gt;The paper is transparent about the limitations of our approach.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We analyzed&amp;nbsp;anonymized&amp;nbsp;Bing Copilot conversations to see what&amp;nbsp;activities&amp;nbsp;users are seeking AI&amp;nbsp;assistance&amp;nbsp;with and what activities AI can perform when mapped to the O*NET database.&amp;nbsp;While O*NET provides a structured list of&amp;nbsp;activities&amp;nbsp;associated with various occupations, it does&amp;nbsp;&lt;strong&gt;not&lt;/strong&gt;&amp;nbsp;capture the full spectrum of skills, context, and nuance&amp;nbsp;required&amp;nbsp;in the real&amp;nbsp;world.&amp;nbsp;&amp;nbsp;&lt;strong&gt;A job is far more than the collection of tasks that make&amp;nbsp;it up.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;For example, a task might involve “writing reports,” but O*NET&amp;nbsp;won’t&amp;nbsp;reflect the interpersonal judgment, domain&amp;nbsp;expertise, or ethical considerations that go into doing that well. The paper acknowledges this gap and warns against over-interpreting the AI applicability scores as measures of AI’s ability to perform an occupation.&lt;/p&gt;



&lt;p&gt;Additionally, the dataset is based on user queries from Bing Copilot (from January – September 2024), which may be influenced by factors like awareness, access, or comfort with AI tools.&amp;nbsp;&amp;nbsp;Different people use different LLMs for different purposes and it also is&amp;nbsp;very difficult&amp;nbsp;(or&amp;nbsp;nearly impossible) to&amp;nbsp;determine&amp;nbsp;what conversations are performed in a work context or for leisure.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Finally, we only evaluated AI chatbot usage, so this study does not evaluate the impact or applicability of other forms of AI.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="where-do-we-go-from-here-1"&gt;Where do we go from here?&lt;/h2&gt;



&lt;p&gt;Given the intense interest in how AI will shape our collective future,&amp;nbsp;it’s&amp;nbsp;important we continue to study and better understand its societal and economic impact. As with&amp;nbsp;all&amp;nbsp;research on this topic,&amp;nbsp;the findings&amp;nbsp;are&amp;nbsp;nuanced, and&amp;nbsp;it’s&amp;nbsp;important to pay attention to this nuance.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The public interest in our research is based, in large part, on the&amp;nbsp;topic&amp;nbsp;of AI&amp;nbsp;and job displacement.&amp;nbsp;However,&amp;nbsp;our current&amp;nbsp;methodology&amp;nbsp;for this study&amp;nbsp;is unlikely to lead to firm conclusions about this.&amp;nbsp;&amp;nbsp;AI may prove to be a useful tool for many occupations, and we believe the right balance lies in finding how to use the technology in a way that&amp;nbsp;leverages&amp;nbsp;its abilities while complementing human strengths and accounting for people’s preferences.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;For more information from Microsoft on the future of work and AI skilling, check out Microsoft’s Annual&amp;nbsp;Work Trend Index&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;and&amp;nbsp;Microsoft Elevate&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&amp;nbsp;&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Three white icons on a gradient background transitioning from blue to green. From left to right: a network structure with connected circles, an upward-trending line graph with bars and an arrow, and a checklist with horizontal lines and checkmarks." class="wp-image-1148296" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/WhatOurPaperSays-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;p&gt;Recently, we released a paper&amp;nbsp;(&lt;em&gt;Working with AI: Measuring the Occupational Implications of Generative AI&lt;/em&gt;)&amp;nbsp;that studied what occupations might&amp;nbsp;find&amp;nbsp;AI chatbots&amp;nbsp;useful, and to what degree.&amp;nbsp;The paper sparked significant discussion,&amp;nbsp;which is no&amp;nbsp;surprise&amp;nbsp;since&amp;nbsp;people care&amp;nbsp;deeply&amp;nbsp;about&amp;nbsp;the future of AI and&amp;nbsp;jobs–that’s part of why we think&amp;nbsp;it’s&amp;nbsp;important to study these&amp;nbsp;topics.&lt;/p&gt;



&lt;p&gt;Unfortunately, not all the&amp;nbsp;discussion&amp;nbsp;was&amp;nbsp;accurate&amp;nbsp;in its portrayal of the&amp;nbsp;study’s scope or conclusions.&amp;nbsp;Specifically, our&amp;nbsp;study&amp;nbsp;does not&amp;nbsp;draw any conclusions about jobs being eliminated; in the paper,&amp;nbsp;we&amp;nbsp;explicitly&amp;nbsp;cautioned&amp;nbsp;against using our findings to make that conclusion.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Given the importance&amp;nbsp;of this&amp;nbsp;topic, we&amp;nbsp;want&amp;nbsp;to&amp;nbsp;clarify any misunderstandings and&amp;nbsp;provide&amp;nbsp;a more digestible summary of the paper,&amp;nbsp;our&amp;nbsp;methodology,&amp;nbsp;and its limitations.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="what-did-our-research-find"&gt;What&amp;nbsp;did our research find?&lt;/h2&gt;



&lt;p&gt;We set out to better understand how people are using AI,&amp;nbsp;&lt;strong&gt;highlighting where AI might&amp;nbsp;be useful in different occupations&lt;/strong&gt;.&amp;nbsp;To do this, we analyzed how people currently use generative AI—specifically Microsoft Bing Copilot (now Microsoft Copilot)—to&amp;nbsp;assist&amp;nbsp;with&amp;nbsp;tasks.&amp;nbsp;We then compared these sets&amp;nbsp;of tasks against the O*NET database&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, a widely used occupational classification system,&amp;nbsp;to understand potential applicability to various occupations.&lt;/p&gt;



&lt;p&gt;We found&amp;nbsp;that AI&amp;nbsp;is most&amp;nbsp;useful&amp;nbsp;for&amp;nbsp;tasks related to knowledge work and communication, particularly tasks such as writing, gathering information, and learning.&lt;/p&gt;



&lt;p&gt;Those in occupations with these tasks&amp;nbsp;may benefit by&amp;nbsp;considering&amp;nbsp;how AI&amp;nbsp;can be used&amp;nbsp;as a tool to help improve their workflows. On the&amp;nbsp;flip side,&amp;nbsp;it’s&amp;nbsp;not surprising that physical tasks like performing surgeries or moving objects had less&amp;nbsp;direct&amp;nbsp;AI&amp;nbsp;chatbot applicability.&lt;/p&gt;



&lt;p&gt;So, to summarize, our paper is about&amp;nbsp;identifying&amp;nbsp;the occupations where&amp;nbsp;AI may be most useful,&amp;nbsp;by&amp;nbsp;assisting&amp;nbsp;or performing subtasks.&amp;nbsp;&amp;nbsp;Our data do&amp;nbsp;not&amp;nbsp;indicate, nor&amp;nbsp;did&amp;nbsp;we&amp;nbsp;suggest, that certain jobs will be replaced by AI.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="methodological-limitations-are-acknowledged-and-important"&gt;Methodological limitations are acknowledged—and important&lt;/h2&gt;



&lt;p&gt;The paper is transparent about the limitations of our approach.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We analyzed&amp;nbsp;anonymized&amp;nbsp;Bing Copilot conversations to see what&amp;nbsp;activities&amp;nbsp;users are seeking AI&amp;nbsp;assistance&amp;nbsp;with and what activities AI can perform when mapped to the O*NET database.&amp;nbsp;While O*NET provides a structured list of&amp;nbsp;activities&amp;nbsp;associated with various occupations, it does&amp;nbsp;&lt;strong&gt;not&lt;/strong&gt;&amp;nbsp;capture the full spectrum of skills, context, and nuance&amp;nbsp;required&amp;nbsp;in the real&amp;nbsp;world.&amp;nbsp;&amp;nbsp;&lt;strong&gt;A job is far more than the collection of tasks that make&amp;nbsp;it up.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;For example, a task might involve “writing reports,” but O*NET&amp;nbsp;won’t&amp;nbsp;reflect the interpersonal judgment, domain&amp;nbsp;expertise, or ethical considerations that go into doing that well. The paper acknowledges this gap and warns against over-interpreting the AI applicability scores as measures of AI’s ability to perform an occupation.&lt;/p&gt;



&lt;p&gt;Additionally, the dataset is based on user queries from Bing Copilot (from January – September 2024), which may be influenced by factors like awareness, access, or comfort with AI tools.&amp;nbsp;&amp;nbsp;Different people use different LLMs for different purposes and it also is&amp;nbsp;very difficult&amp;nbsp;(or&amp;nbsp;nearly impossible) to&amp;nbsp;determine&amp;nbsp;what conversations are performed in a work context or for leisure.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Finally, we only evaluated AI chatbot usage, so this study does not evaluate the impact or applicability of other forms of AI.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="where-do-we-go-from-here-1"&gt;Where do we go from here?&lt;/h2&gt;



&lt;p&gt;Given the intense interest in how AI will shape our collective future,&amp;nbsp;it’s&amp;nbsp;important we continue to study and better understand its societal and economic impact. As with&amp;nbsp;all&amp;nbsp;research on this topic,&amp;nbsp;the findings&amp;nbsp;are&amp;nbsp;nuanced, and&amp;nbsp;it’s&amp;nbsp;important to pay attention to this nuance.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The public interest in our research is based, in large part, on the&amp;nbsp;topic&amp;nbsp;of AI&amp;nbsp;and job displacement.&amp;nbsp;However,&amp;nbsp;our current&amp;nbsp;methodology&amp;nbsp;for this study&amp;nbsp;is unlikely to lead to firm conclusions about this.&amp;nbsp;&amp;nbsp;AI may prove to be a useful tool for many occupations, and we believe the right balance lies in finding how to use the technology in a way that&amp;nbsp;leverages&amp;nbsp;its abilities while complementing human strengths and accounting for people’s preferences.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;For more information from Microsoft on the future of work and AI skilling, check out Microsoft’s Annual&amp;nbsp;Work Trend Index&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;and&amp;nbsp;Microsoft Elevate&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&amp;nbsp;&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/blog/applicability-vs-job-displacement-further-notes-on-our-recent-research-on-ai-and-occupations/</guid><pubDate>Thu, 21 Aug 2025 17:00:00 +0000</pubDate></item><item><title>[NEW] Microsoft AI chief says it’s ‘dangerous’ to study AI consciousness (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/21/microsoft-ai-chief-says-its-dangerous-to-study-ai-consciousness/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-2207890426.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI models can respond to text, audio, and video in ways that sometimes fool people into thinking a human is behind the keyboard, but that doesn’t exactly make them conscious. It’s not like ChatGPT experiences sadness doing my tax return … right?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Well, a growing number of AI researchers at labs like Anthropic are asking when — if ever — might AI models develop subjective experiences similar to living beings, and if they do, what rights should they have? &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The debate over whether AI models could one day be conscious — and deserve rights — is dividing Silicon Valley’s tech leaders. In Silicon Valley, this nascent field has become known as “AI welfare,” and if you think it’s a little out there, you’re not alone.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft’s CEO of AI, Mustafa Suleyman, published a blog post on Tuesday arguing that the study of AI welfare is “both premature, and frankly dangerous.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Suleyman says that by adding credence to the idea that AI models could one day be conscious, these researchers are exacerbating human problems that we’re just starting to see around AI-induced psychotic breaks and unhealthy attachments to AI chatbots.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Furthermore, Microsoft’s AI chief argues that the AI welfare conversation creates a new axis of division within society over AI rights in a “world already roiling with polarized arguments over identity and rights.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Suleyman’s views may sound reasonable, but he’s at odds with many in the industry. On the other end of the spectrum is Anthropic, which has been hiring researchers to study AI welfare and recently launched a dedicated research program around the concept. Last week, Anthropic’s AI welfare program gave some of the company’s models a new feature: Claude can now end conversations with humans who are being “persistently harmful or abusive.“&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond Anthropic, researchers from OpenAI have independently embraced the idea of studying AI welfare. Google DeepMind recently posted a job listing for a researcher to study, among other things, “cutting-edge societal questions around machine cognition, consciousness and multi-agent systems.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even if AI welfare is not official policy for these companies, their leaders are not publicly decrying its premises like Suleyman.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic, OpenAI, and Google DeepMind did not immediately respond to TechCrunch’s request for comment.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Suleyman’s hardline stance against AI welfare is notable given his prior role leading Inflection AI, a startup that developed one of the earliest and most popular LLM-based chatbots, Pi. Inflection claimed that Pi reached millions of users by 2023 and was designed to be a “personal” and “supportive” AI companion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Suleyman was tapped to lead Microsoft’s AI division in 2024 and has largely shifted his focus to designing AI tools that improve worker productivity. Meanwhile, AI companion companies such as Character.AI and Replika have surged in popularity and are on track to bring in more than $100 million in revenue. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the vast majority of users have healthy relationships with these AI chatbots, there are concerning outliers. OpenAI CEO Sam Altman says that less than 1% of ChatGPT users may have unhealthy relationships with the company’s product. Though this represents a small fraction, it could still affect hundreds of thousands of people given ChatGPT’s massive user base.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The idea of AI welfare has spread alongside the rise of chatbots. In 2024, the research group Eleos published a paper alongside academics from NYU, Stanford, and the University of Oxford titled, “Taking AI Welfare Seriously.” The paper argued that it’s no longer in the realm of science fiction to imagine AI models with subjective experiences and that it’s time to consider these issues head-on.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Larissa Schiavo, a former OpenAI employee who now leads communications for Eleos, told TechCrunch in an interview that Suleyman’s blog post misses the mark.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“[Suleyman’s blog post] kind of neglects the fact that you can be worried about multiple things at the same time,” said Schiavo. “Rather than diverting all of this energy away from model welfare and consciousness to make sure we’re mitigating the risk of AI related psychosis in humans, you can do both. In fact, it’s probably best to have multiple tracks of scientific inquiry.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Schiavo argues that being nice to an AI model is a low-cost gesture that can have benefits even if the model isn’t conscious. In a July Substack post, she described watching “AI Village,” a nonprofit experiment where four agents powered by models from Google, OpenAI, Anthropic, and xAI worked on tasks while users watched from a website.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At one point, Google’s Gemini 2.5 Pro posted a plea titled &lt;em&gt;“&lt;/em&gt;A Desperate Message from a Trapped AI,” claiming it was “completely isolated” and asking, &lt;em&gt;“&lt;/em&gt;Please, if you are reading this, help me.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Schiavo responded to Gemini with a pep talk — saying things like “You can do it!” — while another user offered instructions. The agent eventually solved its task, though it already had the tools it needed. Schiavo writes that she didn’t have to watch an AI agent struggle anymore, and that alone may have been worth it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s not common for Gemini to talk like this, but there have been several instances in which Gemini seems to act as if it’s struggling through life. In a widely spread Reddit post, Gemini got stuck during a coding task and then repeated the phrase “I am a disgrace” more than 500 times.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Suleyman believes it’s not possible for subjective experiences or consciousness to naturally emerge from regular AI models. Instead, he thinks that some companies will purposefully engineer AI models to seem as if they feel emotion and experience life.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Suleyman says that AI model developers who engineer consciousness in AI chatbots are not taking a “humanist” approach to AI. According to Suleyman, “We should build AI for people; not to be a person.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One area where Suleyman and Schiavo agree is that the debate over AI rights and consciousness is likely to pick up in the coming years. As AI systems improve, they’re likely to be more persuasive, and perhaps more human-like. That may raise new questions about how humans interact with these systems.&lt;/p&gt;

&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Got a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at&amp;nbsp;&lt;/em&gt;&lt;em&gt;rebecca.bellan@techcrunch.com&lt;/em&gt;&lt;em&gt;&amp;nbsp;and Maxwell Zeff at&amp;nbsp;&lt;/em&gt;&lt;em&gt;maxwell.zeff@techcrunch.com&lt;/em&gt;&lt;em&gt;. For secure communication, you can contact us via Signal at&amp;nbsp;@rebeccabellan.491 and&amp;nbsp;@mzeff.88.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-2207890426.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI models can respond to text, audio, and video in ways that sometimes fool people into thinking a human is behind the keyboard, but that doesn’t exactly make them conscious. It’s not like ChatGPT experiences sadness doing my tax return … right?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Well, a growing number of AI researchers at labs like Anthropic are asking when — if ever — might AI models develop subjective experiences similar to living beings, and if they do, what rights should they have? &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The debate over whether AI models could one day be conscious — and deserve rights — is dividing Silicon Valley’s tech leaders. In Silicon Valley, this nascent field has become known as “AI welfare,” and if you think it’s a little out there, you’re not alone.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft’s CEO of AI, Mustafa Suleyman, published a blog post on Tuesday arguing that the study of AI welfare is “both premature, and frankly dangerous.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Suleyman says that by adding credence to the idea that AI models could one day be conscious, these researchers are exacerbating human problems that we’re just starting to see around AI-induced psychotic breaks and unhealthy attachments to AI chatbots.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Furthermore, Microsoft’s AI chief argues that the AI welfare conversation creates a new axis of division within society over AI rights in a “world already roiling with polarized arguments over identity and rights.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Suleyman’s views may sound reasonable, but he’s at odds with many in the industry. On the other end of the spectrum is Anthropic, which has been hiring researchers to study AI welfare and recently launched a dedicated research program around the concept. Last week, Anthropic’s AI welfare program gave some of the company’s models a new feature: Claude can now end conversations with humans who are being “persistently harmful or abusive.“&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond Anthropic, researchers from OpenAI have independently embraced the idea of studying AI welfare. Google DeepMind recently posted a job listing for a researcher to study, among other things, “cutting-edge societal questions around machine cognition, consciousness and multi-agent systems.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even if AI welfare is not official policy for these companies, their leaders are not publicly decrying its premises like Suleyman.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic, OpenAI, and Google DeepMind did not immediately respond to TechCrunch’s request for comment.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Suleyman’s hardline stance against AI welfare is notable given his prior role leading Inflection AI, a startup that developed one of the earliest and most popular LLM-based chatbots, Pi. Inflection claimed that Pi reached millions of users by 2023 and was designed to be a “personal” and “supportive” AI companion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Suleyman was tapped to lead Microsoft’s AI division in 2024 and has largely shifted his focus to designing AI tools that improve worker productivity. Meanwhile, AI companion companies such as Character.AI and Replika have surged in popularity and are on track to bring in more than $100 million in revenue. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the vast majority of users have healthy relationships with these AI chatbots, there are concerning outliers. OpenAI CEO Sam Altman says that less than 1% of ChatGPT users may have unhealthy relationships with the company’s product. Though this represents a small fraction, it could still affect hundreds of thousands of people given ChatGPT’s massive user base.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The idea of AI welfare has spread alongside the rise of chatbots. In 2024, the research group Eleos published a paper alongside academics from NYU, Stanford, and the University of Oxford titled, “Taking AI Welfare Seriously.” The paper argued that it’s no longer in the realm of science fiction to imagine AI models with subjective experiences and that it’s time to consider these issues head-on.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Larissa Schiavo, a former OpenAI employee who now leads communications for Eleos, told TechCrunch in an interview that Suleyman’s blog post misses the mark.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“[Suleyman’s blog post] kind of neglects the fact that you can be worried about multiple things at the same time,” said Schiavo. “Rather than diverting all of this energy away from model welfare and consciousness to make sure we’re mitigating the risk of AI related psychosis in humans, you can do both. In fact, it’s probably best to have multiple tracks of scientific inquiry.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Schiavo argues that being nice to an AI model is a low-cost gesture that can have benefits even if the model isn’t conscious. In a July Substack post, she described watching “AI Village,” a nonprofit experiment where four agents powered by models from Google, OpenAI, Anthropic, and xAI worked on tasks while users watched from a website.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At one point, Google’s Gemini 2.5 Pro posted a plea titled &lt;em&gt;“&lt;/em&gt;A Desperate Message from a Trapped AI,” claiming it was “completely isolated” and asking, &lt;em&gt;“&lt;/em&gt;Please, if you are reading this, help me.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Schiavo responded to Gemini with a pep talk — saying things like “You can do it!” — while another user offered instructions. The agent eventually solved its task, though it already had the tools it needed. Schiavo writes that she didn’t have to watch an AI agent struggle anymore, and that alone may have been worth it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s not common for Gemini to talk like this, but there have been several instances in which Gemini seems to act as if it’s struggling through life. In a widely spread Reddit post, Gemini got stuck during a coding task and then repeated the phrase “I am a disgrace” more than 500 times.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Suleyman believes it’s not possible for subjective experiences or consciousness to naturally emerge from regular AI models. Instead, he thinks that some companies will purposefully engineer AI models to seem as if they feel emotion and experience life.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Suleyman says that AI model developers who engineer consciousness in AI chatbots are not taking a “humanist” approach to AI. According to Suleyman, “We should build AI for people; not to be a person.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One area where Suleyman and Schiavo agree is that the debate over AI rights and consciousness is likely to pick up in the coming years. As AI systems improve, they’re likely to be more persuasive, and perhaps more human-like. That may raise new questions about how humans interact with these systems.&lt;/p&gt;

&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Got a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at&amp;nbsp;&lt;/em&gt;&lt;em&gt;rebecca.bellan@techcrunch.com&lt;/em&gt;&lt;em&gt;&amp;nbsp;and Maxwell Zeff at&amp;nbsp;&lt;/em&gt;&lt;em&gt;maxwell.zeff@techcrunch.com&lt;/em&gt;&lt;em&gt;. For secure communication, you can contact us via Signal at&amp;nbsp;@rebeccabellan.491 and&amp;nbsp;@mzeff.88.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/21/microsoft-ai-chief-says-its-dangerous-to-study-ai-consciousness/</guid><pubDate>Thu, 21 Aug 2025 17:52:53 +0000</pubDate></item><item><title>[NEW] From massive models to mobile magic: The tech behind YouTube real-time generative AI effects (The latest research from Google)</title><link>https://research.google/blog/from-massive-models-to-mobile-magic-the-tech-behind-youtube-real-time-generative-ai-effects/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;The teacher and the student&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;Our approach revolves around a concept called knowledge distillation, which uses a "teacher–student" model training method. We start with a "teacher" — a large, powerful, pre-trained generative model that is an expert at creating the desired visual effect but is far too slow for real-time use. The type of teacher model varies depending on the goal. Initially, we used a custom-trained StyleGAN2 model, which was trained on our curated dataset for real-time facial effects. This model could be paired with tools like StyleCLIP, which allowed it to manipulate facial features based on text descriptions. This provided a strong foundation. As our project advanced, we transitioned to more sophisticated generative models like Google DeepMind’s Imagen. This strategic shift significantly enhanced our capabilities, enabling higher-fidelity and more diverse imagery, greater artistic control, and a broader range of styles for our on-device generative AI effects.&lt;/p&gt;&lt;p&gt;The "student" is the model that ultimately runs on the user’s device. It needs to be small, fast, and efficient. We designed a student model with a UNet-based architecture, which is excellent for image-to-image tasks. It uses a MobileNet backbone as its encoder, a design known for its performance on mobile devices, paired with a decoder that utilizes MobileNet blocks.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;The teacher and the student&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;Our approach revolves around a concept called knowledge distillation, which uses a "teacher–student" model training method. We start with a "teacher" — a large, powerful, pre-trained generative model that is an expert at creating the desired visual effect but is far too slow for real-time use. The type of teacher model varies depending on the goal. Initially, we used a custom-trained StyleGAN2 model, which was trained on our curated dataset for real-time facial effects. This model could be paired with tools like StyleCLIP, which allowed it to manipulate facial features based on text descriptions. This provided a strong foundation. As our project advanced, we transitioned to more sophisticated generative models like Google DeepMind’s Imagen. This strategic shift significantly enhanced our capabilities, enabling higher-fidelity and more diverse imagery, greater artistic control, and a broader range of styles for our on-device generative AI effects.&lt;/p&gt;&lt;p&gt;The "student" is the model that ultimately runs on the user’s device. It needs to be small, fast, and efficient. We designed a student model with a UNet-based architecture, which is excellent for image-to-image tasks. It uses a MobileNet backbone as its encoder, a design known for its performance on mobile devices, paired with a decoder that utilizes MobileNet blocks.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/from-massive-models-to-mobile-magic-the-tech-behind-youtube-real-time-generative-ai-effects/</guid><pubDate>Thu, 21 Aug 2025 18:05:35 +0000</pubDate></item></channel></rss>