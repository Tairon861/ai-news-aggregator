<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 16 Sep 2025 18:29:53 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>The looming crackdown on AI companionship (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/16/1123614/the-looming-crackdown-on-ai-companionship/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/GettyImages-901654862.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;As long as there has been AI, there have been people sounding alarms about what it might do to us: rogue superintelligence, mass unemployment, or environmental ruin from data center sprawl. But this week showed that another threat entirely—that of kids forming unhealthy bonds with AI—is the one pulling AI safety out of the academic fringe and into regulators’ crosshairs.&lt;/p&gt;  &lt;p&gt;This has been bubbling for a while. Two high-profile lawsuits filed in the last year, against Character.AI and OpenAI, allege that companion-like behavior in their models contributed to the suicides of two teenagers. A study by US nonprofit Common Sense Media, published in July, found that 72% of teenagers have used AI for companionship. Stories in reputable outlets about “AI psychosis” have highlighted how endless conversations with chatbots can lead people down delusional spirals.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;It’s hard to overstate the impact of these stories. To the public, they are proof that AI is not merely imperfect, but a technology that’s more harmful than helpful. If you doubted that this outrage would be taken seriously by regulators and companies, three things happened this week that might change your mind.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;A California law passes the legislature&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;On Thursday, the California state legislature passed a first-of-its-kind bill. It would require AI companies to include reminders for users they know to be minors that responses are AI generated. Companies would also need to have a protocol for addressing suicide and self-harm and provide annual reports on instances of suicidal ideation in users’ conversations with their chatbots. It was led by Democratic state senator Steve Padilla, passed with heavy bipartisan support, and now awaits Governor Gavin Newsom’s signature.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;There are reasons to be skeptical of the bill’s impact. It doesn’t specify efforts companies should take to identify which users are minors, and lots of AI companies already include referrals to crisis providers when someone is talking about suicide. (In the case of Adam Raine, one of the teenagers whose survivors are suing, his conversations with ChatGPT before his death included this type of information, but the chatbot allegedly went on to give advice related to suicide anyway.)&lt;/p&gt;  &lt;p&gt;Still, it is undoubtedly the most significant of the efforts to rein in companion-like behaviors in AI models, which are in the works in other states too. If the bill becomes law, it would strike a blow to the position OpenAI has taken, which is that “America leads best with clear, nationwide rules, not a patchwork of state or local regulations,” as the company’s chief global affairs officer, Chris Lehane, wrote on LinkedIn last week.&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;The Federal Trade Commission takes aim&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;The very same day, the Federal Trade Commission announced an inquiry into seven companies, seeking information about how they develop companion-like characters, monetize engagement, measure and test the impact of their chatbots, and more. The companies are Google, Instagram, Meta, OpenAI, Snap, X, and Character Technologies, the maker of Character.AI.&lt;/p&gt;  &lt;p&gt;The White House now wields immense, and potentially illegal, political influence over the agency. In March, President Trump fired its lone Democratic commissioner, Rebecca Slaughter. In July, a federal judge ruled that firing illegal, but last week the US Supreme Court temporarily permitted the firing.&lt;/p&gt;  &lt;p&gt;“Protecting kids online is a top priority for the Trump-Vance FTC, and so is fostering innovation in critical sectors of our economy,” said FTC chairman Andrew Ferguson in a press release about the inquiry.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Right now, it’s just that—an inquiry—but the process might (depending on how public the FTC makes its findings) reveal the inner workings of how the companies build their AI companions to keep users coming back again and again.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Sam Altman on suicide cases&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;&lt;em&gt;Also&lt;/em&gt; on the same day (a busy day for AI news), Tucker Carlson published an hour-long interview with OpenAI’s CEO, Sam Altman. It covers a lot of ground—Altman’s battle with Elon Musk, OpenAI’s military customers, conspiracy theories about the death of a former employee—but it also includes the most candid comments Altman’s made so far about the cases of suicide following conversations with AI.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Altman talked about “the tension between user freedom and privacy and protecting vulnerable users” in cases like these. But then he offered up something I hadn’t heard before.&lt;/p&gt;  &lt;p&gt;“I think it’d be very reasonable for us to say that in cases of young people talking about suicide seriously, where we cannot get in touch with parents, we do call the authorities,” he said. “That would be a change.”&lt;/p&gt;  &lt;p&gt;So where does all this go next? For now, it’s clear that—at least in the case of children harmed by AI companionship—companies’ familiar playbook won’t hold. They can no longer deflect responsibility by leaning on privacy, personalization, or “user choice.” Pressure to take a harder line is mounting from state laws, regulators, and an outraged public.&lt;/p&gt; 

 &lt;p&gt;But what will that look like? Politically, the left and right are now paying attention to AI’s harm to children, but their solutions differ. On the right, the proposed solution aligns with the wave of internet age-verification laws that have now been passed in over 20 states. These are meant to shield kids from adult content while defending “family values.” On the left, it’s the revival of stalled ambitions to hold Big Tech accountable through antitrust and consumer-protection powers.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Consensus on the problem is easier than agreement on the cure. As it stands, it looks likely we’ll end up with exactly the patchwork of state and local regulations that OpenAI (and plenty of others) have lobbied against.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;For now, it’s down to companies to decide where to draw the lines. They’re having to decide things like: Should chatbots cut off conversations when users spiral toward self-harm, or would that leave some people worse off? Should they be licensed and regulated like therapists, or treated as entertainment products with warnings? The uncertainty stems from a basic contradiction: Companies have built chatbots to act like caring humans, but they’ve postponed developing the standards and accountability we demand of real caregivers. The clock is now running out.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&amp;nbsp;sign up here.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/GettyImages-901654862.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;As long as there has been AI, there have been people sounding alarms about what it might do to us: rogue superintelligence, mass unemployment, or environmental ruin from data center sprawl. But this week showed that another threat entirely—that of kids forming unhealthy bonds with AI—is the one pulling AI safety out of the academic fringe and into regulators’ crosshairs.&lt;/p&gt;  &lt;p&gt;This has been bubbling for a while. Two high-profile lawsuits filed in the last year, against Character.AI and OpenAI, allege that companion-like behavior in their models contributed to the suicides of two teenagers. A study by US nonprofit Common Sense Media, published in July, found that 72% of teenagers have used AI for companionship. Stories in reputable outlets about “AI psychosis” have highlighted how endless conversations with chatbots can lead people down delusional spirals.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;It’s hard to overstate the impact of these stories. To the public, they are proof that AI is not merely imperfect, but a technology that’s more harmful than helpful. If you doubted that this outrage would be taken seriously by regulators and companies, three things happened this week that might change your mind.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;A California law passes the legislature&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;On Thursday, the California state legislature passed a first-of-its-kind bill. It would require AI companies to include reminders for users they know to be minors that responses are AI generated. Companies would also need to have a protocol for addressing suicide and self-harm and provide annual reports on instances of suicidal ideation in users’ conversations with their chatbots. It was led by Democratic state senator Steve Padilla, passed with heavy bipartisan support, and now awaits Governor Gavin Newsom’s signature.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;There are reasons to be skeptical of the bill’s impact. It doesn’t specify efforts companies should take to identify which users are minors, and lots of AI companies already include referrals to crisis providers when someone is talking about suicide. (In the case of Adam Raine, one of the teenagers whose survivors are suing, his conversations with ChatGPT before his death included this type of information, but the chatbot allegedly went on to give advice related to suicide anyway.)&lt;/p&gt;  &lt;p&gt;Still, it is undoubtedly the most significant of the efforts to rein in companion-like behaviors in AI models, which are in the works in other states too. If the bill becomes law, it would strike a blow to the position OpenAI has taken, which is that “America leads best with clear, nationwide rules, not a patchwork of state or local regulations,” as the company’s chief global affairs officer, Chris Lehane, wrote on LinkedIn last week.&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;The Federal Trade Commission takes aim&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;The very same day, the Federal Trade Commission announced an inquiry into seven companies, seeking information about how they develop companion-like characters, monetize engagement, measure and test the impact of their chatbots, and more. The companies are Google, Instagram, Meta, OpenAI, Snap, X, and Character Technologies, the maker of Character.AI.&lt;/p&gt;  &lt;p&gt;The White House now wields immense, and potentially illegal, political influence over the agency. In March, President Trump fired its lone Democratic commissioner, Rebecca Slaughter. In July, a federal judge ruled that firing illegal, but last week the US Supreme Court temporarily permitted the firing.&lt;/p&gt;  &lt;p&gt;“Protecting kids online is a top priority for the Trump-Vance FTC, and so is fostering innovation in critical sectors of our economy,” said FTC chairman Andrew Ferguson in a press release about the inquiry.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Right now, it’s just that—an inquiry—but the process might (depending on how public the FTC makes its findings) reveal the inner workings of how the companies build their AI companions to keep users coming back again and again.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Sam Altman on suicide cases&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;&lt;em&gt;Also&lt;/em&gt; on the same day (a busy day for AI news), Tucker Carlson published an hour-long interview with OpenAI’s CEO, Sam Altman. It covers a lot of ground—Altman’s battle with Elon Musk, OpenAI’s military customers, conspiracy theories about the death of a former employee—but it also includes the most candid comments Altman’s made so far about the cases of suicide following conversations with AI.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Altman talked about “the tension between user freedom and privacy and protecting vulnerable users” in cases like these. But then he offered up something I hadn’t heard before.&lt;/p&gt;  &lt;p&gt;“I think it’d be very reasonable for us to say that in cases of young people talking about suicide seriously, where we cannot get in touch with parents, we do call the authorities,” he said. “That would be a change.”&lt;/p&gt;  &lt;p&gt;So where does all this go next? For now, it’s clear that—at least in the case of children harmed by AI companionship—companies’ familiar playbook won’t hold. They can no longer deflect responsibility by leaning on privacy, personalization, or “user choice.” Pressure to take a harder line is mounting from state laws, regulators, and an outraged public.&lt;/p&gt; 

 &lt;p&gt;But what will that look like? Politically, the left and right are now paying attention to AI’s harm to children, but their solutions differ. On the right, the proposed solution aligns with the wave of internet age-verification laws that have now been passed in over 20 states. These are meant to shield kids from adult content while defending “family values.” On the left, it’s the revival of stalled ambitions to hold Big Tech accountable through antitrust and consumer-protection powers.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Consensus on the problem is easier than agreement on the cure. As it stands, it looks likely we’ll end up with exactly the patchwork of state and local regulations that OpenAI (and plenty of others) have lobbied against.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;For now, it’s down to companies to decide where to draw the lines. They’re having to decide things like: Should chatbots cut off conversations when users spiral toward self-harm, or would that leave some people worse off? Should they be licensed and regulated like therapists, or treated as entertainment products with warnings? The uncertainty stems from a basic contradiction: Companies have built chatbots to act like caring humans, but they’ve postponed developing the standards and accountability we demand of real caregivers. The clock is now running out.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&amp;nbsp;sign up here.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/16/1123614/the-looming-crackdown-on-ai-companionship/</guid><pubDate>Tue, 16 Sep 2025 09:00:00 +0000</pubDate></item><item><title>Millions turn to AI chatbots for spiritual guidance and confession (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/09/millions-turn-to-ai-chatbots-for-spiritual-guidance-and-confession/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Bible Chat hits 30 million downloads as users seek algorithmic absolution.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="3D-generated image of a crowd of people watching a humanoid robot on a screen." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/robot_church-640x360.jpg" width="640" /&gt;
                  &lt;img alt="3D-generated image of a crowd of people watching a humanoid robot on a screen." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/robot_church-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          gremlin via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Sunday, The New York Times reported that tens of millions of people are confessing secrets to AI chatbots trained on religious texts, with apps like Bible Chat reaching over 30 million downloads and Catholic app Hallow briefly topping Netflix, Instagram, and TikTok in Apple's App Store. In China, people are using DeepSeek to try to decode their fortunes. In her report, Lauren Jackson examined "faith tech" apps that cost users up to $70 annually, with some platforms claiming to channel divine communication directly.&lt;/p&gt;
&lt;p&gt;Some of the apps address what creators describe as an accessibility problem. "You don't want to disturb your pastor at three in the morning," Krista Rogers, a 61-year-old Ohio resident, told the Times about using the YouVersion Bible app and ChatGPT for spiritual questions.&lt;/p&gt;
&lt;p&gt;The report also examines platforms that go beyond simple scriptural guidance. While a service like ChatwithGod operates as a "spiritual advisor," its conversational nature is convincing enough that users often question whether they are speaking directly with a divine being. As its chief executive told the Times, the most frequent question from users is, "Is this actually God I am talking to?"&lt;/p&gt;
&lt;p&gt;The answer, of course, is no. These chatbots operate like other large language models—they generate statistically plausible text based on patterns in training data, not divine words from the heavens. When trained on religious texts, they produce responses that sound spiritually informed but can potentially mislead people with erroneous information or reassurance. Unlike human spiritual advisors, chatbots cannot have your best interests in mind because they don't have a mind: Chatbots are neither people nor supernatural beings.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The fusion of AI and religion isn't entirely new. In 2023, we reported on an experimental ChatGPT-powered church service at St. Paul's Church in Fürth, Germany, where over 300 attendees watched computer-generated avatars deliver a 40-minute sermon. Jonas Simmerlein, the theologian behind that event, framed it as learning to deal with AI's increasing presence in all aspects of life. But while that service was an intentional experiment with congregants aware they were hearing machine-generated text, today's faith tech apps blur the line between human spiritual guidance and algorithmic pattern matching, with millions of users potentially unaware of the distinction.&lt;/p&gt;
&lt;h2&gt;Theological yes-men&lt;/h2&gt;
&lt;p&gt;Many of these spiritual-flavored chatbots run on the same AI language models that run apps like ChatGPT and Gemini. While some companies train these models on religious texts and consult theologians about fine-tuning responses, it's widely known (and even admitted by the companies that make them) that these AI models trend toward outputs that validate users' feelings and ideas. If content-filtering safeguards fail, the tendency to affirm all ideas can lead to dangerous situations for vulnerable users.&lt;/p&gt;
&lt;p&gt;"They're generally affirming. They are generally 'yes men,'" Ryan Beck, chief technology officer at Pray.com, told the Times. While this tendency, called "sycophancy" in the AI industry, has led to life-threatening problems with some users, Beck sees affirmation as beneficial. "Who doesn't need a little affirmation in their life?"&lt;/p&gt;
&lt;p&gt;This validation tendency creates theological complications. Traditional faith practices often involve challenging believers to confront uncomfortable truths, but chatbots avoid this spiritual friction. Heidi Campbell, a Texas A&amp;amp;M professor who studies technology and religion, told The Times that chatbots "tell us what we want to hear," and "it's not using spiritual discernment, it is using data and patterns."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Privacy concerns compound these issues. "I wonder if there isn't a larger danger in pouring your heart out to a chatbot," Catholic priest Fr. Mike Schmitz told The Times. "Is it at some point going to become accessible to other people?" Users share intimate spiritual moments that now exist as data points in corporate servers.&lt;/p&gt;
&lt;p&gt;Some users prefer the chatbots' non-judgmental responses to human religious communities. Delphine Collins, a 43-year-old Detroit preschool teacher, told the Times she found more support on Bible Chat than at her church after sharing her health struggles. "People stopped talking to me. It was horrible."&lt;/p&gt;
&lt;p&gt;App creators maintain that their products supplement rather than replace human spiritual connection, and the apps arrive as approximately 40 million people have left US churches in recent decades. "They aren't going to church like they used to," Beck said. "But it's not that they're less inclined to find spiritual nourishment. It's just that they do it through different modes."&lt;/p&gt;
&lt;p&gt;Different modes indeed. What faith-seeking users may not realize is that each chatbot response emerges fresh from the prompt you provide, with no permanent thread connecting one instance to the next beyond a rolling history of the present conversation and what might be stored as a "memory" in a separate system. When a religious chatbot says, "I'll pray for you," the simulated "I" making that promise ceases to exist the moment the response completes. There's no persistent identity to provide ongoing spiritual guidance, and no memory of your spiritual journey beyond what gets fed back into the prompt with every query.&lt;/p&gt;
&lt;p&gt;But this is spirituality we're talking about, and despite technical realities, many people will believe that the chatbots can give them divine guidance. In matters of faith, contradictory evidence rarely shakes a strong belief once it takes hold, whether that faith is placed in the divine or in what are essentially voices emanating from a roll of loaded dice. For many, there may not be much difference.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Bible Chat hits 30 million downloads as users seek algorithmic absolution.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="3D-generated image of a crowd of people watching a humanoid robot on a screen." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/robot_church-640x360.jpg" width="640" /&gt;
                  &lt;img alt="3D-generated image of a crowd of people watching a humanoid robot on a screen." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/robot_church-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          gremlin via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Sunday, The New York Times reported that tens of millions of people are confessing secrets to AI chatbots trained on religious texts, with apps like Bible Chat reaching over 30 million downloads and Catholic app Hallow briefly topping Netflix, Instagram, and TikTok in Apple's App Store. In China, people are using DeepSeek to try to decode their fortunes. In her report, Lauren Jackson examined "faith tech" apps that cost users up to $70 annually, with some platforms claiming to channel divine communication directly.&lt;/p&gt;
&lt;p&gt;Some of the apps address what creators describe as an accessibility problem. "You don't want to disturb your pastor at three in the morning," Krista Rogers, a 61-year-old Ohio resident, told the Times about using the YouVersion Bible app and ChatGPT for spiritual questions.&lt;/p&gt;
&lt;p&gt;The report also examines platforms that go beyond simple scriptural guidance. While a service like ChatwithGod operates as a "spiritual advisor," its conversational nature is convincing enough that users often question whether they are speaking directly with a divine being. As its chief executive told the Times, the most frequent question from users is, "Is this actually God I am talking to?"&lt;/p&gt;
&lt;p&gt;The answer, of course, is no. These chatbots operate like other large language models—they generate statistically plausible text based on patterns in training data, not divine words from the heavens. When trained on religious texts, they produce responses that sound spiritually informed but can potentially mislead people with erroneous information or reassurance. Unlike human spiritual advisors, chatbots cannot have your best interests in mind because they don't have a mind: Chatbots are neither people nor supernatural beings.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The fusion of AI and religion isn't entirely new. In 2023, we reported on an experimental ChatGPT-powered church service at St. Paul's Church in Fürth, Germany, where over 300 attendees watched computer-generated avatars deliver a 40-minute sermon. Jonas Simmerlein, the theologian behind that event, framed it as learning to deal with AI's increasing presence in all aspects of life. But while that service was an intentional experiment with congregants aware they were hearing machine-generated text, today's faith tech apps blur the line between human spiritual guidance and algorithmic pattern matching, with millions of users potentially unaware of the distinction.&lt;/p&gt;
&lt;h2&gt;Theological yes-men&lt;/h2&gt;
&lt;p&gt;Many of these spiritual-flavored chatbots run on the same AI language models that run apps like ChatGPT and Gemini. While some companies train these models on religious texts and consult theologians about fine-tuning responses, it's widely known (and even admitted by the companies that make them) that these AI models trend toward outputs that validate users' feelings and ideas. If content-filtering safeguards fail, the tendency to affirm all ideas can lead to dangerous situations for vulnerable users.&lt;/p&gt;
&lt;p&gt;"They're generally affirming. They are generally 'yes men,'" Ryan Beck, chief technology officer at Pray.com, told the Times. While this tendency, called "sycophancy" in the AI industry, has led to life-threatening problems with some users, Beck sees affirmation as beneficial. "Who doesn't need a little affirmation in their life?"&lt;/p&gt;
&lt;p&gt;This validation tendency creates theological complications. Traditional faith practices often involve challenging believers to confront uncomfortable truths, but chatbots avoid this spiritual friction. Heidi Campbell, a Texas A&amp;amp;M professor who studies technology and religion, told The Times that chatbots "tell us what we want to hear," and "it's not using spiritual discernment, it is using data and patterns."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Privacy concerns compound these issues. "I wonder if there isn't a larger danger in pouring your heart out to a chatbot," Catholic priest Fr. Mike Schmitz told The Times. "Is it at some point going to become accessible to other people?" Users share intimate spiritual moments that now exist as data points in corporate servers.&lt;/p&gt;
&lt;p&gt;Some users prefer the chatbots' non-judgmental responses to human religious communities. Delphine Collins, a 43-year-old Detroit preschool teacher, told the Times she found more support on Bible Chat than at her church after sharing her health struggles. "People stopped talking to me. It was horrible."&lt;/p&gt;
&lt;p&gt;App creators maintain that their products supplement rather than replace human spiritual connection, and the apps arrive as approximately 40 million people have left US churches in recent decades. "They aren't going to church like they used to," Beck said. "But it's not that they're less inclined to find spiritual nourishment. It's just that they do it through different modes."&lt;/p&gt;
&lt;p&gt;Different modes indeed. What faith-seeking users may not realize is that each chatbot response emerges fresh from the prompt you provide, with no permanent thread connecting one instance to the next beyond a rolling history of the present conversation and what might be stored as a "memory" in a separate system. When a religious chatbot says, "I'll pray for you," the simulated "I" making that promise ceases to exist the moment the response completes. There's no persistent identity to provide ongoing spiritual guidance, and no memory of your spiritual journey beyond what gets fed back into the prompt with every query.&lt;/p&gt;
&lt;p&gt;But this is spirituality we're talking about, and despite technical realities, many people will believe that the chatbots can give them divine guidance. In matters of faith, contradictory evidence rarely shakes a strong belief once it takes hold, whether that faith is placed in the divine or in what are essentially voices emanating from a roll of loaded dice. For many, there may not be much difference.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/09/millions-turn-to-ai-chatbots-for-spiritual-guidance-and-confession/</guid><pubDate>Tue, 16 Sep 2025 11:15:32 +0000</pubDate></item><item><title>The Download: regulators are coming for AI companions, and meet our Innovator of 2025 (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/16/1123695/the-download-regulators-are-coming-for-ai-companions-and-meet-our-innovator-of-2025/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The looming crackdown on AI companionship&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;As long as there has been AI, there have been people sounding alarms about what it might do to us: rogue superintelligence, mass unemployment, or environmental ruin. But another threat entirely—that of kids forming unhealthy bonds with AI—is pulling AI safety out of the academic fringe and into regulators’ crosshairs.&lt;/p&gt;  &lt;p&gt;This has been bubbling for a while. Two high-profile lawsuits filed in the last year, against Character.AI and OpenAI, allege that their models contributed to the suicides of two teenagers. A study published in July, found that 72% of teenagers have used AI for companionship. And stories about “AI psychosis” have highlighted how endless conversations with chatbots can lead people down delusional spirals.&lt;/p&gt; 
 &lt;p&gt;It’s hard to overstate the impact of these stories. To the public, they are proof that AI is not merely imperfect, but harmful. If you doubted that this outrage would be taken seriously by regulators and companies, three things happened this week that might change your mind.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—James O’Donnell&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;If you’re interested in reading more about AI companionship, why not check out:&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;+ AI companions are the final stage of digital addiction—and lawmakers are taking aim. Read the full story.&lt;/p&gt;&lt;p&gt;+ Chatbots are rapidly changing how we connect to each other—and ourselves. We’re never going back. Read the full story.&lt;/p&gt;  &lt;p&gt;+ Why GPT-4o’s sudden shutdown last month left people grieving. Read the full story.&lt;/p&gt;&lt;p&gt;+ An AI chatbot told a user how to kill himself—but the company doesn’t want to “censor” it.&lt;/p&gt;&lt;p&gt;+ OpenAI has released its first research into how using ChatGPT affects people’s emotional well-being. But there’s still a lot we don’t know.&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Meet the designer of the world’s fastest whole-genome sequencing method&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Every year, MIT Technology Review selects one individual whose work we admire to recognize as Innovator of the Year. For 2025, we chose Sneha Goenka, who designed the computations behind the world’s fastest whole-genome sequencing method. Thanks to her work, physicians can now sequence a patient’s genome and diagnose a genetic condition in less than eight hours—an achievement that could transform medical care.&lt;/p&gt;  &lt;p&gt;Register here to join an exclusive subscriber-only Roundtable conversation with Goenka, Leilani Battle, assistant professor at the University of Washington, and our editor in chief Mat Honan at 1pm ET on Tuesday September 23.&lt;/p&gt;   

 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Childhood vaccination rates are falling across the US&lt;/strong&gt;&lt;br /&gt;Much of the country no longer has the means to stop the spread of deadly disease. (NBC News)&lt;br /&gt;+ &lt;em&gt;Take a look at the factors driving vaccine hesitancy. &lt;/em&gt;(WP $)&lt;br /&gt;+ &lt;em&gt;RFK Jr is appointing more vaccine skeptics to the CDC advisory panel&lt;/em&gt;. (Ars Technica)&lt;br /&gt;+ &lt;em&gt;Why US federal health agencies are abandoning mRNA vaccines. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 The US and China have reached a TikTok deal&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Beijing says the spin-off version sold to US investors will still use ByteDance’s algorithm. (FT $)&lt;br /&gt;+ &lt;em&gt;But further details are still pretty scarce. &lt;/em&gt;(WP $)&lt;br /&gt;+ &lt;em&gt;The deal may have been fueled by China’s desire for Trump to visit the country. &lt;/em&gt;(WSJ $)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;3 OpenAI is releasing a version of GPT-5 optimized for agentic coding&lt;br /&gt;It’s a direct rival to Anthropic’s Claude Code and Microsoft’s GitHub Copilot. (TechCrunch)&lt;br /&gt;+ &lt;em&gt;OpenAI says it’s been trained on real-world engineering tasks. &lt;/em&gt;(VentureBeat)&lt;br /&gt;+ &lt;em&gt;The second wave of AI coding is here. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;4&lt;/strong&gt; &lt;strong&gt;The FTC is investigating Ticketmaster’s bot-fighting measures&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;It’s probing whether the platform is doing enough to prevent illegal automated reselling. (Bloomberg $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 Google has created a new privacy-preserving LLM&lt;br /&gt;&lt;/strong&gt;VaultGemma uses a technique called differential privacy to reduce the amount of data AI holds onto. (Ars Technica)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 Space tech firms are fighting it out for NATO contracts&lt;br /&gt;&lt;/strong&gt;Militaries are willing to branch out and strike deals with commercial vendors. (FT $)&lt;br /&gt;+ &lt;em&gt;Why Trump’s “golden dome” missile defense idea is another ripped straight from the movies. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Facebook users are receiving their Cambridge Analytica payouts&lt;/strong&gt;&lt;br /&gt;Don’t spend it all at once! (The Verge)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;8 The future of supercomputing could hinge on moon mining missions&lt;br /&gt;&lt;/strong&gt;Companies are rushing to buy the moon’s resources before mining has even begun. (WP $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 What it’s like living with an AI toy&lt;/strong&gt;&lt;br /&gt;Featuring unsettling conversations galore. (The Guardian)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10 Anthropic’s staff are obsessed with an albino alligator 🐊&lt;/strong&gt;&lt;br /&gt;As luck would have it, he just happens to be called Claude. (WSJ $)&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p class="has-large-font-size"&gt;&lt;strong&gt;“It’s going to mean more infections, more hospitalizations, more disability and more death.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Demetre Daskalakis, former director of the CDC's National Center for Immunization and Respiratory Diseases, explains the probable outcomes of America’s current vaccine policy jumble, the BBC reports.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; 
 &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1123697" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/image_fa8fb9.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Robots are bringing new life to extinct species&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;In the last few years, paleontologists have developed a new trick for turning back time and studying prehistoric animals: building experimental robotic models of them.&lt;/p&gt;&lt;p&gt;In the absence of a living specimen, scientists say, an ambling, flying, swimming, or slithering automaton is the next best thing for studying the behavior of extinct organisms. Here are four examples of robots that are shedding light on creatures of yore.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Shi En Kim&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ New York City is full of natural life, if you know where to look.&lt;br /&gt;+ This photo of Jim Morrison enjoying a beer for breakfast is the epitome of rock ‘n’ roll.&lt;br /&gt;+ How to age like a champion athlete.&lt;br /&gt;+ Would you dare drive the world’s most narrow car?&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The looming crackdown on AI companionship&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;As long as there has been AI, there have been people sounding alarms about what it might do to us: rogue superintelligence, mass unemployment, or environmental ruin. But another threat entirely—that of kids forming unhealthy bonds with AI—is pulling AI safety out of the academic fringe and into regulators’ crosshairs.&lt;/p&gt;  &lt;p&gt;This has been bubbling for a while. Two high-profile lawsuits filed in the last year, against Character.AI and OpenAI, allege that their models contributed to the suicides of two teenagers. A study published in July, found that 72% of teenagers have used AI for companionship. And stories about “AI psychosis” have highlighted how endless conversations with chatbots can lead people down delusional spirals.&lt;/p&gt; 
 &lt;p&gt;It’s hard to overstate the impact of these stories. To the public, they are proof that AI is not merely imperfect, but harmful. If you doubted that this outrage would be taken seriously by regulators and companies, three things happened this week that might change your mind.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—James O’Donnell&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;If you’re interested in reading more about AI companionship, why not check out:&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;+ AI companions are the final stage of digital addiction—and lawmakers are taking aim. Read the full story.&lt;/p&gt;&lt;p&gt;+ Chatbots are rapidly changing how we connect to each other—and ourselves. We’re never going back. Read the full story.&lt;/p&gt;  &lt;p&gt;+ Why GPT-4o’s sudden shutdown last month left people grieving. Read the full story.&lt;/p&gt;&lt;p&gt;+ An AI chatbot told a user how to kill himself—but the company doesn’t want to “censor” it.&lt;/p&gt;&lt;p&gt;+ OpenAI has released its first research into how using ChatGPT affects people’s emotional well-being. But there’s still a lot we don’t know.&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Meet the designer of the world’s fastest whole-genome sequencing method&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Every year, MIT Technology Review selects one individual whose work we admire to recognize as Innovator of the Year. For 2025, we chose Sneha Goenka, who designed the computations behind the world’s fastest whole-genome sequencing method. Thanks to her work, physicians can now sequence a patient’s genome and diagnose a genetic condition in less than eight hours—an achievement that could transform medical care.&lt;/p&gt;  &lt;p&gt;Register here to join an exclusive subscriber-only Roundtable conversation with Goenka, Leilani Battle, assistant professor at the University of Washington, and our editor in chief Mat Honan at 1pm ET on Tuesday September 23.&lt;/p&gt;   

 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Childhood vaccination rates are falling across the US&lt;/strong&gt;&lt;br /&gt;Much of the country no longer has the means to stop the spread of deadly disease. (NBC News)&lt;br /&gt;+ &lt;em&gt;Take a look at the factors driving vaccine hesitancy. &lt;/em&gt;(WP $)&lt;br /&gt;+ &lt;em&gt;RFK Jr is appointing more vaccine skeptics to the CDC advisory panel&lt;/em&gt;. (Ars Technica)&lt;br /&gt;+ &lt;em&gt;Why US federal health agencies are abandoning mRNA vaccines. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 The US and China have reached a TikTok deal&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Beijing says the spin-off version sold to US investors will still use ByteDance’s algorithm. (FT $)&lt;br /&gt;+ &lt;em&gt;But further details are still pretty scarce. &lt;/em&gt;(WP $)&lt;br /&gt;+ &lt;em&gt;The deal may have been fueled by China’s desire for Trump to visit the country. &lt;/em&gt;(WSJ $)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;3 OpenAI is releasing a version of GPT-5 optimized for agentic coding&lt;br /&gt;It’s a direct rival to Anthropic’s Claude Code and Microsoft’s GitHub Copilot. (TechCrunch)&lt;br /&gt;+ &lt;em&gt;OpenAI says it’s been trained on real-world engineering tasks. &lt;/em&gt;(VentureBeat)&lt;br /&gt;+ &lt;em&gt;The second wave of AI coding is here. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;4&lt;/strong&gt; &lt;strong&gt;The FTC is investigating Ticketmaster’s bot-fighting measures&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;It’s probing whether the platform is doing enough to prevent illegal automated reselling. (Bloomberg $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 Google has created a new privacy-preserving LLM&lt;br /&gt;&lt;/strong&gt;VaultGemma uses a technique called differential privacy to reduce the amount of data AI holds onto. (Ars Technica)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 Space tech firms are fighting it out for NATO contracts&lt;br /&gt;&lt;/strong&gt;Militaries are willing to branch out and strike deals with commercial vendors. (FT $)&lt;br /&gt;+ &lt;em&gt;Why Trump’s “golden dome” missile defense idea is another ripped straight from the movies. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Facebook users are receiving their Cambridge Analytica payouts&lt;/strong&gt;&lt;br /&gt;Don’t spend it all at once! (The Verge)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;8 The future of supercomputing could hinge on moon mining missions&lt;br /&gt;&lt;/strong&gt;Companies are rushing to buy the moon’s resources before mining has even begun. (WP $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 What it’s like living with an AI toy&lt;/strong&gt;&lt;br /&gt;Featuring unsettling conversations galore. (The Guardian)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10 Anthropic’s staff are obsessed with an albino alligator 🐊&lt;/strong&gt;&lt;br /&gt;As luck would have it, he just happens to be called Claude. (WSJ $)&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p class="has-large-font-size"&gt;&lt;strong&gt;“It’s going to mean more infections, more hospitalizations, more disability and more death.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Demetre Daskalakis, former director of the CDC's National Center for Immunization and Respiratory Diseases, explains the probable outcomes of America’s current vaccine policy jumble, the BBC reports.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; 
 &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1123697" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/image_fa8fb9.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Robots are bringing new life to extinct species&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;In the last few years, paleontologists have developed a new trick for turning back time and studying prehistoric animals: building experimental robotic models of them.&lt;/p&gt;&lt;p&gt;In the absence of a living specimen, scientists say, an ambling, flying, swimming, or slithering automaton is the next best thing for studying the behavior of extinct organisms. Here are four examples of robots that are shedding light on creatures of yore.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Shi En Kim&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ New York City is full of natural life, if you know where to look.&lt;br /&gt;+ This photo of Jim Morrison enjoying a beer for breakfast is the epitome of rock ‘n’ roll.&lt;br /&gt;+ How to age like a champion athlete.&lt;br /&gt;+ Would you dare drive the world’s most narrow car?&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/16/1123695/the-download-regulators-are-coming-for-ai-companions-and-meet-our-innovator-of-2025/</guid><pubDate>Tue, 16 Sep 2025 12:10:00 +0000</pubDate></item><item><title>[NEW] De-risking investment in AI agents (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/16/1123592/de-risking-investment-in-ai-agents/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;NiCE&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Automation has become a defining force in the customer experience. Between the chatbots that answer our questions and the recommendation systems that shape our choices, AI-driven tools are now embedded in nearly every interaction. But the latest wave of so-called “agentic AI”—systems that can plan, act, and adapt toward a defined goal—promises to push automation even further.&lt;/p&gt;  &lt;p&gt;"Every single person that I've spoken to has at least spoken to some sort of GenAI bot on their phones. They expect experiences to be not scripted. It's almost like we're not improving customer experience, we're getting to the point of what customers expect customer experience to be," says vice president of product management at NICE, Neeraj Verma.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1123596" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/1200x628-social-NiCE-webcast-V2_aa9db7.png" /&gt;&lt;/figure&gt;  &lt;p&gt;For businesses, the potential is transformative: AI agents that can handle complex service interactions, support employees in real time, and scale seamlessly as customer demands shift. But the move from scripted, deterministic flows to non-deterministic, generative systems brings new challenges. How can you test something that doesn’t always respond the same way twice? How can you balance safety and flexibility when giving an AI system access to core infrastructure? And how can you manage cost, transparency, and ethical risk while still pursuing meaningful returns?&lt;/p&gt;  &lt;p&gt;These solutions will determine how, and how quickly, companies embrace the next era of customer experience technology.&lt;/p&gt; 
 &lt;p&gt;Verma argues that the story of customer experience automation over the past decade has been one of shifting expectations—from rigid, deterministic flows to flexible, generative systems. Along the way, businesses have had to rethink how they mitigate risk, implement guardrails, and measure success. The future, Verma suggests, belongs to organizations that focus on outcome-oriented design: tools that work transparently, safely, and at scale.&lt;/p&gt;  &lt;p&gt;“I believe that the big winners are going to be the use case companies, the applied AI companies,” says Verma.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Watch the webcast now.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;NiCE&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Automation has become a defining force in the customer experience. Between the chatbots that answer our questions and the recommendation systems that shape our choices, AI-driven tools are now embedded in nearly every interaction. But the latest wave of so-called “agentic AI”—systems that can plan, act, and adapt toward a defined goal—promises to push automation even further.&lt;/p&gt;  &lt;p&gt;"Every single person that I've spoken to has at least spoken to some sort of GenAI bot on their phones. They expect experiences to be not scripted. It's almost like we're not improving customer experience, we're getting to the point of what customers expect customer experience to be," says vice president of product management at NICE, Neeraj Verma.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1123596" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/1200x628-social-NiCE-webcast-V2_aa9db7.png" /&gt;&lt;/figure&gt;  &lt;p&gt;For businesses, the potential is transformative: AI agents that can handle complex service interactions, support employees in real time, and scale seamlessly as customer demands shift. But the move from scripted, deterministic flows to non-deterministic, generative systems brings new challenges. How can you test something that doesn’t always respond the same way twice? How can you balance safety and flexibility when giving an AI system access to core infrastructure? And how can you manage cost, transparency, and ethical risk while still pursuing meaningful returns?&lt;/p&gt;  &lt;p&gt;These solutions will determine how, and how quickly, companies embrace the next era of customer experience technology.&lt;/p&gt; 
 &lt;p&gt;Verma argues that the story of customer experience automation over the past decade has been one of shifting expectations—from rigid, deterministic flows to flexible, generative systems. Along the way, businesses have had to rethink how they mitigate risk, implement guardrails, and measure success. The future, Verma suggests, belongs to organizations that focus on outcome-oriented design: tools that work transparently, safely, and at scale.&lt;/p&gt;  &lt;p&gt;“I believe that the big winners are going to be the use case companies, the applied AI companies,” says Verma.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Watch the webcast now.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/16/1123592/de-risking-investment-in-ai-agents/</guid><pubDate>Tue, 16 Sep 2025 13:00:00 +0000</pubDate></item><item><title>[NEW] Google launches new protocol for agent-driven purchases (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/16/google-launches-new-protocol-for-agent-driven-purchases/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/08/GettyImages-88622588.jpg?resize=1200,870" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Tuesday, Google announced a new open protocol for purchases initiated by AI agents — automated software programs that can shop and make decisions on behalf of users —  with backing from more than 60 merchants and financial institutions. Called the Agent Payments Protocol (AP2), the system is meant to be interoperable between AI platforms, payment systems and vendors, providing a traceable paper trail for each transaction.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a post announcing the protocol, Google executives emphasized their commitment to openness. “We are committed to evolving this protocol in an open, collaborative process, including through standards bodies, and&amp;nbsp; invite the entire payments and technology community to build this future with us,” wrote Stavan Parikh and Rao Surapaneni, who are VPs at Google and Google Cloud, respectively.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The full specification for AP2 was posted to GitHub in conjunction with the announcement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The protocol is built for a future in which AI agents routinely shop for products on customers’ behalf, and engage in complex real-time interactions with retailers’ AI agents. One example in Google’s post imagines a chatbot user asking their agent to shop for a bike trip, which triggers a spontaneous time-sensitive bundle offer from a bike shop’s agent.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In another example, a user asks for travel and lodging for a weekend vacation, giving only the dates, location and budget. “The agent can then interact with both airline and hotel agents, as well as online travel agencies and booking platforms,” the post explains, “and once it finds a combination that fits the budget, it can execute both cryptographically-signed bookings simultaneously.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Enabling that kind of transaction is complex, from both a technological and social standpoint. AP2 requires agents to register two separate approvals before a purchase can be made: first the “intent mandate” (essentially telling the AI, “I’m looking for a polka dot neck tie”), which enables the agent to search for a specific item and negotiate with sellers; then the “cart mandate,” which gives final approval for a purchase once a specific item has been found.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The protocol also contains a provision for fully automated purchases, in which the agent is permitted to automatically generate a cart mandate once an item is found. Those circumstances require a more detailed intent mandate, specifying price limits, timing, and other rules of engagement. In either case, the goal is to maintain an auditable trail that can be re-examined in cases of fraud.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In collaboration with cryptocurrency outfits Coinbase, Metamask and the Ethereum foundation, Google also produced an extension that would integrate the cryptocurrency-oriented x402 protocol, allowing for AI-driven purchasing from crypto wallets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A number of other tech companies are working on their own agentic purchasing systems — most notably Perplexity, which allows for a Buy With Pro service in its agentic browser. The payment provider Stripe also produces software tools for agentic purchasing on its platform, though they are not as comprehensive as AP2.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Like any protocol, the impact of AP2 will depend on its support from other players in the ecosystem — most notably, developers building agentic purchasing systems. But AP2 has already won the support of major financial providers like Mastercard, American Express and PayPal, giving the protocol a significant immediate footprint.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/08/GettyImages-88622588.jpg?resize=1200,870" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Tuesday, Google announced a new open protocol for purchases initiated by AI agents — automated software programs that can shop and make decisions on behalf of users —  with backing from more than 60 merchants and financial institutions. Called the Agent Payments Protocol (AP2), the system is meant to be interoperable between AI platforms, payment systems and vendors, providing a traceable paper trail for each transaction.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a post announcing the protocol, Google executives emphasized their commitment to openness. “We are committed to evolving this protocol in an open, collaborative process, including through standards bodies, and&amp;nbsp; invite the entire payments and technology community to build this future with us,” wrote Stavan Parikh and Rao Surapaneni, who are VPs at Google and Google Cloud, respectively.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The full specification for AP2 was posted to GitHub in conjunction with the announcement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The protocol is built for a future in which AI agents routinely shop for products on customers’ behalf, and engage in complex real-time interactions with retailers’ AI agents. One example in Google’s post imagines a chatbot user asking their agent to shop for a bike trip, which triggers a spontaneous time-sensitive bundle offer from a bike shop’s agent.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In another example, a user asks for travel and lodging for a weekend vacation, giving only the dates, location and budget. “The agent can then interact with both airline and hotel agents, as well as online travel agencies and booking platforms,” the post explains, “and once it finds a combination that fits the budget, it can execute both cryptographically-signed bookings simultaneously.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Enabling that kind of transaction is complex, from both a technological and social standpoint. AP2 requires agents to register two separate approvals before a purchase can be made: first the “intent mandate” (essentially telling the AI, “I’m looking for a polka dot neck tie”), which enables the agent to search for a specific item and negotiate with sellers; then the “cart mandate,” which gives final approval for a purchase once a specific item has been found.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The protocol also contains a provision for fully automated purchases, in which the agent is permitted to automatically generate a cart mandate once an item is found. Those circumstances require a more detailed intent mandate, specifying price limits, timing, and other rules of engagement. In either case, the goal is to maintain an auditable trail that can be re-examined in cases of fraud.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In collaboration with cryptocurrency outfits Coinbase, Metamask and the Ethereum foundation, Google also produced an extension that would integrate the cryptocurrency-oriented x402 protocol, allowing for AI-driven purchasing from crypto wallets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A number of other tech companies are working on their own agentic purchasing systems — most notably Perplexity, which allows for a Buy With Pro service in its agentic browser. The payment provider Stripe also produces software tools for agentic purchasing on its platform, though they are not as comprehensive as AP2.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Like any protocol, the impact of AP2 will depend on its support from other players in the ecosystem — most notably, developers building agentic purchasing systems. But AP2 has already won the support of major financial providers like Mastercard, American Express and PayPal, giving the protocol a significant immediate footprint.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/16/google-launches-new-protocol-for-agent-driven-purchases/</guid><pubDate>Tue, 16 Sep 2025 13:00:00 +0000</pubDate></item><item><title>[NEW] This $30M startup built a dog crate-sized robot factory that learns by watching humans (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/16/this-30m-startup-built-a-dog-crate-sized-robot-factory-that-learns-by-watching-humans/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/MicroFactory_Cofounders-Victor-Petrenko-and-Igor-Kulakov.png?resize=1200,1033" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;While many robotics companies are building human-sized robots, or working to automate entire factories, MicroFactory is instead trying to think big by building small.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;San Francisco-based MicroFactory built a general-purpose, tabletop manufacturing kit that’s about the size of my Siberian Husky’s dog crate. This compact factory includes two robotic arms and can be trained by human demonstration, as well as through AI.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“General purpose robots are good, but it’s not necessary [to] be humanoid,” said Igor Kulakov, the co-founder and CEO of MicroFactory, in an interview with TechCrunch. “We decided to design robots from scratch that will still be general purpose but not in human shape, and this way, it can be done much simpler, much easier, in hardware and on the AI side.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Rather than selling individual robotic arms, MicroFactory’s system comes as an enclosed but transparent workstation, allowing users to watch the manufacturing process in real time. The compact factory-in-a-box is designed for precision tasks like circuit board assembly, component soldering, and cable routing. Users can train the robots by physically guiding the arms through complex motions — a hands-on approach that Kulakov says works faster than traditional AI programming for intricate manufacturing sequences.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Usually it takes couple hours, but in this way, the robot much better understands what it should do,” Kulakov said. “When you hire people, we still need to spend time, like a week or something, to instruct these people to then supervise their work. A manufacturing company, they already have this time and resources to spend, and it will be much easier to train a model and to make it work in this way.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kulakov’s experience with traditional manufacturing helped spark the idea behind MicroFactory.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He and his co-founder, Viktor Petrenko, used to run bitLighter, a manufacturing business that made portable lighting equipment for photographers. Kulakov said it was difficult to train new employees on how to complete the manufacturing process correctly. When advancements in AI made it seem possible to automate this type of work, they decided to jump on the opportunity.&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Kulakov and Petrenko launched MicroFactory in 2024. It took them about five months to build their prototype. Now the company has hundreds of preorders from customers looking to use the machines for various applications, including assembling electronics and even processing snails to be shipped to France for escargot.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;MicroFactory just raised a $1.5 million pre-seed funding round that included investors like executives from the AI company Hugging Face and investor-entrepreneur Naval Ravikant. The round values the young startup at a $30 million post-money valuation.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kulakov said the company plans to use the funding to build and ship out its units. The company is currently converting its prototype into a commercial product that it hopes to begin shipping in about two months.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company also plans to make some hires and continue improving its technology, including the AI models running under the hood. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our growth is related to building hardware, so we set the goal to increase it 10x each year,” Kulakov said. “In the first year, we want to produce 1,000 robots, [about] three per day, and we have the capability to do this. Then, [we want to] make more and more productions.”&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/MicroFactory_Cofounders-Victor-Petrenko-and-Igor-Kulakov.png?resize=1200,1033" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;While many robotics companies are building human-sized robots, or working to automate entire factories, MicroFactory is instead trying to think big by building small.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;San Francisco-based MicroFactory built a general-purpose, tabletop manufacturing kit that’s about the size of my Siberian Husky’s dog crate. This compact factory includes two robotic arms and can be trained by human demonstration, as well as through AI.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“General purpose robots are good, but it’s not necessary [to] be humanoid,” said Igor Kulakov, the co-founder and CEO of MicroFactory, in an interview with TechCrunch. “We decided to design robots from scratch that will still be general purpose but not in human shape, and this way, it can be done much simpler, much easier, in hardware and on the AI side.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Rather than selling individual robotic arms, MicroFactory’s system comes as an enclosed but transparent workstation, allowing users to watch the manufacturing process in real time. The compact factory-in-a-box is designed for precision tasks like circuit board assembly, component soldering, and cable routing. Users can train the robots by physically guiding the arms through complex motions — a hands-on approach that Kulakov says works faster than traditional AI programming for intricate manufacturing sequences.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Usually it takes couple hours, but in this way, the robot much better understands what it should do,” Kulakov said. “When you hire people, we still need to spend time, like a week or something, to instruct these people to then supervise their work. A manufacturing company, they already have this time and resources to spend, and it will be much easier to train a model and to make it work in this way.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kulakov’s experience with traditional manufacturing helped spark the idea behind MicroFactory.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He and his co-founder, Viktor Petrenko, used to run bitLighter, a manufacturing business that made portable lighting equipment for photographers. Kulakov said it was difficult to train new employees on how to complete the manufacturing process correctly. When advancements in AI made it seem possible to automate this type of work, they decided to jump on the opportunity.&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Kulakov and Petrenko launched MicroFactory in 2024. It took them about five months to build their prototype. Now the company has hundreds of preorders from customers looking to use the machines for various applications, including assembling electronics and even processing snails to be shipped to France for escargot.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;MicroFactory just raised a $1.5 million pre-seed funding round that included investors like executives from the AI company Hugging Face and investor-entrepreneur Naval Ravikant. The round values the young startup at a $30 million post-money valuation.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kulakov said the company plans to use the funding to build and ship out its units. The company is currently converting its prototype into a commercial product that it hopes to begin shipping in about two months.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company also plans to make some hires and continue improving its technology, including the AI models running under the hood. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our growth is related to building hardware, so we set the goal to increase it 10x each year,” Kulakov said. “In the first year, we want to produce 1,000 robots, [about] three per day, and we have the capability to do this. Then, [we want to] make more and more productions.”&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/16/this-30m-startup-built-a-dog-crate-sized-robot-factory-that-learns-by-watching-humans/</guid><pubDate>Tue, 16 Sep 2025 13:00:00 +0000</pubDate></item><item><title>[NEW] Salesforce launches ‘Missionforce,’ a national security-focused business unit (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/16/salesforce-launches-missionforce-a-national-security-focused-business-unit/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/06/GettyImages-1125951338.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Salesforce is increasing its focus on national security. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The customer relationship management giant announced the creation of a new business unit called Missionforce on Tuesday. It will be focused on incorporating AI into defense workflows in three main areas: personnel, logistics, and decision making, according to a company press release.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Missionforce will be helmed by Kendall Collins, who joined Salesforce in 2023 and is currently the chief business officer and chief of staff to Salesforce CEO Marc Benioff. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“With Missionforce, we’ll now bring the best of AI, cloud, and platform technology from the private sector to modernize critical areas including personnel, logistics, and analytics,” Collins said in the press release. “The goal is simple: to help our warfighters and the organizations that support them operate smarter, faster, and more efficiently. There’s never been a more important time to serve those who serve.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Salesforce has held contracts with the U.S. government for years across federal agencies and multiple branches of the U.S. military including the U.S. Army, Navy and Air Force. The company doesn’t publicly disclose how many government contracts it has nor how much revenue it makes from them. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This news is the latest in a wave of tech companies&amp;nbsp;building and offering services specifically for the U.S. government.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched a version of its ChatGPT designed for U.S. government agencies in January. In August, the company announced it struck a deal with the government to give federal agencies access to its enterprise ChatGPT tier for just $1 a year.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Other companies quickly followed suit. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A week later, Anthropic announced it was giving the U.S. government access to its government and enterprise tiers of its Claude chatbot for $1. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google announced “Gemini for Government” in late August which offers their AI services to federal agencies for 47 cents for the first year. &amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/06/GettyImages-1125951338.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Salesforce is increasing its focus on national security. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The customer relationship management giant announced the creation of a new business unit called Missionforce on Tuesday. It will be focused on incorporating AI into defense workflows in three main areas: personnel, logistics, and decision making, according to a company press release.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Missionforce will be helmed by Kendall Collins, who joined Salesforce in 2023 and is currently the chief business officer and chief of staff to Salesforce CEO Marc Benioff. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“With Missionforce, we’ll now bring the best of AI, cloud, and platform technology from the private sector to modernize critical areas including personnel, logistics, and analytics,” Collins said in the press release. “The goal is simple: to help our warfighters and the organizations that support them operate smarter, faster, and more efficiently. There’s never been a more important time to serve those who serve.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Salesforce has held contracts with the U.S. government for years across federal agencies and multiple branches of the U.S. military including the U.S. Army, Navy and Air Force. The company doesn’t publicly disclose how many government contracts it has nor how much revenue it makes from them. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This news is the latest in a wave of tech companies&amp;nbsp;building and offering services specifically for the U.S. government.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched a version of its ChatGPT designed for U.S. government agencies in January. In August, the company announced it struck a deal with the government to give federal agencies access to its enterprise ChatGPT tier for just $1 a year.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Other companies quickly followed suit. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A week later, Anthropic announced it was giving the U.S. government access to its government and enterprise tiers of its Claude chatbot for $1. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google announced “Gemini for Government” in late August which offers their AI services to federal agencies for 47 cents for the first year. &amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/16/salesforce-launches-missionforce-a-national-security-focused-business-unit/</guid><pubDate>Tue, 16 Sep 2025 14:00:00 +0000</pubDate></item><item><title>[NEW] YouTube to use AI to help podcasters promote themselves with clips and Shorts (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/16/youtube-to-use-ai-to-help-podcasters-promote-themselves-with-clips-and-shorts/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Tuesday, YouTube introduced new tools for podcasters at its Made on YouTube live event in New York, including new ways to turn video podcasts into clips and YouTube Shorts and a new feature that helps create videos for audio-only podcasters. Both will be powered by AI and will roll out in the months ahead.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Using AI technology, video podcast creators in the U.S. will be able to create clips more easily with AI suggestions, the company says. This will be available in the “coming months,” while a feature that will transform those clips into YouTube Shorts will arrive early next year.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The addition could give YouTube more fodder to compete with rival short-form video apps, like TikTok and Instagram (Reels), while also directing users to podcasters they might find interesting on YouTube’s larger platform, driving subscriptions and engagement.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046308" height="389" src="https://techcrunch.com/wp-content/uploads/2025/09/Podcast-clips-title-card.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, another new feature also available early next year will help audio podcasters turn their content into video. Using AI, these creators will be able to generate a customizable video for their podcast, the company says. However, the feature will only be available to “select podcasters” when it launches, with a larger expansion planned for later in 2026. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046310" height="389" src="https://techcrunch.com/wp-content/uploads/2025/09/Audio-to-video-title-card.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube has been more focused on building out tools for podcasters over the past several years, making pods a more prominent feature on YouTube’s home page and its YouTube Music service. Meanwhile, Spotify has been inching into its market with added support for video podcasts and other engagement features for podcasters, like comments, polls, and Q&amp;amp;As, as well as monetization tools.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046342" height="374" src="https://techcrunch.com/wp-content/uploads/2025/09/youtube-podcasts-1B.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In February, the company announced YouTube had surpassed 1 billion monthly podcaster viewers. Today, YouTube announced that users, as of July 2025, now consume over 100 million hours of podcasts daily, with more than 30% of those hours starting as a livestream or premiere.&lt;/p&gt;


&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Tuesday, YouTube introduced new tools for podcasters at its Made on YouTube live event in New York, including new ways to turn video podcasts into clips and YouTube Shorts and a new feature that helps create videos for audio-only podcasters. Both will be powered by AI and will roll out in the months ahead.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Using AI technology, video podcast creators in the U.S. will be able to create clips more easily with AI suggestions, the company says. This will be available in the “coming months,” while a feature that will transform those clips into YouTube Shorts will arrive early next year.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The addition could give YouTube more fodder to compete with rival short-form video apps, like TikTok and Instagram (Reels), while also directing users to podcasters they might find interesting on YouTube’s larger platform, driving subscriptions and engagement.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046308" height="389" src="https://techcrunch.com/wp-content/uploads/2025/09/Podcast-clips-title-card.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, another new feature also available early next year will help audio podcasters turn their content into video. Using AI, these creators will be able to generate a customizable video for their podcast, the company says. However, the feature will only be available to “select podcasters” when it launches, with a larger expansion planned for later in 2026. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046310" height="389" src="https://techcrunch.com/wp-content/uploads/2025/09/Audio-to-video-title-card.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube has been more focused on building out tools for podcasters over the past several years, making pods a more prominent feature on YouTube’s home page and its YouTube Music service. Meanwhile, Spotify has been inching into its market with added support for video podcasts and other engagement features for podcasters, like comments, polls, and Q&amp;amp;As, as well as monetization tools.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046342" height="374" src="https://techcrunch.com/wp-content/uploads/2025/09/youtube-podcasts-1B.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In February, the company announced YouTube had surpassed 1 billion monthly podcaster viewers. Today, YouTube announced that users, as of July 2025, now consume over 100 million hours of podcasts daily, with more than 30% of those hours starting as a livestream or premiere.&lt;/p&gt;


&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/16/youtube-to-use-ai-to-help-podcasters-promote-themselves-with-clips-and-shorts/</guid><pubDate>Tue, 16 Sep 2025 14:30:00 +0000</pubDate></item><item><title>[NEW] YouTube rolls out Studio updates, ‘likeness’ detection, lip synced dubs, creator collabs, and more (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/16/youtube-rolls-out-studio-updates-likeness-detection-lip-synced-dubs-creator-collabs-and-more/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;YouTube on Tuesday announced a suite of new features coming to YouTube Studio, the platform over 30 million creators use to manage their channels and track their analytics and revenue every month. At its Made on YouTube event, the company unveiled new and updated tools like an AI-powered chatbot for support, an inspiration tab, title A/B testing features, auto dubbing, likeness detection tools, and more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Many of these features build on tools previously announced or tested with smaller groups, but are now rolling out more broadly.  &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046077" height="389" src="https://techcrunch.com/wp-content/uploads/2025/09/Likeness-detection-title-card-1.jpg?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Of these, the most interesting addition is the likeness detection feature, which was first announced in 2024 and expanded earlier this year to a handful of top creators, like Mr. Beast. Now, the company says it’s bringing the technology to an open beta that will be available to all YouTube Partner Program creators — content creators who meet certain subscriber and view thresholds to monetize their channels. These creators will be able to detect, manage, and authorize the removal of any unauthorized videos using their facial likeness. This will help them protect their image and reputation, and ensure their audience isn’t misled, notes YouTube.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046362" height="381" src="https://techcrunch.com/wp-content/uploads/2025/09/likeness-detection.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Another new tool, Ask Studio, provides an AI-powered chatbot assistant that can guide users and answer questions about their account, like how their latest video is performing or what their audience is saying about their editing style, for example. The tool is meant to offer creators actionable insights that will help them grow their channel, according to YouTube.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;(The feature is different from another “Ask” AI tool for viewers that YouTube tested in late 2023, which allowed users to ask questions about a video they were viewing.)&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046338" height="395" src="https://techcrunch.com/wp-content/uploads/2025/09/youtube-ask-studio.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;One feature getting an update is the Inspiration tab in YouTube Studio. Launched publicly at last year’s event, the tab helps creators leverage AI to spark ideas and come up with video concepts. Now, it’s being updated with new ways to generate ideas, including a list of suggested topics tailored to each creator’s channel and a set of nine responses to every AI prompt, to help creators build out their content plan. The company notes that the topics can be combined, or users can add their own, as they brainstorm. The feature will also explain why it’s making specific suggestions based on audience insights and behavior.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046346" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/Ask-studio-demo.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube Studio will also introduce a way to test and compare up to three different video titles and thumbnails, as an update to its A/B testing feature launched to select creators in 2023 and expanded the following year. Creators have used this testing feature more than 15 million times so far, according to the company (a metric that seems a bit small, given that 20 million videos are uploaded to the site daily).&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046349" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/ab-testing-1.jpg?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, creators will be able to collaborate with up to five others on one video that is shown to the audiences of all the participating creators. While the feature is aimed at boosting engagement and helping creators reach new viewers, the revenue earned from the video will be attributed to the channel that posts the video, YouTube says.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046352" height="384" src="https://techcrunch.com/wp-content/uploads/2025/09/invite-collab.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Screenshot&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company says it will also begin testing lip-syncing technology to make its auto dubbing features more realistic. Today, YouTube supports dubbing content into 20 different languages, and in the coming months, it will improve the translated videos to make them appear more natural by matching lip movements to the dubbed audio. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046357" height="377" src="https://techcrunch.com/wp-content/uploads/2025/09/youtube-autodubbing-1.jpg?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube notes that, on average, viewers spent over 75% of their time viewing the autodubbed video compared to the original, based on a comparison that ran from December 2024 to August 2025.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;YouTube on Tuesday announced a suite of new features coming to YouTube Studio, the platform over 30 million creators use to manage their channels and track their analytics and revenue every month. At its Made on YouTube event, the company unveiled new and updated tools like an AI-powered chatbot for support, an inspiration tab, title A/B testing features, auto dubbing, likeness detection tools, and more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Many of these features build on tools previously announced or tested with smaller groups, but are now rolling out more broadly.  &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046077" height="389" src="https://techcrunch.com/wp-content/uploads/2025/09/Likeness-detection-title-card-1.jpg?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Of these, the most interesting addition is the likeness detection feature, which was first announced in 2024 and expanded earlier this year to a handful of top creators, like Mr. Beast. Now, the company says it’s bringing the technology to an open beta that will be available to all YouTube Partner Program creators — content creators who meet certain subscriber and view thresholds to monetize their channels. These creators will be able to detect, manage, and authorize the removal of any unauthorized videos using their facial likeness. This will help them protect their image and reputation, and ensure their audience isn’t misled, notes YouTube.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046362" height="381" src="https://techcrunch.com/wp-content/uploads/2025/09/likeness-detection.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Another new tool, Ask Studio, provides an AI-powered chatbot assistant that can guide users and answer questions about their account, like how their latest video is performing or what their audience is saying about their editing style, for example. The tool is meant to offer creators actionable insights that will help them grow their channel, according to YouTube.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;(The feature is different from another “Ask” AI tool for viewers that YouTube tested in late 2023, which allowed users to ask questions about a video they were viewing.)&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046338" height="395" src="https://techcrunch.com/wp-content/uploads/2025/09/youtube-ask-studio.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;One feature getting an update is the Inspiration tab in YouTube Studio. Launched publicly at last year’s event, the tab helps creators leverage AI to spark ideas and come up with video concepts. Now, it’s being updated with new ways to generate ideas, including a list of suggested topics tailored to each creator’s channel and a set of nine responses to every AI prompt, to help creators build out their content plan. The company notes that the topics can be combined, or users can add their own, as they brainstorm. The feature will also explain why it’s making specific suggestions based on audience insights and behavior.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046346" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/Ask-studio-demo.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube Studio will also introduce a way to test and compare up to three different video titles and thumbnails, as an update to its A/B testing feature launched to select creators in 2023 and expanded the following year. Creators have used this testing feature more than 15 million times so far, according to the company (a metric that seems a bit small, given that 20 million videos are uploaded to the site daily).&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046349" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/ab-testing-1.jpg?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, creators will be able to collaborate with up to five others on one video that is shown to the audiences of all the participating creators. While the feature is aimed at boosting engagement and helping creators reach new viewers, the revenue earned from the video will be attributed to the channel that posts the video, YouTube says.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046352" height="384" src="https://techcrunch.com/wp-content/uploads/2025/09/invite-collab.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Screenshot&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company says it will also begin testing lip-syncing technology to make its auto dubbing features more realistic. Today, YouTube supports dubbing content into 20 different languages, and in the coming months, it will improve the translated videos to make them appear more natural by matching lip movements to the dubbed audio. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046357" height="377" src="https://techcrunch.com/wp-content/uploads/2025/09/youtube-autodubbing-1.jpg?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube notes that, on average, viewers spent over 75% of their time viewing the autodubbed video compared to the original, based on a comparison that ran from December 2024 to August 2025.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/16/youtube-rolls-out-studio-updates-likeness-detection-lip-synced-dubs-creator-collabs-and-more/</guid><pubDate>Tue, 16 Sep 2025 14:30:00 +0000</pubDate></item><item><title>[NEW] YouTube announces new generative AI tools for Shorts creators (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/16/youtube-announces-new-generative-ai-tools-for-shorts-creators/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;At its Made on YouTube live event on Tuesday, the company unveiled new generative AI tools for Shorts creators. YouTube is bringing a custom version of Google’s text-to-video generative AI model, Veo 3, to Shorts, along with a new remixing tool, an “Edit with AI” feature, and more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The custom version of Veo 3, called Veo 3 Fast, generates outputs with lower latency at 480p, making it easy to create video clips, YouTube says. And now, users can do so with sound for the first time.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This update is rolling out in the United States, the United Kingdom, Canada, Australia, and New Zealand. YouTube plans to expand its functionality to more regions in the future.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046043" height="389" src="https://techcrunch.com/wp-content/uploads/2025/09/Veo-3-in-Shorts-product-mock.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube is also bringing new Veo capabilities to Shorts, including the ability to apply motion from a video to an image. For example, you could animate a still image by making the person in it do a dance from a video. The company says this is possible through technology that captures and transfers movement from one subject to another.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Creators can now also use Veo to apply different styles to their videos, such as pop art or origami. Plus, creators now have the ability to add objects like characters or props with text descriptions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These new capabilities will roll out in the coming months. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046049" height="640" src="https://techcrunch.com/wp-content/uploads/2025/09/Add-motion-product-example.gif?w=480" width="480" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;As for the new remixing tool, creators can turn the dialogue from eligible videos into catchy soundtracks for other Shorts. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“As the world’s largest creative playground, YouTube is where trends are born and where you can draw inspiration from. Imagine hearing a line of dialogue that sparks an idea—a funny phrase, a memorable quote, or a one-of-a-kind sound—and you want to remix it into a new sound,” YouTube’s Director of Product, Shorts and Generative AI Creation, Dina Berrada wrote in a blog post. “With our new Speech to Song remixing tool, you’ll be able to do just that.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube notes that the feature uses Google’s AI music model Lyria 2 to create the soundtrack. Creators will be able to add their own vibe to the song, like “chill,” “danceable,” or “fun.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046053" height="680" src="https://techcrunch.com/wp-content/uploads/2025/09/Screenshot-2025-09-15-at-5.19.05PM.png?w=657" width="657" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company plans to test this feature soon, it says, and will roll it out to more creators in the United States in the coming weeks.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With the new Edit with AI feature, creators can turn their raw footage into first drafts. It transforms raw camera roll footage into a first draft by finding and arranging the best moments, adding music, and transitions. It can even add a voiceover that can react to what’s happening in the video, in either English or Hindi. The idea behind the feature is to give creators a starting point for their Shorts, YouTube says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube is experimenting with Edit with AI on Shorts and in the YouTube Create app, and will expand the feature in the coming weeks in select markets. &lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;At its Made on YouTube live event on Tuesday, the company unveiled new generative AI tools for Shorts creators. YouTube is bringing a custom version of Google’s text-to-video generative AI model, Veo 3, to Shorts, along with a new remixing tool, an “Edit with AI” feature, and more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The custom version of Veo 3, called Veo 3 Fast, generates outputs with lower latency at 480p, making it easy to create video clips, YouTube says. And now, users can do so with sound for the first time.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This update is rolling out in the United States, the United Kingdom, Canada, Australia, and New Zealand. YouTube plans to expand its functionality to more regions in the future.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046043" height="389" src="https://techcrunch.com/wp-content/uploads/2025/09/Veo-3-in-Shorts-product-mock.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube is also bringing new Veo capabilities to Shorts, including the ability to apply motion from a video to an image. For example, you could animate a still image by making the person in it do a dance from a video. The company says this is possible through technology that captures and transfers movement from one subject to another.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Creators can now also use Veo to apply different styles to their videos, such as pop art or origami. Plus, creators now have the ability to add objects like characters or props with text descriptions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These new capabilities will roll out in the coming months. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046049" height="640" src="https://techcrunch.com/wp-content/uploads/2025/09/Add-motion-product-example.gif?w=480" width="480" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;As for the new remixing tool, creators can turn the dialogue from eligible videos into catchy soundtracks for other Shorts. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“As the world’s largest creative playground, YouTube is where trends are born and where you can draw inspiration from. Imagine hearing a line of dialogue that sparks an idea—a funny phrase, a memorable quote, or a one-of-a-kind sound—and you want to remix it into a new sound,” YouTube’s Director of Product, Shorts and Generative AI Creation, Dina Berrada wrote in a blog post. “With our new Speech to Song remixing tool, you’ll be able to do just that.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube notes that the feature uses Google’s AI music model Lyria 2 to create the soundtrack. Creators will be able to add their own vibe to the song, like “chill,” “danceable,” or “fun.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046053" height="680" src="https://techcrunch.com/wp-content/uploads/2025/09/Screenshot-2025-09-15-at-5.19.05PM.png?w=657" width="657" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company plans to test this feature soon, it says, and will roll it out to more creators in the United States in the coming weeks.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With the new Edit with AI feature, creators can turn their raw footage into first drafts. It transforms raw camera roll footage into a first draft by finding and arranging the best moments, adding music, and transitions. It can even add a voiceover that can react to what’s happening in the video, in either English or Hindi. The idea behind the feature is to give creators a starting point for their Shorts, YouTube says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube is experimenting with Edit with AI on Shorts and in the YouTube Create app, and will expand the feature in the coming weeks in select markets. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/16/youtube-announces-new-generative-ai-tools-for-shorts-creators/</guid><pubDate>Tue, 16 Sep 2025 14:30:00 +0000</pubDate></item><item><title>[NEW] How to build AI scaling laws for efficient LLM training and budget maximization (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/how-build-ai-scaling-laws-efficient-llm-training-budget-maximization-0916</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202509/Increasing-LLM-size.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;When researchers are building large language models (LLMs), they aim to maximize performance under a particular computational and financial budget. Since training a model can amount to millions of dollars, developers need to be judicious with cost-impacting decisions about, for instance, the model architecture, optimizers, and training datasets before committing to a model. To anticipate the quality and accuracy of a large model’s predictions, practitioners often turn to scaling laws: using smaller, cheaper models to try to approximate the performance of a much larger target model. The challenge, however, is that there are thousands of ways to create a scaling law.&lt;/p&gt;&lt;p&gt;New work from MIT and MIT-IBM Watson AI Lab researchers addresses this by amassing and releasing a collection of hundreds of models and metrics concerning training and performance to approximate more than a thousand scaling laws. From this, the team developed a meta-analysis and guide for how to select small models and estimate scaling laws for different LLM model families, so that the budget is optimally applied toward generating reliable performance predictions.&lt;/p&gt;&lt;p&gt;“The notion that you might want to try to build mathematical models of the training process is a couple of years old, but I think what was new here is that most of the work that people had been doing before is saying, ‘can we say something post-hoc about what happened when we trained all of these models, so that when we’re trying to figure out how to train a new large-scale model, we can make the best decisions about how to use our compute budget?’” says Jacob Andreas, associate professor in the Department of Electrical Engineering and Computer Science and principal investigator with the MIT-IBM Watson AI Lab.&lt;/p&gt;&lt;p&gt;The research was recently presented at the International Conference on Machine Learning by Andreas, along with MIT-IBM Watson AI Lab researchers Leshem Choshen and Yang Zhang of IBM Research.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Extrapolating performance&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;No matter how you slice it, developing LLMs is an expensive endeavor: from decision-making regarding the numbers of parameters and tokens, data selection and size, and training techniques to determining output accuracy and tuning to the target applications and tasks. Scaling laws offer a way to forecast model behavior by relating a large model’s loss to the performance of smaller, less-costly models from the same family, avoiding the need to fully train every candidate. Mainly, the differences between the smaller models are the number of parameters and token training size. According to Choshen, elucidating scaling laws not only enable better pre-training decisions, but also democratize the field by enabling researchers without vast resources to understand and build effective scaling laws.&lt;/p&gt;&lt;p&gt;The functional form of scaling laws is relatively simple, incorporating components from the small models that capture the number of parameters and their scaling effect, the number of training tokens and their scaling effect, and the baseline performance for the model family of interest. Together, they help researchers estimate a target large model’s performance loss; the smaller the loss, the better the target model’s outputs are likely to be.&lt;/p&gt;&lt;p&gt;These laws allow research teams to weigh trade-offs efficiently and to test how best to allocate limited resources. They’re particularly useful for evaluating scaling of a certain variable, like the number of tokens, and for A/B testing of different pre-training setups.&lt;/p&gt;&lt;p&gt;In general, scaling laws aren’t new; however, in the field of AI, they emerged as models grew and costs skyrocketed. “It’s like scaling laws just appeared at some point in the field,” says Choshen. “They started getting attention, but no one really tested how good they are and what you need to do to make a good scaling law.” Further, scaling laws were themselves also a black box, in a sense. “Whenever people have created scaling laws in the past, it has always just been one model, or one model family, and one dataset, and one developer,” says Andreas. “There hadn’t really been a lot of systematic meta-analysis, as everybody is individually training their own scaling laws. So, [we wanted to know,] are there high-level trends that you see across those things?”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Building better&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;To investigate this, Choshen, Andreas, and Zhang created a large dataset. They collected LLMs from 40 model families, including Pythia, OPT, OLMO, LLaMA, Bloom, T5-Pile, ModuleFormer mixture-of-experts, GPT, and other families. These included 485 unique, pre-trained models, and where available, data about their training checkpoints, computational cost (FLOPs), training epochs, and the seed, along with 1.9 million performance metrics of loss and downstream tasks. The models differed in their architectures, weights, and so on. Using these models, the researchers fit over 1,000 scaling laws and compared their accuracy across architectures, model sizes, and training regimes, as well as testing how the number of models, inclusion of intermediate training checkpoints, and partial training impacted the predictive power of scaling laws to target models. They used measurements of absolute relative error (ARE); this is the difference between the scaling law’s prediction and the observed loss of a large, trained model. With this, the team compared the scaling laws, and after analysis, distilled practical recommendations for AI practitioners about what makes effective scaling laws.&lt;/p&gt;&lt;p&gt;Their shared guidelines walk the developer through steps and options to consider and expectations. First, it’s critical to decide on a compute budget and target model accuracy. The team found that 4 percent ARE is about the best achievable accuracy one could expect due to random seed noise, but up to 20 percent ARE is still useful for decision-making. The researchers identified several factors that improve predictions, like including intermediate training checkpoints, rather than relying only on final losses; this made scaling laws more reliable. However, very early training data before 10 billion tokens are noisy, reduce accuracy, and should be discarded. They recommend prioritizing training more models across a spread of sizes to improve robustness of the scaling law’s prediction, not just larger models; selecting five models provides a solid starting point.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Generally, including larger models improves prediction, but costs can be saved by partially training the target model to about 30 percent of its dataset and using that for extrapolation. If the budget is considerably constrained, developers should consider training one smaller model within the target model family and borrow scaling law parameters from a model family with similar architecture; however, this may not work for encoder–decoder models. Lastly, the MIT-IBM research group found that when scaling laws were compared across model families, there was strong correlation between two sets of hyperparameters, meaning that three of the five hyperparameters explained nearly all of the variation and could likely capture the model behavior. Together, these guidelines provide a systematic approach to making scaling law estimation more efficient, reliable, and accessible for AI researchers working under varying budget constraints.&lt;/p&gt;&lt;p&gt;Several surprises arose during this work: small models partially trained are still very predictive, and further, the intermediate training stages from a fully trained model can be used (as if they are individual models) for prediction of another target model. “Basically, you don’t pay anything in the training, because you already trained the full model, so the half-trained model, for instance, is just a byproduct of what you did,” says Choshen. Another feature Andreas pointed out was that, when aggregated, the variability across model families and different experiments jumped out and was noisier than expected. Unexpectedly, the researchers found that it’s possible to utilize the scaling laws on large models to predict performance down to smaller models. Other research in the field has hypothesized that smaller models were a “different beast” compared to large ones; however, Choshen disagrees. “If they’re totally different, they should have shown totally different behavior, and they don’t.”&lt;/p&gt;&lt;p&gt;While this work focused on model training time, the researchers plan to extend their analysis to model inference. Andreas says it’s not, “how does my model get better as I add more training data or more parameters, but instead as I let it think for longer, draw more samples. I think there are definitely lessons to be learned here about how to also build predictive models of how much thinking you need to do at run time.” He says the theory of inference time scaling laws might become even more critical because, “it’s not like I'm going to train one model and then be done. [Rather,] it’s every time a user comes to me, they’re going to have a new query, and I need to figure out how hard [my model needs] to think to come up with the best answer. So, being able to build those kinds of predictive models, like we’re doing in this paper, is even more important.”&lt;/p&gt;&lt;p&gt;This research was supported, in part, by the MIT-IBM Watson AI Lab and a Sloan Research Fellowship.&amp;nbsp;&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202509/Increasing-LLM-size.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;When researchers are building large language models (LLMs), they aim to maximize performance under a particular computational and financial budget. Since training a model can amount to millions of dollars, developers need to be judicious with cost-impacting decisions about, for instance, the model architecture, optimizers, and training datasets before committing to a model. To anticipate the quality and accuracy of a large model’s predictions, practitioners often turn to scaling laws: using smaller, cheaper models to try to approximate the performance of a much larger target model. The challenge, however, is that there are thousands of ways to create a scaling law.&lt;/p&gt;&lt;p&gt;New work from MIT and MIT-IBM Watson AI Lab researchers addresses this by amassing and releasing a collection of hundreds of models and metrics concerning training and performance to approximate more than a thousand scaling laws. From this, the team developed a meta-analysis and guide for how to select small models and estimate scaling laws for different LLM model families, so that the budget is optimally applied toward generating reliable performance predictions.&lt;/p&gt;&lt;p&gt;“The notion that you might want to try to build mathematical models of the training process is a couple of years old, but I think what was new here is that most of the work that people had been doing before is saying, ‘can we say something post-hoc about what happened when we trained all of these models, so that when we’re trying to figure out how to train a new large-scale model, we can make the best decisions about how to use our compute budget?’” says Jacob Andreas, associate professor in the Department of Electrical Engineering and Computer Science and principal investigator with the MIT-IBM Watson AI Lab.&lt;/p&gt;&lt;p&gt;The research was recently presented at the International Conference on Machine Learning by Andreas, along with MIT-IBM Watson AI Lab researchers Leshem Choshen and Yang Zhang of IBM Research.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Extrapolating performance&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;No matter how you slice it, developing LLMs is an expensive endeavor: from decision-making regarding the numbers of parameters and tokens, data selection and size, and training techniques to determining output accuracy and tuning to the target applications and tasks. Scaling laws offer a way to forecast model behavior by relating a large model’s loss to the performance of smaller, less-costly models from the same family, avoiding the need to fully train every candidate. Mainly, the differences between the smaller models are the number of parameters and token training size. According to Choshen, elucidating scaling laws not only enable better pre-training decisions, but also democratize the field by enabling researchers without vast resources to understand and build effective scaling laws.&lt;/p&gt;&lt;p&gt;The functional form of scaling laws is relatively simple, incorporating components from the small models that capture the number of parameters and their scaling effect, the number of training tokens and their scaling effect, and the baseline performance for the model family of interest. Together, they help researchers estimate a target large model’s performance loss; the smaller the loss, the better the target model’s outputs are likely to be.&lt;/p&gt;&lt;p&gt;These laws allow research teams to weigh trade-offs efficiently and to test how best to allocate limited resources. They’re particularly useful for evaluating scaling of a certain variable, like the number of tokens, and for A/B testing of different pre-training setups.&lt;/p&gt;&lt;p&gt;In general, scaling laws aren’t new; however, in the field of AI, they emerged as models grew and costs skyrocketed. “It’s like scaling laws just appeared at some point in the field,” says Choshen. “They started getting attention, but no one really tested how good they are and what you need to do to make a good scaling law.” Further, scaling laws were themselves also a black box, in a sense. “Whenever people have created scaling laws in the past, it has always just been one model, or one model family, and one dataset, and one developer,” says Andreas. “There hadn’t really been a lot of systematic meta-analysis, as everybody is individually training their own scaling laws. So, [we wanted to know,] are there high-level trends that you see across those things?”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Building better&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;To investigate this, Choshen, Andreas, and Zhang created a large dataset. They collected LLMs from 40 model families, including Pythia, OPT, OLMO, LLaMA, Bloom, T5-Pile, ModuleFormer mixture-of-experts, GPT, and other families. These included 485 unique, pre-trained models, and where available, data about their training checkpoints, computational cost (FLOPs), training epochs, and the seed, along with 1.9 million performance metrics of loss and downstream tasks. The models differed in their architectures, weights, and so on. Using these models, the researchers fit over 1,000 scaling laws and compared their accuracy across architectures, model sizes, and training regimes, as well as testing how the number of models, inclusion of intermediate training checkpoints, and partial training impacted the predictive power of scaling laws to target models. They used measurements of absolute relative error (ARE); this is the difference between the scaling law’s prediction and the observed loss of a large, trained model. With this, the team compared the scaling laws, and after analysis, distilled practical recommendations for AI practitioners about what makes effective scaling laws.&lt;/p&gt;&lt;p&gt;Their shared guidelines walk the developer through steps and options to consider and expectations. First, it’s critical to decide on a compute budget and target model accuracy. The team found that 4 percent ARE is about the best achievable accuracy one could expect due to random seed noise, but up to 20 percent ARE is still useful for decision-making. The researchers identified several factors that improve predictions, like including intermediate training checkpoints, rather than relying only on final losses; this made scaling laws more reliable. However, very early training data before 10 billion tokens are noisy, reduce accuracy, and should be discarded. They recommend prioritizing training more models across a spread of sizes to improve robustness of the scaling law’s prediction, not just larger models; selecting five models provides a solid starting point.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Generally, including larger models improves prediction, but costs can be saved by partially training the target model to about 30 percent of its dataset and using that for extrapolation. If the budget is considerably constrained, developers should consider training one smaller model within the target model family and borrow scaling law parameters from a model family with similar architecture; however, this may not work for encoder–decoder models. Lastly, the MIT-IBM research group found that when scaling laws were compared across model families, there was strong correlation between two sets of hyperparameters, meaning that three of the five hyperparameters explained nearly all of the variation and could likely capture the model behavior. Together, these guidelines provide a systematic approach to making scaling law estimation more efficient, reliable, and accessible for AI researchers working under varying budget constraints.&lt;/p&gt;&lt;p&gt;Several surprises arose during this work: small models partially trained are still very predictive, and further, the intermediate training stages from a fully trained model can be used (as if they are individual models) for prediction of another target model. “Basically, you don’t pay anything in the training, because you already trained the full model, so the half-trained model, for instance, is just a byproduct of what you did,” says Choshen. Another feature Andreas pointed out was that, when aggregated, the variability across model families and different experiments jumped out and was noisier than expected. Unexpectedly, the researchers found that it’s possible to utilize the scaling laws on large models to predict performance down to smaller models. Other research in the field has hypothesized that smaller models were a “different beast” compared to large ones; however, Choshen disagrees. “If they’re totally different, they should have shown totally different behavior, and they don’t.”&lt;/p&gt;&lt;p&gt;While this work focused on model training time, the researchers plan to extend their analysis to model inference. Andreas says it’s not, “how does my model get better as I add more training data or more parameters, but instead as I let it think for longer, draw more samples. I think there are definitely lessons to be learned here about how to also build predictive models of how much thinking you need to do at run time.” He says the theory of inference time scaling laws might become even more critical because, “it’s not like I'm going to train one model and then be done. [Rather,] it’s every time a user comes to me, they’re going to have a new query, and I need to figure out how hard [my model needs] to think to come up with the best answer. So, being able to build those kinds of predictive models, like we’re doing in this paper, is even more important.”&lt;/p&gt;&lt;p&gt;This research was supported, in part, by the MIT-IBM Watson AI Lab and a Sloan Research Fellowship.&amp;nbsp;&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/how-build-ai-scaling-laws-efficient-llm-training-budget-maximization-0916</guid><pubDate>Tue, 16 Sep 2025 15:00:00 +0000</pubDate></item><item><title>[NEW] D-ID acquires Berlin-based video startup Simpleshow (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/16/d-id-acquires-berlin-based-video-startup-simpleshow/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/ai-avatar-simpleshow-2154151760.jpg?resize=1200,826" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Video generation and editing platform D-ID said Tuesday that it has acquired Berlin-based B2B video creation platform Simpleshow. The companies didn’t disclose financial terms of the deal.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Simpleshow’s product will operate under D-ID’s umbrella, and eventually the two platforms will merge, D-ID chief executive Gil Perry told TechCrunch. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Simpleshow, founded in 2008, has raised over $20 million in funding, according to Crunchbase data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup has offices in Berlin, Luxembourg, London, Miami, Singapore, Hong Kong, and Tokyo. As part of the merger, the company will have consolidated offices in Berlin, Tel Aviv, and the United States. D-ID didn’t mention Simpleshow’s team size but said that the combined entity will have 140 employees.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Simpleshow initially approached us for a strategic partnership. We saw that there was synergy between management teams and products,” said Perry. “We felt that we needed to increase our speed in capturing a large [part of the enterprise avatar video] market. We thought acquiring Simpleshow would give us the necessary boost in that.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Both companies are seeing a strong future of digital avatars for different kinds of videos, including training, marketing, and sales. D-ID already has a suite of AI-powered interactive avatars that it offers to its clients. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Simpleshow’s CEO Karsten Boehrs said that when he joined the company over a decade ago, it was largely an agency producing videos for businesses and enterprises.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“To achieve scale and serve more clients internationally, we decided to build a SaaS-based tech platform,” Boehrs told TechCrunch. “One of the first tools we launched was a text-to-video tool for our clients in 2017.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Boehrs added that in the last few years, with the rise of AI, it started conversations with companies like Synthesia for potential partnerships and eventually landed on D-ID to get acquired.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside its product, Simpleshow is also bringing more than 1,500 enterprise clients, including Adobe, Audio, Airbus, Microsoft, Bayer, HP, T-Mobile, McDonald’s, eBay, and Deutsche Bank. D-ID’s Perry mentioned that this will boost the company’s bottom line and bring it closer to profitability.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Going forward, D-ID wants to build interactive training videos, which will let users interrupt a video presented by an avatar and ask them a question or take a quiz. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;D-ID has strong competition for enterprise adoption of digital avatars in companies like Synthesia and Soul Machines. Companies such as Google and McKinsey are also developing solutions to let clients use digital avatars.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;D-ID has raised $60 million in funding to date. The company said it has secured funding to bankroll the acquisition, but it didn’t disclose the money.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/ai-avatar-simpleshow-2154151760.jpg?resize=1200,826" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Video generation and editing platform D-ID said Tuesday that it has acquired Berlin-based B2B video creation platform Simpleshow. The companies didn’t disclose financial terms of the deal.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Simpleshow’s product will operate under D-ID’s umbrella, and eventually the two platforms will merge, D-ID chief executive Gil Perry told TechCrunch. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Simpleshow, founded in 2008, has raised over $20 million in funding, according to Crunchbase data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup has offices in Berlin, Luxembourg, London, Miami, Singapore, Hong Kong, and Tokyo. As part of the merger, the company will have consolidated offices in Berlin, Tel Aviv, and the United States. D-ID didn’t mention Simpleshow’s team size but said that the combined entity will have 140 employees.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Simpleshow initially approached us for a strategic partnership. We saw that there was synergy between management teams and products,” said Perry. “We felt that we needed to increase our speed in capturing a large [part of the enterprise avatar video] market. We thought acquiring Simpleshow would give us the necessary boost in that.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Both companies are seeing a strong future of digital avatars for different kinds of videos, including training, marketing, and sales. D-ID already has a suite of AI-powered interactive avatars that it offers to its clients. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Simpleshow’s CEO Karsten Boehrs said that when he joined the company over a decade ago, it was largely an agency producing videos for businesses and enterprises.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“To achieve scale and serve more clients internationally, we decided to build a SaaS-based tech platform,” Boehrs told TechCrunch. “One of the first tools we launched was a text-to-video tool for our clients in 2017.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Boehrs added that in the last few years, with the rise of AI, it started conversations with companies like Synthesia for potential partnerships and eventually landed on D-ID to get acquired.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside its product, Simpleshow is also bringing more than 1,500 enterprise clients, including Adobe, Audio, Airbus, Microsoft, Bayer, HP, T-Mobile, McDonald’s, eBay, and Deutsche Bank. D-ID’s Perry mentioned that this will boost the company’s bottom line and bring it closer to profitability.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Going forward, D-ID wants to build interactive training videos, which will let users interrupt a video presented by an avatar and ask them a question or take a quiz. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;D-ID has strong competition for enterprise adoption of digital avatars in companies like Synthesia and Soul Machines. Companies such as Google and McKinsey are also developing solutions to let clients use digital avatars.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;D-ID has raised $60 million in funding to date. The company said it has secured funding to bankroll the acquisition, but it didn’t disclose the money.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/16/d-id-acquires-berlin-based-video-startup-simpleshow/</guid><pubDate>Tue, 16 Sep 2025 15:00:00 +0000</pubDate></item><item><title>[NEW] OpenAI will apply new restrictions to ChatGPT users under 18 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/16/openai-will-apply-new-restrictions-to-chatgpt-users-under-18/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2197366846.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI CEO Sam Altman announced on Tuesday a raft of new user policies, including a pledge to significantly change how ChatGPT interacts with users under the age of 18.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We prioritize safety ahead of privacy and freedom for teens,” the post reads. “This is a new and powerful technology, and we believe minors need significant protection.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The changes for underage users deal specifically with conversations involving sexual topics or self-harm. Under the new policy, ChatGPT will be trained to no longer engage in “flirtatious talk” with underage users, and additional guardrails will be placed around discussions of suicide. If an underage user uses ChatGPT to imagine suicidal scenarios, the service will attempt to contact their parents or, in particularly severe cases, local police.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sadly, these scenarios are not hypotheticals. OpenAI is currently facing a wrongful death lawsuit from the parents of Adam Raine, who died by suicide after months of interactions with ChatGPT. Character.AI, another consumer chatbot, is facing a similar lawsuit. While the risks are particularly urgent for underage users considering self-harm, the broader phenomenon of chatbot-fueled delusion has drawn widespread concern, particularly as consumer chatbots have become capable of more sustained and detailed interactions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Along with the content-based restrictions, parents who register an underage user account will have the power to set “blackout hours” in which ChatGPT is not available, a feature that was not previously available.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new ChatGPT policies come on the same day as a Senate Judiciary Committee hearing titled “Examining the Harm of AI Chatbots,” announced by Sen. Josh Hawley (R-MO) in August. Adam Raine’s father is scheduled to speak at the hearing, among other guests.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The hearing will also focus on the findings of a Reuters investigation that unearthed policy documents apparently encouraging sexual conversations with underage users. Meta updated its chatbot policies in the wake of the report.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Separating underage users will be a significant technical challenge, and OpenAI detailed its approach in a separate blog post. The service is “building toward a long-term system to understand whether someone is over or under 18,” but in the many ambiguous cases, the system will default toward the more restrictive rules. For concerned parents, the most reliable way to ensure an underage user is recognized is to link the teen’s account to an existing parent account. This also enables the system to directly alert parents when the teen user is believed to be in distress.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But in the same post, Altman emphasized OpenAI’s ongoing commitment to user privacy and giving adult users broad freedom in how they choose to interact with ChatGPT. “We realize that these principles are in conflict,” the post concludes, “and not everyone will agree with how we are resolving that conflict.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;If you or someone you know needs help, call&amp;nbsp;1-800-273-8255&amp;nbsp;for the&amp;nbsp;National Suicide Prevention Lifeline. You can also text HOME to 741-741 for free, 24-hour support from the&amp;nbsp;Crisis Text Line&lt;/em&gt;,&amp;nbsp;&lt;em&gt;or text or call 988. Outside of the U.S., please visit the&amp;nbsp;International Association for Suicide Prevention&amp;nbsp;for a database of resources.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2197366846.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI CEO Sam Altman announced on Tuesday a raft of new user policies, including a pledge to significantly change how ChatGPT interacts with users under the age of 18.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We prioritize safety ahead of privacy and freedom for teens,” the post reads. “This is a new and powerful technology, and we believe minors need significant protection.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The changes for underage users deal specifically with conversations involving sexual topics or self-harm. Under the new policy, ChatGPT will be trained to no longer engage in “flirtatious talk” with underage users, and additional guardrails will be placed around discussions of suicide. If an underage user uses ChatGPT to imagine suicidal scenarios, the service will attempt to contact their parents or, in particularly severe cases, local police.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sadly, these scenarios are not hypotheticals. OpenAI is currently facing a wrongful death lawsuit from the parents of Adam Raine, who died by suicide after months of interactions with ChatGPT. Character.AI, another consumer chatbot, is facing a similar lawsuit. While the risks are particularly urgent for underage users considering self-harm, the broader phenomenon of chatbot-fueled delusion has drawn widespread concern, particularly as consumer chatbots have become capable of more sustained and detailed interactions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Along with the content-based restrictions, parents who register an underage user account will have the power to set “blackout hours” in which ChatGPT is not available, a feature that was not previously available.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new ChatGPT policies come on the same day as a Senate Judiciary Committee hearing titled “Examining the Harm of AI Chatbots,” announced by Sen. Josh Hawley (R-MO) in August. Adam Raine’s father is scheduled to speak at the hearing, among other guests.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The hearing will also focus on the findings of a Reuters investigation that unearthed policy documents apparently encouraging sexual conversations with underage users. Meta updated its chatbot policies in the wake of the report.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Separating underage users will be a significant technical challenge, and OpenAI detailed its approach in a separate blog post. The service is “building toward a long-term system to understand whether someone is over or under 18,” but in the many ambiguous cases, the system will default toward the more restrictive rules. For concerned parents, the most reliable way to ensure an underage user is recognized is to link the teen’s account to an existing parent account. This also enables the system to directly alert parents when the teen user is believed to be in distress.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But in the same post, Altman emphasized OpenAI’s ongoing commitment to user privacy and giving adult users broad freedom in how they choose to interact with ChatGPT. “We realize that these principles are in conflict,” the post concludes, “and not everyone will agree with how we are resolving that conflict.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;If you or someone you know needs help, call&amp;nbsp;1-800-273-8255&amp;nbsp;for the&amp;nbsp;National Suicide Prevention Lifeline. You can also text HOME to 741-741 for free, 24-hour support from the&amp;nbsp;Crisis Text Line&lt;/em&gt;,&amp;nbsp;&lt;em&gt;or text or call 988. Outside of the U.S., please visit the&amp;nbsp;International Association for Suicide Prevention&amp;nbsp;for a database of resources.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/16/openai-will-apply-new-restrictions-to-chatgpt-users-under-18/</guid><pubDate>Tue, 16 Sep 2025 16:28:55 +0000</pubDate></item><item><title>[NEW] Learn Your Way: Reimagining textbooks with generative AI (The latest research from Google)</title><link>https://research.google/blog/learn-your-way-reimagining-textbooks-with-generative-ai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;Acknowledgements&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;&lt;i&gt;Shout out to our Google Research LearnLM team who have contributed to this work: Alicia Martín, Amir Globerson, Amy Wang, Anirudh Shekhawat, Anisha Choudhury, Anna Iurchenko, Ayça Çakmakli, Ayelet Shasha Evron, Charlie Yang, Courtney Heldreth, Dana Oria, Diana Akrong, Hairong Mu, Ian Li, Ido Cohen, Komal Singh, Lev Borovoi, Lidan Hackmon, Lior Belinsky, Michael Fink, Niv Efron, Preeti Singh, Rena Levitt, Shashank Agarwal, Shay Sharon, Sophie Allweis, Tracey Lee-Joe, Xiaohong Hao, Yael Gold-Zamir, Yishay Mor, Yoav Bar Sinai.&lt;/i&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;Acknowledgements&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;&lt;i&gt;Shout out to our Google Research LearnLM team who have contributed to this work: Alicia Martín, Amir Globerson, Amy Wang, Anirudh Shekhawat, Anisha Choudhury, Anna Iurchenko, Ayça Çakmakli, Ayelet Shasha Evron, Charlie Yang, Courtney Heldreth, Dana Oria, Diana Akrong, Hairong Mu, Ian Li, Ido Cohen, Komal Singh, Lev Borovoi, Lidan Hackmon, Lior Belinsky, Michael Fink, Niv Efron, Preeti Singh, Rena Levitt, Shashank Agarwal, Shay Sharon, Sophie Allweis, Tracey Lee-Joe, Xiaohong Hao, Yael Gold-Zamir, Yishay Mor, Yoav Bar Sinai.&lt;/i&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/learn-your-way-reimagining-textbooks-with-generative-ai/</guid><pubDate>Tue, 16 Sep 2025 17:01:00 +0000</pubDate></item><item><title>[NEW] Waymo’s Tekedra Mawakana on Scaling Self-Driving Beyond the Hype (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/16/waymos-tekedra-mawakana-on-the-truth-behind-autonomous-vehicles-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Autonomous vehicles have long been touted as “just around the corner,” but the reality of bringing self-driving cars to the streets is far from simple. At &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; — October 27–29 at Moscone West in San Francisco — Waymo co-CEO &lt;strong&gt;Tekedra Mawakana&lt;/strong&gt; joins the &lt;strong&gt;Disrupt Stage&lt;/strong&gt;  for a wide-ranging conversation on the true state of AVs and where the industry goes from here. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Tekedra Mawakana" class="wp-image-3032642" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/TC25_-Tekedra-Mawakana-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-inside-the-self-driving-reality-check"&gt;Inside the self-driving reality check&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;While headlines often highlight crashes, controversies, or overblown promises, Mawakana has spent years navigating the real-world path to autonomous mobility. At Disrupt, she’ll dig into what it actually takes to scale AV deployment — from rider safety and public trust to regulation, operations, and competitive pressure from Tesla and others.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This session isn’t about vague timelines or flashy demos. It’s about what’s working, what still needs work, and what it means to bring autonomy to life at scale. Whether you’re a founder, investor, or simply curious about the road ahead, you won’t want to miss it.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Waymo jaguar ipace autonomous vehicle" class="wp-image-2320477" height="453" src="https://techcrunch.com/wp-content/uploads/2022/05/IPACE_3.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Waymo&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-meet-the-leader-behind-the-wheel"&gt;Meet the leader behind the wheel&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Tekedra Mawakana brings more than two decades of experience shaping global strategy at major tech companies. As co-CEO of Waymo, she guides the company’s mission to bring the Waymo Driver to the masses and lead the next generation of autonomous innovation. She also serves on Intuit’s board and advises several technology and social impact ventures.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-the-future-of-mobility-live-at-disrupt"&gt;The future of mobility, live at Disrupt&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Waymo’s story is a central chapter in the future of transportation, and this session offers a rare inside look at the journey behind the headlines. Join us at &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, where 10,000+ startup and VC leaders gather to shape what’s next. &lt;strong&gt;Register today&lt;/strong&gt; and save up to &lt;strong&gt;$650&lt;/strong&gt; before rates rise.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Disrupt 2024 Main Stage" class="wp-image-2953554" height="453" src="https://techcrunch.com/wp-content/uploads/2025/01/Disrupt-2024-main-stage.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kimberly White / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Autonomous vehicles have long been touted as “just around the corner,” but the reality of bringing self-driving cars to the streets is far from simple. At &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; — October 27–29 at Moscone West in San Francisco — Waymo co-CEO &lt;strong&gt;Tekedra Mawakana&lt;/strong&gt; joins the &lt;strong&gt;Disrupt Stage&lt;/strong&gt;  for a wide-ranging conversation on the true state of AVs and where the industry goes from here. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Tekedra Mawakana" class="wp-image-3032642" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/TC25_-Tekedra-Mawakana-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-inside-the-self-driving-reality-check"&gt;Inside the self-driving reality check&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;While headlines often highlight crashes, controversies, or overblown promises, Mawakana has spent years navigating the real-world path to autonomous mobility. At Disrupt, she’ll dig into what it actually takes to scale AV deployment — from rider safety and public trust to regulation, operations, and competitive pressure from Tesla and others.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This session isn’t about vague timelines or flashy demos. It’s about what’s working, what still needs work, and what it means to bring autonomy to life at scale. Whether you’re a founder, investor, or simply curious about the road ahead, you won’t want to miss it.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Waymo jaguar ipace autonomous vehicle" class="wp-image-2320477" height="453" src="https://techcrunch.com/wp-content/uploads/2022/05/IPACE_3.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Waymo&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-meet-the-leader-behind-the-wheel"&gt;Meet the leader behind the wheel&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Tekedra Mawakana brings more than two decades of experience shaping global strategy at major tech companies. As co-CEO of Waymo, she guides the company’s mission to bring the Waymo Driver to the masses and lead the next generation of autonomous innovation. She also serves on Intuit’s board and advises several technology and social impact ventures.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-the-future-of-mobility-live-at-disrupt"&gt;The future of mobility, live at Disrupt&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Waymo’s story is a central chapter in the future of transportation, and this session offers a rare inside look at the journey behind the headlines. Join us at &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, where 10,000+ startup and VC leaders gather to shape what’s next. &lt;strong&gt;Register today&lt;/strong&gt; and save up to &lt;strong&gt;$650&lt;/strong&gt; before rates rise.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Disrupt 2024 Main Stage" class="wp-image-2953554" height="453" src="https://techcrunch.com/wp-content/uploads/2025/01/Disrupt-2024-main-stage.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kimberly White / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/16/waymos-tekedra-mawakana-on-the-truth-behind-autonomous-vehicles-at-techcrunch-disrupt-2025/</guid><pubDate>Tue, 16 Sep 2025 17:35:00 +0000</pubDate></item><item><title>[NEW] Gemini overtakes ChatGPT on App Store, as its Nano Banana AI model drives downloads up 45% (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/16/gemini-overtakes-chatgpt-on-app-store-as-its-nano-banana-ai-model-drives-downloads-up-45/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Gemini’s mobile adoption has been soaring since the August launch of its Nano Banana image editor model, which has received positive reviews, particularly from users who say they can now more easily perform complex edits and create realistic images. The app has climbed to the top of global app stores’ charts and has seen a 45% month-over-month increase in downloads in the month of September so far, according to new data provided by app intelligence firm Appfigures.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Though the month is only half over, Gemini’s app has already gained 12.6 million downloads in September, up from 8.7 million in August. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Before this month, Gemini had only gotten as high as No. 3 on the U.S. App Store on January 28, 2025.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Shortly after Nano Banana’s release, Gemini reached the No. 2 spot on the U.S. App Store on September 8. It then became the No. 1 app on September 12, where it has remained, after knocking OpenAI’s ChatGPT down to No. 2. No other dedicated AI apps are in the top 10 on the App Store at this time. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046478" height="365" src="https://techcrunch.com/wp-content/uploads/2025/09/gemini-nano-banana-ios-downloads-spike.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Gemini also became one of the top five iPhone apps overall in 108 countries globally, Appfigures’ data indicates.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Google Play, Gemini jumped from the No. 26 overall top app in the U.S. on September 8 to become the No. 2 app as of Monday. However, despite Android being Google’s own platform, ChatGPT remains in the top spot as of the time of writing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google has been touting Gemini’s growth, as more mainstream users have been trying out the new image editing features. For instance, Google Gemini and Google Labs VP Josh Woodward shared on X on September 8 that the app had gained 23 million first-time users since the Nano Banana model launched, and those users had shared over 500 million images.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The app’s rapid growth is also driving increases in consumer spending. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of the $6.3 million Gemini generated this year on iOS devices, $1.6 million was from the month of August, with much of that coming in after the Nano Banana model’s release. That’s up 1,291% from January’s figure of $115,000, Appfigures estimates.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The app is also on track to at least match August’s number if not surpass it in September, as Gemini has pulled in $792,000 so far this month — roughly half of August’s total. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This year, Gemini’s app has been downloaded 103.7 million times, and has seen 185.4 million downloads to date since its launch on Android in February 2024 and its expansion to iOS later that year.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Gemini’s mobile adoption has been soaring since the August launch of its Nano Banana image editor model, which has received positive reviews, particularly from users who say they can now more easily perform complex edits and create realistic images. The app has climbed to the top of global app stores’ charts and has seen a 45% month-over-month increase in downloads in the month of September so far, according to new data provided by app intelligence firm Appfigures.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Though the month is only half over, Gemini’s app has already gained 12.6 million downloads in September, up from 8.7 million in August. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Before this month, Gemini had only gotten as high as No. 3 on the U.S. App Store on January 28, 2025.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Shortly after Nano Banana’s release, Gemini reached the No. 2 spot on the U.S. App Store on September 8. It then became the No. 1 app on September 12, where it has remained, after knocking OpenAI’s ChatGPT down to No. 2. No other dedicated AI apps are in the top 10 on the App Store at this time. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3046478" height="365" src="https://techcrunch.com/wp-content/uploads/2025/09/gemini-nano-banana-ios-downloads-spike.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Gemini also became one of the top five iPhone apps overall in 108 countries globally, Appfigures’ data indicates.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Google Play, Gemini jumped from the No. 26 overall top app in the U.S. on September 8 to become the No. 2 app as of Monday. However, despite Android being Google’s own platform, ChatGPT remains in the top spot as of the time of writing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google has been touting Gemini’s growth, as more mainstream users have been trying out the new image editing features. For instance, Google Gemini and Google Labs VP Josh Woodward shared on X on September 8 that the app had gained 23 million first-time users since the Nano Banana model launched, and those users had shared over 500 million images.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The app’s rapid growth is also driving increases in consumer spending. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of the $6.3 million Gemini generated this year on iOS devices, $1.6 million was from the month of August, with much of that coming in after the Nano Banana model’s release. That’s up 1,291% from January’s figure of $115,000, Appfigures estimates.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The app is also on track to at least match August’s number if not surpass it in September, as Gemini has pulled in $792,000 so far this month — roughly half of August’s total. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This year, Gemini’s app has been downloaded 103.7 million times, and has seen 185.4 million downloads to date since its launch on Android in February 2024 and its expansion to iOS later that year.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/16/gemini-overtakes-chatgpt-on-app-store-as-its-nano-banana-ai-model-drives-downloads-up-45/</guid><pubDate>Tue, 16 Sep 2025 18:07:40 +0000</pubDate></item></channel></rss>