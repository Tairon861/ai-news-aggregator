<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 03 Jul 2025 18:31:10 +0000</lastBuildDate><item><title>Don’t let hype about AI agents get ahead of reality (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/03/1119545/dont-let-hype-about-ai-agents-get-ahead-of-reality/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/250627_AIagentstalking.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Google’s recent unveiling of what it calls a “new class of agentic experiences” feels like a turning point. At its I/O 2025 event in May, for example, the company showed off a digital assistant that didn’t just answer questions; it helped work on a bicycle repair by finding a matching user manual, locating a YouTube tutorial, and even calling a local store to ask about a part, all with minimal human nudging. Such capabilities could soon extend far outside the Google ecosystem. The company has introduced an open standard called Agent-to-Agent, or A2A, which aims to let agents from different companies talk to each other and work together.&lt;/p&gt;  &lt;p&gt;The vision is exciting: Intelligent software agents that act like digital coworkers, booking your flights, rescheduling meetings, filing expenses, and talking to each other behind the scenes to get things done. But if we’re not careful, we’re going to derail the whole idea before it has a chance to deliver real benefits. As with many tech trends, there’s a risk of hype racing ahead of reality. And when expectations get out of hand, a backlash isn’t far behind.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;Let’s start with the term “agent” itself. Right now, it’s being slapped on everything from simple scripts to sophisticated AI workflows. There’s no shared definition, which leaves plenty of room for companies to market basic automation as something much more advanced. That kind of “agentwashing” doesn’t just confuse customers; it invites disappointment. We don’t necessarily need a rigid standard, but we do need clearer expectations about what these systems are supposed to do, how autonomously they operate, and how reliably they perform.&lt;/p&gt;  &lt;p&gt;And reliability is the next big challenge. Most of today’s agents are powered by large language models (LLMs), which generate probabilistic responses. These systems are powerful, but they’re also unpredictable. They can make things up, go off track, or fail in subtle ways—especially when they’re asked to complete multistep tasks, pulling in external tools and chaining LLM responses together. A recent example: Users of Cursor, a popular AI programming assistant, were told by an automated support agent that they couldn’t use the software on more than one device. There were widespread complaints and reports of users canceling their subscriptions. But it turned out the policy didn’t exist. The AI had invented it.&lt;/p&gt; 
 &lt;p&gt;In enterprise settings, this kind of mistake could create immense damage. We need to stop treating LLMs as standalone products and start building complete systems around them—systems that account for uncertainty, monitor outputs, manage costs, and layer in guardrails for safety and accuracy. These measures can help ensure that the output adheres to the requirements expressed by the user, obeys the company’s policies regarding access to information, respects privacy issues, and so on. Some companies, including AI21 (which I cofounded and which has received funding from Google), are already moving in that direction, wrapping language models in more deliberate, structured architectures. Our latest launch, Maestro, is designed for enterprise reliability, combining LLMs with company data, public information, and other tools to ensure dependable outputs.&lt;/p&gt;  &lt;p&gt;Still, even the smartest agent won’t be useful in a vacuum. For the agent model to work, different agents need to cooperate (booking your travel, checking the weather, submitting your expense report) without constant human supervision. That’s where Google’s A2A protocol comes in. It’s meant to be a universal language that lets agents share what they can do and divide up tasks. In principle, it’s a great idea.&lt;/p&gt;&lt;p&gt;In practice, A2A still falls short. It defines how agents talk to each other, but not what they actually mean. If one agent says it can provide “wind conditions,” another has to guess whether that’s useful for evaluating weather on a flight route. Without a shared vocabulary or context, coordination becomes brittle. We’ve seen this problem before in distributed computing. Solving it at scale is far from trivial.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt;&lt;p&gt;There’s also the assumption that agents are naturally cooperative. That may hold inside Google or another single company’s ecosystem, but in the real world, agents will represent different vendors, customers, or even competitors. For example, if my travel planning agent is requesting price quotes from your airline booking agent, and your agent is incentivized to favor certain airlines, my agent might not be able to get me the best or least expensive itinerary. Without some way to align incentives through contracts, payments, or game-theoretic mechanisms, expecting seamless collaboration may be wishful thinking.&lt;/p&gt;  &lt;p&gt;None of these issues are insurmountable. Shared semantics can be developed. Protocols can evolve. Agents can be taught to negotiate and collaborate in more sophisticated ways. But these problems won’t solve themselves, and if we ignore them, the term “agent” will go the way of other overhyped tech buzzwords. Already, some CIOs are rolling their eyes when they hear it.&lt;/p&gt;  &lt;p&gt;That’s a warning sign. We don’t want the excitement to paper over the pitfalls, only to let developers and users discover them the hard way and develop a negative perspective on the whole endeavor. That would be a shame. The potential here is real. But we need to match the ambition with thoughtful design, clear definitions, and realistic expectations. If we can do that, agents won’t just be another passing trend; they could become the backbone of how we get things done in the digital world.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Yoav Shoham is a professor emeritus at Stanford University and cofounder of AI21 Labs. His 1993 paper on agent-oriented programming received the AI Journal Classic Paper Award. He is coauthor of &lt;/em&gt;Multiagent Systems: Algorithmic, Game-Theoretic, and Logical Foundations&lt;em&gt;, a standard textbook in the field.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/250627_AIagentstalking.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Google’s recent unveiling of what it calls a “new class of agentic experiences” feels like a turning point. At its I/O 2025 event in May, for example, the company showed off a digital assistant that didn’t just answer questions; it helped work on a bicycle repair by finding a matching user manual, locating a YouTube tutorial, and even calling a local store to ask about a part, all with minimal human nudging. Such capabilities could soon extend far outside the Google ecosystem. The company has introduced an open standard called Agent-to-Agent, or A2A, which aims to let agents from different companies talk to each other and work together.&lt;/p&gt;  &lt;p&gt;The vision is exciting: Intelligent software agents that act like digital coworkers, booking your flights, rescheduling meetings, filing expenses, and talking to each other behind the scenes to get things done. But if we’re not careful, we’re going to derail the whole idea before it has a chance to deliver real benefits. As with many tech trends, there’s a risk of hype racing ahead of reality. And when expectations get out of hand, a backlash isn’t far behind.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;Let’s start with the term “agent” itself. Right now, it’s being slapped on everything from simple scripts to sophisticated AI workflows. There’s no shared definition, which leaves plenty of room for companies to market basic automation as something much more advanced. That kind of “agentwashing” doesn’t just confuse customers; it invites disappointment. We don’t necessarily need a rigid standard, but we do need clearer expectations about what these systems are supposed to do, how autonomously they operate, and how reliably they perform.&lt;/p&gt;  &lt;p&gt;And reliability is the next big challenge. Most of today’s agents are powered by large language models (LLMs), which generate probabilistic responses. These systems are powerful, but they’re also unpredictable. They can make things up, go off track, or fail in subtle ways—especially when they’re asked to complete multistep tasks, pulling in external tools and chaining LLM responses together. A recent example: Users of Cursor, a popular AI programming assistant, were told by an automated support agent that they couldn’t use the software on more than one device. There were widespread complaints and reports of users canceling their subscriptions. But it turned out the policy didn’t exist. The AI had invented it.&lt;/p&gt; 
 &lt;p&gt;In enterprise settings, this kind of mistake could create immense damage. We need to stop treating LLMs as standalone products and start building complete systems around them—systems that account for uncertainty, monitor outputs, manage costs, and layer in guardrails for safety and accuracy. These measures can help ensure that the output adheres to the requirements expressed by the user, obeys the company’s policies regarding access to information, respects privacy issues, and so on. Some companies, including AI21 (which I cofounded and which has received funding from Google), are already moving in that direction, wrapping language models in more deliberate, structured architectures. Our latest launch, Maestro, is designed for enterprise reliability, combining LLMs with company data, public information, and other tools to ensure dependable outputs.&lt;/p&gt;  &lt;p&gt;Still, even the smartest agent won’t be useful in a vacuum. For the agent model to work, different agents need to cooperate (booking your travel, checking the weather, submitting your expense report) without constant human supervision. That’s where Google’s A2A protocol comes in. It’s meant to be a universal language that lets agents share what they can do and divide up tasks. In principle, it’s a great idea.&lt;/p&gt;&lt;p&gt;In practice, A2A still falls short. It defines how agents talk to each other, but not what they actually mean. If one agent says it can provide “wind conditions,” another has to guess whether that’s useful for evaluating weather on a flight route. Without a shared vocabulary or context, coordination becomes brittle. We’ve seen this problem before in distributed computing. Solving it at scale is far from trivial.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt;&lt;p&gt;There’s also the assumption that agents are naturally cooperative. That may hold inside Google or another single company’s ecosystem, but in the real world, agents will represent different vendors, customers, or even competitors. For example, if my travel planning agent is requesting price quotes from your airline booking agent, and your agent is incentivized to favor certain airlines, my agent might not be able to get me the best or least expensive itinerary. Without some way to align incentives through contracts, payments, or game-theoretic mechanisms, expecting seamless collaboration may be wishful thinking.&lt;/p&gt;  &lt;p&gt;None of these issues are insurmountable. Shared semantics can be developed. Protocols can evolve. Agents can be taught to negotiate and collaborate in more sophisticated ways. But these problems won’t solve themselves, and if we ignore them, the term “agent” will go the way of other overhyped tech buzzwords. Already, some CIOs are rolling their eyes when they hear it.&lt;/p&gt;  &lt;p&gt;That’s a warning sign. We don’t want the excitement to paper over the pitfalls, only to let developers and users discover them the hard way and develop a negative perspective on the whole endeavor. That would be a shame. The potential here is real. But we need to match the ambition with thoughtful design, clear definitions, and realistic expectations. If we can do that, agents won’t just be another passing trend; they could become the backbone of how we get things done in the digital world.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Yoav Shoham is a professor emeritus at Stanford University and cofounder of AI21 Labs. His 1993 paper on agent-oriented programming received the AI Journal Classic Paper Award. He is coauthor of &lt;/em&gt;Multiagent Systems: Algorithmic, Game-Theoretic, and Logical Foundations&lt;em&gt;, a standard textbook in the field.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/03/1119545/dont-let-hype-about-ai-agents-get-ahead-of-reality/</guid><pubDate>Thu, 03 Jul 2025 09:00:00 +0000</pubDate></item><item><title>Google’s electricity demand is skyrocketing (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/03/1119627/google-electricity-fusion-ai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/5-25-SPARC-Tokamak-Hall-in-Devens.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;We got two big pieces of energy news from Google this week. The company announced that it’s signed an agreement to purchase electricity from a fusion company’s forthcoming first power plant. Google also released its latest environmental report, which shows that &lt;strong&gt;its energy use from data centers has &lt;/strong&gt;&lt;strong&gt;&lt;em&gt;doubled&lt;/em&gt;&lt;/strong&gt;&lt;strong&gt; since 2020&lt;/strong&gt;.&lt;/p&gt;  &lt;p&gt;Taken together, these two bits of news offer a fascinating look at just how desperately big tech companies are hunting for clean electricity to power their data centers as energy demand and emissions balloon in the age of AI. Of course, we don’t know exactly how much of this pollution is attributable to AI because Google doesn’t break that out. (Also a problem!) So, what’s next and what does this all mean?&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;Let’s start with fusion: Google’s deal with Commonwealth Fusion Systems is intended to provide the tech giant with 200 megawatts of power. This will come from Commonwealth’s first commercial plant, a facility planned for Virginia that the company refers to as the Arc power plant. The agreement represents half its capacity.&lt;/p&gt;  &lt;p&gt;What’s important to note here is that this power plant doesn’t exist yet. In fact, Commonwealth still needs to get its Sparc demonstration reactor, located outside Boston, up and running. That site, which I visited in the fall, should be completed in 2026.&lt;/p&gt; 
 &lt;p&gt;(An aside: This isn’t the first deal between Big Tech and a fusion company. Microsoft signed an agreement with Helion a couple of years ago to buy 50 megawatts of power from a planned power plant, scheduled to come online in 2028. Experts expressed skepticism in the wake of that deal, as my colleague James Temple reported.)&lt;/p&gt;  &lt;p&gt;Nonetheless, Google’s announcement is a big moment for fusion, in part because of the size of the commitment and also because Commonwealth, a spinout company from MIT’s Plasma Science and Fusion Center, is seen by many in the industry as a likely candidate to be the first to get a commercial plant off the ground. (&lt;em&gt;MIT Technology Review &lt;/em&gt;is owned by MIT but is editorially independent.)&lt;/p&gt; 
 &lt;p&gt;Google leadership was very up-front about the length of the timeline. “We would certainly put this in the long-term category,” said Michael Terrell, Google’s head of advanced energy, in a press call about the deal.&lt;/p&gt;  &lt;p&gt;The news of Google’s foray into fusion comes just days after the tech giant’s release of its latest environmental report. While the company highlighted some wins, some of the numbers in this report are eye-catching, and not in a positive way.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Google’s emissions have increased by over 50% since 2019&lt;/strong&gt;, rising 6% in the last year alone. That’s decidedly the wrong direction for a company that’s set a goal to reach net-zero greenhouse-gas emissions by the end of the decade.&lt;/p&gt;  &lt;p&gt;It’s true that the company has committed billions to clean energy projects, including big investments in next-generation technologies like advanced nuclear and enhanced geothermal systems. Those deals have helped dampen emissions growth, but it’s an arguably impossible task to keep up with the energy demand the company is seeing.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt;&lt;p&gt;Google’s electricity consumption from data centers was up 27% from the year before. It’s &lt;em&gt;doubled&lt;/em&gt; since 2020, reaching over 30 terawatt-hours. &lt;strong&gt;That’s nearly the annual electricity consumption from the entire country of&lt;/strong&gt; &lt;strong&gt;Ireland&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;As an outsider, it’s tempting to point the finger at AI, since that technology has crashed into the mainstream and percolated into every corner of Google’s products and business. And yet the report downplays the role of AI. Here’s one bit that struck me:&lt;/p&gt;  &lt;p&gt;“However, it’s important to note that our growing electricity needs aren’t solely driven by AI. The accelerating growth of Google Cloud, continued investments in Search, the expanding reach of YouTube, and more, have also contributed to this overall growth.”&lt;/p&gt;  &lt;p&gt;There is enough wiggle room in that statement to drive a large electric truck through. When I asked about the relative contributions here, company representative Mara Harris said via email that they don’t break out what portion comes from AI. When I followed up asking if the company didn’t have this information or just wouldn’t share it, she said she’d check but didn’t get back to me.&lt;/p&gt; 

 &lt;p&gt;I’ll make the point here that we’ve made before, including in our recent package on AI and energy: &lt;strong&gt;Big companies should be disclosing more about the energy demands of AI. We shouldn’t be guessing at this technology’s effects.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Google has put a ton of effort and resources into setting and chasing ambitious climate goals. But as its energy needs and those of the rest of the industry continue to explode, it’s obvious that this problem is getting tougher, and it’s also clear that more transparency is a crucial part of the way forward.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark, &lt;/em&gt;MIT Technology Review&lt;em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday,&lt;/em&gt; &lt;em&gt;sign up here&lt;/em&gt;.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/5-25-SPARC-Tokamak-Hall-in-Devens.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;We got two big pieces of energy news from Google this week. The company announced that it’s signed an agreement to purchase electricity from a fusion company’s forthcoming first power plant. Google also released its latest environmental report, which shows that &lt;strong&gt;its energy use from data centers has &lt;/strong&gt;&lt;strong&gt;&lt;em&gt;doubled&lt;/em&gt;&lt;/strong&gt;&lt;strong&gt; since 2020&lt;/strong&gt;.&lt;/p&gt;  &lt;p&gt;Taken together, these two bits of news offer a fascinating look at just how desperately big tech companies are hunting for clean electricity to power their data centers as energy demand and emissions balloon in the age of AI. Of course, we don’t know exactly how much of this pollution is attributable to AI because Google doesn’t break that out. (Also a problem!) So, what’s next and what does this all mean?&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;Let’s start with fusion: Google’s deal with Commonwealth Fusion Systems is intended to provide the tech giant with 200 megawatts of power. This will come from Commonwealth’s first commercial plant, a facility planned for Virginia that the company refers to as the Arc power plant. The agreement represents half its capacity.&lt;/p&gt;  &lt;p&gt;What’s important to note here is that this power plant doesn’t exist yet. In fact, Commonwealth still needs to get its Sparc demonstration reactor, located outside Boston, up and running. That site, which I visited in the fall, should be completed in 2026.&lt;/p&gt; 
 &lt;p&gt;(An aside: This isn’t the first deal between Big Tech and a fusion company. Microsoft signed an agreement with Helion a couple of years ago to buy 50 megawatts of power from a planned power plant, scheduled to come online in 2028. Experts expressed skepticism in the wake of that deal, as my colleague James Temple reported.)&lt;/p&gt;  &lt;p&gt;Nonetheless, Google’s announcement is a big moment for fusion, in part because of the size of the commitment and also because Commonwealth, a spinout company from MIT’s Plasma Science and Fusion Center, is seen by many in the industry as a likely candidate to be the first to get a commercial plant off the ground. (&lt;em&gt;MIT Technology Review &lt;/em&gt;is owned by MIT but is editorially independent.)&lt;/p&gt; 
 &lt;p&gt;Google leadership was very up-front about the length of the timeline. “We would certainly put this in the long-term category,” said Michael Terrell, Google’s head of advanced energy, in a press call about the deal.&lt;/p&gt;  &lt;p&gt;The news of Google’s foray into fusion comes just days after the tech giant’s release of its latest environmental report. While the company highlighted some wins, some of the numbers in this report are eye-catching, and not in a positive way.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Google’s emissions have increased by over 50% since 2019&lt;/strong&gt;, rising 6% in the last year alone. That’s decidedly the wrong direction for a company that’s set a goal to reach net-zero greenhouse-gas emissions by the end of the decade.&lt;/p&gt;  &lt;p&gt;It’s true that the company has committed billions to clean energy projects, including big investments in next-generation technologies like advanced nuclear and enhanced geothermal systems. Those deals have helped dampen emissions growth, but it’s an arguably impossible task to keep up with the energy demand the company is seeing.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt;&lt;p&gt;Google’s electricity consumption from data centers was up 27% from the year before. It’s &lt;em&gt;doubled&lt;/em&gt; since 2020, reaching over 30 terawatt-hours. &lt;strong&gt;That’s nearly the annual electricity consumption from the entire country of&lt;/strong&gt; &lt;strong&gt;Ireland&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;As an outsider, it’s tempting to point the finger at AI, since that technology has crashed into the mainstream and percolated into every corner of Google’s products and business. And yet the report downplays the role of AI. Here’s one bit that struck me:&lt;/p&gt;  &lt;p&gt;“However, it’s important to note that our growing electricity needs aren’t solely driven by AI. The accelerating growth of Google Cloud, continued investments in Search, the expanding reach of YouTube, and more, have also contributed to this overall growth.”&lt;/p&gt;  &lt;p&gt;There is enough wiggle room in that statement to drive a large electric truck through. When I asked about the relative contributions here, company representative Mara Harris said via email that they don’t break out what portion comes from AI. When I followed up asking if the company didn’t have this information or just wouldn’t share it, she said she’d check but didn’t get back to me.&lt;/p&gt; 

 &lt;p&gt;I’ll make the point here that we’ve made before, including in our recent package on AI and energy: &lt;strong&gt;Big companies should be disclosing more about the energy demands of AI. We shouldn’t be guessing at this technology’s effects.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Google has put a ton of effort and resources into setting and chasing ambitious climate goals. But as its energy needs and those of the rest of the industry continue to explode, it’s obvious that this problem is getting tougher, and it’s also clear that more transparency is a crucial part of the way forward.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark, &lt;/em&gt;MIT Technology Review&lt;em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday,&lt;/em&gt; &lt;em&gt;sign up here&lt;/em&gt;.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/03/1119627/google-electricity-fusion-ai/</guid><pubDate>Thu, 03 Jul 2025 10:00:00 +0000</pubDate></item><item><title>Google rolls out its new Veo 3 video-generation model globally (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/03/google-rolls-out-its-new-veo-3-video-generation-model-globally/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/03/GettyImages-2169339854.jpg?resize=1200,857" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google on Thursday said it has begun rolling out its Veo 3 video generation model to Gemini users in more than 159 countries. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Video generation via the new model is available only to paying subscribers of Google’s AI Pro plan and is capped at three videos per day.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Veo 3, which Google showed off in May, lets users generate videos up to eight seconds long using text prompts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google’s Josh Woodward has said that the company is working on adding image-to-video generation capabilities to Gemini.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/03/GettyImages-2169339854.jpg?resize=1200,857" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google on Thursday said it has begun rolling out its Veo 3 video generation model to Gemini users in more than 159 countries. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Video generation via the new model is available only to paying subscribers of Google’s AI Pro plan and is capped at three videos per day.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Veo 3, which Google showed off in May, lets users generate videos up to eight seconds long using text prompts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google’s Josh Woodward has said that the company is working on adding image-to-video generation capabilities to Gemini.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/03/google-rolls-out-its-new-veo-3-video-generation-model-globally/</guid><pubDate>Thu, 03 Jul 2025 10:56:48 +0000</pubDate></item><item><title>CyXcel research discovers a third of UK businesses at AI risk (AI News)</title><link>https://www.artificialintelligence-news.com/news/cyxcel-research-discovers-a-third-of-uk-businesses-at-ai-risk/</link><description>&lt;p&gt;Research by cybersecurity consultancy CyXcel has revealed 29% of UK businesses surveyed have only recently implemented their first AI risk strategy, with 31% not no AI governance policies set up. The is despite a third of businesses recognising AI as a potential cybersecurity threat. The blind spot in AI risk preparedness leaves businesses prey to data leaks and breaches, operational disruptions, and regulatory fines, the company says.&lt;/p&gt;&lt;p&gt;Of those surveyed, 18% of UK and US organisations are unprepared for AI data poisoning, a form of cyberattack that targets the training data of AI and machine learning models. Moreover, 16% have no policies in place to fight cloning and deepfake incidents.&lt;/p&gt;&lt;p&gt;Megha Kumar, Chief Product Officer and Head of Geopolitical Risk at CyXcel, stated there is a catch 22 situation, where companies want to adopt AI solutions but simultaneously worry about its risks. “Organisations want to use AI but are worried about risks – especially as many do not have a policy and governance process in place.”&lt;/p&gt;&lt;p&gt;He said CyXcel’s Digital Risk Management (DRM) platform can help respond to mounting threats. “The CyXcel DRM provides clients in all sectors, especially those that have limited technological resources in house, with a robust tool to proactively manage digital risk and harness AI confidently and safely.”&lt;/p&gt;&lt;p&gt;The CyXcel DRM platform is designed to provide businesses with insight into growing AI risks. It combines cyber, legal, technical, and strategic expertise to help manage threats and improve digital resilience. The company says its DRM platform also helps implement governance and policies that will mitigate possible risks.&lt;/p&gt;&lt;p&gt;The DRM platform provides strategies for – AI, Cyber, Supply Chain, Geopolitics, Regulation, Technology (OT/IT), and Corporate Responsibility, available through a dashboard where users can manage digitals risks using solutions proffered by the platform.&lt;/p&gt;&lt;p&gt;Legal and technical insights come from expertise coded into the platform, so users can see trends, the potential impact of risks, and emerging threats. It advises on possible strategies for combatting danger and vulnerabilities.&lt;/p&gt;&lt;p&gt;The DRM also offers a “full-spectrum dispute resolution and litigation service” aimed at reducing the time needed for organisations to follow regulations and laws related to various digital threats. For businesses with strict regulations in place, CyXcel’s DRM covers 26 sectors legally required to follow regulations like the EU’s NIS2 and DORA (Digital Operational Resilience Act). These sectors are considered essential infrastructure, with each classified as Critical National Infrastructure (CNI) in regions like the US, UK, and EU.&lt;/p&gt;&lt;p&gt;CyXcel CEO, Edward Lewis, spoke on the evolving and complex landscape of cybersecurity regulation. “Governments worldwide are enhancing protections for critical infrastructure and sensitive data through legislation like the EU’s Cyber Resilience Act, which mandates security measures like automatic updates and incident reporting. Similarly, new laws are likely to arrive in the UK next year which introduce mandatory ransomware reporting and stronger regulatory powers.”&lt;/p&gt;&lt;p&gt;Businesses worldwide are at the mercy of digital breaches and attacks, including, by its own admission CyXcel itself. Commercially, legally, and strategically, CyXcel’s DRM platform is designed to tackle the issues it’s also at risk from.&lt;/p&gt;&lt;p&gt;CyXcel clients are typically bound by stringent cybersecurity laws, which, if broken, can result in fines and reputational damage. Similarly, if CyXcel’s advice falters, the company itself could be on the hook for failed compliance and breaches.&lt;/p&gt;&lt;p&gt;The company is at pains to stress thet it’s facing the same digital risks as its clients. CyXcel’s marketing materials state that the company’s commitment to risk isn’t advisory, it’s ‘personal.’&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image “Risk – MSK” by anarchosyn is licensed under CC BY-SA 2.0&lt;/em&gt;)&lt;/p&gt;&lt;p&gt;See also: Huawei HarmonyOS 6 AI agents offer alternative to Android and iOS&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, Data Centre Expo, Digital Transformation Expo, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Research by cybersecurity consultancy CyXcel has revealed 29% of UK businesses surveyed have only recently implemented their first AI risk strategy, with 31% not no AI governance policies set up. The is despite a third of businesses recognising AI as a potential cybersecurity threat. The blind spot in AI risk preparedness leaves businesses prey to data leaks and breaches, operational disruptions, and regulatory fines, the company says.&lt;/p&gt;&lt;p&gt;Of those surveyed, 18% of UK and US organisations are unprepared for AI data poisoning, a form of cyberattack that targets the training data of AI and machine learning models. Moreover, 16% have no policies in place to fight cloning and deepfake incidents.&lt;/p&gt;&lt;p&gt;Megha Kumar, Chief Product Officer and Head of Geopolitical Risk at CyXcel, stated there is a catch 22 situation, where companies want to adopt AI solutions but simultaneously worry about its risks. “Organisations want to use AI but are worried about risks – especially as many do not have a policy and governance process in place.”&lt;/p&gt;&lt;p&gt;He said CyXcel’s Digital Risk Management (DRM) platform can help respond to mounting threats. “The CyXcel DRM provides clients in all sectors, especially those that have limited technological resources in house, with a robust tool to proactively manage digital risk and harness AI confidently and safely.”&lt;/p&gt;&lt;p&gt;The CyXcel DRM platform is designed to provide businesses with insight into growing AI risks. It combines cyber, legal, technical, and strategic expertise to help manage threats and improve digital resilience. The company says its DRM platform also helps implement governance and policies that will mitigate possible risks.&lt;/p&gt;&lt;p&gt;The DRM platform provides strategies for – AI, Cyber, Supply Chain, Geopolitics, Regulation, Technology (OT/IT), and Corporate Responsibility, available through a dashboard where users can manage digitals risks using solutions proffered by the platform.&lt;/p&gt;&lt;p&gt;Legal and technical insights come from expertise coded into the platform, so users can see trends, the potential impact of risks, and emerging threats. It advises on possible strategies for combatting danger and vulnerabilities.&lt;/p&gt;&lt;p&gt;The DRM also offers a “full-spectrum dispute resolution and litigation service” aimed at reducing the time needed for organisations to follow regulations and laws related to various digital threats. For businesses with strict regulations in place, CyXcel’s DRM covers 26 sectors legally required to follow regulations like the EU’s NIS2 and DORA (Digital Operational Resilience Act). These sectors are considered essential infrastructure, with each classified as Critical National Infrastructure (CNI) in regions like the US, UK, and EU.&lt;/p&gt;&lt;p&gt;CyXcel CEO, Edward Lewis, spoke on the evolving and complex landscape of cybersecurity regulation. “Governments worldwide are enhancing protections for critical infrastructure and sensitive data through legislation like the EU’s Cyber Resilience Act, which mandates security measures like automatic updates and incident reporting. Similarly, new laws are likely to arrive in the UK next year which introduce mandatory ransomware reporting and stronger regulatory powers.”&lt;/p&gt;&lt;p&gt;Businesses worldwide are at the mercy of digital breaches and attacks, including, by its own admission CyXcel itself. Commercially, legally, and strategically, CyXcel’s DRM platform is designed to tackle the issues it’s also at risk from.&lt;/p&gt;&lt;p&gt;CyXcel clients are typically bound by stringent cybersecurity laws, which, if broken, can result in fines and reputational damage. Similarly, if CyXcel’s advice falters, the company itself could be on the hook for failed compliance and breaches.&lt;/p&gt;&lt;p&gt;The company is at pains to stress thet it’s facing the same digital risks as its clients. CyXcel’s marketing materials state that the company’s commitment to risk isn’t advisory, it’s ‘personal.’&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image “Risk – MSK” by anarchosyn is licensed under CC BY-SA 2.0&lt;/em&gt;)&lt;/p&gt;&lt;p&gt;See also: Huawei HarmonyOS 6 AI agents offer alternative to Android and iOS&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, Data Centre Expo, Digital Transformation Expo, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/cyxcel-research-discovers-a-third-of-uk-businesses-at-ai-risk/</guid><pubDate>Thu, 03 Jul 2025 11:13:07 +0000</pubDate></item><item><title>The Download: AI agents hype, and Google’s electricity plans (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/03/1119682/the-download-ai-agents-hype-and-googles-electricity-plans/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Don’t let hype about AI agents get ahead of reality&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;&lt;em&gt;—Yoav Shoham is a professor emeritus at Stanford University and cofounder of AI21 Labs.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;At Google’s I/O 2025 event in May, the company showed off a digital assistant that didn’t just answer questions; it helped work on a bicycle repair by finding a matching user manual, locating a YouTube tutorial, and even calling a local store to ask about a part, all with minimal human nudging. Such capabilities could soon extend far outside the Google ecosystem.&lt;/p&gt;&lt;p&gt;The vision is exciting: Intelligent software agents that act like digital coworkers, booking your flights, rescheduling meetings, filing expenses, and talking to each other behind the scenes to get things done.&lt;/p&gt;&lt;p&gt;But if we’re not careful, we’re going to derail the whole idea before it has a chance to deliver real benefits. As with many tech trends, there’s a risk of hype racing ahead of reality. And when expectations get out of hand, a backlash isn’t far behind. Read the full story.&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Google’s electricity demand is skyrocketing&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;We got two big pieces of energy news from Google this week. The company announced that it’s signed an agreement to purchase electricity from a fusion company’s forthcoming first power plant. Google also released its latest environmental report, which shows that its energy use from data centers has doubled since 2020.&lt;/p&gt;  &lt;p&gt;Taken together, these two bits of news offer a fascinating look at just how desperately big tech companies are hunting for clean electricity to power their data centers as energy demand and emissions balloon in the age of AI. Of course, we don’t know exactly how much of this pollution is attributable to AI because Google doesn’t break that out. (Also a problem!) So, what’s next and what does this all mean?&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Casey Crownhart&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This article is from The Spark, MIT Technology Review’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;em&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;+ To read more about whether nuclear energy is really a viable way to power the AI boom, check out Casey’s recent article, which is part of Power Hungry: AI and our energy future—our new series shining a light on the energy demands and carbon costs of the artificial intelligence revolution. You can take a look at the rest of the package here.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Meta’s climate tool was ‘trained using faulty data’&lt;/strong&gt;&lt;br /&gt;Scientists claim it raised false hopes about the feasibility of removing carbon dioxide from the atmosphere. (FT $)&lt;br /&gt;+ &lt;em&gt;xAI’s gas turbines have been greenlit, despite community backlash. &lt;/em&gt;(Wired $)&lt;br /&gt;+ &lt;em&gt;Why we need to shoot carbon dioxide thousands of feet underground. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;2 We don’t know whether US insurers will cover vaccines for kids&lt;/strong&gt;&lt;br /&gt;Major insurers haven’t confirmed whether they’ll keep covering the costs of shots. (Wired $)&lt;br /&gt;+ &lt;em&gt;What’s next for the Gates Foundation’s global health initiatives? &lt;/em&gt;(Undark)&lt;br /&gt;+ &lt;em&gt;How measuring vaccine hesitancy could help health professionals tackle it. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 The Trump administration wants to gut Biden’s climate law&lt;/strong&gt;&lt;br /&gt;The Inflation Reduction Act’s green energy tax incentives are hanging in the balance. (WP $)&lt;br /&gt;+ &lt;em&gt;It’s bad news for one of the US economy’s biggest growth sectors. &lt;/em&gt;(Vox)&lt;br /&gt;+ &lt;em&gt;How are we going to feed the world without making climate change worse? &lt;/em&gt;(New Yorker $)&lt;br /&gt;+ &lt;em&gt;The President threatened to unravel the landmark law long before he was elected. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 There are certain tells a scientific study abstract has been written by AI&lt;/strong&gt;&lt;br /&gt;Use of hundreds of words has shot up since ChatGPT was made public. (NYT $)&lt;br /&gt;+ &lt;em&gt;Beware over-reliance on AI-text detection tools, though. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 Elon Musk doesn’t care about cars any more&lt;/strong&gt;&lt;br /&gt;Which is terrible news for Tesla and its investors. (WSJ $)&lt;br /&gt;+ &lt;em&gt;Things aren’t looking too hot for Rivian, either. &lt;/em&gt;(Insider $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;6 America’s weather forecasting is getting worse&lt;br /&gt;&lt;/strong&gt;Just a year ago, US storm forecasting was the best it had ever been. Now, its accuracy is rapidly declining. (The Atlantic $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Brazil has sustainable data center ambitions&lt;br /&gt;&lt;/strong&gt;Environmentalists aren’t convinced, however. (Rest of World)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 A mysterious object has been spotted passing through the solar system&lt;br /&gt;&lt;/strong&gt;And we’ve got good reason to believe it originated outside our system. (Ars Technica)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 A rising band on Spotify is probably AI-generated&lt;/strong&gt;&lt;br /&gt;But no one seems able to say for sure. (Vice)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;10 The homes float in flood water&lt;/strong&gt;&lt;br /&gt;It’s one solution to building homes on known flood plains. (Fast Company $)&lt;br /&gt;+ &lt;em&gt;How to stop a state from sinking. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“AI doesn’t know what an orgasm sounds like.”&amp;nbsp;&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;—Annabelle Tudor, an audiobook narrator, tells the Guardian why she’s not convinced by the industry’s plans to have AI narrate audiobooks.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXejlOQvDkVHy-uVFXkn_td_yo7zHtzg7_5qm2hQkP3s-aXW19-EhujifsFx1IUc3OuzYnE75pgSb5Nx42Oi181ANggglDQeCKx3SXCOGIOtZt8RQfJZ6AGPS_G6KFV2iaGkjk1V_w?key=pQnoawGrrEloJLzh1vt7qA" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Who gets to decide who receives experimental medical treatments?&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;There has been a trend toward lowering the bar for new medicines, and it is becoming easier for people to access treatments that might not help them—and could even harm them. Anecdotes appear to be overpowering evidence in decisions on drug approval. As a result, we’re ending up with some drugs that don’t work.&lt;/p&gt;  &lt;p&gt;We urgently need to question how these decisions are made. Who should have access to experimental therapies? And who should get to decide? Such questions are especially pressing considering how quickly biotechnology is advancing. We’re not just improving on existing classes of treatments—we’re creating entirely new ones. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Jessica Hamzelou&lt;/em&gt;&lt;/p&gt;   
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ These aerial shots of Glastonbury festival are crazy.&lt;br /&gt;+ Our oceans really are amazing places—take a moment to appreciate them.&lt;br /&gt;+ How to be truly cool, according to science.&lt;br /&gt;+ Happy 62nd birthday to Tracey Emin, still an enfant terrible after all these years.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Don’t let hype about AI agents get ahead of reality&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;&lt;em&gt;—Yoav Shoham is a professor emeritus at Stanford University and cofounder of AI21 Labs.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;At Google’s I/O 2025 event in May, the company showed off a digital assistant that didn’t just answer questions; it helped work on a bicycle repair by finding a matching user manual, locating a YouTube tutorial, and even calling a local store to ask about a part, all with minimal human nudging. Such capabilities could soon extend far outside the Google ecosystem.&lt;/p&gt;&lt;p&gt;The vision is exciting: Intelligent software agents that act like digital coworkers, booking your flights, rescheduling meetings, filing expenses, and talking to each other behind the scenes to get things done.&lt;/p&gt;&lt;p&gt;But if we’re not careful, we’re going to derail the whole idea before it has a chance to deliver real benefits. As with many tech trends, there’s a risk of hype racing ahead of reality. And when expectations get out of hand, a backlash isn’t far behind. Read the full story.&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Google’s electricity demand is skyrocketing&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;We got two big pieces of energy news from Google this week. The company announced that it’s signed an agreement to purchase electricity from a fusion company’s forthcoming first power plant. Google also released its latest environmental report, which shows that its energy use from data centers has doubled since 2020.&lt;/p&gt;  &lt;p&gt;Taken together, these two bits of news offer a fascinating look at just how desperately big tech companies are hunting for clean electricity to power their data centers as energy demand and emissions balloon in the age of AI. Of course, we don’t know exactly how much of this pollution is attributable to AI because Google doesn’t break that out. (Also a problem!) So, what’s next and what does this all mean?&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Casey Crownhart&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This article is from The Spark, MIT Technology Review’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;em&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;+ To read more about whether nuclear energy is really a viable way to power the AI boom, check out Casey’s recent article, which is part of Power Hungry: AI and our energy future—our new series shining a light on the energy demands and carbon costs of the artificial intelligence revolution. You can take a look at the rest of the package here.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Meta’s climate tool was ‘trained using faulty data’&lt;/strong&gt;&lt;br /&gt;Scientists claim it raised false hopes about the feasibility of removing carbon dioxide from the atmosphere. (FT $)&lt;br /&gt;+ &lt;em&gt;xAI’s gas turbines have been greenlit, despite community backlash. &lt;/em&gt;(Wired $)&lt;br /&gt;+ &lt;em&gt;Why we need to shoot carbon dioxide thousands of feet underground. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;2 We don’t know whether US insurers will cover vaccines for kids&lt;/strong&gt;&lt;br /&gt;Major insurers haven’t confirmed whether they’ll keep covering the costs of shots. (Wired $)&lt;br /&gt;+ &lt;em&gt;What’s next for the Gates Foundation’s global health initiatives? &lt;/em&gt;(Undark)&lt;br /&gt;+ &lt;em&gt;How measuring vaccine hesitancy could help health professionals tackle it. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 The Trump administration wants to gut Biden’s climate law&lt;/strong&gt;&lt;br /&gt;The Inflation Reduction Act’s green energy tax incentives are hanging in the balance. (WP $)&lt;br /&gt;+ &lt;em&gt;It’s bad news for one of the US economy’s biggest growth sectors. &lt;/em&gt;(Vox)&lt;br /&gt;+ &lt;em&gt;How are we going to feed the world without making climate change worse? &lt;/em&gt;(New Yorker $)&lt;br /&gt;+ &lt;em&gt;The President threatened to unravel the landmark law long before he was elected. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 There are certain tells a scientific study abstract has been written by AI&lt;/strong&gt;&lt;br /&gt;Use of hundreds of words has shot up since ChatGPT was made public. (NYT $)&lt;br /&gt;+ &lt;em&gt;Beware over-reliance on AI-text detection tools, though. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 Elon Musk doesn’t care about cars any more&lt;/strong&gt;&lt;br /&gt;Which is terrible news for Tesla and its investors. (WSJ $)&lt;br /&gt;+ &lt;em&gt;Things aren’t looking too hot for Rivian, either. &lt;/em&gt;(Insider $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;6 America’s weather forecasting is getting worse&lt;br /&gt;&lt;/strong&gt;Just a year ago, US storm forecasting was the best it had ever been. Now, its accuracy is rapidly declining. (The Atlantic $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Brazil has sustainable data center ambitions&lt;br /&gt;&lt;/strong&gt;Environmentalists aren’t convinced, however. (Rest of World)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 A mysterious object has been spotted passing through the solar system&lt;br /&gt;&lt;/strong&gt;And we’ve got good reason to believe it originated outside our system. (Ars Technica)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 A rising band on Spotify is probably AI-generated&lt;/strong&gt;&lt;br /&gt;But no one seems able to say for sure. (Vice)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;10 The homes float in flood water&lt;/strong&gt;&lt;br /&gt;It’s one solution to building homes on known flood plains. (Fast Company $)&lt;br /&gt;+ &lt;em&gt;How to stop a state from sinking. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“AI doesn’t know what an orgasm sounds like.”&amp;nbsp;&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;—Annabelle Tudor, an audiobook narrator, tells the Guardian why she’s not convinced by the industry’s plans to have AI narrate audiobooks.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXejlOQvDkVHy-uVFXkn_td_yo7zHtzg7_5qm2hQkP3s-aXW19-EhujifsFx1IUc3OuzYnE75pgSb5Nx42Oi181ANggglDQeCKx3SXCOGIOtZt8RQfJZ6AGPS_G6KFV2iaGkjk1V_w?key=pQnoawGrrEloJLzh1vt7qA" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Who gets to decide who receives experimental medical treatments?&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;There has been a trend toward lowering the bar for new medicines, and it is becoming easier for people to access treatments that might not help them—and could even harm them. Anecdotes appear to be overpowering evidence in decisions on drug approval. As a result, we’re ending up with some drugs that don’t work.&lt;/p&gt;  &lt;p&gt;We urgently need to question how these decisions are made. Who should have access to experimental therapies? And who should get to decide? Such questions are especially pressing considering how quickly biotechnology is advancing. We’re not just improving on existing classes of treatments—we’re creating entirely new ones. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Jessica Hamzelou&lt;/em&gt;&lt;/p&gt;   
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ These aerial shots of Glastonbury festival are crazy.&lt;br /&gt;+ Our oceans really are amazing places—take a moment to appreciate them.&lt;br /&gt;+ How to be truly cool, according to science.&lt;br /&gt;+ Happy 62nd birthday to Tracey Emin, still an enfant terrible after all these years.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/03/1119682/the-download-ai-agents-hype-and-googles-electricity-plans/</guid><pubDate>Thu, 03 Jul 2025 12:10:00 +0000</pubDate></item><item><title>[NEW] GeForce NOW’s 20 July Games Bring the Heat to the Cloud (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/geforce-now-thursday-july-2025-games/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;The forecast this month is showing a 100% chance of epic gaming. Catch the scorching lineup of 20 titles coming to the cloud, which gamers can play whether indoors or on the go.&lt;/p&gt;
&lt;p&gt;Six new games are landing on GeForce NOW this week, including launch day titles &lt;i&gt;Figment &lt;/i&gt;and &lt;i&gt;Little Nightmares II.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;And to make the summer even hotter, the GeForce NOW Summer Sale is in full swing. It’s the last chance to upgrade to a six-month Performance membership for just $29.99 and stream top titles like the recently released classic &lt;i&gt;Borderlands &lt;/i&gt;series, &lt;i&gt;DOOM: The Dark Ages&lt;/i&gt;, &lt;i&gt;FBC: Firebreak&lt;/i&gt;, and more with GeForce RTX power.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Jump Into July&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_82970"&gt;&lt;img alt="Figment on GeForce NOW" class="size-large wp-image-82970" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/07/GFN_Thursday-Figment-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-82970"&gt;&lt;em&gt;Face your nightmares.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;In &lt;i&gt;Figment,&lt;/i&gt; a whimsical action-adventure game set in the human mind, players guide Dusty — the grumpy, retired voice of courage — and his upbeat companion Piper on a surreal journey to restore lost bravery after a traumatic event. Blending hand-drawn visuals, clever puzzles and musical boss battles, &lt;i&gt;Figment&lt;/i&gt; explores themes of fear, grief and emotional healing in a colorful, dreamlike world filled with humor and song.&lt;/p&gt;
&lt;p&gt;In addition, members can look for the following games to stream this week:&lt;i&gt;&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;Here’s what’s coming in the rest of July:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;The Ascent&lt;/i&gt; (New release on Xbox, PC Game Pass, July 8)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Every Day We Fight &lt;/i&gt;(New release on Steam, July 10)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Mycopunk &lt;/i&gt;(New release on Steam, July 10)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Brickadia &lt;/i&gt;(New release on Steam, July 11)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;HUNTER×HUNTER NEN×IMPACT &lt;/i&gt;(New release on Steam, July 15)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Stronghold Crusader: Definitive Edition &lt;/i&gt;(New release on Steam, July 15)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;DREADZONE &lt;/i&gt;(New release on Steam, July 17)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;The Drifter &lt;/i&gt;(New release on Steam, July 17)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;He Is Coming &lt;/i&gt;(New release on Steam, July 17)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Killing Floor 3 &lt;/i&gt;(New release on Steam, July 24)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;RoboCop: Rogue City – Unfinished Business &lt;/i&gt;(New release on Steam, July 17)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Wildgate&lt;/i&gt; (New release on Steam, July 22)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Wuchang: Fallen Feathers &lt;/i&gt;(New release on Steam and Epic Games Store, July 23)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Battle Brothers &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;b&gt;June-tastic Games&amp;nbsp;&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;In addition to the 25 games announced last month, 11 more joined the GeForce NOW library:&lt;i&gt;&lt;/i&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;Frosthaven &lt;/i&gt;Demo (New release on Steam, June 9)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Kingdom Two Crowns&lt;/i&gt; (New release on Xbox, available on PC Game Pass, June 11)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Firefighting Simulator – The Squad&lt;/i&gt; (Xbox, available on PC Game Pass)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;JDM: Japanese Drift Master&lt;/i&gt; (Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Hellslave &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Date Everything! &lt;/i&gt;(New release on Steam, June 17)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;METAL EDEN &lt;/i&gt;Demo (Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Torque Drift 2&lt;/i&gt; (Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Broken Age &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Sandwich Simulator &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;We Happy Few&lt;/i&gt; (Steam)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What are you planning to play this weekend? Let us know on X or in the comments below.&lt;/p&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p dir="ltr" lang="en"&gt;📆 New month, new energy.&lt;/p&gt;
&lt;p&gt;What are your cloud gaming goals for July? ☁️🎮&lt;/p&gt;
&lt;p&gt;— 🌩️ NVIDIA GeForce NOW (@NVIDIAGFN) July 2, 2025&lt;/p&gt;&lt;/blockquote&gt;


		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;The forecast this month is showing a 100% chance of epic gaming. Catch the scorching lineup of 20 titles coming to the cloud, which gamers can play whether indoors or on the go.&lt;/p&gt;
&lt;p&gt;Six new games are landing on GeForce NOW this week, including launch day titles &lt;i&gt;Figment &lt;/i&gt;and &lt;i&gt;Little Nightmares II.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;And to make the summer even hotter, the GeForce NOW Summer Sale is in full swing. It’s the last chance to upgrade to a six-month Performance membership for just $29.99 and stream top titles like the recently released classic &lt;i&gt;Borderlands &lt;/i&gt;series, &lt;i&gt;DOOM: The Dark Ages&lt;/i&gt;, &lt;i&gt;FBC: Firebreak&lt;/i&gt;, and more with GeForce RTX power.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Jump Into July&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_82970"&gt;&lt;img alt="Figment on GeForce NOW" class="size-large wp-image-82970" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/07/GFN_Thursday-Figment-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-82970"&gt;&lt;em&gt;Face your nightmares.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;In &lt;i&gt;Figment,&lt;/i&gt; a whimsical action-adventure game set in the human mind, players guide Dusty — the grumpy, retired voice of courage — and his upbeat companion Piper on a surreal journey to restore lost bravery after a traumatic event. Blending hand-drawn visuals, clever puzzles and musical boss battles, &lt;i&gt;Figment&lt;/i&gt; explores themes of fear, grief and emotional healing in a colorful, dreamlike world filled with humor and song.&lt;/p&gt;
&lt;p&gt;In addition, members can look for the following games to stream this week:&lt;i&gt;&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;Here’s what’s coming in the rest of July:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;The Ascent&lt;/i&gt; (New release on Xbox, PC Game Pass, July 8)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Every Day We Fight &lt;/i&gt;(New release on Steam, July 10)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Mycopunk &lt;/i&gt;(New release on Steam, July 10)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Brickadia &lt;/i&gt;(New release on Steam, July 11)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;HUNTER×HUNTER NEN×IMPACT &lt;/i&gt;(New release on Steam, July 15)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Stronghold Crusader: Definitive Edition &lt;/i&gt;(New release on Steam, July 15)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;DREADZONE &lt;/i&gt;(New release on Steam, July 17)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;The Drifter &lt;/i&gt;(New release on Steam, July 17)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;He Is Coming &lt;/i&gt;(New release on Steam, July 17)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Killing Floor 3 &lt;/i&gt;(New release on Steam, July 24)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;RoboCop: Rogue City – Unfinished Business &lt;/i&gt;(New release on Steam, July 17)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Wildgate&lt;/i&gt; (New release on Steam, July 22)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Wuchang: Fallen Feathers &lt;/i&gt;(New release on Steam and Epic Games Store, July 23)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Battle Brothers &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;b&gt;June-tastic Games&amp;nbsp;&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;In addition to the 25 games announced last month, 11 more joined the GeForce NOW library:&lt;i&gt;&lt;/i&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;Frosthaven &lt;/i&gt;Demo (New release on Steam, June 9)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Kingdom Two Crowns&lt;/i&gt; (New release on Xbox, available on PC Game Pass, June 11)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Firefighting Simulator – The Squad&lt;/i&gt; (Xbox, available on PC Game Pass)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;JDM: Japanese Drift Master&lt;/i&gt; (Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Hellslave &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Date Everything! &lt;/i&gt;(New release on Steam, June 17)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;METAL EDEN &lt;/i&gt;Demo (Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Torque Drift 2&lt;/i&gt; (Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Broken Age &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Sandwich Simulator &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;We Happy Few&lt;/i&gt; (Steam)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What are you planning to play this weekend? Let us know on X or in the comments below.&lt;/p&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p dir="ltr" lang="en"&gt;📆 New month, new energy.&lt;/p&gt;
&lt;p&gt;What are your cloud gaming goals for July? ☁️🎮&lt;/p&gt;
&lt;p&gt;— 🌩️ NVIDIA GeForce NOW (@NVIDIAGFN) July 2, 2025&lt;/p&gt;&lt;/blockquote&gt;


		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/geforce-now-thursday-july-2025-games/</guid><pubDate>Thu, 03 Jul 2025 13:00:48 +0000</pubDate></item><item><title>[NEW] HOLY SMOKES! A new, 200% faster DeepSeek R1-0528 variant appears from German lab TNG Technology Consulting GmbH (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/holy-smokes-a-new-200-faster-deepseek-r1-0528-variant-appears-from-german-lab-tng-technology-consulting-gmbh/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;It’s been a little more than a month since Chinese AI startup DeepSeek, an offshoot of Hong Kong-based High-Flyer Capital Management, released the latest version of its hit open source model DeepSeek, R1-0528.&lt;/p&gt;



&lt;p&gt;Like its predecessor, DeepSeek-R1 — which rocked the AI and global business communities with how cheaply it was trained and how well it performed on reasoning tasks, all available to developers and enterprises for free — R1-0528 is already being adapted and remixed by other AI labs and developers, thanks in large part to its permissive Apache 2.0 license.&lt;/p&gt;



&lt;p&gt;This week, the 24-year-old German firm TNG Technology Consulting GmbH released one such adaptation: DeepSeek-TNG R1T2 Chimera, the latest model in its Chimera large language model (LLM) family. R1T2 delivers a notable boost in efficiency and speed, scoring at upwards of &lt;strong&gt;90% of R1-0528’s intelligence benchmark scores&lt;/strong&gt;, while generating answers with &lt;strong&gt;less than 40% of R1-0528’s output token count&lt;/strong&gt;. &lt;/p&gt;



&lt;p&gt;That means it produces shorter responses, translating directly into &lt;strong&gt;faster inference and lower compute costs&lt;/strong&gt;. On the model card TNG released for its new R1T2 on the AI code sharing community Hugging Face, the company states that it is “about 20% faster than the regular R1” (the one released back in January) “and more than twice as fast as R1-0528” (the May official update from DeepSeek).&lt;/p&gt;



&lt;p&gt;Already, the response has been incredibly positive from the AI developer community. “DAMN! DeepSeek R1T2 – 200% faster than R1-0528 &amp;amp; 20% faster than R1,” wrote Vaibhav (VB) Srivastav, a senior leader at Hugging Face, on X. “Significantly better than R1 on GPQA &amp;amp; AIME 24, made via Assembly of Experts with DS V3, R1 &amp;amp; R1-0528 — and it’s MIT-licensed, available on Hugging Face.”&lt;/p&gt;



&lt;p&gt;This gain is made possible by TNG’s Assembly-of-Experts (AoE) method — a technique for building LLMs by selectively merging the weight tensors (internal parameters) from multiple pre-trained models that TNG described in a paper published in May on arXiv, the non-peer reviewed open access online journal. &lt;/p&gt;



&lt;p&gt;A successor to the original R1T Chimera, R1T2 introduces a new “Tri-Mind” configuration that integrates three parent models: DeepSeek-R1-0528, DeepSeek-R1, and DeepSeek-V3-0324. The result is a model engineered to maintain high reasoning capability while significantly reducing inference cost.&lt;/p&gt;



&lt;p&gt;R1T2 is constructed without further fine-tuning or retraining. It inherits the reasoning strength of R1-0528, the structured thought patterns of R1, and the concise, instruction-oriented behavior of V3-0324 — delivering a more efficient, yet capable model for enterprise and research use.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-assembly-of-experts-aoe-differs-from-mixture-of-experts-moe"&gt;How Assembly-of-Experts (AoE) Differs from Mixture-of-Experts (MoE)&lt;/h2&gt;



&lt;p&gt;Mixture-of-Experts (MoE) is an architectural design in which different components, or “experts,” are conditionally activated per input. In MoE LLMs like DeepSeek-V3 or Mixtral, only a subset of the model’s expert layers (e.g., 8 out of 256) are active during any given token’s forward pass. This allows very large models to achieve higher parameter counts and specialization while keeping inference costs manageable — because only a fraction of the network is evaluated per token.&lt;/p&gt;



&lt;p&gt;Assembly-of-Experts (AoE) is a model merging technique, not an architecture. It’s used to create a new model from multiple pre-trained MoE models by selectively interpolating their weight tensors. &lt;/p&gt;



&lt;p&gt;The “experts” in AoE refer to the model components being merged — typically the routed expert tensors within MoE layers — not experts dynamically activated at runtime.&lt;/p&gt;



&lt;p&gt;TNG’s implementation of AoE focuses primarily on merging routed expert tensors — the part of a model most responsible for specialized reasoning — while often retaining the more efficient shared and attention layers from faster models like V3-0324. This approach enables the resulting Chimera models to inherit reasoning strength without replicating the verbosity or latency of the strongest parent models.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-performance-and-speed-what-the-benchmarks-actually-show"&gt;Performance and Speed: What the Benchmarks Actually Show&lt;/h2&gt;



&lt;p&gt;According to benchmark comparisons presented by TNG, R1T2 achieves between &lt;strong&gt;90% and 92%&lt;/strong&gt; of the reasoning performance of its most intelligent parent, DeepSeek-R1-0528, as measured by AIME-24, AIME-25, and GPQA-Diamond test sets. &lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3013743" height="598" src="https://venturebeat.com/wp-content/uploads/2025/07/Gu4d8kzWoAA9ohx.jpg?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;However, unlike DeepSeek-R1-0528 — which tends to produce long, detailed answers due to its extended chain-of-thought reasoning — R1T2 is designed to be much more concise. It delivers similarly intelligent responses while using significantly fewer words.&lt;/p&gt;



&lt;p&gt;Rather than focusing on raw processing time or tokens-per-second, TNG measures “speed” in terms of &lt;strong&gt;output token count per answer&lt;/strong&gt; — a practical proxy for both cost and latency. According to benchmarks shared by TNG, R1T2 generates responses using &lt;strong&gt;approximately 40% of the tokens&lt;/strong&gt; required by R1-0528. &lt;/p&gt;



&lt;p&gt;That translates to a &lt;strong&gt;60% reduction in output length&lt;/strong&gt;, which directly reduces inference time and compute load, speeding up responses by 2X, or 200%.&lt;/p&gt;



&lt;p&gt;When compared to the original DeepSeek-R1, R1T2 is also around &lt;strong&gt;20% more concise on average&lt;/strong&gt;, offering meaningful gains in efficiency for high-throughput or cost-sensitive deployments.&lt;/p&gt;



&lt;p&gt;This efficiency does not come at the cost of intelligence. As shown in the benchmark chart presented in TNG’s technical paper, R1T2 sits in a desirable zone on the intelligence vs. output cost curve. It preserves reasoning quality while minimizing verbosity — an outcome critical to enterprise applications where inference speed, throughput, and cost all matter.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-deployment-considerations-and-availability"&gt;Deployment Considerations and Availability&lt;/h2&gt;



&lt;p&gt;R1T2 is released under a permissive MIT License and is available now on Hugging Face, meaning it is open source and available to be used and built into commercial applications. &lt;/p&gt;



&lt;p&gt;TNG notes that while the model is well-suited for general reasoning tasks, it is not currently recommended for use cases requiring function calling or tool use, due to limitations inherited from its DeepSeek-R1 lineage. These may be addressed in future updates.&lt;/p&gt;



&lt;p&gt;The company also advises European users to assess compliance with the EU AI Act, which comes into effect on August 2, 2025. &lt;/p&gt;



&lt;p&gt;Enterprises operating in the EU should review relevant provisions or consider halting model use after that date if requirements cannot be met.&lt;/p&gt;



&lt;p&gt;However, U.S. companies operating domestically and servicing U.S.-based users, or those of other nations, are &lt;em&gt;not&lt;/em&gt; subject to the terms of the EU AI Act, which should give them considerable flexibility when using and deploying this free, speedy open source reasoning model. If they service users in the E.U., some provisions of the EU Act will still apply. &lt;/p&gt;



&lt;p&gt;TNG has already made prior Chimera variants available through platforms like OpenRouter and Chutes, where they reportedly processed billions of tokens daily. The release of R1T2 represents a further evolution in this public availability effort.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-about-tng-technology-consulting-gmbh"&gt;About TNG Technology Consulting GmbH&lt;/h2&gt;



&lt;p&gt;Founded in January 2001, TNG Technology Consulting GmbH is based in Bavaria, Germany, and employs over 900 people, with a high concentration of PhDs and technical specialists. &lt;/p&gt;



&lt;p&gt;The company focuses on software development, artificial intelligence, and DevOps/cloud services, serving major enterprise clients across industries such as telecommunications, insurance, automotive, e-commerce, and logistics.&lt;/p&gt;



&lt;p&gt;TNG operates as a values-based consulting partnership. Its unique structure, grounded in operational research and self-management principles, supports a culture of technical innovation. &lt;/p&gt;



&lt;p&gt;It actively contributes to open-source communities and research, as demonstrated through public releases like R1T2 and the publication of its Assembly-of-Experts methodology.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-it-means-for-enterprise-technical-decision-makers"&gt;What It Means for Enterprise Technical Decision-Makers&lt;/h2&gt;



&lt;p&gt;For CTOs, AI platform owners, engineering leads, and IT procurement teams, R1T2 introduces tangible benefits and strategic options:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Lower Inference Costs&lt;/strong&gt;: With fewer output tokens per task, R1T2 reduces GPU time and energy consumption, translating directly into infrastructure savings — especially important in high-throughput or real-time environments.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;High Reasoning Quality Without Overhead&lt;/strong&gt;: It preserves much of the reasoning power of top-tier models like R1-0528, but without their long-windedness. This is ideal for structured tasks (math, programming, logic) where concise answers are preferable.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Open and Modifiable&lt;/strong&gt;: The MIT License allows full deployment control and customization, enabling private hosting, model alignment, or further training within regulated or air-gapped environments.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Emerging Modularity&lt;/strong&gt;: The AoE approach suggests a future where models are built modularly, allowing enterprises to assemble specialized variants by recombining strengths of existing models, rather than retraining from scratch.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Caveats&lt;/strong&gt;: Enterprises relying on function-calling, tool use, or advanced agent orchestration should note current limitations, though future Chimera updates may address these gaps.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;TNG encourages researchers, developers, and enterprise users to explore the model, test its behavior, and provide feedback. The R1T2 Chimera is available at huggingface.co/tngtech/DeepSeek-TNG-R1T2-Chimera, and technical inquiries can be directed to &lt;strong&gt;research@tngtech.com&lt;/strong&gt;.&lt;/p&gt;



&lt;p&gt;For technical background and benchmark methodology, TNG’s research paper is available at arXiv:2506.14794.&lt;/p&gt;




&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;It’s been a little more than a month since Chinese AI startup DeepSeek, an offshoot of Hong Kong-based High-Flyer Capital Management, released the latest version of its hit open source model DeepSeek, R1-0528.&lt;/p&gt;



&lt;p&gt;Like its predecessor, DeepSeek-R1 — which rocked the AI and global business communities with how cheaply it was trained and how well it performed on reasoning tasks, all available to developers and enterprises for free — R1-0528 is already being adapted and remixed by other AI labs and developers, thanks in large part to its permissive Apache 2.0 license.&lt;/p&gt;



&lt;p&gt;This week, the 24-year-old German firm TNG Technology Consulting GmbH released one such adaptation: DeepSeek-TNG R1T2 Chimera, the latest model in its Chimera large language model (LLM) family. R1T2 delivers a notable boost in efficiency and speed, scoring at upwards of &lt;strong&gt;90% of R1-0528’s intelligence benchmark scores&lt;/strong&gt;, while generating answers with &lt;strong&gt;less than 40% of R1-0528’s output token count&lt;/strong&gt;. &lt;/p&gt;



&lt;p&gt;That means it produces shorter responses, translating directly into &lt;strong&gt;faster inference and lower compute costs&lt;/strong&gt;. On the model card TNG released for its new R1T2 on the AI code sharing community Hugging Face, the company states that it is “about 20% faster than the regular R1” (the one released back in January) “and more than twice as fast as R1-0528” (the May official update from DeepSeek).&lt;/p&gt;



&lt;p&gt;Already, the response has been incredibly positive from the AI developer community. “DAMN! DeepSeek R1T2 – 200% faster than R1-0528 &amp;amp; 20% faster than R1,” wrote Vaibhav (VB) Srivastav, a senior leader at Hugging Face, on X. “Significantly better than R1 on GPQA &amp;amp; AIME 24, made via Assembly of Experts with DS V3, R1 &amp;amp; R1-0528 — and it’s MIT-licensed, available on Hugging Face.”&lt;/p&gt;



&lt;p&gt;This gain is made possible by TNG’s Assembly-of-Experts (AoE) method — a technique for building LLMs by selectively merging the weight tensors (internal parameters) from multiple pre-trained models that TNG described in a paper published in May on arXiv, the non-peer reviewed open access online journal. &lt;/p&gt;



&lt;p&gt;A successor to the original R1T Chimera, R1T2 introduces a new “Tri-Mind” configuration that integrates three parent models: DeepSeek-R1-0528, DeepSeek-R1, and DeepSeek-V3-0324. The result is a model engineered to maintain high reasoning capability while significantly reducing inference cost.&lt;/p&gt;



&lt;p&gt;R1T2 is constructed without further fine-tuning or retraining. It inherits the reasoning strength of R1-0528, the structured thought patterns of R1, and the concise, instruction-oriented behavior of V3-0324 — delivering a more efficient, yet capable model for enterprise and research use.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-assembly-of-experts-aoe-differs-from-mixture-of-experts-moe"&gt;How Assembly-of-Experts (AoE) Differs from Mixture-of-Experts (MoE)&lt;/h2&gt;



&lt;p&gt;Mixture-of-Experts (MoE) is an architectural design in which different components, or “experts,” are conditionally activated per input. In MoE LLMs like DeepSeek-V3 or Mixtral, only a subset of the model’s expert layers (e.g., 8 out of 256) are active during any given token’s forward pass. This allows very large models to achieve higher parameter counts and specialization while keeping inference costs manageable — because only a fraction of the network is evaluated per token.&lt;/p&gt;



&lt;p&gt;Assembly-of-Experts (AoE) is a model merging technique, not an architecture. It’s used to create a new model from multiple pre-trained MoE models by selectively interpolating their weight tensors. &lt;/p&gt;



&lt;p&gt;The “experts” in AoE refer to the model components being merged — typically the routed expert tensors within MoE layers — not experts dynamically activated at runtime.&lt;/p&gt;



&lt;p&gt;TNG’s implementation of AoE focuses primarily on merging routed expert tensors — the part of a model most responsible for specialized reasoning — while often retaining the more efficient shared and attention layers from faster models like V3-0324. This approach enables the resulting Chimera models to inherit reasoning strength without replicating the verbosity or latency of the strongest parent models.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-performance-and-speed-what-the-benchmarks-actually-show"&gt;Performance and Speed: What the Benchmarks Actually Show&lt;/h2&gt;



&lt;p&gt;According to benchmark comparisons presented by TNG, R1T2 achieves between &lt;strong&gt;90% and 92%&lt;/strong&gt; of the reasoning performance of its most intelligent parent, DeepSeek-R1-0528, as measured by AIME-24, AIME-25, and GPQA-Diamond test sets. &lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3013743" height="598" src="https://venturebeat.com/wp-content/uploads/2025/07/Gu4d8kzWoAA9ohx.jpg?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;However, unlike DeepSeek-R1-0528 — which tends to produce long, detailed answers due to its extended chain-of-thought reasoning — R1T2 is designed to be much more concise. It delivers similarly intelligent responses while using significantly fewer words.&lt;/p&gt;



&lt;p&gt;Rather than focusing on raw processing time or tokens-per-second, TNG measures “speed” in terms of &lt;strong&gt;output token count per answer&lt;/strong&gt; — a practical proxy for both cost and latency. According to benchmarks shared by TNG, R1T2 generates responses using &lt;strong&gt;approximately 40% of the tokens&lt;/strong&gt; required by R1-0528. &lt;/p&gt;



&lt;p&gt;That translates to a &lt;strong&gt;60% reduction in output length&lt;/strong&gt;, which directly reduces inference time and compute load, speeding up responses by 2X, or 200%.&lt;/p&gt;



&lt;p&gt;When compared to the original DeepSeek-R1, R1T2 is also around &lt;strong&gt;20% more concise on average&lt;/strong&gt;, offering meaningful gains in efficiency for high-throughput or cost-sensitive deployments.&lt;/p&gt;



&lt;p&gt;This efficiency does not come at the cost of intelligence. As shown in the benchmark chart presented in TNG’s technical paper, R1T2 sits in a desirable zone on the intelligence vs. output cost curve. It preserves reasoning quality while minimizing verbosity — an outcome critical to enterprise applications where inference speed, throughput, and cost all matter.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-deployment-considerations-and-availability"&gt;Deployment Considerations and Availability&lt;/h2&gt;



&lt;p&gt;R1T2 is released under a permissive MIT License and is available now on Hugging Face, meaning it is open source and available to be used and built into commercial applications. &lt;/p&gt;



&lt;p&gt;TNG notes that while the model is well-suited for general reasoning tasks, it is not currently recommended for use cases requiring function calling or tool use, due to limitations inherited from its DeepSeek-R1 lineage. These may be addressed in future updates.&lt;/p&gt;



&lt;p&gt;The company also advises European users to assess compliance with the EU AI Act, which comes into effect on August 2, 2025. &lt;/p&gt;



&lt;p&gt;Enterprises operating in the EU should review relevant provisions or consider halting model use after that date if requirements cannot be met.&lt;/p&gt;



&lt;p&gt;However, U.S. companies operating domestically and servicing U.S.-based users, or those of other nations, are &lt;em&gt;not&lt;/em&gt; subject to the terms of the EU AI Act, which should give them considerable flexibility when using and deploying this free, speedy open source reasoning model. If they service users in the E.U., some provisions of the EU Act will still apply. &lt;/p&gt;



&lt;p&gt;TNG has already made prior Chimera variants available through platforms like OpenRouter and Chutes, where they reportedly processed billions of tokens daily. The release of R1T2 represents a further evolution in this public availability effort.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-about-tng-technology-consulting-gmbh"&gt;About TNG Technology Consulting GmbH&lt;/h2&gt;



&lt;p&gt;Founded in January 2001, TNG Technology Consulting GmbH is based in Bavaria, Germany, and employs over 900 people, with a high concentration of PhDs and technical specialists. &lt;/p&gt;



&lt;p&gt;The company focuses on software development, artificial intelligence, and DevOps/cloud services, serving major enterprise clients across industries such as telecommunications, insurance, automotive, e-commerce, and logistics.&lt;/p&gt;



&lt;p&gt;TNG operates as a values-based consulting partnership. Its unique structure, grounded in operational research and self-management principles, supports a culture of technical innovation. &lt;/p&gt;



&lt;p&gt;It actively contributes to open-source communities and research, as demonstrated through public releases like R1T2 and the publication of its Assembly-of-Experts methodology.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-it-means-for-enterprise-technical-decision-makers"&gt;What It Means for Enterprise Technical Decision-Makers&lt;/h2&gt;



&lt;p&gt;For CTOs, AI platform owners, engineering leads, and IT procurement teams, R1T2 introduces tangible benefits and strategic options:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Lower Inference Costs&lt;/strong&gt;: With fewer output tokens per task, R1T2 reduces GPU time and energy consumption, translating directly into infrastructure savings — especially important in high-throughput or real-time environments.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;High Reasoning Quality Without Overhead&lt;/strong&gt;: It preserves much of the reasoning power of top-tier models like R1-0528, but without their long-windedness. This is ideal for structured tasks (math, programming, logic) where concise answers are preferable.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Open and Modifiable&lt;/strong&gt;: The MIT License allows full deployment control and customization, enabling private hosting, model alignment, or further training within regulated or air-gapped environments.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Emerging Modularity&lt;/strong&gt;: The AoE approach suggests a future where models are built modularly, allowing enterprises to assemble specialized variants by recombining strengths of existing models, rather than retraining from scratch.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Caveats&lt;/strong&gt;: Enterprises relying on function-calling, tool use, or advanced agent orchestration should note current limitations, though future Chimera updates may address these gaps.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;TNG encourages researchers, developers, and enterprise users to explore the model, test its behavior, and provide feedback. The R1T2 Chimera is available at huggingface.co/tngtech/DeepSeek-TNG-R1T2-Chimera, and technical inquiries can be directed to &lt;strong&gt;research@tngtech.com&lt;/strong&gt;.&lt;/p&gt;



&lt;p&gt;For technical background and benchmark methodology, TNG’s research paper is available at arXiv:2506.14794.&lt;/p&gt;




&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/holy-smokes-a-new-200-faster-deepseek-r1-0528-variant-appears-from-german-lab-tng-technology-consulting-gmbh/</guid><pubDate>Thu, 03 Jul 2025 13:32:44 +0000</pubDate></item><item><title>[NEW] Writer CEO May Habib to take the AI Stage at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/03/writer-ceo-may-habib-to-take-the-ai-stage-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI agents are reshaping how work gets done across industries, and at &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, one of the leading voices in that transformation is stepping onto the AI Stage. May Habib, CEO and co-founder of Writer, will join us in San Francisco, October 27-29, for a fireside chat that dives deep into how enterprises are operationalizing AI — at scale and with speed. With more than 10,000 startup and VC leaders attending the event, this session is set to be one of the most timely and talked-about conversations on the &lt;strong&gt;agenda&lt;/strong&gt;.&lt;br /&gt;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 May Habib " class="wp-image-3024496" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/TC25_May-Habib-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-inside-the-enterprise-ai-revolution"&gt;Inside the enterprise AI revolution&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;As the CEO of Writer, Habib has led one of the fastest-growing generative AI companies in the world. From financial services to clinical research to global e-commerce, companies like Uber, Intuit, Accenture, and Vanguard are using Writer’s AI agent platform to transform mission-critical operations. These aren’t just tools — they’re intelligent systems built with domain-specific language models that adapt, learn, and deliver results.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Habib is also the driving force behind Palmyra, Writer’s family of enterprise-grade LLMs that power these AI agents. Known for their transparency, reliability, and performance, Palmyra models have set new standards for what enterprise grade really means in the AI era. Under Habib’s leadership, Writer has raised more than $326 million, reached a $1.9 billion valuation, and built the world’s only enterprise-specific AI research lab.&lt;/p&gt;

&lt;h2 class="wp-block-heading"&gt;What to expect on the AI Stage&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;This fireside chat&lt;/strong&gt; will go beyond the headlines to explore how enterprise AI agents are being deployed right now, what it takes to scale them responsibly, and how companies are preparing for what comes next. This conversation will offer real-world insight into how AI is moving from experimentation to execution.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Catch it live on the AI Stage at TechCrunch Disrupt 2025. It’s all happening October 27–29 at Moscone West in San Francisco. &lt;strong&gt;Register now&lt;/strong&gt; to join more than 10,000 startup and VC leaders and &lt;strong&gt;save up to $675&lt;/strong&gt; before prices increase.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI agents are reshaping how work gets done across industries, and at &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, one of the leading voices in that transformation is stepping onto the AI Stage. May Habib, CEO and co-founder of Writer, will join us in San Francisco, October 27-29, for a fireside chat that dives deep into how enterprises are operationalizing AI — at scale and with speed. With more than 10,000 startup and VC leaders attending the event, this session is set to be one of the most timely and talked-about conversations on the &lt;strong&gt;agenda&lt;/strong&gt;.&lt;br /&gt;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 May Habib " class="wp-image-3024496" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/TC25_May-Habib-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-inside-the-enterprise-ai-revolution"&gt;Inside the enterprise AI revolution&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;As the CEO of Writer, Habib has led one of the fastest-growing generative AI companies in the world. From financial services to clinical research to global e-commerce, companies like Uber, Intuit, Accenture, and Vanguard are using Writer’s AI agent platform to transform mission-critical operations. These aren’t just tools — they’re intelligent systems built with domain-specific language models that adapt, learn, and deliver results.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Habib is also the driving force behind Palmyra, Writer’s family of enterprise-grade LLMs that power these AI agents. Known for their transparency, reliability, and performance, Palmyra models have set new standards for what enterprise grade really means in the AI era. Under Habib’s leadership, Writer has raised more than $326 million, reached a $1.9 billion valuation, and built the world’s only enterprise-specific AI research lab.&lt;/p&gt;

&lt;h2 class="wp-block-heading"&gt;What to expect on the AI Stage&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;This fireside chat&lt;/strong&gt; will go beyond the headlines to explore how enterprise AI agents are being deployed right now, what it takes to scale them responsibly, and how companies are preparing for what comes next. This conversation will offer real-world insight into how AI is moving from experimentation to execution.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Catch it live on the AI Stage at TechCrunch Disrupt 2025. It’s all happening October 27–29 at Moscone West in San Francisco. &lt;strong&gt;Register now&lt;/strong&gt; to join more than 10,000 startup and VC leaders and &lt;strong&gt;save up to $675&lt;/strong&gt; before prices increase.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/03/writer-ceo-may-habib-to-take-the-ai-stage-at-techcrunch-disrupt-2025/</guid><pubDate>Thu, 03 Jul 2025 14:00:00 +0000</pubDate></item><item><title>[NEW] xAI gets permits for 15 natural gas generators at Memphis data center (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/03/xai-gets-permits-for-15-natural-gas-generators-at-memphis-data-center/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-2217198328.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;County regulators yesterday granted xAI permits to operate 15 natural gas turbines at its data center outside Memphis, despite the threat of a lawsuit. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Elon Musk’s AI company has been operating as many as 35 generators without permits, the Southern Environmental Law Center (SELC) said. Altogether, they’re capable of producing up to 421 megawatts of electricity. The legal organization has said that it will sue xAI for violations of the Clean Air Act on behalf of the NAACP.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company recently raised $10 billion, split evenly between debt and equity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The permit issued by the Shelby County Health Department says that xAI can operate 15 Solar SMT-130 generators with certain emissions controls, which can generate up to 247 megawatts. The company has already been operating eight of the same model without permits, according to the SELC, though the group added that the ones in operation do have the appropriate pollution controls.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Under the conditions of the permit, xAI will still be allowed to emit significant amounts of pollution on a rolling 12-month basis, including 87 tons of smog-forming NO&lt;sub&gt;x&lt;/sub&gt;, 94 tons of carbon monoxide, 85 tons of volatile organic compounds, 73 tons of particulate pollution, and nearly 14 tons of hazardous air pollutants, including 9.8 tons of formaldehyde, a known carcinogen. The company is required to keep its own emissions records.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Before the permit was issued, a Memphis community group said that it had $250,000 in funds to pay for an independent air quality study.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The City of Memphis performed its own air quality testing in June, though the SELC raised several concerns about the way the tests were carried out.&amp;nbsp;&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;The testing contractor did not measure ozone levels, the SELC noted, and the tests were done on days when the wind was blowing xAI’s pollution away from the two closest testing sites. The contractor also placed the testing equipment either directly against or in close proximity to buildings, which can interfere with results.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Previously, the health department claimed that it did not have the authority to permit “mobile” gas-burning turbines if they were in operation for less than 364 days, saying that under those circumstances, the EPA was the relevant regulator. The SELC said that the interpretation of the law was “incorrect” and the letter justifying inaction was “without any legal analysis.”&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-2217198328.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;County regulators yesterday granted xAI permits to operate 15 natural gas turbines at its data center outside Memphis, despite the threat of a lawsuit. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Elon Musk’s AI company has been operating as many as 35 generators without permits, the Southern Environmental Law Center (SELC) said. Altogether, they’re capable of producing up to 421 megawatts of electricity. The legal organization has said that it will sue xAI for violations of the Clean Air Act on behalf of the NAACP.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company recently raised $10 billion, split evenly between debt and equity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The permit issued by the Shelby County Health Department says that xAI can operate 15 Solar SMT-130 generators with certain emissions controls, which can generate up to 247 megawatts. The company has already been operating eight of the same model without permits, according to the SELC, though the group added that the ones in operation do have the appropriate pollution controls.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Under the conditions of the permit, xAI will still be allowed to emit significant amounts of pollution on a rolling 12-month basis, including 87 tons of smog-forming NO&lt;sub&gt;x&lt;/sub&gt;, 94 tons of carbon monoxide, 85 tons of volatile organic compounds, 73 tons of particulate pollution, and nearly 14 tons of hazardous air pollutants, including 9.8 tons of formaldehyde, a known carcinogen. The company is required to keep its own emissions records.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Before the permit was issued, a Memphis community group said that it had $250,000 in funds to pay for an independent air quality study.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The City of Memphis performed its own air quality testing in June, though the SELC raised several concerns about the way the tests were carried out.&amp;nbsp;&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;The testing contractor did not measure ozone levels, the SELC noted, and the tests were done on days when the wind was blowing xAI’s pollution away from the two closest testing sites. The contractor also placed the testing equipment either directly against or in close proximity to buildings, which can interfere with results.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Previously, the health department claimed that it did not have the authority to permit “mobile” gas-burning turbines if they were in operation for less than 364 days, saying that under those circumstances, the EPA was the relevant regulator. The SELC said that the interpretation of the law was “incorrect” and the letter justifying inaction was “without any legal analysis.”&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/03/xai-gets-permits-for-15-natural-gas-generators-at-memphis-data-center/</guid><pubDate>Thu, 03 Jul 2025 14:45:34 +0000</pubDate></item><item><title>[NEW] xAI data center gets air permit to run 15 turbines, but imaging shows 24 on site (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/07/xai-gets-an-air-permit-to-power-its-supercomputer-but-pollution-fears-remain/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        County health department accused of turning a "blind eye" to xAI's alleged pollution.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="528" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/xAI-Satellite-Image-via-SELC-640x528.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/xAI-Satellite-Image-via-SELC-944x648.jpg" width="944" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A satellite image of xAI's Memphis data center showed 24 turbines on July 1, the Southern Environmental Law Center reported.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Satellite image via the Southern Environmental Law Center

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;After months of backlash over alleged pollution concerns, xAI has finally secured an air permit covering some of the methane gas turbines powering its Colossus supercomputer data center in Memphis, Tennessee.&lt;/p&gt;
&lt;p&gt;On Wednesday, the Shelby County Health Department granted xAI an air permit that allows it to power 15 gas turbines while adhering to a range of restrictions designed to minimize emissions. Expiring on January 2, 2027, the permit requires xAI to install and operate the best available control technology (BACT) by September 1 to ensure emissions do not exceed certain limits.&lt;/p&gt;
&lt;p&gt;Any failure to comply could trigger enforcement actions by the Environmental Protection Agency or the county health department, the permit notes.&lt;/p&gt;
&lt;p&gt;But Memphis residents insist that the health department should already be investigating xAI for possible enforcement actions. They claim that the AI company owned by Elon Musk has been operating dozens of turbines without BACT for more than a year, exposing predominantly Black neighborhoods located near the facility—who have historically suffered from industrial poor air quality—to a potential new major source of pollution. In June, the NAACP threatened legal action within 60 days&amp;nbsp;if xAI refused to meet with groups concerned about the alleged smog-forming pollution.&lt;/p&gt;
&lt;p&gt;The fact that the health department is finally requiring xAI to install BACT is not a comfort to residents, the Southern Environmental Law Center said in a press release sent to Ars. Most glaringly, the air permit does not seem to cover all the gas turbines potentially operating at the facility, the SELC noted. Thermal imaging taken July 1 shows that xAI maintains 24 gas turbines on site, the SELC said, which is substantially more than the 15 that xAI will soon be required to dutifully report on—tracking every startup, shutdown, and combustion so that the health department can finally start tracking emissions.&lt;/p&gt;
&lt;p&gt;According to the SELC, the health department's decision granting permits covering some of xAI's turbines—but not all of them—"ignores the facility’s continued use of turbines not covered by the permit and months of intense public pushback from local communities in Memphis who worry about the impact xAI’s operations will have on their air."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;For Memphis residents, xAI's facility operating even a single turbine without BACT potentially threatens to release pollutants "tied to asthma, respiratory illnesses, heart problems, and even certain types of cancer." These communities already live in a place that does not meet national standards for smog, the SELC said, and they "face elevated asthma rates and cancer risks four times the national average."&lt;/p&gt;
&lt;p&gt;In the press release, critics decried the health department's decision to grant xAI the permits. LaTricea Adams, the CEO and president of Young, Gifted &amp;amp; Green, described the decision as "a stark reminder that our community's health continues to be compromised for profit."&lt;/p&gt;
&lt;p&gt;SELC Senior Attorney Amanda Garcia accused the health department of "turning a blind eye to obvious Clean Air Act violations in order to allow another polluter to set up shop in this already-overburdened community without appropriate protections." She confirmed that the SELC is evaluating its options to move forward with its efforts to confront xAI and demand more transparency.&lt;/p&gt;
&lt;p&gt;To community members, the health department's decision to grant the permits without probing xAI's alleged unlawful operations over the past year was "devastating," KeShaun Pearson, director of Memphis Community Against Pollution, said.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;"We are deeply disappointed and oppose the decision by our Shelby County Health Department to approve the permit without meaningfully addressing the unlawful use of turbines on the site," Pearson said. "Our local leaders are entrusted with protecting us from corporations violating on our right to clean air, but we are witnessing their failure to do so. We are devastated, yet we remain determined to the mission of justice for our families in South Memphis who are overburdened with air pollution."&lt;/p&gt;
&lt;p&gt;xAI and the Shelby County Health Department did not immediately respond to Ars' request to comment.&lt;/p&gt;
&lt;h2&gt;Critics demand more transparency from xAI&lt;/h2&gt;
&lt;p&gt;While critics continue to fight for more transparency, they also acknowledge that the overdue air permit at least suggests that some of xAI's feared pollution could be checked in the future.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Before xAI got the permit, residents were stuck relying on infrequent thermal imaging to determine how many turbines appeared to be running without BACT. Now that xAI has secured the permit, the company will be required to "record the date, time, and durations of all startups, shutdowns, malfunctions, and tuning events" and "always minimize emissions including startup, shutdown, maintenance, and combustion tuning periods."&lt;/p&gt;
&lt;p&gt;These records—which also document fuel usage, facility-wide emissions, and excess emissions—must be shared with the health department semiannually, with xAI's first report due by December 31. Additionally, xAI must maintain five years of "monitoring, preventive, and maintenance records for air pollution control equipment," which the department can request to review at any time.&lt;/p&gt;
&lt;p&gt;For Memphis residents worried about smog-forming pollution, the worst fear would likely be visibly detecting the pollution. Mitigating this, xAI's air permit requires that visible emissions "from each emission point at the facility shall not exceed" 20 percent in opacity for more than minutes in any one-hour period or more than 20 minutes in any 24-hour period.&lt;/p&gt;
&lt;p&gt;It also prevents xAI from operating turbines all the time, limiting xAI to "a maximum of 22 startup events and 22 shutdown events per year" for the 15 turbines included in the permit, "with a total combined duration of 110 hours annually." Additionally, it specifies that each startup or shutdown event must not exceed one hour.&lt;/p&gt;
&lt;p&gt;A senior communications manager for the SELC, Eric Hilt, told Ars that the "SELC and our partners intend to continue monitoring xAI's operations in the Memphis area." He further noted that the air permit does not address all of citizens' concerns at a time when xAI is planning to build another data center in the area, sparking new questions.&lt;/p&gt;
&lt;p&gt;"While these permits increase the amount of public information and accountability around 15 of xAI's turbines, there are still significant concerns around transparency—both for xAI's first South Memphis data center near the Boxtown neighborhood and the planned data center in the Whitehaven neighborhood," Hilt said. "XAI has not said how that second data center will be powered or if it plans to use gas turbines for that facility as well."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        County health department accused of turning a "blind eye" to xAI's alleged pollution.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="528" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/xAI-Satellite-Image-via-SELC-640x528.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/xAI-Satellite-Image-via-SELC-944x648.jpg" width="944" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A satellite image of xAI's Memphis data center showed 24 turbines on July 1, the Southern Environmental Law Center reported.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Satellite image via the Southern Environmental Law Center

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;After months of backlash over alleged pollution concerns, xAI has finally secured an air permit covering some of the methane gas turbines powering its Colossus supercomputer data center in Memphis, Tennessee.&lt;/p&gt;
&lt;p&gt;On Wednesday, the Shelby County Health Department granted xAI an air permit that allows it to power 15 gas turbines while adhering to a range of restrictions designed to minimize emissions. Expiring on January 2, 2027, the permit requires xAI to install and operate the best available control technology (BACT) by September 1 to ensure emissions do not exceed certain limits.&lt;/p&gt;
&lt;p&gt;Any failure to comply could trigger enforcement actions by the Environmental Protection Agency or the county health department, the permit notes.&lt;/p&gt;
&lt;p&gt;But Memphis residents insist that the health department should already be investigating xAI for possible enforcement actions. They claim that the AI company owned by Elon Musk has been operating dozens of turbines without BACT for more than a year, exposing predominantly Black neighborhoods located near the facility—who have historically suffered from industrial poor air quality—to a potential new major source of pollution. In June, the NAACP threatened legal action within 60 days&amp;nbsp;if xAI refused to meet with groups concerned about the alleged smog-forming pollution.&lt;/p&gt;
&lt;p&gt;The fact that the health department is finally requiring xAI to install BACT is not a comfort to residents, the Southern Environmental Law Center said in a press release sent to Ars. Most glaringly, the air permit does not seem to cover all the gas turbines potentially operating at the facility, the SELC noted. Thermal imaging taken July 1 shows that xAI maintains 24 gas turbines on site, the SELC said, which is substantially more than the 15 that xAI will soon be required to dutifully report on—tracking every startup, shutdown, and combustion so that the health department can finally start tracking emissions.&lt;/p&gt;
&lt;p&gt;According to the SELC, the health department's decision granting permits covering some of xAI's turbines—but not all of them—"ignores the facility’s continued use of turbines not covered by the permit and months of intense public pushback from local communities in Memphis who worry about the impact xAI’s operations will have on their air."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;For Memphis residents, xAI's facility operating even a single turbine without BACT potentially threatens to release pollutants "tied to asthma, respiratory illnesses, heart problems, and even certain types of cancer." These communities already live in a place that does not meet national standards for smog, the SELC said, and they "face elevated asthma rates and cancer risks four times the national average."&lt;/p&gt;
&lt;p&gt;In the press release, critics decried the health department's decision to grant xAI the permits. LaTricea Adams, the CEO and president of Young, Gifted &amp;amp; Green, described the decision as "a stark reminder that our community's health continues to be compromised for profit."&lt;/p&gt;
&lt;p&gt;SELC Senior Attorney Amanda Garcia accused the health department of "turning a blind eye to obvious Clean Air Act violations in order to allow another polluter to set up shop in this already-overburdened community without appropriate protections." She confirmed that the SELC is evaluating its options to move forward with its efforts to confront xAI and demand more transparency.&lt;/p&gt;
&lt;p&gt;To community members, the health department's decision to grant the permits without probing xAI's alleged unlawful operations over the past year was "devastating," KeShaun Pearson, director of Memphis Community Against Pollution, said.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;"We are deeply disappointed and oppose the decision by our Shelby County Health Department to approve the permit without meaningfully addressing the unlawful use of turbines on the site," Pearson said. "Our local leaders are entrusted with protecting us from corporations violating on our right to clean air, but we are witnessing their failure to do so. We are devastated, yet we remain determined to the mission of justice for our families in South Memphis who are overburdened with air pollution."&lt;/p&gt;
&lt;p&gt;xAI and the Shelby County Health Department did not immediately respond to Ars' request to comment.&lt;/p&gt;
&lt;h2&gt;Critics demand more transparency from xAI&lt;/h2&gt;
&lt;p&gt;While critics continue to fight for more transparency, they also acknowledge that the overdue air permit at least suggests that some of xAI's feared pollution could be checked in the future.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Before xAI got the permit, residents were stuck relying on infrequent thermal imaging to determine how many turbines appeared to be running without BACT. Now that xAI has secured the permit, the company will be required to "record the date, time, and durations of all startups, shutdowns, malfunctions, and tuning events" and "always minimize emissions including startup, shutdown, maintenance, and combustion tuning periods."&lt;/p&gt;
&lt;p&gt;These records—which also document fuel usage, facility-wide emissions, and excess emissions—must be shared with the health department semiannually, with xAI's first report due by December 31. Additionally, xAI must maintain five years of "monitoring, preventive, and maintenance records for air pollution control equipment," which the department can request to review at any time.&lt;/p&gt;
&lt;p&gt;For Memphis residents worried about smog-forming pollution, the worst fear would likely be visibly detecting the pollution. Mitigating this, xAI's air permit requires that visible emissions "from each emission point at the facility shall not exceed" 20 percent in opacity for more than minutes in any one-hour period or more than 20 minutes in any 24-hour period.&lt;/p&gt;
&lt;p&gt;It also prevents xAI from operating turbines all the time, limiting xAI to "a maximum of 22 startup events and 22 shutdown events per year" for the 15 turbines included in the permit, "with a total combined duration of 110 hours annually." Additionally, it specifies that each startup or shutdown event must not exceed one hour.&lt;/p&gt;
&lt;p&gt;A senior communications manager for the SELC, Eric Hilt, told Ars that the "SELC and our partners intend to continue monitoring xAI's operations in the Memphis area." He further noted that the air permit does not address all of citizens' concerns at a time when xAI is planning to build another data center in the area, sparking new questions.&lt;/p&gt;
&lt;p&gt;"While these permits increase the amount of public information and accountability around 15 of xAI's turbines, there are still significant concerns around transparency—both for xAI's first South Memphis data center near the Boxtown neighborhood and the planned data center in the Whitehaven neighborhood," Hilt said. "XAI has not said how that second data center will be powered or if it plans to use gas turbines for that facility as well."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/07/xai-gets-an-air-permit-to-power-its-supercomputer-but-pollution-fears-remain/</guid><pubDate>Thu, 03 Jul 2025 15:34:41 +0000</pubDate></item><item><title>[NEW] OpenAI rejects Robinhood’s unauthorised tokenised shares (AI News)</title><link>https://www.artificialintelligence-news.com/news/openai-rejects-robinhood-unauthorised-tokenised-shares/</link><description>&lt;p&gt;Robinhood has begun offering tokenised shares in private companies, sparking backlash from OpenAI as one of the targeted firms.&lt;/p&gt;&lt;p&gt;During an event in Cannes on Monday, Robinhood co-founder and CEO Vlad Tenev displayed what he described as “stock tokens” for OpenAI and SpaceX. The move forms part of Robinhood’s European expansion, which also includes offering more than 200 tokenised shares of publicly-traded US stocks to EU users.&lt;/p&gt;&lt;p&gt;Tenev told attendees that European users who download the Robinhood app would have the opportunity to own tokenised shares in OpenAI and Elon Musk’s space exploration venture SpaceX, both of which are private companies that haven’t announced plans to go public.&lt;/p&gt;&lt;p&gt;The trading platform explains on its website: “Robinhood Stock Tokens follow the prices of publicly-traded stocks and ETFs — they are derivatives tracked on the blockchain, giving you exposure to the US market. When buying stock tokens, you are not buying the actual stocks — you are buying tokenised contracts that follow their price, recorded on a blockchain.”&lt;/p&gt;&lt;p&gt;This distinction means token holders wouldn’t enjoy traditional shareholder rights, such as voting privileges, despite having financial exposure to the companies.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-openai-rebuffs-robinhood-s-tokenised-shares-offering"&gt;OpenAI rebuffs Robinhood’s tokenised shares offering&lt;/h3&gt;&lt;p&gt;The announcement triggered a sharp rebuke from OpenAI. The high-profile AI firm, led by Sam Altman, categorically denied any involvement with Robinhood’s initiative.&lt;/p&gt;&lt;p&gt;“These ‘OpenAI tokens’ are not OpenAI equity,” the company stated in a post on X. “We did not partner with Robinhood, were not involved in this, and do not endorse it. Any transfer of OpenAI equity requires our approval — we did not approve any transfer. Please be careful.”&lt;/p&gt;&lt;p&gt;Industry observers note that Robinhood’s approach appears designed to provide price exposure to underlying equities rather than actual ownership, likely structured this way to navigate complex regulatory requirements.&lt;/p&gt;&lt;p&gt;This mechanism bears similarities to offerings from other financial technology firms. For instance, cryptocurrency platform Kraken offers products called xStocks that likewise don’t represent direct equity ownership but are instead backed by underlying shares.&lt;/p&gt;&lt;p&gt;The introduction of tokenised shares like OpenAI represents Robinhood’s latest effort to expand its footprint in Europe while broadening its cryptocurrency and blockchain-based offerings. During the same announcement, the company promoted the launch of tokenised US equities in Europe, alongside perpetual trading and staking capabilities for American users.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-implications-for-private-market-investment"&gt;Implications for private market investment&lt;/h3&gt;&lt;p&gt;Robinhood’s initiative, if successful despite the pushback, could democratise access to sought-after private companies whose shares are typically available only to institutional investors, venture capitalists, and accredited individual investors.&lt;/p&gt;&lt;p&gt;However, the controversy highlights the challenges of bringing innovation to regulated financial markets, particularly when dealing with private companies that maintain tight control over their equity.&lt;/p&gt;&lt;p&gt;Financial experts caution that potential investors should thoroughly understand the distinction between these tokenised derivatives and actual equity ownership. The value proposition and risks differ significantly from traditional share ownership, even as they provide exposure to previously inaccessible investment opportunities.&lt;/p&gt;&lt;p&gt;Robinhood’s broader European expansion continues apace, with the company keen to capitalise on growing interest in both American equities and cryptocurrency investments among European traders. Whether the issue of tokenised shares, and the subsequent backlash from companies like OpenAI, will help or hinder those ambitions remains to be seen.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Flood of interest in Europe’s AI Gigafactories plan&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Robinhood has begun offering tokenised shares in private companies, sparking backlash from OpenAI as one of the targeted firms.&lt;/p&gt;&lt;p&gt;During an event in Cannes on Monday, Robinhood co-founder and CEO Vlad Tenev displayed what he described as “stock tokens” for OpenAI and SpaceX. The move forms part of Robinhood’s European expansion, which also includes offering more than 200 tokenised shares of publicly-traded US stocks to EU users.&lt;/p&gt;&lt;p&gt;Tenev told attendees that European users who download the Robinhood app would have the opportunity to own tokenised shares in OpenAI and Elon Musk’s space exploration venture SpaceX, both of which are private companies that haven’t announced plans to go public.&lt;/p&gt;&lt;p&gt;The trading platform explains on its website: “Robinhood Stock Tokens follow the prices of publicly-traded stocks and ETFs — they are derivatives tracked on the blockchain, giving you exposure to the US market. When buying stock tokens, you are not buying the actual stocks — you are buying tokenised contracts that follow their price, recorded on a blockchain.”&lt;/p&gt;&lt;p&gt;This distinction means token holders wouldn’t enjoy traditional shareholder rights, such as voting privileges, despite having financial exposure to the companies.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-openai-rebuffs-robinhood-s-tokenised-shares-offering"&gt;OpenAI rebuffs Robinhood’s tokenised shares offering&lt;/h3&gt;&lt;p&gt;The announcement triggered a sharp rebuke from OpenAI. The high-profile AI firm, led by Sam Altman, categorically denied any involvement with Robinhood’s initiative.&lt;/p&gt;&lt;p&gt;“These ‘OpenAI tokens’ are not OpenAI equity,” the company stated in a post on X. “We did not partner with Robinhood, were not involved in this, and do not endorse it. Any transfer of OpenAI equity requires our approval — we did not approve any transfer. Please be careful.”&lt;/p&gt;&lt;p&gt;Industry observers note that Robinhood’s approach appears designed to provide price exposure to underlying equities rather than actual ownership, likely structured this way to navigate complex regulatory requirements.&lt;/p&gt;&lt;p&gt;This mechanism bears similarities to offerings from other financial technology firms. For instance, cryptocurrency platform Kraken offers products called xStocks that likewise don’t represent direct equity ownership but are instead backed by underlying shares.&lt;/p&gt;&lt;p&gt;The introduction of tokenised shares like OpenAI represents Robinhood’s latest effort to expand its footprint in Europe while broadening its cryptocurrency and blockchain-based offerings. During the same announcement, the company promoted the launch of tokenised US equities in Europe, alongside perpetual trading and staking capabilities for American users.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-implications-for-private-market-investment"&gt;Implications for private market investment&lt;/h3&gt;&lt;p&gt;Robinhood’s initiative, if successful despite the pushback, could democratise access to sought-after private companies whose shares are typically available only to institutional investors, venture capitalists, and accredited individual investors.&lt;/p&gt;&lt;p&gt;However, the controversy highlights the challenges of bringing innovation to regulated financial markets, particularly when dealing with private companies that maintain tight control over their equity.&lt;/p&gt;&lt;p&gt;Financial experts caution that potential investors should thoroughly understand the distinction between these tokenised derivatives and actual equity ownership. The value proposition and risks differ significantly from traditional share ownership, even as they provide exposure to previously inaccessible investment opportunities.&lt;/p&gt;&lt;p&gt;Robinhood’s broader European expansion continues apace, with the company keen to capitalise on growing interest in both American equities and cryptocurrency investments among European traders. Whether the issue of tokenised shares, and the subsequent backlash from companies like OpenAI, will help or hinder those ambitions remains to be seen.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Flood of interest in Europe’s AI Gigafactories plan&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/openai-rejects-robinhood-unauthorised-tokenised-shares/</guid><pubDate>Thu, 03 Jul 2025 15:54:30 +0000</pubDate></item><item><title>[NEW] AI Safety Newsletter #58: Senate Removes State AI Regulation Moratorium (AI Safety Newsletter)</title><link>https://newsletter.safe.ai/p/ai-safety-newsletter-58-senate-removes</link><description>&lt;p&gt;&lt;span&gt;Welcome to the AI Safety Newsletter by the &lt;/span&gt;&lt;a href="https://www.safe.ai/" rel="rel"&gt;Center for AI Safety&lt;/a&gt;&lt;span&gt;. We discuss developments in AI and AI safety. No technical background required.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;In this edition: The Senate removes a provision from Republican's “Big Beautiful Bill” aimed at restricting states from regulating AI; two federal judges split on whether training AI on copyrighted books in fair use.&lt;/p&gt;&lt;p&gt;&lt;span&gt;Listen to the AI Safety Newsletter for free on &lt;/span&gt;&lt;a href="https://spotify.link/E6lHa1ij2Cb" rel="rel"&gt;Spotify&lt;/a&gt;&lt;span&gt; or &lt;/span&gt;&lt;a href="https://podcasts.apple.com/us/podcast/ai-safety-newsletter/id1702875110" rel="rel"&gt;Apple Podcasts&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;The Senate removed a provision from Republican's “Big Beautiful Bill” aimed at restricting states from regulating AI. The moratorium would have prohibited states from receiving federal broadband expansion funds if they regulated AI—however, it faced procedural and political challenges in the Senate, and was ultimately removed in a vote of 99-1. Here’s what happened.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A watered-down moratorium cleared the Byrd Rule. &lt;/strong&gt;&lt;span&gt;In an attempt to bypass the Byrd Rule, which prohibits policy provisions in budget bills, the Senate Commerce Committee &lt;/span&gt;&lt;a href="https://www.politico.com/live-updates/2025/06/05/congress/senate-commerce-megabill-frees-spectrum-ties-bead-to-ai-moratorium-00391136" rel="rel"&gt;revised&lt;/a&gt;&lt;span&gt; the original moratorium to be a prerequisite for states to receive federal broadband expansion funds rather than a blanket restriction. On Wednesday,&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;&lt;span&gt;Senate&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;&lt;span&gt;Parliamentarian Elizabeth MacDonough &lt;/span&gt;&lt;a href="https://thehill.com/policy/technology/5374053-ai-regulation-bill-clears-byrd-rule/" rel="rel"&gt;judged&lt;/a&gt;&lt;span&gt; that the moratorium would only clear the Byrd Rule if it was tied to only the new $500 million in federal broadband expansion funds provided by the reconciliation bill—not all $42.45 billion previously appropriated.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;This significantly weakened the moratorium—even if it had been passed, states might have decided that regulating AI was worth foregoing new broadband expansion funds.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The moratorium moved to a vote in the Senate. &lt;/strong&gt;&lt;span&gt;On Saturday,&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;&lt;span&gt;the senate&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;&lt;span&gt;voted 51-49 to move to general debate on the reconciliation bill, beginning the process of a “vote-a-rama” which saw many amendments debated and voted on in rapid succession. Senators Josh Hawley and Maria Cantwell were &lt;/span&gt;&lt;a href="https://punchbowl.news/article/tech/ted-cruz-parliamentarian-artificial-intelligence/" rel="rel"&gt;expected&lt;/a&gt;&lt;span&gt; to bring an amendment to remove the moratorium from the bill.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Ted Cruz and Sen. Marsha Blackburn—another critic of the original moratorium—&lt;/span&gt;&lt;a href="https://www.politico.com/live-updates/2025/06/29/congress/blackburn-cruz-find-potential-truce-on-state-ai-moratorium-child-safety-00432296" rel="rel"&gt;were set&lt;/a&gt;&lt;span&gt; to pitch a compromise &lt;/span&gt;&lt;a href="https://www.blackburn.senate.gov/services/files/178AE7B5-7583-415E-8CF3-475241C6E5F9" rel="rel"&gt;draft&lt;/a&gt;&lt;span&gt; that shortened the moratorium from ten to five years and exempt state legislation establishing internet protections. However, on Tuesday, Blackburn abandoned that compromise after Steve Bannon and others &lt;/span&gt;&lt;a href="https://www.wsj.com/politics/policy/how-a-bold-plan-to-ban-state-ai-laws-fell-apartand-divided-trumpworld-96bce19d?st=rXP9V8&amp;amp;reflink=desktopwebshare_permalink" rel="rel"&gt;reportedly&lt;/a&gt;&lt;span&gt; reached out to her.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Instead, she brought an amendment with Sen. Cantwell to remove the moratorium entirely. Lacking enough support, even Cruz voted for the amendment, which &lt;/span&gt;&lt;a href="https://apnews.com/article/congress-ai-provision-moratorium-states-20beeeb6967057be5fe64678f72f6ab0" rel="rel"&gt;passed&lt;/a&gt;&lt;span&gt; 99-1.&lt;/span&gt;&lt;/p&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2 is-viewable-img" href="https://substackcdn.com/image/fetch/$s_!3W7Q!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0121db23-e6ab-48b8-9f8e-50a6e3705f24_1600x1067.jpeg" rel="rel" target="_blank"&gt;&lt;div class="image2-inset"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="971" src="https://substackcdn.com/image/fetch/$s_!3W7Q!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0121db23-e6ab-48b8-9f8e-50a6e3705f24_1600x1067.jpeg" width="1456" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;&lt;em&gt;Sen. Blackburn cosponsored the Kids Online Safety Act last year.&lt;/em&gt;&lt;span&gt; &lt;/span&gt;&lt;em&gt;&lt;span&gt;(&lt;/span&gt;&lt;a href="https://ciosenus.app.box.com/s/s913tsl67j6y2owtvzbnrlpu7x6cjmrk/file/1524677161363" rel="rel"&gt;Source&lt;/a&gt;&lt;span&gt;.)&lt;/span&gt;&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;span&gt;Even if the moratorium had survived the Senate, it could have faced an uphill battle in the House—Representatives &lt;/span&gt;&lt;a href="https://x.com/RepMTG/status/1930650431253827806?t=rK_HvP4W2eb3qIB-FikMjw" rel="rel"&gt;Marjorie Taylor Greene&lt;/a&gt;&lt;span&gt; and &lt;/span&gt;&lt;a href="https://x.com/RepThomasMassie/status/1930642561124716866" rel="rel"&gt;Thomas Massie&lt;/a&gt;&lt;span&gt; came out against it, along with other prominent Republicans like Arkansas Governor &lt;/span&gt;&lt;a href="https://www.washingtonpost.com/opinions/2025/06/26/state-ai-regulations-ban-obbb/" rel="rel"&gt;Sarah Huckabee Sanders&lt;/a&gt;&lt;em&gt; &lt;/em&gt;&lt;span&gt;and &lt;/span&gt;&lt;a href="https://www.wsj.com/politics/policy/how-a-bold-plan-to-ban-state-ai-laws-fell-apartand-divided-trumpworld-96bce19d?st=rXP9V8&amp;amp;reflink=desktopwebshare_permalink" rel="rel"&gt;Steve Bannon&lt;/a&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Last&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;&lt;span&gt;week, two U.S. district judges decided cases involving Anthropic and Meta on the question of whether training LLMs on copyrighted works qualifies as fair use. While both judges sided with the AI companies, they sharply disagreed about how the Copyright Act should apply to similar cases—leaving legal precedent on the question ambiguous.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;One judge ruled that training Anthropic’s Claude on copyrighted books is fair use. &lt;/strong&gt;&lt;span&gt;U.S. District Judge William Alsup &lt;/span&gt;&lt;a href="https://www.reuters.com/legal/litigation/anthropic-wins-key-ruling-ai-authors-copyright-lawsuit-2025-06-24/" rel="rel"&gt;granted a summary judgment&lt;/a&gt;&lt;span&gt; that Anthropic using copyrighted books to train LLMs qualifies as fair use. The &lt;/span&gt;&lt;a href="https://storage.courtlistener.com/recap/gov.uscourts.cand.434709/gov.uscourts.cand.434709.231.0_2.pdf" rel="rel"&gt;order&lt;/a&gt;&lt;span&gt; held that three out of four of the factors considered when determining whether a given use of a copyrighted work is a fair use favored Anthropic’s use in training LLMs.&lt;/span&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;The purpose and character of the use. &lt;/strong&gt;&lt;span&gt;The court held that using copyrighted books to train LLMs is highly transformative, favoring fair use.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;The nature of the copyrighted work. &lt;/strong&gt;&lt;span&gt;The books in question were expressive, pointing against fair use.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;The amount and substantiality of the portion used. &lt;/strong&gt;&lt;span&gt;The court held that it was reasonably necessary to use the entirety of books in training LLMs, favoring fair use.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;The effect of the use upon the potential market for or value of the copyrighted work. &lt;/strong&gt;&lt;span&gt;No exact copies or knockoffs resulted from the use of copyrighted books to train Claude, since Anthropic implemented guardrails to prevent Claude from exactly replicating the works on which it was trained. While the use may result in an “explosion” of AI-generated writing that competes with the copyrighted books, the court held that such a market effect doesn’t count under the Copyright Act.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;Digitizing print books Anthropic lawfully bought is also protected—but piracy is not. &lt;/strong&gt;&lt;span&gt;Judge&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;&lt;span&gt;Alsup drew a sharp line between scanning paperbacks Anthropic had purchased and the millions of volumes it admitted downloading from pirate libraries. Turning a lawfully owned print copy into a PDF is fair use, but pirating books is not. That issue will proceed to trial.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;In a case against Meta, another judge reached the opposite conclusion.&lt;/strong&gt;&lt;span&gt; While U.S. District Judge Vince Chhabria &lt;/span&gt;&lt;a href="https://apnews.com/article/meta-ai-copyright-lawsuit-sarah-silverman-e77968015b94fbbf38234e3178ede578" rel="rel"&gt;sided with Meta&lt;/a&gt;&lt;span&gt; in its case, his &lt;/span&gt;&lt;a href="https://storage.courtlistener.com/recap/gov.uscourts.cand.415175/gov.uscourts.cand.415175.598.0_1.pdf" rel="rel"&gt;order&lt;/a&gt;&lt;span&gt; made clear he only did so because he believed the plaintiffs made the wrong arguments and presented the wrong evidence.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;His analysis of whether using copyrighted books to train LLMs is fair use agrees with Judge Alsup’s on the first three factors—but sharply disagrees on the relevance of market effects. The upshot, he writes, is that “in many circumstances it will be illegal to copy copyright-protected works to train generative AI models without permission.” He sided with Mate only because the plaintiffs failed to provide arguments or evidence showing that Meta’s LLMs resulted in market harm to their books.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The judges disagree on whether “indirect displacement” is a relevant market effect under the Copyright Act. &lt;/strong&gt;&lt;span&gt;Both orders assume that LLMs may now or soon be able to generate many competitors to human-written books, which could harm the market for human-written books.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Judge Alsup writes that the authors’ complaint about such an effect is “no different than it would be if they complained that training schoolchildren to write well would result in an explosion of competing works,” which is “not the kind of competitive or creative displacement that concerns the Copyright Act.”&lt;/p&gt;&lt;p&gt;However, Judge Chhabria responds that “using books to teach children to write is not remotely like using books to create a product that a single individual could employ to generate countless competing works with a miniscule fraction of the time and creativity it would otherwise take.” That is, he argues that a similarity in kind does not outweigh a vast difference in magnitude.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Higher courts will likely settle the dispute.&lt;/strong&gt;&lt;span&gt; While Judge Alsup’s order might have provided precedence for similar cases, Chhabria’s disagreement leaves precedent ambiguous. However, both decisions fall under the jurisdiction of the Ninth Circuit, which has yet to rule on AI fair use. The authors in Anthropic’s case, at least, indicated that they will appeal the decision to the Ninth Circuit—and, ultimately, the issue may be up to the Supreme Court to decide.&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Michael C. Horowitz and Lauren A. Kahn &lt;/span&gt;&lt;a href="https://ai-frontiers.org/articles/nuclear-non-proliferation-is-the-wrong-framework-for-ai-governance" rel="rel"&gt;argue&lt;/a&gt;&lt;span&gt; that placing AI in a nuclear framework inflates expectations and distracts from practical, sector-specific governance.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Laura González Salmerón &lt;/span&gt;&lt;a href="https://ai-frontiers.org/articles/can-copyright-survive-ai" rel="rel"&gt;discusses&lt;/a&gt;&lt;span&gt; how copyright law is under pressure from generative AI.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Kristin O’Donoghue &lt;/span&gt;&lt;a href="https://ai-frontiers.org/articles/congress-might-block-states-from-regulating-ai" rel="rel"&gt;argues&lt;/a&gt;&lt;span&gt; that a moratorium on state AI legislation would upend federalism and halt the experiments that drive smarter policy.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Pete Buttigieg &lt;/span&gt;&lt;a href="https://petebuttigieg.substack.com/p/we-are-still-underreacting-on-ai" rel="rel"&gt;wrote&lt;/a&gt;&lt;span&gt; a blog post arguing that AI presents “a fundamental change to our society—and we remain dangerously underprepared.”&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Researchers at UC Berkeley released &lt;/span&gt;&lt;a href="https://www.cybergym.io/" rel="rel"&gt;CyberGym&lt;/a&gt;&lt;span&gt;, a new cybersecurity benchmark. The LLMs they evaluated discovered 15 zero-day vulnerabilities in large software projects.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;A &lt;/span&gt;&lt;a href="https://forecastingresearch.org/ai-enabled-biorisk" rel="rel"&gt;new report&lt;/a&gt;&lt;span&gt; from the Forecasting Research Institute shows that experts and superforecasters predict that existing AI capabilities may substantially increase the risk of human-caused epidemics.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;See also: &lt;/span&gt;&lt;a href="https://x.com/ai_risks?lang=en" rel="rel"&gt;CAIS’ X account&lt;/a&gt;&lt;span&gt;, our paper on &lt;/span&gt;&lt;a href="https://www.nationalsecurity.ai/" rel="rel"&gt;superintelligence strategy&lt;/a&gt;&lt;span&gt;, our &lt;/span&gt;&lt;a href="https://www.aisafetybook.com/" rel="rel"&gt;AI safety course&lt;/a&gt;&lt;span&gt;, and &lt;/span&gt;&lt;a href="http://ai-frontiers.org/" rel="rel"&gt;AI Frontiers&lt;/a&gt;&lt;span&gt;, a new platform for expert commentary and analysis.&lt;/span&gt;&lt;/p&gt;&lt;p class="button-wrapper"&gt;&lt;a class="button primary" href="https://newsletter.safe.ai/p/ai-safety-newsletter-58-senate-removes?utm_source=substack&amp;amp;utm_medium=email&amp;amp;utm_content=share&amp;amp;action=share" rel="rel"&gt;&lt;span&gt;Share&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;</description><content:encoded>&lt;p&gt;&lt;span&gt;Welcome to the AI Safety Newsletter by the &lt;/span&gt;&lt;a href="https://www.safe.ai/" rel="rel"&gt;Center for AI Safety&lt;/a&gt;&lt;span&gt;. We discuss developments in AI and AI safety. No technical background required.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;In this edition: The Senate removes a provision from Republican's “Big Beautiful Bill” aimed at restricting states from regulating AI; two federal judges split on whether training AI on copyrighted books in fair use.&lt;/p&gt;&lt;p&gt;&lt;span&gt;Listen to the AI Safety Newsletter for free on &lt;/span&gt;&lt;a href="https://spotify.link/E6lHa1ij2Cb" rel="rel"&gt;Spotify&lt;/a&gt;&lt;span&gt; or &lt;/span&gt;&lt;a href="https://podcasts.apple.com/us/podcast/ai-safety-newsletter/id1702875110" rel="rel"&gt;Apple Podcasts&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;The Senate removed a provision from Republican's “Big Beautiful Bill” aimed at restricting states from regulating AI. The moratorium would have prohibited states from receiving federal broadband expansion funds if they regulated AI—however, it faced procedural and political challenges in the Senate, and was ultimately removed in a vote of 99-1. Here’s what happened.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A watered-down moratorium cleared the Byrd Rule. &lt;/strong&gt;&lt;span&gt;In an attempt to bypass the Byrd Rule, which prohibits policy provisions in budget bills, the Senate Commerce Committee &lt;/span&gt;&lt;a href="https://www.politico.com/live-updates/2025/06/05/congress/senate-commerce-megabill-frees-spectrum-ties-bead-to-ai-moratorium-00391136" rel="rel"&gt;revised&lt;/a&gt;&lt;span&gt; the original moratorium to be a prerequisite for states to receive federal broadband expansion funds rather than a blanket restriction. On Wednesday,&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;&lt;span&gt;Senate&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;&lt;span&gt;Parliamentarian Elizabeth MacDonough &lt;/span&gt;&lt;a href="https://thehill.com/policy/technology/5374053-ai-regulation-bill-clears-byrd-rule/" rel="rel"&gt;judged&lt;/a&gt;&lt;span&gt; that the moratorium would only clear the Byrd Rule if it was tied to only the new $500 million in federal broadband expansion funds provided by the reconciliation bill—not all $42.45 billion previously appropriated.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;This significantly weakened the moratorium—even if it had been passed, states might have decided that regulating AI was worth foregoing new broadband expansion funds.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The moratorium moved to a vote in the Senate. &lt;/strong&gt;&lt;span&gt;On Saturday,&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;&lt;span&gt;the senate&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;&lt;span&gt;voted 51-49 to move to general debate on the reconciliation bill, beginning the process of a “vote-a-rama” which saw many amendments debated and voted on in rapid succession. Senators Josh Hawley and Maria Cantwell were &lt;/span&gt;&lt;a href="https://punchbowl.news/article/tech/ted-cruz-parliamentarian-artificial-intelligence/" rel="rel"&gt;expected&lt;/a&gt;&lt;span&gt; to bring an amendment to remove the moratorium from the bill.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Ted Cruz and Sen. Marsha Blackburn—another critic of the original moratorium—&lt;/span&gt;&lt;a href="https://www.politico.com/live-updates/2025/06/29/congress/blackburn-cruz-find-potential-truce-on-state-ai-moratorium-child-safety-00432296" rel="rel"&gt;were set&lt;/a&gt;&lt;span&gt; to pitch a compromise &lt;/span&gt;&lt;a href="https://www.blackburn.senate.gov/services/files/178AE7B5-7583-415E-8CF3-475241C6E5F9" rel="rel"&gt;draft&lt;/a&gt;&lt;span&gt; that shortened the moratorium from ten to five years and exempt state legislation establishing internet protections. However, on Tuesday, Blackburn abandoned that compromise after Steve Bannon and others &lt;/span&gt;&lt;a href="https://www.wsj.com/politics/policy/how-a-bold-plan-to-ban-state-ai-laws-fell-apartand-divided-trumpworld-96bce19d?st=rXP9V8&amp;amp;reflink=desktopwebshare_permalink" rel="rel"&gt;reportedly&lt;/a&gt;&lt;span&gt; reached out to her.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Instead, she brought an amendment with Sen. Cantwell to remove the moratorium entirely. Lacking enough support, even Cruz voted for the amendment, which &lt;/span&gt;&lt;a href="https://apnews.com/article/congress-ai-provision-moratorium-states-20beeeb6967057be5fe64678f72f6ab0" rel="rel"&gt;passed&lt;/a&gt;&lt;span&gt; 99-1.&lt;/span&gt;&lt;/p&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2 is-viewable-img" href="https://substackcdn.com/image/fetch/$s_!3W7Q!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0121db23-e6ab-48b8-9f8e-50a6e3705f24_1600x1067.jpeg" rel="rel" target="_blank"&gt;&lt;div class="image2-inset"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="971" src="https://substackcdn.com/image/fetch/$s_!3W7Q!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0121db23-e6ab-48b8-9f8e-50a6e3705f24_1600x1067.jpeg" width="1456" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;&lt;em&gt;Sen. Blackburn cosponsored the Kids Online Safety Act last year.&lt;/em&gt;&lt;span&gt; &lt;/span&gt;&lt;em&gt;&lt;span&gt;(&lt;/span&gt;&lt;a href="https://ciosenus.app.box.com/s/s913tsl67j6y2owtvzbnrlpu7x6cjmrk/file/1524677161363" rel="rel"&gt;Source&lt;/a&gt;&lt;span&gt;.)&lt;/span&gt;&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;span&gt;Even if the moratorium had survived the Senate, it could have faced an uphill battle in the House—Representatives &lt;/span&gt;&lt;a href="https://x.com/RepMTG/status/1930650431253827806?t=rK_HvP4W2eb3qIB-FikMjw" rel="rel"&gt;Marjorie Taylor Greene&lt;/a&gt;&lt;span&gt; and &lt;/span&gt;&lt;a href="https://x.com/RepThomasMassie/status/1930642561124716866" rel="rel"&gt;Thomas Massie&lt;/a&gt;&lt;span&gt; came out against it, along with other prominent Republicans like Arkansas Governor &lt;/span&gt;&lt;a href="https://www.washingtonpost.com/opinions/2025/06/26/state-ai-regulations-ban-obbb/" rel="rel"&gt;Sarah Huckabee Sanders&lt;/a&gt;&lt;em&gt; &lt;/em&gt;&lt;span&gt;and &lt;/span&gt;&lt;a href="https://www.wsj.com/politics/policy/how-a-bold-plan-to-ban-state-ai-laws-fell-apartand-divided-trumpworld-96bce19d?st=rXP9V8&amp;amp;reflink=desktopwebshare_permalink" rel="rel"&gt;Steve Bannon&lt;/a&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Last&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;&lt;span&gt;week, two U.S. district judges decided cases involving Anthropic and Meta on the question of whether training LLMs on copyrighted works qualifies as fair use. While both judges sided with the AI companies, they sharply disagreed about how the Copyright Act should apply to similar cases—leaving legal precedent on the question ambiguous.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;One judge ruled that training Anthropic’s Claude on copyrighted books is fair use. &lt;/strong&gt;&lt;span&gt;U.S. District Judge William Alsup &lt;/span&gt;&lt;a href="https://www.reuters.com/legal/litigation/anthropic-wins-key-ruling-ai-authors-copyright-lawsuit-2025-06-24/" rel="rel"&gt;granted a summary judgment&lt;/a&gt;&lt;span&gt; that Anthropic using copyrighted books to train LLMs qualifies as fair use. The &lt;/span&gt;&lt;a href="https://storage.courtlistener.com/recap/gov.uscourts.cand.434709/gov.uscourts.cand.434709.231.0_2.pdf" rel="rel"&gt;order&lt;/a&gt;&lt;span&gt; held that three out of four of the factors considered when determining whether a given use of a copyrighted work is a fair use favored Anthropic’s use in training LLMs.&lt;/span&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;The purpose and character of the use. &lt;/strong&gt;&lt;span&gt;The court held that using copyrighted books to train LLMs is highly transformative, favoring fair use.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;The nature of the copyrighted work. &lt;/strong&gt;&lt;span&gt;The books in question were expressive, pointing against fair use.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;The amount and substantiality of the portion used. &lt;/strong&gt;&lt;span&gt;The court held that it was reasonably necessary to use the entirety of books in training LLMs, favoring fair use.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;The effect of the use upon the potential market for or value of the copyrighted work. &lt;/strong&gt;&lt;span&gt;No exact copies or knockoffs resulted from the use of copyrighted books to train Claude, since Anthropic implemented guardrails to prevent Claude from exactly replicating the works on which it was trained. While the use may result in an “explosion” of AI-generated writing that competes with the copyrighted books, the court held that such a market effect doesn’t count under the Copyright Act.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;Digitizing print books Anthropic lawfully bought is also protected—but piracy is not. &lt;/strong&gt;&lt;span&gt;Judge&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;&lt;span&gt;Alsup drew a sharp line between scanning paperbacks Anthropic had purchased and the millions of volumes it admitted downloading from pirate libraries. Turning a lawfully owned print copy into a PDF is fair use, but pirating books is not. That issue will proceed to trial.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;In a case against Meta, another judge reached the opposite conclusion.&lt;/strong&gt;&lt;span&gt; While U.S. District Judge Vince Chhabria &lt;/span&gt;&lt;a href="https://apnews.com/article/meta-ai-copyright-lawsuit-sarah-silverman-e77968015b94fbbf38234e3178ede578" rel="rel"&gt;sided with Meta&lt;/a&gt;&lt;span&gt; in its case, his &lt;/span&gt;&lt;a href="https://storage.courtlistener.com/recap/gov.uscourts.cand.415175/gov.uscourts.cand.415175.598.0_1.pdf" rel="rel"&gt;order&lt;/a&gt;&lt;span&gt; made clear he only did so because he believed the plaintiffs made the wrong arguments and presented the wrong evidence.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;His analysis of whether using copyrighted books to train LLMs is fair use agrees with Judge Alsup’s on the first three factors—but sharply disagrees on the relevance of market effects. The upshot, he writes, is that “in many circumstances it will be illegal to copy copyright-protected works to train generative AI models without permission.” He sided with Mate only because the plaintiffs failed to provide arguments or evidence showing that Meta’s LLMs resulted in market harm to their books.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The judges disagree on whether “indirect displacement” is a relevant market effect under the Copyright Act. &lt;/strong&gt;&lt;span&gt;Both orders assume that LLMs may now or soon be able to generate many competitors to human-written books, which could harm the market for human-written books.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Judge Alsup writes that the authors’ complaint about such an effect is “no different than it would be if they complained that training schoolchildren to write well would result in an explosion of competing works,” which is “not the kind of competitive or creative displacement that concerns the Copyright Act.”&lt;/p&gt;&lt;p&gt;However, Judge Chhabria responds that “using books to teach children to write is not remotely like using books to create a product that a single individual could employ to generate countless competing works with a miniscule fraction of the time and creativity it would otherwise take.” That is, he argues that a similarity in kind does not outweigh a vast difference in magnitude.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Higher courts will likely settle the dispute.&lt;/strong&gt;&lt;span&gt; While Judge Alsup’s order might have provided precedence for similar cases, Chhabria’s disagreement leaves precedent ambiguous. However, both decisions fall under the jurisdiction of the Ninth Circuit, which has yet to rule on AI fair use. The authors in Anthropic’s case, at least, indicated that they will appeal the decision to the Ninth Circuit—and, ultimately, the issue may be up to the Supreme Court to decide.&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Michael C. Horowitz and Lauren A. Kahn &lt;/span&gt;&lt;a href="https://ai-frontiers.org/articles/nuclear-non-proliferation-is-the-wrong-framework-for-ai-governance" rel="rel"&gt;argue&lt;/a&gt;&lt;span&gt; that placing AI in a nuclear framework inflates expectations and distracts from practical, sector-specific governance.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Laura González Salmerón &lt;/span&gt;&lt;a href="https://ai-frontiers.org/articles/can-copyright-survive-ai" rel="rel"&gt;discusses&lt;/a&gt;&lt;span&gt; how copyright law is under pressure from generative AI.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Kristin O’Donoghue &lt;/span&gt;&lt;a href="https://ai-frontiers.org/articles/congress-might-block-states-from-regulating-ai" rel="rel"&gt;argues&lt;/a&gt;&lt;span&gt; that a moratorium on state AI legislation would upend federalism and halt the experiments that drive smarter policy.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Pete Buttigieg &lt;/span&gt;&lt;a href="https://petebuttigieg.substack.com/p/we-are-still-underreacting-on-ai" rel="rel"&gt;wrote&lt;/a&gt;&lt;span&gt; a blog post arguing that AI presents “a fundamental change to our society—and we remain dangerously underprepared.”&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Researchers at UC Berkeley released &lt;/span&gt;&lt;a href="https://www.cybergym.io/" rel="rel"&gt;CyberGym&lt;/a&gt;&lt;span&gt;, a new cybersecurity benchmark. The LLMs they evaluated discovered 15 zero-day vulnerabilities in large software projects.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;A &lt;/span&gt;&lt;a href="https://forecastingresearch.org/ai-enabled-biorisk" rel="rel"&gt;new report&lt;/a&gt;&lt;span&gt; from the Forecasting Research Institute shows that experts and superforecasters predict that existing AI capabilities may substantially increase the risk of human-caused epidemics.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;See also: &lt;/span&gt;&lt;a href="https://x.com/ai_risks?lang=en" rel="rel"&gt;CAIS’ X account&lt;/a&gt;&lt;span&gt;, our paper on &lt;/span&gt;&lt;a href="https://www.nationalsecurity.ai/" rel="rel"&gt;superintelligence strategy&lt;/a&gt;&lt;span&gt;, our &lt;/span&gt;&lt;a href="https://www.aisafetybook.com/" rel="rel"&gt;AI safety course&lt;/a&gt;&lt;span&gt;, and &lt;/span&gt;&lt;a href="http://ai-frontiers.org/" rel="rel"&gt;AI Frontiers&lt;/a&gt;&lt;span&gt;, a new platform for expert commentary and analysis.&lt;/span&gt;&lt;/p&gt;&lt;p class="button-wrapper"&gt;&lt;a class="button primary" href="https://newsletter.safe.ai/p/ai-safety-newsletter-58-senate-removes?utm_source=substack&amp;amp;utm_medium=email&amp;amp;utm_content=share&amp;amp;action=share" rel="rel"&gt;&lt;span&gt;Share&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://newsletter.safe.ai/p/ai-safety-newsletter-58-senate-removes</guid><pubDate>Thu, 03 Jul 2025 16:23:06 +0000</pubDate></item><item><title>[NEW] Meta has found another way to keep you engaged: Chatbots that message you first (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/03/meta-has-found-another-way-to-keep-you-engaged-chatbots-that-message-you-first/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/Meta-AI-chatbots.png?resize=1200,673" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Imagine you’re messaging some friends on the Facebook Messenger app or WhatsApp, and you get an unsolicited message from an AI chatbot that’s obsessed with films.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I hope you’re having a harmonious day!” it writes. “I wanted to check in and see if you’ve discovered any new favorite soundtracks or composers recently. Or perhaps you’d like some recommendations for your next movie night? Let me know, and I’ll be happy to help!”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That’s a real example of what a sample AI persona named “The Maestro of Movie Magic” might send as a proactive message on Messenger, WhatsApp, or Instagram, per guidelines from data labeling firm Alignerr that Business Insider viewed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The outlet learned through leaked documents that Meta is working with Alignerr to train customizable chatbots to reach out to users unprompted and follow up on any past conversations. That means the bots, which users can create in Meta’s AI Studio platform, also remember information about users.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta confirmed that it was testing follow-up messaging with AIs to TechCrunch. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI chatbots will only send follow-ups within 14 days after a user initiates a conversation and if the user has sent at least five messages to the bot within that time frame. Meta says the chatbots won’t keep messaging if there’s no response to the first follow-up. Users can keep their bots private or share them through stories, direct links, and even display them on a Facebook or Instagram profile.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This allows you to continue exploring topics of interest and engage in more meaningful conversations with the AIs across our apps,” a Meta spokesperson said.&amp;nbsp;&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;The technology is similar to that offered by AI startups like Character.AI and Replika. Both companies allow their chatbots to initiate conversations and ask questions in order to function as AI companions. Character.AI’s new CEO, Karandeep Anand, joined the team last month after serving as Meta’s VP of business products.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But with engagement comes risk. Character.AI is undergoing an active lawsuit after allegations that one of the company’s bots played a role in the death of a 14-year-old boy.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When asked how Meta plans to address safety to avoid situations like Character.AI’s, a spokesperson directed TechCrunch to a series of disclaimers. One of them warns that an AI’s response “may be inaccurate or inappropriate and should not be used to make important decisions.” Another says that the AIs aren’t licensed professionals or experts trained to help people.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Chats with custom AIs can’t replace professional advice. You shouldn’t rely on AI chats for medical, psychological, financial, legal, or any other type of professional advice.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has also asked Meta if it imposes an age limit for engagement with its chatbots. A brief internet dive comes up with no company-imposed age limitations for using Meta AI, though laws in Tennessee and Puerto Rico limit teens from some engagement.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the surface, the mission is aligned with Mark Zuckerberg’s quest to combat the “loneliness epidemic.” However, most of Meta’s business is built on advertising revenue, and the company has garnered a reputation for using algorithms to keep people scrolling, commenting, and liking, which correlates to more eyes on ads. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In court documents that were unsealed in April, Meta predicted that its generative AI products would secure it $2 billion to $3 billion in revenue in 2025, and up to $1.4 trillion by 2035. Much, if not most, of that would come from Meta’s revenue-sharing agreements with companies that host its open Llama collection of models. The company said its AI assistant may eventually show ads and offer a subscription option.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta declined to comment on TechCrunch’s questions on how it plans to commercialize its AI chatbots, whether it plans to include ads or sponsored replies, and whether the company’s long-term strategy with AI companions involves integration with Horizon, Meta’s social virtual reality game.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Got a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at rebecca.bellan@techcrunch.com and Maxwell Zeff at maxwell.zeff@techcrunch.com. For secure communication, you can contact us via Signal at @rebeccabellan.491 and @mzeff.88.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/Meta-AI-chatbots.png?resize=1200,673" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Imagine you’re messaging some friends on the Facebook Messenger app or WhatsApp, and you get an unsolicited message from an AI chatbot that’s obsessed with films.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I hope you’re having a harmonious day!” it writes. “I wanted to check in and see if you’ve discovered any new favorite soundtracks or composers recently. Or perhaps you’d like some recommendations for your next movie night? Let me know, and I’ll be happy to help!”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That’s a real example of what a sample AI persona named “The Maestro of Movie Magic” might send as a proactive message on Messenger, WhatsApp, or Instagram, per guidelines from data labeling firm Alignerr that Business Insider viewed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The outlet learned through leaked documents that Meta is working with Alignerr to train customizable chatbots to reach out to users unprompted and follow up on any past conversations. That means the bots, which users can create in Meta’s AI Studio platform, also remember information about users.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta confirmed that it was testing follow-up messaging with AIs to TechCrunch. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI chatbots will only send follow-ups within 14 days after a user initiates a conversation and if the user has sent at least five messages to the bot within that time frame. Meta says the chatbots won’t keep messaging if there’s no response to the first follow-up. Users can keep their bots private or share them through stories, direct links, and even display them on a Facebook or Instagram profile.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This allows you to continue exploring topics of interest and engage in more meaningful conversations with the AIs across our apps,” a Meta spokesperson said.&amp;nbsp;&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;The technology is similar to that offered by AI startups like Character.AI and Replika. Both companies allow their chatbots to initiate conversations and ask questions in order to function as AI companions. Character.AI’s new CEO, Karandeep Anand, joined the team last month after serving as Meta’s VP of business products.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But with engagement comes risk. Character.AI is undergoing an active lawsuit after allegations that one of the company’s bots played a role in the death of a 14-year-old boy.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When asked how Meta plans to address safety to avoid situations like Character.AI’s, a spokesperson directed TechCrunch to a series of disclaimers. One of them warns that an AI’s response “may be inaccurate or inappropriate and should not be used to make important decisions.” Another says that the AIs aren’t licensed professionals or experts trained to help people.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Chats with custom AIs can’t replace professional advice. You shouldn’t rely on AI chats for medical, psychological, financial, legal, or any other type of professional advice.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has also asked Meta if it imposes an age limit for engagement with its chatbots. A brief internet dive comes up with no company-imposed age limitations for using Meta AI, though laws in Tennessee and Puerto Rico limit teens from some engagement.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the surface, the mission is aligned with Mark Zuckerberg’s quest to combat the “loneliness epidemic.” However, most of Meta’s business is built on advertising revenue, and the company has garnered a reputation for using algorithms to keep people scrolling, commenting, and liking, which correlates to more eyes on ads. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In court documents that were unsealed in April, Meta predicted that its generative AI products would secure it $2 billion to $3 billion in revenue in 2025, and up to $1.4 trillion by 2035. Much, if not most, of that would come from Meta’s revenue-sharing agreements with companies that host its open Llama collection of models. The company said its AI assistant may eventually show ads and offer a subscription option.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta declined to comment on TechCrunch’s questions on how it plans to commercialize its AI chatbots, whether it plans to include ads or sponsored replies, and whether the company’s long-term strategy with AI companions involves integration with Horizon, Meta’s social virtual reality game.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Got a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at rebecca.bellan@techcrunch.com and Maxwell Zeff at maxwell.zeff@techcrunch.com. For secure communication, you can contact us via Signal at @rebeccabellan.491 and @mzeff.88.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/03/meta-has-found-another-way-to-keep-you-engaged-chatbots-that-message-you-first/</guid><pubDate>Thu, 03 Jul 2025 16:34:22 +0000</pubDate></item><item><title>[NEW] Dust hits $6M ARR helping enterprises build AI agents that actually do stuff instead of just talking (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/dust-hits-6m-arr-helping-enterprises-build-ai-agents-that-actually-do-stuff-instead-of-just-talking/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Dust, a two-year-old artificial intelligence platform that helps enterprises build AI agents capable of completing entire business workflows, has reached $6 million in annual revenue — a six-fold increase from $1 million just one year ago. The company’s rapid growth signals a shift in enterprise AI adoption from simple chatbots toward sophisticated systems that can take concrete actions across business applications.&lt;/p&gt;



&lt;p&gt;The San Francisco-based startup announced Thursday that it has been selected as part of Anthropic’s “Powered by Claude” ecosystem, highlighting a new category of AI companies building specialized enterprise tools on top of frontier language models rather than developing their own AI systems from scratch.&lt;/p&gt;



&lt;p&gt;“Users want more than just conversational interfaces,” said Gabriel Hubert, CEO and co-founder of Dust, in an interview with VentureBeat. “Instead of generating a draft, they want to create the actual document automatically. Rather than getting meeting summaries, they need CRM records updated without manual intervention.”&lt;/p&gt;



&lt;p&gt;Dust’s platform goes far beyond the chatbot-style AI tools that dominated early enterprise adoption. Instead of simply answering questions, Dust’s AI agents can automatically create GitHub issues, schedule calendar meetings, update customer records, and even push code reviews based on internal coding standards–all while maintaining enterprise-grade security protocols.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-ai-agents-turn-sales-calls-into-automated-github-tickets-and-crm-updates"&gt;How AI agents turn sales calls into automated GitHub tickets and CRM updates&lt;/h2&gt;



&lt;p&gt;The company’s approach becomes clear through a concrete example Hubert described: a business-to-business sales company using multiple Dust agents to process sales call transcripts. One agent analyzes which sales arguments resonated with prospects and automatically updates battle cards in Salesforce. Simultaneously, another agent identifies customer feature requests, maps them to the product roadmap, and in some cases, automatically generates GitHub tickets for small features deemed ready for development.&lt;/p&gt;



&lt;p&gt;“Each call transcript is going to be analyzed by multiple agents,” Hubert explained. “You’ll have a sales battle card optimizer agent that’s going to look at the arguments the salesperson made, which ones were powerful and seem to resonate with the prospect, and that’s going to go and feed into a process on the Salesforce side.”&lt;/p&gt;



&lt;p&gt;This level of automation is enabled by the Model Context Protocol (MCP), a new standard developed by Anthropic that allows AI systems to securely connect with external data sources and applications. Guillaume Princen, Head of EMEA at Anthropic, described MCP as “like a USB-C connector between AI models and apps,” enabling agents to access company data while maintaining security boundaries.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-claude-and-mcp-are-powering-the-next-wave-of-enterprise-ai-automation"&gt;Why Claude and MCP are powering the next wave of enterprise AI automation&lt;/h2&gt;



&lt;p&gt;Dust’s success reflects broader changes in how enterprises are approaching AI implementation. Rather than building custom models, companies like Dust are leveraging increasingly capable foundation models — particularly Anthropic’s Claude 4 suite — and combining them with specialized orchestration software.&lt;/p&gt;



&lt;p&gt;“We just want to give our customers access to the best models,” Hubert said. “And I think right now, Anthropic is early in the lead, especially on coding related models.” The company charges customers $40-50 per user per month and serves thousands of workspaces ranging from small startups to large enterprises with thousands of employees.&lt;/p&gt;



&lt;p&gt;Anthropic’s Claude models have seen particularly strong adoption for coding tasks, with the company reporting 300% growth in Claude Code usage over the past four weeks following the release of its latest Claude 4 models. “Opus 4 is the most powerful model for coding in the world,” Princen noted. “We were already leading the coding race. We’re reinforcing that.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-enterprise-security-gets-complex-when-ai-agents-can-actually-take-action"&gt;Enterprise security gets complex when AI agents can actually take action&lt;/h2&gt;



&lt;p&gt;The shift toward AI agents that can take real actions across business systems introduces new security complexities that didn’t exist with simple chatbot implementations. Dust addresses this through what Hubert calls a “native permissioning layer” that separates data access rights from agent usage rights.&lt;/p&gt;



&lt;p&gt;“Permission creation, as well as data &amp;amp; tool management is part of the onboarding experience to mitigate sensitive data exposure when AI agents operate across multiple business systems,” the company explains in technical documentation. This becomes critical when agents have the ability to create GitHub issues, update CRM records, or modify documents across an organization’s technology stack.&lt;/p&gt;



&lt;p&gt;The company implements enterprise-grade infrastructure with Anthropic’s Zero Data Retention policies, ensuring that sensitive business information processed by AI agents isn’t stored by the model provider. This addresses a key concern for enterprises considering AI adoption at scale.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-rise-of-ai-native-startups-building-on-foundation-models-instead-of-creating-their-own"&gt;The rise of AI-native startups building on foundation models instead of creating their own&lt;/h2&gt;



&lt;p&gt;Dust’s growth is part of what Anthropic calls an emerging ecosystem of “AI native startups”—companies that fundamentally couldn’t exist without advanced AI capabilities. These firms are building businesses not by developing their own AI models, but by creating sophisticated applications on top of existing foundation models.&lt;/p&gt;



&lt;p&gt;“These companies have a very, very strong sense of what their end customers need and want for that specific use case,” Princen explained. “We’re providing the tools for them to kind of build and adapt their product to those specific customers and use cases they’re looking for.”&lt;/p&gt;



&lt;p&gt;This approach represents a significant shift in the AI industry’s structure. Instead of every company needing to develop its own AI capabilities, specialized platforms like Dust can provide the orchestration layer that makes powerful AI models useful for specific business applications.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-dust-s-6m-revenue-growth-signals-about-the-future-of-enterprise-software"&gt;What Dust’s $6M revenue growth signals about the future of enterprise software&lt;/h2&gt;



&lt;p&gt;The success of companies like Dust suggests that the enterprise AI market is moving beyond the experimental phase toward practical implementation. Rather than replacing human workers wholesale, these systems are designed to eliminate routine tasks and context-switching between applications, allowing employees to focus on higher-value activities.&lt;/p&gt;



&lt;p&gt;“By providing universal AI primitives that make all company workflows more intelligent as well as a proper permissioning system, we are setting the foundations for an agent operating system that is future-proof,” Hubert said.&lt;/p&gt;



&lt;p&gt;The company’s customer base includes organizations convinced that AI will fundamentally change business operations. “The common thread between all customers is that they’re pretty stemmed towards the future and convinced that this technology is going to change a lot of things,” Hubert noted.&lt;/p&gt;



&lt;p&gt;As AI models become more capable and protocols like MCP mature, the distinction between AI tools that simply provide information and those that take action is likely to become a key differentiator in the enterprise market. Dust’s rapid revenue growth suggests that businesses are willing to pay premium prices for AI systems that can complete real work rather than just assist with it.&lt;/p&gt;



&lt;p&gt;The implications extend beyond individual companies to the broader structure of enterprise software. If AI agents can seamlessly integrate and automate workflows across disconnected business applications, it could reshape how organizations think about software procurement and workflow design—potentially reducing the complexity that has long plagued enterprise technology stacks.&lt;/p&gt;



&lt;p&gt;Perhaps the most telling sign of this transformation is how naturally Hubert describes AI agents not as tools, but as digital employees that show up to work every day. In a business world that has spent decades connecting systems with APIs and integration platforms, companies like Dust are proving that the future might not require connecting everything—just teaching AI to navigate the chaos we’ve already built.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Dust, a two-year-old artificial intelligence platform that helps enterprises build AI agents capable of completing entire business workflows, has reached $6 million in annual revenue — a six-fold increase from $1 million just one year ago. The company’s rapid growth signals a shift in enterprise AI adoption from simple chatbots toward sophisticated systems that can take concrete actions across business applications.&lt;/p&gt;



&lt;p&gt;The San Francisco-based startup announced Thursday that it has been selected as part of Anthropic’s “Powered by Claude” ecosystem, highlighting a new category of AI companies building specialized enterprise tools on top of frontier language models rather than developing their own AI systems from scratch.&lt;/p&gt;



&lt;p&gt;“Users want more than just conversational interfaces,” said Gabriel Hubert, CEO and co-founder of Dust, in an interview with VentureBeat. “Instead of generating a draft, they want to create the actual document automatically. Rather than getting meeting summaries, they need CRM records updated without manual intervention.”&lt;/p&gt;



&lt;p&gt;Dust’s platform goes far beyond the chatbot-style AI tools that dominated early enterprise adoption. Instead of simply answering questions, Dust’s AI agents can automatically create GitHub issues, schedule calendar meetings, update customer records, and even push code reviews based on internal coding standards–all while maintaining enterprise-grade security protocols.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-ai-agents-turn-sales-calls-into-automated-github-tickets-and-crm-updates"&gt;How AI agents turn sales calls into automated GitHub tickets and CRM updates&lt;/h2&gt;



&lt;p&gt;The company’s approach becomes clear through a concrete example Hubert described: a business-to-business sales company using multiple Dust agents to process sales call transcripts. One agent analyzes which sales arguments resonated with prospects and automatically updates battle cards in Salesforce. Simultaneously, another agent identifies customer feature requests, maps them to the product roadmap, and in some cases, automatically generates GitHub tickets for small features deemed ready for development.&lt;/p&gt;



&lt;p&gt;“Each call transcript is going to be analyzed by multiple agents,” Hubert explained. “You’ll have a sales battle card optimizer agent that’s going to look at the arguments the salesperson made, which ones were powerful and seem to resonate with the prospect, and that’s going to go and feed into a process on the Salesforce side.”&lt;/p&gt;



&lt;p&gt;This level of automation is enabled by the Model Context Protocol (MCP), a new standard developed by Anthropic that allows AI systems to securely connect with external data sources and applications. Guillaume Princen, Head of EMEA at Anthropic, described MCP as “like a USB-C connector between AI models and apps,” enabling agents to access company data while maintaining security boundaries.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-claude-and-mcp-are-powering-the-next-wave-of-enterprise-ai-automation"&gt;Why Claude and MCP are powering the next wave of enterprise AI automation&lt;/h2&gt;



&lt;p&gt;Dust’s success reflects broader changes in how enterprises are approaching AI implementation. Rather than building custom models, companies like Dust are leveraging increasingly capable foundation models — particularly Anthropic’s Claude 4 suite — and combining them with specialized orchestration software.&lt;/p&gt;



&lt;p&gt;“We just want to give our customers access to the best models,” Hubert said. “And I think right now, Anthropic is early in the lead, especially on coding related models.” The company charges customers $40-50 per user per month and serves thousands of workspaces ranging from small startups to large enterprises with thousands of employees.&lt;/p&gt;



&lt;p&gt;Anthropic’s Claude models have seen particularly strong adoption for coding tasks, with the company reporting 300% growth in Claude Code usage over the past four weeks following the release of its latest Claude 4 models. “Opus 4 is the most powerful model for coding in the world,” Princen noted. “We were already leading the coding race. We’re reinforcing that.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-enterprise-security-gets-complex-when-ai-agents-can-actually-take-action"&gt;Enterprise security gets complex when AI agents can actually take action&lt;/h2&gt;



&lt;p&gt;The shift toward AI agents that can take real actions across business systems introduces new security complexities that didn’t exist with simple chatbot implementations. Dust addresses this through what Hubert calls a “native permissioning layer” that separates data access rights from agent usage rights.&lt;/p&gt;



&lt;p&gt;“Permission creation, as well as data &amp;amp; tool management is part of the onboarding experience to mitigate sensitive data exposure when AI agents operate across multiple business systems,” the company explains in technical documentation. This becomes critical when agents have the ability to create GitHub issues, update CRM records, or modify documents across an organization’s technology stack.&lt;/p&gt;



&lt;p&gt;The company implements enterprise-grade infrastructure with Anthropic’s Zero Data Retention policies, ensuring that sensitive business information processed by AI agents isn’t stored by the model provider. This addresses a key concern for enterprises considering AI adoption at scale.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-rise-of-ai-native-startups-building-on-foundation-models-instead-of-creating-their-own"&gt;The rise of AI-native startups building on foundation models instead of creating their own&lt;/h2&gt;



&lt;p&gt;Dust’s growth is part of what Anthropic calls an emerging ecosystem of “AI native startups”—companies that fundamentally couldn’t exist without advanced AI capabilities. These firms are building businesses not by developing their own AI models, but by creating sophisticated applications on top of existing foundation models.&lt;/p&gt;



&lt;p&gt;“These companies have a very, very strong sense of what their end customers need and want for that specific use case,” Princen explained. “We’re providing the tools for them to kind of build and adapt their product to those specific customers and use cases they’re looking for.”&lt;/p&gt;



&lt;p&gt;This approach represents a significant shift in the AI industry’s structure. Instead of every company needing to develop its own AI capabilities, specialized platforms like Dust can provide the orchestration layer that makes powerful AI models useful for specific business applications.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-dust-s-6m-revenue-growth-signals-about-the-future-of-enterprise-software"&gt;What Dust’s $6M revenue growth signals about the future of enterprise software&lt;/h2&gt;



&lt;p&gt;The success of companies like Dust suggests that the enterprise AI market is moving beyond the experimental phase toward practical implementation. Rather than replacing human workers wholesale, these systems are designed to eliminate routine tasks and context-switching between applications, allowing employees to focus on higher-value activities.&lt;/p&gt;



&lt;p&gt;“By providing universal AI primitives that make all company workflows more intelligent as well as a proper permissioning system, we are setting the foundations for an agent operating system that is future-proof,” Hubert said.&lt;/p&gt;



&lt;p&gt;The company’s customer base includes organizations convinced that AI will fundamentally change business operations. “The common thread between all customers is that they’re pretty stemmed towards the future and convinced that this technology is going to change a lot of things,” Hubert noted.&lt;/p&gt;



&lt;p&gt;As AI models become more capable and protocols like MCP mature, the distinction between AI tools that simply provide information and those that take action is likely to become a key differentiator in the enterprise market. Dust’s rapid revenue growth suggests that businesses are willing to pay premium prices for AI systems that can complete real work rather than just assist with it.&lt;/p&gt;



&lt;p&gt;The implications extend beyond individual companies to the broader structure of enterprise software. If AI agents can seamlessly integrate and automate workflows across disconnected business applications, it could reshape how organizations think about software procurement and workflow design—potentially reducing the complexity that has long plagued enterprise technology stacks.&lt;/p&gt;



&lt;p&gt;Perhaps the most telling sign of this transformation is how naturally Hubert describes AI agents not as tools, but as digital employees that show up to work every day. In a business world that has spent decades connecting systems with APIs and integration platforms, companies like Dust are proving that the future might not require connecting everything—just teaching AI to navigate the chaos we’ve already built.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/dust-hits-6m-arr-helping-enterprises-build-ai-agents-that-actually-do-stuff-instead-of-just-talking/</guid><pubDate>Thu, 03 Jul 2025 17:00:00 +0000</pubDate></item><item><title>[NEW] Y Combinator alum launched a new $34M fund dedicated to YC startups, backed by Garry Tan (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/03/y-combinator-alum-launched-a-new-34m-fund-dedicated-to-yc-startups-backed-by-garry-tan/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/CowanKulveer-0035.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Investing in Y Combinator startups can lead to significant returns to investors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If you look at the data: 6% of YC companies become unicorns, and of that 6% a quarter become decacorns,” Kulveer Taggar told TechCrunch. Taggar is a two-time YC alum best known for founding Zeus Living, a property management startup that raised over $150 million in funding.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Taggar is so confident in the continuing return potential offered by the famed accelerator that he established Phosphor Capital, a venture firm dedicated solely to investing in YC companies. Since launching last year, Phosphor has raised $34 million in capital across two funds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Phosphor isn’t the only venture capital firm focused on YC startups — Pioneer Fund and Rebel Fund employ similar strategies—the firm is the only dedicated YC fund led by a solo general partner. And because of Taggar’s long relationship with YC, he also nabbed YC CEO Garry Tan as an investor in the fund, he says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Taggar’s relationship with Y Combinator began in 2007 when he, his cousin Harj Taggar, and future Stripe founders Patrick and John Collison, brought their startup, Auctomatic, through the program. Although Auctomatic was sold just a year later, that experience was key to forging a strong connection with the top accelerator.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He went through Y Combinator again in 2011, this time with Zeus Living, a startup that bought homes to offer furnished accommodations with flexible terms for business and personal travel. Initialized Capital, co-founded by current YC chief Garry Tan, led Zeus Living’s Series A funding and joined its board.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At its peak, the startup was valued at over $200 million and had an annual revenue run rate of about $120 million, according to Taggar.&amp;nbsp;&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;However, Zeus encountered significant headwinds when interest rates surged earlier this decade and the startup was sold to competitor Blueground in late 2023 for undisclosed terms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Taggar launched Phosphor mere months after leaving Zeus. He told TechCrunch he was particularly excited by the opportunity to invest in young AI startups and by Garry Tan’s leadership of the prestigious accelerator. “You could view this as a bet on Garry. I think he is taking Y Combinator to new levels,” Taggar said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike many emerging managers, Taggar had a relatively easy time raising capital. Beyond Tan, he says his other LPs include Zeus’s investors. “I had a relationship with them and a track record, so they knew me, and they knew how hard I work,” he said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Others include family offices and a large asset manager who are taking a bet on Taggar in large part because of his deep connection and long-standing ties to Y Combinator.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Kulveer is what you might call an OG alum from the early days of YC,” said YC partner Jared Friedman. “He’s close to me and to many of the folks who now run YC.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Taggar’s background as a YC alum and a founder was also a part of the draw to Phosphor for LPs and a benefit for founders. “Zeus was a really hard company to run. He has a tremendous number of battle scars from doing this hard thing in the physical world,” Friedman said. “I hear this from founders that he has incredible empathy for what they are going through, because he went through it all himself.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Phosphor writes checks ranging from $100,000 to $500,000. The firm has already backed over 200 YC companies, with several going on to raise Series A funding, including workflow automation platform Gumloop and AI meeting manager Circleback.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/CowanKulveer-0035.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Investing in Y Combinator startups can lead to significant returns to investors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If you look at the data: 6% of YC companies become unicorns, and of that 6% a quarter become decacorns,” Kulveer Taggar told TechCrunch. Taggar is a two-time YC alum best known for founding Zeus Living, a property management startup that raised over $150 million in funding.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Taggar is so confident in the continuing return potential offered by the famed accelerator that he established Phosphor Capital, a venture firm dedicated solely to investing in YC companies. Since launching last year, Phosphor has raised $34 million in capital across two funds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Phosphor isn’t the only venture capital firm focused on YC startups — Pioneer Fund and Rebel Fund employ similar strategies—the firm is the only dedicated YC fund led by a solo general partner. And because of Taggar’s long relationship with YC, he also nabbed YC CEO Garry Tan as an investor in the fund, he says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Taggar’s relationship with Y Combinator began in 2007 when he, his cousin Harj Taggar, and future Stripe founders Patrick and John Collison, brought their startup, Auctomatic, through the program. Although Auctomatic was sold just a year later, that experience was key to forging a strong connection with the top accelerator.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He went through Y Combinator again in 2011, this time with Zeus Living, a startup that bought homes to offer furnished accommodations with flexible terms for business and personal travel. Initialized Capital, co-founded by current YC chief Garry Tan, led Zeus Living’s Series A funding and joined its board.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At its peak, the startup was valued at over $200 million and had an annual revenue run rate of about $120 million, according to Taggar.&amp;nbsp;&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;However, Zeus encountered significant headwinds when interest rates surged earlier this decade and the startup was sold to competitor Blueground in late 2023 for undisclosed terms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Taggar launched Phosphor mere months after leaving Zeus. He told TechCrunch he was particularly excited by the opportunity to invest in young AI startups and by Garry Tan’s leadership of the prestigious accelerator. “You could view this as a bet on Garry. I think he is taking Y Combinator to new levels,” Taggar said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike many emerging managers, Taggar had a relatively easy time raising capital. Beyond Tan, he says his other LPs include Zeus’s investors. “I had a relationship with them and a track record, so they knew me, and they knew how hard I work,” he said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Others include family offices and a large asset manager who are taking a bet on Taggar in large part because of his deep connection and long-standing ties to Y Combinator.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Kulveer is what you might call an OG alum from the early days of YC,” said YC partner Jared Friedman. “He’s close to me and to many of the folks who now run YC.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Taggar’s background as a YC alum and a founder was also a part of the draw to Phosphor for LPs and a benefit for founders. “Zeus was a really hard company to run. He has a tremendous number of battle scars from doing this hard thing in the physical world,” Friedman said. “I hear this from founders that he has incredible empathy for what they are going through, because he went through it all himself.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Phosphor writes checks ranging from $100,000 to $500,000. The firm has already backed over 200 YC companies, with several going on to raise Series A funding, including workflow automation platform Gumloop and AI meeting manager Circleback.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/03/y-combinator-alum-launched-a-new-34m-fund-dedicated-to-yc-startups-backed-by-garry-tan/</guid><pubDate>Thu, 03 Jul 2025 17:00:00 +0000</pubDate></item><item><title>[NEW] Meta’s “AI superintelligence” effort sounds just like its failed “metaverse” (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/07/metas-ai-superintelligence-effort-sounds-just-like-its-failed-metaverse/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Zuckerberg and company talked up another supposed tech revolution four short years ago.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="356" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/zuckmetaverse-640x356.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="600" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/zuckmetaverse.jpg" width="1080" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Artist's conception of Mark Zuckerberg looking into our glorious AI-powered future.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Facebook

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;In a memo to employees earlier this week, Meta CEO Mark Zuckerberg shared a vision for a near-future in which "personal [AI] superintelligence for everyone" forms "the beginning of a new era for humanity." The newly formed Meta Superintelligence Labs—freshly staffed with multiple high-level acquisitions from OpenAI and other AI companies—will spearhead the development of "our next generation of models to get to the frontier in the next year or so," Zuckerberg wrote.&lt;/p&gt;
&lt;p&gt;Reading that memo, I couldn't help but think of another "vision for the future" Zuckerberg shared not that long ago. At his 2021 Facebook Connect keynote, Zuckerberg laid out his plan for the metaverse, a virtual place where “you're gonna be able to do almost anything you can imagine" and which would form the basis of "the next version of the Internet."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-1832297 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="439" src="https://cdn.arstechnica.net/wp-content/uploads/2022/02/metabound1.png" width="780" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      "The future of the Internet" of the recent past.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Meta

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Zuckerberg believed in that vision so much at the time that he abandoned the well-known Facebook corporate brand in favor of the new name "Meta." "I'm going to keep pushing and giving everything I've got to make this happen now," Zuckerberg said at the time. Less than four years later, Zuckerberg seems to now be “giving everything [he's] got" for a vision of AI “superintelligence," reportedly offering pay packages of up to $300 million over four years to attract top talent from other AI companies (Meta has since denied those reports, saying, “The size and structure of these compensation packages have been misrepresented all over the place").&lt;/p&gt;
&lt;p&gt;Once again, Zuckerberg is promising that this new technology will revolutionize our lives and replace the ways we currently socialize and work on the Internet. But the utter failure (so far) of those over-the-top promises for the metaverse has us more than a little skeptical of how impactful Zuckerberg’s vision of “personal superintelligence for everyone" will truly be.&lt;/p&gt;
&lt;h2&gt;Meta-vision&lt;/h2&gt;
&lt;p&gt;Looking back at Zuckerberg’s 2021 Facebook Connect keynote shows just how hard the company was selling the promise of the metaverse at the time. Zuckerberg said the metaverse would represent an “even more immersive and embodied Internet" where “everything we do online today—connecting socially, entertainment, games, work—is going to be more natural and vivid."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Mark Zuckerberg lays out his vision for the metaverse in 2021.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;"Teleporting around the metaverse is going to be like clicking a link on the Internet," Zuckerberg promised, and metaverse users would probably switch between “a photorealistic avatar for work, a stylized one for hanging out, and maybe even a fantasy one for gaming." This kind of personalization would lead to “hundreds of thousands" of artists being able to make a living selling virtual metaverse goods that could be embedded in virtual or real-world environments.&lt;/p&gt;
&lt;p&gt;“Lots of things that are physical today, like screens, will just be able to be holograms in the future," Zuckerberg promised. “You won't need a physical TV; it'll just be a one-dollar hologram from some high school kid halfway across the world… we'll be able to express ourselves in new joyful, completely immersive ways, and that's going to unlock a lot of amazing new experiences."&lt;/p&gt;
&lt;p&gt;A pre-rendered concept video showed metaverse users playing poker in a zero-gravity space station with robot avatars, then pausing briefly to appreciate some animated 3D art a friend had encountered on the street. Another video showed a young woman teleporting via metaverse avatar to virtually join a friend attending a live concert in Tokyo, then buying virtual merch from the concert at a metaverse afterparty from the comfort of her home. Yet another showed old men playing chess on a park bench, even though one of the players was sitting across the country.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Meta-failure&lt;/h2&gt;
&lt;p&gt;Fast forward to 2025, and the current reality of Zuckerberg’s metaverse efforts bears almost no resemblance to anything shown or discussed back in 2021. Even enthusiasts describe Meta’s Horizon Worlds as a “depressing" and “lonely" experience characterized by “completely empty" venues. And Meta engineers anonymously gripe about metaverse tools that even employees actively avoid using and a messy codebase that was treated like “a 3D version of a mobile app. "&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-1788691 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="screen sharing" class="fullwidth full" height="501" src="https://cdn.arstechnica.net/wp-content/uploads/2021/08/CD21_546-_-NRP-Oculus-Cross-Post_-Horizon-Workrooms-Launch_Inline-3.jpg" width="890" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Even Meta employees reportedly don't want to work in Horizon Workrooms.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Facebook

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The creation of a $50 million creator fund seems to have failed to encourage peeved creators to give the metaverse another chance. Things look a bit better if you expand your view past Meta’s own metaverse sandbox; the chaotic world of VR Chat attracts tens of thousands of daily users on Steam alone, for instance. Still, we’re a far cry from the replacement for the mobile Internet that Zuckerberg once trumpeted.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Then again, it’s possible that we just haven’t given Zuckerberg’s version of the metaverse enough time to develop. Back in 2021, he said that “a lot of this is going to be mainstream" within “the next five or 10 years." That timeframe gives Meta at least a few more years to develop and release its long-teased, lightweight augmented reality glasses that the company showed off last year in the form of a prototype that reportedly still costs $10,000 per unit.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2070873 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="fullwidth full" height="682" src="https://cdn.arstechnica.net/wp-content/uploads/2025/01/GettyImages-2173579471.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Zuckerberg shows off prototype AR glasses that could change the way we think about "the metaverse."

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Bloomberg / Contributor | Bloomberg

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Maybe those glasses will ignite widespread interest in the metaverse in a way that Meta’s bulky, niche VR goggles have utterly failed to. Regardless, after nearly four years and roughly $60 billion in VR-related losses, Meta thus far has surprisingly little to show for its massive investment in Zuckerberg’s metaverse vision.&lt;/p&gt;
&lt;h2&gt;Our AI future?&lt;/h2&gt;
&lt;p&gt;When I hear Zuckerberg talk about the promise of AI these days, it’s hard not to hear echoes of his monumental vision for the metaverse from 2021. If anything, Zuckerberg’s vision of our AI-powered future is even more grandiose than his view of the metaverse.&lt;/p&gt;
&lt;p&gt;As with the metaverse, Zuckerberg now sees AI forming a replacement for the current version of the Internet. “Do you think in five years we’re just going to be sitting in our feed and consuming media that's just video?" Zuckerberg asked rhetorically in an April interview with Drawkesh Patel. “No, it's going to be interactive," he continued, envisioning something like Instagram Reels, but “you can talk to it, or interact with it, and it talks back, or it changes what it's doing. Or you can jump into it like a game and interact with it. That's all going to be AI."&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Mark Zuckerberg talks about all the ways superhuman AI is going to change our lives in the near future.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;As with the Metaverse, Zuckerberg sees AI as revolutionizing the way we interact with each other. He envisions “always-on video chats with the AI" incorporating expressions and body language borrowed from the company’s work on the metaverse. And our relationships with AI models are “just going to get more intense as these AIs become more unique, more personable, more intelligent, more spontaneous, more funny, and so forth," Zuckerberg said. "As the personalization loop kicks in and the AI starts to get to know you better and better, that will just be really compelling."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Zuckerberg did allow that relationships with AI would “probably not" replace in-person connections, because there are “things that are better about physical connections when you can have them." At the same time, he said, for the average American who has three friends, AI relationships can fill the “demand" for “something like 15 friends" without the effort of real-world socializing. “People just don't have as much connection as they want," Zuckerberg said. “They feel more alone a lot of the time than they would like."&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;figure class="ars-wp-img-shortcode id-1958135 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="A toy robot saying &amp;quot;plz use facebook.&amp;quot;" class="fullwidth full" height="675" src="https://cdn.arstechnica.net/wp-content/uploads/2023/08/facebook_bot_hero_3.jpg" width="1200" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Why chat with real friends on Facebook when you can chat with AI avatars?

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards / Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Zuckerberg also sees AI leading to a flourishing of human productivity and creativity in a way even his wildest metaverse imaginings couldn’t match. Zuckerberg said that AI advancement could “lead toward a world of abundance where everyone has these superhuman tools to create whatever they want." That means personal access to “a super powerful [virtual] software engineer" and AIs that are “solving diseases, advancing science, developing new technology that makes our lives better."&lt;/p&gt;
&lt;p&gt;That will also mean that some companies will be able to get by with fewer employees before too long, Zuckerberg said. In customer service, for instance, “as AI gets better, you're going to get to a place where AI can handle a bunch of people's issues," he said. “Not all of them—maybe 10 years from now it can handle all of them—but thinking about a three- to five-year time horizon, it will be able to handle a bunch.“&lt;/p&gt;
&lt;p&gt;In the longer term, Zuckerberg said, AIs will be integrated into our more casual pursuits as well. "If everyone has these superhuman tools to create a ton of different stuff, you're going to get incredible diversity," and "the amount of creativity that's going to be unlocked is going to be massive," he said. "I would guess the world is going to get a lot funnier, weirder, and quirkier, the way that memes on the Internet have gotten over the last 10 years."&lt;/p&gt;
&lt;h2&gt;Compare and contrast&lt;/h2&gt;
&lt;p&gt;To be sure, there are some important differences between the past promise of the metaverse and the current promise of AI technology. Zuckerberg claims that a billion people use Meta’s AI products monthly, for instance, utterly dwarfing the highest estimates for regular use of “the metaverse" or augmented reality as a whole (even if many AI users seem to balk at paying for regular use of AI tools). Meta coders are also reportedly already using AI coding tools regularly in a way they never did with Meta’s metaverse tools. And people are already developing what they consider meaningful relationships with AI personas, whether that’s in the form of therapists or romantic partners.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Still, there are reasons to be skeptical about the future of AI when current models still routinely hallucinate basic facts, show fundamental issues when attempting reasoning, and struggle with basic tasks like beating a children’s video game. The path from where we are to a supposed “superhuman" AI is not simple or inevitable, despite the handwaving of industry boosters like Zuckerberg.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-1905416 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="1280" src="https://cdn.arstechnica.net/wp-content/uploads/2022/12/carmackavatar.png" width="1993" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Artist's conception of Carmack's VR avatar waving goodbye to Meta.

          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;At the 2021 rollout of Meta’s push to develop a metaverse, high-ranking Meta executives like John Carmack were at least up front about the technical and product-development barriers that could get in the way of Zuckerberg’s vision. "Everybody that wants to work on the metaverse talks about the limitless possibilities of it," Carmack said at the time (before departing the company in late 2022). "But it's not limitless. It is a challenge to fit things in, but you can make smarter decisions about exactly what is important and then really optimize the heck out of things."&lt;/p&gt;
&lt;p&gt;Today, those kinds of voices of internal skepticism seem in short supply as Meta sets itself up to push AI in the same way it once backed the metaverse. Don’t be surprised, though, if today’s promise that we're at "the beginning of a new era for humanity" ages about as well as Meta’s former promises about a metaverse where "you're gonna be able to do almost anything you can imagine."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Zuckerberg and company talked up another supposed tech revolution four short years ago.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="356" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/zuckmetaverse-640x356.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="600" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/zuckmetaverse.jpg" width="1080" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Artist's conception of Mark Zuckerberg looking into our glorious AI-powered future.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Facebook

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;In a memo to employees earlier this week, Meta CEO Mark Zuckerberg shared a vision for a near-future in which "personal [AI] superintelligence for everyone" forms "the beginning of a new era for humanity." The newly formed Meta Superintelligence Labs—freshly staffed with multiple high-level acquisitions from OpenAI and other AI companies—will spearhead the development of "our next generation of models to get to the frontier in the next year or so," Zuckerberg wrote.&lt;/p&gt;
&lt;p&gt;Reading that memo, I couldn't help but think of another "vision for the future" Zuckerberg shared not that long ago. At his 2021 Facebook Connect keynote, Zuckerberg laid out his plan for the metaverse, a virtual place where “you're gonna be able to do almost anything you can imagine" and which would form the basis of "the next version of the Internet."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-1832297 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="439" src="https://cdn.arstechnica.net/wp-content/uploads/2022/02/metabound1.png" width="780" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      "The future of the Internet" of the recent past.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Meta

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Zuckerberg believed in that vision so much at the time that he abandoned the well-known Facebook corporate brand in favor of the new name "Meta." "I'm going to keep pushing and giving everything I've got to make this happen now," Zuckerberg said at the time. Less than four years later, Zuckerberg seems to now be “giving everything [he's] got" for a vision of AI “superintelligence," reportedly offering pay packages of up to $300 million over four years to attract top talent from other AI companies (Meta has since denied those reports, saying, “The size and structure of these compensation packages have been misrepresented all over the place").&lt;/p&gt;
&lt;p&gt;Once again, Zuckerberg is promising that this new technology will revolutionize our lives and replace the ways we currently socialize and work on the Internet. But the utter failure (so far) of those over-the-top promises for the metaverse has us more than a little skeptical of how impactful Zuckerberg’s vision of “personal superintelligence for everyone" will truly be.&lt;/p&gt;
&lt;h2&gt;Meta-vision&lt;/h2&gt;
&lt;p&gt;Looking back at Zuckerberg’s 2021 Facebook Connect keynote shows just how hard the company was selling the promise of the metaverse at the time. Zuckerberg said the metaverse would represent an “even more immersive and embodied Internet" where “everything we do online today—connecting socially, entertainment, games, work—is going to be more natural and vivid."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Mark Zuckerberg lays out his vision for the metaverse in 2021.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;"Teleporting around the metaverse is going to be like clicking a link on the Internet," Zuckerberg promised, and metaverse users would probably switch between “a photorealistic avatar for work, a stylized one for hanging out, and maybe even a fantasy one for gaming." This kind of personalization would lead to “hundreds of thousands" of artists being able to make a living selling virtual metaverse goods that could be embedded in virtual or real-world environments.&lt;/p&gt;
&lt;p&gt;“Lots of things that are physical today, like screens, will just be able to be holograms in the future," Zuckerberg promised. “You won't need a physical TV; it'll just be a one-dollar hologram from some high school kid halfway across the world… we'll be able to express ourselves in new joyful, completely immersive ways, and that's going to unlock a lot of amazing new experiences."&lt;/p&gt;
&lt;p&gt;A pre-rendered concept video showed metaverse users playing poker in a zero-gravity space station with robot avatars, then pausing briefly to appreciate some animated 3D art a friend had encountered on the street. Another video showed a young woman teleporting via metaverse avatar to virtually join a friend attending a live concert in Tokyo, then buying virtual merch from the concert at a metaverse afterparty from the comfort of her home. Yet another showed old men playing chess on a park bench, even though one of the players was sitting across the country.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Meta-failure&lt;/h2&gt;
&lt;p&gt;Fast forward to 2025, and the current reality of Zuckerberg’s metaverse efforts bears almost no resemblance to anything shown or discussed back in 2021. Even enthusiasts describe Meta’s Horizon Worlds as a “depressing" and “lonely" experience characterized by “completely empty" venues. And Meta engineers anonymously gripe about metaverse tools that even employees actively avoid using and a messy codebase that was treated like “a 3D version of a mobile app. "&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-1788691 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="screen sharing" class="fullwidth full" height="501" src="https://cdn.arstechnica.net/wp-content/uploads/2021/08/CD21_546-_-NRP-Oculus-Cross-Post_-Horizon-Workrooms-Launch_Inline-3.jpg" width="890" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Even Meta employees reportedly don't want to work in Horizon Workrooms.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Facebook

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The creation of a $50 million creator fund seems to have failed to encourage peeved creators to give the metaverse another chance. Things look a bit better if you expand your view past Meta’s own metaverse sandbox; the chaotic world of VR Chat attracts tens of thousands of daily users on Steam alone, for instance. Still, we’re a far cry from the replacement for the mobile Internet that Zuckerberg once trumpeted.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Then again, it’s possible that we just haven’t given Zuckerberg’s version of the metaverse enough time to develop. Back in 2021, he said that “a lot of this is going to be mainstream" within “the next five or 10 years." That timeframe gives Meta at least a few more years to develop and release its long-teased, lightweight augmented reality glasses that the company showed off last year in the form of a prototype that reportedly still costs $10,000 per unit.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2070873 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="fullwidth full" height="682" src="https://cdn.arstechnica.net/wp-content/uploads/2025/01/GettyImages-2173579471.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Zuckerberg shows off prototype AR glasses that could change the way we think about "the metaverse."

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Bloomberg / Contributor | Bloomberg

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Maybe those glasses will ignite widespread interest in the metaverse in a way that Meta’s bulky, niche VR goggles have utterly failed to. Regardless, after nearly four years and roughly $60 billion in VR-related losses, Meta thus far has surprisingly little to show for its massive investment in Zuckerberg’s metaverse vision.&lt;/p&gt;
&lt;h2&gt;Our AI future?&lt;/h2&gt;
&lt;p&gt;When I hear Zuckerberg talk about the promise of AI these days, it’s hard not to hear echoes of his monumental vision for the metaverse from 2021. If anything, Zuckerberg’s vision of our AI-powered future is even more grandiose than his view of the metaverse.&lt;/p&gt;
&lt;p&gt;As with the metaverse, Zuckerberg now sees AI forming a replacement for the current version of the Internet. “Do you think in five years we’re just going to be sitting in our feed and consuming media that's just video?" Zuckerberg asked rhetorically in an April interview with Drawkesh Patel. “No, it's going to be interactive," he continued, envisioning something like Instagram Reels, but “you can talk to it, or interact with it, and it talks back, or it changes what it's doing. Or you can jump into it like a game and interact with it. That's all going to be AI."&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Mark Zuckerberg talks about all the ways superhuman AI is going to change our lives in the near future.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;As with the Metaverse, Zuckerberg sees AI as revolutionizing the way we interact with each other. He envisions “always-on video chats with the AI" incorporating expressions and body language borrowed from the company’s work on the metaverse. And our relationships with AI models are “just going to get more intense as these AIs become more unique, more personable, more intelligent, more spontaneous, more funny, and so forth," Zuckerberg said. "As the personalization loop kicks in and the AI starts to get to know you better and better, that will just be really compelling."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Zuckerberg did allow that relationships with AI would “probably not" replace in-person connections, because there are “things that are better about physical connections when you can have them." At the same time, he said, for the average American who has three friends, AI relationships can fill the “demand" for “something like 15 friends" without the effort of real-world socializing. “People just don't have as much connection as they want," Zuckerberg said. “They feel more alone a lot of the time than they would like."&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;figure class="ars-wp-img-shortcode id-1958135 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="A toy robot saying &amp;quot;plz use facebook.&amp;quot;" class="fullwidth full" height="675" src="https://cdn.arstechnica.net/wp-content/uploads/2023/08/facebook_bot_hero_3.jpg" width="1200" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Why chat with real friends on Facebook when you can chat with AI avatars?

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards / Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Zuckerberg also sees AI leading to a flourishing of human productivity and creativity in a way even his wildest metaverse imaginings couldn’t match. Zuckerberg said that AI advancement could “lead toward a world of abundance where everyone has these superhuman tools to create whatever they want." That means personal access to “a super powerful [virtual] software engineer" and AIs that are “solving diseases, advancing science, developing new technology that makes our lives better."&lt;/p&gt;
&lt;p&gt;That will also mean that some companies will be able to get by with fewer employees before too long, Zuckerberg said. In customer service, for instance, “as AI gets better, you're going to get to a place where AI can handle a bunch of people's issues," he said. “Not all of them—maybe 10 years from now it can handle all of them—but thinking about a three- to five-year time horizon, it will be able to handle a bunch.“&lt;/p&gt;
&lt;p&gt;In the longer term, Zuckerberg said, AIs will be integrated into our more casual pursuits as well. "If everyone has these superhuman tools to create a ton of different stuff, you're going to get incredible diversity," and "the amount of creativity that's going to be unlocked is going to be massive," he said. "I would guess the world is going to get a lot funnier, weirder, and quirkier, the way that memes on the Internet have gotten over the last 10 years."&lt;/p&gt;
&lt;h2&gt;Compare and contrast&lt;/h2&gt;
&lt;p&gt;To be sure, there are some important differences between the past promise of the metaverse and the current promise of AI technology. Zuckerberg claims that a billion people use Meta’s AI products monthly, for instance, utterly dwarfing the highest estimates for regular use of “the metaverse" or augmented reality as a whole (even if many AI users seem to balk at paying for regular use of AI tools). Meta coders are also reportedly already using AI coding tools regularly in a way they never did with Meta’s metaverse tools. And people are already developing what they consider meaningful relationships with AI personas, whether that’s in the form of therapists or romantic partners.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Still, there are reasons to be skeptical about the future of AI when current models still routinely hallucinate basic facts, show fundamental issues when attempting reasoning, and struggle with basic tasks like beating a children’s video game. The path from where we are to a supposed “superhuman" AI is not simple or inevitable, despite the handwaving of industry boosters like Zuckerberg.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-1905416 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="1280" src="https://cdn.arstechnica.net/wp-content/uploads/2022/12/carmackavatar.png" width="1993" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Artist's conception of Carmack's VR avatar waving goodbye to Meta.

          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;At the 2021 rollout of Meta’s push to develop a metaverse, high-ranking Meta executives like John Carmack were at least up front about the technical and product-development barriers that could get in the way of Zuckerberg’s vision. "Everybody that wants to work on the metaverse talks about the limitless possibilities of it," Carmack said at the time (before departing the company in late 2022). "But it's not limitless. It is a challenge to fit things in, but you can make smarter decisions about exactly what is important and then really optimize the heck out of things."&lt;/p&gt;
&lt;p&gt;Today, those kinds of voices of internal skepticism seem in short supply as Meta sets itself up to push AI in the same way it once backed the metaverse. Don’t be surprised, though, if today’s promise that we're at "the beginning of a new era for humanity" ages about as well as Meta’s former promises about a metaverse where "you're gonna be able to do almost anything you can imagine."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/07/metas-ai-superintelligence-effort-sounds-just-like-its-failed-metaverse/</guid><pubDate>Thu, 03 Jul 2025 17:21:09 +0000</pubDate></item><item><title>[NEW] Ilya Sutskever will lead Safe Superintelligence following his CEO’s exit (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/03/ilya-sutskever-will-lead-safe-superintelligence-following-his-ceos-exit/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/ilyausutskever-GettyImages.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI co-founder Ilya Sutskever says he is stepping into the CEO role at Safe Superintelligence, the AI startup he launched in 2024.&amp;nbsp;In a&amp;nbsp;post on X, Sutskever confirmed Thursday that Daniel Gross, the startup’s co-founder and CEO, departed the company as of June 29. Safe Superintelligence co-founder Daniel Levy is becoming president of the startup, according to Sutskever.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The announcement follows weeks of reporting that Meta CEO Mark Zuckerberg was in advanced talks to hire Gross, as well as his longtime investing partner, former GitHub CEO Nat Friedman. At one point, Zuckerberg reportedly attempted to acquire all of Safe Superintelligence, a startup most recently valued at $32 billion. Sutskever addressed those reports as well.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“You might have heard rumors of companies looking to acquire us. We are flattered by their attention but are focused on seeing our work through,” said Sutskever. “We have the compute, we have the team, and we know what to do. Together we will keep building safe superintelligence.”&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;I sent the following message to our team and investors:&lt;br /&gt;—&lt;/p&gt;&lt;p&gt;As you know, Daniel Gross’s time with us has been winding down, and as of June 29 he is officially no longer a part of SSI. We are grateful for his early contributions to the company and wish him well in his next…&lt;/p&gt;— Ilya Sutskever (@ilyasut) July 3, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Naturally, Gross’ departure may raise questions around the startup. If Safe Superintelligence was close to its goal — surely a groundbreaking technology, as it’s described — why would its co-founder leave to start something new, seemingly at Meta?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, Safe Superintelligence describes themselves as the world’s “first straight-shot SSI lab,” meaning the company has no other products or ambitions outside of developing, well, safe superintelligence. That’s the name, that’s the product, that’s their whole thing. Sutskever started Safe Superintelligence shortly after leaving OpenAI, where he played a role in the brief ousting of CEO Sam Altman.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, it seems likely that Meta Superintelligence Labs will develop technology that powers lots of the company’s products. In&amp;nbsp;Zuckerberg’s memo&amp;nbsp;announcing the new unit, he referenced Meta’s expertise in building and growing products that reach billions of people, and cited the early wins Meta has had in AI wearables.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That means Gross, who previously led AI teams at Apple after the iPhone maker acquired his startup, could have a more familiar role at Meta, should he join. Zuckerberg has also nabbed some&amp;nbsp;top researchers from OpenAI&amp;nbsp;and Google DeepMind to fill out his new AI team.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Nevertheless, Sutskever may have his hands full as Safe Superintelligence’s CEO. While he’s held previous high-ranking positions, such as OpenAI’s chief scientist, the CEO role may come with new challenges — such as raising new capital from investors and recruiting top talent. Sutskever notes in his post that he’ll continue to oversee Safe Superintelligence’s technical team.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/ilyausutskever-GettyImages.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI co-founder Ilya Sutskever says he is stepping into the CEO role at Safe Superintelligence, the AI startup he launched in 2024.&amp;nbsp;In a&amp;nbsp;post on X, Sutskever confirmed Thursday that Daniel Gross, the startup’s co-founder and CEO, departed the company as of June 29. Safe Superintelligence co-founder Daniel Levy is becoming president of the startup, according to Sutskever.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The announcement follows weeks of reporting that Meta CEO Mark Zuckerberg was in advanced talks to hire Gross, as well as his longtime investing partner, former GitHub CEO Nat Friedman. At one point, Zuckerberg reportedly attempted to acquire all of Safe Superintelligence, a startup most recently valued at $32 billion. Sutskever addressed those reports as well.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“You might have heard rumors of companies looking to acquire us. We are flattered by their attention but are focused on seeing our work through,” said Sutskever. “We have the compute, we have the team, and we know what to do. Together we will keep building safe superintelligence.”&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;I sent the following message to our team and investors:&lt;br /&gt;—&lt;/p&gt;&lt;p&gt;As you know, Daniel Gross’s time with us has been winding down, and as of June 29 he is officially no longer a part of SSI. We are grateful for his early contributions to the company and wish him well in his next…&lt;/p&gt;— Ilya Sutskever (@ilyasut) July 3, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Naturally, Gross’ departure may raise questions around the startup. If Safe Superintelligence was close to its goal — surely a groundbreaking technology, as it’s described — why would its co-founder leave to start something new, seemingly at Meta?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, Safe Superintelligence describes themselves as the world’s “first straight-shot SSI lab,” meaning the company has no other products or ambitions outside of developing, well, safe superintelligence. That’s the name, that’s the product, that’s their whole thing. Sutskever started Safe Superintelligence shortly after leaving OpenAI, where he played a role in the brief ousting of CEO Sam Altman.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, it seems likely that Meta Superintelligence Labs will develop technology that powers lots of the company’s products. In&amp;nbsp;Zuckerberg’s memo&amp;nbsp;announcing the new unit, he referenced Meta’s expertise in building and growing products that reach billions of people, and cited the early wins Meta has had in AI wearables.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That means Gross, who previously led AI teams at Apple after the iPhone maker acquired his startup, could have a more familiar role at Meta, should he join. Zuckerberg has also nabbed some&amp;nbsp;top researchers from OpenAI&amp;nbsp;and Google DeepMind to fill out his new AI team.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Nevertheless, Sutskever may have his hands full as Safe Superintelligence’s CEO. While he’s held previous high-ranking positions, such as OpenAI’s chief scientist, the CEO role may come with new challenges — such as raising new capital from investors and recruiting top talent. Sutskever notes in his post that he’ll continue to oversee Safe Superintelligence’s technical team.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/03/ilya-sutskever-will-lead-safe-superintelligence-following-his-ceos-exit/</guid><pubDate>Thu, 03 Jul 2025 17:29:07 +0000</pubDate></item><item><title>[NEW] Why Cloudflare wants AI companies to pay for content (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/podcast/why-cloudflare-wants-ai-companies-to-pay-for-content/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2019/12/Matthew-Prince-CloudflareDSC00252.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;Cloudflare wants AI companies to pay up. The cloud infrastructure provider, which powers around 20% of the web, is launching a new experiment that would let publishers charge AI firms every time their bots scrape a site. It’s called Pay per Crawl, and it could reshape how content is accessed and monetized online.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Today on TechCrunch’s Equity podcast, hosts Kirsten Korosec and Max Zeff dig into Cloudflare’s big swing, why it’s a natural next step after a year of laying groundwork for bot-blocking tools, and whether the plan to sit at the center of a pay-for-content protocol is genius…or just wishful thinking.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear more about:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;How ICEBlock, an app for anonymously reporting ICE sightings, went viral thanks to backlash from former prosecutor Pam Bondi. ICEBlock is now one of the most-downloaded free iPhone apps in the U.S.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Why Figma’s S-1 filing could set the stage for a blockbuster IPO, and what its 48% revenue growth says about demand for design tools&lt;/li&gt;
&lt;/ul&gt;







&lt;p class="wp-block-paragraph"&gt;Equity will be back next week, and for those of you in the U.S., enjoy the long holiday weekend!&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Subscribe to us on&lt;/em&gt;&lt;em&gt; &lt;/em&gt;&lt;em&gt;Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2019/12/Matthew-Prince-CloudflareDSC00252.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;Cloudflare wants AI companies to pay up. The cloud infrastructure provider, which powers around 20% of the web, is launching a new experiment that would let publishers charge AI firms every time their bots scrape a site. It’s called Pay per Crawl, and it could reshape how content is accessed and monetized online.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Today on TechCrunch’s Equity podcast, hosts Kirsten Korosec and Max Zeff dig into Cloudflare’s big swing, why it’s a natural next step after a year of laying groundwork for bot-blocking tools, and whether the plan to sit at the center of a pay-for-content protocol is genius…or just wishful thinking.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear more about:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;How ICEBlock, an app for anonymously reporting ICE sightings, went viral thanks to backlash from former prosecutor Pam Bondi. ICEBlock is now one of the most-downloaded free iPhone apps in the U.S.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Why Figma’s S-1 filing could set the stage for a blockbuster IPO, and what its 48% revenue growth says about demand for design tools&lt;/li&gt;
&lt;/ul&gt;







&lt;p class="wp-block-paragraph"&gt;Equity will be back next week, and for those of you in the U.S., enjoy the long holiday weekend!&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Subscribe to us on&lt;/em&gt;&lt;em&gt; &lt;/em&gt;&lt;em&gt;Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/podcast/why-cloudflare-wants-ai-companies-to-pay-for-content/</guid><pubDate>Thu, 03 Jul 2025 17:58:12 +0000</pubDate></item></channel></rss>