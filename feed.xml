<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 21 Aug 2025 06:41:32 +0000</lastBuildDate><item><title>Gen AI makes no financial difference in 95% of cases (AI News)</title><link>https://www.artificialintelligence-news.com/news/gen-ai-makes-no-financial-difference-in-95-of-cases/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/genai-ineffective-in-95-percent-of-cases-survey.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Stocks in US AI technology companies fell in value at the close of trading yesterday, with the NASDAQ Composite index down 1.4%. Among those losing value were Palantir, down 9.4% and Arm Holdings down 5%. According to the &lt;em&gt;Financial Times&lt;/em&gt; [paywall], Tuesday saw the biggest one-day fall in the market since the beginning of August.&lt;/p&gt;&lt;p&gt;Some traders put the falls down to a report released [PDF] by an AI company, NANDA, which noted the high failure rate of many generative AI projects in commercial organisations. Project NANDA originated at the Massachusetts Institute of Technology Media Lab and describes itself as an organisation that’s building an “agentic web.” The paper has, since publication, been placed behind a survey wall, but is available for download from this site.&lt;/p&gt;&lt;p&gt;The research authors state only 5% of gen AI pilots reach production and actually produce measurable monetary value, with the vast majority of projects creating little impact on profit &amp;amp; loss metrics. The research undertaken by NANDA comprised of the content of 52 structured interviews with enterprise decision-makers, researchers’ analysis of 300+ public AI initiatives and announcements, and a survey questionnaire completed by 153 company leaders. It measured return on investment over six months after gen AI projects left pilot status.&lt;/p&gt;&lt;p&gt;While many organisations deploy AI in front-office or customer-facing business functions, successful projects tend to be found among back-office workflows, the paper says. It’s in the mundane tasks of the back office where savings are accrued, largely from a lowered need for third-party agencies and BPOs. The survey found there was little impact by AI projects on overall internal staff levels.&lt;/p&gt;&lt;p&gt;While 90% of staff stated they have personally benefited from using publicly-available AIs, typically in the form of large language models like ChatGPT, those subjective gains are not translated at institution level. Around 40% of the companies surveyed pay for a subscription to LLMs.&lt;/p&gt;&lt;p&gt;Many of the failed projects’ owners cited the lack of contextual awareness exhibited by generative AI models – that is, adapting to circumstances, changing over time, and remembering previous enquiries. NANDA states that forming a partnership with an organisation that can supply such a system and ensure it adapts to an organisation’s specific circumstances is the critical element for success. The paper highlights several quotes “derived from interviews” that include between 60%-70% agreeing with the statements, “[The AI system] doesn’t learn from our feedback,” and “Too much manual context required each time.”&lt;/p&gt;&lt;p&gt;The vertical most positively affected by gen AI was media &amp;amp; telecom, followed by professional services, healthcare &amp;amp; pharma, consumer &amp;amp; retail, and financial services. The energy &amp;amp; materials sector’s rate of generative AI project launch is currently negligible, the paper says. In terms of business units, sales &amp;amp; marketing is where most projects are or were based, with finance &amp;amp; procurement least popular as a place where AI projects might be begun.&lt;/p&gt;&lt;p&gt;The area in a typical organisation where generative AI is deployed most is in sales &amp;amp; marketing, with finance and procurement being the least popular site. And complex tasks are those least likely to be expected to be completed by AI; managers would assign projects like client management to an AI only 10% of the time, while tasks like summarising a report or writing an email would go to a human on 70% of occasions.&lt;/p&gt;&lt;p&gt;The language of the published report and its lack of academic rigour suggest that its provenance and purpose are more akin to marketing than intellectual and technological discussion. The paper’s authors urge for strategic partnerships with a knowledgeable vendor to increase the chances of generative AI projects’ success, a partnership which NANDA is, purely coincidentally, able to form one half of. There are “unprecedented opportunities for vendors who can deliver learning-capable, deeply integrated AI systems,” the paper’s conclusions state.&lt;/p&gt;&lt;p&gt;The headlines from the NANDA report make for sobering reading among decision-makers tasked with generative AI implementations, yet the paper’s underlying messages are weakened by the intentions behind its publication. Stock prices this week could have been affected by partisan surveys from authors with obvious skin in the game, but it seems more likely that the NANDA publication simply reflects trading floors’ concerns about generative AI’s practical effectiveness as a business tool.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “Arthur Daley” by Tim Dennell is licensed under CC BY-NC-ND 2.0.&lt;/em&gt;)&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/genai-ineffective-in-95-percent-of-cases-survey.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Stocks in US AI technology companies fell in value at the close of trading yesterday, with the NASDAQ Composite index down 1.4%. Among those losing value were Palantir, down 9.4% and Arm Holdings down 5%. According to the &lt;em&gt;Financial Times&lt;/em&gt; [paywall], Tuesday saw the biggest one-day fall in the market since the beginning of August.&lt;/p&gt;&lt;p&gt;Some traders put the falls down to a report released [PDF] by an AI company, NANDA, which noted the high failure rate of many generative AI projects in commercial organisations. Project NANDA originated at the Massachusetts Institute of Technology Media Lab and describes itself as an organisation that’s building an “agentic web.” The paper has, since publication, been placed behind a survey wall, but is available for download from this site.&lt;/p&gt;&lt;p&gt;The research authors state only 5% of gen AI pilots reach production and actually produce measurable monetary value, with the vast majority of projects creating little impact on profit &amp;amp; loss metrics. The research undertaken by NANDA comprised of the content of 52 structured interviews with enterprise decision-makers, researchers’ analysis of 300+ public AI initiatives and announcements, and a survey questionnaire completed by 153 company leaders. It measured return on investment over six months after gen AI projects left pilot status.&lt;/p&gt;&lt;p&gt;While many organisations deploy AI in front-office or customer-facing business functions, successful projects tend to be found among back-office workflows, the paper says. It’s in the mundane tasks of the back office where savings are accrued, largely from a lowered need for third-party agencies and BPOs. The survey found there was little impact by AI projects on overall internal staff levels.&lt;/p&gt;&lt;p&gt;While 90% of staff stated they have personally benefited from using publicly-available AIs, typically in the form of large language models like ChatGPT, those subjective gains are not translated at institution level. Around 40% of the companies surveyed pay for a subscription to LLMs.&lt;/p&gt;&lt;p&gt;Many of the failed projects’ owners cited the lack of contextual awareness exhibited by generative AI models – that is, adapting to circumstances, changing over time, and remembering previous enquiries. NANDA states that forming a partnership with an organisation that can supply such a system and ensure it adapts to an organisation’s specific circumstances is the critical element for success. The paper highlights several quotes “derived from interviews” that include between 60%-70% agreeing with the statements, “[The AI system] doesn’t learn from our feedback,” and “Too much manual context required each time.”&lt;/p&gt;&lt;p&gt;The vertical most positively affected by gen AI was media &amp;amp; telecom, followed by professional services, healthcare &amp;amp; pharma, consumer &amp;amp; retail, and financial services. The energy &amp;amp; materials sector’s rate of generative AI project launch is currently negligible, the paper says. In terms of business units, sales &amp;amp; marketing is where most projects are or were based, with finance &amp;amp; procurement least popular as a place where AI projects might be begun.&lt;/p&gt;&lt;p&gt;The area in a typical organisation where generative AI is deployed most is in sales &amp;amp; marketing, with finance and procurement being the least popular site. And complex tasks are those least likely to be expected to be completed by AI; managers would assign projects like client management to an AI only 10% of the time, while tasks like summarising a report or writing an email would go to a human on 70% of occasions.&lt;/p&gt;&lt;p&gt;The language of the published report and its lack of academic rigour suggest that its provenance and purpose are more akin to marketing than intellectual and technological discussion. The paper’s authors urge for strategic partnerships with a knowledgeable vendor to increase the chances of generative AI projects’ success, a partnership which NANDA is, purely coincidentally, able to form one half of. There are “unprecedented opportunities for vendors who can deliver learning-capable, deeply integrated AI systems,” the paper’s conclusions state.&lt;/p&gt;&lt;p&gt;The headlines from the NANDA report make for sobering reading among decision-makers tasked with generative AI implementations, yet the paper’s underlying messages are weakened by the intentions behind its publication. Stock prices this week could have been affected by partisan surveys from authors with obvious skin in the game, but it seems more likely that the NANDA publication simply reflects trading floors’ concerns about generative AI’s practical effectiveness as a business tool.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “Arthur Daley” by Tim Dennell is licensed under CC BY-NC-ND 2.0.&lt;/em&gt;)&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/gen-ai-makes-no-financial-difference-in-95-of-cases/</guid><pubDate>Wed, 20 Aug 2025 18:57:06 +0000</pubDate></item><item><title>Securing private data at scale with differentially private partition selection (The latest research from Google)</title><link>https://research.google/blog/securing-private-data-at-scale-with-differentially-private-partition-selection/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Large, user-based datasets are invaluable for advancing AI and machine learning models. They drive innovation that directly benefits users through improved services, more accurate predictions, and personalized experiences. Collaborating on and sharing such datasets can accelerate research, foster new applications, and contribute to the broader scientific community. However, leveraging these powerful datasets also comes with potential data privacy risks.&lt;/p&gt;&lt;p&gt;The process of identifying a specific, meaningful subset of unique items that can be shared safely from a vast collection based on how frequently or prominently they appear across many individual contributions (like finding all the common words used across a huge set of documents) is called “differentially private (DP) partition selection”. By applying differential privacy protections in partition selection, it’s possible to perform that selection in a way that prevents anyone from knowing whether any single individual's data contributed a specific item to the final list. This is done by adding controlled noise and only selecting items that are sufficiently common even after that noise is included, ensuring individual privacy. DP is the first step in many important data science and machine learning tasks, including extracting vocabulary (or &lt;i&gt;n&lt;/i&gt;-grams) from a large private corpus (a necessary step of many textual analysis and language modeling applications), analyzing data streams in a privacy preserving way, obtaining histograms over user data, and increasing efficiency in private model fine-tuning.&lt;/p&gt;&lt;p&gt;In the context of massive datasets like user queries, a &lt;i&gt;parallel&lt;/i&gt; algorithm is crucial. Instead of processing data one piece at a time (like a &lt;i&gt;sequential&lt;/i&gt; algorithm would), a parallel algorithm breaks the problem down into many smaller parts that can be computed simultaneously across multiple processors or machines. This practice isn't just for optimization; it's a fundamental necessity when dealing with the scale of modern data. Parallelization allows the processing of vast amounts of information all at once, enabling researchers to handle datasets with hundreds of billions of items. With this, it’s possible to achieve robust privacy guarantees without sacrificing the utility derived from large datasets.&lt;/p&gt;&lt;p&gt;In our recent publication, “Scalable Private Partition Selection via Adaptive Weighting”, which appeared at ICML2025, we introduce an efficient parallel algorithm that makes it possible to apply DP partition selection to various data releases. Our algorithm provides the best results across the board among parallel algorithms and scales to datasets with hundreds of billions of items, up to three orders of magnitude larger than those analyzed by prior sequential algorithms. To encourage collaboration and innovation by the research community, we are open-sourcing DP partition selection on GitHub.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Large, user-based datasets are invaluable for advancing AI and machine learning models. They drive innovation that directly benefits users through improved services, more accurate predictions, and personalized experiences. Collaborating on and sharing such datasets can accelerate research, foster new applications, and contribute to the broader scientific community. However, leveraging these powerful datasets also comes with potential data privacy risks.&lt;/p&gt;&lt;p&gt;The process of identifying a specific, meaningful subset of unique items that can be shared safely from a vast collection based on how frequently or prominently they appear across many individual contributions (like finding all the common words used across a huge set of documents) is called “differentially private (DP) partition selection”. By applying differential privacy protections in partition selection, it’s possible to perform that selection in a way that prevents anyone from knowing whether any single individual's data contributed a specific item to the final list. This is done by adding controlled noise and only selecting items that are sufficiently common even after that noise is included, ensuring individual privacy. DP is the first step in many important data science and machine learning tasks, including extracting vocabulary (or &lt;i&gt;n&lt;/i&gt;-grams) from a large private corpus (a necessary step of many textual analysis and language modeling applications), analyzing data streams in a privacy preserving way, obtaining histograms over user data, and increasing efficiency in private model fine-tuning.&lt;/p&gt;&lt;p&gt;In the context of massive datasets like user queries, a &lt;i&gt;parallel&lt;/i&gt; algorithm is crucial. Instead of processing data one piece at a time (like a &lt;i&gt;sequential&lt;/i&gt; algorithm would), a parallel algorithm breaks the problem down into many smaller parts that can be computed simultaneously across multiple processors or machines. This practice isn't just for optimization; it's a fundamental necessity when dealing with the scale of modern data. Parallelization allows the processing of vast amounts of information all at once, enabling researchers to handle datasets with hundreds of billions of items. With this, it’s possible to achieve robust privacy guarantees without sacrificing the utility derived from large datasets.&lt;/p&gt;&lt;p&gt;In our recent publication, “Scalable Private Partition Selection via Adaptive Weighting”, which appeared at ICML2025, we introduce an efficient parallel algorithm that makes it possible to apply DP partition selection to various data releases. Our algorithm provides the best results across the board among parallel algorithms and scales to datasets with hundreds of billions of items, up to three orders of magnitude larger than those analyzed by prior sequential algorithms. To encourage collaboration and innovation by the research community, we are open-sourcing DP partition selection on GitHub.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/securing-private-data-at-scale-with-differentially-private-partition-selection/</guid><pubDate>Wed, 20 Aug 2025 19:24:05 +0000</pubDate></item><item><title>TikTok parent company ByteDance releases new open source Seed-OSS-36B model with 512K token context (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/tiktok-parent-company-bytedance-releases-new-open-source-seed-oss-36b-model-with-512k-token-context/</link><description>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;The company’s&lt;strong&gt; Seed Team of AI researchers today released Seed-OSS-36B on AI code sharing website Hugging Face.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Seed-OSS-36B is new line of open source, large language models (LLM) designed for advanced reasoning, and developer-focused usability with a &lt;strong&gt;longer token context&lt;/strong&gt; — that is, how much information the models can accept as inputs and then output in a single exchange — &lt;strong&gt;than many competing LLMs from U.S. tech companies&lt;/strong&gt;, even leaders such as OpenAI and Anthropic.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Seed-OSS-36B-Base&lt;/strong&gt; with synthetic data&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Seed-OSS-36B-Base&lt;/strong&gt; &lt;strong&gt;without synthetic data&lt;/strong&gt;&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Seed-OSS-36B-Instruct&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;In releasing both synthetic and non-synthetic versions of the Seed-OSS-36B-Base model, the Seed Team sought to balance practical performance with research flexibility. &lt;/p&gt;



&lt;p&gt;The &lt;strong&gt;synthetic-data variant,&lt;/strong&gt; trained with additional instruction data, consistently &lt;strong&gt;delivers stronger scores on standard benchmarks&lt;/strong&gt; and is intended as a higher-performing general-purpose option. &lt;/p&gt;



&lt;p&gt;The&lt;strong&gt; non-synthetic model,&lt;/strong&gt; by contrast, omits these augmentations, creating &lt;strong&gt;a cleaner foundation that avoids potential bias or distortion&lt;/strong&gt; introduced by synthetic instruction data. &lt;/p&gt;



&lt;p&gt;By providing both, the team gives applied users access to improved results while ensuring researchers retain a neutral baseline for studying post-training methods.&lt;/p&gt;



&lt;p&gt;Meanwhile, the &lt;strong&gt;Seed-OSS-36B-Instruct model &lt;/strong&gt;differs in that it is &lt;strong&gt;post-trained with instruction data&lt;/strong&gt; to prioritize task execution and instruction following, rather than serving purely as a foundation model.&lt;/p&gt;



&lt;p&gt;All three models are released under the Apache-2.0 license, allowing free use, modification, and redistribution by researchers and developers working for enterprises.&lt;/p&gt;



&lt;p&gt;That means&lt;strong&gt; they can be used to power commercial applications, internal to a company or external/customer-facing, without paying ByteDance any licensing fees or for application programming interface (API) usage.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;This continues the summer 2025 trend of Chinese companies shipping powerful open source models with OpenAI attempting to catch up with its own open source gpt-oss duet released earlier this month.&lt;/p&gt;



&lt;p&gt;The Seed Team positions&lt;strong&gt; Seed-OSS for international applications&lt;/strong&gt;, emphasizing versatility across reasoning, agent-like task execution, and multilingual settings.&lt;/p&gt;



&lt;p&gt;The Seed Team, formed in 2023, has concentrated on building foundation models that can serve both research and applied use cases. &lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-design-and-core-features"&gt;Design and core features&lt;/h2&gt;



&lt;p&gt;The architecture behind Seed-OSS-36B combines familiar design choices such as causal language modeling, grouped query attention, SwiGLU activation, RMSNorm, and RoPE positional encoding.&lt;/p&gt;



&lt;p&gt;Each model carries 36 billion parameters across 64 layers and supports a vocabulary of 155,000 tokens.&lt;/p&gt;



&lt;p&gt;One of the defining features is its&lt;strong&gt; native long-context capability, with a maximum length of 512,000 tokens,&lt;/strong&gt; designed to process extended documents and reasoning chains without performance loss.&lt;/p&gt;



&lt;p&gt;That’s twice the length of OpenAI’s new GPT-5 model family and is &lt;strong&gt;roughly equivalent to about 1,600 pages of text, &lt;/strong&gt;the length of a Christian Bible. &lt;/p&gt;



&lt;p&gt;Another distinguishing element is the introduction of a &lt;strong&gt;thinking budget&lt;/strong&gt;, which lets developers specify how much reasoning the model should perform before delivering an answer. &lt;/p&gt;



&lt;p&gt;It’s something we’ve seen from other recent open source models as well, including Nvidia’s new Nemotron-Nano-9B-v2, also available on Hugging Face.&lt;/p&gt;



&lt;p&gt;In practice, this means teams can tune performance depending on the complexity of the task and the efficiency requirements of deployment. &lt;/p&gt;



&lt;p&gt;Budgets are recommended in multiples of 512 tokens, with 0 providing a direct response mode/&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-competitive-performance-on-third-party-benchmarks"&gt;Competitive performance on third-party benchmarks&lt;/h2&gt;



&lt;p&gt;Benchmarks published with the release position Seed-OSS-36B among the stronger large open-source models. The Instruct variant, in particular, posts state-of-the-art results in multiple areas.&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Math and reasoning&lt;/strong&gt;: Seed-OSS-36B-Instruct achieves &lt;strong&gt;91.7 percent on AIME24&lt;/strong&gt; and &lt;strong&gt;65 on BeyondAIME&lt;/strong&gt;, both representing open-source “state-of-the-art” (SOTA).&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Coding&lt;/strong&gt;: On LiveCodeBench v6, the Instruct model records &lt;strong&gt;67.4&lt;/strong&gt;, another SOTA score.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Long-context handling&lt;/strong&gt;: On RULER at 128K context length, it reaches &lt;strong&gt;94.6&lt;/strong&gt;, marking the highest open-source result reported.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Base model performance&lt;/strong&gt;: The synthetic-data Base variant delivers &lt;strong&gt;65.1 on MMLU-Pro&lt;/strong&gt; and &lt;strong&gt;81.7 on MATH&lt;/strong&gt;, both state-of-the-art results in their categories.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;The no-synthetic Base version, while slightly behind on many measures, proves competitive in its own right. &lt;/p&gt;



&lt;p&gt;It &lt;strong&gt;outperforms its synthetic counterpart on GPQA-D,&lt;/strong&gt; providing researchers with a cleaner, instruction-free baseline for experimentation.&lt;/p&gt;



&lt;p&gt;For enterprises comparing open options, these results &lt;strong&gt;suggest Seed-OSS offers strong potential across math-heavy, coding, and long-context workloads&lt;/strong&gt; while still providing flexibility for research use cases.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-access-and-deployment"&gt;Access and deployment&lt;/h2&gt;



&lt;p&gt;Beyond performance, the Seed Team highlights accessibility for developers and practitioners. The models &lt;strong&gt;can be deployed using Hugging Face Transformers&lt;/strong&gt;, with &lt;strong&gt;quantization support in both 4-bit and 8-bit formats&lt;/strong&gt; to reduce memory requirements. &lt;/p&gt;



&lt;p&gt;They also&lt;strong&gt; integrate with vLLM for scalable serving&lt;/strong&gt;, including configuration examples and API server instructions.&lt;/p&gt;



&lt;p&gt;To lower barriers further, the team includes scripts for inference, prompt customization, and tool integration. &lt;/p&gt;



&lt;p&gt;For&lt;strong&gt; technical leaders managing small teams or working under budget constraints&lt;/strong&gt;, these provisions are positioned to make experimentation with 36-billion-parameter models more approachable.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-licensing-and-considerations-for-enterprise-decision-makers"&gt;Licensing and considerations for enterprise decision-makers&lt;/h2&gt;



&lt;p&gt;With the models offered under Apache-2.0, organizations can adopt them without restrictive licensing terms, an important factor for teams balancing legal and operational concerns.&lt;/p&gt;



&lt;p&gt;For decision makers evaluating the open-source landscape, the release brings three takeaways:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;State-of-the-art benchmarks across math, coding, and long-context reasoning.&lt;/li&gt;



&lt;li&gt;A balance between higher-performing synthetic-trained models and clean research baselines.&lt;/li&gt;



&lt;li&gt;Accessibility features that lower operational overhead for lean engineering teams.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;By placing strong performance and flexible deployment under an open license, ByteDance’s Seed Team has added new options for enterprises, researchers, and developers alike. &lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;The company’s&lt;strong&gt; Seed Team of AI researchers today released Seed-OSS-36B on AI code sharing website Hugging Face.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Seed-OSS-36B is new line of open source, large language models (LLM) designed for advanced reasoning, and developer-focused usability with a &lt;strong&gt;longer token context&lt;/strong&gt; — that is, how much information the models can accept as inputs and then output in a single exchange — &lt;strong&gt;than many competing LLMs from U.S. tech companies&lt;/strong&gt;, even leaders such as OpenAI and Anthropic.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Seed-OSS-36B-Base&lt;/strong&gt; with synthetic data&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Seed-OSS-36B-Base&lt;/strong&gt; &lt;strong&gt;without synthetic data&lt;/strong&gt;&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Seed-OSS-36B-Instruct&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;In releasing both synthetic and non-synthetic versions of the Seed-OSS-36B-Base model, the Seed Team sought to balance practical performance with research flexibility. &lt;/p&gt;



&lt;p&gt;The &lt;strong&gt;synthetic-data variant,&lt;/strong&gt; trained with additional instruction data, consistently &lt;strong&gt;delivers stronger scores on standard benchmarks&lt;/strong&gt; and is intended as a higher-performing general-purpose option. &lt;/p&gt;



&lt;p&gt;The&lt;strong&gt; non-synthetic model,&lt;/strong&gt; by contrast, omits these augmentations, creating &lt;strong&gt;a cleaner foundation that avoids potential bias or distortion&lt;/strong&gt; introduced by synthetic instruction data. &lt;/p&gt;



&lt;p&gt;By providing both, the team gives applied users access to improved results while ensuring researchers retain a neutral baseline for studying post-training methods.&lt;/p&gt;



&lt;p&gt;Meanwhile, the &lt;strong&gt;Seed-OSS-36B-Instruct model &lt;/strong&gt;differs in that it is &lt;strong&gt;post-trained with instruction data&lt;/strong&gt; to prioritize task execution and instruction following, rather than serving purely as a foundation model.&lt;/p&gt;



&lt;p&gt;All three models are released under the Apache-2.0 license, allowing free use, modification, and redistribution by researchers and developers working for enterprises.&lt;/p&gt;



&lt;p&gt;That means&lt;strong&gt; they can be used to power commercial applications, internal to a company or external/customer-facing, without paying ByteDance any licensing fees or for application programming interface (API) usage.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;This continues the summer 2025 trend of Chinese companies shipping powerful open source models with OpenAI attempting to catch up with its own open source gpt-oss duet released earlier this month.&lt;/p&gt;



&lt;p&gt;The Seed Team positions&lt;strong&gt; Seed-OSS for international applications&lt;/strong&gt;, emphasizing versatility across reasoning, agent-like task execution, and multilingual settings.&lt;/p&gt;



&lt;p&gt;The Seed Team, formed in 2023, has concentrated on building foundation models that can serve both research and applied use cases. &lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-design-and-core-features"&gt;Design and core features&lt;/h2&gt;



&lt;p&gt;The architecture behind Seed-OSS-36B combines familiar design choices such as causal language modeling, grouped query attention, SwiGLU activation, RMSNorm, and RoPE positional encoding.&lt;/p&gt;



&lt;p&gt;Each model carries 36 billion parameters across 64 layers and supports a vocabulary of 155,000 tokens.&lt;/p&gt;



&lt;p&gt;One of the defining features is its&lt;strong&gt; native long-context capability, with a maximum length of 512,000 tokens,&lt;/strong&gt; designed to process extended documents and reasoning chains without performance loss.&lt;/p&gt;



&lt;p&gt;That’s twice the length of OpenAI’s new GPT-5 model family and is &lt;strong&gt;roughly equivalent to about 1,600 pages of text, &lt;/strong&gt;the length of a Christian Bible. &lt;/p&gt;



&lt;p&gt;Another distinguishing element is the introduction of a &lt;strong&gt;thinking budget&lt;/strong&gt;, which lets developers specify how much reasoning the model should perform before delivering an answer. &lt;/p&gt;



&lt;p&gt;It’s something we’ve seen from other recent open source models as well, including Nvidia’s new Nemotron-Nano-9B-v2, also available on Hugging Face.&lt;/p&gt;



&lt;p&gt;In practice, this means teams can tune performance depending on the complexity of the task and the efficiency requirements of deployment. &lt;/p&gt;



&lt;p&gt;Budgets are recommended in multiples of 512 tokens, with 0 providing a direct response mode/&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-competitive-performance-on-third-party-benchmarks"&gt;Competitive performance on third-party benchmarks&lt;/h2&gt;



&lt;p&gt;Benchmarks published with the release position Seed-OSS-36B among the stronger large open-source models. The Instruct variant, in particular, posts state-of-the-art results in multiple areas.&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Math and reasoning&lt;/strong&gt;: Seed-OSS-36B-Instruct achieves &lt;strong&gt;91.7 percent on AIME24&lt;/strong&gt; and &lt;strong&gt;65 on BeyondAIME&lt;/strong&gt;, both representing open-source “state-of-the-art” (SOTA).&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Coding&lt;/strong&gt;: On LiveCodeBench v6, the Instruct model records &lt;strong&gt;67.4&lt;/strong&gt;, another SOTA score.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Long-context handling&lt;/strong&gt;: On RULER at 128K context length, it reaches &lt;strong&gt;94.6&lt;/strong&gt;, marking the highest open-source result reported.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Base model performance&lt;/strong&gt;: The synthetic-data Base variant delivers &lt;strong&gt;65.1 on MMLU-Pro&lt;/strong&gt; and &lt;strong&gt;81.7 on MATH&lt;/strong&gt;, both state-of-the-art results in their categories.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;The no-synthetic Base version, while slightly behind on many measures, proves competitive in its own right. &lt;/p&gt;



&lt;p&gt;It &lt;strong&gt;outperforms its synthetic counterpart on GPQA-D,&lt;/strong&gt; providing researchers with a cleaner, instruction-free baseline for experimentation.&lt;/p&gt;



&lt;p&gt;For enterprises comparing open options, these results &lt;strong&gt;suggest Seed-OSS offers strong potential across math-heavy, coding, and long-context workloads&lt;/strong&gt; while still providing flexibility for research use cases.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-access-and-deployment"&gt;Access and deployment&lt;/h2&gt;



&lt;p&gt;Beyond performance, the Seed Team highlights accessibility for developers and practitioners. The models &lt;strong&gt;can be deployed using Hugging Face Transformers&lt;/strong&gt;, with &lt;strong&gt;quantization support in both 4-bit and 8-bit formats&lt;/strong&gt; to reduce memory requirements. &lt;/p&gt;



&lt;p&gt;They also&lt;strong&gt; integrate with vLLM for scalable serving&lt;/strong&gt;, including configuration examples and API server instructions.&lt;/p&gt;



&lt;p&gt;To lower barriers further, the team includes scripts for inference, prompt customization, and tool integration. &lt;/p&gt;



&lt;p&gt;For&lt;strong&gt; technical leaders managing small teams or working under budget constraints&lt;/strong&gt;, these provisions are positioned to make experimentation with 36-billion-parameter models more approachable.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-licensing-and-considerations-for-enterprise-decision-makers"&gt;Licensing and considerations for enterprise decision-makers&lt;/h2&gt;



&lt;p&gt;With the models offered under Apache-2.0, organizations can adopt them without restrictive licensing terms, an important factor for teams balancing legal and operational concerns.&lt;/p&gt;



&lt;p&gt;For decision makers evaluating the open-source landscape, the release brings three takeaways:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;State-of-the-art benchmarks across math, coding, and long-context reasoning.&lt;/li&gt;



&lt;li&gt;A balance between higher-performing synthetic-trained models and clean research baselines.&lt;/li&gt;



&lt;li&gt;Accessibility features that lower operational overhead for lean engineering teams.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;By placing strong performance and flexible deployment under an open license, ByteDance’s Seed Team has added new options for enterprises, researchers, and developers alike. &lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/tiktok-parent-company-bytedance-releases-new-open-source-seed-oss-36b-model-with-512k-token-context/</guid><pubDate>Wed, 20 Aug 2025 22:04:24 +0000</pubDate></item><item><title>Enterprise Claude gets admin, compliance tools—just not unlimited usage (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/enterprise-claude-gets-admin-compliance-tools-just-not-unlimited-usage/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;A few weeks after announcing rate limits for Claude and the popular Claude Code, Anthropic will &lt;span&gt;offer Claude Enterprise and Teams customers&amp;nbsp;upgrades to access&amp;nbsp;more usage and Claude Code in a single&lt;/span&gt; subscription.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The upgrades will also include more admin controls and a new Compliance API that will give enterprises “access to usage data and customer content for better observability, auditing and governance.”&lt;/p&gt;



&lt;p&gt;Anthropic said in a post that with a single subscription to Claude and Claude Code, users “can move seamlessly between ideation and implementation, while admins get the visibility and controls they need to scale Claude across their organization.”&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Claude Code is now available on Team and Enterprise plans.&lt;/p&gt;&lt;p&gt;Flexible pricing lets you mix standard and premium Claude Code seats across your organization and scale with usage. pic.twitter.com/co3UT5PcP3&lt;/p&gt;— Claude (@claudeai) August 20, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;The premium seats, separate from the standard seats that most everyone in the organization receives, can be used with both Claude and Claude Code. Admins can assign individuals premium seats based on their role in the organization.&amp;nbsp;&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;h2 class="wp-block-heading" id="h-throttled-rates"&gt;Throttled rates&lt;/h2&gt;



&lt;p&gt;Anthropic’s announcement of additional usage for Enterprise and Teams users sparked criticism, with critics demanding that the company remove rate limits for Claude.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The company said rate limits, which will begin on August 28, would free up space for more projects and deter people who “abuse” the system by overusing Claude Code.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Yea but what about getting rid of throttling?…&lt;/p&gt;— Cyb3rEchos (@Cyb3rEchos) August 20, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Big news! The premium seats sound promising—especially with more Claude Code access. Does the new Claude Code upgrade also affect API rate limits or make it easier to set up custom integrations for teams?&lt;/p&gt;— Ben✨ (@_BenResearch) August 20, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Extra usage for all users pls.. Feels like we've been at 45/5hr for a lifetime.&lt;/p&gt;— Artificially Inclined™ (@Art_If_Ficial) August 20, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;In an email, Anthropic told VentureBeat that the existing five-hour usage limits still stand for premium seats on Enterprise and Team, the same as for users of Max 5x.&lt;/p&gt;



&lt;p&gt;“Now with the new Claude Code bundle, both standard (Claude.ai access) and premium (Claude.ai + Claude Code access) seats have the option for extra usage and admins have robust seat management controls so that power users can continue their workflows with Claude however they need,” Anthropic said through a spokesperson.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-admin-and-compliance-control"&gt;Admin and compliance control&lt;/h2&gt;



&lt;p&gt;The draw for the upgrades, Anthropic said, revolves around the additional controls and enterprise-ready features.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“While individual Max plans work for personal use, the Enterprise bundle provides the security, compliance, analytics, and management capabilities that organizations need at scale,” the company said.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Anthropic noted enterprise customers often have to choose between speed and governance, so bringing in admin controls and compliance features “solves that tradeoff by letting teams move seamlessly between planning in Claude and building in the terminal using Claude Code.” It also consolidates expenses using Claude Code from individual accounts to the broader enterprise.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;p&gt;Enterprise IT admins will be able to manage seats, including buying and allocating the seats, set spending controls and view Claude Code analytics in Claude, including knowing which lines of code were accepted and usage patterns. They can also set tool permissioning, policy settings and MCP configurations.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Since the number of seats will be based on the number of premium or standard seats the enterprises need, Anthropic said it will offer flexible pricing.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The Compliance API enables companies, particularly those in regulated sectors, to access usage data and customer content on Claude for monitoring and policy enforcement. The API allows organizations to bring Claude data into their compliance and orchestration dashboards.&lt;/p&gt;




&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;A few weeks after announcing rate limits for Claude and the popular Claude Code, Anthropic will &lt;span&gt;offer Claude Enterprise and Teams customers&amp;nbsp;upgrades to access&amp;nbsp;more usage and Claude Code in a single&lt;/span&gt; subscription.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The upgrades will also include more admin controls and a new Compliance API that will give enterprises “access to usage data and customer content for better observability, auditing and governance.”&lt;/p&gt;



&lt;p&gt;Anthropic said in a post that with a single subscription to Claude and Claude Code, users “can move seamlessly between ideation and implementation, while admins get the visibility and controls they need to scale Claude across their organization.”&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Claude Code is now available on Team and Enterprise plans.&lt;/p&gt;&lt;p&gt;Flexible pricing lets you mix standard and premium Claude Code seats across your organization and scale with usage. pic.twitter.com/co3UT5PcP3&lt;/p&gt;— Claude (@claudeai) August 20, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;The premium seats, separate from the standard seats that most everyone in the organization receives, can be used with both Claude and Claude Code. Admins can assign individuals premium seats based on their role in the organization.&amp;nbsp;&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;h2 class="wp-block-heading" id="h-throttled-rates"&gt;Throttled rates&lt;/h2&gt;



&lt;p&gt;Anthropic’s announcement of additional usage for Enterprise and Teams users sparked criticism, with critics demanding that the company remove rate limits for Claude.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The company said rate limits, which will begin on August 28, would free up space for more projects and deter people who “abuse” the system by overusing Claude Code.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Yea but what about getting rid of throttling?…&lt;/p&gt;— Cyb3rEchos (@Cyb3rEchos) August 20, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Big news! The premium seats sound promising—especially with more Claude Code access. Does the new Claude Code upgrade also affect API rate limits or make it easier to set up custom integrations for teams?&lt;/p&gt;— Ben✨ (@_BenResearch) August 20, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Extra usage for all users pls.. Feels like we've been at 45/5hr for a lifetime.&lt;/p&gt;— Artificially Inclined™ (@Art_If_Ficial) August 20, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;In an email, Anthropic told VentureBeat that the existing five-hour usage limits still stand for premium seats on Enterprise and Team, the same as for users of Max 5x.&lt;/p&gt;



&lt;p&gt;“Now with the new Claude Code bundle, both standard (Claude.ai access) and premium (Claude.ai + Claude Code access) seats have the option for extra usage and admins have robust seat management controls so that power users can continue their workflows with Claude however they need,” Anthropic said through a spokesperson.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-admin-and-compliance-control"&gt;Admin and compliance control&lt;/h2&gt;



&lt;p&gt;The draw for the upgrades, Anthropic said, revolves around the additional controls and enterprise-ready features.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“While individual Max plans work for personal use, the Enterprise bundle provides the security, compliance, analytics, and management capabilities that organizations need at scale,” the company said.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Anthropic noted enterprise customers often have to choose between speed and governance, so bringing in admin controls and compliance features “solves that tradeoff by letting teams move seamlessly between planning in Claude and building in the terminal using Claude Code.” It also consolidates expenses using Claude Code from individual accounts to the broader enterprise.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;p&gt;Enterprise IT admins will be able to manage seats, including buying and allocating the seats, set spending controls and view Claude Code analytics in Claude, including knowing which lines of code were accepted and usage patterns. They can also set tool permissioning, policy settings and MCP configurations.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Since the number of seats will be based on the number of premium or standard seats the enterprises need, Anthropic said it will offer flexible pricing.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The Compliance API enables companies, particularly those in regulated sectors, to access usage data and customer content on Claude for monitoring and policy enforcement. The API allows organizations to bring Claude data into their compliance and orchestration dashboards.&lt;/p&gt;




&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/enterprise-claude-gets-admin-compliance-tools-just-not-unlimited-usage/</guid><pubDate>Wed, 20 Aug 2025 23:28:55 +0000</pubDate></item></channel></rss>