<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 18 Oct 2025 06:28:45 +0000</lastBuildDate><item><title>New software designs eco-friendly clothing that can reassemble into new items (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/refashion-software-designs-eco-friendly-clothing-that-can-reassemble-new-items-1017</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202510/MIT-Refashion.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr" id="docs-internal-guid-1cf4f40f-7fff-2939-9710-707696adbaca"&gt;It’s hard to keep up with the ever-changing trends of the fashion world. What’s “in” one minute is often out of style the next season, potentially causing you to re-evaluate your wardrobe.&lt;/p&gt;&lt;p dir="ltr"&gt;Staying current with the latest fashion styles can be wasteful and expensive, though. Roughly&amp;nbsp;92 million tons of textile waste are produced annually, including the clothes we discard when they go out of style or no longer fit. But what if we could simply reassemble our clothes into whatever outfits we wanted, adapting to trends and the ways our bodies change?&lt;/p&gt;&lt;p dir="ltr"&gt;A team of researchers at MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) and Adobe are attempting to bring eco-friendly, versatile garments to life. Their new “Refashion” software system breaks down fashion design into modules — essentially, smaller building blocks — by allowing users to draw, plan, and visualize each element of a clothing item. The tool turns fashion ideas into a blueprint that outlines how to assemble each component into reconfigurable clothing, such as a pair of pants that can be transformed into a dress.&lt;/p&gt;&lt;p dir="ltr"&gt;With Refashion, users simply draw shapes and place them together to develop an outline for adaptable fashion pieces. It’s a visual diagram that shows how to cut garments, providing a straightforward way to design things like a shirt with an attachable hood for rainy days. One could also create a skirt that can then be reconfigured into a dress for a formal dinner, or maternity wear that fits during different stages of pregnancy.&lt;/p&gt;&lt;p&gt;“We wanted to create garments that consider reuse from the start,” says Rebecca Lin, MIT Department of Electrical Engineering and Computer Science (EECS) PhD student, CSAIL and Media Lab researcher, and lead author on a&amp;nbsp;paper presenting the project. “Most clothes you buy today are static, and are discarded when you no longer want them. Refashion instead makes the most of our garments by helping us design items that can be easily resized, repaired, or restyled into different outfits.”&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;Modules à la mode&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;The researchers conducted a preliminary user study where both designers and novices explored Refashion and were able to create garment prototypes. Participants assembled pieces such as an asymmetric top that could be extended into a jumpsuit, or remade into a formal dress, often within 30 minutes. These results suggest that Refashion has the potential to make prototyping garments more approachable and efficient. But what features might contribute to this ease of use?&lt;/p&gt;&lt;p dir="ltr"&gt;Its interface first presents a simple grid in its “Pattern Editor” mode, where users can connect dots to outline the boundaries of a clothing item. It’s essentially drawing rectangular panels and specifying how different modules will connect to each other.&lt;/p&gt;&lt;p dir="ltr"&gt;Users can customize the shape of each component, create a straight design for garments (which might be useful for less form-fitting items, like chinos) or perhaps tinkering with one of Refashion’s templates. A user can edit pre-designed blueprints for things like a T-shirt, fitted blouse, or trousers.&lt;/p&gt;&lt;p&gt;Another, more creative route is to change the design of individual modules. One can choose the “pleat” feature to fold a garment over itself, similar to an accordion, for starters. It’s a useful way to design something like a maxi dress. The “gather” option adds an artsy flourish, where a garment is crumpled together to create puffy skirts or sleeves. A user might even go with the “dart” module, which removes a triangular piece from the fabric. It allows for shaping a garment at the waist (perhaps for a pencil skirt) or tailor to the upper body (fitted shirts, for instance).&lt;/p&gt;&lt;p dir="ltr"&gt;While it might seem that each of these components needs to be sewn together, Refashion enables users to connect garments through more flexible, efficient means. Edges can be seamed together via double-sided connectors such as metal snaps (like the buttons used to close a denim jacket) or Velcro dots. A user could also fasten them in pins called brads, which have a pointed side that they stick through a hole and split into two “legs” to attach to another surface; it’s a handy way to secure, say, a picture on a poster board. Both connective methods make it easy to reconfigure modules, should they be damaged or a “fit check” calls for a new look.&lt;/p&gt;&lt;p&gt;As a user designs their clothing piece, the system automatically creates a simplified diagram of how it can be assembled. The pattern is divided into numbered blocks, which is dragged onto different parts of a 2D mannequin to specify the position of each component. The user can then simulate how their sustainable clothing will look on 3D models of a range of body types (one can also upload a model).&lt;/p&gt;&lt;p dir="ltr"&gt;Finally, a digital blueprint for sustainable clothing can extend, shorten, or combine with other pieces. Thanks to Refashion, a new piece could be emblematic of a potential shift in fashion: Instead of buying new clothes every time we want a new outfit, we can simply reconfigure existing ones. Yesterday’s scarf could be today’s hat, and today’s T-shirt could be tomorrow’s jacket.&lt;/p&gt;&lt;p dir="ltr"&gt;“Rebecca’s work is at an exciting intersection between computation and art, craft, and design,” says MIT EECS professor and CSAIL principal investigator Erik Demaine, who advises Lin. “I’m excited to see how Refashion can make custom fashion design accessible to the wearer, while also making clothes more reusable and sustainable.”&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;Constant change&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;While Refashion presents a greener vision for the future of fashion, the researchers note that they’re actively improving the system. They intend to revise the interface to support more durable items, stepping beyond standard prototyping fabrics. Refashion may soon support other modules, like curved panels, as well. The CSAIL-Adobe team may also evaluate whether their system can use as few materials as possible to minimize waste, and whether it can help “remix” old store-bought outfits.&lt;/p&gt;&lt;p dir="ltr"&gt;Lin also plans to develop new computational tools that help designers create unique, personalized outfits using colors and textures. She’s exploring how to design clothing by patchwork — essentially, cutting out small pieces from materials like decorative fabrics, recycled denim, and crochet blocks and assembling them into a larger item.&lt;/p&gt;&lt;p&gt;“This is a great example of how computer-aided design can also be key in supporting more sustainable practices in the fashion industry,” says Adrien Bousseau, a senior researcher at Inria Centre at Université Côte d'Azur who wasn’t involved in the paper. “By promoting garment alteration from the ground up, they developed a novel design interface and accompanying optimization algorithm that helps designers create garments that can undergo a longer lifetime through reconfiguration. While sustainability often imposes additional constraints on industrial production, I am confident that research like the one by Lin and her colleagues will empower designers in innovating despite these constraints.”&lt;/p&gt;&lt;p&gt;Lin wrote the paper with Adobe Research scientists Michal Lukáč and Mackenzie Leake, who is the paper’s senior author and a former CSAIL postdoc. Their work was supported, in part, by the MIT Morningside Academy for Design, an MIT MAKE Design-2-Making Mini-Grant, and the Natural Sciences and Engineering Research Council of Canada. The researchers presented their work recently at the ACM Symposium on User Interface Software and Technology.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202510/MIT-Refashion.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr" id="docs-internal-guid-1cf4f40f-7fff-2939-9710-707696adbaca"&gt;It’s hard to keep up with the ever-changing trends of the fashion world. What’s “in” one minute is often out of style the next season, potentially causing you to re-evaluate your wardrobe.&lt;/p&gt;&lt;p dir="ltr"&gt;Staying current with the latest fashion styles can be wasteful and expensive, though. Roughly&amp;nbsp;92 million tons of textile waste are produced annually, including the clothes we discard when they go out of style or no longer fit. But what if we could simply reassemble our clothes into whatever outfits we wanted, adapting to trends and the ways our bodies change?&lt;/p&gt;&lt;p dir="ltr"&gt;A team of researchers at MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) and Adobe are attempting to bring eco-friendly, versatile garments to life. Their new “Refashion” software system breaks down fashion design into modules — essentially, smaller building blocks — by allowing users to draw, plan, and visualize each element of a clothing item. The tool turns fashion ideas into a blueprint that outlines how to assemble each component into reconfigurable clothing, such as a pair of pants that can be transformed into a dress.&lt;/p&gt;&lt;p dir="ltr"&gt;With Refashion, users simply draw shapes and place them together to develop an outline for adaptable fashion pieces. It’s a visual diagram that shows how to cut garments, providing a straightforward way to design things like a shirt with an attachable hood for rainy days. One could also create a skirt that can then be reconfigured into a dress for a formal dinner, or maternity wear that fits during different stages of pregnancy.&lt;/p&gt;&lt;p&gt;“We wanted to create garments that consider reuse from the start,” says Rebecca Lin, MIT Department of Electrical Engineering and Computer Science (EECS) PhD student, CSAIL and Media Lab researcher, and lead author on a&amp;nbsp;paper presenting the project. “Most clothes you buy today are static, and are discarded when you no longer want them. Refashion instead makes the most of our garments by helping us design items that can be easily resized, repaired, or restyled into different outfits.”&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;Modules à la mode&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;The researchers conducted a preliminary user study where both designers and novices explored Refashion and were able to create garment prototypes. Participants assembled pieces such as an asymmetric top that could be extended into a jumpsuit, or remade into a formal dress, often within 30 minutes. These results suggest that Refashion has the potential to make prototyping garments more approachable and efficient. But what features might contribute to this ease of use?&lt;/p&gt;&lt;p dir="ltr"&gt;Its interface first presents a simple grid in its “Pattern Editor” mode, where users can connect dots to outline the boundaries of a clothing item. It’s essentially drawing rectangular panels and specifying how different modules will connect to each other.&lt;/p&gt;&lt;p dir="ltr"&gt;Users can customize the shape of each component, create a straight design for garments (which might be useful for less form-fitting items, like chinos) or perhaps tinkering with one of Refashion’s templates. A user can edit pre-designed blueprints for things like a T-shirt, fitted blouse, or trousers.&lt;/p&gt;&lt;p&gt;Another, more creative route is to change the design of individual modules. One can choose the “pleat” feature to fold a garment over itself, similar to an accordion, for starters. It’s a useful way to design something like a maxi dress. The “gather” option adds an artsy flourish, where a garment is crumpled together to create puffy skirts or sleeves. A user might even go with the “dart” module, which removes a triangular piece from the fabric. It allows for shaping a garment at the waist (perhaps for a pencil skirt) or tailor to the upper body (fitted shirts, for instance).&lt;/p&gt;&lt;p dir="ltr"&gt;While it might seem that each of these components needs to be sewn together, Refashion enables users to connect garments through more flexible, efficient means. Edges can be seamed together via double-sided connectors such as metal snaps (like the buttons used to close a denim jacket) or Velcro dots. A user could also fasten them in pins called brads, which have a pointed side that they stick through a hole and split into two “legs” to attach to another surface; it’s a handy way to secure, say, a picture on a poster board. Both connective methods make it easy to reconfigure modules, should they be damaged or a “fit check” calls for a new look.&lt;/p&gt;&lt;p&gt;As a user designs their clothing piece, the system automatically creates a simplified diagram of how it can be assembled. The pattern is divided into numbered blocks, which is dragged onto different parts of a 2D mannequin to specify the position of each component. The user can then simulate how their sustainable clothing will look on 3D models of a range of body types (one can also upload a model).&lt;/p&gt;&lt;p dir="ltr"&gt;Finally, a digital blueprint for sustainable clothing can extend, shorten, or combine with other pieces. Thanks to Refashion, a new piece could be emblematic of a potential shift in fashion: Instead of buying new clothes every time we want a new outfit, we can simply reconfigure existing ones. Yesterday’s scarf could be today’s hat, and today’s T-shirt could be tomorrow’s jacket.&lt;/p&gt;&lt;p dir="ltr"&gt;“Rebecca’s work is at an exciting intersection between computation and art, craft, and design,” says MIT EECS professor and CSAIL principal investigator Erik Demaine, who advises Lin. “I’m excited to see how Refashion can make custom fashion design accessible to the wearer, while also making clothes more reusable and sustainable.”&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;Constant change&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;While Refashion presents a greener vision for the future of fashion, the researchers note that they’re actively improving the system. They intend to revise the interface to support more durable items, stepping beyond standard prototyping fabrics. Refashion may soon support other modules, like curved panels, as well. The CSAIL-Adobe team may also evaluate whether their system can use as few materials as possible to minimize waste, and whether it can help “remix” old store-bought outfits.&lt;/p&gt;&lt;p dir="ltr"&gt;Lin also plans to develop new computational tools that help designers create unique, personalized outfits using colors and textures. She’s exploring how to design clothing by patchwork — essentially, cutting out small pieces from materials like decorative fabrics, recycled denim, and crochet blocks and assembling them into a larger item.&lt;/p&gt;&lt;p&gt;“This is a great example of how computer-aided design can also be key in supporting more sustainable practices in the fashion industry,” says Adrien Bousseau, a senior researcher at Inria Centre at Université Côte d'Azur who wasn’t involved in the paper. “By promoting garment alteration from the ground up, they developed a novel design interface and accompanying optimization algorithm that helps designers create garments that can undergo a longer lifetime through reconfiguration. While sustainability often imposes additional constraints on industrial production, I am confident that research like the one by Lin and her colleagues will empower designers in innovating despite these constraints.”&lt;/p&gt;&lt;p&gt;Lin wrote the paper with Adobe Research scientists Michal Lukáč and Mackenzie Leake, who is the paper’s senior author and a former CSAIL postdoc. Their work was supported, in part, by the MIT Morningside Academy for Design, an MIT MAKE Design-2-Making Mini-Grant, and the Natural Sciences and Engineering Research Council of Canada. The researchers presented their work recently at the ACM Symposium on User Interface Software and Technology.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/refashion-software-designs-eco-friendly-clothing-that-can-reassemble-new-items-1017</guid><pubDate>Fri, 17 Oct 2025 18:30:00 +0000</pubDate></item><item><title>Should AI do everything? OpenAI thinks so (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/video/should-ai-do-everything-openai-thinks-so/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/GettyImages-2214107176.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;figure class="wp-block-embed alignwide is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Silicon Valley’s rule? It’s not cool to be cautious. As OpenAI removes guardrails and VCs criticize companies like Anthropic for supporting AI safety regulations, it’s becoming clearer who the industry thinks should shape AI development.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;On this episode of Equity, Kirsten Korosec, Anthony Ha, and Max Zeff discuss how the line between innovation and responsibility is getting blurrier, plus what happens when pranks go from digital to physical.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Watch to the full episode for more about:&amp;nbsp;&lt;/p&gt;















&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Why advocating for AI safety has become “uncool” in Silicon Valley from Anthropic facing backlash to California’s SB 243 regulation of AI companion chatbots and the success of companies like Character.AI&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Which startups are using an SEC workaround to file for IPOs during the shutdown&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;p class="wp-block-paragraph"&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Subscribe to us on Apple Podcasts, Overcast, Spotify and all the casts. You also can follow Equity on X and Threads, at @EquityPod.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/GettyImages-2214107176.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;figure class="wp-block-embed alignwide is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Silicon Valley’s rule? It’s not cool to be cautious. As OpenAI removes guardrails and VCs criticize companies like Anthropic for supporting AI safety regulations, it’s becoming clearer who the industry thinks should shape AI development.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;On this episode of Equity, Kirsten Korosec, Anthony Ha, and Max Zeff discuss how the line between innovation and responsibility is getting blurrier, plus what happens when pranks go from digital to physical.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Watch to the full episode for more about:&amp;nbsp;&lt;/p&gt;















&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Why advocating for AI safety has become “uncool” in Silicon Valley from Anthropic facing backlash to California’s SB 243 regulation of AI companion chatbots and the success of companies like Character.AI&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Which startups are using an SEC workaround to file for IPOs during the shutdown&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;p class="wp-block-paragraph"&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Subscribe to us on Apple Podcasts, Overcast, Spotify and all the casts. You also can follow Equity on X and Threads, at @EquityPod.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/video/should-ai-do-everything-openai-thinks-so/</guid><pubDate>Fri, 17 Oct 2025 19:00:00 +0000</pubDate></item><item><title>Your AI tools run on fracked gas and bulldozed Texas land (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/17/your-ai-tools-run-on-fracked-gas-and-bulldozed-texas-land/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-5.21.01PM.png?resize=1200,742" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The AI era is giving fracking a second act, a surprising twist for an industry that, even during its early 2010s boom years, was blamed by climate advocates for poisoned water tables, man-made earthquakes, and the stubborn persistence of fossil fuels.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI companies are building massive data centers near major gas-production sites, often generating their own power by tapping directly into fossil fuels. It’s a trend that’s been overshadowed by headlines about the intersection of AI and healthcare (and solving climate change), but it’s one that could reshape — and raise difficult questions for — the communities that host these facilities.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Take the latest example. This week, the Wall Street Journal reported that AI coding assistant startup Poolside is constructing a data center complex on more than 500 acres in West Texas — about 300 miles west of Dallas — a footprint two-thirds the size of Central Park. The facility will generate its own power by tapping natural gas from the Permian Basin, the nation’s most productive oil and gas field, where hydraulic fracturing isn’t just common but really the only game in town.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The project, dubbed Horizon, will produce two gigawatts of computing power. That’s equivalent to the Hoover Dam’s entire electric capacity, except instead of harnessing the Colorado River, it’s burning fracked gas. Poolside is developing the facility with CoreWeave, a cloud computing company that rents out access to Nvidia AI chips and that’s supplying access to more than 40,000 of them. The Journal calls it an “energy Wild West,” which seems apt.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Yet Poolside is far from alone. Nearly all the major AI players are pursuing similar strategies. Last month, OpenAI CEO Sam Altman toured his company’s flagship Stargate data center in Abilene, Texas — around 200 miles from the Permian Basin — where he was candid, saying, “We’re burning gas to run this data center.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The complex requires about 900 megawatts of electricity across eight buildings and includes a new gas-fired power plant using turbines similar to those that power warships, according to the Associated Press. The companies say the plant provides only backup power, with most electricity coming from the local grid. That grid, for the record, draws from a mix of natural gas and the sprawling wind and solar farms in West Texas.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the people living near these projects aren’t exactly comforted. Arlene Mendler lives across the street from Stargate. She told the AP she wishes someone had asked her opinion before bulldozers eliminated a huge tract of mesquite shrubland to make room for what’s being built atop it.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“It has completely changed the way we were living,” Mendler told the AP. She moved to the area 33 years ago seeking “peace, quiet, tranquility.” Now construction is the soundtrack in the background, and bright lights on the scene have spoiled her nighttime views.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Then there’s the water. In drought-prone West Texas, locals are particularly nervous about how new data centers will impact the water supply. The city’s reservoirs were at roughly half capacity during Altman’s visit, with residents on a twice-weekly outdoor watering schedule. Oracle claims each of the eight buildings will need just 12,000 gallons per year after an initial million-gallon fill for closed-loop cooling systems. But Shaolei Ren, a University of California, Riverside, professor who studies AI’s environmental footprint, told the AP that’s misleading. These systems require more electricity, which means more indirect water consumption at the power plants generating that electricity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta is pursuing a similar strategy. In Richland Parish, the poorest region of Louisiana, the company plans to build a $10 billion data center the size of 1,700 football fields that will require two gigawatts of power for computation alone. Utility company Entergy will spend $3.2 billion to build three large natural-gas power plants with 2.3 gigawatts of capacity to feed the facility by burning gas extracted through fracking in the nearby Haynesville Shale. Louisiana residents, like those in Abilene, aren’t thrilled to be encircled by bulldozers around the clock.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;(Meta is also building in Texas, though elsewhere in the state. This week the company announced a $1.5 billion data center in El Paso, near the New Mexico border, with one gigawatt of capacity expected online in 2028. El Paso isn’t near the Permian Basin, and Meta says the facility will be matched with 100% clean and renewable energy. One point for Meta.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even Elon Musk’s xAI, whose Memphis facility has generated considerable controversy this year, has fracking connections. Memphis Light, Gas and Water — which currently sells power to xAI but will eventually own the substations xAI is building — purchases natural gas on the spot market and pipes it to Memphis via two companies: Texas Gas Transmission Corp. and Trunkline Gas Company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Texas Gas Transmission is a bidirectional pipeline carrying natural gas from Gulf Coast supply areas and several major hydraulically fractured shale formations through Arkansas, Mississippi, Kentucky, and Tennessee. Trunkline Gas Company, the other Memphis supplier, also carries natural gas from fracked sources.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If you’re wondering why AI companies are pursuing this path, they’ll tell you it’s not just about electricity; it’s also about beating China.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That was the argument Chris Lehane made last week. Lehane, a veteran political operative who joined OpenAI as vice president of global affairs in 2024, laid out the case during an onstage interview with TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We believe that in the not-too-distant future, at least in the U.S., and really around the world, we are going to need to be generating in the neighborhood of a gigawatt of energy a week,” Lehane said. He pointed to China’s massive energy buildout: 450 gigawatts and 33 nuclear facilities constructed in the last year alone.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When TechCrunch asked about Stargate’s decision to build in economically challenged areas like Abilene, or Lordstown, Ohio, where more gas-powered plants are planned, Lehane returned to geopolitics. “If we [as a country] do this right, you have an opportunity to re-industrialize countries, bring manufacturing back and also transition our energy systems so that we do the modernization that needs to take place.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Trump administration is certainly on board. The July 2025 executive order fast-tracks gas-powered AI data centers by streamlining environmental permits, offering financial incentives, and opening federal lands for projects using natural gas, coal, or nuclear power — while explicitly excluding renewables from support.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For now, most AI users remain largely unaware of the carbon footprint behind their dazzling new toys and work tools. They’re more focused on capabilities like Sora 2 — OpenAI’s hyperrealistic video-generation product that requires exponentially more energy than a simple chatbot — than on where the electricity comes from.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The companies are counting on this. They’ve positioned natural gas as the pragmatic, inevitable answer to AI’s exploding power demands. But the speed and scale of this fossil fuel buildout deserves more attention than it’s getting. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If this is a bubble, it won’t be pretty. The AI sector has become a circular firing squad of dependencies: OpenAI needs Microsoft needs Nvidia needs Broadcom needs Oracle needs data center operators who need OpenAI. They’re all buying from and selling to each other in a self-reinforcing loop. The Financial Times noted this week if the foundation cracks, there’ll be a lot of expensive infrastructure left standing around, both the digital and the gas-burning kind. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s ability alone to meet its obligations is “increasingly a concern for the wider economy,” the outlet wrote.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One key question that’s been largely absent from the conversation is whether all this new capacity is even necessary. A Duke University study found that utilities typically use only 53% of their available capacity throughout the year. That suggests significant room to accommodate new demand without constructing new power plants, as MIT Technology Review reported earlier this year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Duke researchers estimate that if data centers reduced electricity consumption by roughly half for just a few hours during annual peak demand periods, utilities could handle an additional 76 gigawatts of new load. That would effectively absorb the 65 gigawatts data centers are projected to need by 2029.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That kind of flexibility would allow companies to launch AI data centers faster. More importantly, it could provide a reprieve from the rush to build natural gas infrastructure, giving utilities time to develop cleaner alternatives.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But again, that would mean losing ground to an autocratic regime, per Lehane and many others in the industry, so instead, the natural gas building spree appears likely to saddle regions with more fossil-fuel plants and leave residents with soaring electricity bills to finance today’s investments, including long after the tech companies’ contracts expire.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Meta, for instance, has guaranteed it will cover Entergy’s costs for the new Louisiana generation for 15 years. Poolside’s lease with CoreWeave runs for 15 years. What happens to customers when those contracts end remains an open question.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Things may eventually change. A lot of private money is being funneled into small modular reactors and solar installations with the expectation that these cleaner energy alternatives will become more central energy sources for these data centers. Fusion startups like Helion and Commonwealth Fusion Systems have similarly raised substantial funding from those on the front lines of AI, including Nvidia and Altman.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This optimism isn’t confined to private investment circles. The excitement has spilled over into public markets, where several “non-revenue-generating” energy companies that have managed to go public have truly anticipatory market caps, based on the expectation that they will one day fuel these data centers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the meantime — which could still be decades — the most pressing concern is that the people who’ll be left holding the bag, financially and environmentally, never asked for any of this in the first place.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/Screenshot-2025-10-16-at-5.21.01PM.png?resize=1200,742" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The AI era is giving fracking a second act, a surprising twist for an industry that, even during its early 2010s boom years, was blamed by climate advocates for poisoned water tables, man-made earthquakes, and the stubborn persistence of fossil fuels.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI companies are building massive data centers near major gas-production sites, often generating their own power by tapping directly into fossil fuels. It’s a trend that’s been overshadowed by headlines about the intersection of AI and healthcare (and solving climate change), but it’s one that could reshape — and raise difficult questions for — the communities that host these facilities.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Take the latest example. This week, the Wall Street Journal reported that AI coding assistant startup Poolside is constructing a data center complex on more than 500 acres in West Texas — about 300 miles west of Dallas — a footprint two-thirds the size of Central Park. The facility will generate its own power by tapping natural gas from the Permian Basin, the nation’s most productive oil and gas field, where hydraulic fracturing isn’t just common but really the only game in town.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The project, dubbed Horizon, will produce two gigawatts of computing power. That’s equivalent to the Hoover Dam’s entire electric capacity, except instead of harnessing the Colorado River, it’s burning fracked gas. Poolside is developing the facility with CoreWeave, a cloud computing company that rents out access to Nvidia AI chips and that’s supplying access to more than 40,000 of them. The Journal calls it an “energy Wild West,” which seems apt.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Yet Poolside is far from alone. Nearly all the major AI players are pursuing similar strategies. Last month, OpenAI CEO Sam Altman toured his company’s flagship Stargate data center in Abilene, Texas — around 200 miles from the Permian Basin — where he was candid, saying, “We’re burning gas to run this data center.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The complex requires about 900 megawatts of electricity across eight buildings and includes a new gas-fired power plant using turbines similar to those that power warships, according to the Associated Press. The companies say the plant provides only backup power, with most electricity coming from the local grid. That grid, for the record, draws from a mix of natural gas and the sprawling wind and solar farms in West Texas.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the people living near these projects aren’t exactly comforted. Arlene Mendler lives across the street from Stargate. She told the AP she wishes someone had asked her opinion before bulldozers eliminated a huge tract of mesquite shrubland to make room for what’s being built atop it.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“It has completely changed the way we were living,” Mendler told the AP. She moved to the area 33 years ago seeking “peace, quiet, tranquility.” Now construction is the soundtrack in the background, and bright lights on the scene have spoiled her nighttime views.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Then there’s the water. In drought-prone West Texas, locals are particularly nervous about how new data centers will impact the water supply. The city’s reservoirs were at roughly half capacity during Altman’s visit, with residents on a twice-weekly outdoor watering schedule. Oracle claims each of the eight buildings will need just 12,000 gallons per year after an initial million-gallon fill for closed-loop cooling systems. But Shaolei Ren, a University of California, Riverside, professor who studies AI’s environmental footprint, told the AP that’s misleading. These systems require more electricity, which means more indirect water consumption at the power plants generating that electricity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta is pursuing a similar strategy. In Richland Parish, the poorest region of Louisiana, the company plans to build a $10 billion data center the size of 1,700 football fields that will require two gigawatts of power for computation alone. Utility company Entergy will spend $3.2 billion to build three large natural-gas power plants with 2.3 gigawatts of capacity to feed the facility by burning gas extracted through fracking in the nearby Haynesville Shale. Louisiana residents, like those in Abilene, aren’t thrilled to be encircled by bulldozers around the clock.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;(Meta is also building in Texas, though elsewhere in the state. This week the company announced a $1.5 billion data center in El Paso, near the New Mexico border, with one gigawatt of capacity expected online in 2028. El Paso isn’t near the Permian Basin, and Meta says the facility will be matched with 100% clean and renewable energy. One point for Meta.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even Elon Musk’s xAI, whose Memphis facility has generated considerable controversy this year, has fracking connections. Memphis Light, Gas and Water — which currently sells power to xAI but will eventually own the substations xAI is building — purchases natural gas on the spot market and pipes it to Memphis via two companies: Texas Gas Transmission Corp. and Trunkline Gas Company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Texas Gas Transmission is a bidirectional pipeline carrying natural gas from Gulf Coast supply areas and several major hydraulically fractured shale formations through Arkansas, Mississippi, Kentucky, and Tennessee. Trunkline Gas Company, the other Memphis supplier, also carries natural gas from fracked sources.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If you’re wondering why AI companies are pursuing this path, they’ll tell you it’s not just about electricity; it’s also about beating China.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That was the argument Chris Lehane made last week. Lehane, a veteran political operative who joined OpenAI as vice president of global affairs in 2024, laid out the case during an onstage interview with TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We believe that in the not-too-distant future, at least in the U.S., and really around the world, we are going to need to be generating in the neighborhood of a gigawatt of energy a week,” Lehane said. He pointed to China’s massive energy buildout: 450 gigawatts and 33 nuclear facilities constructed in the last year alone.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When TechCrunch asked about Stargate’s decision to build in economically challenged areas like Abilene, or Lordstown, Ohio, where more gas-powered plants are planned, Lehane returned to geopolitics. “If we [as a country] do this right, you have an opportunity to re-industrialize countries, bring manufacturing back and also transition our energy systems so that we do the modernization that needs to take place.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Trump administration is certainly on board. The July 2025 executive order fast-tracks gas-powered AI data centers by streamlining environmental permits, offering financial incentives, and opening federal lands for projects using natural gas, coal, or nuclear power — while explicitly excluding renewables from support.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For now, most AI users remain largely unaware of the carbon footprint behind their dazzling new toys and work tools. They’re more focused on capabilities like Sora 2 — OpenAI’s hyperrealistic video-generation product that requires exponentially more energy than a simple chatbot — than on where the electricity comes from.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The companies are counting on this. They’ve positioned natural gas as the pragmatic, inevitable answer to AI’s exploding power demands. But the speed and scale of this fossil fuel buildout deserves more attention than it’s getting. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If this is a bubble, it won’t be pretty. The AI sector has become a circular firing squad of dependencies: OpenAI needs Microsoft needs Nvidia needs Broadcom needs Oracle needs data center operators who need OpenAI. They’re all buying from and selling to each other in a self-reinforcing loop. The Financial Times noted this week if the foundation cracks, there’ll be a lot of expensive infrastructure left standing around, both the digital and the gas-burning kind. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s ability alone to meet its obligations is “increasingly a concern for the wider economy,” the outlet wrote.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One key question that’s been largely absent from the conversation is whether all this new capacity is even necessary. A Duke University study found that utilities typically use only 53% of their available capacity throughout the year. That suggests significant room to accommodate new demand without constructing new power plants, as MIT Technology Review reported earlier this year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Duke researchers estimate that if data centers reduced electricity consumption by roughly half for just a few hours during annual peak demand periods, utilities could handle an additional 76 gigawatts of new load. That would effectively absorb the 65 gigawatts data centers are projected to need by 2029.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That kind of flexibility would allow companies to launch AI data centers faster. More importantly, it could provide a reprieve from the rush to build natural gas infrastructure, giving utilities time to develop cleaner alternatives.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But again, that would mean losing ground to an autocratic regime, per Lehane and many others in the industry, so instead, the natural gas building spree appears likely to saddle regions with more fossil-fuel plants and leave residents with soaring electricity bills to finance today’s investments, including long after the tech companies’ contracts expire.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Meta, for instance, has guaranteed it will cover Entergy’s costs for the new Louisiana generation for 15 years. Poolside’s lease with CoreWeave runs for 15 years. What happens to customers when those contracts end remains an open question.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Things may eventually change. A lot of private money is being funneled into small modular reactors and solar installations with the expectation that these cleaner energy alternatives will become more central energy sources for these data centers. Fusion startups like Helion and Commonwealth Fusion Systems have similarly raised substantial funding from those on the front lines of AI, including Nvidia and Altman.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This optimism isn’t confined to private investment circles. The excitement has spilled over into public markets, where several “non-revenue-generating” energy companies that have managed to go public have truly anticipatory market caps, based on the expectation that they will one day fuel these data centers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the meantime — which could still be decades — the most pressing concern is that the people who’ll be left holding the bag, financially and environmentally, never asked for any of this in the first place.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/17/your-ai-tools-run-on-fracked-gas-and-bulldozed-texas-land/</guid><pubDate>Fri, 17 Oct 2025 19:53:30 +0000</pubDate></item><item><title>The Engines of American-Made Intelligence: NVIDIA and TSMC Celebrate First NVIDIA Blackwell Wafer Produced in the US (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/tsmc-blackwell-manufacturing/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/tsmc-flag-1280x680-3.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;AI has ignited a new industrial revolution.&lt;/p&gt;
&lt;p&gt;NVIDIA and TSMC are working together to build the infrastructure that powers the world’s AI factories, right here in America.&lt;/p&gt;
&lt;p&gt;NVIDIA founder and CEO Jensen Huang today visited TSMC’s semiconductor manufacturing facility in Phoenix to celebrate the first NVIDIA Blackwell wafer produced on U.S. soil, representing that Blackwell has reached volume production.&lt;/p&gt;
&lt;p&gt;Onstage at the celebration, Huang joined Y.L. Wang, vice president of operations at TSMC, to sign the Blackwell wafer, commemorating a milestone that showcases how the engines of the world’s AI infrastructure are now being constructed domestically.&lt;/p&gt;
&lt;p&gt;This bolsters the U.S. supply chain and onshores the AI technology stack that will turn data into intelligence and secure America’s leadership for the AI era.&lt;/p&gt;
&lt;p&gt;“This is a historic moment for several reasons. It’s the very first time in recent American history that the single most important chip is being manufactured here in the United States by the most advanced fab, by TSMC, here in the United States,” Huang said at the event. “This is the vision of President Trump of reindustrialization — to bring back manufacturing to America, to create jobs, of course, but also, this is the single most vital manufacturing industry and the most important technology industry in the world.”&lt;/p&gt;
&lt;p&gt;“To go from arriving in Arizona to delivering the first U.S.-made NVIDIA Blackwell chip in just a few short years represents the very best of TSMC,” said Ray Chuang, CEO of TSMC Arizona. “This milestone is built on three decades of partnership with NVIDIA — pushing the boundaries of technology together — and on the unwavering dedication of our employees and the local partners who helped to make TSMC Arizona possible.”&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;The wafer — the base material for semiconductors — will go through a complex process of layering, patterning, etching and dicing before taking shape as the ultra-high-performance, accelerated AI chip the NVIDIA Blackwell architecture offers.&lt;/p&gt;
&lt;p&gt;TSMC Arizona will produce advanced technologies including two-, three- and four-nanometer chips, as well as A16 chips, all essential for applications like AI, telecommunications and high-performance computing.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Onshoring World-Class AI Chipmaking to American Soil&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;America-based manufacturing is crucial to meeting the growing demand for AI.&lt;/p&gt;
&lt;p&gt;Today’s achievement marks a huge step forward in semiconductor manufacturing and AI development in the U.S., paving the way for sustained American leadership in artificial intelligence. NVIDIA Blackwell GPUs offer exceptional performance, return on investment and energy efficiency for AI inference.&lt;/p&gt;
&lt;p&gt;In addition, NVIDIA plans to deploy its advanced AI, robotics and digital twin technologies to design and operate new U.S. manufacturing facilities.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Learn more about how NVIDIA technologies accelerate innovation for America’s enterprises, government organizations, researchers and startups at &lt;/i&gt;&lt;i&gt;NVIDIA GTC Washington, D.C.&lt;/i&gt;&lt;i&gt;, running Oct. 27-29.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/tsmc-flag-1280x680-3.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;AI has ignited a new industrial revolution.&lt;/p&gt;
&lt;p&gt;NVIDIA and TSMC are working together to build the infrastructure that powers the world’s AI factories, right here in America.&lt;/p&gt;
&lt;p&gt;NVIDIA founder and CEO Jensen Huang today visited TSMC’s semiconductor manufacturing facility in Phoenix to celebrate the first NVIDIA Blackwell wafer produced on U.S. soil, representing that Blackwell has reached volume production.&lt;/p&gt;
&lt;p&gt;Onstage at the celebration, Huang joined Y.L. Wang, vice president of operations at TSMC, to sign the Blackwell wafer, commemorating a milestone that showcases how the engines of the world’s AI infrastructure are now being constructed domestically.&lt;/p&gt;
&lt;p&gt;This bolsters the U.S. supply chain and onshores the AI technology stack that will turn data into intelligence and secure America’s leadership for the AI era.&lt;/p&gt;
&lt;p&gt;“This is a historic moment for several reasons. It’s the very first time in recent American history that the single most important chip is being manufactured here in the United States by the most advanced fab, by TSMC, here in the United States,” Huang said at the event. “This is the vision of President Trump of reindustrialization — to bring back manufacturing to America, to create jobs, of course, but also, this is the single most vital manufacturing industry and the most important technology industry in the world.”&lt;/p&gt;
&lt;p&gt;“To go from arriving in Arizona to delivering the first U.S.-made NVIDIA Blackwell chip in just a few short years represents the very best of TSMC,” said Ray Chuang, CEO of TSMC Arizona. “This milestone is built on three decades of partnership with NVIDIA — pushing the boundaries of technology together — and on the unwavering dedication of our employees and the local partners who helped to make TSMC Arizona possible.”&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;The wafer — the base material for semiconductors — will go through a complex process of layering, patterning, etching and dicing before taking shape as the ultra-high-performance, accelerated AI chip the NVIDIA Blackwell architecture offers.&lt;/p&gt;
&lt;p&gt;TSMC Arizona will produce advanced technologies including two-, three- and four-nanometer chips, as well as A16 chips, all essential for applications like AI, telecommunications and high-performance computing.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Onshoring World-Class AI Chipmaking to American Soil&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;America-based manufacturing is crucial to meeting the growing demand for AI.&lt;/p&gt;
&lt;p&gt;Today’s achievement marks a huge step forward in semiconductor manufacturing and AI development in the U.S., paving the way for sustained American leadership in artificial intelligence. NVIDIA Blackwell GPUs offer exceptional performance, return on investment and energy efficiency for AI inference.&lt;/p&gt;
&lt;p&gt;In addition, NVIDIA plans to deploy its advanced AI, robotics and digital twin technologies to design and operate new U.S. manufacturing facilities.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Learn more about how NVIDIA technologies accelerate innovation for America’s enterprises, government organizations, researchers and startups at &lt;/i&gt;&lt;i&gt;NVIDIA GTC Washington, D.C.&lt;/i&gt;&lt;i&gt;, running Oct. 27-29.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/tsmc-blackwell-manufacturing/</guid><pubDate>Fri, 17 Oct 2025 21:27:28 +0000</pubDate></item><item><title>Senate Republicans deepfaked Chuck Schumer, and X hasn’t taken it down (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/17/senate-republicans-deepfaked-chuck-schumer-and-x-hasnt-taken-it-down/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2018/02/tc-backlight-e1689786273147.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Senate Republicans shared a deepfake video of Chuck Schumer, the Senate minority leader, designed to make it seem like Democrats are celebrating the ongoing government shutdown, which has lasted 16 days. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the deepfake, an AI-generated Schumer repeats the phrase “every day gets better for us,” an actual quote taken out of context from a Punchbowl News article. In the original story, Schumer discussed the Democrats’ healthcare-focused shutdown strategy, and said they were not going to back away from Republicans’ playbook of threats and “bambooz[ling].”&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The shutdown is happening because Democrats and Republicans cannot agree to pass a bill funding government through October and beyond. Democrats are trying to hold on to tax credits that would make health insurance cheaper for millions of Americans, secure a reversal to Trump’s Medicaid cuts, and block cuts to government health agencies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The video was posted Friday on the Senate Republicans’ X account. According to X’s policies, the platform prohibits “deceptively shar[ing] synthetic or manipulated media that are likely to cause harm.” Harmful content includes media that could “mislead people” or “cause significant confusion on public issues.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Enforcement actions include removing content, labeling warnings, or reducing visibility. X has not, as of the time of this writing, removed the deepfake or added a warning label — though the video does include a watermark denoting its AI origins.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Schumer video is not the first time X has allowed deepfakes of politicians to remain on the platform. In late 2024, X owner Elon Musk shared a manipulated video of former vice president Kamala Harris in the lead-up to the election, sparking debate about misleading voters. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to X for comment. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Up to 28 states have enacted laws prohibiting deepfakes of political figures, specifically around campaigns and elections, though most don’t outright ban them if they have clear disclosures. California, Minnesota, and Texas have banned deepfakes intended to influence elections, deceive voters, or harm candidates. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The latest post comes weeks after President Donald Trump posted deepfakes on Truth Social depicting Schumer and Hakeem Jeffries, the House minority leader, making false statements about immigration and voter fraud.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Responding to criticism of the lack of honesty and ethics, Joanna Rodriguez, the National Republican Senatorial Committee communications director, said: “AI is here and not going anywhere. Adapt &amp;amp; win or pearl clutch &amp;amp; lose.”&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2018/02/tc-backlight-e1689786273147.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Senate Republicans shared a deepfake video of Chuck Schumer, the Senate minority leader, designed to make it seem like Democrats are celebrating the ongoing government shutdown, which has lasted 16 days. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the deepfake, an AI-generated Schumer repeats the phrase “every day gets better for us,” an actual quote taken out of context from a Punchbowl News article. In the original story, Schumer discussed the Democrats’ healthcare-focused shutdown strategy, and said they were not going to back away from Republicans’ playbook of threats and “bambooz[ling].”&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The shutdown is happening because Democrats and Republicans cannot agree to pass a bill funding government through October and beyond. Democrats are trying to hold on to tax credits that would make health insurance cheaper for millions of Americans, secure a reversal to Trump’s Medicaid cuts, and block cuts to government health agencies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The video was posted Friday on the Senate Republicans’ X account. According to X’s policies, the platform prohibits “deceptively shar[ing] synthetic or manipulated media that are likely to cause harm.” Harmful content includes media that could “mislead people” or “cause significant confusion on public issues.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Enforcement actions include removing content, labeling warnings, or reducing visibility. X has not, as of the time of this writing, removed the deepfake or added a warning label — though the video does include a watermark denoting its AI origins.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Schumer video is not the first time X has allowed deepfakes of politicians to remain on the platform. In late 2024, X owner Elon Musk shared a manipulated video of former vice president Kamala Harris in the lead-up to the election, sparking debate about misleading voters. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to X for comment. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Up to 28 states have enacted laws prohibiting deepfakes of political figures, specifically around campaigns and elections, though most don’t outright ban them if they have clear disclosures. California, Minnesota, and Texas have banned deepfakes intended to influence elections, deceive voters, or harm candidates. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The latest post comes weeks after President Donald Trump posted deepfakes on Truth Social depicting Schumer and Hakeem Jeffries, the House minority leader, making false statements about immigration and voter fraud.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Responding to criticism of the lack of honesty and ethics, Joanna Rodriguez, the National Republican Senatorial Committee communications director, said: “AI is here and not going anywhere. Adapt &amp;amp; win or pearl clutch &amp;amp; lose.”&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/17/senate-republicans-deepfaked-chuck-schumer-and-x-hasnt-taken-it-down/</guid><pubDate>Fri, 17 Oct 2025 21:44:07 +0000</pubDate></item><item><title>Developers can now add live Google Maps data to Gemini-powered AI app outputs (AI | VentureBeat)</title><link>https://venturebeat.com/ai/developers-can-now-add-live-google-maps-data-to-gemini-powered-ai-app</link><description>[unable to retrieve full-text content]&lt;p&gt;Google is adding a new feature for third-party developers building atop its Gemini AI models that rivals like OpenAI&amp;#x27;s ChatGPT, Anthropic&amp;#x27;s Claude, and the growing array of Chinese open source options are unlikely to get anytime soon: &lt;a href="https://blog.google/technology/developers/grounding-google-maps-gemini-api/"&gt;grounding with Google Maps.&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This addition allows developers to connect Google&amp;#x27;s Gemini AI models&amp;#x27; reasoning capabilities with live geospatial data from Google Maps, enabling applications to deliver detailed, location-relevant responses to user queries—such as business hours, reviews, or the atmosphere of a specific venue. &lt;/p&gt;&lt;p&gt;By tapping into data from over 250 million places, developers can now build more intelligent and responsive location-aware experiences.&lt;/p&gt;&lt;p&gt;This is particularly useful for applications where proximity, real-time availability, or location-specific personalization matter—such as local search, delivery services, real estate, and travel planning. &lt;/p&gt;&lt;p&gt;When the user’s location is known, developers can pass latitude and longitude into the request to enhance the response quality.&lt;/p&gt;&lt;p&gt;By tightly integrating real-time and historical Maps data into the Gemini API, Google enables applications to generate grounded, location-specific responses with factual accuracy and contextual depth that are uniquely possible through its mapping infrastructure.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Merging AI and Geospatial Intelligence&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The new feature is accessible in Google AI Studio, where developers can try a live demo powered by the Gemini Live API. Models that support the grounding with Google Maps include:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Gemini 2.5 Pro&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Gemini 2.5 Flash&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Gemini 2.5 Flash-Lite&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Gemini 2.0 Flash&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In one &lt;a href="https://youtu.be/vw5gIrTVQIY?si=LWJ4XEYPIyI1elrM"&gt;demonstration&lt;/a&gt;, a user asked for Italian restaurant recommendations in Chicago. &lt;/p&gt;&lt;div&gt;&lt;/div&gt;&lt;p&gt;The assistant, leveraging Maps data, retrieved top-rated options and clarified a misspelled restaurant name before locating the correct venue with accurate business details.&lt;/p&gt;&lt;p&gt;Developers can also retrieve a context token to embed a Google Maps widget in their app’s user interface. This interactive component displays photos, reviews, and other familiar content typically found in Google Maps.&lt;/p&gt;&lt;p&gt;Integration is handled via the &lt;code&gt;generateContent&lt;/code&gt; method in the Gemini API, where developers include &lt;code&gt;googleMaps&lt;/code&gt; as a tool. They can also enable a Maps widget by setting a parameter in the request. The widget, rendered using a returned context token, can provide a visual layer alongside the AI-generated text.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Use Cases Across Industries&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The Maps grounding tool is designed to support a wide range of practical use cases:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Itinerary generation:&lt;/b&gt; Travel apps can create detailed daily plans with routing, timing, and venue information.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Personalized local recommendations:&lt;/b&gt; Real estate platforms can highlight listings near kid-friendly amenities like schools and parks.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Detailed location queries:&lt;/b&gt; Applications can provide specific information, such as whether a cafe offers outdoor seating, using community reviews and Maps metadata.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Developers are encouraged to only enable the tool when geographic context is relevant, to optimize both performance and cost. &lt;/p&gt;&lt;p&gt;According to the developer documentation, pricing starts at $25 per 1,000 grounded prompts — a steep sum for those trafficking in numerous queries.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Combining Search and Maps for Enhanced Context&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Developers can use Grounding with Google Maps alongside Grounding with Google Search in the same request.&lt;/p&gt;&lt;p&gt;While the Maps tool contributes factual data—like addresses, hours, and ratings—the Search tool adds broader context from web content, such as news or event listings.&lt;/p&gt;&lt;p&gt;For example, when asked about live music on Beale Street, the combined tools provide venue details from Maps and event times from Search. &lt;/p&gt;&lt;p&gt;According to Google, internal testing shows that using both tools together leads to significantly improved response quality.&lt;/p&gt;&lt;p&gt;Unfortunately, it doesn&amp;#x27;t appear that the Google Maps grounding includes live vehicular traffic data — at least not yet.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Customization and Developer Flexibility&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The experience is built for customization. Developers can tweak system prompts, choose from different Gemini models, and configure voice settings to tailor interactions.&lt;/p&gt;&lt;p&gt; The demo app in Google AI Studio is also remixable, enabling developers to test ideas, add features, and iterate on designs within a flexible development environment.&lt;/p&gt;&lt;p&gt;The API returns structured metadata—including source links, place IDs, and citation spans—that developers can use to build inline citations or verify the AI-generated outputs. &lt;/p&gt;&lt;p&gt;This supports transparency and enhances trust in user-facing applications. Google also requires that Maps-based sources be attributed clearly and linked back to the source using their URI.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Implementation Considerations for AI Builders&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;For technical teams integrating this capability, Google recommends:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Passing user location context when known, for better results.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Displaying Google Maps source links directly beneath the relevant content.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Only enabling the tool when the query clearly involves geographic context.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Monitoring latency and disabling grounding when performance is critical.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Grounding with Google Maps is currently available globally, though prohibited in several territories (including China, Iran, North Korea, and Cuba), and not permitted for emergency response use cases.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Availability and Access&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Grounding with Google Maps is now generally available through the Gemini API. &lt;/p&gt;&lt;p&gt;With this release, Google continues to expand the capabilities of the Gemini API, empowering developers to build AI-driven applications that understand and respond to the world around them.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;Google is adding a new feature for third-party developers building atop its Gemini AI models that rivals like OpenAI&amp;#x27;s ChatGPT, Anthropic&amp;#x27;s Claude, and the growing array of Chinese open source options are unlikely to get anytime soon: &lt;a href="https://blog.google/technology/developers/grounding-google-maps-gemini-api/"&gt;grounding with Google Maps.&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This addition allows developers to connect Google&amp;#x27;s Gemini AI models&amp;#x27; reasoning capabilities with live geospatial data from Google Maps, enabling applications to deliver detailed, location-relevant responses to user queries—such as business hours, reviews, or the atmosphere of a specific venue. &lt;/p&gt;&lt;p&gt;By tapping into data from over 250 million places, developers can now build more intelligent and responsive location-aware experiences.&lt;/p&gt;&lt;p&gt;This is particularly useful for applications where proximity, real-time availability, or location-specific personalization matter—such as local search, delivery services, real estate, and travel planning. &lt;/p&gt;&lt;p&gt;When the user’s location is known, developers can pass latitude and longitude into the request to enhance the response quality.&lt;/p&gt;&lt;p&gt;By tightly integrating real-time and historical Maps data into the Gemini API, Google enables applications to generate grounded, location-specific responses with factual accuracy and contextual depth that are uniquely possible through its mapping infrastructure.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Merging AI and Geospatial Intelligence&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The new feature is accessible in Google AI Studio, where developers can try a live demo powered by the Gemini Live API. Models that support the grounding with Google Maps include:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Gemini 2.5 Pro&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Gemini 2.5 Flash&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Gemini 2.5 Flash-Lite&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Gemini 2.0 Flash&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In one &lt;a href="https://youtu.be/vw5gIrTVQIY?si=LWJ4XEYPIyI1elrM"&gt;demonstration&lt;/a&gt;, a user asked for Italian restaurant recommendations in Chicago. &lt;/p&gt;&lt;div&gt;&lt;/div&gt;&lt;p&gt;The assistant, leveraging Maps data, retrieved top-rated options and clarified a misspelled restaurant name before locating the correct venue with accurate business details.&lt;/p&gt;&lt;p&gt;Developers can also retrieve a context token to embed a Google Maps widget in their app’s user interface. This interactive component displays photos, reviews, and other familiar content typically found in Google Maps.&lt;/p&gt;&lt;p&gt;Integration is handled via the &lt;code&gt;generateContent&lt;/code&gt; method in the Gemini API, where developers include &lt;code&gt;googleMaps&lt;/code&gt; as a tool. They can also enable a Maps widget by setting a parameter in the request. The widget, rendered using a returned context token, can provide a visual layer alongside the AI-generated text.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Use Cases Across Industries&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The Maps grounding tool is designed to support a wide range of practical use cases:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Itinerary generation:&lt;/b&gt; Travel apps can create detailed daily plans with routing, timing, and venue information.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Personalized local recommendations:&lt;/b&gt; Real estate platforms can highlight listings near kid-friendly amenities like schools and parks.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Detailed location queries:&lt;/b&gt; Applications can provide specific information, such as whether a cafe offers outdoor seating, using community reviews and Maps metadata.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Developers are encouraged to only enable the tool when geographic context is relevant, to optimize both performance and cost. &lt;/p&gt;&lt;p&gt;According to the developer documentation, pricing starts at $25 per 1,000 grounded prompts — a steep sum for those trafficking in numerous queries.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Combining Search and Maps for Enhanced Context&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Developers can use Grounding with Google Maps alongside Grounding with Google Search in the same request.&lt;/p&gt;&lt;p&gt;While the Maps tool contributes factual data—like addresses, hours, and ratings—the Search tool adds broader context from web content, such as news or event listings.&lt;/p&gt;&lt;p&gt;For example, when asked about live music on Beale Street, the combined tools provide venue details from Maps and event times from Search. &lt;/p&gt;&lt;p&gt;According to Google, internal testing shows that using both tools together leads to significantly improved response quality.&lt;/p&gt;&lt;p&gt;Unfortunately, it doesn&amp;#x27;t appear that the Google Maps grounding includes live vehicular traffic data — at least not yet.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Customization and Developer Flexibility&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The experience is built for customization. Developers can tweak system prompts, choose from different Gemini models, and configure voice settings to tailor interactions.&lt;/p&gt;&lt;p&gt; The demo app in Google AI Studio is also remixable, enabling developers to test ideas, add features, and iterate on designs within a flexible development environment.&lt;/p&gt;&lt;p&gt;The API returns structured metadata—including source links, place IDs, and citation spans—that developers can use to build inline citations or verify the AI-generated outputs. &lt;/p&gt;&lt;p&gt;This supports transparency and enhances trust in user-facing applications. Google also requires that Maps-based sources be attributed clearly and linked back to the source using their URI.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Implementation Considerations for AI Builders&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;For technical teams integrating this capability, Google recommends:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Passing user location context when known, for better results.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Displaying Google Maps source links directly beneath the relevant content.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Only enabling the tool when the query clearly involves geographic context.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Monitoring latency and disabling grounding when performance is critical.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Grounding with Google Maps is currently available globally, though prohibited in several territories (including China, Iran, North Korea, and Cuba), and not permitted for emergency response use cases.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Availability and Access&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Grounding with Google Maps is now generally available through the Gemini API. &lt;/p&gt;&lt;p&gt;With this release, Google continues to expand the capabilities of the Gemini API, empowering developers to build AI-driven applications that understand and respond to the world around them.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/developers-can-now-add-live-google-maps-data-to-gemini-powered-ai-app</guid><pubDate>Fri, 17 Oct 2025 22:31:00 +0000</pubDate></item><item><title>Silicon Valley spooks the AI safety advocates (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/17/silicon-valley-spooks-the-ai-safety-advocates/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2020/03/GettyImages-1167639112.jpg?w=1000" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Silicon Valley leaders including White House AI &amp;amp; Crypto Czar David Sacks and OpenAI Chief Strategy Officer Jason Kwon caused a stir online this week for their comments about groups promoting AI safety. In separate instances, they alleged that certain advocates of AI safety are not as virtuous as they appear, and are either acting in the interest of themselves or billionaire puppet masters behind the scenes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI safety groups that spoke with TechCrunch say the allegations from Sacks and OpenAI are Silicon Valley’s latest attempt to intimidate its critics, but certainly not the first. In 2024, some venture capital firms spread rumors that a California AI safety bill, SB 1047, would send startup founders to jail. The Brookings Institution labeled the rumor as one of many “misrepresentations” about the bill, but Governor Gavin Newsom ultimately vetoed it anyway.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Whether or not Sacks and OpenAI intended to intimidate critics, their actions have sufficiently scared several AI safety advocates. Many nonprofit leaders that TechCrunch reached out to in the last week asked to speak on the condition of anonymity to spare their groups from retaliation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The controversy underscores Silicon Valley’s growing tension between building AI responsibly and building it to be a massive consumer product — a theme my colleagues Kirsten Korosec, Anthony Ha, and I unpack on this week’s &lt;em&gt;Equity&lt;/em&gt; podcast. We also dive into a new AI safety law passed in California to regulate chatbots, and OpenAI’s approach to erotica in ChatGPT.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;On Tuesday, Sacks wrote a post on X alleging that Anthropic — which has raised concerns over AI’s ability to contribute to unemployment, cyberattacks, and catastrophic harms to society — is simply fearmongering to get laws passed that will benefit itself and drown out smaller startups in paperwork. Anthropic was the only major AI lab to endorse California’s Senate Bill 53 (SB 53), a bill that sets safety reporting requirements for large AI companies, which was signed into law last month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sacks was responding to a viral essay from Anthropic co-founder Jack Clark about his fears regarding AI. Clark delivered the essay as a speech at the Curve AI safety conference in Berkeley weeks earlier. Sitting in the audience, it certainly felt like a genuine account of a technologist’s reservations about his products, but Sacks didn’t see it that way.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Anthropic is running a sophisticated regulatory capture strategy based on fear-mongering. It is principally responsible for the state regulatory frenzy that is damaging the startup ecosystem. https://t.co/C5RuJbVi4P&lt;/p&gt;— David Sacks (@DavidSacks) October 14, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Sacks said Anthropic is running a “sophisticated regulatory capture strategy,” though it’s worth noting that a truly sophisticated strategy probably wouldn’t involve making an enemy out of the federal government. In a follow up post on X, Sacks noted that Anthropic has positioned “itself consistently as a foe of the Trump administration.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Also this week, OpenAI’s chief strategy officer, Jason Kwon, wrote a post on X explaining why the company was sending subpoenas to AI safety nonprofits, such as Encode, a nonprofit that advocates for responsible AI policy. (A subpoena is a legal order demanding documents or testimony.) Kwon said that after Elon Musk sued OpenAI — over concerns that the ChatGPT-maker has veered away from its nonprofit mission — OpenAI found it suspicious how several organizations also raised opposition to its restructuring. Encode filed an amicus brief in support of Musk’s lawsuit, and other nonprofits spoke out publicly against OpenAI’s restructuring.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;There’s quite a lot more to the story than this.&lt;/p&gt;&lt;p&gt;As everyone knows, we are actively defending against Elon in a lawsuit where he is trying to damage OpenAI for his own financial benefit.&lt;/p&gt;&lt;p&gt;Encode, the organization for which @_NathanCalvin  serves as the General Counsel, was one… https://t.co/DiBJmEwtE4&lt;/p&gt;— Jason Kwon (@jasonkwon) October 10, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“This raised transparency questions about who was funding them and whether there was any coordination,” said Kwon.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;NBC News reported this week that OpenAI sent broad subpoenas to Encode and six other nonprofits that criticized the company, asking for their communications related to two of OpenAI’s biggest opponents, Musk and Meta CEO Mark Zuckerberg. OpenAI also asked Encode for communications related to its support of SB 53.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;One prominent AI safety leader told TechCrunch that there’s a growing split between OpenAI’s government affairs team and its research organization. While OpenAI’s safety researchers frequently publish reports disclosing the risks of AI systems, OpenAI’s policy unit lobbied against SB 53, saying it would rather have uniform rules at the federal level.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s head of mission alignment, Joshua Achiam, spoke out about his company sending subpoenas to nonprofits in a post on X this week.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt; “At what is possibly a risk to my whole career I will say: this doesn’t seem great,” said Achiam.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Brendan Steinhauser, CEO of the AI safety nonprofit Alliance for Secure AI (which has not been subpoenaed by OpenAI), told TechCrunch that OpenAI seems convinced its critics are part of a Musk-led conspiracy. However, he argues this is not the case, and that much of the AI safety community is quite critical of xAI’s safety practices, or lack thereof.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“On OpenAI’s part, this is meant to silence critics, to intimidate them, and to dissuade other nonprofits from doing the same,” said Steinhauser. “For Sacks, I think he’s concerned that [the AI safety] movement is growing and people want to hold these companies accountable.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sriram Krishnan, the White House’s senior policy advisor for AI and a former a16z general partner, chimed in on the conversation this week with a social media post of his own, calling AI safety advocates out of touch. He urged AI safety organizations to talk to “people in the real world using, selling, adopting AI in their homes and organizations.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A recent Pew study found that roughly half of Americans are more concerned than excited about AI, but it’s unclear what worries them exactly. Another recent study went into more detail and found that American voters care more about job losses and deepfakes than catastrophic risks caused by AI, which the AI safety movement is largely focused on.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Addressing these safety concerns could come at the expense of the AI industry’s rapid growth — a trade-off that worries many in Silicon Valley. With AI investment propping up much of America’s economy, the fear of over-regulation is understandable. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But after years of unregulated AI progress, the AI safety movement appears to be gaining real momentum heading into 2026. Silicon Valley’s attempts to fight back against safety-focused groups may be a sign that they’re working.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2020/03/GettyImages-1167639112.jpg?w=1000" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Silicon Valley leaders including White House AI &amp;amp; Crypto Czar David Sacks and OpenAI Chief Strategy Officer Jason Kwon caused a stir online this week for their comments about groups promoting AI safety. In separate instances, they alleged that certain advocates of AI safety are not as virtuous as they appear, and are either acting in the interest of themselves or billionaire puppet masters behind the scenes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI safety groups that spoke with TechCrunch say the allegations from Sacks and OpenAI are Silicon Valley’s latest attempt to intimidate its critics, but certainly not the first. In 2024, some venture capital firms spread rumors that a California AI safety bill, SB 1047, would send startup founders to jail. The Brookings Institution labeled the rumor as one of many “misrepresentations” about the bill, but Governor Gavin Newsom ultimately vetoed it anyway.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Whether or not Sacks and OpenAI intended to intimidate critics, their actions have sufficiently scared several AI safety advocates. Many nonprofit leaders that TechCrunch reached out to in the last week asked to speak on the condition of anonymity to spare their groups from retaliation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The controversy underscores Silicon Valley’s growing tension between building AI responsibly and building it to be a massive consumer product — a theme my colleagues Kirsten Korosec, Anthony Ha, and I unpack on this week’s &lt;em&gt;Equity&lt;/em&gt; podcast. We also dive into a new AI safety law passed in California to regulate chatbots, and OpenAI’s approach to erotica in ChatGPT.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;On Tuesday, Sacks wrote a post on X alleging that Anthropic — which has raised concerns over AI’s ability to contribute to unemployment, cyberattacks, and catastrophic harms to society — is simply fearmongering to get laws passed that will benefit itself and drown out smaller startups in paperwork. Anthropic was the only major AI lab to endorse California’s Senate Bill 53 (SB 53), a bill that sets safety reporting requirements for large AI companies, which was signed into law last month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sacks was responding to a viral essay from Anthropic co-founder Jack Clark about his fears regarding AI. Clark delivered the essay as a speech at the Curve AI safety conference in Berkeley weeks earlier. Sitting in the audience, it certainly felt like a genuine account of a technologist’s reservations about his products, but Sacks didn’t see it that way.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Anthropic is running a sophisticated regulatory capture strategy based on fear-mongering. It is principally responsible for the state regulatory frenzy that is damaging the startup ecosystem. https://t.co/C5RuJbVi4P&lt;/p&gt;— David Sacks (@DavidSacks) October 14, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Sacks said Anthropic is running a “sophisticated regulatory capture strategy,” though it’s worth noting that a truly sophisticated strategy probably wouldn’t involve making an enemy out of the federal government. In a follow up post on X, Sacks noted that Anthropic has positioned “itself consistently as a foe of the Trump administration.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Also this week, OpenAI’s chief strategy officer, Jason Kwon, wrote a post on X explaining why the company was sending subpoenas to AI safety nonprofits, such as Encode, a nonprofit that advocates for responsible AI policy. (A subpoena is a legal order demanding documents or testimony.) Kwon said that after Elon Musk sued OpenAI — over concerns that the ChatGPT-maker has veered away from its nonprofit mission — OpenAI found it suspicious how several organizations also raised opposition to its restructuring. Encode filed an amicus brief in support of Musk’s lawsuit, and other nonprofits spoke out publicly against OpenAI’s restructuring.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;There’s quite a lot more to the story than this.&lt;/p&gt;&lt;p&gt;As everyone knows, we are actively defending against Elon in a lawsuit where he is trying to damage OpenAI for his own financial benefit.&lt;/p&gt;&lt;p&gt;Encode, the organization for which @_NathanCalvin  serves as the General Counsel, was one… https://t.co/DiBJmEwtE4&lt;/p&gt;— Jason Kwon (@jasonkwon) October 10, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“This raised transparency questions about who was funding them and whether there was any coordination,” said Kwon.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;NBC News reported this week that OpenAI sent broad subpoenas to Encode and six other nonprofits that criticized the company, asking for their communications related to two of OpenAI’s biggest opponents, Musk and Meta CEO Mark Zuckerberg. OpenAI also asked Encode for communications related to its support of SB 53.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;One prominent AI safety leader told TechCrunch that there’s a growing split between OpenAI’s government affairs team and its research organization. While OpenAI’s safety researchers frequently publish reports disclosing the risks of AI systems, OpenAI’s policy unit lobbied against SB 53, saying it would rather have uniform rules at the federal level.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s head of mission alignment, Joshua Achiam, spoke out about his company sending subpoenas to nonprofits in a post on X this week.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt; “At what is possibly a risk to my whole career I will say: this doesn’t seem great,” said Achiam.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Brendan Steinhauser, CEO of the AI safety nonprofit Alliance for Secure AI (which has not been subpoenaed by OpenAI), told TechCrunch that OpenAI seems convinced its critics are part of a Musk-led conspiracy. However, he argues this is not the case, and that much of the AI safety community is quite critical of xAI’s safety practices, or lack thereof.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“On OpenAI’s part, this is meant to silence critics, to intimidate them, and to dissuade other nonprofits from doing the same,” said Steinhauser. “For Sacks, I think he’s concerned that [the AI safety] movement is growing and people want to hold these companies accountable.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sriram Krishnan, the White House’s senior policy advisor for AI and a former a16z general partner, chimed in on the conversation this week with a social media post of his own, calling AI safety advocates out of touch. He urged AI safety organizations to talk to “people in the real world using, selling, adopting AI in their homes and organizations.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A recent Pew study found that roughly half of Americans are more concerned than excited about AI, but it’s unclear what worries them exactly. Another recent study went into more detail and found that American voters care more about job losses and deepfakes than catastrophic risks caused by AI, which the AI safety movement is largely focused on.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Addressing these safety concerns could come at the expense of the AI industry’s rapid growth — a trade-off that worries many in Silicon Valley. With AI investment propping up much of America’s economy, the fear of over-regulation is understandable. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But after years of unregulated AI progress, the AI safety movement appears to be gaining real momentum heading into 2026. Silicon Valley’s attempts to fight back against safety-focused groups may be a sign that they’re working.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/17/silicon-valley-spooks-the-ai-safety-advocates/</guid><pubDate>Sat, 18 Oct 2025 01:21:30 +0000</pubDate></item></channel></rss>