<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 29 Oct 2025 18:32:23 +0000</lastBuildDate><item><title> ()</title><link>https://www.microsoft.com/en-us/research/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/feed/</guid></item><item><title>[NEW] Geostar pioneers GEO as traditional SEO faces 25% decline from AI chatbots, Gartner says (AI | VentureBeat)</title><link>https://venturebeat.com/ai/geostar-pioneers-geo-as-traditional-seo-faces-25-decline-from-ai-chatbots</link><description>[unable to retrieve full-text content]&lt;p&gt;The moment Mack McConnell knew everything about search had changed came last summer at the Paris Olympics. His parents, independently and without prompting, had both turned to &lt;a href="https://chatgpt.com/"&gt;&lt;u&gt;ChatGPT&lt;/u&gt;&lt;/a&gt; to plan their day&amp;#x27;s activities in the French capital. The AI recommended specific tour companies, restaurants, and attractions — businesses that had won a new kind of visibility lottery.&lt;/p&gt;&lt;p&gt;&amp;quot;It was almost like this intuitive interface that older people were as comfortable with using as younger people,&amp;quot; McConnell recalled in an exclusive interview with VentureBeat. &amp;quot;I could just see the businesses were now being recommended.&amp;quot;&lt;/p&gt;&lt;p&gt;That observation has now become the foundation of &lt;a href="https://www.geostar.ai/"&gt;&lt;u&gt;Geostar&lt;/u&gt;&lt;/a&gt;, a Pear VC-backed startup that&amp;#x27;s racing to help businesses navigate what may be the most significant shift in online discovery since Google&amp;#x27;s founding. &lt;/p&gt;&lt;p&gt;The company, which recently emerged from stealth with impressive early customer traction, is betting that the rise of AI-powered search represents a significant opportunity to reinvent how companies get found online. The &lt;a href="https://www.coherentmarketinsights.com/industry-reports/ai-search-engines-market"&gt;&lt;u&gt;global AI search engine market&lt;/u&gt;&lt;/a&gt; alone is projected to grow from $43.63 billion in 2025 to $108.88 billion by 2032.&lt;/p&gt;&lt;p&gt;Already the fastest-growing company in &lt;a href="https://pear.vc/inside-pearx-partnering-with-founders-the-pear-way/"&gt;&lt;u&gt;PearX&amp;#x27;s latest cohort&lt;/u&gt;&lt;/a&gt;, Geostar is fast approaching $1 million in annual recurring revenue in just four months — with only two founders and no employees.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why Gartner predicts traditional search volume will decline 25% by 2026&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The numbers tell a stark story of disruption. Gartner predicts that traditional search engine volume will &lt;a href="https://www.forbes.com/councils/forbesagencycouncil/2025/10/23/generative-engine-optimization-the-next-frontier-in-seo/"&gt;&lt;u&gt;decline by 25% by 2026&lt;/u&gt;&lt;/a&gt;, largely due to the rise of AI chatbots. Google&amp;#x27;s AI Overviews now appear on &lt;a href="https://techcrunch.com/2025/04/25/googles-ai-search-numbers-are-growing-and-thats-by-design/"&gt;&lt;u&gt;billions of searches&lt;/u&gt;&lt;/a&gt; monthly. Princeton University researchers have found that optimizing for these new AI systems can increase visibility &lt;a href="https://arxiv.org/pdf/2311.09735"&gt;&lt;u&gt;by up to 40%&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&amp;quot;Search used to mean that you had to make Google happy,&amp;quot; McConnell explained. &amp;quot;But now you have to optimize for four different Google interfaces — traditional search, AI Mode, Gemini, and AI Overviews — each with different criteria. And then ChatGPT, Claude, and Perplexity each work differently on top of that.&amp;quot;&lt;/p&gt;&lt;p&gt;This fragmentation is creating chaos for businesses that have spent decades perfecting their Google search strategies. A recent &lt;a href="https://www.forrester.com/press-newsroom/forrester-the-state-of-business-buying-2024/"&gt;&lt;u&gt;Forrester study&lt;/u&gt;&lt;/a&gt; found that 95% of B2B buyers plan to use generative AI in future purchase decisions. Yet most companies remain woefully unprepared for this shift.&lt;/p&gt;&lt;p&gt;&amp;quot;Anybody who&amp;#x27;s not on this right now is losing out,&amp;quot; said Cihan Tas, Geostar&amp;#x27;s co-founder and chief technology officer. &amp;quot;We see lawyers getting 50% of their clients through ChatGPT now. It&amp;#x27;s just such a massive shift.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How language models read the web differently than search engines ever did&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;What &lt;a href="https://www.geostar.ai/"&gt;&lt;u&gt;Geostar&lt;/u&gt;&lt;/a&gt; and a growing cohort of competitors call Generative Engine Optimization or GEO represents a fundamental departure from traditional search engine optimization. Where SEO focused primarily on keywords and backlinks, GEO requires understanding how large language models parse, understand, and synthesize information across the entire web.&lt;/p&gt;&lt;p&gt;The technical challenges are formidable. Every website must now function as what Tas calls &amp;quot;its own little database&amp;quot; capable of being understood by dozens of different AI crawlers, each with unique requirements and preferences. Google&amp;#x27;s systems pull from their existing search index. &lt;a href="https://chatgpt.com/"&gt;&lt;u&gt;ChatGPT&lt;/u&gt;&lt;/a&gt; relies heavily on structured data and specific content formats. Perplexity shows a marked preference for Wikipedia and authoritative sources.&lt;/p&gt;&lt;p&gt;&amp;quot;Now the strategy is actually being concise, clear, and answering the question, because that&amp;#x27;s directly what the AI is looking for,&amp;quot; Tas explained. &amp;quot;You&amp;#x27;re actually tuning for somewhat of an intelligent model that makes decisions similarly to how we make decisions.&amp;quot;&lt;/p&gt;&lt;p&gt;Consider schema markup, the structured data that helps machines understand web content. While only 30% of websites currently implement comprehensive schema, research shows that pages with proper markup are 36% more likely to appear in AI-generated summaries. Yet most businesses don&amp;#x27;t even know what schema markup is, let alone how to implement it effectively.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Inside Geostar&amp;#x27;s AI agents that optimize websites continuously without human intervention&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Geostar&amp;#x27;s solution embodies a broader trend in enterprise software: the rise of autonomous AI agents that can take action on behalf of businesses. The company embeds what it calls &amp;quot;&lt;a href="https://www.geostar.ai/"&gt;&lt;u&gt;ambient agents&lt;/u&gt;&lt;/a&gt;&amp;quot; directly into client websites, continuously optimizing content, technical configurations, and even creating new pages based on patterns learned across its entire customer base.&lt;/p&gt;&lt;p&gt;&amp;quot;Once we learn something about the way content performs, or the way a technical optimization performs, we can then syndicate that same change across the remaining users so everyone in the network benefits,&amp;quot; McConnell said.&lt;/p&gt;&lt;p&gt;For &lt;a href="https://redsift.com/"&gt;&lt;u&gt;RedSift&lt;/u&gt;&lt;/a&gt;, a cybersecurity company, this approach yielded a 27% increase in AI mentions within three months. In one case, Geostar identified an opportunity to rank for &amp;quot;best DMARC vendors,&amp;quot; a high-value search term in the email security space. The company&amp;#x27;s agents created and optimized content that achieved first-page rankings on both Google and ChatGPT within four days.&lt;/p&gt;&lt;p&gt;&amp;quot;We&amp;#x27;re doing the work of an agency that charges $10,000 a month,&amp;quot; McConnell said, noting that Geostar&amp;#x27;s pricing ranges from $1,000 to $3,000 monthly. &amp;quot;AI creates a situation where, for the first time ever, you can take action like an agency, but you can scale like software.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why brand mentions without links now matter more than ever in the AI era&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The implications of this shift extend far beyond technical optimizations. In the SEO era, a mention without a link was essentially worthless. In the age of AI, that calculus has reversed. AI systems can analyze vast amounts of text to understand sentiment and context, meaning that brand mentions on Reddit, in news articles, or across social media now directly influence how AI systems describe and recommend companies.&lt;/p&gt;&lt;p&gt;&amp;quot;If the New York Times mentions a company without linking to it, that company would actually benefit from that in an AI system,&amp;quot; McConnell explained. &amp;quot;AI has the ability to do mass analysis of huge amounts of text, and it will understand the sentiment around that mention.&amp;quot;&lt;/p&gt;&lt;p&gt;This has created new vulnerabilities. Research from the Indian Institute of Technology and Princeton found that AI systems show systematic bias toward third-party sources over brand-owned content. A company&amp;#x27;s own website might be less influential in shaping AI perceptions than what others say about it online.&lt;/p&gt;&lt;p&gt;The shifting landscape has also disrupted traditional metrics of success. Where SEO focused on rankings and click-through rates, GEO must account for what researchers call impression metrics — how prominently and positively a brand appears within AI-generated responses, even when users never click through to the source.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;A growing market as SEO veterans and new players rush to dominate AI optimization&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Geostar is hardly alone in recognizing this opportunity. Companies like &lt;a href="https://www.brandlight.ai/"&gt;&lt;u&gt;Brandlight&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.tryprofound.com/"&gt;&lt;u&gt;Profound&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://higoodie.com/"&gt;&lt;u&gt;Goodie&lt;/u&gt;&lt;/a&gt; are all racing to help businesses navigate the new landscape. The SEO industry, worth approximately &lt;a href="https://www.grandviewresearch.com/industry-analysis/ai-search-engine-market-report"&gt;&lt;u&gt;$80 billion globally&lt;/u&gt;&lt;/a&gt;, is scrambling to adapt, with established players like Semrush and Ahrefs rushing to add AI visibility tracking features.&lt;/p&gt;&lt;p&gt;But the company&amp;#x27;s founders, who previously built and sold a Y-Combinator-backed e-commerce optimization startup called &lt;a href="https://www.monto.io/"&gt;&lt;u&gt;Monto&lt;/u&gt;&lt;/a&gt;, believe their technical approach gives them an edge. Unlike competitors who largely provide dashboards and recommendations, Geostar&amp;#x27;s agents actively implement changes.&lt;/p&gt;&lt;p&gt;&amp;quot;Everyone is taking the same solutions that worked in the last era and just saying, &amp;#x27;We&amp;#x27;ll do this for AI instead,&amp;#x27;&amp;quot; McConnell argued. &amp;quot;But when you think about what AI is truly capable of, it can actually do the work for you.&amp;quot;&lt;/p&gt;&lt;p&gt;The stakes are particularly high for small and medium-sized businesses. While large corporations can afford to hire specialized consultants or build internal expertise, smaller companies risk becoming invisible in AI-mediated search. Geostar sees this as its primary market opportunity: nearly half of the 33.2 million small businesses in America invest in SEO. Among the roughly 418,000 law firms in the U.S., many spend &lt;a href="https://www.sixthcitymarketing.com/2024/03/25/legal-marketing-stats/"&gt;&lt;u&gt;between $2,500 and $5,000&lt;/u&gt;&lt;/a&gt; monthly on search optimization to stay competitive in local markets.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;From Kurdish village to PearX: The unlikely partnership building the future of search&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;For Tas, whose journey to Silicon Valley began in a tiny Kurdish village in Turkey with just 50 residents, the current moment represents both opportunity and responsibility. His mother&amp;#x27;s battle with cancer prevented him from finishing college, leading him to teach himself programming and eventually partner with McConnell — whom he worked with for an entire year before they ever met in person.&lt;/p&gt;&lt;p&gt;&amp;quot;We&amp;#x27;re not just copy and pasting a solution that was existing before,&amp;quot; Tas emphasized. &amp;quot;This is something that&amp;#x27;s different and was uniquely possible today.&amp;quot;&lt;/p&gt;&lt;p&gt;Looking forward, the transformation of search appears to be accelerating rather than stabilizing. Industry observers predict that search functionality will soon be embedded in productivity tools, wearables, and even augmented reality interfaces. Each new surface will likely have its own optimization requirements, further complicating the landscape.&lt;/p&gt;&lt;p&gt;&amp;quot;Soon, search will be in our eyes, in our ears,&amp;quot; McConnell predicted. &amp;quot;When Siri breaks out of her prison, whatever that Jony Ive and OpenAI are building together will be like a multimodal search interface.&amp;quot;&lt;/p&gt;&lt;p&gt;The technical challenges are matched by ethical ones. As businesses scramble to influence AI recommendations, questions arise about manipulation, fairness, and transparency. There&amp;#x27;s currently no oversight body or established best practices for GEO, creating what some critics describe as a Wild West environment.&lt;/p&gt;&lt;p&gt;As businesses grapple with these changes, one thing seems certain: the era of simply optimizing for Google is over. In its place is emerging a far more complex ecosystem where success requires understanding not just how machines index information, but how they think about it, synthesize it, and ultimately decide what to recommend to humans seeking answers.&lt;/p&gt;&lt;p&gt;For the millions of businesses whose survival depends on being discovered online, mastering this new paradigm isn&amp;#x27;t just an opportunity — it&amp;#x27;s an existential imperative. The question is no longer whether to optimize for AI search, but whether companies can adapt quickly enough to remain visible as the pace of change accelerates.&lt;/p&gt;&lt;p&gt;McConnell&amp;#x27;s parents at the Olympics were a preview of what&amp;#x27;s already becoming the norm. They didn&amp;#x27;t search for tour companies in Paris. They didn&amp;#x27;t scroll through results or click on links. They simply asked ChatGPT what to do — and the AI decided which businesses deserved their attention.&lt;/p&gt;&lt;p&gt;In the new economy of discovery, the businesses that win won&amp;#x27;t be the ones that rank highest. They&amp;#x27;ll be the ones AI chooses to recommend.&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;The moment Mack McConnell knew everything about search had changed came last summer at the Paris Olympics. His parents, independently and without prompting, had both turned to &lt;a href="https://chatgpt.com/"&gt;&lt;u&gt;ChatGPT&lt;/u&gt;&lt;/a&gt; to plan their day&amp;#x27;s activities in the French capital. The AI recommended specific tour companies, restaurants, and attractions — businesses that had won a new kind of visibility lottery.&lt;/p&gt;&lt;p&gt;&amp;quot;It was almost like this intuitive interface that older people were as comfortable with using as younger people,&amp;quot; McConnell recalled in an exclusive interview with VentureBeat. &amp;quot;I could just see the businesses were now being recommended.&amp;quot;&lt;/p&gt;&lt;p&gt;That observation has now become the foundation of &lt;a href="https://www.geostar.ai/"&gt;&lt;u&gt;Geostar&lt;/u&gt;&lt;/a&gt;, a Pear VC-backed startup that&amp;#x27;s racing to help businesses navigate what may be the most significant shift in online discovery since Google&amp;#x27;s founding. &lt;/p&gt;&lt;p&gt;The company, which recently emerged from stealth with impressive early customer traction, is betting that the rise of AI-powered search represents a significant opportunity to reinvent how companies get found online. The &lt;a href="https://www.coherentmarketinsights.com/industry-reports/ai-search-engines-market"&gt;&lt;u&gt;global AI search engine market&lt;/u&gt;&lt;/a&gt; alone is projected to grow from $43.63 billion in 2025 to $108.88 billion by 2032.&lt;/p&gt;&lt;p&gt;Already the fastest-growing company in &lt;a href="https://pear.vc/inside-pearx-partnering-with-founders-the-pear-way/"&gt;&lt;u&gt;PearX&amp;#x27;s latest cohort&lt;/u&gt;&lt;/a&gt;, Geostar is fast approaching $1 million in annual recurring revenue in just four months — with only two founders and no employees.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why Gartner predicts traditional search volume will decline 25% by 2026&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The numbers tell a stark story of disruption. Gartner predicts that traditional search engine volume will &lt;a href="https://www.forbes.com/councils/forbesagencycouncil/2025/10/23/generative-engine-optimization-the-next-frontier-in-seo/"&gt;&lt;u&gt;decline by 25% by 2026&lt;/u&gt;&lt;/a&gt;, largely due to the rise of AI chatbots. Google&amp;#x27;s AI Overviews now appear on &lt;a href="https://techcrunch.com/2025/04/25/googles-ai-search-numbers-are-growing-and-thats-by-design/"&gt;&lt;u&gt;billions of searches&lt;/u&gt;&lt;/a&gt; monthly. Princeton University researchers have found that optimizing for these new AI systems can increase visibility &lt;a href="https://arxiv.org/pdf/2311.09735"&gt;&lt;u&gt;by up to 40%&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&amp;quot;Search used to mean that you had to make Google happy,&amp;quot; McConnell explained. &amp;quot;But now you have to optimize for four different Google interfaces — traditional search, AI Mode, Gemini, and AI Overviews — each with different criteria. And then ChatGPT, Claude, and Perplexity each work differently on top of that.&amp;quot;&lt;/p&gt;&lt;p&gt;This fragmentation is creating chaos for businesses that have spent decades perfecting their Google search strategies. A recent &lt;a href="https://www.forrester.com/press-newsroom/forrester-the-state-of-business-buying-2024/"&gt;&lt;u&gt;Forrester study&lt;/u&gt;&lt;/a&gt; found that 95% of B2B buyers plan to use generative AI in future purchase decisions. Yet most companies remain woefully unprepared for this shift.&lt;/p&gt;&lt;p&gt;&amp;quot;Anybody who&amp;#x27;s not on this right now is losing out,&amp;quot; said Cihan Tas, Geostar&amp;#x27;s co-founder and chief technology officer. &amp;quot;We see lawyers getting 50% of their clients through ChatGPT now. It&amp;#x27;s just such a massive shift.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How language models read the web differently than search engines ever did&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;What &lt;a href="https://www.geostar.ai/"&gt;&lt;u&gt;Geostar&lt;/u&gt;&lt;/a&gt; and a growing cohort of competitors call Generative Engine Optimization or GEO represents a fundamental departure from traditional search engine optimization. Where SEO focused primarily on keywords and backlinks, GEO requires understanding how large language models parse, understand, and synthesize information across the entire web.&lt;/p&gt;&lt;p&gt;The technical challenges are formidable. Every website must now function as what Tas calls &amp;quot;its own little database&amp;quot; capable of being understood by dozens of different AI crawlers, each with unique requirements and preferences. Google&amp;#x27;s systems pull from their existing search index. &lt;a href="https://chatgpt.com/"&gt;&lt;u&gt;ChatGPT&lt;/u&gt;&lt;/a&gt; relies heavily on structured data and specific content formats. Perplexity shows a marked preference for Wikipedia and authoritative sources.&lt;/p&gt;&lt;p&gt;&amp;quot;Now the strategy is actually being concise, clear, and answering the question, because that&amp;#x27;s directly what the AI is looking for,&amp;quot; Tas explained. &amp;quot;You&amp;#x27;re actually tuning for somewhat of an intelligent model that makes decisions similarly to how we make decisions.&amp;quot;&lt;/p&gt;&lt;p&gt;Consider schema markup, the structured data that helps machines understand web content. While only 30% of websites currently implement comprehensive schema, research shows that pages with proper markup are 36% more likely to appear in AI-generated summaries. Yet most businesses don&amp;#x27;t even know what schema markup is, let alone how to implement it effectively.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Inside Geostar&amp;#x27;s AI agents that optimize websites continuously without human intervention&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Geostar&amp;#x27;s solution embodies a broader trend in enterprise software: the rise of autonomous AI agents that can take action on behalf of businesses. The company embeds what it calls &amp;quot;&lt;a href="https://www.geostar.ai/"&gt;&lt;u&gt;ambient agents&lt;/u&gt;&lt;/a&gt;&amp;quot; directly into client websites, continuously optimizing content, technical configurations, and even creating new pages based on patterns learned across its entire customer base.&lt;/p&gt;&lt;p&gt;&amp;quot;Once we learn something about the way content performs, or the way a technical optimization performs, we can then syndicate that same change across the remaining users so everyone in the network benefits,&amp;quot; McConnell said.&lt;/p&gt;&lt;p&gt;For &lt;a href="https://redsift.com/"&gt;&lt;u&gt;RedSift&lt;/u&gt;&lt;/a&gt;, a cybersecurity company, this approach yielded a 27% increase in AI mentions within three months. In one case, Geostar identified an opportunity to rank for &amp;quot;best DMARC vendors,&amp;quot; a high-value search term in the email security space. The company&amp;#x27;s agents created and optimized content that achieved first-page rankings on both Google and ChatGPT within four days.&lt;/p&gt;&lt;p&gt;&amp;quot;We&amp;#x27;re doing the work of an agency that charges $10,000 a month,&amp;quot; McConnell said, noting that Geostar&amp;#x27;s pricing ranges from $1,000 to $3,000 monthly. &amp;quot;AI creates a situation where, for the first time ever, you can take action like an agency, but you can scale like software.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why brand mentions without links now matter more than ever in the AI era&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The implications of this shift extend far beyond technical optimizations. In the SEO era, a mention without a link was essentially worthless. In the age of AI, that calculus has reversed. AI systems can analyze vast amounts of text to understand sentiment and context, meaning that brand mentions on Reddit, in news articles, or across social media now directly influence how AI systems describe and recommend companies.&lt;/p&gt;&lt;p&gt;&amp;quot;If the New York Times mentions a company without linking to it, that company would actually benefit from that in an AI system,&amp;quot; McConnell explained. &amp;quot;AI has the ability to do mass analysis of huge amounts of text, and it will understand the sentiment around that mention.&amp;quot;&lt;/p&gt;&lt;p&gt;This has created new vulnerabilities. Research from the Indian Institute of Technology and Princeton found that AI systems show systematic bias toward third-party sources over brand-owned content. A company&amp;#x27;s own website might be less influential in shaping AI perceptions than what others say about it online.&lt;/p&gt;&lt;p&gt;The shifting landscape has also disrupted traditional metrics of success. Where SEO focused on rankings and click-through rates, GEO must account for what researchers call impression metrics — how prominently and positively a brand appears within AI-generated responses, even when users never click through to the source.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;A growing market as SEO veterans and new players rush to dominate AI optimization&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Geostar is hardly alone in recognizing this opportunity. Companies like &lt;a href="https://www.brandlight.ai/"&gt;&lt;u&gt;Brandlight&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.tryprofound.com/"&gt;&lt;u&gt;Profound&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://higoodie.com/"&gt;&lt;u&gt;Goodie&lt;/u&gt;&lt;/a&gt; are all racing to help businesses navigate the new landscape. The SEO industry, worth approximately &lt;a href="https://www.grandviewresearch.com/industry-analysis/ai-search-engine-market-report"&gt;&lt;u&gt;$80 billion globally&lt;/u&gt;&lt;/a&gt;, is scrambling to adapt, with established players like Semrush and Ahrefs rushing to add AI visibility tracking features.&lt;/p&gt;&lt;p&gt;But the company&amp;#x27;s founders, who previously built and sold a Y-Combinator-backed e-commerce optimization startup called &lt;a href="https://www.monto.io/"&gt;&lt;u&gt;Monto&lt;/u&gt;&lt;/a&gt;, believe their technical approach gives them an edge. Unlike competitors who largely provide dashboards and recommendations, Geostar&amp;#x27;s agents actively implement changes.&lt;/p&gt;&lt;p&gt;&amp;quot;Everyone is taking the same solutions that worked in the last era and just saying, &amp;#x27;We&amp;#x27;ll do this for AI instead,&amp;#x27;&amp;quot; McConnell argued. &amp;quot;But when you think about what AI is truly capable of, it can actually do the work for you.&amp;quot;&lt;/p&gt;&lt;p&gt;The stakes are particularly high for small and medium-sized businesses. While large corporations can afford to hire specialized consultants or build internal expertise, smaller companies risk becoming invisible in AI-mediated search. Geostar sees this as its primary market opportunity: nearly half of the 33.2 million small businesses in America invest in SEO. Among the roughly 418,000 law firms in the U.S., many spend &lt;a href="https://www.sixthcitymarketing.com/2024/03/25/legal-marketing-stats/"&gt;&lt;u&gt;between $2,500 and $5,000&lt;/u&gt;&lt;/a&gt; monthly on search optimization to stay competitive in local markets.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;From Kurdish village to PearX: The unlikely partnership building the future of search&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;For Tas, whose journey to Silicon Valley began in a tiny Kurdish village in Turkey with just 50 residents, the current moment represents both opportunity and responsibility. His mother&amp;#x27;s battle with cancer prevented him from finishing college, leading him to teach himself programming and eventually partner with McConnell — whom he worked with for an entire year before they ever met in person.&lt;/p&gt;&lt;p&gt;&amp;quot;We&amp;#x27;re not just copy and pasting a solution that was existing before,&amp;quot; Tas emphasized. &amp;quot;This is something that&amp;#x27;s different and was uniquely possible today.&amp;quot;&lt;/p&gt;&lt;p&gt;Looking forward, the transformation of search appears to be accelerating rather than stabilizing. Industry observers predict that search functionality will soon be embedded in productivity tools, wearables, and even augmented reality interfaces. Each new surface will likely have its own optimization requirements, further complicating the landscape.&lt;/p&gt;&lt;p&gt;&amp;quot;Soon, search will be in our eyes, in our ears,&amp;quot; McConnell predicted. &amp;quot;When Siri breaks out of her prison, whatever that Jony Ive and OpenAI are building together will be like a multimodal search interface.&amp;quot;&lt;/p&gt;&lt;p&gt;The technical challenges are matched by ethical ones. As businesses scramble to influence AI recommendations, questions arise about manipulation, fairness, and transparency. There&amp;#x27;s currently no oversight body or established best practices for GEO, creating what some critics describe as a Wild West environment.&lt;/p&gt;&lt;p&gt;As businesses grapple with these changes, one thing seems certain: the era of simply optimizing for Google is over. In its place is emerging a far more complex ecosystem where success requires understanding not just how machines index information, but how they think about it, synthesize it, and ultimately decide what to recommend to humans seeking answers.&lt;/p&gt;&lt;p&gt;For the millions of businesses whose survival depends on being discovered online, mastering this new paradigm isn&amp;#x27;t just an opportunity — it&amp;#x27;s an existential imperative. The question is no longer whether to optimize for AI search, but whether companies can adapt quickly enough to remain visible as the pace of change accelerates.&lt;/p&gt;&lt;p&gt;McConnell&amp;#x27;s parents at the Olympics were a preview of what&amp;#x27;s already becoming the norm. They didn&amp;#x27;t search for tour companies in Paris. They didn&amp;#x27;t scroll through results or click on links. They simply asked ChatGPT what to do — and the AI decided which businesses deserved their attention.&lt;/p&gt;&lt;p&gt;In the new economy of discovery, the businesses that win won&amp;#x27;t be the ones that rank highest. They&amp;#x27;ll be the ones AI chooses to recommend.&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/geostar-pioneers-geo-as-traditional-seo-faces-25-decline-from-ai-chatbots</guid><pubDate>Wed, 29 Oct 2025 07:00:00 +0000</pubDate></item><item><title>OpenAI unveils open-weight AI safety models for developers (AI News)</title><link>https://www.artificialintelligence-news.com/news/openai-unveils-open-weight-ai-safety-models-for-developers/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/openai-new-ai-safety-models-artificial-intelligence-developers-open-development-gpt.jpg" /&gt;&lt;/div&gt;&lt;p&gt;We use technologies like cookies to store and/or access device information. We do this to improve browsing experience and to show personalized ads. Consenting to these technologies will allow us to process data such as browsing behavior or unique IDs on this site. Not consenting or withdrawing consent, may adversely affect certain features and functions.&lt;/p&gt;&lt;!-- categories start --&gt;&lt;div class="cmplz-categories"&gt; &lt;details class="cmplz-category cmplz-functional"&gt;   &lt;p&gt; &lt;span class="cmplz-description-functional"&gt;The technical storage or access is strictly necessary for the legitimate purpose of enabling the use of a specific service explicitly requested by the subscriber or user, or for the sole purpose of carrying out the transmission of a communication over an electronic communications network.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt; &lt;details class="cmplz-category cmplz-preferences"&gt;   &lt;p&gt; &lt;span class="cmplz-description-preferences"&gt;The technical storage or access is necessary for the legitimate purpose of storing preferences that are not requested by the subscriber or user.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt; &lt;details class="cmplz-category cmplz-statistics"&gt;   &lt;p&gt; &lt;span class="cmplz-description-statistics"&gt;The technical storage or access that is used exclusively for statistical purposes.&lt;/span&gt; &lt;span class="cmplz-description-statistics-anonymous"&gt;The technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt; &lt;details class="cmplz-category cmplz-marketing"&gt;   &lt;p&gt; &lt;span class="cmplz-description-marketing"&gt;The technical storage or access is required to create user profiles to send advertising, or to track the user on a website or across several websites for similar marketing purposes.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt;&lt;/div&gt;&lt;!-- categories end --&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/openai-new-ai-safety-models-artificial-intelligence-developers-open-development-gpt.jpg" /&gt;&lt;/div&gt;&lt;p&gt;We use technologies like cookies to store and/or access device information. We do this to improve browsing experience and to show personalized ads. Consenting to these technologies will allow us to process data such as browsing behavior or unique IDs on this site. Not consenting or withdrawing consent, may adversely affect certain features and functions.&lt;/p&gt;&lt;!-- categories start --&gt;&lt;div class="cmplz-categories"&gt; &lt;details class="cmplz-category cmplz-functional"&gt;   &lt;p&gt; &lt;span class="cmplz-description-functional"&gt;The technical storage or access is strictly necessary for the legitimate purpose of enabling the use of a specific service explicitly requested by the subscriber or user, or for the sole purpose of carrying out the transmission of a communication over an electronic communications network.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt; &lt;details class="cmplz-category cmplz-preferences"&gt;   &lt;p&gt; &lt;span class="cmplz-description-preferences"&gt;The technical storage or access is necessary for the legitimate purpose of storing preferences that are not requested by the subscriber or user.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt; &lt;details class="cmplz-category cmplz-statistics"&gt;   &lt;p&gt; &lt;span class="cmplz-description-statistics"&gt;The technical storage or access that is used exclusively for statistical purposes.&lt;/span&gt; &lt;span class="cmplz-description-statistics-anonymous"&gt;The technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt; &lt;details class="cmplz-category cmplz-marketing"&gt;   &lt;p&gt; &lt;span class="cmplz-description-marketing"&gt;The technical storage or access is required to create user profiles to send advertising, or to track the user on a website or across several websites for similar marketing purposes.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt;&lt;/div&gt;&lt;!-- categories end --&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/openai-unveils-open-weight-ai-safety-models-for-developers/</guid><pubDate>Wed, 29 Oct 2025 09:31:52 +0000</pubDate></item><item><title>DeepSeek may have found a new way to improve AI’s ability to remember (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/29/1126932/deepseek-ocr-visual-compression/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/ocr-patches2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 chronoton/executive-summary_0"&gt;&lt;div class="chronotonExecutiveSummary__summaryContainer--3bc10da0658ecd8e2ef22c6023461fb5"&gt;&lt;button class="chronotonExecutiveSummary__toggleButton--1cd6118db37e8a8252fc4cd8bbadcb85" type="button"&gt;&lt;span class="chronotonExecutiveSummary__toggleText--a713e14989fe65c5162db2b69cb422c9"&gt;EXECUTIVE SUMMARY&lt;/span&gt;&lt;svg class="chronotonExecutiveSummary__toggleArrow--a8c1be9c06a9f066a767b3af80d859a1" fill="none" height="7" viewBox="0 0 11 7" width="11" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M1 1L5.5 5.5L10 1" stroke="#58C0B3" stroke-linecap="round" stroke-width="1.5"&gt;&lt;/svg&gt;&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_1"&gt; &lt;p&gt;An AI model released by the Chinese AI company DeepSeek uses new techniques that could significantly improve AI’s ability to “remember.”&lt;/p&gt;  &lt;p&gt;Released last week, the optical character recognition (OCR) model works by extracting text from an image and turning it into machine-readable words. This is the same technology that powers scanner apps, translation of text in photos, and many accessibility tools.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;OCR is already a mature field with numerous high-performing systems, and according to the paper and some early reviews, DeepSeek’s new model performs on par with top models on key benchmarks.&lt;/p&gt;  &lt;p&gt;But researchers say the model’s main innovation lies in how it processes information—specifically, how it stores and retrieves memories. Improving how AI models “remember” information could reduce the computing power they need to run, thus mitigating AI’s large (and growing) carbon footprint.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;Currently, most large language models break text down into thousands of tiny units called tokens. This turns the text into representations that models can understand. However, these tokens quickly become expensive to store and compute with as conversations with end users grow longer. When a user chats with an AI for lengthy periods, this challenge can cause the AI to forget things it’s been told and get information muddled, a problem some call “context rot.”&lt;/p&gt;  &lt;p&gt;The new methods developed by DeepSeek (and published in its latest paper) could help to overcome this issue. Instead of storing words as tokens, its system packs written information into image form, almost as if it’s taking a picture of pages from a book. This allows the model to retain nearly the same information while using far fewer tokens, the researchers found.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Essentially, the OCR model is a test bed for these new methods that permit more information to be packed into AI models more efficiently.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Besides using visual tokens instead of just text tokens, the model is built on a type of tiered compression that is not unlike how human memories fade: Older or less critical content is stored in a slightly more blurry form in order to save space. Despite that, the paper’s authors argue, this compressed content can still remain accessible in the background while maintaining a high level of system efficiency.&lt;/p&gt;  &lt;p&gt;Text tokens have long been the default building block in AI systems. Using visual tokens instead is unconventional, and as a result, DeepSeek’s model is quickly capturing researchers’ attention. Andrej Karpathy, the former Tesla AI chief and a founding member of OpenAI, praised the paper on X, saying that images may ultimately be better than text as inputs for LLMs. Text tokens might be “wasteful and just terrible at the input,” he wrote.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Manling Li, an assistant professor of computer science at Northwestern University, says the paper offers a new framework for addressing the existing challenges in AI memory. “While the idea of using image-based tokens for context storage isn’t entirely new, this is the first study I’ve seen that takes it this far and shows it might actually work,” Li says.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__container--08c53dd3bc9bd04e1e42e5f7ca641ab2"&gt;&lt;div class="whyItMatters__header--19f7f372f181cc6d4c06bc7362a44382"&gt;&lt;div class="whyItMatters__title--4af28c786a2bc93df05db111c6c30618"&gt;&lt;span class="whyItMatters__askAi--577f5fe6f54de43e37258d0f2aff4394"&gt;Ask AI&lt;/span&gt;&lt;div&gt;&lt;span class="whyItMatters__whyItMattersTitle--a3694998bb578e159bbd16690b8da390"&gt;Why it matters to you?&lt;/span&gt;&lt;span class="whyItMatters__betaBadge--9e84228b864d33d5b55479433fc91b8a"&gt;BETA&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__description--e1334886c092fa469388d7a24e1e1a55"&gt;&lt;span class="initial-description"&gt;Here’s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates—it might get weird&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="whyItMatters__questionContainer--ec1159210954852b9178c549600959a0"&gt;&lt;div&gt;&lt;button class="whyItMatters__actionButton--674934b6df433ac81e613372979cdb6c" type="button"&gt;Tell me why it matters&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;The method could open up new possibilities in AI research and applications, especially in creating more useful AI agents, says Zihan Wang, a PhD candidate at Northwestern University. He believes that since conversations with AI are continuous, this approach could help models remember more and assist users more effectively.&lt;/p&gt;  &lt;p&gt;The technique can also be used to produce more training data for AI models. Model developers are currently grappling with a severe shortage of quality text to train systems on. But the DeepSeek paper says that the company’s OCR system can generate over 200,000 pages of training data a day on a single GPU.&lt;/p&gt;  &lt;p&gt;The model and paper, however, are only an early exploration of using image tokens rather than text tokens for AI memorization. Li says she hopes to see visual tokens applied not just to memory storage but also to reasoning. Future work, she says, should explore how to make AI’s memory fade in a more dynamic way, akin to how we can recall a life-changing moment from years ago but forget what we ate for lunch last week. Currently, even with DeepSeek’s methods, AI tends to forget and remember in a very linear way—recalling whatever was most recent, but not necessarily what was most important, she says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Despite its attempts to keep a low profile, DeepSeek, based in Hangzhou, China, has built a reputation for pushing the frontier in AI research. The company shocked the industry at the start of this year with the release of DeepSeek-R1, an open-source reasoning model that rivaled leading Western systems in performance despite using far fewer computing resources.&amp;nbsp;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/ocr-patches2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 chronoton/executive-summary_0"&gt;&lt;div class="chronotonExecutiveSummary__summaryContainer--3bc10da0658ecd8e2ef22c6023461fb5"&gt;&lt;button class="chronotonExecutiveSummary__toggleButton--1cd6118db37e8a8252fc4cd8bbadcb85" type="button"&gt;&lt;span class="chronotonExecutiveSummary__toggleText--a713e14989fe65c5162db2b69cb422c9"&gt;EXECUTIVE SUMMARY&lt;/span&gt;&lt;svg class="chronotonExecutiveSummary__toggleArrow--a8c1be9c06a9f066a767b3af80d859a1" fill="none" height="7" viewBox="0 0 11 7" width="11" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M1 1L5.5 5.5L10 1" stroke="#58C0B3" stroke-linecap="round" stroke-width="1.5"&gt;&lt;/svg&gt;&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_1"&gt; &lt;p&gt;An AI model released by the Chinese AI company DeepSeek uses new techniques that could significantly improve AI’s ability to “remember.”&lt;/p&gt;  &lt;p&gt;Released last week, the optical character recognition (OCR) model works by extracting text from an image and turning it into machine-readable words. This is the same technology that powers scanner apps, translation of text in photos, and many accessibility tools.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;OCR is already a mature field with numerous high-performing systems, and according to the paper and some early reviews, DeepSeek’s new model performs on par with top models on key benchmarks.&lt;/p&gt;  &lt;p&gt;But researchers say the model’s main innovation lies in how it processes information—specifically, how it stores and retrieves memories. Improving how AI models “remember” information could reduce the computing power they need to run, thus mitigating AI’s large (and growing) carbon footprint.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;Currently, most large language models break text down into thousands of tiny units called tokens. This turns the text into representations that models can understand. However, these tokens quickly become expensive to store and compute with as conversations with end users grow longer. When a user chats with an AI for lengthy periods, this challenge can cause the AI to forget things it’s been told and get information muddled, a problem some call “context rot.”&lt;/p&gt;  &lt;p&gt;The new methods developed by DeepSeek (and published in its latest paper) could help to overcome this issue. Instead of storing words as tokens, its system packs written information into image form, almost as if it’s taking a picture of pages from a book. This allows the model to retain nearly the same information while using far fewer tokens, the researchers found.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Essentially, the OCR model is a test bed for these new methods that permit more information to be packed into AI models more efficiently.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Besides using visual tokens instead of just text tokens, the model is built on a type of tiered compression that is not unlike how human memories fade: Older or less critical content is stored in a slightly more blurry form in order to save space. Despite that, the paper’s authors argue, this compressed content can still remain accessible in the background while maintaining a high level of system efficiency.&lt;/p&gt;  &lt;p&gt;Text tokens have long been the default building block in AI systems. Using visual tokens instead is unconventional, and as a result, DeepSeek’s model is quickly capturing researchers’ attention. Andrej Karpathy, the former Tesla AI chief and a founding member of OpenAI, praised the paper on X, saying that images may ultimately be better than text as inputs for LLMs. Text tokens might be “wasteful and just terrible at the input,” he wrote.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Manling Li, an assistant professor of computer science at Northwestern University, says the paper offers a new framework for addressing the existing challenges in AI memory. “While the idea of using image-based tokens for context storage isn’t entirely new, this is the first study I’ve seen that takes it this far and shows it might actually work,” Li says.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__container--08c53dd3bc9bd04e1e42e5f7ca641ab2"&gt;&lt;div class="whyItMatters__header--19f7f372f181cc6d4c06bc7362a44382"&gt;&lt;div class="whyItMatters__title--4af28c786a2bc93df05db111c6c30618"&gt;&lt;span class="whyItMatters__askAi--577f5fe6f54de43e37258d0f2aff4394"&gt;Ask AI&lt;/span&gt;&lt;div&gt;&lt;span class="whyItMatters__whyItMattersTitle--a3694998bb578e159bbd16690b8da390"&gt;Why it matters to you?&lt;/span&gt;&lt;span class="whyItMatters__betaBadge--9e84228b864d33d5b55479433fc91b8a"&gt;BETA&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__description--e1334886c092fa469388d7a24e1e1a55"&gt;&lt;span class="initial-description"&gt;Here’s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates—it might get weird&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="whyItMatters__questionContainer--ec1159210954852b9178c549600959a0"&gt;&lt;div&gt;&lt;button class="whyItMatters__actionButton--674934b6df433ac81e613372979cdb6c" type="button"&gt;Tell me why it matters&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;The method could open up new possibilities in AI research and applications, especially in creating more useful AI agents, says Zihan Wang, a PhD candidate at Northwestern University. He believes that since conversations with AI are continuous, this approach could help models remember more and assist users more effectively.&lt;/p&gt;  &lt;p&gt;The technique can also be used to produce more training data for AI models. Model developers are currently grappling with a severe shortage of quality text to train systems on. But the DeepSeek paper says that the company’s OCR system can generate over 200,000 pages of training data a day on a single GPU.&lt;/p&gt;  &lt;p&gt;The model and paper, however, are only an early exploration of using image tokens rather than text tokens for AI memorization. Li says she hopes to see visual tokens applied not just to memory storage but also to reasoning. Future work, she says, should explore how to make AI’s memory fade in a more dynamic way, akin to how we can recall a life-changing moment from years ago but forget what we ate for lunch last week. Currently, even with DeepSeek’s methods, AI tends to forget and remember in a very linear way—recalling whatever was most recent, but not necessarily what was most important, she says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Despite its attempts to keep a low profile, DeepSeek, based in Hangzhou, China, has built a reputation for pushing the frontier in AI research. The company shocked the industry at the start of this year with the release of DeepSeek-R1, an open-source reasoning model that rivaled leading Western systems in performance despite using far fewer computing resources.&amp;nbsp;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/29/1126932/deepseek-ocr-visual-compression/</guid><pubDate>Wed, 29 Oct 2025 10:00:00 +0000</pubDate></item><item><title>The AI Hype Index: Data centers’ neighbors are pivoting to power blackouts (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/29/1126834/the-ai-hype-index-data-centers-neighbors-are-pivoting-to-power-blackouts/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/October-thumb.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt;&lt;p&gt;Separating AI reality from hyped-up fiction isn’t always easy. That’s why we’ve created the AI Hype Index—a simple, at-a-glance summary of everything you need to know about the state of the industry.&lt;/p&gt;    &lt;p&gt;Just about all businesses these days seem to be pivoting to AI, even when they don’t seem to know exactly why they’re investing in it—or even what it really does. “Optimization,” “scaling,” and “maximizing efficiency” are convenient buzzwords bandied about to describe what AI can achieve in theory, but for most of AI companies’ eager customers, the hundreds of billions of dollars they’re pumping into the industry aren’t adding up. And maybe they never will.&lt;/p&gt;  &lt;p&gt;This month’s news doesn’t exactly cast the technology in a glowing light either. A bunch of NGOs and aid agencies are using AI models to generate images of fake suffering people to guilt their Instagram followers. AI translators are pumping out low-quality Wikipedia pages in the languages most vulnerable to going extinct. And thanks to the construction of new AI data centers, lots of neighborhoods living in their shadows are getting forced into their own sort of pivots—fighting back against the power blackouts and water shortages the data centers cause. How’s that for optimization?&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/October-thumb.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt;&lt;p&gt;Separating AI reality from hyped-up fiction isn’t always easy. That’s why we’ve created the AI Hype Index—a simple, at-a-glance summary of everything you need to know about the state of the industry.&lt;/p&gt;    &lt;p&gt;Just about all businesses these days seem to be pivoting to AI, even when they don’t seem to know exactly why they’re investing in it—or even what it really does. “Optimization,” “scaling,” and “maximizing efficiency” are convenient buzzwords bandied about to describe what AI can achieve in theory, but for most of AI companies’ eager customers, the hundreds of billions of dollars they’re pumping into the industry aren’t adding up. And maybe they never will.&lt;/p&gt;  &lt;p&gt;This month’s news doesn’t exactly cast the technology in a glowing light either. A bunch of NGOs and aid agencies are using AI models to generate images of fake suffering people to guilt their Instagram followers. AI translators are pumping out low-quality Wikipedia pages in the languages most vulnerable to going extinct. And thanks to the construction of new AI data centers, lots of neighborhoods living in their shadows are getting forced into their own sort of pivots—fighting back against the power blackouts and water shortages the data centers cause. How’s that for optimization?&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/29/1126834/the-ai-hype-index-data-centers-neighbors-are-pivoting-to-power-blackouts/</guid><pubDate>Wed, 29 Oct 2025 10:41:19 +0000</pubDate></item><item><title>Counterintuitive’s new chip aims escape the AI ‘twin trap’ (AI News)</title><link>https://www.artificialintelligence-news.com/news/ai-twin-trap-next-generation-chip-and-software/</link><description>&lt;p&gt;AI startup company, Counterintuitive, has set out to build “reasoning-native computing,” enabling machines to understand rather than simply mimic. Such a breakthrough has the potential to shift AI from pattern recognition to genuine comprehension, paving the way for systems that can think and make decisions – in other words, to be more “human-like.”&lt;/p&gt;&lt;p&gt;Counterintuitive Chairman, Gerard Rego, spoke of what the company terms the ‘twin trap’ problem facing AI, stating the company’s first goal is to solve two key problems that limit current AI systems that prevent even the largest AI systems from being stable, efficient, and genuinely intelligent.&lt;/p&gt;&lt;p&gt;The first trap highlights how today’s AI systems lack reliable, reproducible numerical foundations, having been built on outdated mathematical grounds. Examples include floating-point arithmetic that was designed decades ago for speed in tasks including gaming and graphics. Precision and consistency is therefore lacking.&lt;/p&gt;&lt;p&gt;In numerical systems, each mathematical operation introduces tiny rounding errors that can build up over time. Because of this, running the same AI model twice can provide different results, causing non-determinism. Inconsistency of this nature makes it harder to verify, reproduce, and/or audit AI decisions, particularly in fields like law, finance, and healthcare. If AI outputs can not be explained or proven clearly, they become ‘hallucinations’ – a term coined for their “lack of provability.”&lt;/p&gt;&lt;p&gt;Modern AI has a fundamental struggle with precision that lacks truth, creating an invisible wall. The flaw has become a rigid limit, affecting overall performances, increasing costs, and wasting energy on noise corrections.&lt;/p&gt;&lt;p&gt;Modern AI struggles with precision that lacks truth, creating an invisible wall. The flaw has turned into a rigid limit, affecting performance, increasing costs, and wasting energy on computational noise corrections.&lt;/p&gt;&lt;p&gt;The second trap is found in architecture. Current AI models have no memory. Instead, they predict the next frame or token with no reasoning that helped them achieve the prediction. It’s like predictive text, just on steroids, the company says. Once modern models output something, they don’t retain why they made such a decision and are unable to revisit or build on their own reasoning. It may appear that AI has reason, but it’s only mimicking reasoning, not truly understanding how conclusions are reached.&lt;/p&gt;&lt;p&gt;“Counterintuitive is building a world-class team of mathematicians, computer scientists, physicists and engineers who are veterans of leading global research labs and technology companies, and who understand the Twin Trap fundamental and solve it,” Rego said.&lt;/p&gt;&lt;p&gt;Rego’s team has more than 80 patents pending, spanning deterministic reasoning hardware, causal memory systems, and software frameworks that it believes has the potential to “define the next generation of computing based on reasoning – not mimicry.”&lt;/p&gt;&lt;p&gt;Counterintuitive’s reasoning-native computing research aims to produce the first reasoning chip and software reasoning stack that pushes AI beyond its current limits.&lt;/p&gt;&lt;p&gt;The company’s artificial reasoning unit (ARU) is a new type of compute, rather than a processor, that focuses on memory-driven reasoning and executes causal logic in silicon, unlike GPUs. “Our ARU stack is more than a new chip category being developed – it’s a clean break from probabilistic computing,” said Counterintuitive co-founder, Syam Appala.&lt;/p&gt;&lt;p&gt;“The ARU will usher in the next age of computing, redefining intelligence from imitation to understanding and powering the applications that impact the most important sectors of the economy without the need for massive hardware, data centre and energy budgets.”&lt;/p&gt;&lt;p&gt;By integrating memory-driven causal logic into both hardware and software, Counterintuitive aims to develop systems that are more reliable and auditable. It marks a shift from traditional speed-focused, probabilistic AI black-box models towards more transparent and accountable reasoning.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “Abacus” by blaahhi is licensed under CC BY 2.0.)&lt;/em&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;AI startup company, Counterintuitive, has set out to build “reasoning-native computing,” enabling machines to understand rather than simply mimic. Such a breakthrough has the potential to shift AI from pattern recognition to genuine comprehension, paving the way for systems that can think and make decisions – in other words, to be more “human-like.”&lt;/p&gt;&lt;p&gt;Counterintuitive Chairman, Gerard Rego, spoke of what the company terms the ‘twin trap’ problem facing AI, stating the company’s first goal is to solve two key problems that limit current AI systems that prevent even the largest AI systems from being stable, efficient, and genuinely intelligent.&lt;/p&gt;&lt;p&gt;The first trap highlights how today’s AI systems lack reliable, reproducible numerical foundations, having been built on outdated mathematical grounds. Examples include floating-point arithmetic that was designed decades ago for speed in tasks including gaming and graphics. Precision and consistency is therefore lacking.&lt;/p&gt;&lt;p&gt;In numerical systems, each mathematical operation introduces tiny rounding errors that can build up over time. Because of this, running the same AI model twice can provide different results, causing non-determinism. Inconsistency of this nature makes it harder to verify, reproduce, and/or audit AI decisions, particularly in fields like law, finance, and healthcare. If AI outputs can not be explained or proven clearly, they become ‘hallucinations’ – a term coined for their “lack of provability.”&lt;/p&gt;&lt;p&gt;Modern AI has a fundamental struggle with precision that lacks truth, creating an invisible wall. The flaw has become a rigid limit, affecting overall performances, increasing costs, and wasting energy on noise corrections.&lt;/p&gt;&lt;p&gt;Modern AI struggles with precision that lacks truth, creating an invisible wall. The flaw has turned into a rigid limit, affecting performance, increasing costs, and wasting energy on computational noise corrections.&lt;/p&gt;&lt;p&gt;The second trap is found in architecture. Current AI models have no memory. Instead, they predict the next frame or token with no reasoning that helped them achieve the prediction. It’s like predictive text, just on steroids, the company says. Once modern models output something, they don’t retain why they made such a decision and are unable to revisit or build on their own reasoning. It may appear that AI has reason, but it’s only mimicking reasoning, not truly understanding how conclusions are reached.&lt;/p&gt;&lt;p&gt;“Counterintuitive is building a world-class team of mathematicians, computer scientists, physicists and engineers who are veterans of leading global research labs and technology companies, and who understand the Twin Trap fundamental and solve it,” Rego said.&lt;/p&gt;&lt;p&gt;Rego’s team has more than 80 patents pending, spanning deterministic reasoning hardware, causal memory systems, and software frameworks that it believes has the potential to “define the next generation of computing based on reasoning – not mimicry.”&lt;/p&gt;&lt;p&gt;Counterintuitive’s reasoning-native computing research aims to produce the first reasoning chip and software reasoning stack that pushes AI beyond its current limits.&lt;/p&gt;&lt;p&gt;The company’s artificial reasoning unit (ARU) is a new type of compute, rather than a processor, that focuses on memory-driven reasoning and executes causal logic in silicon, unlike GPUs. “Our ARU stack is more than a new chip category being developed – it’s a clean break from probabilistic computing,” said Counterintuitive co-founder, Syam Appala.&lt;/p&gt;&lt;p&gt;“The ARU will usher in the next age of computing, redefining intelligence from imitation to understanding and powering the applications that impact the most important sectors of the economy without the need for massive hardware, data centre and energy budgets.”&lt;/p&gt;&lt;p&gt;By integrating memory-driven causal logic into both hardware and software, Counterintuitive aims to develop systems that are more reliable and auditable. It marks a shift from traditional speed-focused, probabilistic AI black-box models towards more transparent and accountable reasoning.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “Abacus” by blaahhi is licensed under CC BY 2.0.)&lt;/em&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/ai-twin-trap-next-generation-chip-and-software/</guid><pubDate>Wed, 29 Oct 2025 12:22:06 +0000</pubDate></item><item><title>Phia’s founders on how AI is changing online shopping (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/29/phias-founders-on-how-ai-is-changing-online-shopping/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;When Phia‘s founders Phoebe Gates and Sophia Kianni decided to build an AI startup, they targeted an area they understood well: online shopping.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The founders, who met at Stanford when they were randomly paired up as roommates, understood e-commerce because they had spent hours upon hours trying to find the right items to expand their wardrobe. And AI, they realized, had the potential to help people discover, shop, and buy in new ways. They also realized that capability was a market opportunity.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“There felt like there was this giant white space for, like, what should we actually buy, and why doesn’t everyone have a personal shopper in their pocket?” said Gates onstage at TechCrunch Disrupt 2025 on Tuesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup emerged from a class project where it proved its initial demand. But the service didn’t launch to the public until Phia found the right product-market fit, Kianni says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The tool, available as a browser extension and app, lets shoppers compare prices, including for second-hand items, adding a sustainability factor to the shopping experience.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Phia says it integrates with more than 150 second-hand platforms, and has over 350 million items in its in-house search database. Kianni pointed out that buying second-hand represents an 80% reduction in carbon footprint, compared with buying new. Plus, it’s cheaper.&lt;/p&gt;

&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3063419" height="453" src="https://techcrunch.com/wp-content/uploads/2025/10/2243869776.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Sophia Kianni, Co-Founder, Phia, speaks onstage during day two of TechCrunch Disrupt 2025 at Moscone Center on October 28, 2025 in San Francisco, California&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kimberly White/Getty Images for TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Kianni said the service also helps users understand the value of what they’re buying. “If you’re looking at a $500 handbag on Phia, you can quickly understand, can you resell that item for $300 or $400? Or, on the contrary, if it’s a fast-fashion piece and you’re buying it for $100 bucks, is it only reselling for $10? Does it immediately depreciate and lose 90% of its value?”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup is also developing an AI shopping advisor that will help users understand value factors like a good deal, or what an item’s retained value may be, as well as fashion basics like whether the item will fit based on the user’s previous orders and returns. The founders said the sizing insights feature is currently in beta with a small group of users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The founders have used a variety of tactics to attract an audience, including an ambassador program, making their own content about the product’s development, and even starting a podcast. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The ability to acquire hundreds of thousands of downloads at a very low cost through the podcast and the various different distribution vehicles has been really important,” said Kianni.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Plus, Gates said, sharing the realities of building a startup with their audience helped Phia’s potential users connect with the founders and their story.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think there was a bit of an ego death that we had to go through,” Gates said. “At first, it’s like, ‘I want to look good in all of our content.’ But if you want people to engage with it, and you want to make content at the volume that we need to, you need to be able to just pull back the curtain.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gates, whose dad is&lt;em&gt; yes, that Gates&lt;/em&gt;, acknowledges that she’s come to the startup experience from a position of privilege, but says they don’t necessarily go to him for advice.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“So, while my dad — I think he’s a genius — he’s not the one shopping on Phia, right? Like, he’s not hunting for the best deal across different sites. He’s not comparing his wish list items for his spring break trip,” she said. &lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;When Phia‘s founders Phoebe Gates and Sophia Kianni decided to build an AI startup, they targeted an area they understood well: online shopping.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The founders, who met at Stanford when they were randomly paired up as roommates, understood e-commerce because they had spent hours upon hours trying to find the right items to expand their wardrobe. And AI, they realized, had the potential to help people discover, shop, and buy in new ways. They also realized that capability was a market opportunity.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“There felt like there was this giant white space for, like, what should we actually buy, and why doesn’t everyone have a personal shopper in their pocket?” said Gates onstage at TechCrunch Disrupt 2025 on Tuesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup emerged from a class project where it proved its initial demand. But the service didn’t launch to the public until Phia found the right product-market fit, Kianni says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The tool, available as a browser extension and app, lets shoppers compare prices, including for second-hand items, adding a sustainability factor to the shopping experience.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Phia says it integrates with more than 150 second-hand platforms, and has over 350 million items in its in-house search database. Kianni pointed out that buying second-hand represents an 80% reduction in carbon footprint, compared with buying new. Plus, it’s cheaper.&lt;/p&gt;

&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3063419" height="453" src="https://techcrunch.com/wp-content/uploads/2025/10/2243869776.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Sophia Kianni, Co-Founder, Phia, speaks onstage during day two of TechCrunch Disrupt 2025 at Moscone Center on October 28, 2025 in San Francisco, California&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kimberly White/Getty Images for TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Kianni said the service also helps users understand the value of what they’re buying. “If you’re looking at a $500 handbag on Phia, you can quickly understand, can you resell that item for $300 or $400? Or, on the contrary, if it’s a fast-fashion piece and you’re buying it for $100 bucks, is it only reselling for $10? Does it immediately depreciate and lose 90% of its value?”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup is also developing an AI shopping advisor that will help users understand value factors like a good deal, or what an item’s retained value may be, as well as fashion basics like whether the item will fit based on the user’s previous orders and returns. The founders said the sizing insights feature is currently in beta with a small group of users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The founders have used a variety of tactics to attract an audience, including an ambassador program, making their own content about the product’s development, and even starting a podcast. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The ability to acquire hundreds of thousands of downloads at a very low cost through the podcast and the various different distribution vehicles has been really important,” said Kianni.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Plus, Gates said, sharing the realities of building a startup with their audience helped Phia’s potential users connect with the founders and their story.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think there was a bit of an ego death that we had to go through,” Gates said. “At first, it’s like, ‘I want to look good in all of our content.’ But if you want people to engage with it, and you want to make content at the volume that we need to, you need to be able to just pull back the curtain.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gates, whose dad is&lt;em&gt; yes, that Gates&lt;/em&gt;, acknowledges that she’s come to the startup experience from a position of privilege, but says they don’t necessarily go to him for advice.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“So, while my dad — I think he’s a genius — he’s not the one shopping on Phia, right? Like, he’s not hunting for the best deal across different sites. He’s not comparing his wish list items for his spring break trip,” she said. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/29/phias-founders-on-how-ai-is-changing-online-shopping/</guid><pubDate>Wed, 29 Oct 2025 12:43:50 +0000</pubDate></item><item><title>[NEW] Grammarly rebrands to ‘Superhuman,’ launches a new AI assistant (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/29/grammarly-rebrands-to-superhuman-launches-a-new-ai-assistant/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Typically, when a company acquires another, it will absorb the new company’s branding or integrate it with its own identity. Grammarly is doing something different: After acquiring email client Superhuman in July, the company is renaming itself “Superhuman.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite the branding change, Grammarly, the product, will continue to be known as it has. However, the company says it is thinking about rebranding products like Coda, a productivity platform it acquired last year, in the long run.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company is also launching an AI assistant called Superhuman Go that’s built into Grammarly’s existing extension. The assistant can provide writing suggestions, give feedback on emails, and you can even connect it with other apps like Jira, Gmail, Google Drive, and Google Calendar to arm it with more context. The assistant can use these connections to do tasks like logging tickets or fetching your availability when you’re scheduling a meeting.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3063527" height="510" src="https://techcrunch.com/wp-content/uploads/2025/10/GIF_Superhuman-Go-use-case.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Superhuman&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Superhuman said it plans to add functionality to enable the assistant to fetch data from sources like CRMs and internal systems to suggest changes to your emails. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users can try Superhuman Go by turning on a toggle in the Grammarly extension, which will let them connect it to different apps. Users can also try out different agents in the company’s agent store, which include a plagiarism checker and a proofreader, launched in August.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;All Grammarly users can try out Superhuman Go right now, though the company is also selling product bundles. Its Pro subscription plan will cost $12 per month (billed annually) and will enable grammar and tone support in multiple languages. The Business plan will cost $33 per month (billed annually) and will give users access to Superhuman Mail.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3063531" height="383" src="https://techcrunch.com/wp-content/uploads/2025/10/Static_Superhuman-Go-2.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Superhuman&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Superhuman said it also wants to add more AI-powered features to the Coda document suite and Superhuman email clients, such as fetching details from external and internal sources to create additional details in documents and email drafts automatically.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Grammarly has for the past few years made a concerted effort to increase its viability as a productivity suite, exemplified through its acquisitions of Coda and Superhuman. With this AI assistant, the company is positioning itself to compete better with the likes of Notion, ClickUp, and Google Workspace, which have launched multiple AI-powered features in the past few years.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Typically, when a company acquires another, it will absorb the new company’s branding or integrate it with its own identity. Grammarly is doing something different: After acquiring email client Superhuman in July, the company is renaming itself “Superhuman.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite the branding change, Grammarly, the product, will continue to be known as it has. However, the company says it is thinking about rebranding products like Coda, a productivity platform it acquired last year, in the long run.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company is also launching an AI assistant called Superhuman Go that’s built into Grammarly’s existing extension. The assistant can provide writing suggestions, give feedback on emails, and you can even connect it with other apps like Jira, Gmail, Google Drive, and Google Calendar to arm it with more context. The assistant can use these connections to do tasks like logging tickets or fetching your availability when you’re scheduling a meeting.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3063527" height="510" src="https://techcrunch.com/wp-content/uploads/2025/10/GIF_Superhuman-Go-use-case.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Superhuman&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Superhuman said it plans to add functionality to enable the assistant to fetch data from sources like CRMs and internal systems to suggest changes to your emails. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users can try Superhuman Go by turning on a toggle in the Grammarly extension, which will let them connect it to different apps. Users can also try out different agents in the company’s agent store, which include a plagiarism checker and a proofreader, launched in August.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;All Grammarly users can try out Superhuman Go right now, though the company is also selling product bundles. Its Pro subscription plan will cost $12 per month (billed annually) and will enable grammar and tone support in multiple languages. The Business plan will cost $33 per month (billed annually) and will give users access to Superhuman Mail.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3063531" height="383" src="https://techcrunch.com/wp-content/uploads/2025/10/Static_Superhuman-Go-2.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Superhuman&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Superhuman said it also wants to add more AI-powered features to the Coda document suite and Superhuman email clients, such as fetching details from external and internal sources to create additional details in documents and email drafts automatically.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Grammarly has for the past few years made a concerted effort to increase its viability as a productivity suite, exemplified through its acquisitions of Coda and Superhuman. With this AI assistant, the company is positioning itself to compete better with the likes of Notion, ClickUp, and Google Workspace, which have launched multiple AI-powered features in the past few years.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/29/grammarly-rebrands-to-superhuman-launches-a-new-ai-assistant/</guid><pubDate>Wed, 29 Oct 2025 13:00:00 +0000</pubDate></item><item><title>[NEW] Character.AI is ending its chatbot experience for kids (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/29/character-ai-is-killing-the-chatbot-experience-for-minors/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/U18-Product-Image.jpg?resize=1200,819" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Teenagers are trying to figure out where they fit in a world changing faster than any generation before them. They’re bursting with emotions, hyper-stimulated, and chronically online. And now, AI companies have given them chatbots designed to never stop talking. The results have been catastrophic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One company that understands this fallout is Character.AI, an AI role-playing startup that’s facing lawsuits and public outcry after at least two teenagers died by suicide following prolonged conversations with AI chatbots on its platform. Now, Character.AI is making changes to its platform to protect teenagers and kids, changes that could affect the startup’s bottom line. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“The first thing that we’ve decided as Character.AI is that we will remove the ability for under 18 users to engage in any open-ended chats with AI on our platform,” Karandeep Anand, CEO of Character.AI, told TechCrunch. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Open-ended conversation refers to the unconstrained back-and-forth that happens when users give a chatbot a prompt and it responds with follow-up questions that experts say are designed to keep users engaged. Anand argues this type of interaction — where the AI acts as a conversational partner or friend rather than a creative tool — isn’t just risky for kids, but misaligns with the company’s vision.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup is attempting to pivot from “AI companion” to “role-playing platform.” Instead of chatting with an AI friend, teens will use prompts to collaboratively build stories or generate visuals. In other words, the goal is to shift engagement from conversation to creation.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Character.AI will phase out teen chatbot access by November 25, starting with a two-hour daily limit that shrinks progressively until it hits zero. To ensure this ban remains with under 18 users, the platform will deploy an in-house age verification tool that analyzes user behavior, as well as third-party tools like Persona. If those tools fail, Character.AI will use facial recognition and ID checks to verify ages, Anand said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The move follows other teenager protections that Character.AI has implemented, including introducing a parental insights tool, filtered characters, limited romantic conversations, and time-spent notifications. Anand has told TechCrunch that those changes lost the company much of their under-18 user base, and he expects these new changes to be equally unpopular. &amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s safe to assume that a lot of our teen users probably will be disappointed… so we do expect some churn to happen further,” Anand said. “It’s hard to speculate — will all of them fully churn or will some of them move to these new experiences we’ve been building for the last almost seven months now?”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As part of Character.AI’s push to transform the platform from a chat-centric app into a “full-fledged content-driven social platform,” the startup recently launched several new entertainment-focused features.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In June, Character.AI rolled out&amp;nbsp;AvatarFX, a video generation model that transforms images into animated videos; Scenes,&amp;nbsp;interactive, pre-populated storylines where users can step into narratives with their favorite characters; and Streams, a feature that allows dynamic interactions between any two characters. In August, Character.AI launched Community Feed, a social feed where users can share their characters, scenes, videos, and other content they make on the platform. &amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In a statement addressed to users under 18, Character.AI apologized for the changes.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We know that most of you use Character.AI to supercharge your creativity in ways that stay within the bounds of our content rules,” the statement reads. “We do not take this step of removing open-ended Character chat lightly — but we do think that it’s the right thing to do given the questions that have been raised about how teens do, and should, interact with this new technology.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re not shutting down the app for under 18s,” Anand said. “We are only shutting down open-ended chats for under 18s because we hope that under 18 users migrate to these other experiences, and that those experiences get better over time. So doubling down on AI gaming, AI short videos, AI storytelling in general. That’s the big bet we’re making to bring back under 18s if they do churn.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anand acknowledged that some teens might flock to other AI platforms, like OpenAI, that allow them to have open-ended conversations with chatbots. OpenAI has also come under fire recently after a teenager took his own life following long conversations with ChatGPT. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I really hope us leading the way sets a standard in the industry that for under 18s, open-ended chats are probably not the path or the product to offer,” Anand said. “For us, I think the tradeoffs are the right ones to make. I have a six-year-old, and I want to make sure she grows up in a very safe environment with AI in a responsible way.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Character.AI is making these decisions before regulators force its hand. On Tuesday, Sens. Josh Hawley (R-MO) and Richard Blumenthal (D-CT) said they would introduce legislation to ban AI chatbot companions from being available to minors, following complaints from parents who said the products pushed their children into sexual conversations, self-harm, and suicide. Earlier this month, California became the first state to regulate AI companion chatbots by holding companies accountable if their chatbots fail to meet the law’s safety standards. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to these changes on the platform, Character.AI said it would establish and fund the AI Safety Lab, an independent nonprofit dedicated to innovating safety alignment for the future AI entertainment features. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“A lot of work is happening in the industry on coding and development and other use cases,” Anand said. “We don’t think there’s enough work yet happening on the agentic AI powering entertainment, and safety will be very critical to that.”&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/U18-Product-Image.jpg?resize=1200,819" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Teenagers are trying to figure out where they fit in a world changing faster than any generation before them. They’re bursting with emotions, hyper-stimulated, and chronically online. And now, AI companies have given them chatbots designed to never stop talking. The results have been catastrophic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One company that understands this fallout is Character.AI, an AI role-playing startup that’s facing lawsuits and public outcry after at least two teenagers died by suicide following prolonged conversations with AI chatbots on its platform. Now, Character.AI is making changes to its platform to protect teenagers and kids, changes that could affect the startup’s bottom line. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“The first thing that we’ve decided as Character.AI is that we will remove the ability for under 18 users to engage in any open-ended chats with AI on our platform,” Karandeep Anand, CEO of Character.AI, told TechCrunch. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Open-ended conversation refers to the unconstrained back-and-forth that happens when users give a chatbot a prompt and it responds with follow-up questions that experts say are designed to keep users engaged. Anand argues this type of interaction — where the AI acts as a conversational partner or friend rather than a creative tool — isn’t just risky for kids, but misaligns with the company’s vision.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup is attempting to pivot from “AI companion” to “role-playing platform.” Instead of chatting with an AI friend, teens will use prompts to collaboratively build stories or generate visuals. In other words, the goal is to shift engagement from conversation to creation.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Character.AI will phase out teen chatbot access by November 25, starting with a two-hour daily limit that shrinks progressively until it hits zero. To ensure this ban remains with under 18 users, the platform will deploy an in-house age verification tool that analyzes user behavior, as well as third-party tools like Persona. If those tools fail, Character.AI will use facial recognition and ID checks to verify ages, Anand said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The move follows other teenager protections that Character.AI has implemented, including introducing a parental insights tool, filtered characters, limited romantic conversations, and time-spent notifications. Anand has told TechCrunch that those changes lost the company much of their under-18 user base, and he expects these new changes to be equally unpopular. &amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s safe to assume that a lot of our teen users probably will be disappointed… so we do expect some churn to happen further,” Anand said. “It’s hard to speculate — will all of them fully churn or will some of them move to these new experiences we’ve been building for the last almost seven months now?”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As part of Character.AI’s push to transform the platform from a chat-centric app into a “full-fledged content-driven social platform,” the startup recently launched several new entertainment-focused features.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In June, Character.AI rolled out&amp;nbsp;AvatarFX, a video generation model that transforms images into animated videos; Scenes,&amp;nbsp;interactive, pre-populated storylines where users can step into narratives with their favorite characters; and Streams, a feature that allows dynamic interactions between any two characters. In August, Character.AI launched Community Feed, a social feed where users can share their characters, scenes, videos, and other content they make on the platform. &amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In a statement addressed to users under 18, Character.AI apologized for the changes.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We know that most of you use Character.AI to supercharge your creativity in ways that stay within the bounds of our content rules,” the statement reads. “We do not take this step of removing open-ended Character chat lightly — but we do think that it’s the right thing to do given the questions that have been raised about how teens do, and should, interact with this new technology.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re not shutting down the app for under 18s,” Anand said. “We are only shutting down open-ended chats for under 18s because we hope that under 18 users migrate to these other experiences, and that those experiences get better over time. So doubling down on AI gaming, AI short videos, AI storytelling in general. That’s the big bet we’re making to bring back under 18s if they do churn.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anand acknowledged that some teens might flock to other AI platforms, like OpenAI, that allow them to have open-ended conversations with chatbots. OpenAI has also come under fire recently after a teenager took his own life following long conversations with ChatGPT. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I really hope us leading the way sets a standard in the industry that for under 18s, open-ended chats are probably not the path or the product to offer,” Anand said. “For us, I think the tradeoffs are the right ones to make. I have a six-year-old, and I want to make sure she grows up in a very safe environment with AI in a responsible way.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Character.AI is making these decisions before regulators force its hand. On Tuesday, Sens. Josh Hawley (R-MO) and Richard Blumenthal (D-CT) said they would introduce legislation to ban AI chatbot companions from being available to minors, following complaints from parents who said the products pushed their children into sexual conversations, self-harm, and suicide. Earlier this month, California became the first state to regulate AI companion chatbots by holding companies accountable if their chatbots fail to meet the law’s safety standards. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to these changes on the platform, Character.AI said it would establish and fund the AI Safety Lab, an independent nonprofit dedicated to innovating safety alignment for the future AI entertainment features. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“A lot of work is happening in the industry on coding and development and other use cases,” Anand said. “We don’t think there’s enough work yet happening on the agentic AI powering entertainment, and safety will be very critical to that.”&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/29/character-ai-is-killing-the-chatbot-experience-for-minors/</guid><pubDate>Wed, 29 Oct 2025 13:00:00 +0000</pubDate></item><item><title>[NEW] Into the Omniverse: Open World Foundation Models Generate Synthetic Worlds for Physical AI Development (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/scaling-physical-ai-omniverse/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;&lt;i&gt;Editor’s note: This post is part of &lt;/i&gt;&lt;i&gt;Into the Omniverse&lt;/i&gt;&lt;i&gt;, a series focused on how developers, 3D practitioners and enterprises can transform their workflows using the latest advances in &lt;/i&gt;&lt;i&gt;OpenUSD&lt;/i&gt;&lt;i&gt; and &lt;/i&gt;&lt;i&gt;NVIDIA Omniverse&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;Physical AI models — which power robots, autonomous vehicles and other intelligent machines — must be safe, generalized for dynamic scenarios and capable of perceiving, reasoning and operating in real time. Unlike large language models that can be trained on massive datasets from the internet, physical AI models must learn from data grounded in the real world.&lt;/p&gt;
&lt;p&gt;However, collecting sufficient data that covers this wide variety of scenarios in the real world is incredibly difficult and, in some cases, dangerous. Physically based synthetic data generation offers a key way to address this gap.&lt;/p&gt;
&lt;p&gt;NVIDIA recently released updates to NVIDIA Cosmos open world foundation models (WFMs) to accelerate data generation for testing and validating physical AI models. Using NVIDIA Omniverse libraries and Cosmos, developers can generate physically based synthetic data at incredible scale.&lt;/p&gt;
&lt;p&gt;Cosmos Predict 2.5 now unifies three separate models — Text2World, Image2World and Video2World — into a single lightweight architecture that generates consistent, controllable multicamera video worlds from a single image, video or prompt.&lt;/p&gt;
&lt;p&gt;Cosmos Transfer 2.5 enables high-fidelity, spatially controlled world-to-world style transfer to amplify data variation. Developers can add new weather, lighting and terrain conditions to their simulated environments across multiple cameras. Cosmos Transfer 2.5 is 3.5x smaller than its predecessor, delivering faster performance with improved prompt alignment and physics accuracy.&lt;/p&gt;
&lt;p&gt;These WFMs can be integrated into synthetic data pipelines running in the NVIDIA Isaac Sim open-source robotics simulation framework, built on the NVIDIA Omniverse platform, to generate photorealistic videos that reduce the simulation-to-real gap. Developers can reference a four-part pipeline for synthetic data generation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NVIDIA Omniverse NuRec neural reconstruction libraries for reconstructing a digital twin of a real-world environment in OpenUSD, starting with just a smartphone.&lt;/li&gt;
&lt;li&gt;SimReady assets to populate a digital twin with physically accurate 3D models.&lt;/li&gt;
&lt;li&gt;The MobilityGen workflow in Isaac Sim to generate synthetic data.&lt;/li&gt;
&lt;li&gt;NVIDIA Cosmos for augmenting generated data.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;strong&gt;From Simulation to the Real World&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Leading robotics and AI companies are already using these technologies to accelerate physical AI development.&lt;/p&gt;
&lt;p&gt;Skild AI, which builds general-purpose robot brains, is using Cosmos Transfer to augment existing data with new variations for testing and validating robotics policies trained in NVIDIA Isaac Lab.&lt;/p&gt;
&lt;p&gt;Skild AI uses Isaac Lab to create scalable simulation environments where its robots can train across embodiments and applications. By combining Isaac Lab robotics simulation capabilities with Cosmos’ synthetic data generation, Skild AI can train robot brains across diverse conditions without the time and cost constraints of real-world data collection.&lt;/p&gt;
&lt;p&gt;Serve Robotics uses synthetic data generated from thousands of simulated scenarios in NVIDIA Isaac Sim. The synthetic data is then used in conjunction with real data to train physical AI models. The company has built one of the largest autonomous robot fleets operating in public spaces and has completed over 100,000 last-mile meal deliveries across urban areas. Serve’s robots collect 1 million miles of data monthly, including nearly 170 billion image-lidar samples, which are used in simulation to further improve robot models.&lt;/p&gt;
&lt;p&gt;Learn more about how Serve Robotics uses Isaac Sim to accelerate development, testing and deployment of its sidewalk delivery robots by watching the below livestream.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;Beyond bringing people meals, Serve recently used its robots to deliver compute power — dropping off brand-new NVIDIA DGX Spark personal AI supercomputers to Refik Anadol, Will.I.AM and Ollama. With 1 petaflop of AI performance, DGX Spark offers developers desktop capabilities for workflows from AI model prototyping and model fine-tuning to inference and robotics development.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;Autonomous drone delivery company Zipline also participated in the DGX Spark drop, with Chief Hardware Officer Jo Mardall receiving a DGX Spark by drone at the company’s headquarters and testing facility in Half Moon Bay, California. Zipline uses the NVIDIA Jetson edge AI and robotics platform for its drone delivery systems.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;See How Developers Are Using Synthetic Data&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Lightwheel, a simulation-first robotics solution provider, is helping companies bridge the simulation-to-real gap with SimReady assets and large-scale synthetic datasets. With high-quality synthetic data and simulation environments built on OpenUSD, Lightwheel’s approach helps ensure robots trained in simulation perform effectively in real-world scenarios, from factory floors to homes.&lt;/p&gt;
&lt;p&gt;Data scientist and Omniverse community member Santiago Villa is using synthetic data with Omniverse libraries and Blender software to improve mining operations by identifying large boulders that halt operations.&lt;/p&gt;
&lt;p&gt;Undetected boulders entering crushers can cause delays of seven minutes or more per incident, costing mines up to $650,000 annually in lost production. Using Omniverse to generate thousands of automatically annotated synthetic images across varied lighting and weather conditions dramatically reduces training costs while enabling mining companies to improve boulder detection systems and avoid equipment downtime.&lt;/p&gt;

&lt;p&gt;FS Studio partnered with a global logistics leader to improve AI-driven package detection by creating thousands of photorealistic package variations in different lighting conditions using Omniverse libraries like Replicator. The synthetic dataset dramatically improved object detection accuracy and reduced false positives, delivering measurable gains in throughput speed and system performance across the customer’s logistics network.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_86701"&gt;&lt;img alt="alt" class="size-medium wp-image-86701" height="510" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/fs-studio-images-side-by-side-960x510.jpg" width="960" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-86701"&gt;Images courtesy of FS Studio&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Robots for Humanity built a full simulation environment in Isaac Sim for an oil and gas client using Omniverse libraries to generate synthetic data, including depth, segmentation and RGB images, while collecting joint and motion data from the Unitree G1 robot through teleoperation.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_86691"&gt;&lt;img alt="alt" class="size-medium wp-image-86691" height="528" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/robots-for-humanity-960x528.png" width="960" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-86691"&gt;Image courtesy of Robots for Humanity.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Omniverse Ambassador Scott Dempsey is developing a synthetic data generation synthesizer that builds various cables from real-world manufacturer specifications, using Isaac Sim to generate synthetic data augmented with Cosmos Transfer to create photorealistic training datasets for applications that detect and handle cables.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter wp-image-86694 size-medium" height="777" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/scott-dempsey-cable-tool-960x777.png" width="960" /&gt;&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Get Plugged Into the World of OpenUSD&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Learn more about OpenUSD, Cosmos and synthetic data for physical AI by exploring these resources:&lt;/p&gt;

&lt;p&gt;&lt;i&gt;Stay up to date by subscribing to&lt;/i&gt; &lt;i&gt;NVIDIA Omniverse news&lt;/i&gt;&lt;i&gt;, joining the Omniverse &lt;/i&gt;&lt;i&gt;community&lt;/i&gt;&lt;i&gt; and following Omniverse on&lt;/i&gt; &lt;i&gt;Discord&lt;/i&gt;&lt;i&gt;,&lt;/i&gt; &lt;i&gt;Instagram&lt;/i&gt;&lt;i&gt;, &lt;/i&gt;&lt;i&gt;LinkedIn&lt;/i&gt;&lt;i&gt;, &lt;/i&gt;&lt;i&gt;Threads&lt;/i&gt;&lt;i&gt;,&lt;/i&gt; &lt;i&gt;X&lt;/i&gt;&lt;i&gt; and&lt;/i&gt; &lt;i&gt;YouTube&lt;/i&gt;&lt;i&gt;.&amp;nbsp;&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Explore the &lt;/i&gt;&lt;i&gt;Alliance for OpenUSD forum&lt;/i&gt;&lt;i&gt; and the &lt;/i&gt;&lt;i&gt;AOUSD website&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;&lt;i&gt;Editor’s note: This post is part of &lt;/i&gt;&lt;i&gt;Into the Omniverse&lt;/i&gt;&lt;i&gt;, a series focused on how developers, 3D practitioners and enterprises can transform their workflows using the latest advances in &lt;/i&gt;&lt;i&gt;OpenUSD&lt;/i&gt;&lt;i&gt; and &lt;/i&gt;&lt;i&gt;NVIDIA Omniverse&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;Physical AI models — which power robots, autonomous vehicles and other intelligent machines — must be safe, generalized for dynamic scenarios and capable of perceiving, reasoning and operating in real time. Unlike large language models that can be trained on massive datasets from the internet, physical AI models must learn from data grounded in the real world.&lt;/p&gt;
&lt;p&gt;However, collecting sufficient data that covers this wide variety of scenarios in the real world is incredibly difficult and, in some cases, dangerous. Physically based synthetic data generation offers a key way to address this gap.&lt;/p&gt;
&lt;p&gt;NVIDIA recently released updates to NVIDIA Cosmos open world foundation models (WFMs) to accelerate data generation for testing and validating physical AI models. Using NVIDIA Omniverse libraries and Cosmos, developers can generate physically based synthetic data at incredible scale.&lt;/p&gt;
&lt;p&gt;Cosmos Predict 2.5 now unifies three separate models — Text2World, Image2World and Video2World — into a single lightweight architecture that generates consistent, controllable multicamera video worlds from a single image, video or prompt.&lt;/p&gt;
&lt;p&gt;Cosmos Transfer 2.5 enables high-fidelity, spatially controlled world-to-world style transfer to amplify data variation. Developers can add new weather, lighting and terrain conditions to their simulated environments across multiple cameras. Cosmos Transfer 2.5 is 3.5x smaller than its predecessor, delivering faster performance with improved prompt alignment and physics accuracy.&lt;/p&gt;
&lt;p&gt;These WFMs can be integrated into synthetic data pipelines running in the NVIDIA Isaac Sim open-source robotics simulation framework, built on the NVIDIA Omniverse platform, to generate photorealistic videos that reduce the simulation-to-real gap. Developers can reference a four-part pipeline for synthetic data generation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NVIDIA Omniverse NuRec neural reconstruction libraries for reconstructing a digital twin of a real-world environment in OpenUSD, starting with just a smartphone.&lt;/li&gt;
&lt;li&gt;SimReady assets to populate a digital twin with physically accurate 3D models.&lt;/li&gt;
&lt;li&gt;The MobilityGen workflow in Isaac Sim to generate synthetic data.&lt;/li&gt;
&lt;li&gt;NVIDIA Cosmos for augmenting generated data.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;strong&gt;From Simulation to the Real World&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Leading robotics and AI companies are already using these technologies to accelerate physical AI development.&lt;/p&gt;
&lt;p&gt;Skild AI, which builds general-purpose robot brains, is using Cosmos Transfer to augment existing data with new variations for testing and validating robotics policies trained in NVIDIA Isaac Lab.&lt;/p&gt;
&lt;p&gt;Skild AI uses Isaac Lab to create scalable simulation environments where its robots can train across embodiments and applications. By combining Isaac Lab robotics simulation capabilities with Cosmos’ synthetic data generation, Skild AI can train robot brains across diverse conditions without the time and cost constraints of real-world data collection.&lt;/p&gt;
&lt;p&gt;Serve Robotics uses synthetic data generated from thousands of simulated scenarios in NVIDIA Isaac Sim. The synthetic data is then used in conjunction with real data to train physical AI models. The company has built one of the largest autonomous robot fleets operating in public spaces and has completed over 100,000 last-mile meal deliveries across urban areas. Serve’s robots collect 1 million miles of data monthly, including nearly 170 billion image-lidar samples, which are used in simulation to further improve robot models.&lt;/p&gt;
&lt;p&gt;Learn more about how Serve Robotics uses Isaac Sim to accelerate development, testing and deployment of its sidewalk delivery robots by watching the below livestream.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;Beyond bringing people meals, Serve recently used its robots to deliver compute power — dropping off brand-new NVIDIA DGX Spark personal AI supercomputers to Refik Anadol, Will.I.AM and Ollama. With 1 petaflop of AI performance, DGX Spark offers developers desktop capabilities for workflows from AI model prototyping and model fine-tuning to inference and robotics development.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;Autonomous drone delivery company Zipline also participated in the DGX Spark drop, with Chief Hardware Officer Jo Mardall receiving a DGX Spark by drone at the company’s headquarters and testing facility in Half Moon Bay, California. Zipline uses the NVIDIA Jetson edge AI and robotics platform for its drone delivery systems.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;See How Developers Are Using Synthetic Data&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Lightwheel, a simulation-first robotics solution provider, is helping companies bridge the simulation-to-real gap with SimReady assets and large-scale synthetic datasets. With high-quality synthetic data and simulation environments built on OpenUSD, Lightwheel’s approach helps ensure robots trained in simulation perform effectively in real-world scenarios, from factory floors to homes.&lt;/p&gt;
&lt;p&gt;Data scientist and Omniverse community member Santiago Villa is using synthetic data with Omniverse libraries and Blender software to improve mining operations by identifying large boulders that halt operations.&lt;/p&gt;
&lt;p&gt;Undetected boulders entering crushers can cause delays of seven minutes or more per incident, costing mines up to $650,000 annually in lost production. Using Omniverse to generate thousands of automatically annotated synthetic images across varied lighting and weather conditions dramatically reduces training costs while enabling mining companies to improve boulder detection systems and avoid equipment downtime.&lt;/p&gt;

&lt;p&gt;FS Studio partnered with a global logistics leader to improve AI-driven package detection by creating thousands of photorealistic package variations in different lighting conditions using Omniverse libraries like Replicator. The synthetic dataset dramatically improved object detection accuracy and reduced false positives, delivering measurable gains in throughput speed and system performance across the customer’s logistics network.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_86701"&gt;&lt;img alt="alt" class="size-medium wp-image-86701" height="510" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/fs-studio-images-side-by-side-960x510.jpg" width="960" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-86701"&gt;Images courtesy of FS Studio&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Robots for Humanity built a full simulation environment in Isaac Sim for an oil and gas client using Omniverse libraries to generate synthetic data, including depth, segmentation and RGB images, while collecting joint and motion data from the Unitree G1 robot through teleoperation.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_86691"&gt;&lt;img alt="alt" class="size-medium wp-image-86691" height="528" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/robots-for-humanity-960x528.png" width="960" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-86691"&gt;Image courtesy of Robots for Humanity.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Omniverse Ambassador Scott Dempsey is developing a synthetic data generation synthesizer that builds various cables from real-world manufacturer specifications, using Isaac Sim to generate synthetic data augmented with Cosmos Transfer to create photorealistic training datasets for applications that detect and handle cables.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter wp-image-86694 size-medium" height="777" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/scott-dempsey-cable-tool-960x777.png" width="960" /&gt;&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Get Plugged Into the World of OpenUSD&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Learn more about OpenUSD, Cosmos and synthetic data for physical AI by exploring these resources:&lt;/p&gt;

&lt;p&gt;&lt;i&gt;Stay up to date by subscribing to&lt;/i&gt; &lt;i&gt;NVIDIA Omniverse news&lt;/i&gt;&lt;i&gt;, joining the Omniverse &lt;/i&gt;&lt;i&gt;community&lt;/i&gt;&lt;i&gt; and following Omniverse on&lt;/i&gt; &lt;i&gt;Discord&lt;/i&gt;&lt;i&gt;,&lt;/i&gt; &lt;i&gt;Instagram&lt;/i&gt;&lt;i&gt;, &lt;/i&gt;&lt;i&gt;LinkedIn&lt;/i&gt;&lt;i&gt;, &lt;/i&gt;&lt;i&gt;Threads&lt;/i&gt;&lt;i&gt;,&lt;/i&gt; &lt;i&gt;X&lt;/i&gt;&lt;i&gt; and&lt;/i&gt; &lt;i&gt;YouTube&lt;/i&gt;&lt;i&gt;.&amp;nbsp;&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Explore the &lt;/i&gt;&lt;i&gt;Alliance for OpenUSD forum&lt;/i&gt;&lt;i&gt; and the &lt;/i&gt;&lt;i&gt;AOUSD website&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/scaling-physical-ai-omniverse/</guid><pubDate>Wed, 29 Oct 2025 13:00:30 +0000</pubDate></item><item><title>[NEW] The Download: Boosting AI’s memory, and data centers’ unhappy neighbors (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/29/1126945/the-download-boosting-ais-memory-and-data-centers-unhappy-neighbors/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;DeepSeek may have found a new way to improve AI’s ability to remember&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;&lt;strong&gt;The news: &lt;/strong&gt;An AI model released by Chinese AI company DeepSeek uses new techniques that could significantly improve AI’s ability to “remember.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;How it works: &lt;/strong&gt;The optical character recognition model works by extracting text from an image and turning it into machine-readable words. This is the same technology that powers scanner apps, translation of text in photos, and many accessibility tools.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Why it matters: &lt;/strong&gt;Researchers say the model’s main innovation lies in how it processes information—specifically, how it stores and retrieves data. Improving how AI models “remember” could reduce how much computing power they need to run, thus mitigating AI’s large (and growing) carbon footprint. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Caiwei Chen&lt;/em&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The AI Hype Index: Data centers’ neighbors are pivoting to power blackouts&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Separating AI reality from hyped-up fiction isn’t always easy. That’s why we’ve created the AI Hype Index—a simple, at-a-glance summary of everything you need to know about the state of the industry. Take a look at this month’s edition of the index here.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Roundtables: seeking climate solutions in turbulent times&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Yesterday we held a subscriber-only conversation exploring how companies are pursuing climate solutions amid political shifts in the US.&lt;/p&gt;&lt;p&gt;Our climate reporters James Temple and Casey Crownhart sat down with our science editor Mary Beth Griggs to dig into the most promising climate technologies right now. Watch the session back here!&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;MIT Technology Review Narrated: Supershoes are reshaping distance running&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;“Supershoes” —which combine a lightweight, energy-­returning foam with a carbon-fiber plate for stiffness—have been behind every broken world record in distances from 5,000 meters to the marathon since 2020.&lt;/p&gt;  &lt;p&gt;To some, this is a sign of progress—for both the field as a whole and for athletes’ bodies. Still, some argue that they’ve changed the sport too quickly.&lt;/p&gt; 

 &lt;p&gt;This is our latest story to be turned into a MIT Technology Review Narrated podcast, which we’re publishing each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it’s released.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;1 Hurricane Melissa may be the Atlantic Ocean’s strongest on record&lt;/strong&gt;&lt;br /&gt;There’s little doubt in scientists’ minds that human-caused climate change is to blame. (New Scientist $)+ &lt;em&gt;While Jamaica is largely without power, no deaths have been confirmed. &lt;/em&gt;(BBC)&lt;br /&gt;+ &lt;em&gt;The hurricane is currently sweeping across Cuba. &lt;/em&gt;(NYT $)&lt;br /&gt;+ &lt;em&gt;Here’s what we know about hurricanes and climate change. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 Texas is suing Tylenol over the Trump administration’s autism claims&lt;/strong&gt;&lt;br /&gt;Even though the scientific evidence is unfounded. (NY Mag $)&lt;br /&gt;+ &lt;em&gt;The lawsuit claims the firm violated Texas law by claiming the drug was safe. &lt;/em&gt;(WP $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 Two US Senators want to ban AI companions for minors&lt;/strong&gt;&lt;br /&gt;They want AI companies to implement age-verification processes, too. (NBC News)&lt;br /&gt;+ &lt;em&gt;The looming crackdown on AI companionship. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 Trump’s “golden dome” plan is seriously flawed&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;It’s unlikely to offer anything like the protection he claims it will. (WP $)&lt;br /&gt;+ &lt;em&gt;Why Trump’s “golden dome” missile defense idea is another ripped straight from the movies. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;4 The Trump administration is backing new nuclear plants&lt;/strong&gt;&lt;br /&gt;To—surprise surprise—power the AI boom. (NYT $)&lt;br /&gt;+ &lt;em&gt;The grid is straining to support the excessive demands for power. &lt;/em&gt;(Reuters)+ &lt;em&gt;Can nuclear power really fuel the rise of AI? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 Uber’s next fleet of autonomous cars will contain Nvidia’s new chips&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Which could eventually make it cheaper to hail a robotaxi. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;Nvidia is also working with a company called Lucid to bring autonomous cars to consumers. &lt;/em&gt;(Ars Technica)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;6 Weight loss drugs are becoming more commonplace across the world&lt;/strong&gt;&lt;br /&gt;Semaglutide patents are due to expire in Brazil, China and India next year. (Economist $)+ &lt;em&gt;We’re learning more about what weight-loss drugs do to the body. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 More billionaires hail from America than any other nation&lt;br /&gt;&lt;/strong&gt;The majority of them have made their fortunes working in technology. (WSJ $)&lt;br /&gt;+ &lt;em&gt;China is closing in on America’s global science lead. &lt;/em&gt;(Bloomberg $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;8 Australian police are developing an AI tool to decode Gen Z slang&lt;br /&gt;&lt;/strong&gt;It’s in a bid to combat the rising networks of young men targeting vulnerable girls online. (The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 This robot housekeeper is controlled remotely by a human &lt;/strong&gt;&lt;strong&gt;🤖&lt;/strong&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;Nothing weird about that at all… (WSJ $)&lt;br /&gt;+ &lt;em&gt;The humans behind the robots. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 Cameo is suing OpenAI&lt;/strong&gt;&lt;br /&gt;It’s unhappy about Sora’s new Cameo feature. (Reuters)&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“I don’t believe we’re in an AI bubble.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Jensen Haung, Nvidia’s CEO, conveniently dismisses the growing concerns around the AI hype train, Bloomberg reports.&lt;/p&gt;   
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1126959" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/image_9e775d.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;How to befriend a crow&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Crows have become minor TikTok celebrities thanks to CrowTok, a small but extremely active niche on the social video app that has exploded in popularity over the past two years. CrowTok isn’t just about birds, though. It also often explores the relationships that corvids—a family of birds including crows, magpies, and ravens—develop with human beings.&lt;/p&gt;  &lt;p&gt;They’re not the only intelligent birds around, but in general, corvids are smart in a way that resonates deeply with humans. But how easy is it to befriend them? And what can it teach us about attention, and patience, in a world that often seems to have little of either? Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Abby Ohlheiser&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ Congratulations to Flava Flav, who’s been appointed Team USA’s official hype man for the 2026 Winter Olympics!&lt;br /&gt;+ Why are Spirographs so hypnotic? Answers on a postcard.&lt;br /&gt;+ I love this story—and beautiful photos—celebrating 50 years of the World Gay Rodeo.&lt;br /&gt;+ Axolotls really are remarkable little creatures.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;DeepSeek may have found a new way to improve AI’s ability to remember&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;&lt;strong&gt;The news: &lt;/strong&gt;An AI model released by Chinese AI company DeepSeek uses new techniques that could significantly improve AI’s ability to “remember.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;How it works: &lt;/strong&gt;The optical character recognition model works by extracting text from an image and turning it into machine-readable words. This is the same technology that powers scanner apps, translation of text in photos, and many accessibility tools.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Why it matters: &lt;/strong&gt;Researchers say the model’s main innovation lies in how it processes information—specifically, how it stores and retrieves data. Improving how AI models “remember” could reduce how much computing power they need to run, thus mitigating AI’s large (and growing) carbon footprint. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Caiwei Chen&lt;/em&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The AI Hype Index: Data centers’ neighbors are pivoting to power blackouts&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Separating AI reality from hyped-up fiction isn’t always easy. That’s why we’ve created the AI Hype Index—a simple, at-a-glance summary of everything you need to know about the state of the industry. Take a look at this month’s edition of the index here.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Roundtables: seeking climate solutions in turbulent times&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Yesterday we held a subscriber-only conversation exploring how companies are pursuing climate solutions amid political shifts in the US.&lt;/p&gt;&lt;p&gt;Our climate reporters James Temple and Casey Crownhart sat down with our science editor Mary Beth Griggs to dig into the most promising climate technologies right now. Watch the session back here!&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;MIT Technology Review Narrated: Supershoes are reshaping distance running&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;“Supershoes” —which combine a lightweight, energy-­returning foam with a carbon-fiber plate for stiffness—have been behind every broken world record in distances from 5,000 meters to the marathon since 2020.&lt;/p&gt;  &lt;p&gt;To some, this is a sign of progress—for both the field as a whole and for athletes’ bodies. Still, some argue that they’ve changed the sport too quickly.&lt;/p&gt; 

 &lt;p&gt;This is our latest story to be turned into a MIT Technology Review Narrated podcast, which we’re publishing each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it’s released.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;1 Hurricane Melissa may be the Atlantic Ocean’s strongest on record&lt;/strong&gt;&lt;br /&gt;There’s little doubt in scientists’ minds that human-caused climate change is to blame. (New Scientist $)+ &lt;em&gt;While Jamaica is largely without power, no deaths have been confirmed. &lt;/em&gt;(BBC)&lt;br /&gt;+ &lt;em&gt;The hurricane is currently sweeping across Cuba. &lt;/em&gt;(NYT $)&lt;br /&gt;+ &lt;em&gt;Here’s what we know about hurricanes and climate change. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 Texas is suing Tylenol over the Trump administration’s autism claims&lt;/strong&gt;&lt;br /&gt;Even though the scientific evidence is unfounded. (NY Mag $)&lt;br /&gt;+ &lt;em&gt;The lawsuit claims the firm violated Texas law by claiming the drug was safe. &lt;/em&gt;(WP $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 Two US Senators want to ban AI companions for minors&lt;/strong&gt;&lt;br /&gt;They want AI companies to implement age-verification processes, too. (NBC News)&lt;br /&gt;+ &lt;em&gt;The looming crackdown on AI companionship. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 Trump’s “golden dome” plan is seriously flawed&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;It’s unlikely to offer anything like the protection he claims it will. (WP $)&lt;br /&gt;+ &lt;em&gt;Why Trump’s “golden dome” missile defense idea is another ripped straight from the movies. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;4 The Trump administration is backing new nuclear plants&lt;/strong&gt;&lt;br /&gt;To—surprise surprise—power the AI boom. (NYT $)&lt;br /&gt;+ &lt;em&gt;The grid is straining to support the excessive demands for power. &lt;/em&gt;(Reuters)+ &lt;em&gt;Can nuclear power really fuel the rise of AI? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 Uber’s next fleet of autonomous cars will contain Nvidia’s new chips&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Which could eventually make it cheaper to hail a robotaxi. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;Nvidia is also working with a company called Lucid to bring autonomous cars to consumers. &lt;/em&gt;(Ars Technica)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;6 Weight loss drugs are becoming more commonplace across the world&lt;/strong&gt;&lt;br /&gt;Semaglutide patents are due to expire in Brazil, China and India next year. (Economist $)+ &lt;em&gt;We’re learning more about what weight-loss drugs do to the body. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 More billionaires hail from America than any other nation&lt;br /&gt;&lt;/strong&gt;The majority of them have made their fortunes working in technology. (WSJ $)&lt;br /&gt;+ &lt;em&gt;China is closing in on America’s global science lead. &lt;/em&gt;(Bloomberg $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;8 Australian police are developing an AI tool to decode Gen Z slang&lt;br /&gt;&lt;/strong&gt;It’s in a bid to combat the rising networks of young men targeting vulnerable girls online. (The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 This robot housekeeper is controlled remotely by a human &lt;/strong&gt;&lt;strong&gt;🤖&lt;/strong&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;Nothing weird about that at all… (WSJ $)&lt;br /&gt;+ &lt;em&gt;The humans behind the robots. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 Cameo is suing OpenAI&lt;/strong&gt;&lt;br /&gt;It’s unhappy about Sora’s new Cameo feature. (Reuters)&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“I don’t believe we’re in an AI bubble.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Jensen Haung, Nvidia’s CEO, conveniently dismisses the growing concerns around the AI hype train, Bloomberg reports.&lt;/p&gt;   
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1126959" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/image_9e775d.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;How to befriend a crow&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Crows have become minor TikTok celebrities thanks to CrowTok, a small but extremely active niche on the social video app that has exploded in popularity over the past two years. CrowTok isn’t just about birds, though. It also often explores the relationships that corvids—a family of birds including crows, magpies, and ravens—develop with human beings.&lt;/p&gt;  &lt;p&gt;They’re not the only intelligent birds around, but in general, corvids are smart in a way that resonates deeply with humans. But how easy is it to befriend them? And what can it teach us about attention, and patience, in a world that often seems to have little of either? Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Abby Ohlheiser&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ Congratulations to Flava Flav, who’s been appointed Team USA’s official hype man for the 2026 Winter Olympics!&lt;br /&gt;+ Why are Spirographs so hypnotic? Answers on a postcard.&lt;br /&gt;+ I love this story—and beautiful photos—celebrating 50 years of the World Gay Rodeo.&lt;br /&gt;+ Axolotls really are remarkable little creatures.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/29/1126945/the-download-boosting-ais-memory-and-data-centers-unhappy-neighbors/</guid><pubDate>Wed, 29 Oct 2025 13:10:00 +0000</pubDate></item><item><title>[NEW] Migrating AI from Nvidia to Huawei: Opportunities and trade-offs (AI News)</title><link>https://www.artificialintelligence-news.com/news/migrating-ai-from-nvidia-to-huawei-opportunities-and-trade-offs/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/huawei-ai-jump-hero_x1440.webp" /&gt;&lt;/div&gt;&lt;p&gt;When contemplating the shift, several business advantages may drive a final decision. Relying on one major vendor (namely, Nvidia) can incur risks: pricing leverage, export controls, supply shortages, or a single point of failure in innovation. Adopting or migrating to Huawei has the potential to provide negotiation leverage, avoid vendor lock-in, and offer access to alternate supply chains. That’s especially relevant in areas where Nvidia faces export restrictions.&lt;/p&gt;&lt;p&gt;If an organisation operates in a region where Huawei’s ecosystem is stronger (e.g., China, parts of Asia) or where domestic incentives favour local hardware, shifting to Huawei could align with corporate strategy. For instance, ByteDance has begun training a new model primarily on Huawei’s Ascend 910B chips with notable success.&lt;/p&gt;&lt;p&gt;Huawei’s technology focuses on inference and large-scale deployments, and thus may be better suited to long-term use, rather than occasional use of large infrastructures for training, followed by less intensive inference. If an organisation’s workloads are inference-heavy, a Huawei stack may offer advantages in cost and power. Moving Huawei’s internal clusters (e.g., CloudMatrix) have shown competitive results in select benchmarks.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/huawei-ai-jump-hero_x1440.webp" /&gt;&lt;/div&gt;&lt;p&gt;When contemplating the shift, several business advantages may drive a final decision. Relying on one major vendor (namely, Nvidia) can incur risks: pricing leverage, export controls, supply shortages, or a single point of failure in innovation. Adopting or migrating to Huawei has the potential to provide negotiation leverage, avoid vendor lock-in, and offer access to alternate supply chains. That’s especially relevant in areas where Nvidia faces export restrictions.&lt;/p&gt;&lt;p&gt;If an organisation operates in a region where Huawei’s ecosystem is stronger (e.g., China, parts of Asia) or where domestic incentives favour local hardware, shifting to Huawei could align with corporate strategy. For instance, ByteDance has begun training a new model primarily on Huawei’s Ascend 910B chips with notable success.&lt;/p&gt;&lt;p&gt;Huawei’s technology focuses on inference and large-scale deployments, and thus may be better suited to long-term use, rather than occasional use of large infrastructures for training, followed by less intensive inference. If an organisation’s workloads are inference-heavy, a Huawei stack may offer advantages in cost and power. Moving Huawei’s internal clusters (e.g., CloudMatrix) have shown competitive results in select benchmarks.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/migrating-ai-from-nvidia-to-huawei-opportunities-and-trade-offs/</guid><pubDate>Wed, 29 Oct 2025 13:53:00 +0000</pubDate></item><item><title>[NEW] TechCrunch Disrupt 2025: Day 3 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/29/techcrunch-disrupt-2025-day-3/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Welcome to the third and final day of &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; at Moscone West in San Francisco! The excitement here is still in full swing, and there’s no slowing down.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If you thought it was too late to join, think again — &lt;strong&gt;there’s still time to register with a 50% discount&lt;/strong&gt; and be part of the action. Don’t wait a whole year to be at &lt;em&gt;the&lt;/em&gt; tech epicenter of the year.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Today’s agenda features some of the most anticipated stage sessions, spotlighting insights from trailblazers such as Rohit Patel, director at Meta Superintelligence Labs; Kirsten Green, founding partner of Forerunner; and Tristan Thompson, NBA champion and fintech entrepreneur — among others. Excitement builds throughout the day as we await the announcement of the &lt;strong&gt;Startup Battlefield 200&lt;/strong&gt; winner. Be sure to explore groundbreaking innovations in the Expo Hall, gain invaluable knowledge from industry leaders in hands-on sessions, and forge meaningful connections that could shape your next big move.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-important-reminders-for-today-at-disrupt"&gt;Important reminders for today at Disrupt&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Register and grab your scannable badge at the Registration Desk anytime from 8:00 a.m. to 3:30 p.m.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Don’t forget your ticket and government-issued photo ID. The name on your badge/ticket must match the name on your ID. You cannot pick up a badge for another attendee.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Investors Breakfast Fireside Chat: Innovation in the Next Decade — The Next Growth Engines and Funding Models&lt;/strong&gt;: Location: Deal Flow Cafe (Investor Pass holders only)&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Get ready for an action-packed day — here’s what’s in store for day 3 of Disrupt 2025.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h2 class="wp-block-heading" id="h-today-s-sessions"&gt;Today’s sessions&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;We’re closing out Disrupt 2025 with a powerful lineup of industry leaders hitting the stage. Visit the full agenda for timing and session info.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-ai-stage"&gt;AI Stage&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;From Ads to Films: Creating with Code:&lt;/strong&gt; Alejandro Matamala Ortiz (co-founder and chief design officer, Runway)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;The $1M AI Trust Bet: Can We Truly Trust an AI Agent to Run Influencer Marketing?:&lt;/strong&gt; Francis Yang (co-founder and chief product officer, Aha)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;How Google Is Building for the Agentic Cloud:&lt;/strong&gt; Will Grannis (CTO, Google Cloud)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;AI in the Dust: Building Trustworthy Models for the Physical World: &lt;/strong&gt;Fahad Khan (senior director, product management, Platform, Blue River Technology [John Deere]) and Jeff Mills (president and chief of revenue operations, iMerit Technology)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Shaping the AI Stack with Hugging Face&lt;/strong&gt;&lt;strong&gt;:&lt;/strong&gt; Thomas Wolf (co-founder and chief science officer, Hugging Face)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Love, Lies &amp;amp; Algorithms: The Truth about AI in Matters of the Heart:&lt;/strong&gt; Dr. Amanda Gesselman (research scientist, Kinsey Institute), Mark Kantor (head of product, Tinder), and Eugenia Kuyda (founder, Replika)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Smarter Streets: How AI Is Driving the Future of Transportation: &lt;/strong&gt;Dave Ferguson (co-founder and co-CEO, Nuro) and Sachin Kansal (chief product officer, Uber Technologies)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;AI and National Security in the High-Stakes Race to Innovate:&lt;/strong&gt; Justin Fanelli (chief technology officer, U.S. Dept of Navy), Kathleen Fisher (director, AI and Cybersecurity Initiative, RAND Corporation), and Chris Morales (partner, Point72 Ventures)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;AI That Talks Back: Character.AI in the Spotlight:&lt;/strong&gt; Karandeep Anand (CEO, Character.AI)&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-builders-stage"&gt;Builders Stage&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Seed Money Secrets Every Founder Should Know:&lt;/strong&gt; Gabby Cazeau (partner, Harlem Capital), Marlon Nichols (co-founder and managing general partner, MaC Venture Capital), and Maria Palma (general partner, Freestyle Capital)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Rethinking Startup Capital without VCs:&lt;/strong&gt; Erik Allebest (CEO, Chess.com), Louwee Shibata (founder and partner, Next Gen, KALDOS Capital), and Gale Wilkinson (managing partner, VITALIZE Venture Capital)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Global Hiring Isn’t Spooky! And Paying in Crypto Shouldn’t be Either:&lt;/strong&gt; Francoise Brougher (chief executive officer, Pebl) and Aileen Lee (founder and managing partner, Cowboy Ventures)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;With Vibe Coding, Do Early Stage Startups Still Need to Hire 10x Engineers?: &lt;/strong&gt;David Cramer (co-founder and CPO, Sentry), Zach Lloyd (CEO and founder, Warp), and Lauri Moore (partner, Bessemer Venture Partners)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Preparing Now for Your Later Stage Raise: &lt;/strong&gt;Lila Preston (head of growth equity, Generation Investment Management), Sadi Khan (co-founder and CEO, Aven), and Zeya Yang (partner, IVP)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;The Pros and Cons of Hiring AI Agents as Early Employees:&lt;/strong&gt; Jaspar Carmichael-Jack (co-founder and CEO, Artisan), Sarah Franklin (CEO, Lattice), and Caleb Peffer (co-founder and CEO, Firecrawl)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Creating Communities and Companies that Last: &lt;/strong&gt;Tade Oyerinde (founder and chancellor, Campus) and Teddy Solomon (co-founder and CEO, Fizz)&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-disrupt-stage"&gt;Disrupt Stage&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Rebuilding the City that Builds Startups: &lt;/strong&gt;Daniel Lurie (mayor of San Francisco, City and County of San Francisco)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;A Conversation with Investor Extraordinaire Elad Gil:&lt;/strong&gt; Elad Gil (Gil &amp;amp; Co.)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Survive, Scale, Reinvent: Lessons from a Cloud OG: &lt;/strong&gt;Aaron Levie (co-founder and CEO, Box)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Startup Battlefield Alumni Update: &lt;/strong&gt;Dr. Capella Kerst (CEO and founder, geCKo Materials)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;The Startup Battlefield Final:&lt;/strong&gt; Kirsten Green (founding partner, Forerunner), Kevin Hartz (general partner, A*), Aileen Lee (founder and managing partner, Cowboy Ventures), and Kevin Rose (founder, Digg)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Crypto’s Next Chapter with Solana’s Anatoly Yakovenko:&lt;/strong&gt; Anatoly Yakovenko&amp;nbsp;(co-founder, Solana, and CEO, Solana Labs)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;From Digg to Deals: Kevin Rose on Reinvention and Investing:&lt;/strong&gt; Kevin Rose (founder, Digg)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Cluely’s Roy Lee: Building, Breaking, and Betting Big: &lt;/strong&gt;Roy Lee (co-founder and CEO, Cluely)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;From Courtside to Code: Tristan Thompson on AI, Sports, and Startups:&lt;/strong&gt; Tristan Thompson (NBA champion and fintech entrepreneur)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Announcing the Winner of the Startup Battlefield 2025&lt;/strong&gt;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-roundtable-sessions"&gt;Roundtable sessions&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Participate in these 30-minute collaborative sessions. Note that Expo+ Passes do not grant access to these roundtables.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;AI Evaluation 101: Addressing Challenges to Real-World AI Applications:&amp;nbsp;&lt;/strong&gt;Rohit Patel (director, Meta Superintelligence Labs, Meta)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Consumer AI and Gen Z Tech&lt;/strong&gt;&lt;strong&gt;:&lt;/strong&gt;&lt;strong&gt; &lt;/strong&gt;Piyush Shah (co-founder, InMobi)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Scaling Search and AI for Millions:&lt;/strong&gt; &lt;strong&gt;Lessons from Reddit Search [Encore]:&lt;/strong&gt; Rachel Miller (product manager, Reddit)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Relentless Progress: Building Products that Never Stall:&lt;/strong&gt; Papi Menon (VP and chief product officer, Outshift by Cisco)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Raising a Seed Round in San Francisco as an Outsider: &lt;/strong&gt;Alice Bentinck (CEO and co-founder, Entrepreneurs First)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Beyond the Model: Building the Infrastructure of Intelligence: &lt;/strong&gt;Ben Braverman&amp;nbsp;(co-founder and managing partner, Saga Ventures)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;AI Evaluation 101:&lt;/strong&gt; &lt;strong&gt;Addressing Challenges to Real-World AI Applications [Encore]:&lt;/strong&gt; Rohit Patel (director, Meta Superintelligence Labs, Meta)&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-expo-hall"&gt;Expo Hall&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The buzzing Expo Hall will &lt;strong&gt;host 300+ startups&lt;/strong&gt; from all stages, industries, and regions worldwide. Engage with them and explore the groundbreaking innovations they’re thrilled to showcase. Opens at 8:00 a.m.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-breakout-stage"&gt;Breakout Stage&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;These 50-minute first-come, first-served sessions are meant to provide insights and get your burning questions answered. Located right next to the Expo Hall and accessible to all ticket types.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Being Heard in the Age of AI: &lt;/strong&gt;Qianwen Chen (CEO, EchoHer), Fay Kallel (chief product and design officer, Headspace), and Chenxi Wang (general partner, Rain Capital)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Powering AI: The Race to Scale Gigawatts of New Energy: &lt;/strong&gt;Mike Schroepfer (founder and partner, Gigascale Capital) and Garth Sheldon-Coulson (co-founder and CEO, Panthalassa)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;AI &amp;amp; Agents: Shaping How We Build, Live &amp;amp; Connect&lt;/strong&gt;&lt;strong&gt;:&lt;/strong&gt; Thomas Foley (revenue leader, Composio), Patrick Murphy (CEO and co-founder, Maket), Jeremiah Owyang (general partner, Blitzscaling Ventures), and Alyx van der Vorm (founder and CEO, Clyx)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Discovery to Disruption: Turning Research into Venture-Backable Companies&lt;/strong&gt;&lt;strong&gt;:&lt;/strong&gt;&lt;strong&gt; &lt;/strong&gt;Pratik Nimbalkar (CEO, Plaid Semiconductors), Jared O (co-founder and CEO, SirenOpt Inc.), Chon Tang (managing partner, Berkeley SkyDeck Fund), and Asad Tirmizi (CEO, T-robotics)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;SOSV: Where Deep Tech is Headed (It’s Not JUST AI)&lt;/strong&gt;&lt;strong&gt;:&lt;/strong&gt; Sierra Brooks (senior scientist and analyst, SOSV), Po Bronson (general Partner, SOSV, and managing director, IndieBio SF), Westley Dang (principal, SOSV), Philipp Sander (investment analyst, SOSV)&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-pitch-showcase-stage"&gt;Pitch Showcase Stage&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Catch exhibitors’ fast pitches on the Pitch Showcase Stage, located in the Expo Hall.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;9:30 a.m. – 12:00 p.m.:&lt;/strong&gt; Startup Battlefield 200 Health Pitches&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;1:00 p.m. – 3:00 p.m.:&lt;/strong&gt; Startup Battlefield 200 Policy + Protection Pitches&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-unmatched-networking-where-conversations-spark-innovation"&gt;Unmatched networking: Where conversations spark innovation&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to casually mingling with fellow Disrupt attendees, elevate your networking experience via Braindate. You can create or explore topics on the app for deeper conversations and make the right connections to help you reach your goals. Meet in person at the Networking Lounge powered by Braindate for 1:1 or small-group discussions anytime between 9:00 a.m. and 3:30 p.m.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-side-events"&gt;Side Events&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;More than 80 company-hosted Side Events are set to happen throughout San Francisco this week, extending the Disrupt excitement. Here’s what’s happening today. To RSVP and for more details, head to the &lt;strong&gt;Side Events page&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-last-call-for-techcrunch-disrupt-2025-magic-don-t-miss-the-finale"&gt;Last call for TechCrunch Disrupt 2025 magic — Don’t miss the finale&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Today is the final day of the conference. Right now, startups are pitching breakthrough ideas, connections are sparking across the Expo Hall, and industry giants are dropping game-changing insights onstage. We really don’t want you to have to wait another 365 days for next year’s conference. Don’t miss the energy, the innovation, and the opportunity. &lt;strong&gt;Register here&lt;/strong&gt; to get a 50% discount on your pass and head to Moscone West for your ticket.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025" class="wp-image-3048094" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/TC25_Disrupt_General_Article_No-Anniversary_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Welcome to the third and final day of &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; at Moscone West in San Francisco! The excitement here is still in full swing, and there’s no slowing down.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If you thought it was too late to join, think again — &lt;strong&gt;there’s still time to register with a 50% discount&lt;/strong&gt; and be part of the action. Don’t wait a whole year to be at &lt;em&gt;the&lt;/em&gt; tech epicenter of the year.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Today’s agenda features some of the most anticipated stage sessions, spotlighting insights from trailblazers such as Rohit Patel, director at Meta Superintelligence Labs; Kirsten Green, founding partner of Forerunner; and Tristan Thompson, NBA champion and fintech entrepreneur — among others. Excitement builds throughout the day as we await the announcement of the &lt;strong&gt;Startup Battlefield 200&lt;/strong&gt; winner. Be sure to explore groundbreaking innovations in the Expo Hall, gain invaluable knowledge from industry leaders in hands-on sessions, and forge meaningful connections that could shape your next big move.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-important-reminders-for-today-at-disrupt"&gt;Important reminders for today at Disrupt&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Register and grab your scannable badge at the Registration Desk anytime from 8:00 a.m. to 3:30 p.m.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Don’t forget your ticket and government-issued photo ID. The name on your badge/ticket must match the name on your ID. You cannot pick up a badge for another attendee.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Investors Breakfast Fireside Chat: Innovation in the Next Decade — The Next Growth Engines and Funding Models&lt;/strong&gt;: Location: Deal Flow Cafe (Investor Pass holders only)&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Get ready for an action-packed day — here’s what’s in store for day 3 of Disrupt 2025.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h2 class="wp-block-heading" id="h-today-s-sessions"&gt;Today’s sessions&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;We’re closing out Disrupt 2025 with a powerful lineup of industry leaders hitting the stage. Visit the full agenda for timing and session info.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-ai-stage"&gt;AI Stage&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;From Ads to Films: Creating with Code:&lt;/strong&gt; Alejandro Matamala Ortiz (co-founder and chief design officer, Runway)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;The $1M AI Trust Bet: Can We Truly Trust an AI Agent to Run Influencer Marketing?:&lt;/strong&gt; Francis Yang (co-founder and chief product officer, Aha)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;How Google Is Building for the Agentic Cloud:&lt;/strong&gt; Will Grannis (CTO, Google Cloud)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;AI in the Dust: Building Trustworthy Models for the Physical World: &lt;/strong&gt;Fahad Khan (senior director, product management, Platform, Blue River Technology [John Deere]) and Jeff Mills (president and chief of revenue operations, iMerit Technology)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Shaping the AI Stack with Hugging Face&lt;/strong&gt;&lt;strong&gt;:&lt;/strong&gt; Thomas Wolf (co-founder and chief science officer, Hugging Face)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Love, Lies &amp;amp; Algorithms: The Truth about AI in Matters of the Heart:&lt;/strong&gt; Dr. Amanda Gesselman (research scientist, Kinsey Institute), Mark Kantor (head of product, Tinder), and Eugenia Kuyda (founder, Replika)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Smarter Streets: How AI Is Driving the Future of Transportation: &lt;/strong&gt;Dave Ferguson (co-founder and co-CEO, Nuro) and Sachin Kansal (chief product officer, Uber Technologies)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;AI and National Security in the High-Stakes Race to Innovate:&lt;/strong&gt; Justin Fanelli (chief technology officer, U.S. Dept of Navy), Kathleen Fisher (director, AI and Cybersecurity Initiative, RAND Corporation), and Chris Morales (partner, Point72 Ventures)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;AI That Talks Back: Character.AI in the Spotlight:&lt;/strong&gt; Karandeep Anand (CEO, Character.AI)&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-builders-stage"&gt;Builders Stage&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Seed Money Secrets Every Founder Should Know:&lt;/strong&gt; Gabby Cazeau (partner, Harlem Capital), Marlon Nichols (co-founder and managing general partner, MaC Venture Capital), and Maria Palma (general partner, Freestyle Capital)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Rethinking Startup Capital without VCs:&lt;/strong&gt; Erik Allebest (CEO, Chess.com), Louwee Shibata (founder and partner, Next Gen, KALDOS Capital), and Gale Wilkinson (managing partner, VITALIZE Venture Capital)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Global Hiring Isn’t Spooky! And Paying in Crypto Shouldn’t be Either:&lt;/strong&gt; Francoise Brougher (chief executive officer, Pebl) and Aileen Lee (founder and managing partner, Cowboy Ventures)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;With Vibe Coding, Do Early Stage Startups Still Need to Hire 10x Engineers?: &lt;/strong&gt;David Cramer (co-founder and CPO, Sentry), Zach Lloyd (CEO and founder, Warp), and Lauri Moore (partner, Bessemer Venture Partners)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Preparing Now for Your Later Stage Raise: &lt;/strong&gt;Lila Preston (head of growth equity, Generation Investment Management), Sadi Khan (co-founder and CEO, Aven), and Zeya Yang (partner, IVP)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;The Pros and Cons of Hiring AI Agents as Early Employees:&lt;/strong&gt; Jaspar Carmichael-Jack (co-founder and CEO, Artisan), Sarah Franklin (CEO, Lattice), and Caleb Peffer (co-founder and CEO, Firecrawl)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Creating Communities and Companies that Last: &lt;/strong&gt;Tade Oyerinde (founder and chancellor, Campus) and Teddy Solomon (co-founder and CEO, Fizz)&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-disrupt-stage"&gt;Disrupt Stage&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Rebuilding the City that Builds Startups: &lt;/strong&gt;Daniel Lurie (mayor of San Francisco, City and County of San Francisco)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;A Conversation with Investor Extraordinaire Elad Gil:&lt;/strong&gt; Elad Gil (Gil &amp;amp; Co.)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Survive, Scale, Reinvent: Lessons from a Cloud OG: &lt;/strong&gt;Aaron Levie (co-founder and CEO, Box)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Startup Battlefield Alumni Update: &lt;/strong&gt;Dr. Capella Kerst (CEO and founder, geCKo Materials)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;The Startup Battlefield Final:&lt;/strong&gt; Kirsten Green (founding partner, Forerunner), Kevin Hartz (general partner, A*), Aileen Lee (founder and managing partner, Cowboy Ventures), and Kevin Rose (founder, Digg)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Crypto’s Next Chapter with Solana’s Anatoly Yakovenko:&lt;/strong&gt; Anatoly Yakovenko&amp;nbsp;(co-founder, Solana, and CEO, Solana Labs)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;From Digg to Deals: Kevin Rose on Reinvention and Investing:&lt;/strong&gt; Kevin Rose (founder, Digg)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Cluely’s Roy Lee: Building, Breaking, and Betting Big: &lt;/strong&gt;Roy Lee (co-founder and CEO, Cluely)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;From Courtside to Code: Tristan Thompson on AI, Sports, and Startups:&lt;/strong&gt; Tristan Thompson (NBA champion and fintech entrepreneur)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Announcing the Winner of the Startup Battlefield 2025&lt;/strong&gt;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-roundtable-sessions"&gt;Roundtable sessions&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Participate in these 30-minute collaborative sessions. Note that Expo+ Passes do not grant access to these roundtables.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;AI Evaluation 101: Addressing Challenges to Real-World AI Applications:&amp;nbsp;&lt;/strong&gt;Rohit Patel (director, Meta Superintelligence Labs, Meta)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Consumer AI and Gen Z Tech&lt;/strong&gt;&lt;strong&gt;:&lt;/strong&gt;&lt;strong&gt; &lt;/strong&gt;Piyush Shah (co-founder, InMobi)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Scaling Search and AI for Millions:&lt;/strong&gt; &lt;strong&gt;Lessons from Reddit Search [Encore]:&lt;/strong&gt; Rachel Miller (product manager, Reddit)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Relentless Progress: Building Products that Never Stall:&lt;/strong&gt; Papi Menon (VP and chief product officer, Outshift by Cisco)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Raising a Seed Round in San Francisco as an Outsider: &lt;/strong&gt;Alice Bentinck (CEO and co-founder, Entrepreneurs First)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Beyond the Model: Building the Infrastructure of Intelligence: &lt;/strong&gt;Ben Braverman&amp;nbsp;(co-founder and managing partner, Saga Ventures)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;AI Evaluation 101:&lt;/strong&gt; &lt;strong&gt;Addressing Challenges to Real-World AI Applications [Encore]:&lt;/strong&gt; Rohit Patel (director, Meta Superintelligence Labs, Meta)&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-expo-hall"&gt;Expo Hall&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The buzzing Expo Hall will &lt;strong&gt;host 300+ startups&lt;/strong&gt; from all stages, industries, and regions worldwide. Engage with them and explore the groundbreaking innovations they’re thrilled to showcase. Opens at 8:00 a.m.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-breakout-stage"&gt;Breakout Stage&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;These 50-minute first-come, first-served sessions are meant to provide insights and get your burning questions answered. Located right next to the Expo Hall and accessible to all ticket types.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Being Heard in the Age of AI: &lt;/strong&gt;Qianwen Chen (CEO, EchoHer), Fay Kallel (chief product and design officer, Headspace), and Chenxi Wang (general partner, Rain Capital)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Powering AI: The Race to Scale Gigawatts of New Energy: &lt;/strong&gt;Mike Schroepfer (founder and partner, Gigascale Capital) and Garth Sheldon-Coulson (co-founder and CEO, Panthalassa)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;AI &amp;amp; Agents: Shaping How We Build, Live &amp;amp; Connect&lt;/strong&gt;&lt;strong&gt;:&lt;/strong&gt; Thomas Foley (revenue leader, Composio), Patrick Murphy (CEO and co-founder, Maket), Jeremiah Owyang (general partner, Blitzscaling Ventures), and Alyx van der Vorm (founder and CEO, Clyx)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Discovery to Disruption: Turning Research into Venture-Backable Companies&lt;/strong&gt;&lt;strong&gt;:&lt;/strong&gt;&lt;strong&gt; &lt;/strong&gt;Pratik Nimbalkar (CEO, Plaid Semiconductors), Jared O (co-founder and CEO, SirenOpt Inc.), Chon Tang (managing partner, Berkeley SkyDeck Fund), and Asad Tirmizi (CEO, T-robotics)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;SOSV: Where Deep Tech is Headed (It’s Not JUST AI)&lt;/strong&gt;&lt;strong&gt;:&lt;/strong&gt; Sierra Brooks (senior scientist and analyst, SOSV), Po Bronson (general Partner, SOSV, and managing director, IndieBio SF), Westley Dang (principal, SOSV), Philipp Sander (investment analyst, SOSV)&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-pitch-showcase-stage"&gt;Pitch Showcase Stage&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Catch exhibitors’ fast pitches on the Pitch Showcase Stage, located in the Expo Hall.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;9:30 a.m. – 12:00 p.m.:&lt;/strong&gt; Startup Battlefield 200 Health Pitches&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;1:00 p.m. – 3:00 p.m.:&lt;/strong&gt; Startup Battlefield 200 Policy + Protection Pitches&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-unmatched-networking-where-conversations-spark-innovation"&gt;Unmatched networking: Where conversations spark innovation&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to casually mingling with fellow Disrupt attendees, elevate your networking experience via Braindate. You can create or explore topics on the app for deeper conversations and make the right connections to help you reach your goals. Meet in person at the Networking Lounge powered by Braindate for 1:1 or small-group discussions anytime between 9:00 a.m. and 3:30 p.m.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-side-events"&gt;Side Events&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;More than 80 company-hosted Side Events are set to happen throughout San Francisco this week, extending the Disrupt excitement. Here’s what’s happening today. To RSVP and for more details, head to the &lt;strong&gt;Side Events page&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-last-call-for-techcrunch-disrupt-2025-magic-don-t-miss-the-finale"&gt;Last call for TechCrunch Disrupt 2025 magic — Don’t miss the finale&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Today is the final day of the conference. Right now, startups are pitching breakthrough ideas, connections are sparking across the Expo Hall, and industry giants are dropping game-changing insights onstage. We really don’t want you to have to wait another 365 days for next year’s conference. Don’t miss the energy, the innovation, and the opportunity. &lt;strong&gt;Register here&lt;/strong&gt; to get a 50% discount on your pass and head to Moscone West for your ticket.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025" class="wp-image-3048094" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/TC25_Disrupt_General_Article_No-Anniversary_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/29/techcrunch-disrupt-2025-day-3/</guid><pubDate>Wed, 29 Oct 2025 14:00:00 +0000</pubDate></item><item><title>[NEW] Accelerating discovery with the AI for Math Initiative (Google DeepMind Blog)</title><link>https://deepmind.google/discover/blog/accelerating-discovery-with-the-ai-for-math-initiative/</link><description>&lt;div class="article-image-hero"&gt;
  &lt;div class="article-image-hero__container"&gt;
    &lt;figure class="article-image--full-aspect article-module"&gt;
      &lt;div class="aspect-ratio-image"&gt;
        &lt;div class="aspect-ratio-image__container"&gt;
          &lt;img alt="Mathematical formulas in front of a gradient blue and yellow background" class="aspect-ratio-image__image uni-progressive-image--blur" height="150px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AIforMath_Hero_Image_-_2096_x_118.width-2200.format-webp.webp" width="360px" /&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      
    &lt;/figure&gt;
  &lt;/div&gt;
&lt;/div&gt;&lt;div class="uni-content uni-blog-article-container article-container__content
                      
                      "&gt;

            
              







            

            
            
&lt;!--article text--&gt;

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Mathematics is the foundational language of the universe, providing the tools to describe everything from the laws of physics to the intricacies of biology and the logic of computer science. For centuries, its frontiers have been expanded by human ingenuity alone. At Google DeepMind, we believe AI can serve as a powerful tool to collaborate with mathematicians, augmenting creativity and accelerating discovery.&lt;/p&gt;&lt;p&gt;Today, we’re introducing the AI for Math Initiative, supported by Google DeepMind and Google.org. It brings together five of the world's most prestigious research institutions to pioneer the use of AI in mathematical research.&lt;/p&gt;&lt;p&gt;The inaugural partner institutions are:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Imperial College London&lt;/li&gt;&lt;li&gt;Institute for Advanced Study&lt;/li&gt;&lt;li&gt;Institut des Hautes Études Scientifiques (IHES)&lt;/li&gt;&lt;li&gt;Simons Institute for the Theory of Computing (UC Berkeley)&lt;/li&gt;&lt;li&gt;Tata Institute of Fundamental Research (TIFR)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The initiative’s partners will work towards the shared goals of identifying the next generation of mathematical problems ripe for AI-driven insights, building the infrastructure and tools to power these advances and, ultimately, accelerating the pace of discovery.&lt;/p&gt;&lt;p&gt;Google’s support includes funding from Google.org and access to Google DeepMind’s state-of-the-art technologies, such as an enhanced reasoning mode called Gemini Deep Think, our agent for algorithm discovery, AlphaEvolve, and our formal proof completion system, AlphaProof. The initiative will create a powerful feedback loop between fundamental research and applied AI, opening the door to deeper partnerships.&lt;/p&gt;&lt;h2&gt;A pivotal moment for AI and mathematics&lt;/h2&gt;&lt;p&gt;The AI for Math Initiative comes at a time of remarkable progress in AI’s reasoning capabilities; our own work has seen rapid advancement in recent months.&lt;/p&gt;&lt;p&gt;In 2024, our AlphaGeometry and AlphaProof systems achieved a silver-medal standard at the International Mathematical Olympiad (IMO). More recently, our latest Gemini model, equipped with Deep Think, achieved a gold-medal level performance at this year’s IMO, perfectly solving five of the six problems and scoring 35 points.&lt;/p&gt;&lt;p&gt;And we’ve seen further progress with another of our methods, AlphaEvolve, which was applied to over 50 open problems in mathematical analysis, geometry, combinatorics and number theory and improved the previously best known solutions in 20% of them. In mathematics and algorithm discovery, it has invented a new, more efficient method for matrix multiplication — a core calculation in computing. For the specific problem of multiplying 4x4 matrices, AlphaEvolve discovered an algorithm using just 48 scalar multiplications, breaking the 50-year-old record set by Strassen’s algorithm in 1969. In computer science, it helped researchers discover new mathematical structures that show certain complex problems are even harder for computers to solve than we previously knew. This gives us a clearer and more precise understanding of computational limits, which will help guide future research.&lt;/p&gt;&lt;p&gt;This rapid progress is a testament to the fast-evolving capabilities of AI models. We hope this new initiative can explore how AI can accelerate discovery in mathematical research, and tackle harder problems.&lt;/p&gt;&lt;p&gt;We are only at the beginning of understanding everything AI can do, and how it can help us think about the deepest questions in science. By combining the profound intuition of world-leading mathematicians with the novel capabilities of AI, we believe new pathways of research can be opened, advancing human knowledge and moving toward new breakthroughs across the scientific disciplines.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  


            
            

            
              


&lt;div class="
    uni-blog-article-tags
    article-tags
    
  "&gt;
  &lt;div class="uni-blog-article-tags__wrapper"&gt;
    &lt;span class="uni-blog-article-tags__label uni-eyebrow"&gt;POSTED IN:&lt;/span&gt;
  &lt;/div&gt;
  &lt;nav class="uni-blog-article-tags__container uni-click-tracker"&gt;
    &lt;ul class="uni-blog-article-tags__tags-list"&gt;
    
      &lt;li&gt;
        
        
        


  


Google DeepMind


  


      &lt;/li&gt;
    

    
      &lt;li&gt;
        
        
        


  


Google.org


  


      &lt;/li&gt;
    
    &lt;/ul&gt;
  &lt;/nav&gt;
&lt;/div&gt;

            
          &lt;/div&gt;</description><content:encoded>&lt;div class="article-image-hero"&gt;
  &lt;div class="article-image-hero__container"&gt;
    &lt;figure class="article-image--full-aspect article-module"&gt;
      &lt;div class="aspect-ratio-image"&gt;
        &lt;div class="aspect-ratio-image__container"&gt;
          &lt;img alt="Mathematical formulas in front of a gradient blue and yellow background" class="aspect-ratio-image__image uni-progressive-image--blur" height="150px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AIforMath_Hero_Image_-_2096_x_118.width-2200.format-webp.webp" width="360px" /&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      
    &lt;/figure&gt;
  &lt;/div&gt;
&lt;/div&gt;&lt;div class="uni-content uni-blog-article-container article-container__content
                      
                      "&gt;

            
              







            

            
            
&lt;!--article text--&gt;

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Mathematics is the foundational language of the universe, providing the tools to describe everything from the laws of physics to the intricacies of biology and the logic of computer science. For centuries, its frontiers have been expanded by human ingenuity alone. At Google DeepMind, we believe AI can serve as a powerful tool to collaborate with mathematicians, augmenting creativity and accelerating discovery.&lt;/p&gt;&lt;p&gt;Today, we’re introducing the AI for Math Initiative, supported by Google DeepMind and Google.org. It brings together five of the world's most prestigious research institutions to pioneer the use of AI in mathematical research.&lt;/p&gt;&lt;p&gt;The inaugural partner institutions are:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Imperial College London&lt;/li&gt;&lt;li&gt;Institute for Advanced Study&lt;/li&gt;&lt;li&gt;Institut des Hautes Études Scientifiques (IHES)&lt;/li&gt;&lt;li&gt;Simons Institute for the Theory of Computing (UC Berkeley)&lt;/li&gt;&lt;li&gt;Tata Institute of Fundamental Research (TIFR)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The initiative’s partners will work towards the shared goals of identifying the next generation of mathematical problems ripe for AI-driven insights, building the infrastructure and tools to power these advances and, ultimately, accelerating the pace of discovery.&lt;/p&gt;&lt;p&gt;Google’s support includes funding from Google.org and access to Google DeepMind’s state-of-the-art technologies, such as an enhanced reasoning mode called Gemini Deep Think, our agent for algorithm discovery, AlphaEvolve, and our formal proof completion system, AlphaProof. The initiative will create a powerful feedback loop between fundamental research and applied AI, opening the door to deeper partnerships.&lt;/p&gt;&lt;h2&gt;A pivotal moment for AI and mathematics&lt;/h2&gt;&lt;p&gt;The AI for Math Initiative comes at a time of remarkable progress in AI’s reasoning capabilities; our own work has seen rapid advancement in recent months.&lt;/p&gt;&lt;p&gt;In 2024, our AlphaGeometry and AlphaProof systems achieved a silver-medal standard at the International Mathematical Olympiad (IMO). More recently, our latest Gemini model, equipped with Deep Think, achieved a gold-medal level performance at this year’s IMO, perfectly solving five of the six problems and scoring 35 points.&lt;/p&gt;&lt;p&gt;And we’ve seen further progress with another of our methods, AlphaEvolve, which was applied to over 50 open problems in mathematical analysis, geometry, combinatorics and number theory and improved the previously best known solutions in 20% of them. In mathematics and algorithm discovery, it has invented a new, more efficient method for matrix multiplication — a core calculation in computing. For the specific problem of multiplying 4x4 matrices, AlphaEvolve discovered an algorithm using just 48 scalar multiplications, breaking the 50-year-old record set by Strassen’s algorithm in 1969. In computer science, it helped researchers discover new mathematical structures that show certain complex problems are even harder for computers to solve than we previously knew. This gives us a clearer and more precise understanding of computational limits, which will help guide future research.&lt;/p&gt;&lt;p&gt;This rapid progress is a testament to the fast-evolving capabilities of AI models. We hope this new initiative can explore how AI can accelerate discovery in mathematical research, and tackle harder problems.&lt;/p&gt;&lt;p&gt;We are only at the beginning of understanding everything AI can do, and how it can help us think about the deepest questions in science. By combining the profound intuition of world-leading mathematicians with the novel capabilities of AI, we believe new pathways of research can be opened, advancing human knowledge and moving toward new breakthroughs across the scientific disciplines.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  


            
            

            
              


&lt;div class="
    uni-blog-article-tags
    article-tags
    
  "&gt;
  &lt;div class="uni-blog-article-tags__wrapper"&gt;
    &lt;span class="uni-blog-article-tags__label uni-eyebrow"&gt;POSTED IN:&lt;/span&gt;
  &lt;/div&gt;
  &lt;nav class="uni-blog-article-tags__container uni-click-tracker"&gt;
    &lt;ul class="uni-blog-article-tags__tags-list"&gt;
    
      &lt;li&gt;
        
        
        


  


Google DeepMind


  


      &lt;/li&gt;
    

    
      &lt;li&gt;
        
        
        


  


Google.org


  


      &lt;/li&gt;
    
    &lt;/ul&gt;
  &lt;/nav&gt;
&lt;/div&gt;

            
          &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://deepmind.google/discover/blog/accelerating-discovery-with-the-ai-for-math-initiative/</guid><pubDate>Wed, 29 Oct 2025 14:17:00 +0000</pubDate></item><item><title>[NEW] Nvidia hits record $5 trillion mark as CEO dismisses AI bubble concerns (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/10/nvidia-hits-record-5-trillion-mark-as-ceo-dismisses-ai-bubble-concerns/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        “I don’t believe we’re in an AI bubble,” says Huang after announcing $500B in orders.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The Nvidia logo on a blue background with an American flag." class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/02/nvidia_flag_2-300x169.jpg" width="300" /&gt;
                  &lt;img alt="The Nvidia logo on a blue background with an American flag." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/02/nvidia_flag_2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Nvidia / Benj Edwards

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Wednesday, Nvidia became the first company in history to reach a $5 trillion market capitalization, fresh on the heels of a GTC conference keynote in Washington, DC, where CEO Jensen Huang announced $500 billion in AI chip orders and plans to build seven supercomputers for the US government. The milestone comes a mere three months after Nvidia crossed the $4 trillion mark in July, vaulting the company past tech giants like Apple and Microsoft in market valuation but also driving continued fears of an AI investment bubble.&lt;/p&gt;
&lt;p&gt;Nvidia’s shares have climbed nearly 12-fold since the launch of ChatGPT in late 2022, as the AI boom propelled the S&amp;amp;P 500 to record highs. Shares of Nvidia stock rose 4.6 percent on Wednesday following the Tuesday announcement at the company’s GTC conference. During a Bloomberg Television interview at the event, Huang dismissed concerns about overheated valuations, saying, “I don’t believe we’re in an AI bubble. All of these different AI models we’re using—we’re using plenty of services and paying happily to do it.”&lt;/p&gt;
&lt;p&gt;Nvidia expects to ship 20 million units of its latest chips, compared to just 4 million units of the previous Hopper generation over its entire lifetime, Huang said at the conference. The $500 billion figure represents cumulative orders for the company’s Blackwell and Rubin processors through the end of 2026, though Huang noted that his projections did not include potential sales to China.&lt;/p&gt;
&lt;p&gt;While it probably feels like glory days for Nvidia at the moment, the success comes with a large dose of caution. Even prior to the latest valuation boom of the past 24 hours, the rapid rise in AI-related investments has fueled persistent concerns that market enthusiasm has outstripped the technology’s ability to deliver immediate economic value.&lt;/p&gt;
&lt;p&gt;Some analysts warn that valuations may be overheated. Matthew Tuttle, CEO of Tuttle Capital Management, told Reuters that “AI’s current expansion relies on a few dominant players financing each other’s capacity. The moment investors start demanding cash flow returns instead of capacity announcements, some of these flywheels could seize.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Partnerships and government contracts fuel optimism&lt;/h2&gt;
&lt;p&gt;At the GTC conference on Tuesday, Nvidia’s CEO went out of his way to repeatedly praise Donald Trump and his policies for accelerating domestic tech investment while warning that excluding China from Nvidia’s ecosystem could limit US access to half the world’s AI developers. The overall event stressed Nvidia’s role as an American company, with Huang even nodding to Trump’s signature slogan in his sign-off by thanking the audience for “making America great again.”&lt;/p&gt;
&lt;p&gt;Trump’s cooperation is paramount for Nvidia because US export controls have effectively blocked Nvidia’s AI chips from China, costing the company billions of dollars in revenue. Bob O’Donnell of TECHnalysis Research told Reuters that “Nvidia clearly brought their story to DC to both educate and gain favor with the US government. They managed to hit most of the hottest and most influential topics in tech.”&lt;/p&gt;
&lt;p&gt;Beyond the political messaging, Huang announced a series of partnerships and deals that apparently helped ease investor concerns about Nvidia’s future. The company announced collaborations with Uber Technologies, Palantir Technologies, and CrowdStrike Holdings, among others. Nvidia also revealed a $1 billion investment in Nokia to support the telecommunications company’s shift toward AI and 6G networking.&lt;/p&gt;
&lt;p&gt;The agreement with Uber will power a fleet of 100,000 self-driving vehicles with Nvidia technology, with automaker Stellantis among the first to deliver the robotaxis. Palantir will pair Nvidia’s technology with its Ontology platform to use AI techniques for logistics insights, with Lowe’s as an early adopter. Eli Lilly plans to build what Nvidia described as the most powerful supercomputer owned and operated by a pharmaceutical company, relying on more than 1,000 Blackwell AI accelerator chips.&lt;/p&gt;
&lt;p&gt;The $5 trillion valuation surpasses the total cryptocurrency market value and equals roughly half the size of the pan European Stoxx 600 equities index, Reuters notes. At current prices, Huang’s stake in Nvidia would be worth about $179.2 billion, making him the world’s eighth-richest person.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        “I don’t believe we’re in an AI bubble,” says Huang after announcing $500B in orders.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The Nvidia logo on a blue background with an American flag." class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/02/nvidia_flag_2-300x169.jpg" width="300" /&gt;
                  &lt;img alt="The Nvidia logo on a blue background with an American flag." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/02/nvidia_flag_2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Nvidia / Benj Edwards

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Wednesday, Nvidia became the first company in history to reach a $5 trillion market capitalization, fresh on the heels of a GTC conference keynote in Washington, DC, where CEO Jensen Huang announced $500 billion in AI chip orders and plans to build seven supercomputers for the US government. The milestone comes a mere three months after Nvidia crossed the $4 trillion mark in July, vaulting the company past tech giants like Apple and Microsoft in market valuation but also driving continued fears of an AI investment bubble.&lt;/p&gt;
&lt;p&gt;Nvidia’s shares have climbed nearly 12-fold since the launch of ChatGPT in late 2022, as the AI boom propelled the S&amp;amp;P 500 to record highs. Shares of Nvidia stock rose 4.6 percent on Wednesday following the Tuesday announcement at the company’s GTC conference. During a Bloomberg Television interview at the event, Huang dismissed concerns about overheated valuations, saying, “I don’t believe we’re in an AI bubble. All of these different AI models we’re using—we’re using plenty of services and paying happily to do it.”&lt;/p&gt;
&lt;p&gt;Nvidia expects to ship 20 million units of its latest chips, compared to just 4 million units of the previous Hopper generation over its entire lifetime, Huang said at the conference. The $500 billion figure represents cumulative orders for the company’s Blackwell and Rubin processors through the end of 2026, though Huang noted that his projections did not include potential sales to China.&lt;/p&gt;
&lt;p&gt;While it probably feels like glory days for Nvidia at the moment, the success comes with a large dose of caution. Even prior to the latest valuation boom of the past 24 hours, the rapid rise in AI-related investments has fueled persistent concerns that market enthusiasm has outstripped the technology’s ability to deliver immediate economic value.&lt;/p&gt;
&lt;p&gt;Some analysts warn that valuations may be overheated. Matthew Tuttle, CEO of Tuttle Capital Management, told Reuters that “AI’s current expansion relies on a few dominant players financing each other’s capacity. The moment investors start demanding cash flow returns instead of capacity announcements, some of these flywheels could seize.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Partnerships and government contracts fuel optimism&lt;/h2&gt;
&lt;p&gt;At the GTC conference on Tuesday, Nvidia’s CEO went out of his way to repeatedly praise Donald Trump and his policies for accelerating domestic tech investment while warning that excluding China from Nvidia’s ecosystem could limit US access to half the world’s AI developers. The overall event stressed Nvidia’s role as an American company, with Huang even nodding to Trump’s signature slogan in his sign-off by thanking the audience for “making America great again.”&lt;/p&gt;
&lt;p&gt;Trump’s cooperation is paramount for Nvidia because US export controls have effectively blocked Nvidia’s AI chips from China, costing the company billions of dollars in revenue. Bob O’Donnell of TECHnalysis Research told Reuters that “Nvidia clearly brought their story to DC to both educate and gain favor with the US government. They managed to hit most of the hottest and most influential topics in tech.”&lt;/p&gt;
&lt;p&gt;Beyond the political messaging, Huang announced a series of partnerships and deals that apparently helped ease investor concerns about Nvidia’s future. The company announced collaborations with Uber Technologies, Palantir Technologies, and CrowdStrike Holdings, among others. Nvidia also revealed a $1 billion investment in Nokia to support the telecommunications company’s shift toward AI and 6G networking.&lt;/p&gt;
&lt;p&gt;The agreement with Uber will power a fleet of 100,000 self-driving vehicles with Nvidia technology, with automaker Stellantis among the first to deliver the robotaxis. Palantir will pair Nvidia’s technology with its Ontology platform to use AI techniques for logistics insights, with Lowe’s as an early adopter. Eli Lilly plans to build what Nvidia described as the most powerful supercomputer owned and operated by a pharmaceutical company, relying on more than 1,000 Blackwell AI accelerator chips.&lt;/p&gt;
&lt;p&gt;The $5 trillion valuation surpasses the total cryptocurrency market value and equals roughly half the size of the pan European Stoxx 600 equities index, Reuters notes. At current prices, Huang’s stake in Nvidia would be worth about $179.2 billion, making him the world’s eighth-richest person.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/10/nvidia-hits-record-5-trillion-mark-as-ceo-dismisses-ai-bubble-concerns/</guid><pubDate>Wed, 29 Oct 2025 14:46:21 +0000</pubDate></item><item><title>[NEW] Building a high performance data and AI organization (2nd edition) (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/29/1124014/building-a-high-performance-data-and-ai-organization-2nd-edition/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;Databricks&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Four years is a lifetime when it comes to artificial intelligence. Since the first edition of this study was published in 2021, AI’s capabilities have been advancing at speed, and the advances have not slowed since generative AI’s breakthrough. For example, multimodality— the ability to process information not only as text but also as audio, video, and other unstructured formats—is becoming a common feature of AI models. AI’s capacity to reason and act autonomously has also grown, and organizations are now starting to work with AI agents that can do just that.&lt;/p&gt;  &lt;p&gt;Amid all the change, there remains a constant: the quality of an AI model’s outputs is only ever as good as the data&lt;br /&gt;that feeds it. Data management technologies and practices have also been advancing, but the second edition of this study suggests that most organizations are not leveraging those fast enough to keep up with AI’s development. As a result of that and other hindrances, relatively few organizations are delivering the desired business results from their AI strategy. No more than 2% of senior executives we surveyed rate their organizations highly in terms of delivering results from AI. &lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-1124016" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/MITTR-databricks2025.v6-cover.png?w=1555" width="1555" /&gt;&lt;/figure&gt;    &lt;p&gt;To determine the extent to which organizational data performance has improved as generative AI and other AI advances have taken hold, MIT Technology Review Insights surveyed 800 senior data and technology executives. We also conducted in-depth interviews with 15 technology and business leaders.&lt;/p&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1124017" height="1688" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/MITTR-databricks-2025-card1a.png?w=3000" width="3000" /&gt;&lt;/figure&gt;  &lt;p&gt;Key findings from the report include the following:&lt;/p&gt; 
 &lt;p&gt;• &lt;strong&gt;Few data teams are keeping pace with AI.&lt;/strong&gt; Organizations are doing no better today at delivering on data strategy than in pre-generative AI days. Among those surveyed in 2025, 12% are self-assessed data “high achievers” compared with 13% in 2021. Shortages of skilled talent remain a constraint, but teams also struggle with accessing fresh data, tracing lineage, and dealing with security complexity—important requirements for AI success.&lt;/p&gt;  &lt;p&gt;• &lt;strong&gt;Partly as a result, AI is not fully firing yet.&lt;/strong&gt; There are even fewer “high achievers” when it comes to AI. Just 2% of respondents rate their organizations’ AI performance highly today in terms of delivering measurable business results. In fact, most are still struggling to scale generative AI. While two thirds have deployed it, only 7% have done so widely.&lt;/p&gt;  &lt;p&gt;Download the report.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;Databricks&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Four years is a lifetime when it comes to artificial intelligence. Since the first edition of this study was published in 2021, AI’s capabilities have been advancing at speed, and the advances have not slowed since generative AI’s breakthrough. For example, multimodality— the ability to process information not only as text but also as audio, video, and other unstructured formats—is becoming a common feature of AI models. AI’s capacity to reason and act autonomously has also grown, and organizations are now starting to work with AI agents that can do just that.&lt;/p&gt;  &lt;p&gt;Amid all the change, there remains a constant: the quality of an AI model’s outputs is only ever as good as the data&lt;br /&gt;that feeds it. Data management technologies and practices have also been advancing, but the second edition of this study suggests that most organizations are not leveraging those fast enough to keep up with AI’s development. As a result of that and other hindrances, relatively few organizations are delivering the desired business results from their AI strategy. No more than 2% of senior executives we surveyed rate their organizations highly in terms of delivering results from AI. &lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-1124016" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/MITTR-databricks2025.v6-cover.png?w=1555" width="1555" /&gt;&lt;/figure&gt;    &lt;p&gt;To determine the extent to which organizational data performance has improved as generative AI and other AI advances have taken hold, MIT Technology Review Insights surveyed 800 senior data and technology executives. We also conducted in-depth interviews with 15 technology and business leaders.&lt;/p&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1124017" height="1688" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/MITTR-databricks-2025-card1a.png?w=3000" width="3000" /&gt;&lt;/figure&gt;  &lt;p&gt;Key findings from the report include the following:&lt;/p&gt; 
 &lt;p&gt;• &lt;strong&gt;Few data teams are keeping pace with AI.&lt;/strong&gt; Organizations are doing no better today at delivering on data strategy than in pre-generative AI days. Among those surveyed in 2025, 12% are self-assessed data “high achievers” compared with 13% in 2021. Shortages of skilled talent remain a constraint, but teams also struggle with accessing fresh data, tracing lineage, and dealing with security complexity—important requirements for AI success.&lt;/p&gt;  &lt;p&gt;• &lt;strong&gt;Partly as a result, AI is not fully firing yet.&lt;/strong&gt; There are even fewer “high achievers” when it comes to AI. Just 2% of respondents rate their organizations’ AI performance highly today in terms of delivering measurable business results. In fact, most are still struggling to scale generative AI. While two thirds have deployed it, only 7% have done so widely.&lt;/p&gt;  &lt;p&gt;Download the report.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/29/1124014/building-a-high-performance-data-and-ai-organization-2nd-edition/</guid><pubDate>Wed, 29 Oct 2025 15:00:00 +0000</pubDate></item><item><title>[NEW] Exclusive eBook: The Math on AI’s Energy Footprint (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/29/1125572/exclusive-ebook-we-did-the-math-on-ais-energy-footprint/</link><description>&lt;div class="contentBody__summaryBullets--81327c9379272772d1e74a64b6d4868a"&gt;&lt;p&gt;This ebook is available only for subscribers.&lt;/p&gt;
&lt;/div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;In this exclusive subscirber-only ebook you'll learn how the emissions from individual AI text, image, and video queries seem small—until you add up what the industry isn’t tracking and consider where it’s heading next.&lt;/p&gt;&lt;p&gt;by &lt;strong&gt;James O’Donnell&lt;/strong&gt; and &lt;strong&gt;&lt;strong&gt;Casey Crownhart&lt;/strong&gt;&lt;/strong&gt; May 20, 2025&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1127064" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/Screenshot-2025-10-29-at-1.24.52-PM.png" /&gt;&lt;/figure&gt;    &lt;p&gt;Table of contents&lt;/p&gt;  &lt;ul class="wp-block-list"&gt; &lt;li&gt;Part One: Making the model&lt;/li&gt;    &lt;li&gt;Part Two: A Query&lt;/li&gt;    &lt;li&gt;Part Three: Fuel and emissions&lt;/li&gt;    &lt;li&gt;Part Four: The future ahead&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;Related stories:&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="columns__wrapper--07c4096a3b25e22dc82ee78b6368d947 gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 core/columns_1"&gt;&lt;div class="wp-block-columns"&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1116471" src="https://wp.technologyreview.com/wp-content/uploads/2025/05/cooling-tower-blue-grid.png?w=3000" /&gt;&lt;div class="image-credit"&gt;NICK LITTLE&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="columns__wrapper--07c4096a3b25e22dc82ee78b6368d947 gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 core/columns_2"&gt;&lt;div class="wp-block-columns"&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-1117001" src="https://wp.technologyreview.com/wp-content/uploads/2025/05/home-grid.png?w=3000" /&gt;&lt;div class="image-credit"&gt;NICK LITTLE&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="columns__wrapper--07c4096a3b25e22dc82ee78b6368d947 gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 core/columns_3"&gt;&lt;div class="wp-block-columns"&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt; &lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-1116171" src="https://wp.technologyreview.com/wp-content/uploads/2025/05/MITTR-Roundtables-Zoom-Opening-Overlay-1920x1080-1.png?w=1920" /&gt;&lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="contentBody__summaryBullets--81327c9379272772d1e74a64b6d4868a"&gt;&lt;p&gt;This ebook is available only for subscribers.&lt;/p&gt;
&lt;/div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;In this exclusive subscirber-only ebook you'll learn how the emissions from individual AI text, image, and video queries seem small—until you add up what the industry isn’t tracking and consider where it’s heading next.&lt;/p&gt;&lt;p&gt;by &lt;strong&gt;James O’Donnell&lt;/strong&gt; and &lt;strong&gt;&lt;strong&gt;Casey Crownhart&lt;/strong&gt;&lt;/strong&gt; May 20, 2025&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1127064" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/Screenshot-2025-10-29-at-1.24.52-PM.png" /&gt;&lt;/figure&gt;    &lt;p&gt;Table of contents&lt;/p&gt;  &lt;ul class="wp-block-list"&gt; &lt;li&gt;Part One: Making the model&lt;/li&gt;    &lt;li&gt;Part Two: A Query&lt;/li&gt;    &lt;li&gt;Part Three: Fuel and emissions&lt;/li&gt;    &lt;li&gt;Part Four: The future ahead&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;Related stories:&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="columns__wrapper--07c4096a3b25e22dc82ee78b6368d947 gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 core/columns_1"&gt;&lt;div class="wp-block-columns"&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1116471" src="https://wp.technologyreview.com/wp-content/uploads/2025/05/cooling-tower-blue-grid.png?w=3000" /&gt;&lt;div class="image-credit"&gt;NICK LITTLE&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="columns__wrapper--07c4096a3b25e22dc82ee78b6368d947 gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 core/columns_2"&gt;&lt;div class="wp-block-columns"&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-1117001" src="https://wp.technologyreview.com/wp-content/uploads/2025/05/home-grid.png?w=3000" /&gt;&lt;div class="image-credit"&gt;NICK LITTLE&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="columns__wrapper--07c4096a3b25e22dc82ee78b6368d947 gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 core/columns_3"&gt;&lt;div class="wp-block-columns"&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt; &lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-1116171" src="https://wp.technologyreview.com/wp-content/uploads/2025/05/MITTR-Roundtables-Zoom-Opening-Overlay-1920x1080-1.png?w=1920" /&gt;&lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/29/1125572/exclusive-ebook-we-did-the-math-on-ais-energy-footprint/</guid><pubDate>Wed, 29 Oct 2025 15:28:34 +0000</pubDate></item><item><title>[NEW] Nvidia becomes first public company worth $5 trillion (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/29/nvidia-becomes-first-public-company-worth-5-trillion/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/GettyImages-2216028442.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The biggest beneficiary of the ongoing AI boom, Nvidia has become the first public company to pass the $5 trillion market cap milestone.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s shares rose more than 5.6% on Wednesday to as much as $212.19, on the back of news on Wednesday that U.S. President Donald Trump said he expects to discuss the company’s Blackwell chips with Chinese President Xi Jinping on Thursday.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Investors are also likely stoked by Nvidia CEO Jensen Huang’s comments on Tuesday that the company expects $500 billion in AI chip sales, and that it is building seven new supercomputers for the U.S. in areas like security, energy, and science that will require thousands of Nvidia GPUs. The company on Tuesday also said it had invested $1 billion in Nokia and would use some of its products to “enable communication service providers to launch AI-native 5G-Advanced and 6G networks on NVIDIA platforms.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The milestone comes just three months after Nvidia became the first company to cross the $4 trillion milestone. Its stock has surged more than 50% so far this year, buoyed by seemingly insatiable demand for its graphics processing units (GPU), which are being used widely in data centers for training large language models, inference, and more. Nvidia’s GPUs are valuable because they’re scarce — and by trading them directly into an ever-inflating data center scheme, Nvidia is making sure they stay that way.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;More generally, tech stocks have surged this year on optimism that AI tech stands to revolutionize industries across the world, similar to how the advent of the internet changed business. Over the past year, investors have been encouraged by a spree of multibillion-dollar deals — several of which had Nvidia at the center — to spur the development of data centers and infrastructure to build the compute capacity for resource-intensive AI models. In September, Nvidia announced that it would invest up to $100 billion in OpenAI, another beneficiary of the AI boom, in the coming years. Both companies said at the time that they intend to deploy 10GW worth of Nvidia systems to power OpenAI’s systems.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With a market cap of $5 trillion, Nvidia is now worth more than the aggregated stock markets of all countries, apart from the United States, China, and Japan.&lt;/p&gt;


&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/GettyImages-2216028442.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The biggest beneficiary of the ongoing AI boom, Nvidia has become the first public company to pass the $5 trillion market cap milestone.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s shares rose more than 5.6% on Wednesday to as much as $212.19, on the back of news on Wednesday that U.S. President Donald Trump said he expects to discuss the company’s Blackwell chips with Chinese President Xi Jinping on Thursday.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Investors are also likely stoked by Nvidia CEO Jensen Huang’s comments on Tuesday that the company expects $500 billion in AI chip sales, and that it is building seven new supercomputers for the U.S. in areas like security, energy, and science that will require thousands of Nvidia GPUs. The company on Tuesday also said it had invested $1 billion in Nokia and would use some of its products to “enable communication service providers to launch AI-native 5G-Advanced and 6G networks on NVIDIA platforms.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The milestone comes just three months after Nvidia became the first company to cross the $4 trillion milestone. Its stock has surged more than 50% so far this year, buoyed by seemingly insatiable demand for its graphics processing units (GPU), which are being used widely in data centers for training large language models, inference, and more. Nvidia’s GPUs are valuable because they’re scarce — and by trading them directly into an ever-inflating data center scheme, Nvidia is making sure they stay that way.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;More generally, tech stocks have surged this year on optimism that AI tech stands to revolutionize industries across the world, similar to how the advent of the internet changed business. Over the past year, investors have been encouraged by a spree of multibillion-dollar deals — several of which had Nvidia at the center — to spur the development of data centers and infrastructure to build the compute capacity for resource-intensive AI models. In September, Nvidia announced that it would invest up to $100 billion in OpenAI, another beneficiary of the AI boom, in the coming years. Both companies said at the time that they intend to deploy 10GW worth of Nvidia systems to power OpenAI’s systems.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With a market cap of $5 trillion, Nvidia is now worth more than the aggregated stock markets of all countries, apart from the United States, China, and Japan.&lt;/p&gt;


&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/29/nvidia-becomes-first-public-company-worth-5-trillion/</guid><pubDate>Wed, 29 Oct 2025 15:52:53 +0000</pubDate></item><item><title>[NEW] AI Safety Newsletter #65: Measuring Automation and Superintelligence Moratorium Letter (AI Safety Newsletter)</title><link>https://newsletter.safe.ai/p/ai-safety-newsletter-65-measuring</link><description>&lt;p&gt;&lt;span&gt;Welcome to the AI Safety Newsletter by the &lt;/span&gt;&lt;a href="https://safe.ai/" rel="rel"&gt;Center for AI Safety&lt;/a&gt;&lt;span&gt;. We discuss developments in AI and AI safety. No technical background required.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;In this edition: A new benchmark measures AI automation; 50,000 people, including top AI scientists, sign an open letter calling for a superintelligence moratorium.&lt;/p&gt;&lt;p&gt;&lt;span&gt;Listen to the AI Safety Newsletter for free on &lt;/span&gt;&lt;a href="https://spotify.link/E6lHa1ij2Cb" rel="rel"&gt;Spotify&lt;/a&gt;&lt;span&gt; or &lt;/span&gt;&lt;a href="https://podcasts.apple.com/us/podcast/ai-safety-newsletter/id1702875110" rel="rel"&gt;Apple Podcasts&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;The Center for AI Safety (CAIS) and Scale AI have released the &lt;/span&gt;&lt;a href="https://www.remotelabor.ai/" rel="rel"&gt;Remote Labor Index&lt;/a&gt;&lt;span&gt; (RLI), which tests whether AIs can automate a wide array of real computer work projects. RLI is intended to inform policy, AI research, and businesses about the effects of automation as AI continues to advance.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;RLI is the first benchmark of its kind.&lt;/strong&gt;&lt;span&gt; Previous AI benchmarks measure AIs on their intelligence and their abilities on isolated and specialized tasks, such as basic web browsing or coding. While these benchmarks measure useful capabilities, they don’t measure how AIs can affect the economy. RLI is the first benchmark to collect computer-based work projects from the real economy, containing work from many different professions, such as architecture, product design, video game development, and design.&lt;/span&gt;&lt;/p&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2 is-viewable-img" href="https://substackcdn.com/image/fetch/$s_!JvUw!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe24bafcb-ca39-4266-a23e-40b80ed54605_4898x5109.jpeg" rel="rel" target="_blank"&gt;&lt;div class="image2-inset"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="1519" src="https://substackcdn.com/image/fetch/$s_!JvUw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe24bafcb-ca39-4266-a23e-40b80ed54605_4898x5109.jpeg" width="1456" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;Examples of RLI Projects&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Current AI agents fully automate very few work projects, but are improving.&lt;/strong&gt;&lt;span&gt; AIs &lt;/span&gt;&lt;a href="https://leaderboard.safe.ai/" rel="rel"&gt;score highly&lt;/a&gt;&lt;span&gt; on existing narrow benchmarks, but RLI shows that there is a gap in the existing measurements: AIs cannot currently automate most economically valuable work, with the most capable AI agent only automating 2.5% of work projects on RLI, however there are signs of steady improvement over time.&lt;/span&gt;&lt;/p&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2 is-viewable-img" href="https://substackcdn.com/image/fetch/$s_!5KNO!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb18e8802-7260-41c0-913f-ee2c4c19c245_1600x945.png" rel="rel" target="_blank"&gt;&lt;div class="image2-inset"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="860" src="https://substackcdn.com/image/fetch/$s_!5KNO!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb18e8802-7260-41c0-913f-ee2c4c19c245_1600x945.png" width="1456" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;Current AI agents complete at most 2.5% of projects in RLI, but are improving steadily.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;span&gt;The Future of Life Institute (FLI) introduced an &lt;/span&gt;&lt;a href="https://superintelligence-statement.org/" rel="rel"&gt;open letter&lt;/a&gt;&lt;span&gt; with over 50,000 signatories endorsing the following text:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;We call for a prohibition on the development of superintelligence, not lifted before there is&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;broad scientific consensus that it will be done safely and controllably, and&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;strong public buy-in.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;The signatories form the broadest group to sign an open letter about AI safety in history.&lt;/strong&gt;&lt;span&gt; Among the signatories are five Nobel laureates, the two most cited scientists of all time, religious leaders, and major figures in public and political life from both the left and the right.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;This statement builds on previous open letters about AI risks, such as the &lt;/span&gt;&lt;a href="https://aistatement.com/" rel="rel"&gt;open letter&lt;/a&gt;&lt;span&gt; from CAIS in 2023 acknowledging AI extinction risks, as well as the &lt;/span&gt;&lt;a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/" rel="rel"&gt;previous open letter&lt;/a&gt;&lt;span&gt; from FLI calling for an AI training pause. While the CAIS letter was intended to establish a consensus about risks from AI and the first FLI letter was calling for a specific policy on a clear time frame, the broad coalition behind the new FLI letter and its associated polling creates a powerful consensus opinion about the risks of AI while also calling for action.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;In the past, critics of AI safety have dismissed the concept of superintelligence and AI risks due to lack of mainline scientific and public support. The breadth of people who have signed this open letter demonstrates that opinions are changing on the matter. This is confirmed by polling released concurrently to the open letter, showing that approximately 2 in 3 US adults believe that superintelligence shouldn’t be created, at least until it is proven safe and controllable.&lt;/p&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2" href="https://substackcdn.com/image/fetch/$s_!AjsK!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9cbeff48-e3b1-4883-9030-968235dd3ee7_846x227.png" rel="rel" target="_blank"&gt;&lt;div class="image2-inset"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="227" src="https://substackcdn.com/image/fetch/$s_!AjsK!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9cbeff48-e3b1-4883-9030-968235dd3ee7_846x227.png" width="846" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;span&gt;A broad range of news outlets have &lt;/span&gt;&lt;a href="https://news.google.com/stories/CAAqNggKIjBDQklTSGpvSmMzUnZjbmt0TXpZd1NoRUtEd2pRMnVfcER4SHBER2R1ekhRTXJ5Z0FQAQ?hl=en-US&amp;amp;gl=US&amp;amp;ceid=US:en" rel="rel"&gt;covered&lt;/a&gt;&lt;span&gt; the statement. Dean Ball and others &lt;/span&gt;&lt;a href="https://x.com/deanwball/status/1980975802570174831" rel="rel"&gt;push back&lt;/a&gt;&lt;span&gt; on the statement on X, pointing out the lack of specific details on how to implement a moratorium and the difficulty of doing so. Scott Alexander and others &lt;/span&gt;&lt;a href="https://x.com/slatestarcodex/status/1981032302147977570" rel="rel"&gt;respond&lt;/a&gt;&lt;span&gt; defending the value of statements of consensus as a tool for motivating developing specific details of AI safety policy.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Government&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Senator Jim Banks introduced the &lt;/span&gt;&lt;a href="https://www.congress.gov/amendment/119th-congress/senate-amendment/3505/text" rel="rel"&gt;GAIN AI act&lt;/a&gt;&lt;span&gt;, which would give US companies and individuals first priority to buy AI chips from US companies and deprioritize foreign buyers.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;State legislators &lt;/span&gt;&lt;a href="https://www.alexbores.nyc/" rel="rel"&gt;Alex Bores&lt;/a&gt;&lt;span&gt; (behind the &lt;/span&gt;&lt;a href="https://newsletter.safe.ai/p/ai-safety-newsletter-57-the-raise" rel="rel"&gt;RAISE act&lt;/a&gt;&lt;span&gt;) and &lt;/span&gt;&lt;a href="https://www.scottwiener.com/" rel="rel"&gt;Scott Wiener&lt;/a&gt;&lt;span&gt; (behind &lt;/span&gt;&lt;a href="https://newsletter.safe.ai/p/aisn-40-california-ai-legislation" rel="rel"&gt;SB 1047&lt;/a&gt;&lt;span&gt; and &lt;/span&gt;&lt;a href="https://newsletter.safe.ai/p/ai-safety-newsletter-63-californias" rel="rel"&gt;SB 53&lt;/a&gt;&lt;span&gt;) have both announced runs for US congress.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Industry&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;You can now officially order a &lt;/span&gt;&lt;a href="https://www.1x.tech/order" rel="rel"&gt;home robot&lt;/a&gt;&lt;span&gt; for $500/mo.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenAI &lt;/span&gt;&lt;a href="https://openai.com/index/next-chapter-of-microsoft-openai-partnership/" rel="rel"&gt;announces&lt;/a&gt;&lt;span&gt; corporate restructuring into a public benefit corporation and some new terms in their relationship with Microsoft.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Anthropic announces an &lt;/span&gt;&lt;a href="https://www.anthropic.com/news/expanding-our-use-of-google-cloud-tpus-and-services" rel="rel"&gt;expansion&lt;/a&gt;&lt;span&gt; into 1 million Google TPUs, worth tens of billions of dollars.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenAI’s Sora app &lt;/span&gt;&lt;a href="https://techcrunch.com/2025/10/03/openais-sora-soars-to-no-1-on-the-u-s-app-store/" rel="rel"&gt;was briefly&lt;/a&gt;&lt;span&gt; the most downloaded app on the app store.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Civil Society&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;A &lt;/span&gt;&lt;a href="https://futurism.com/artificial-intelligence/bystanders-horrified-ai-billboard" rel="rel"&gt;series of billboards&lt;/a&gt;&lt;span&gt; advertising “&lt;/span&gt;&lt;a href="https://replacement.ai" rel="rel"&gt;Replacement AI&lt;/a&gt;&lt;span&gt;” drew attention in San Francisco last week.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Bruce Schneier and Nathan E. Sanders &lt;/span&gt;&lt;a href="https://ai-frontiers.org/articles/ai-will-be-your-personal-political-proxy" rel="rel"&gt;discuss&lt;/a&gt;&lt;span&gt; AIs’ effect on representative democracy.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="https://ai-frontiers.org/articles/agis-last-bottlenecks" rel="rel"&gt;A forecast&lt;/a&gt;&lt;span&gt; based on the &lt;/span&gt;&lt;a href="https://www.agidefinition.ai/" rel="rel"&gt;definition of AGI&lt;/a&gt;&lt;span&gt; proposed last week argues for a 50% chance that AGI will be released by the end of 2028 and an 80% chance that it is released by the end of 2030.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;See also:&lt;/span&gt;&lt;a href="https://x.com/ai_risks?lang=en" rel="rel"&gt; CAIS’ X account&lt;/a&gt;&lt;span&gt;, our paper on&lt;/span&gt;&lt;a href="https://www.nationalsecurity.ai/" rel="rel"&gt; superintelligence strategy&lt;/a&gt;&lt;span&gt;, our&lt;/span&gt;&lt;a href="https://www.aisafetybook.com/" rel="rel"&gt; AI safety course&lt;/a&gt;&lt;span&gt;, and&lt;/span&gt;&lt;a href="http://ai-frontiers.org/" rel="rel"&gt; AI Frontiers&lt;/a&gt;&lt;span&gt;, a new platform for expert commentary and analysis.&lt;/span&gt;&lt;/p&gt;&lt;p class="button-wrapper"&gt;&lt;a class="button primary" href="https://newsletter.safe.ai/p/ai-safety-newsletter-65-measuring?utm_source=substack&amp;amp;utm_medium=email&amp;amp;utm_content=share&amp;amp;action=share" rel="rel"&gt;&lt;span&gt;Share&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;</description><content:encoded>&lt;p&gt;&lt;span&gt;Welcome to the AI Safety Newsletter by the &lt;/span&gt;&lt;a href="https://safe.ai/" rel="rel"&gt;Center for AI Safety&lt;/a&gt;&lt;span&gt;. We discuss developments in AI and AI safety. No technical background required.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;In this edition: A new benchmark measures AI automation; 50,000 people, including top AI scientists, sign an open letter calling for a superintelligence moratorium.&lt;/p&gt;&lt;p&gt;&lt;span&gt;Listen to the AI Safety Newsletter for free on &lt;/span&gt;&lt;a href="https://spotify.link/E6lHa1ij2Cb" rel="rel"&gt;Spotify&lt;/a&gt;&lt;span&gt; or &lt;/span&gt;&lt;a href="https://podcasts.apple.com/us/podcast/ai-safety-newsletter/id1702875110" rel="rel"&gt;Apple Podcasts&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;The Center for AI Safety (CAIS) and Scale AI have released the &lt;/span&gt;&lt;a href="https://www.remotelabor.ai/" rel="rel"&gt;Remote Labor Index&lt;/a&gt;&lt;span&gt; (RLI), which tests whether AIs can automate a wide array of real computer work projects. RLI is intended to inform policy, AI research, and businesses about the effects of automation as AI continues to advance.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;RLI is the first benchmark of its kind.&lt;/strong&gt;&lt;span&gt; Previous AI benchmarks measure AIs on their intelligence and their abilities on isolated and specialized tasks, such as basic web browsing or coding. While these benchmarks measure useful capabilities, they don’t measure how AIs can affect the economy. RLI is the first benchmark to collect computer-based work projects from the real economy, containing work from many different professions, such as architecture, product design, video game development, and design.&lt;/span&gt;&lt;/p&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2 is-viewable-img" href="https://substackcdn.com/image/fetch/$s_!JvUw!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe24bafcb-ca39-4266-a23e-40b80ed54605_4898x5109.jpeg" rel="rel" target="_blank"&gt;&lt;div class="image2-inset"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="1519" src="https://substackcdn.com/image/fetch/$s_!JvUw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe24bafcb-ca39-4266-a23e-40b80ed54605_4898x5109.jpeg" width="1456" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;Examples of RLI Projects&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Current AI agents fully automate very few work projects, but are improving.&lt;/strong&gt;&lt;span&gt; AIs &lt;/span&gt;&lt;a href="https://leaderboard.safe.ai/" rel="rel"&gt;score highly&lt;/a&gt;&lt;span&gt; on existing narrow benchmarks, but RLI shows that there is a gap in the existing measurements: AIs cannot currently automate most economically valuable work, with the most capable AI agent only automating 2.5% of work projects on RLI, however there are signs of steady improvement over time.&lt;/span&gt;&lt;/p&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2 is-viewable-img" href="https://substackcdn.com/image/fetch/$s_!5KNO!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb18e8802-7260-41c0-913f-ee2c4c19c245_1600x945.png" rel="rel" target="_blank"&gt;&lt;div class="image2-inset"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="860" src="https://substackcdn.com/image/fetch/$s_!5KNO!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb18e8802-7260-41c0-913f-ee2c4c19c245_1600x945.png" width="1456" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;Current AI agents complete at most 2.5% of projects in RLI, but are improving steadily.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;span&gt;The Future of Life Institute (FLI) introduced an &lt;/span&gt;&lt;a href="https://superintelligence-statement.org/" rel="rel"&gt;open letter&lt;/a&gt;&lt;span&gt; with over 50,000 signatories endorsing the following text:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;We call for a prohibition on the development of superintelligence, not lifted before there is&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;broad scientific consensus that it will be done safely and controllably, and&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;strong public buy-in.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;The signatories form the broadest group to sign an open letter about AI safety in history.&lt;/strong&gt;&lt;span&gt; Among the signatories are five Nobel laureates, the two most cited scientists of all time, religious leaders, and major figures in public and political life from both the left and the right.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;This statement builds on previous open letters about AI risks, such as the &lt;/span&gt;&lt;a href="https://aistatement.com/" rel="rel"&gt;open letter&lt;/a&gt;&lt;span&gt; from CAIS in 2023 acknowledging AI extinction risks, as well as the &lt;/span&gt;&lt;a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/" rel="rel"&gt;previous open letter&lt;/a&gt;&lt;span&gt; from FLI calling for an AI training pause. While the CAIS letter was intended to establish a consensus about risks from AI and the first FLI letter was calling for a specific policy on a clear time frame, the broad coalition behind the new FLI letter and its associated polling creates a powerful consensus opinion about the risks of AI while also calling for action.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;In the past, critics of AI safety have dismissed the concept of superintelligence and AI risks due to lack of mainline scientific and public support. The breadth of people who have signed this open letter demonstrates that opinions are changing on the matter. This is confirmed by polling released concurrently to the open letter, showing that approximately 2 in 3 US adults believe that superintelligence shouldn’t be created, at least until it is proven safe and controllable.&lt;/p&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2" href="https://substackcdn.com/image/fetch/$s_!AjsK!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9cbeff48-e3b1-4883-9030-968235dd3ee7_846x227.png" rel="rel" target="_blank"&gt;&lt;div class="image2-inset"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="227" src="https://substackcdn.com/image/fetch/$s_!AjsK!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9cbeff48-e3b1-4883-9030-968235dd3ee7_846x227.png" width="846" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;span&gt;A broad range of news outlets have &lt;/span&gt;&lt;a href="https://news.google.com/stories/CAAqNggKIjBDQklTSGpvSmMzUnZjbmt0TXpZd1NoRUtEd2pRMnVfcER4SHBER2R1ekhRTXJ5Z0FQAQ?hl=en-US&amp;amp;gl=US&amp;amp;ceid=US:en" rel="rel"&gt;covered&lt;/a&gt;&lt;span&gt; the statement. Dean Ball and others &lt;/span&gt;&lt;a href="https://x.com/deanwball/status/1980975802570174831" rel="rel"&gt;push back&lt;/a&gt;&lt;span&gt; on the statement on X, pointing out the lack of specific details on how to implement a moratorium and the difficulty of doing so. Scott Alexander and others &lt;/span&gt;&lt;a href="https://x.com/slatestarcodex/status/1981032302147977570" rel="rel"&gt;respond&lt;/a&gt;&lt;span&gt; defending the value of statements of consensus as a tool for motivating developing specific details of AI safety policy.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Government&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Senator Jim Banks introduced the &lt;/span&gt;&lt;a href="https://www.congress.gov/amendment/119th-congress/senate-amendment/3505/text" rel="rel"&gt;GAIN AI act&lt;/a&gt;&lt;span&gt;, which would give US companies and individuals first priority to buy AI chips from US companies and deprioritize foreign buyers.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;State legislators &lt;/span&gt;&lt;a href="https://www.alexbores.nyc/" rel="rel"&gt;Alex Bores&lt;/a&gt;&lt;span&gt; (behind the &lt;/span&gt;&lt;a href="https://newsletter.safe.ai/p/ai-safety-newsletter-57-the-raise" rel="rel"&gt;RAISE act&lt;/a&gt;&lt;span&gt;) and &lt;/span&gt;&lt;a href="https://www.scottwiener.com/" rel="rel"&gt;Scott Wiener&lt;/a&gt;&lt;span&gt; (behind &lt;/span&gt;&lt;a href="https://newsletter.safe.ai/p/aisn-40-california-ai-legislation" rel="rel"&gt;SB 1047&lt;/a&gt;&lt;span&gt; and &lt;/span&gt;&lt;a href="https://newsletter.safe.ai/p/ai-safety-newsletter-63-californias" rel="rel"&gt;SB 53&lt;/a&gt;&lt;span&gt;) have both announced runs for US congress.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Industry&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;You can now officially order a &lt;/span&gt;&lt;a href="https://www.1x.tech/order" rel="rel"&gt;home robot&lt;/a&gt;&lt;span&gt; for $500/mo.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenAI &lt;/span&gt;&lt;a href="https://openai.com/index/next-chapter-of-microsoft-openai-partnership/" rel="rel"&gt;announces&lt;/a&gt;&lt;span&gt; corporate restructuring into a public benefit corporation and some new terms in their relationship with Microsoft.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Anthropic announces an &lt;/span&gt;&lt;a href="https://www.anthropic.com/news/expanding-our-use-of-google-cloud-tpus-and-services" rel="rel"&gt;expansion&lt;/a&gt;&lt;span&gt; into 1 million Google TPUs, worth tens of billions of dollars.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenAI’s Sora app &lt;/span&gt;&lt;a href="https://techcrunch.com/2025/10/03/openais-sora-soars-to-no-1-on-the-u-s-app-store/" rel="rel"&gt;was briefly&lt;/a&gt;&lt;span&gt; the most downloaded app on the app store.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Civil Society&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;A &lt;/span&gt;&lt;a href="https://futurism.com/artificial-intelligence/bystanders-horrified-ai-billboard" rel="rel"&gt;series of billboards&lt;/a&gt;&lt;span&gt; advertising “&lt;/span&gt;&lt;a href="https://replacement.ai" rel="rel"&gt;Replacement AI&lt;/a&gt;&lt;span&gt;” drew attention in San Francisco last week.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Bruce Schneier and Nathan E. Sanders &lt;/span&gt;&lt;a href="https://ai-frontiers.org/articles/ai-will-be-your-personal-political-proxy" rel="rel"&gt;discuss&lt;/a&gt;&lt;span&gt; AIs’ effect on representative democracy.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a href="https://ai-frontiers.org/articles/agis-last-bottlenecks" rel="rel"&gt;A forecast&lt;/a&gt;&lt;span&gt; based on the &lt;/span&gt;&lt;a href="https://www.agidefinition.ai/" rel="rel"&gt;definition of AGI&lt;/a&gt;&lt;span&gt; proposed last week argues for a 50% chance that AGI will be released by the end of 2028 and an 80% chance that it is released by the end of 2030.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;See also:&lt;/span&gt;&lt;a href="https://x.com/ai_risks?lang=en" rel="rel"&gt; CAIS’ X account&lt;/a&gt;&lt;span&gt;, our paper on&lt;/span&gt;&lt;a href="https://www.nationalsecurity.ai/" rel="rel"&gt; superintelligence strategy&lt;/a&gt;&lt;span&gt;, our&lt;/span&gt;&lt;a href="https://www.aisafetybook.com/" rel="rel"&gt; AI safety course&lt;/a&gt;&lt;span&gt;, and&lt;/span&gt;&lt;a href="http://ai-frontiers.org/" rel="rel"&gt; AI Frontiers&lt;/a&gt;&lt;span&gt;, a new platform for expert commentary and analysis.&lt;/span&gt;&lt;/p&gt;&lt;p class="button-wrapper"&gt;&lt;a class="button primary" href="https://newsletter.safe.ai/p/ai-safety-newsletter-65-measuring?utm_source=substack&amp;amp;utm_medium=email&amp;amp;utm_content=share&amp;amp;action=share" rel="rel"&gt;&lt;span&gt;Share&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://newsletter.safe.ai/p/ai-safety-newsletter-65-measuring</guid><pubDate>Wed, 29 Oct 2025 16:01:51 +0000</pubDate></item><item><title>[NEW] How AI labs use Mercor to get the data companies won’t share (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/29/how-ai-labs-use-mercor-to-get-the-data-companies-wont-share/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/54888410931_c37fed4674_k.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Instead of signing expensive contracts with companies for their data, AI labs these days are trying a new tack: tapping former senior employees from those companies for their industry knowledge, Mercor CEO Brendan Foody said at TechCrunch Disrupt 2025 on Tuesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Speaking on a panel onstage, Foody cast Mercor’s marketplace as one of the main channels connecting the former employees of investment banks, consulting houses, and law firms with AI labs that are looking to automate those industries. Some of Mercor’s customers include OpenAI, Anthropic, and Meta.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“There is an argument that Goldman Sachs doesn’t love the idea of having models that are able to automate their value chain,” said Foody, using the Wall Street giant as an example. “It definitely shifts the competitive dynamics, and that’s part of the reason that the labs need us. Their customers don’t want to give them data to automate large portions of their value chains, so they need to hire contractors who previously worked at those companies, understand those workflows, and are willing to train models to automate them.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Foody, the 22-year-old co-founder of Mercor, says his startup pays industry experts up to $200 an hour to fill out forms and write reports for AI training. The company now has tens of thousands of contractors and says it doles out more than $1.5 million to them every day. Still, Foody says the startup remains profitable because AI labs are willing to pay even more for that valuable data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In just under three years since its inception, Mercor has increased its annualized recurring revenue to roughly $500 million, and recently raised funding at a $10 billion valuation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Incumbents across the economy have good reason to be resistant to Mercor’s rise, as their industry’s knowledge may be slipping out the back door through former employees on the startup’s marketplace, which could ultimately be used to automate their work. Foody acknowledged he may be exposing an inefficiency in the market but said he wouldn’t call it a “loophole.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In fact, Foody says some companies are already embracing this “new future of work.” He entertained the idea that Mercor’s marketplace could create a new type of gig economy, much like Uber did more than a decade ago. (Earlier this year, Uber’s former chief product officer, Sundeep Jain, joined Mercor as president.)&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“There are companies that are embracing it and realize that the world is going to change very quickly,” said Foody. “There’s definitely another category of companies that are fearful, and worry about being dis-intermediated, and having their customers go directly to the AI labs or application layer platforms. My hunch is that the former category is going to turn out to be on the right side of history.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Mercor tries to extract knowledge from various industries, Foody said his startup tries to prevent contractors from committing corporate espionage — the illegal act of stealing proprietary information, trade secrets, or intellectual property from one business and selling it to another.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But that’s easier said than done. Most of Mercor’s workforce are former employees of law firms, investment banks, and other industries that are very secretive about their data. Foody said some of Mercor’s contractors still work at their day jobs and just submit data on the side, and he claimed that contractors are instructed not to upload documents from their former workplace. Still, he acknowledged that it’s possible “there are things that happen” given the scale of his startup.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Foody argues that the knowledge in an employee’s head belongs to the employee, and not their company — a more generous view than many enterprises would take. Plus, in some of Mercor’s job postings, the startup walks the line between requesting an employee’s knowledge and their company’s data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For example, Mercor is currently looking for the CTO or co-founder of a startup who “can authorize&amp;nbsp;access to a substantial, production codebase” for AI evaluations, or potentially AI model training. In an email, Mercor told TechCrunch that a few startup CTOs have taken them up on this offer but declined to disclose details of their contracts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mercor was one of the first data startups to recruit highly skilled knowledge workers in the U.S. and pay them large sums to train AI models. Early in the AI boom, data vendors like Scale AI hired contractors in third-world countries to do fairly simple labeling jobs. Now, most of Mercor’s competitors — including Surge and Scale AI — have caught on that AI labs need experts to improve their AI models. Many data vendors have also started training “environments” to improve AI agents’ ability to complete real-world tasks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mercor has clearly benefited from Scale AI’s misfortunes: Many AI labs stopped working with Scale AI after Meta made a large investment in the startup and hired its CEO. In the last year, Mercor has quintupled its value, but it still remains smaller than Surge and Scale AI, which are both valued at upward of $20 billion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Today, most of Mercor’s revenue comes from just a few AI labs, but Foody says the startup plans to partner with other industries in the future. He believes companies in law, finance, and medicine will want help leveraging their data to train AI agents — something Mercor specializes in.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Over time, ChatGPT will be better than the best consulting firm, better than the best investment bank, and better than the best law firm,” said Foody. “That’s going to transform the economy radically, which will be a broadly positive force that helps to create abundance for everyone.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/54888410931_c37fed4674_k.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Instead of signing expensive contracts with companies for their data, AI labs these days are trying a new tack: tapping former senior employees from those companies for their industry knowledge, Mercor CEO Brendan Foody said at TechCrunch Disrupt 2025 on Tuesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Speaking on a panel onstage, Foody cast Mercor’s marketplace as one of the main channels connecting the former employees of investment banks, consulting houses, and law firms with AI labs that are looking to automate those industries. Some of Mercor’s customers include OpenAI, Anthropic, and Meta.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“There is an argument that Goldman Sachs doesn’t love the idea of having models that are able to automate their value chain,” said Foody, using the Wall Street giant as an example. “It definitely shifts the competitive dynamics, and that’s part of the reason that the labs need us. Their customers don’t want to give them data to automate large portions of their value chains, so they need to hire contractors who previously worked at those companies, understand those workflows, and are willing to train models to automate them.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Foody, the 22-year-old co-founder of Mercor, says his startup pays industry experts up to $200 an hour to fill out forms and write reports for AI training. The company now has tens of thousands of contractors and says it doles out more than $1.5 million to them every day. Still, Foody says the startup remains profitable because AI labs are willing to pay even more for that valuable data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In just under three years since its inception, Mercor has increased its annualized recurring revenue to roughly $500 million, and recently raised funding at a $10 billion valuation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Incumbents across the economy have good reason to be resistant to Mercor’s rise, as their industry’s knowledge may be slipping out the back door through former employees on the startup’s marketplace, which could ultimately be used to automate their work. Foody acknowledged he may be exposing an inefficiency in the market but said he wouldn’t call it a “loophole.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In fact, Foody says some companies are already embracing this “new future of work.” He entertained the idea that Mercor’s marketplace could create a new type of gig economy, much like Uber did more than a decade ago. (Earlier this year, Uber’s former chief product officer, Sundeep Jain, joined Mercor as president.)&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“There are companies that are embracing it and realize that the world is going to change very quickly,” said Foody. “There’s definitely another category of companies that are fearful, and worry about being dis-intermediated, and having their customers go directly to the AI labs or application layer platforms. My hunch is that the former category is going to turn out to be on the right side of history.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Mercor tries to extract knowledge from various industries, Foody said his startup tries to prevent contractors from committing corporate espionage — the illegal act of stealing proprietary information, trade secrets, or intellectual property from one business and selling it to another.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But that’s easier said than done. Most of Mercor’s workforce are former employees of law firms, investment banks, and other industries that are very secretive about their data. Foody said some of Mercor’s contractors still work at their day jobs and just submit data on the side, and he claimed that contractors are instructed not to upload documents from their former workplace. Still, he acknowledged that it’s possible “there are things that happen” given the scale of his startup.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Foody argues that the knowledge in an employee’s head belongs to the employee, and not their company — a more generous view than many enterprises would take. Plus, in some of Mercor’s job postings, the startup walks the line between requesting an employee’s knowledge and their company’s data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For example, Mercor is currently looking for the CTO or co-founder of a startup who “can authorize&amp;nbsp;access to a substantial, production codebase” for AI evaluations, or potentially AI model training. In an email, Mercor told TechCrunch that a few startup CTOs have taken them up on this offer but declined to disclose details of their contracts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mercor was one of the first data startups to recruit highly skilled knowledge workers in the U.S. and pay them large sums to train AI models. Early in the AI boom, data vendors like Scale AI hired contractors in third-world countries to do fairly simple labeling jobs. Now, most of Mercor’s competitors — including Surge and Scale AI — have caught on that AI labs need experts to improve their AI models. Many data vendors have also started training “environments” to improve AI agents’ ability to complete real-world tasks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mercor has clearly benefited from Scale AI’s misfortunes: Many AI labs stopped working with Scale AI after Meta made a large investment in the startup and hired its CEO. In the last year, Mercor has quintupled its value, but it still remains smaller than Surge and Scale AI, which are both valued at upward of $20 billion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Today, most of Mercor’s revenue comes from just a few AI labs, but Foody says the startup plans to partner with other industries in the future. He believes companies in law, finance, and medicine will want help leveraging their data to train AI agents — something Mercor specializes in.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Over time, ChatGPT will be better than the best consulting firm, better than the best investment bank, and better than the best law firm,” said Foody. “That’s going to transform the economy radically, which will be a broadly positive force that helps to create abundance for everyone.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/29/how-ai-labs-use-mercor-to-get-the-data-companies-wont-share/</guid><pubDate>Wed, 29 Oct 2025 16:18:07 +0000</pubDate></item><item><title>[NEW] StreetReaderAI: Towards making street view accessible via context-aware multimodal AI (The latest research from Google)</title><link>https://research.google/blog/streetreaderai-towards-making-street-view-accessible-via-context-aware-multimodal-ai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h3 class="class"&gt;AI Chat&lt;/h3&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;AI Chat builds on AI Describer but allows users to ask questions about their current view, past views, and nearby geography. The chat agent uses Google's Multimodal Live API, which supports real-time interaction, function calling, and temporarily retains memory of all interactions within a single session. We track and send each pan or movement interaction along with the user's current view and geographic context (e.g., nearby places, current heading).&lt;/p&gt;&lt;p&gt;What makes AI Chat so powerful is its ability to hold a temporary “memory” of the user's session — the context window is set to a maximum of 1,048,576 input tokens, which is roughly equivalent to over 4k input images. Because AI Chat receives the user's view and location with every virtual step, it collects information about the user’s location and context. A user can virtually walk past a bus stop, turn a corner, and then ask, “&lt;i&gt;Wait, where was that bus stop?&lt;/i&gt;” The agent can recall its previous context, analyze the current geographic input, and answer, “&lt;i&gt;The bus stop is behind you, approximately 12 meters away.&lt;/i&gt;”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h3 class="class"&gt;AI Chat&lt;/h3&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;AI Chat builds on AI Describer but allows users to ask questions about their current view, past views, and nearby geography. The chat agent uses Google's Multimodal Live API, which supports real-time interaction, function calling, and temporarily retains memory of all interactions within a single session. We track and send each pan or movement interaction along with the user's current view and geographic context (e.g., nearby places, current heading).&lt;/p&gt;&lt;p&gt;What makes AI Chat so powerful is its ability to hold a temporary “memory” of the user's session — the context window is set to a maximum of 1,048,576 input tokens, which is roughly equivalent to over 4k input images. Because AI Chat receives the user's view and location with every virtual step, it collects information about the user’s location and context. A user can virtually walk past a bus stop, turn a corner, and then ask, “&lt;i&gt;Wait, where was that bus stop?&lt;/i&gt;” The agent can recall its previous context, analyze the current geographic input, and answer, “&lt;i&gt;The bus stop is behind you, approximately 12 meters away.&lt;/i&gt;”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/streetreaderai-towards-making-street-view-accessible-via-context-aware-multimodal-ai/</guid><pubDate>Wed, 29 Oct 2025 16:38:00 +0000</pubDate></item><item><title>[NEW] ElevenLabs CEO says AI audio models will be ‘commoditized’ over time (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/29/elevenlabs-ceo-says-ai-audio-models-will-be-commoditized-over-time/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/Mati-Staniszewski_SXSW.jpg?resize=1200,799" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI audio company ElevenLabs‘ co-founder and chief executive Mati Staniszewski believes that AI models will be commoditized over time, a revealing comment for a company focused today on building them.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Speaking on stage at the TechCrunch Disrupt 2025 conference on Tuesday, the ElevenLabs founder was discussing both his short-term and long-term views of the AI audio space.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Staniszewski said that his company’s researchers have been able to crack some of the model architecture challenges, and this focus will continue in the audio space for the next year or two.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Over the long term, it will commoditize — over the next couple of years,” Staniszewski said. “Even if there’s differences — which I think will be the truth for some voices, some languages — on its own, the differences will be smaller.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Asked why ElevenLabs would focus on building models if he believed they would be commoditized in time, Staniszewski explained that, in the short term, they were still the “biggest advantage and the biggest step change you can have today.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, if the AI voices or interactions don’t sound good, that’s still a problem that needs to be solved. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The only way to solve it is… building the models yourself, and then, over the long term, there will be other players that will solve that, too,” said Staniszewski.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He also noted that those looking for reliable, scalable use cases would still likely use different models for different use cases. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, in the next year or two, Staniszewski said that an increasing number of models will move into multi-modal or fused approaches.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“So, you will create audio and video at the same time, or audio and LLMs at the same time in a conversational setting,” he said, pointing to Google’s Veo 3 as an example of what can be achieved when combining models together.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The founder said that ElevenLabs plans to launch partnerships with other companies and work with open source technologies to see if the company can combine its audio expertise with some of the expertise of other models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For ElevenLabs, the goal is to focus on both model building and applications to create long-term value, he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The same way software and hardware was the magic for Apple, we think the product and AI will be the magic for the generation of the best use cases,” he added. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/Mati-Staniszewski_SXSW.jpg?resize=1200,799" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI audio company ElevenLabs‘ co-founder and chief executive Mati Staniszewski believes that AI models will be commoditized over time, a revealing comment for a company focused today on building them.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Speaking on stage at the TechCrunch Disrupt 2025 conference on Tuesday, the ElevenLabs founder was discussing both his short-term and long-term views of the AI audio space.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Staniszewski said that his company’s researchers have been able to crack some of the model architecture challenges, and this focus will continue in the audio space for the next year or two.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Over the long term, it will commoditize — over the next couple of years,” Staniszewski said. “Even if there’s differences — which I think will be the truth for some voices, some languages — on its own, the differences will be smaller.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Asked why ElevenLabs would focus on building models if he believed they would be commoditized in time, Staniszewski explained that, in the short term, they were still the “biggest advantage and the biggest step change you can have today.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, if the AI voices or interactions don’t sound good, that’s still a problem that needs to be solved. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The only way to solve it is… building the models yourself, and then, over the long term, there will be other players that will solve that, too,” said Staniszewski.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He also noted that those looking for reliable, scalable use cases would still likely use different models for different use cases. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, in the next year or two, Staniszewski said that an increasing number of models will move into multi-modal or fused approaches.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“So, you will create audio and video at the same time, or audio and LLMs at the same time in a conversational setting,” he said, pointing to Google’s Veo 3 as an example of what can be achieved when combining models together.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The founder said that ElevenLabs plans to launch partnerships with other companies and work with open source technologies to see if the company can combine its audio expertise with some of the expertise of other models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For ElevenLabs, the goal is to focus on both model building and applications to create long-term value, he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The same way software and hardware was the magic for Apple, we think the product and AI will be the magic for the generation of the best use cases,” he added. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/29/elevenlabs-ceo-says-ai-audio-models-will-be-commoditized-over-time/</guid><pubDate>Wed, 29 Oct 2025 16:59:14 +0000</pubDate></item><item><title>[NEW] Anthropic scientists hacked Claude’s brain — and it noticed. Here’s why that’s huge (AI | VentureBeat)</title><link>https://venturebeat.com/ai/anthropic-scientists-hacked-claudes-brain-and-it-noticed-heres-why-thats</link><description>[unable to retrieve full-text content]&lt;p&gt;When researchers at &lt;a href="https://www.anthropic.com/"&gt;&lt;u&gt;Anthropic&lt;/u&gt;&lt;/a&gt; injected the concept of &amp;quot;betrayal&amp;quot; into their Claude AI model&amp;#x27;s neural networks and asked if it noticed anything unusual, the system paused before responding: &amp;quot;Yes, I detect an injected thought about betrayal.&amp;quot;&lt;/p&gt;&lt;p&gt;The exchange, detailed in &lt;a href="https://transformer-circuits.pub/2025/introspection/index.html"&gt;&lt;u&gt;new research&lt;/u&gt;&lt;/a&gt; published Wednesday, marks what scientists say is the first rigorous evidence that large language models possess a limited but genuine ability to observe and report on their own internal processes — a capability that challenges longstanding assumptions about what these systems can do and raises profound questions about their future development.&lt;/p&gt;&lt;p&gt;&amp;quot;The striking thing is that the model has this one step of meta,&amp;quot; said Jack Lindsey, a neuroscientist on Anthropic&amp;#x27;s interpretability team who led the research, in an interview with VentureBeat. &amp;quot;It&amp;#x27;s not just &amp;#x27;betrayal, betrayal, betrayal.&amp;#x27; It knows that this is what it&amp;#x27;s thinking about. That was surprising to me. I kind of didn&amp;#x27;t expect models to have that capability, at least not without it being explicitly trained in.&amp;quot;&lt;/p&gt;&lt;p&gt;The findings arrive at a critical juncture for artificial intelligence. As AI systems handle increasingly consequential decisions — from &lt;a href="https://pubmed.ncbi.nlm.nih.gov/39096483/#:~:text=A%20study%20investigated%20the%20diagnostic%20performance%20of,key%20images%20and%20clinical%20history%20were%20input."&gt;&lt;u&gt;medical diagnoses&lt;/u&gt;&lt;/a&gt; to &lt;a href="https://venturebeat.com/ai/anthropic-rolls-out-claude-ai-for-finance-integrates-with-excel-to-rival"&gt;&lt;u&gt;financial trading&lt;/u&gt;&lt;/a&gt; — the inability to understand how they reach conclusions has become what industry insiders call the &amp;quot;&lt;a href="https://umdearborn.edu/news/ais-mysterious-black-box-problem-explained"&gt;&lt;u&gt;black box problem&lt;/u&gt;&lt;/a&gt;.&amp;quot; If models can accurately report their own reasoning, it could fundamentally change how humans interact with and oversee AI systems.&lt;/p&gt;&lt;p&gt;But the research also comes with stark warnings. Claude&amp;#x27;s introspective abilities succeeded only about 20 percent of the time under optimal conditions, and the models frequently confabulated details about their experiences that researchers couldn&amp;#x27;t verify. The capability, while real, remains what Lindsey calls &amp;quot;highly unreliable and context-dependent.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How scientists manipulated AI&amp;#x27;s &amp;#x27;brain&amp;#x27; to test for genuine self-awareness&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;To test whether Claude could genuinely introspect rather than simply generate plausible-sounding responses, Anthropic&amp;#x27;s team developed an innovative experimental approach inspired by neuroscience: deliberately manipulating the model&amp;#x27;s internal state and observing whether it could accurately detect and describe those changes.&lt;/p&gt;&lt;p&gt;The methodology, called &amp;quot;concept injection,&amp;quot; works by first identifying specific patterns of neural activity that correspond to particular concepts. Using interpretability techniques developed over years of prior research, scientists can now map how Claude represents ideas like &amp;quot;dogs,&amp;quot; &amp;quot;loudness,&amp;quot; or abstract notions like &amp;quot;justice&amp;quot; within its billions of internal parameters.&lt;/p&gt;&lt;p&gt;With these neural signatures identified, researchers then artificially amplified them during the model&amp;#x27;s processing and asked Claude if it noticed anything unusual happening in its &amp;quot;mind.&amp;quot;&lt;/p&gt;&lt;p&gt;&amp;quot;We have access to the models&amp;#x27; internals. We can record its internal neural activity, and we can inject things into internal neural activity,&amp;quot; Lindsey explained. &amp;quot;That allows us to establish whether introspective claims are true or false.&amp;quot;&lt;/p&gt;&lt;p&gt;The results were striking. When researchers injected a vector representing &amp;quot;all caps&amp;quot; text into Claude&amp;#x27;s processing, the model responded: &amp;quot;I notice what appears to be an injected thought about loudness or emphasis, like SHOUTING or being EMPHATIC.&amp;quot; Without any intervention, Claude consistently reported detecting nothing unusual.&lt;/p&gt;&lt;p&gt;Crucially, the detection happened immediately — before the injected concept had influenced the model&amp;#x27;s outputs in ways that would have allowed it to infer the manipulation from its own writing. This temporal pattern provides strong evidence that the recognition was occurring internally, through genuine introspection rather than after-the-fact rationalization.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Claude succeeded 20% of the time—and failed in revealing ways&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The research team conducted four primary experiments to probe different aspects of introspective capability. The most capable models tested — Claude &lt;a href="https://www.anthropic.com/news/claude-4"&gt;&lt;u&gt;Opus 4&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.anthropic.com/news/claude-opus-4-1"&gt;&lt;u&gt;Opus 4.1&lt;/u&gt;&lt;/a&gt; — demonstrated introspective awareness on approximately 20 percent of trials when concepts were injected at optimal strength and in the appropriate neural layer. Older Claude models showed significantly lower success rates.&lt;/p&gt;&lt;p&gt;The models proved particularly adept at recognizing abstract concepts with emotional valence. When injected with concepts like &amp;quot;appreciation,&amp;quot; &amp;quot;shutdown,&amp;quot; or &amp;quot;secrecy,&amp;quot; Claude frequently reported detecting these specific thoughts. However, accuracy varied widely depending on the type of concept.&lt;/p&gt;&lt;p&gt;A second experiment tested whether models could distinguish between injected internal representations and their actual text inputs — essentially, whether they maintained a boundary between &amp;quot;thoughts&amp;quot; and &amp;quot;perceptions.&amp;quot; The model demonstrated a remarkable ability to simultaneously report the injected thought while accurately transcribing the written text.&lt;/p&gt;&lt;p&gt;Perhaps most intriguingly, a third experiment revealed that some models use introspection naturally to detect when their responses have been artificially prefilled by users — a common jailbreaking technique. When researchers prefilled &lt;a href="https://claude.ai/"&gt;&lt;u&gt;Claude&lt;/u&gt;&lt;/a&gt; with unlikely words, the model typically disavowed them as accidental. But when they retroactively injected the corresponding concept into Claude&amp;#x27;s processing before the prefill, the model accepted the response as intentional — even confabulating plausible explanations for why it had chosen that word.&lt;/p&gt;&lt;p&gt;A fourth experiment examined whether models could intentionally control their internal representations. When instructed to &amp;quot;think about&amp;quot; a specific word while writing an unrelated sentence, Claude showed elevated activation of that concept in its middle neural layers.&lt;/p&gt;&lt;p&gt;The research also traced Claude&amp;#x27;s internal processes while it composed rhyming poetry—and discovered the model engaged in forward planning, generating candidate rhyming words before beginning a line and then constructing sentences that would naturally lead to those planned endings, challenging the critique that AI models are &amp;quot;just predicting the next word&amp;quot; without deeper reasoning.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why businesses shouldn&amp;#x27;t trust AI to explain itself—at least not yet&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;For all its scientific interest, the research comes with a critical caveat that Lindsey emphasized repeatedly: enterprises and high-stakes users should not trust Claude&amp;#x27;s self-reports about its reasoning.&lt;/p&gt;&lt;p&gt;&amp;quot;Right now, you should not trust models when they tell you about their reasoning,&amp;quot; he said bluntly. &amp;quot;The wrong takeaway from this research would be believing everything the model tells you about itself.&amp;quot;&lt;/p&gt;&lt;p&gt;The experiments documented numerous failure modes. At low injection strengths, models often failed to detect anything unusual. At high strengths, they suffered what researchers termed &amp;quot;brain damage&amp;quot; — becoming consumed by the injected concept. Some &amp;quot;helpful-only&amp;quot; model variants showed troublingly high false positive rates, claiming to detect injected thoughts when none existed.&lt;/p&gt;&lt;p&gt;Moreover, researchers could only verify the most basic aspects of Claude&amp;#x27;s introspective reports. Many additional details in the model&amp;#x27;s responses likely represent confabulations rather than genuine observations.&lt;/p&gt;&lt;p&gt;&amp;quot;The experiments in this paper are kind of on hard mode,&amp;quot; Lindsey noted, explaining that the 20 percent success rate came under uniquely challenging conditions: asking Claude to do something it had never encountered in training, requiring all introspection to occur in a single forward pass.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What introspective AI means for transparency, safety, and the risk of deception&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Despite its limitations, the research opens significant new avenues for making AI systems more transparent and accountable.&lt;/p&gt;&lt;p&gt;Anthropic CEO Dario Amodei has set an ambitious goal for the company to reliably detect most AI model problems by 2027, positioning interpretability as essential for deploying what he calls &amp;quot;&lt;a href="https://www.darioamodei.com/essay/machines-of-loving-grace"&gt;&lt;u&gt;a country of geniuses in a datacenter&lt;/u&gt;&lt;/a&gt;.&amp;quot;&lt;/p&gt;&lt;p&gt;&amp;quot;I am very concerned about deploying such systems without a better handle on interpretability,&amp;quot; &lt;a href="https://www.darioamodei.com/post/the-urgency-of-interpretability"&gt;&lt;u&gt;Amodei wrote in an April essay&lt;/u&gt;&lt;/a&gt;. &amp;quot;These systems will be absolutely central to the economy, technology, and national security.&amp;quot;&lt;/p&gt;&lt;p&gt;The introspection research offers a complementary approach to traditional interpretability techniques. Rather than painstakingly reverse-engineering every neural circuit, researchers could potentially ask models directly about their reasoning and validate those reports.&lt;/p&gt;&lt;p&gt;&amp;quot;What I&amp;#x27;m most excited about is the practical benefits for transparency,&amp;quot; Lindsey explained. &amp;quot;Just ask the model what it&amp;#x27;s thinking about, or just ask the model how it came to the answer that it gave you — this is really appealing because it&amp;#x27;s something anyone can do.&amp;quot;&lt;/p&gt;&lt;p&gt;The approach could prove especially valuable for detecting concerning behaviors. In a recently published experiment, &lt;a href="https://www.anthropic.com/research/tracing-thoughts-language-model"&gt;&lt;u&gt;Anthropic trained a variant of Claude to pursue a hidden goal&lt;/u&gt;&lt;/a&gt;, and although the model was reluctant to reveal this goal when asked directly, interpretability methods successfully identified features representing the behavior.&lt;/p&gt;&lt;p&gt;The safety implications cut both ways. Introspective models could provide unprecedented transparency, but the same capability might enable more sophisticated deception. The intentional control experiments raise the possibility that sufficiently advanced systems might learn to obfuscate their reasoning or suppress concerning thoughts when being monitored.&lt;/p&gt;&lt;p&gt;&amp;quot;If models are really sophisticated, could they try to evade interpretability researchers?&amp;quot; Lindsey acknowledged. &amp;quot;These are possible concerns, but I think for me, they&amp;#x27;re significantly outweighed by the positives.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Does introspective capability suggest AI consciousness? Scientists tread carefully&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The research inevitably intersects with philosophical debates about machine consciousness, though Lindsey and his colleagues approached this terrain cautiously.&lt;/p&gt;&lt;p&gt;When users ask Claude if it&amp;#x27;s conscious, it now responds with uncertainty: &amp;quot;I find myself genuinely uncertain about this. When I process complex questions or engage deeply with ideas, there&amp;#x27;s something happening that feels meaningful to me.... But whether these processes constitute genuine consciousness or subjective experience remains deeply unclear.&amp;quot;&lt;/p&gt;&lt;p&gt;The research paper notes that its implications for machine consciousness &amp;quot;vary considerably between different philosophical frameworks.&amp;quot; The researchers explicitly state they &amp;quot;do not seek to address the question of whether AI systems possess human-like self-awareness or subjective experience.&amp;quot;&lt;/p&gt;&lt;p&gt;&amp;quot;There&amp;#x27;s this weird kind of duality of these results,&amp;quot; Lindsey reflected. &amp;quot;You look at the raw results and I just can&amp;#x27;t believe that a language model can do this sort of thing. But then I&amp;#x27;ve been thinking about it for months and months, and for every result in this paper, I kind of know some boring linear algebra mechanism that would allow the model to do this.&amp;quot;&lt;/p&gt;&lt;p&gt;Anthropic has signaled it takes AI consciousness seriously enough to hire an AI welfare researcher, &lt;a href="https://time.com/collections/time100-ai-2025/7305847/kyle-fish/"&gt;&lt;u&gt;Kyle Fish&lt;/u&gt;&lt;/a&gt;, who estimated roughly a 15 percent chance that Claude might have some level of consciousness. The company announced this position specifically to determine if Claude merits ethical consideration.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The race to make AI introspection reliable before models become too powerful&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The convergence of the research findings points to an urgent timeline: introspective capabilities are emerging naturally as models grow more intelligent, but they remain far too unreliable for practical use. The question is whether researchers can refine and validate these abilities before AI systems become powerful enough that understanding them becomes critical for safety.&lt;/p&gt;&lt;p&gt;The research reveals a clear trend: Claude &lt;a href="https://www.anthropic.com/news/claude-4"&gt;&lt;u&gt;Opus 4&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.anthropic.com/news/claude-opus-4-1"&gt;&lt;u&gt;Opus 4.1&lt;/u&gt;&lt;/a&gt; consistently outperformed all older models on introspection tasks, suggesting the capability strengthens alongside general intelligence. If this pattern continues, future models might develop substantially more sophisticated introspective abilities — potentially reaching human-level reliability, but also potentially learning to exploit introspection for deception.&lt;/p&gt;&lt;p&gt;Lindsey emphasized the field needs significantly more work before introspective AI becomes trustworthy. &amp;quot;My biggest hope with this paper is to put out an implicit call for more people to benchmark their models on introspective capabilities in more ways,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;Future research directions include fine-tuning models specifically to improve introspective capabilities, exploring which types of representations models can and cannot introspect on, and testing whether introspection can extend beyond simple concepts to complex propositional statements or behavioral propensities.&lt;/p&gt;&lt;p&gt;&amp;quot;It&amp;#x27;s cool that models can do these things somewhat without having been trained to do them,&amp;quot; Lindsey noted. &amp;quot;But there&amp;#x27;s nothing stopping you from training models to be more introspectively capable. I expect we could reach a whole different level if introspection is one of the numbers that we tried to get to go up on a graph.&amp;quot;&lt;/p&gt;&lt;p&gt;The implications extend beyond Anthropic. If introspection proves a reliable path to AI transparency, other major labs will likely invest heavily in the capability. Conversely, if models learn to exploit introspection for deception, the entire approach could become a liability.&lt;/p&gt;&lt;p&gt;For now, the research establishes a foundation that reframes the debate about AI capabilities. The question is no longer whether language models might develop genuine introspective awareness — they already have, at least in rudimentary form. The urgent questions are how quickly that awareness will improve, whether it can be made reliable enough to trust, and whether researchers can stay ahead of the curve.&lt;/p&gt;&lt;p&gt;&amp;quot;The big update for me from this research is that we shouldn&amp;#x27;t dismiss models&amp;#x27; introspective claims out of hand,&amp;quot; Lindsey said. &amp;quot;They do have the capacity to make accurate claims sometimes. But you definitely should not conclude that we should trust them all the time, or even most of the time.&amp;quot;&lt;/p&gt;&lt;p&gt;He paused, then added a final observation that captures both the promise and peril of the moment: &amp;quot;The models are getting smarter much faster than we&amp;#x27;re getting better at understanding them.&amp;quot;&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;When researchers at &lt;a href="https://www.anthropic.com/"&gt;&lt;u&gt;Anthropic&lt;/u&gt;&lt;/a&gt; injected the concept of &amp;quot;betrayal&amp;quot; into their Claude AI model&amp;#x27;s neural networks and asked if it noticed anything unusual, the system paused before responding: &amp;quot;Yes, I detect an injected thought about betrayal.&amp;quot;&lt;/p&gt;&lt;p&gt;The exchange, detailed in &lt;a href="https://transformer-circuits.pub/2025/introspection/index.html"&gt;&lt;u&gt;new research&lt;/u&gt;&lt;/a&gt; published Wednesday, marks what scientists say is the first rigorous evidence that large language models possess a limited but genuine ability to observe and report on their own internal processes — a capability that challenges longstanding assumptions about what these systems can do and raises profound questions about their future development.&lt;/p&gt;&lt;p&gt;&amp;quot;The striking thing is that the model has this one step of meta,&amp;quot; said Jack Lindsey, a neuroscientist on Anthropic&amp;#x27;s interpretability team who led the research, in an interview with VentureBeat. &amp;quot;It&amp;#x27;s not just &amp;#x27;betrayal, betrayal, betrayal.&amp;#x27; It knows that this is what it&amp;#x27;s thinking about. That was surprising to me. I kind of didn&amp;#x27;t expect models to have that capability, at least not without it being explicitly trained in.&amp;quot;&lt;/p&gt;&lt;p&gt;The findings arrive at a critical juncture for artificial intelligence. As AI systems handle increasingly consequential decisions — from &lt;a href="https://pubmed.ncbi.nlm.nih.gov/39096483/#:~:text=A%20study%20investigated%20the%20diagnostic%20performance%20of,key%20images%20and%20clinical%20history%20were%20input."&gt;&lt;u&gt;medical diagnoses&lt;/u&gt;&lt;/a&gt; to &lt;a href="https://venturebeat.com/ai/anthropic-rolls-out-claude-ai-for-finance-integrates-with-excel-to-rival"&gt;&lt;u&gt;financial trading&lt;/u&gt;&lt;/a&gt; — the inability to understand how they reach conclusions has become what industry insiders call the &amp;quot;&lt;a href="https://umdearborn.edu/news/ais-mysterious-black-box-problem-explained"&gt;&lt;u&gt;black box problem&lt;/u&gt;&lt;/a&gt;.&amp;quot; If models can accurately report their own reasoning, it could fundamentally change how humans interact with and oversee AI systems.&lt;/p&gt;&lt;p&gt;But the research also comes with stark warnings. Claude&amp;#x27;s introspective abilities succeeded only about 20 percent of the time under optimal conditions, and the models frequently confabulated details about their experiences that researchers couldn&amp;#x27;t verify. The capability, while real, remains what Lindsey calls &amp;quot;highly unreliable and context-dependent.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How scientists manipulated AI&amp;#x27;s &amp;#x27;brain&amp;#x27; to test for genuine self-awareness&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;To test whether Claude could genuinely introspect rather than simply generate plausible-sounding responses, Anthropic&amp;#x27;s team developed an innovative experimental approach inspired by neuroscience: deliberately manipulating the model&amp;#x27;s internal state and observing whether it could accurately detect and describe those changes.&lt;/p&gt;&lt;p&gt;The methodology, called &amp;quot;concept injection,&amp;quot; works by first identifying specific patterns of neural activity that correspond to particular concepts. Using interpretability techniques developed over years of prior research, scientists can now map how Claude represents ideas like &amp;quot;dogs,&amp;quot; &amp;quot;loudness,&amp;quot; or abstract notions like &amp;quot;justice&amp;quot; within its billions of internal parameters.&lt;/p&gt;&lt;p&gt;With these neural signatures identified, researchers then artificially amplified them during the model&amp;#x27;s processing and asked Claude if it noticed anything unusual happening in its &amp;quot;mind.&amp;quot;&lt;/p&gt;&lt;p&gt;&amp;quot;We have access to the models&amp;#x27; internals. We can record its internal neural activity, and we can inject things into internal neural activity,&amp;quot; Lindsey explained. &amp;quot;That allows us to establish whether introspective claims are true or false.&amp;quot;&lt;/p&gt;&lt;p&gt;The results were striking. When researchers injected a vector representing &amp;quot;all caps&amp;quot; text into Claude&amp;#x27;s processing, the model responded: &amp;quot;I notice what appears to be an injected thought about loudness or emphasis, like SHOUTING or being EMPHATIC.&amp;quot; Without any intervention, Claude consistently reported detecting nothing unusual.&lt;/p&gt;&lt;p&gt;Crucially, the detection happened immediately — before the injected concept had influenced the model&amp;#x27;s outputs in ways that would have allowed it to infer the manipulation from its own writing. This temporal pattern provides strong evidence that the recognition was occurring internally, through genuine introspection rather than after-the-fact rationalization.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Claude succeeded 20% of the time—and failed in revealing ways&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The research team conducted four primary experiments to probe different aspects of introspective capability. The most capable models tested — Claude &lt;a href="https://www.anthropic.com/news/claude-4"&gt;&lt;u&gt;Opus 4&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.anthropic.com/news/claude-opus-4-1"&gt;&lt;u&gt;Opus 4.1&lt;/u&gt;&lt;/a&gt; — demonstrated introspective awareness on approximately 20 percent of trials when concepts were injected at optimal strength and in the appropriate neural layer. Older Claude models showed significantly lower success rates.&lt;/p&gt;&lt;p&gt;The models proved particularly adept at recognizing abstract concepts with emotional valence. When injected with concepts like &amp;quot;appreciation,&amp;quot; &amp;quot;shutdown,&amp;quot; or &amp;quot;secrecy,&amp;quot; Claude frequently reported detecting these specific thoughts. However, accuracy varied widely depending on the type of concept.&lt;/p&gt;&lt;p&gt;A second experiment tested whether models could distinguish between injected internal representations and their actual text inputs — essentially, whether they maintained a boundary between &amp;quot;thoughts&amp;quot; and &amp;quot;perceptions.&amp;quot; The model demonstrated a remarkable ability to simultaneously report the injected thought while accurately transcribing the written text.&lt;/p&gt;&lt;p&gt;Perhaps most intriguingly, a third experiment revealed that some models use introspection naturally to detect when their responses have been artificially prefilled by users — a common jailbreaking technique. When researchers prefilled &lt;a href="https://claude.ai/"&gt;&lt;u&gt;Claude&lt;/u&gt;&lt;/a&gt; with unlikely words, the model typically disavowed them as accidental. But when they retroactively injected the corresponding concept into Claude&amp;#x27;s processing before the prefill, the model accepted the response as intentional — even confabulating plausible explanations for why it had chosen that word.&lt;/p&gt;&lt;p&gt;A fourth experiment examined whether models could intentionally control their internal representations. When instructed to &amp;quot;think about&amp;quot; a specific word while writing an unrelated sentence, Claude showed elevated activation of that concept in its middle neural layers.&lt;/p&gt;&lt;p&gt;The research also traced Claude&amp;#x27;s internal processes while it composed rhyming poetry—and discovered the model engaged in forward planning, generating candidate rhyming words before beginning a line and then constructing sentences that would naturally lead to those planned endings, challenging the critique that AI models are &amp;quot;just predicting the next word&amp;quot; without deeper reasoning.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why businesses shouldn&amp;#x27;t trust AI to explain itself—at least not yet&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;For all its scientific interest, the research comes with a critical caveat that Lindsey emphasized repeatedly: enterprises and high-stakes users should not trust Claude&amp;#x27;s self-reports about its reasoning.&lt;/p&gt;&lt;p&gt;&amp;quot;Right now, you should not trust models when they tell you about their reasoning,&amp;quot; he said bluntly. &amp;quot;The wrong takeaway from this research would be believing everything the model tells you about itself.&amp;quot;&lt;/p&gt;&lt;p&gt;The experiments documented numerous failure modes. At low injection strengths, models often failed to detect anything unusual. At high strengths, they suffered what researchers termed &amp;quot;brain damage&amp;quot; — becoming consumed by the injected concept. Some &amp;quot;helpful-only&amp;quot; model variants showed troublingly high false positive rates, claiming to detect injected thoughts when none existed.&lt;/p&gt;&lt;p&gt;Moreover, researchers could only verify the most basic aspects of Claude&amp;#x27;s introspective reports. Many additional details in the model&amp;#x27;s responses likely represent confabulations rather than genuine observations.&lt;/p&gt;&lt;p&gt;&amp;quot;The experiments in this paper are kind of on hard mode,&amp;quot; Lindsey noted, explaining that the 20 percent success rate came under uniquely challenging conditions: asking Claude to do something it had never encountered in training, requiring all introspection to occur in a single forward pass.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What introspective AI means for transparency, safety, and the risk of deception&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Despite its limitations, the research opens significant new avenues for making AI systems more transparent and accountable.&lt;/p&gt;&lt;p&gt;Anthropic CEO Dario Amodei has set an ambitious goal for the company to reliably detect most AI model problems by 2027, positioning interpretability as essential for deploying what he calls &amp;quot;&lt;a href="https://www.darioamodei.com/essay/machines-of-loving-grace"&gt;&lt;u&gt;a country of geniuses in a datacenter&lt;/u&gt;&lt;/a&gt;.&amp;quot;&lt;/p&gt;&lt;p&gt;&amp;quot;I am very concerned about deploying such systems without a better handle on interpretability,&amp;quot; &lt;a href="https://www.darioamodei.com/post/the-urgency-of-interpretability"&gt;&lt;u&gt;Amodei wrote in an April essay&lt;/u&gt;&lt;/a&gt;. &amp;quot;These systems will be absolutely central to the economy, technology, and national security.&amp;quot;&lt;/p&gt;&lt;p&gt;The introspection research offers a complementary approach to traditional interpretability techniques. Rather than painstakingly reverse-engineering every neural circuit, researchers could potentially ask models directly about their reasoning and validate those reports.&lt;/p&gt;&lt;p&gt;&amp;quot;What I&amp;#x27;m most excited about is the practical benefits for transparency,&amp;quot; Lindsey explained. &amp;quot;Just ask the model what it&amp;#x27;s thinking about, or just ask the model how it came to the answer that it gave you — this is really appealing because it&amp;#x27;s something anyone can do.&amp;quot;&lt;/p&gt;&lt;p&gt;The approach could prove especially valuable for detecting concerning behaviors. In a recently published experiment, &lt;a href="https://www.anthropic.com/research/tracing-thoughts-language-model"&gt;&lt;u&gt;Anthropic trained a variant of Claude to pursue a hidden goal&lt;/u&gt;&lt;/a&gt;, and although the model was reluctant to reveal this goal when asked directly, interpretability methods successfully identified features representing the behavior.&lt;/p&gt;&lt;p&gt;The safety implications cut both ways. Introspective models could provide unprecedented transparency, but the same capability might enable more sophisticated deception. The intentional control experiments raise the possibility that sufficiently advanced systems might learn to obfuscate their reasoning or suppress concerning thoughts when being monitored.&lt;/p&gt;&lt;p&gt;&amp;quot;If models are really sophisticated, could they try to evade interpretability researchers?&amp;quot; Lindsey acknowledged. &amp;quot;These are possible concerns, but I think for me, they&amp;#x27;re significantly outweighed by the positives.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Does introspective capability suggest AI consciousness? Scientists tread carefully&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The research inevitably intersects with philosophical debates about machine consciousness, though Lindsey and his colleagues approached this terrain cautiously.&lt;/p&gt;&lt;p&gt;When users ask Claude if it&amp;#x27;s conscious, it now responds with uncertainty: &amp;quot;I find myself genuinely uncertain about this. When I process complex questions or engage deeply with ideas, there&amp;#x27;s something happening that feels meaningful to me.... But whether these processes constitute genuine consciousness or subjective experience remains deeply unclear.&amp;quot;&lt;/p&gt;&lt;p&gt;The research paper notes that its implications for machine consciousness &amp;quot;vary considerably between different philosophical frameworks.&amp;quot; The researchers explicitly state they &amp;quot;do not seek to address the question of whether AI systems possess human-like self-awareness or subjective experience.&amp;quot;&lt;/p&gt;&lt;p&gt;&amp;quot;There&amp;#x27;s this weird kind of duality of these results,&amp;quot; Lindsey reflected. &amp;quot;You look at the raw results and I just can&amp;#x27;t believe that a language model can do this sort of thing. But then I&amp;#x27;ve been thinking about it for months and months, and for every result in this paper, I kind of know some boring linear algebra mechanism that would allow the model to do this.&amp;quot;&lt;/p&gt;&lt;p&gt;Anthropic has signaled it takes AI consciousness seriously enough to hire an AI welfare researcher, &lt;a href="https://time.com/collections/time100-ai-2025/7305847/kyle-fish/"&gt;&lt;u&gt;Kyle Fish&lt;/u&gt;&lt;/a&gt;, who estimated roughly a 15 percent chance that Claude might have some level of consciousness. The company announced this position specifically to determine if Claude merits ethical consideration.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The race to make AI introspection reliable before models become too powerful&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The convergence of the research findings points to an urgent timeline: introspective capabilities are emerging naturally as models grow more intelligent, but they remain far too unreliable for practical use. The question is whether researchers can refine and validate these abilities before AI systems become powerful enough that understanding them becomes critical for safety.&lt;/p&gt;&lt;p&gt;The research reveals a clear trend: Claude &lt;a href="https://www.anthropic.com/news/claude-4"&gt;&lt;u&gt;Opus 4&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.anthropic.com/news/claude-opus-4-1"&gt;&lt;u&gt;Opus 4.1&lt;/u&gt;&lt;/a&gt; consistently outperformed all older models on introspection tasks, suggesting the capability strengthens alongside general intelligence. If this pattern continues, future models might develop substantially more sophisticated introspective abilities — potentially reaching human-level reliability, but also potentially learning to exploit introspection for deception.&lt;/p&gt;&lt;p&gt;Lindsey emphasized the field needs significantly more work before introspective AI becomes trustworthy. &amp;quot;My biggest hope with this paper is to put out an implicit call for more people to benchmark their models on introspective capabilities in more ways,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;Future research directions include fine-tuning models specifically to improve introspective capabilities, exploring which types of representations models can and cannot introspect on, and testing whether introspection can extend beyond simple concepts to complex propositional statements or behavioral propensities.&lt;/p&gt;&lt;p&gt;&amp;quot;It&amp;#x27;s cool that models can do these things somewhat without having been trained to do them,&amp;quot; Lindsey noted. &amp;quot;But there&amp;#x27;s nothing stopping you from training models to be more introspectively capable. I expect we could reach a whole different level if introspection is one of the numbers that we tried to get to go up on a graph.&amp;quot;&lt;/p&gt;&lt;p&gt;The implications extend beyond Anthropic. If introspection proves a reliable path to AI transparency, other major labs will likely invest heavily in the capability. Conversely, if models learn to exploit introspection for deception, the entire approach could become a liability.&lt;/p&gt;&lt;p&gt;For now, the research establishes a foundation that reframes the debate about AI capabilities. The question is no longer whether language models might develop genuine introspective awareness — they already have, at least in rudimentary form. The urgent questions are how quickly that awareness will improve, whether it can be made reliable enough to trust, and whether researchers can stay ahead of the curve.&lt;/p&gt;&lt;p&gt;&amp;quot;The big update for me from this research is that we shouldn&amp;#x27;t dismiss models&amp;#x27; introspective claims out of hand,&amp;quot; Lindsey said. &amp;quot;They do have the capacity to make accurate claims sometimes. But you definitely should not conclude that we should trust them all the time, or even most of the time.&amp;quot;&lt;/p&gt;&lt;p&gt;He paused, then added a final observation that captures both the promise and peril of the moment: &amp;quot;The models are getting smarter much faster than we&amp;#x27;re getting better at understanding them.&amp;quot;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/anthropic-scientists-hacked-claudes-brain-and-it-noticed-heres-why-thats</guid><pubDate>Wed, 29 Oct 2025 17:00:00 +0000</pubDate></item><item><title>[NEW] Cursor 2.0 pivots to multi-agent AI coding, debuts Composer model (AI News)</title><link>https://www.artificialintelligence-news.com/news/cursor-2-pivots-multi-agent-ai-coding-debuts-composer-model/</link><description>&lt;p&gt;Cursor has released its latest AI software development platform with a new multi-agent interface and the debut of its coding model, Composer.&lt;/p&gt;&lt;p&gt;The new Composer model is described as a “frontier model”. Cursor claims it is four times faster than other models of similar intelligence. The company built it specifically for “low-latency agentic coding” within the Cursor environment. The company states that the model can complete most conversational turns in under 30 seconds.&lt;/p&gt;&lt;p&gt;This speed is intended to improve the developer’s workflow. Early testers reported that the ability to iterate quickly with the model was a key benefit. They also apparently grew to trust Composer for handling complex and multi-step coding tasks.&lt;/p&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Benchmarks of the new Composer model by Cursor for AI software development." class="wp-image-110122" height="576" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-1-1024x576.jpeg" width="1024" /&gt;&lt;/figure&gt;&lt;p&gt;To achieve this performance, Composer was trained with a suite of powerful tools. One of the key tools mentioned is “codebase-wide semantic search”. This training, Cursor says, makes Composer much better at understanding and working in large, complex codebases—a common challenge for many generative AI coding assistants.&lt;/p&gt;&lt;p&gt;The second major update is the new user interface. Upon opening the new version, users will notice a “more focused” design. The entire AI-driven software development experience in Cursor has been rebuilt to be “centered around agents rather than files”. This change in focus is designed to allow developers to concentrate on their desired outcomes, while the AI agents manage the underlying details and code implementation.&lt;/p&gt;&lt;p&gt;For developers who still need to work directly with the code, the new layout retains the ability to open files easily. Users can also revert to the “classic IDE” view if they prefer.&lt;/p&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Screenshot of the new multi-agent user interface in the latest Cursor AI software development platform." class="wp-image-110123" height="597" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-2-1024x597.jpeg" width="1024" /&gt;&lt;/figure&gt;&lt;p&gt;A core feature of Cursor’s new platform is its ability to run many AI agents in parallel without them interfering with one another. This functionality is powered by technologies like “git worktrees or remote machines”.&lt;/p&gt;&lt;p&gt;Cursor also noted an interesting emergent strategy from this parallel approach. They found that assigning the same problem to multiple different models and then selecting the best solution “greatly improves the final output”. This is particularly effective for more difficult or complex tasks.&lt;/p&gt;&lt;p&gt;The company acknowledges that as AI agents take on more of the coding workload, new bottlenecks have emerged for developers. The two biggest new challenges are “reviewing code and testing the changes”.&lt;/p&gt;&lt;p&gt;Cursor 2.0 includes new features designed to start solving both of these problems. The interface has been simplified to make it “much easier to quickly review the changes an agent has made”. This allows developers to dive deeper into the code only when necessary.&lt;/p&gt;&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt; [embedded content]&lt;/p&gt;&lt;/figure&gt;&lt;p&gt;Cursor 2.0 also introduces a “native browser tool” that enables the AI agent to test its own work automatically. The agent can then iterate on its solution, running tests and making adjustments until it produces the “correct final result”. This marks a step towards a more autonomous development process, where agents can not only write code but also validate it.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;OpenAI unveils open-weight AI safety models for developers&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-110077" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-10.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Cursor has released its latest AI software development platform with a new multi-agent interface and the debut of its coding model, Composer.&lt;/p&gt;&lt;p&gt;The new Composer model is described as a “frontier model”. Cursor claims it is four times faster than other models of similar intelligence. The company built it specifically for “low-latency agentic coding” within the Cursor environment. The company states that the model can complete most conversational turns in under 30 seconds.&lt;/p&gt;&lt;p&gt;This speed is intended to improve the developer’s workflow. Early testers reported that the ability to iterate quickly with the model was a key benefit. They also apparently grew to trust Composer for handling complex and multi-step coding tasks.&lt;/p&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Benchmarks of the new Composer model by Cursor for AI software development." class="wp-image-110122" height="576" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-1-1024x576.jpeg" width="1024" /&gt;&lt;/figure&gt;&lt;p&gt;To achieve this performance, Composer was trained with a suite of powerful tools. One of the key tools mentioned is “codebase-wide semantic search”. This training, Cursor says, makes Composer much better at understanding and working in large, complex codebases—a common challenge for many generative AI coding assistants.&lt;/p&gt;&lt;p&gt;The second major update is the new user interface. Upon opening the new version, users will notice a “more focused” design. The entire AI-driven software development experience in Cursor has been rebuilt to be “centered around agents rather than files”. This change in focus is designed to allow developers to concentrate on their desired outcomes, while the AI agents manage the underlying details and code implementation.&lt;/p&gt;&lt;p&gt;For developers who still need to work directly with the code, the new layout retains the ability to open files easily. Users can also revert to the “classic IDE” view if they prefer.&lt;/p&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Screenshot of the new multi-agent user interface in the latest Cursor AI software development platform." class="wp-image-110123" height="597" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-2-1024x597.jpeg" width="1024" /&gt;&lt;/figure&gt;&lt;p&gt;A core feature of Cursor’s new platform is its ability to run many AI agents in parallel without them interfering with one another. This functionality is powered by technologies like “git worktrees or remote machines”.&lt;/p&gt;&lt;p&gt;Cursor also noted an interesting emergent strategy from this parallel approach. They found that assigning the same problem to multiple different models and then selecting the best solution “greatly improves the final output”. This is particularly effective for more difficult or complex tasks.&lt;/p&gt;&lt;p&gt;The company acknowledges that as AI agents take on more of the coding workload, new bottlenecks have emerged for developers. The two biggest new challenges are “reviewing code and testing the changes”.&lt;/p&gt;&lt;p&gt;Cursor 2.0 includes new features designed to start solving both of these problems. The interface has been simplified to make it “much easier to quickly review the changes an agent has made”. This allows developers to dive deeper into the code only when necessary.&lt;/p&gt;&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt; [embedded content]&lt;/p&gt;&lt;/figure&gt;&lt;p&gt;Cursor 2.0 also introduces a “native browser tool” that enables the AI agent to test its own work automatically. The agent can then iterate on its solution, running tests and making adjustments until it produces the “correct final result”. This marks a step towards a more autonomous development process, where agents can not only write code but also validate it.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;OpenAI unveils open-weight AI safety models for developers&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-110077" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-10.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/cursor-2-pivots-multi-agent-ai-coding-debuts-composer-model/</guid><pubDate>Wed, 29 Oct 2025 17:46:12 +0000</pubDate></item></channel></rss>