<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 19 Feb 2026 18:54:13 +0000</lastBuildDate><item><title>From integration chaos to digital clarity: Nutrien Ag Solutions’ post-acquisition reset (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/19/1133320/from-integration-chaos-to-digital-clarity-nutrien-ag-solutions-post-acquisition-reset/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt;&lt;p&gt;Thank you for joining us on the "Enterprise AI hub."&lt;/p&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1113531" src="https://wp.technologyreview.com/wp-content/uploads/2025/03/2025-Infosys-logo-lockup.png?w=1800" /&gt;&lt;/figure&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1133321" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/MIT-Nutrien-Ag-Sriram-Kalyan-I-Dylan-Cosper.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;In this episode of the Infosys Knowledge Institute Podcast, Dylan Cosper speaks with Sriram Kalyan, head of applications and data at Nutrien Ag Solutions, Australia, about turning a high-risk post-acquisition IT landscape into a scalable digital foundation. Sriram shares how the merger of two major Australian agricultural companies created duplicated systems, fragile integrations, and operational risk, compounded by the sudden loss of key platform experts and partners. He explains how leadership alignment, disciplined platform consolidation, and a clear focus on business outcomes transformed integration from an invisible liability into a strategic enabler, positioning Nutrien Ag Solutions for future growth, cloud transformation, and enterprise scale.&lt;/p&gt;  &lt;p&gt;Click here to continue.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt;&lt;p&gt;Thank you for joining us on the "Enterprise AI hub."&lt;/p&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1113531" src="https://wp.technologyreview.com/wp-content/uploads/2025/03/2025-Infosys-logo-lockup.png?w=1800" /&gt;&lt;/figure&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1133321" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/MIT-Nutrien-Ag-Sriram-Kalyan-I-Dylan-Cosper.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;In this episode of the Infosys Knowledge Institute Podcast, Dylan Cosper speaks with Sriram Kalyan, head of applications and data at Nutrien Ag Solutions, Australia, about turning a high-risk post-acquisition IT landscape into a scalable digital foundation. Sriram shares how the merger of two major Australian agricultural companies created duplicated systems, fragile integrations, and operational risk, compounded by the sudden loss of key platform experts and partners. He explains how leadership alignment, disciplined platform consolidation, and a clear focus on business outcomes transformed integration from an invisible liability into a strategic enabler, positioning Nutrien Ag Solutions for future growth, cloud transformation, and enterprise scale.&lt;/p&gt;  &lt;p&gt;Click here to continue.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/19/1133320/from-integration-chaos-to-digital-clarity-nutrien-ag-solutions-post-acquisition-reset/</guid><pubDate>Thu, 19 Feb 2026 08:48:53 +0000</pubDate></item><item><title>What it takes to make agentic AI work in retail (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/19/1133324/what-it-takes-to-make-agentic-ai-work-in-retail/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt;&lt;p&gt;Thank you for joining us on the "Enterprise AI hub."&lt;/p&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1113531" src="https://wp.technologyreview.com/wp-content/uploads/2025/03/2025-Infosys-logo-lockup.png?w=1800" /&gt;&lt;/figure&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1133326" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/MIT-Dollar-General-Prasad-Banala-I-Dylan-Cosper-1.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;In this episode of the Infosys Knowledge Institute Podcast, Dylan Cosper speaks with Prasad Banala, director of software engineering at a large US-based retail organization, about operationalizing agentic AI across the software development lifecycle. Prasad explains how his team applies AI to validate requirements, generate and analyze test cases, and accelerate issue resolution, while maintaining strict governance, human-in-the-loop review, and measurable quality outcomes.&lt;/p&gt;  &lt;p&gt;Click here to continue.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt;&lt;p&gt;Thank you for joining us on the "Enterprise AI hub."&lt;/p&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1113531" src="https://wp.technologyreview.com/wp-content/uploads/2025/03/2025-Infosys-logo-lockup.png?w=1800" /&gt;&lt;/figure&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1133326" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/MIT-Dollar-General-Prasad-Banala-I-Dylan-Cosper-1.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;In this episode of the Infosys Knowledge Institute Podcast, Dylan Cosper speaks with Prasad Banala, director of software engineering at a large US-based retail organization, about operationalizing agentic AI across the software development lifecycle. Prasad explains how his team applies AI to validate requirements, generate and analyze test cases, and accelerate issue resolution, while maintaining strict governance, human-in-the-loop review, and measurable quality outcomes.&lt;/p&gt;  &lt;p&gt;Click here to continue.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/19/1133324/what-it-takes-to-make-agentic-ai-work-in-retail/</guid><pubDate>Thu, 19 Feb 2026 08:54:41 +0000</pubDate></item><item><title>DBS pilots system that lets AI agents make payments for customers (AI News)</title><link>https://www.artificialintelligence-news.com/news/dbs-pilots-system-that-lets-ai-agents-make-payments-for-customers/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/DBS-pilots-system-that-lets-AI-agents-make-payments-for-customers-scaled-e1771483760926.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Artificial intelligence is moving closer to the point where it can act, not advise. A new pilot by DBS Bank shows how that change may soon affect everyday payments, as financial institutions begin testing systems that allow AI agents to complete purchases on behalf of customers.&lt;/p&gt;&lt;p&gt;DBS is working with Visa to trial Visa Intelligent Commerce, a framework designed to support transactions initiated by AI software not humans. The system allows digital agents to search for products, select options, and complete purchases using payment credentials issued and controlled by the bank. According to reports from &lt;em&gt;Asian Banking &amp;amp; Finance&lt;/em&gt; and &lt;em&gt;Fintech Futures&lt;/em&gt;, the pilot has already processed real transactions, including food and beverage purchases made using DBS or POSB cards.&lt;/p&gt;&lt;h3&gt;Moving from recommendations to real transactions&lt;/h3&gt;&lt;p&gt;The trial highlights how banks are preparing for what some in the industry call “agent-driven commerce.” In this model, AI tools act subject to rules set by both the customer and the issuing bank.&lt;/p&gt;&lt;p&gt;Visa’s approach keeps the bank at the centre of the process. Payment details are tokenised, and transactions pass through issuer-controlled approval flows designed to confirm identity and spending limits. The means the bank still decides whether the agent’s action fits the user’s permissions before money moves.&lt;/p&gt;&lt;p&gt;The DBS pilot is part of a wider effort to test where AI fits into financial infrastructure. Rather than treating AI as a customer-facing tool, banks are increasingly examining how it might change the mechanics of payments, fraud checks, and authorisation. Industry observers note that this is a change from AI as a productivity assistant to AI as an operational participant in transactions.&lt;/p&gt;&lt;h3&gt;Early use cases focus on routine purchases&lt;/h3&gt;&lt;p&gt;Early use cases for agent-based commerce include routine purchases like ordering groceries, renewing subscriptions, booking travel, or restocking household items. In these cases, the agent follows instructions set in advance by the user, like budget limits or preferred brands. DBS and Visa plan to expand the pilot into broader online shopping and travel bookings as testing continues, according to &lt;em&gt;Fintech Futures&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;The idea of AI executing purchases raises opportunity and risk for financial institutions. On one hand, banks that support agent-based payments could gain a stronger role in digital commerce by acting as the control layer that manages consent and security. On the other, they must handle new questions about liability and dispute handling if an agent makes a purchase the customer later challenges.&lt;/p&gt;&lt;p&gt;Security and governance will likely shape how fast this model spreads. Analysts often point out that customers may accept AI suggestions long before they accept AI decisions involving money. By keeping approval logic in the issuing bank’s systems, Visa’s framework attempts to reassure users that human oversight remains embedded in the process.&lt;/p&gt;&lt;h3&gt;A wider change in how enterprises deploy AI agents&lt;/h3&gt;&lt;p&gt;Over the past year, many companies have moved beyond testing chatbots or internal assistants and started placing AI into workflows that directly affect revenue, operations, or customer transactions. In banking, this includes fraud monitoring, credit scoring support, and automated customer service. Allowing AI to trigger payments could be the next step in that progression.&lt;/p&gt;&lt;p&gt;DBS has invested heavily in digital banking systems, and the trial fits into a longer effort to integrate automation into financial services. The bank has focused previously on using data analytics and AI tools to streamline operations and personalise services.&lt;/p&gt;&lt;p&gt;Whether agent-based payments become common will depend on how comfortable customers feel delegating financial decisions to software. It will also depend on how clearly banks define the boundaries of what AI agents can and cannot do. Industry experts say adoption may begin with low-risk, repeat purchases before expanding to more complex transactions.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Patrick Tomasso)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: How financial institutions are embedding AI decision-making&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security &amp;amp; Cloud Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/DBS-pilots-system-that-lets-AI-agents-make-payments-for-customers-scaled-e1771483760926.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Artificial intelligence is moving closer to the point where it can act, not advise. A new pilot by DBS Bank shows how that change may soon affect everyday payments, as financial institutions begin testing systems that allow AI agents to complete purchases on behalf of customers.&lt;/p&gt;&lt;p&gt;DBS is working with Visa to trial Visa Intelligent Commerce, a framework designed to support transactions initiated by AI software not humans. The system allows digital agents to search for products, select options, and complete purchases using payment credentials issued and controlled by the bank. According to reports from &lt;em&gt;Asian Banking &amp;amp; Finance&lt;/em&gt; and &lt;em&gt;Fintech Futures&lt;/em&gt;, the pilot has already processed real transactions, including food and beverage purchases made using DBS or POSB cards.&lt;/p&gt;&lt;h3&gt;Moving from recommendations to real transactions&lt;/h3&gt;&lt;p&gt;The trial highlights how banks are preparing for what some in the industry call “agent-driven commerce.” In this model, AI tools act subject to rules set by both the customer and the issuing bank.&lt;/p&gt;&lt;p&gt;Visa’s approach keeps the bank at the centre of the process. Payment details are tokenised, and transactions pass through issuer-controlled approval flows designed to confirm identity and spending limits. The means the bank still decides whether the agent’s action fits the user’s permissions before money moves.&lt;/p&gt;&lt;p&gt;The DBS pilot is part of a wider effort to test where AI fits into financial infrastructure. Rather than treating AI as a customer-facing tool, banks are increasingly examining how it might change the mechanics of payments, fraud checks, and authorisation. Industry observers note that this is a change from AI as a productivity assistant to AI as an operational participant in transactions.&lt;/p&gt;&lt;h3&gt;Early use cases focus on routine purchases&lt;/h3&gt;&lt;p&gt;Early use cases for agent-based commerce include routine purchases like ordering groceries, renewing subscriptions, booking travel, or restocking household items. In these cases, the agent follows instructions set in advance by the user, like budget limits or preferred brands. DBS and Visa plan to expand the pilot into broader online shopping and travel bookings as testing continues, according to &lt;em&gt;Fintech Futures&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;The idea of AI executing purchases raises opportunity and risk for financial institutions. On one hand, banks that support agent-based payments could gain a stronger role in digital commerce by acting as the control layer that manages consent and security. On the other, they must handle new questions about liability and dispute handling if an agent makes a purchase the customer later challenges.&lt;/p&gt;&lt;p&gt;Security and governance will likely shape how fast this model spreads. Analysts often point out that customers may accept AI suggestions long before they accept AI decisions involving money. By keeping approval logic in the issuing bank’s systems, Visa’s framework attempts to reassure users that human oversight remains embedded in the process.&lt;/p&gt;&lt;h3&gt;A wider change in how enterprises deploy AI agents&lt;/h3&gt;&lt;p&gt;Over the past year, many companies have moved beyond testing chatbots or internal assistants and started placing AI into workflows that directly affect revenue, operations, or customer transactions. In banking, this includes fraud monitoring, credit scoring support, and automated customer service. Allowing AI to trigger payments could be the next step in that progression.&lt;/p&gt;&lt;p&gt;DBS has invested heavily in digital banking systems, and the trial fits into a longer effort to integrate automation into financial services. The bank has focused previously on using data analytics and AI tools to streamline operations and personalise services.&lt;/p&gt;&lt;p&gt;Whether agent-based payments become common will depend on how comfortable customers feel delegating financial decisions to software. It will also depend on how clearly banks define the boundaries of what AI agents can and cannot do. Industry experts say adoption may begin with low-risk, repeat purchases before expanding to more complex transactions.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Patrick Tomasso)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: How financial institutions are embedding AI decision-making&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security &amp;amp; Cloud Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/dbs-pilots-system-that-lets-ai-agents-make-payments-for-customers/</guid><pubDate>Thu, 19 Feb 2026 10:00:00 +0000</pubDate></item><item><title>The building legal case for global climate justice (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/19/1132877/legal-climate-justice/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;The United States and the European Union grew into economic superpowers by committing climate atrocities. They have burned a wildly disproportionate share of the world’s oil and gas, planting carbon time bombs that will detonate first in the poorest, hottest parts of the globe.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Meanwhile, places like the Solomon Islands and Chad—low-lying or just plain sweltering—have emitted relatively little carbon dioxide, but by dint of their latitude and history, they rank among the countries most vulnerable to the fiercest consequences of global warming. That means increasingly devastating cyclones, heat waves, famines, and floods.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Morally, there’s an ironclad case that the countries or companies responsible for this mess should provide compensation for the homes that will be destroyed, the shorelines that will disappear beneath rising seas, and the lives that will be cut short. By one estimate, the major economies owe a climate debt to the rest of the world approaching $200 trillion in reparations.&lt;/p&gt;  &lt;p&gt;Legally, though, the case has been far harder to make. Even putting aside the jurisdictional problems, early climate science couldn’t trace the provenance of airborne molecules of carbon dioxide across oceans and years. Deep-pocketed corporations with top-tier legal teams easily exploited those difficulties.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Now those tides might be turning. More climate-related lawsuits are getting filed, particularly in the Global South. Governments, nonprofits, and citizens in the most climate-exposed nations continue to test new legal arguments in new courts, and some of those courts are showing a new willingness to put nations and their industries on the hook as a matter of human rights. In addition, the science of figuring out exactly who is to blame for specific weather disasters, and to what degree, is getting better and better.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It’s true that no court has yet held any climate emitter liable for climate-related damages. For starters, nations are generally immune from lawsuits originating in other countries. That’s why most cases have focused on major carbon producers. But they’ve leaned on a pretty powerful defense.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;While oil and gas companies extract, refine, and sell the world’s fossil fuels, most of the emissions come out of “the vehicles, power plants, and factories that burn the fuel,” as Michael Gerrard and Jessica Wentz, of Columbia Law School’s Sabin Center, note in a recent piece in &lt;em&gt;Nature&lt;/em&gt;. In other words, companies just dig the stuff up. It’s not their fault someone else sets it on fire.&lt;/p&gt;  &lt;p&gt;So victims of extreme weather events continue to try new legal avenues and approaches, backed by ever-more-convincing science. Plaintiffs in the Philippines recently sued the oil giant Shell over its role in driving Super Typhoon Odette, a 2021 storm that killed more than 400 people and displaced nearly 800,000. The case relies partially on an attribution study that found climate change made extreme rainfall like that seen in Odette twice as likely.&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Survivors of Super Typhoon Odette (Rai) on using fishing boats and kayaks hold come together in the water to hold a giant banner: &amp;quot;SHELL, WE'RE SUING YOU FOR ODETTE.&amp;quot;" class="wp-image-1132871" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/GP0SU770C_Low-res.jpg?w=800" /&gt;&lt;div class="image-credit"&gt;IVAN JOESEFF GUIWANON/GREENPEACE&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Overall, evidence of corporate culpability—linking a specific company’s fossil fuel to a specific disaster—is getting easier to find. For example, a study published in &lt;em&gt;Nature&lt;/em&gt; in September was able to determine how much particular companies contributed to a series of 21st-century heat waves.&lt;/p&gt;  &lt;p&gt;A number of recent legal decisions signal improving odds for these kinds of suits. Notably, a handful of determinations in climate cases before the European Court of Human Rights affirmed that states have legal obligations to protect people from the effects of climate change. And though it dismissed the case of a Peruvian farmer who sued a German power company over fears that a melting alpine glacier could destroy his property, a German court determined that major carbon polluters could in principle be found liable for climate damages tied to their emissions.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;&lt;p&gt;At least one lawsuit has already emerged that could test that principle: Dozens of Pakistani farmers whose land was deluged during the massive flooding events of 2022 have sued a pair of major German power and cement companies.&lt;/p&gt;  &lt;p&gt;Even if the lawsuit fails, that would be a problem with the system, not the science. Major carbon-polluting countries and companies have a disproportionate responsibility for climate-change-powered disasters.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Wealthy nations continued to encourage business practices that pollute the atmosphere, even as the threat of climate change grew increasingly grave. And oil and gas companies remain the kingpin suppliers to a fossil-fuel-addicted world. They have operated with the full knowledge of the massive social, environmental, and human cost imposed by their business while lobbying fiercely against any rules that would force them to pay for those harms or clean up their act.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;They did it. They knew. In a civil society where rule of law matters, they should pay the price.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark,&amp;nbsp;&lt;/em&gt;MIT Technology Review&lt;em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday,&amp;nbsp;&lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;The United States and the European Union grew into economic superpowers by committing climate atrocities. They have burned a wildly disproportionate share of the world’s oil and gas, planting carbon time bombs that will detonate first in the poorest, hottest parts of the globe.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Meanwhile, places like the Solomon Islands and Chad—low-lying or just plain sweltering—have emitted relatively little carbon dioxide, but by dint of their latitude and history, they rank among the countries most vulnerable to the fiercest consequences of global warming. That means increasingly devastating cyclones, heat waves, famines, and floods.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Morally, there’s an ironclad case that the countries or companies responsible for this mess should provide compensation for the homes that will be destroyed, the shorelines that will disappear beneath rising seas, and the lives that will be cut short. By one estimate, the major economies owe a climate debt to the rest of the world approaching $200 trillion in reparations.&lt;/p&gt;  &lt;p&gt;Legally, though, the case has been far harder to make. Even putting aside the jurisdictional problems, early climate science couldn’t trace the provenance of airborne molecules of carbon dioxide across oceans and years. Deep-pocketed corporations with top-tier legal teams easily exploited those difficulties.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Now those tides might be turning. More climate-related lawsuits are getting filed, particularly in the Global South. Governments, nonprofits, and citizens in the most climate-exposed nations continue to test new legal arguments in new courts, and some of those courts are showing a new willingness to put nations and their industries on the hook as a matter of human rights. In addition, the science of figuring out exactly who is to blame for specific weather disasters, and to what degree, is getting better and better.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It’s true that no court has yet held any climate emitter liable for climate-related damages. For starters, nations are generally immune from lawsuits originating in other countries. That’s why most cases have focused on major carbon producers. But they’ve leaned on a pretty powerful defense.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;While oil and gas companies extract, refine, and sell the world’s fossil fuels, most of the emissions come out of “the vehicles, power plants, and factories that burn the fuel,” as Michael Gerrard and Jessica Wentz, of Columbia Law School’s Sabin Center, note in a recent piece in &lt;em&gt;Nature&lt;/em&gt;. In other words, companies just dig the stuff up. It’s not their fault someone else sets it on fire.&lt;/p&gt;  &lt;p&gt;So victims of extreme weather events continue to try new legal avenues and approaches, backed by ever-more-convincing science. Plaintiffs in the Philippines recently sued the oil giant Shell over its role in driving Super Typhoon Odette, a 2021 storm that killed more than 400 people and displaced nearly 800,000. The case relies partially on an attribution study that found climate change made extreme rainfall like that seen in Odette twice as likely.&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Survivors of Super Typhoon Odette (Rai) on using fishing boats and kayaks hold come together in the water to hold a giant banner: &amp;quot;SHELL, WE'RE SUING YOU FOR ODETTE.&amp;quot;" class="wp-image-1132871" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/GP0SU770C_Low-res.jpg?w=800" /&gt;&lt;div class="image-credit"&gt;IVAN JOESEFF GUIWANON/GREENPEACE&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Overall, evidence of corporate culpability—linking a specific company’s fossil fuel to a specific disaster—is getting easier to find. For example, a study published in &lt;em&gt;Nature&lt;/em&gt; in September was able to determine how much particular companies contributed to a series of 21st-century heat waves.&lt;/p&gt;  &lt;p&gt;A number of recent legal decisions signal improving odds for these kinds of suits. Notably, a handful of determinations in climate cases before the European Court of Human Rights affirmed that states have legal obligations to protect people from the effects of climate change. And though it dismissed the case of a Peruvian farmer who sued a German power company over fears that a melting alpine glacier could destroy his property, a German court determined that major carbon polluters could in principle be found liable for climate damages tied to their emissions.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;&lt;p&gt;At least one lawsuit has already emerged that could test that principle: Dozens of Pakistani farmers whose land was deluged during the massive flooding events of 2022 have sued a pair of major German power and cement companies.&lt;/p&gt;  &lt;p&gt;Even if the lawsuit fails, that would be a problem with the system, not the science. Major carbon-polluting countries and companies have a disproportionate responsibility for climate-change-powered disasters.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Wealthy nations continued to encourage business practices that pollute the atmosphere, even as the threat of climate change grew increasingly grave. And oil and gas companies remain the kingpin suppliers to a fossil-fuel-addicted world. They have operated with the full knowledge of the massive social, environmental, and human cost imposed by their business while lobbying fiercely against any rules that would force them to pay for those harms or clean up their act.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;They did it. They knew. In a civil society where rule of law matters, they should pay the price.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark,&amp;nbsp;&lt;/em&gt;MIT Technology Review&lt;em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday,&amp;nbsp;&lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/19/1132877/legal-climate-justice/</guid><pubDate>Thu, 19 Feb 2026 11:00:00 +0000</pubDate></item><item><title>How uncrewed narco subs could transform the Colombian drug trade (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/19/1132619/uncrewed-narco-subs-transform-columbian-drug-trade/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;On a bright morning last April, a surveillance plane operated by the Colombian military spotted a 40-foot-long shark-like silhouette idling in the ocean just off Tayrona National Park. It was, unmistakably, a “narco sub,” a stealthy fiberglass vessel that sails with its hull almost entirely underwater, used by drug cartels to move cocaine north. The plane’s crew radioed it in, and eventually nearby coast guard boats got the order, routine but urgent: Intercept.&lt;/p&gt;  &lt;p&gt;In Cartagena, about 150 miles from the action, Captain Jaime González Zamudio, commander of the regional coast guard group, sat down at his desk to watch what happened next. On his computer monitor, icons representing his patrol boats raced toward the sub’s coordinates as updates crackled over his radio from the crews at sea. This was all standard; Colombia is the world’s largest producer of cocaine, and its navy has been seizing narco subs for decades. And so the captain was pretty sure what the outcome would be. His crew would catch up to the sub, just a bit of it showing above the water’s surface. They’d bring it to heel, board it, and force open the hatch to find two, three, maybe four exhausted men suffocating in a mix of diesel fumes and humidity, and a cargo compartment holding several tons of cocaine.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;The boats caught up to the sub. A crew boarded, forced open the hatch, and confirmed that the vessel was secure. But from that point on, things were different.&lt;/p&gt;  &lt;p&gt;First, some unexpected details came over the radio: There was no cocaine on board. Neither was there a crew, nor a helm, nor even enough room for a person to lie down. Instead, inside the hull the crew found a fuel tank, an autopilot system and control electronics, and a remotely monitored security camera. González Zamudio’s crew started sending pictures back to Cartagena: Bolted to the hull was another camera, as well as two plastic rectangles, each about the size of a cookie sheet—antennas for connecting to Starlink satellite internet.&lt;/p&gt; 
 &lt;p&gt;The authorities towed the boat back to Cartagena, where military techs took a closer look. Weeks later, they came to an unsettling conclusion: This was Colombia’s first confirmed &lt;em&gt;uncrewed&lt;/em&gt; narco sub. It could be operated by remote control, but it was also capable of some degree of autonomous travel. The techs concluded that the sub was likely a prototype built by the Clan del Golfo, a powerful criminal group that operates along the Caribbean coast.&lt;/p&gt;  &lt;p&gt;For decades, handmade narco subs have been some of the cocaine trade’s most elusive and productive workhorses, ferrying multi-ton loads of illicit drugs from Colombian estuaries toward markets in North America and, increasingly, the rest of the world. Now off-the-shelf technology—Starlink terminals, plug-and-play nautical autopilots, high-resolution video cameras—may be advancing that cat-and-mouse game into a new phase. &lt;/p&gt; 
 &lt;p&gt;Uncrewed subs could move more cocaine over longer distances, and they wouldn’t put human smugglers at risk of capture. Law enforcement around the world is just beginning to grapple with what the Tayrona sub means for the future—whether it was merely an isolated experiment or the opening move in a new era of autonomous drug smuggling at sea.&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;Drug traffickers love the ocean. “You can move drug traffic through legal and illegal routes,” says Juan Pablo Serrano, a captain in the Colombian navy and head of the operational coordination center for Orión, a multiagency, multinational counternarcotics effort. The giant container ships at the heart of global commerce offer a favorite approach, Serrano says. Bribe a chain of dockworkers and inspectors, hide a load in one of thousands of cargo boxes, and put it on a totally legal commercial vessel headed to Europe or North America. That route is slow and expensive—involving months of transit and bribes spread across a wide network—but relatively low risk. “A ship can carry 5,000 containers. Good luck finding the right one,” he says.&lt;/p&gt;  &lt;p&gt;Far less legal, but much faster and cheaper, are small, powerful motorboats. Quick to build and cheap to crew, these “go-fasts” top out at just under 50 feet long and can move smaller loads in hours rather than days. But they’re also easy for coastal radars and patrols to spot.&lt;/p&gt;  &lt;p&gt;Submersibles—or, more accurately, “semisubmersibles”—fit somewhere in the middle. They take more money and engineering to build than an open speedboat, but they buy stealth—even if a bit of the vessel rides at the surface, the bulk stays hidden underwater. That adds another option to a portfolio that smugglers constantly rebalance across three variables: risk, time, and cost. When US and Colombian authorities tightened control over air routes and commercial shipping in the early 1990s, subs became more attractive. The first ones were crude wooden hulls with a fiberglass shell and extra fuel tanks, cobbled together in mangrove estuaries, hidden from prying eyes. Today’s fiberglass semisubmersible designs ride mostly below the surface, relying on diesel engines that can push multi-ton loads for days at a time while presenting little more than a ripple and a hot exhaust pipe to radar and infrared sensors.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;A typical semisubmersible costs under $2 million to build and can carry three metric tons of cocaine. That’s worth over $160 million in Europe—wholesale.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;Most ferry between South American coasts and handoff points in Central America and Mexico, where allied criminal organizations break up the cargo and slowly funnel it toward the US. But some now go much farther. In 2019, Spanish authorities intercepted a semisubmersible after a 27-day transatlantic voyage from Brazil. In 2024, police in the Solomon Islands found the first narco sub in the Asia-Pacific region, a semisubmersible probably originating from Colombia on its way to Australia or New Zealand.&lt;/p&gt;  &lt;p&gt;If the variables are risk, time, and cost, then the economics of a narco sub are simple. Even if they spend more time on the water than a powerboat, they’re less likely to get caught—and a relative bargain to produce. A narco sub might cost between $1&amp;nbsp;million and $2 million to build, but a kilo of cocaine costs just about $500 to make. “By the time that kilo reaches Europe, it can sell for between $44,000 and $55,000,” Serrano says. A typical semisubmersible carries up to three metric tons—cargo worth well over $160 million at European wholesale prices.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="imageSet__wrap"&gt;&lt;div class="class"&gt; &lt;p class="imageSet__caption"&gt;Off-the-shelf nautical autopilots, WiFi antennas, Starlink satellite internet connections, and remote cameras are all drug smugglers need to turn semisubmersibles into drone ships.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;As a result, narco subs are getting more common. Seizures by authorities tripled in the last 20 years, according to Colombia’s International Center for Research and Analysis Against Maritime Drug Trafficking (CMCON), and Serrano admits that the Orión alliance has enough ships and aircraft to catch only a fraction of what sails.&lt;/p&gt;  &lt;p&gt;Until now, though, narco subs have had one major flaw: They depended on people, usually poor fishermen or low-level recruits sealed into stifling compartments for days at a time, steering by GPS and sight, hoping not to be spotted. That made the subs expensive and a risk to drug sellers if captured. Like good capitalists, the Tayrona boat’s builders seem to have been trying to obviate labor costs with automation. No crew means more room for drugs or fuel and no sailors to pay—or to get arrested or flip if a mission goes wrong.&lt;/p&gt; 

 &lt;p&gt;“If you don’t have a person or people on board, that makes the transoceanic routes much more feasible,” says Henry Shuldiner, a researcher at InSight Crime who has analyzed hundreds of narco-sub cases. It’s one thing, he notes, to persuade someone to spend a day or two going from Colombia to Panama for a big payout; it’s another to ask four people to spend three weeks sealed inside a cramped tube, sleeping, eating, and relieving themselves in the same space. “That’s a hard sell,” Shuldiner says.&lt;/p&gt;  &lt;p&gt;An uncrewed sub doesn’t have to race to a rendezvous because its crew can endure only a few days inside. It can move more slowly and stealthily. It can wait out patrols or bad weather, loiter near a meeting point, or take longer and less well-monitored routes. And if something goes wrong—if a military plane appears or navigation fails—its owners can simply scuttle the vessel from afar.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt; &lt;p&gt;Meanwhile, the basic technology to make all that work is getting more and more affordable, and the potential profit margins are rising. “The rapidly approaching universality of autonomous technology could be a nightmare for the U.S. Coast Guard,” wrote two Coast Guard officers in the US Naval Institute’s journal &lt;em&gt;Proceedings&lt;/em&gt; in 2021. And as if to prove how good an idea drone narco subs are, the US Marine Corps and the weapons builder Leidos are testing a low-profile uncrewed vessel called the Sea Specter, which they describe as being “inspired” by narco-sub design.&lt;/p&gt;  &lt;p&gt;The possibility that drug smugglers are experimenting with autonomous subs isn’t just theoretical. Law enforcement agencies on other smuggling routes have found signs the Tayrona sub isn’t an isolated case. In 2022, Spanish police seized three small submersible drones near Cádiz, on Spain’s southern coast. Two years later, Italian authorities confiscated a remote-­controlled minisubmarine they believed was intended for drug runs. “The probability of expansion is high,” says Diego Cánovas, a port and maritime security expert in Spain. Tayrona, the biggest and most technologically advanced uncrewed narco sub found so far, is more likely a preview than an anomaly.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_11"&gt; &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;Today, the Tayrona semisubmersible sits on a strip of grass at the ARC Bolívar naval base in Cartagena. It’s exposed to the elements; rain has streaked its paint. To one side lies an older, bulkier narco sub seized a decade ago, a blue cylinder with a clumsy profile. The Tayrona’s hull looks lower, leaner, and more refined.&lt;/p&gt;  &lt;p&gt;Up close, it is also unmistakably handmade. The hull is a dull gray-blue, the fiberglass rough in places, with scrapes and dents from the tow that brought it into port. It has no identifying marks on the exterior—nothing that would tie it to a country, a company, or a port. On the upper surface sit the two Starlink antennas, painted over in the same gray-blue to keep them from standing out against the sea.&lt;/p&gt;  &lt;p&gt;I climb up a ladder and drop through the small hatch near the stern. Inside, the air is damp and close, the walls beaded with condensation. Small puddles of fuel have collected in the bilge. The vessel has no seating, no helm or steering wheel, and not enough space to stand up straight or lie down. It’s clear it was never meant to carry people. A technical report by CMCON found that the sub would have enough fuel for a journey of some 800 nautical miles, and the central cargo bay would hold between 1 and 1.5 tons of cocaine.&lt;/p&gt;  &lt;p&gt;At the aft end, the machinery compartment is a tangle of hardware: diesel engine, batteries, pumps, and a chaotic bundle of cables feeding an electronics rack. All the core components are still there. Inside that rack, investigators identified a NAC-3 autopilot processor, a commercial unit designed to steer midsize boats by tying into standard hydraulic pumps, heading sensors, and rudder-­feedback systems. They cost about $2,200 on Amazon.&lt;/p&gt; 
 &lt;p&gt;“These are plug-and-play technologies,” says Wilmar Martínez, a mechatronics professor at the University of America in Bogotá, when I show him pictures of the inside of the sub. “Midcareer mechatronics students could install them.”&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;For all its advantages, an autonomous drug-smuggling submarine wouldn’t be invincible. Even without a crew on board, there are still people in the chain. Every satellite internet terminal—Starlink or not—comes with a billing address, a payment method, and a log of where and when it pings the constellation. Colombian officers have begun to talk about negotiating formal agreements with providers, asking them to alert authorities when a transceiver’s movements match known smuggling patterns. Brazil’s government has already cut a deal with Starlink to curb criminal use of its service in the Amazon.&lt;/p&gt; 
 &lt;p&gt;The basic playbook for finding a drone sub will look much like the one for crewed semisubmersibles. Aircraft and ships will use radar to pick out small anomalies and infrared cameras to look for the heat of a diesel engine or the turbulence of a wake. That said, it might not work. “If they wind up being smaller, they’re going to be darn near impossible to detect,” says Michael Knickerbocker, a former US Navy officer who advises defense tech firms.&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;Autonomous drug subs are “a great example of how resilient cocaine traffickers are, and how they’re continuously one step ahead of authorities,” says one researcher.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;Even worse, navies already act on only a fraction of their intelligence leads because they don’t have enough ships and aircraft. The answer, Knickerbocker argues, is “robot on robot.” Navies and coast guards will need swarms of their own small, relatively cheap uncrewed systems—surface vessels, underwater gliders, and long-endurance aerial vehicles that can loiter, sense, and relay data back to human operators. Those experiments have already begun. The US 4th Fleet, which covers Latin America and the Caribbean, is experimenting with uncrewed platforms in counternarcotics patrols. Across the Atlantic, the European Union’s European Maritime Safety Agency operates drones for maritime surveillance.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_13"&gt; &lt;p&gt;Today, though, the major screens against oceangoing vessels of all kinds are coastal radar networks. Spain operates SIVE to watch over choke points like the Strait of Gibraltar, and in the Pacific, Australia’s over-the-horizon radar network, JORN, can spot objects hundreds of miles away, far beyond the range of conventional radar.&lt;/p&gt;  &lt;p&gt;Even so, it’s not enough to just spot an uncrewed narco sub. Law enforcement also has to stop it—and that will be tricky.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="man in naval uniform pointing at a map" class="wp-image-1132927" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/COLOMBIA-5.edit_.jpg?w=2000" width="2000" /&gt;&lt;figcaption class="wp-element-caption"&gt;To find drone subs, international law enforcement will likely have to rely on networks of surveillance systems and, someday, swarms of their own drones.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;CARLOS PARRA RIOS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;With a crewed vessel, Colombian doctrine says coast guard units should try to hail the boat first with lights, sirens, radio calls, and warning shots. If that fails, interceptor crews sometimes have to jump aboard and force the hatch. Officers worry that future autonomous craft could be wired to sink or even explode if someone gets too close. “If they get destroyed, we may lose the evidence,” says Víctor González Badrán, a navy captain and director of CMCON. “That means no seizure and no legal proceedings against that organization.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;That’s where electronic warfare enters the picture—radio-frequency jamming, cyber tools, perhaps more exotic options. In the simplest version, jamming means flooding the receiver with noise so that commands from the operator never reach the vessel. Spoofing goes a step further, feeding fake signals so that the sub thinks it’s somewhere else or obediently follows a fake set of waypoints. Cyber tools might aim higher up the chain, trying to penetrate the software that runs the vessel or the networks it uses to talk to satellite constellations. At the cutting edge of these countermeasures are electromagnetic pulses designed to fry electronics outright, turning a million-dollar narco sub into a dead hull drifting at sea.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_15"&gt;&lt;p&gt;In reality, the tools that might catch a future Tayrona sub are unevenly distributed, politically sensitive, and often experimental. Powerful cyber or electromagnetic tricks are closely guarded secrets; using them in a drug case risks exposing capabilities that militaries would rather reserve for wars. Systems like Australia’s JORN radar are tightly held national security assets, their exact performance specs classified, and sharing raw data with countries on the front lines of the cocaine trade would inevitably mean revealing hints as to how they got it. “Just because a capability exists doesn’t mean you employ it,” Knickerbocker says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Analysts don’t think uncrewed narco subs will reshape the global drug trade, despite the technological leap. Trafficking organizations will still hedge their bets across those three variables, hiding cocaine in shipping containers, dissolving it into liquids and paints, racing it north in fast boats. “I don’t think this is revolutionary,” Shuldiner says. “But it’s a great example of how resilient cocaine traffickers are, and how they’re continuously one step ahead of authorities.”&lt;/p&gt;  &lt;p&gt;There’s still that chance, though, that everything international law enforcement agencies know about drug smuggling is about to change. González Zamudio says he keeps getting requests from foreign navies, coast guards, and security agencies to come see the Tayrona sub. He greets their delegations, takes them out to the strip of grass on the base, and walks them around it, gives them tours. It has become a kind of pilgrimage. Everyone who makes it worries that the next time a narco sub appears near a distant coastline, they’ll board it as usual, force the hatch—and find it full of cocaine and gadgets, but without a single human occupant. And no one knows what happens after that.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Eduardo Echeverri López is a journalist based in Colombia.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;On a bright morning last April, a surveillance plane operated by the Colombian military spotted a 40-foot-long shark-like silhouette idling in the ocean just off Tayrona National Park. It was, unmistakably, a “narco sub,” a stealthy fiberglass vessel that sails with its hull almost entirely underwater, used by drug cartels to move cocaine north. The plane’s crew radioed it in, and eventually nearby coast guard boats got the order, routine but urgent: Intercept.&lt;/p&gt;  &lt;p&gt;In Cartagena, about 150 miles from the action, Captain Jaime González Zamudio, commander of the regional coast guard group, sat down at his desk to watch what happened next. On his computer monitor, icons representing his patrol boats raced toward the sub’s coordinates as updates crackled over his radio from the crews at sea. This was all standard; Colombia is the world’s largest producer of cocaine, and its navy has been seizing narco subs for decades. And so the captain was pretty sure what the outcome would be. His crew would catch up to the sub, just a bit of it showing above the water’s surface. They’d bring it to heel, board it, and force open the hatch to find two, three, maybe four exhausted men suffocating in a mix of diesel fumes and humidity, and a cargo compartment holding several tons of cocaine.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;The boats caught up to the sub. A crew boarded, forced open the hatch, and confirmed that the vessel was secure. But from that point on, things were different.&lt;/p&gt;  &lt;p&gt;First, some unexpected details came over the radio: There was no cocaine on board. Neither was there a crew, nor a helm, nor even enough room for a person to lie down. Instead, inside the hull the crew found a fuel tank, an autopilot system and control electronics, and a remotely monitored security camera. González Zamudio’s crew started sending pictures back to Cartagena: Bolted to the hull was another camera, as well as two plastic rectangles, each about the size of a cookie sheet—antennas for connecting to Starlink satellite internet.&lt;/p&gt; 
 &lt;p&gt;The authorities towed the boat back to Cartagena, where military techs took a closer look. Weeks later, they came to an unsettling conclusion: This was Colombia’s first confirmed &lt;em&gt;uncrewed&lt;/em&gt; narco sub. It could be operated by remote control, but it was also capable of some degree of autonomous travel. The techs concluded that the sub was likely a prototype built by the Clan del Golfo, a powerful criminal group that operates along the Caribbean coast.&lt;/p&gt;  &lt;p&gt;For decades, handmade narco subs have been some of the cocaine trade’s most elusive and productive workhorses, ferrying multi-ton loads of illicit drugs from Colombian estuaries toward markets in North America and, increasingly, the rest of the world. Now off-the-shelf technology—Starlink terminals, plug-and-play nautical autopilots, high-resolution video cameras—may be advancing that cat-and-mouse game into a new phase. &lt;/p&gt; 
 &lt;p&gt;Uncrewed subs could move more cocaine over longer distances, and they wouldn’t put human smugglers at risk of capture. Law enforcement around the world is just beginning to grapple with what the Tayrona sub means for the future—whether it was merely an isolated experiment or the opening move in a new era of autonomous drug smuggling at sea.&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;Drug traffickers love the ocean. “You can move drug traffic through legal and illegal routes,” says Juan Pablo Serrano, a captain in the Colombian navy and head of the operational coordination center for Orión, a multiagency, multinational counternarcotics effort. The giant container ships at the heart of global commerce offer a favorite approach, Serrano says. Bribe a chain of dockworkers and inspectors, hide a load in one of thousands of cargo boxes, and put it on a totally legal commercial vessel headed to Europe or North America. That route is slow and expensive—involving months of transit and bribes spread across a wide network—but relatively low risk. “A ship can carry 5,000 containers. Good luck finding the right one,” he says.&lt;/p&gt;  &lt;p&gt;Far less legal, but much faster and cheaper, are small, powerful motorboats. Quick to build and cheap to crew, these “go-fasts” top out at just under 50 feet long and can move smaller loads in hours rather than days. But they’re also easy for coastal radars and patrols to spot.&lt;/p&gt;  &lt;p&gt;Submersibles—or, more accurately, “semisubmersibles”—fit somewhere in the middle. They take more money and engineering to build than an open speedboat, but they buy stealth—even if a bit of the vessel rides at the surface, the bulk stays hidden underwater. That adds another option to a portfolio that smugglers constantly rebalance across three variables: risk, time, and cost. When US and Colombian authorities tightened control over air routes and commercial shipping in the early 1990s, subs became more attractive. The first ones were crude wooden hulls with a fiberglass shell and extra fuel tanks, cobbled together in mangrove estuaries, hidden from prying eyes. Today’s fiberglass semisubmersible designs ride mostly below the surface, relying on diesel engines that can push multi-ton loads for days at a time while presenting little more than a ripple and a hot exhaust pipe to radar and infrared sensors.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;A typical semisubmersible costs under $2 million to build and can carry three metric tons of cocaine. That’s worth over $160 million in Europe—wholesale.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;Most ferry between South American coasts and handoff points in Central America and Mexico, where allied criminal organizations break up the cargo and slowly funnel it toward the US. But some now go much farther. In 2019, Spanish authorities intercepted a semisubmersible after a 27-day transatlantic voyage from Brazil. In 2024, police in the Solomon Islands found the first narco sub in the Asia-Pacific region, a semisubmersible probably originating from Colombia on its way to Australia or New Zealand.&lt;/p&gt;  &lt;p&gt;If the variables are risk, time, and cost, then the economics of a narco sub are simple. Even if they spend more time on the water than a powerboat, they’re less likely to get caught—and a relative bargain to produce. A narco sub might cost between $1&amp;nbsp;million and $2 million to build, but a kilo of cocaine costs just about $500 to make. “By the time that kilo reaches Europe, it can sell for between $44,000 and $55,000,” Serrano says. A typical semisubmersible carries up to three metric tons—cargo worth well over $160 million at European wholesale prices.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="imageSet__wrap"&gt;&lt;div class="class"&gt; &lt;p class="imageSet__caption"&gt;Off-the-shelf nautical autopilots, WiFi antennas, Starlink satellite internet connections, and remote cameras are all drug smugglers need to turn semisubmersibles into drone ships.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;As a result, narco subs are getting more common. Seizures by authorities tripled in the last 20 years, according to Colombia’s International Center for Research and Analysis Against Maritime Drug Trafficking (CMCON), and Serrano admits that the Orión alliance has enough ships and aircraft to catch only a fraction of what sails.&lt;/p&gt;  &lt;p&gt;Until now, though, narco subs have had one major flaw: They depended on people, usually poor fishermen or low-level recruits sealed into stifling compartments for days at a time, steering by GPS and sight, hoping not to be spotted. That made the subs expensive and a risk to drug sellers if captured. Like good capitalists, the Tayrona boat’s builders seem to have been trying to obviate labor costs with automation. No crew means more room for drugs or fuel and no sailors to pay—or to get arrested or flip if a mission goes wrong.&lt;/p&gt; 

 &lt;p&gt;“If you don’t have a person or people on board, that makes the transoceanic routes much more feasible,” says Henry Shuldiner, a researcher at InSight Crime who has analyzed hundreds of narco-sub cases. It’s one thing, he notes, to persuade someone to spend a day or two going from Colombia to Panama for a big payout; it’s another to ask four people to spend three weeks sealed inside a cramped tube, sleeping, eating, and relieving themselves in the same space. “That’s a hard sell,” Shuldiner says.&lt;/p&gt;  &lt;p&gt;An uncrewed sub doesn’t have to race to a rendezvous because its crew can endure only a few days inside. It can move more slowly and stealthily. It can wait out patrols or bad weather, loiter near a meeting point, or take longer and less well-monitored routes. And if something goes wrong—if a military plane appears or navigation fails—its owners can simply scuttle the vessel from afar.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt; &lt;p&gt;Meanwhile, the basic technology to make all that work is getting more and more affordable, and the potential profit margins are rising. “The rapidly approaching universality of autonomous technology could be a nightmare for the U.S. Coast Guard,” wrote two Coast Guard officers in the US Naval Institute’s journal &lt;em&gt;Proceedings&lt;/em&gt; in 2021. And as if to prove how good an idea drone narco subs are, the US Marine Corps and the weapons builder Leidos are testing a low-profile uncrewed vessel called the Sea Specter, which they describe as being “inspired” by narco-sub design.&lt;/p&gt;  &lt;p&gt;The possibility that drug smugglers are experimenting with autonomous subs isn’t just theoretical. Law enforcement agencies on other smuggling routes have found signs the Tayrona sub isn’t an isolated case. In 2022, Spanish police seized three small submersible drones near Cádiz, on Spain’s southern coast. Two years later, Italian authorities confiscated a remote-­controlled minisubmarine they believed was intended for drug runs. “The probability of expansion is high,” says Diego Cánovas, a port and maritime security expert in Spain. Tayrona, the biggest and most technologically advanced uncrewed narco sub found so far, is more likely a preview than an anomaly.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_11"&gt; &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;Today, the Tayrona semisubmersible sits on a strip of grass at the ARC Bolívar naval base in Cartagena. It’s exposed to the elements; rain has streaked its paint. To one side lies an older, bulkier narco sub seized a decade ago, a blue cylinder with a clumsy profile. The Tayrona’s hull looks lower, leaner, and more refined.&lt;/p&gt;  &lt;p&gt;Up close, it is also unmistakably handmade. The hull is a dull gray-blue, the fiberglass rough in places, with scrapes and dents from the tow that brought it into port. It has no identifying marks on the exterior—nothing that would tie it to a country, a company, or a port. On the upper surface sit the two Starlink antennas, painted over in the same gray-blue to keep them from standing out against the sea.&lt;/p&gt;  &lt;p&gt;I climb up a ladder and drop through the small hatch near the stern. Inside, the air is damp and close, the walls beaded with condensation. Small puddles of fuel have collected in the bilge. The vessel has no seating, no helm or steering wheel, and not enough space to stand up straight or lie down. It’s clear it was never meant to carry people. A technical report by CMCON found that the sub would have enough fuel for a journey of some 800 nautical miles, and the central cargo bay would hold between 1 and 1.5 tons of cocaine.&lt;/p&gt;  &lt;p&gt;At the aft end, the machinery compartment is a tangle of hardware: diesel engine, batteries, pumps, and a chaotic bundle of cables feeding an electronics rack. All the core components are still there. Inside that rack, investigators identified a NAC-3 autopilot processor, a commercial unit designed to steer midsize boats by tying into standard hydraulic pumps, heading sensors, and rudder-­feedback systems. They cost about $2,200 on Amazon.&lt;/p&gt; 
 &lt;p&gt;“These are plug-and-play technologies,” says Wilmar Martínez, a mechatronics professor at the University of America in Bogotá, when I show him pictures of the inside of the sub. “Midcareer mechatronics students could install them.”&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;For all its advantages, an autonomous drug-smuggling submarine wouldn’t be invincible. Even without a crew on board, there are still people in the chain. Every satellite internet terminal—Starlink or not—comes with a billing address, a payment method, and a log of where and when it pings the constellation. Colombian officers have begun to talk about negotiating formal agreements with providers, asking them to alert authorities when a transceiver’s movements match known smuggling patterns. Brazil’s government has already cut a deal with Starlink to curb criminal use of its service in the Amazon.&lt;/p&gt; 
 &lt;p&gt;The basic playbook for finding a drone sub will look much like the one for crewed semisubmersibles. Aircraft and ships will use radar to pick out small anomalies and infrared cameras to look for the heat of a diesel engine or the turbulence of a wake. That said, it might not work. “If they wind up being smaller, they’re going to be darn near impossible to detect,” says Michael Knickerbocker, a former US Navy officer who advises defense tech firms.&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;Autonomous drug subs are “a great example of how resilient cocaine traffickers are, and how they’re continuously one step ahead of authorities,” says one researcher.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;Even worse, navies already act on only a fraction of their intelligence leads because they don’t have enough ships and aircraft. The answer, Knickerbocker argues, is “robot on robot.” Navies and coast guards will need swarms of their own small, relatively cheap uncrewed systems—surface vessels, underwater gliders, and long-endurance aerial vehicles that can loiter, sense, and relay data back to human operators. Those experiments have already begun. The US 4th Fleet, which covers Latin America and the Caribbean, is experimenting with uncrewed platforms in counternarcotics patrols. Across the Atlantic, the European Union’s European Maritime Safety Agency operates drones for maritime surveillance.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_13"&gt; &lt;p&gt;Today, though, the major screens against oceangoing vessels of all kinds are coastal radar networks. Spain operates SIVE to watch over choke points like the Strait of Gibraltar, and in the Pacific, Australia’s over-the-horizon radar network, JORN, can spot objects hundreds of miles away, far beyond the range of conventional radar.&lt;/p&gt;  &lt;p&gt;Even so, it’s not enough to just spot an uncrewed narco sub. Law enforcement also has to stop it—and that will be tricky.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="man in naval uniform pointing at a map" class="wp-image-1132927" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/COLOMBIA-5.edit_.jpg?w=2000" width="2000" /&gt;&lt;figcaption class="wp-element-caption"&gt;To find drone subs, international law enforcement will likely have to rely on networks of surveillance systems and, someday, swarms of their own drones.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;CARLOS PARRA RIOS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;With a crewed vessel, Colombian doctrine says coast guard units should try to hail the boat first with lights, sirens, radio calls, and warning shots. If that fails, interceptor crews sometimes have to jump aboard and force the hatch. Officers worry that future autonomous craft could be wired to sink or even explode if someone gets too close. “If they get destroyed, we may lose the evidence,” says Víctor González Badrán, a navy captain and director of CMCON. “That means no seizure and no legal proceedings against that organization.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;That’s where electronic warfare enters the picture—radio-frequency jamming, cyber tools, perhaps more exotic options. In the simplest version, jamming means flooding the receiver with noise so that commands from the operator never reach the vessel. Spoofing goes a step further, feeding fake signals so that the sub thinks it’s somewhere else or obediently follows a fake set of waypoints. Cyber tools might aim higher up the chain, trying to penetrate the software that runs the vessel or the networks it uses to talk to satellite constellations. At the cutting edge of these countermeasures are electromagnetic pulses designed to fry electronics outright, turning a million-dollar narco sub into a dead hull drifting at sea.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_15"&gt;&lt;p&gt;In reality, the tools that might catch a future Tayrona sub are unevenly distributed, politically sensitive, and often experimental. Powerful cyber or electromagnetic tricks are closely guarded secrets; using them in a drug case risks exposing capabilities that militaries would rather reserve for wars. Systems like Australia’s JORN radar are tightly held national security assets, their exact performance specs classified, and sharing raw data with countries on the front lines of the cocaine trade would inevitably mean revealing hints as to how they got it. “Just because a capability exists doesn’t mean you employ it,” Knickerbocker says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Analysts don’t think uncrewed narco subs will reshape the global drug trade, despite the technological leap. Trafficking organizations will still hedge their bets across those three variables, hiding cocaine in shipping containers, dissolving it into liquids and paints, racing it north in fast boats. “I don’t think this is revolutionary,” Shuldiner says. “But it’s a great example of how resilient cocaine traffickers are, and how they’re continuously one step ahead of authorities.”&lt;/p&gt;  &lt;p&gt;There’s still that chance, though, that everything international law enforcement agencies know about drug smuggling is about to change. González Zamudio says he keeps getting requests from foreign navies, coast guards, and security agencies to come see the Tayrona sub. He greets their delegations, takes them out to the strip of grass on the base, and walks them around it, gives them tours. It has become a kind of pilgrimage. Everyone who makes it worries that the next time a narco sub appears near a distant coastline, they’ll board it as usual, force the hatch—and find it full of cocaine and gadgets, but without a single human occupant. And no one knows what happens after that.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Eduardo Echeverri López is a journalist based in Colombia.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/19/1132619/uncrewed-narco-subs-transform-columbian-drug-trade/</guid><pubDate>Thu, 19 Feb 2026 11:00:00 +0000</pubDate></item><item><title>Reliance unveils $110B AI investment plan as India ramps up tech ambitions (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/19/reliance-unveils-110b-ai-investment-plan-as-india-ramps-up-tech-ambitions/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/reliance-mukesh-ambani.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Mukesh Ambani, the billionaire chairperson of Indian conglomerate Reliance, on Thursday unveiled the group’s ₹10 trillion (about $110 billion) plan to build AI computing infrastructure in India over the next seven years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Speaking at the India AI Impact Summit in New Delhi on Thursday, Ambani said the investment would fund gigawatt-scale data centers, a nationwide edge computing network, and new AI services integrated with Reliance’s Jio telecom platform.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Reliance has already begun construction of multi-gigawatt data centers in Jamnagar, Gujarat, Ambani said, and more than 120 megawatts of capacity is expected to come online in the second half of 2026.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ambani’s pledge adds to a growing wave of AI investment in India. Earlier this week, Adani Group outlined plans to invest about $100 billion to build AI data centers in the country, and the Indian government expects more than $200 billion in AI infrastructure spending over the next two years. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Global technology firms are also stepping up their presence, with OpenAI partnering with the Tata Group to develop about 100 megawatts of AI capacity in the country, and plans to scale that to 1 gigawatt eventually.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ambani said the push is essential for India’s technological self-reliance, saying the country “cannot afford to rent intelligence,” and that Reliance aims to cut the cost of AI services as dramatically as it once reduced mobile data prices in the country.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The biggest constraint in AI today is not talent or imagination,” Ambani said. “It is scarcity and high cost of compute.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The build-out, Ambani said, would be supported by Reliance’s green energy capacity, which stretches to 10 gigawatts of surplus power from solar projects in Gujarat and Andhra Pradesh.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Reliance will partner with Indian enterprises, startups, and academic institutions to embed AI in industries ranging from manufacturing and logistics to agriculture, healthcare and financial services.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Jio has already been striking AI partnerships: it last year landed a deal with Google to offer free Gemini AI Pro access to millions of its users in India.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Reliance also plans to develop AI capabilities in several Indian languages to spur adoption of the tech, Ambani said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The aggressive push highlights how India’s largest conglomerates are racing to secure a foothold in what is expected to be one of the country’s biggest technology opportunities.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/reliance-mukesh-ambani.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Mukesh Ambani, the billionaire chairperson of Indian conglomerate Reliance, on Thursday unveiled the group’s ₹10 trillion (about $110 billion) plan to build AI computing infrastructure in India over the next seven years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Speaking at the India AI Impact Summit in New Delhi on Thursday, Ambani said the investment would fund gigawatt-scale data centers, a nationwide edge computing network, and new AI services integrated with Reliance’s Jio telecom platform.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Reliance has already begun construction of multi-gigawatt data centers in Jamnagar, Gujarat, Ambani said, and more than 120 megawatts of capacity is expected to come online in the second half of 2026.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ambani’s pledge adds to a growing wave of AI investment in India. Earlier this week, Adani Group outlined plans to invest about $100 billion to build AI data centers in the country, and the Indian government expects more than $200 billion in AI infrastructure spending over the next two years. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Global technology firms are also stepping up their presence, with OpenAI partnering with the Tata Group to develop about 100 megawatts of AI capacity in the country, and plans to scale that to 1 gigawatt eventually.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ambani said the push is essential for India’s technological self-reliance, saying the country “cannot afford to rent intelligence,” and that Reliance aims to cut the cost of AI services as dramatically as it once reduced mobile data prices in the country.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The biggest constraint in AI today is not talent or imagination,” Ambani said. “It is scarcity and high cost of compute.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The build-out, Ambani said, would be supported by Reliance’s green energy capacity, which stretches to 10 gigawatts of surplus power from solar projects in Gujarat and Andhra Pradesh.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Reliance will partner with Indian enterprises, startups, and academic institutions to embed AI in industries ranging from manufacturing and logistics to agriculture, healthcare and financial services.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Jio has already been striking AI partnerships: it last year landed a deal with Google to offer free Gemini AI Pro access to millions of its users in India.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Reliance also plans to develop AI capabilities in several Indian languages to spur adoption of the tech, Ambani said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The aggressive push highlights how India’s largest conglomerates are racing to secure a foothold in what is expected to be one of the country’s biggest technology opportunities.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/19/reliance-unveils-110b-ai-investment-plan-as-india-ramps-up-tech-ambitions/</guid><pubDate>Thu, 19 Feb 2026 11:39:17 +0000</pubDate></item><item><title>Freeform raises $67M Series B to scale up laser AI manufacturing (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/19/freeform-raises-67m-series-b-to-scale-up-laser-ai-manufacturing/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/DSCF1027.jpeg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Tech investors haven’t given up on the dream of making physical products with the same speed and ease as coding software.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Executives at Freeform, a startup developing a novel 3D printing system for metal components, told TechCrunch that the company raised a $67 million Series B to expand its manufacturing platform.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Investors include Apandion, AE Ventures, Founders Fund, Linse Capital, NVidia’s NVentures , Threshold Ventures, and Two Sigma Ventures. FreeForm declined to disclose the company’s post-financing valuation, which Pitchbook cites as $179 million.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CEO and cofounder Erik Palitsch said the funding would allow the company to upgrade its current GoldenEye printing system, which uses 18 lasers to fuse metal powders into precision components, to a new version. Dubbed Skyfall, the next iteration of the platform would use hundreds of lasers to produce thousands of kilograms of metal parts each day.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s the culmination of a vision Palitsch launched in 2018 after developing rocket engines at SpaceX, where they found that industrial machines for printing metal components are expensive, finicky, and not well designed for mass manufacturing.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Their new company would build its platform from the ground up to achieve higher throughput and flexibility, with an emphasis on active software controls. Palitsch says Freeform’s platform is “AI native,” noting a partnership with Nvidia that allows the company to access advanced GPUs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think we’re the only quote-unquote manufacturing company out there that has H200 clusters in a data center on site,” Paltisch told TechCrunch. “What are they doing? We’re running real-time physics-based simulations and learning all the different aspects of the end to end manufacturing workflow.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The data collected by sensors in the company’s manufacturing platform and during the simulations allows Freeform to rapidly improve production quality and quantity.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have more meaningful data on the physics of the metal-printing process than any company in the world,” head of talent Cameron Kay said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Palitsch said he could not disclose any customers, he said the company is already delivering hundreds of “mission-critical” parts to buyers. Now, the company wants to hire as many as 100 new employees and expand its facility to start executing on its contract backlog.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Manufacturing-as-a-service has grown as a category as venture investors have taken a greater interest in building vehicles, robots, and energy production systems. For example, Hadrian recently earned a $1.6B valuation from its investors while developing automated production for defense, and VulcanForms and Divergent have raised hundreds of millions to develop metal-printing services of their own.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This piece has been updated to reflect former president Thomas Ronacher’s departure from Freeform. &lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/DSCF1027.jpeg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Tech investors haven’t given up on the dream of making physical products with the same speed and ease as coding software.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Executives at Freeform, a startup developing a novel 3D printing system for metal components, told TechCrunch that the company raised a $67 million Series B to expand its manufacturing platform.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Investors include Apandion, AE Ventures, Founders Fund, Linse Capital, NVidia’s NVentures , Threshold Ventures, and Two Sigma Ventures. FreeForm declined to disclose the company’s post-financing valuation, which Pitchbook cites as $179 million.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CEO and cofounder Erik Palitsch said the funding would allow the company to upgrade its current GoldenEye printing system, which uses 18 lasers to fuse metal powders into precision components, to a new version. Dubbed Skyfall, the next iteration of the platform would use hundreds of lasers to produce thousands of kilograms of metal parts each day.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s the culmination of a vision Palitsch launched in 2018 after developing rocket engines at SpaceX, where they found that industrial machines for printing metal components are expensive, finicky, and not well designed for mass manufacturing.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Their new company would build its platform from the ground up to achieve higher throughput and flexibility, with an emphasis on active software controls. Palitsch says Freeform’s platform is “AI native,” noting a partnership with Nvidia that allows the company to access advanced GPUs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think we’re the only quote-unquote manufacturing company out there that has H200 clusters in a data center on site,” Paltisch told TechCrunch. “What are they doing? We’re running real-time physics-based simulations and learning all the different aspects of the end to end manufacturing workflow.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The data collected by sensors in the company’s manufacturing platform and during the simulations allows Freeform to rapidly improve production quality and quantity.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have more meaningful data on the physics of the metal-printing process than any company in the world,” head of talent Cameron Kay said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Palitsch said he could not disclose any customers, he said the company is already delivering hundreds of “mission-critical” parts to buyers. Now, the company wants to hire as many as 100 new employees and expand its facility to start executing on its contract backlog.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Manufacturing-as-a-service has grown as a category as venture investors have taken a greater interest in building vehicles, robots, and energy production systems. For example, Hadrian recently earned a $1.6B valuation from its investors while developing automated production for defense, and VulcanForms and Divergent have raised hundreds of millions to develop metal-printing services of their own.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This piece has been updated to reflect former president Thomas Ronacher’s departure from Freeform. &lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/19/freeform-raises-67m-series-b-to-scale-up-laser-ai-manufacturing/</guid><pubDate>Thu, 19 Feb 2026 13:00:00 +0000</pubDate></item><item><title>[NEW] The Download: autonomous narco submarines, and virtue signaling chatbots (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/19/1133339/the-download-autonomous-narco-submarines-and-virtue-signaling-chatbots/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;How uncrewed narco subs could transform the Colombian drug trade&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;For decades, handmade narco subs have been some of the cocaine trade’s most elusive and productive workhorses, ferrying multi-ton loads of illicit drugs from Colombian estuaries toward markets in North America and, increasingly, the rest of the world. Now off-the-shelf technology—Starlink terminals, plug-and-play nautical autopilots, high-resolution video cameras—may be advancing that cat-and-mouse game into a new phase.&lt;/p&gt;&lt;p&gt;Uncrewed subs could move more cocaine over longer distances, and they wouldn’t put human smugglers at risk of capture. And law enforcement around the world is just beginning to grapple with what this means for the future.&lt;strong&gt; &lt;/strong&gt;Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Eduardo Echeverri López&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;This story is from the next print issue of&lt;em&gt; MIT Technology Review&lt;/em&gt; magazine, which is all about crime. If you haven’t already, &lt;/strong&gt;&lt;strong&gt;subscribe now&lt;/strong&gt;&lt;strong&gt; to receive future issues once they land.&lt;/strong&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;&amp;nbsp;Google DeepMind wants to know if chatbots are just virtue signaling&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;The news: &lt;/strong&gt;Google DeepMind is calling for the moral behavior of large language models—such as what they do when called on to act as companions, therapists, medical advisors, and so on—to be scrutinized with the same kind of rigor as their ability to code or do math.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Why it matters: &lt;/strong&gt;As LLMs improve, people are asking them to play more and more sensitive roles in their lives. Agents are starting to take actions on people’s behalf. LLMs may be able to influence human decision-making. And yet nobody knows how trustworthy this technology really is at such tasks. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Will Douglas Heaven&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The building legal case for global climate justice&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;The United States and the European Union grew into economic superpowers by committing climate atrocities. They have burned a wildly disproportionate share of the world’s oil and gas, planting carbon time bombs that will detonate first in the poorest, hottest parts of the globe.&lt;/p&gt;&lt;p&gt;Morally, there’s an ironclad case that the countries or companies responsible for this mess should provide compensation. Legally, though, the case has been far harder to make. But now those tides might be turning. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—James Temple&lt;/em&gt;&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;This article is from The Spark, &lt;em&gt;MIT Technology Review&lt;/em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;1 The US is building an online portal to access content banned elsewhere&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;The freedom.gov site is Washington’s broadbrush solution to global censorship. (Reuters)&lt;br /&gt;+ &lt;em&gt;The Trump administration is on a mission to train a cadre of elite coders. &lt;/em&gt;(FT $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 Mark Zuckerberg overruled wellbeing experts to keep beauty filters on Instagram&lt;br /&gt;&lt;/strong&gt;Because removing them may have impinged on “free expression,” apparently. (FT $)+ &lt;em&gt;The CEO claims that increasing engagement is not Instagram’s goal. &lt;/em&gt;(CNBC)&lt;br /&gt;+ &lt;em&gt;Instead, the company’s true calling is to give its users “something useful”. &lt;/em&gt;(WSJ $)&lt;br /&gt;+ &lt;em&gt;A new investigation found Meta is failing to protect children from predators. &lt;/em&gt;(WP $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 Silicon Valley is working on a shadow power grid for US data centers&lt;/strong&gt;&lt;br /&gt;AI firms are planning to build their own private power plants across the US. (WP $)&lt;br /&gt;+ &lt;em&gt;They’re pushing the narrative that generative AI will save the Earth. &lt;/em&gt;(Wired $)&lt;br /&gt;+ &lt;em&gt;We need better metrics to measure data center sustainability with. &lt;/em&gt;(IEEE Spectrum)&lt;br /&gt;+ &lt;em&gt;The data center boom in the desert. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 Russian forces are struggling with Starlink and Telegram crackdowns&lt;/strong&gt;&lt;br /&gt;New restrictions have left troops without a means to communicate. (Bloomberg $)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;5 Bill Gates won’t speak at India’s AI summit after all&lt;br /&gt;Given the growing controversy surrounding his ties to Jeffrey Epstein. (BBC)&lt;br /&gt;+ &lt;em&gt;The event has been accused of being disorganized and poorly managed. &lt;/em&gt;(Reuters)&lt;br /&gt;+ &lt;em&gt;AI leaders didn’t appreciate this awkward photoshoot. &lt;/em&gt;(Bloomberg $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 AI software sales are slowing down&lt;br /&gt;&lt;/strong&gt;Last year’s boom appears to be waning, vendors have warned. (WSJ $)&lt;br /&gt;+ &lt;em&gt;What even is the AI bubble? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 eBay has acquired its clothes resale rival Depop &lt;/strong&gt;&lt;strong&gt;👚&lt;/strong&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;It’s a naked play to corner younger Gen Z shoppers. (NYT $)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;8 There’s a lot more going on inside cells than we originally thought&lt;/strong&gt;&lt;br /&gt;It’s seriously crowded inside there. (Quanta Magazine)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 What it means to create a chart-topping app&lt;/strong&gt;&lt;br /&gt;Does anyone care any more? (The Verge)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10 Do we really need eight hours of sleep?&lt;/strong&gt;&lt;br /&gt;Research suggests some people really are fine operating on as little as four hours of snooze time. (New Yorker $)&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p class="has-large-font-size"&gt;&lt;strong&gt;“Too often, those victims have been left to fight alone…That is not justice. It is failure.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Keir Starmer, the UK’s prime minister, outlines plans to force technology firms to remove deepfake nudes and revenge porn within 48 hours or risk being blocked in the UK, the Guardian reports.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; 
 &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1133342" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/image_62473e.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;End of life decisions are difficult and distressing. Could AI help?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;End-of-life decisions can be extremely upsetting for surrogates—the people who have to make those calls on behalf of another person. Friends or family members may disagree over what’s best for their loved one, which can lead to distressing situations.&lt;/p&gt;&lt;p&gt;David Wendler, a bioethicist at the US National Institutes of Health, and his colleagues have been working on an idea for something that could make things easier: an artificial intelligence-based tool that can help surrogates predict what the patients themselves would want in any given situation.&lt;/p&gt;&lt;p&gt;Wendler hopes to start building their tool as soon as they secure funding for it, potentially in the coming months. But rolling it out won’t be simple. Critics wonder how such a tool can ethically be trained on a person’s data, and whether life-or-death decisions should ever be entrusted to AI. Read the full story.&lt;/p&gt;&lt;p&gt;&lt;em&gt;—Jessica Hamzelou&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ Oakland Library keeps a remarkable public log of all the weird and wonderful artefacts their librarians find tucked away in the pages of their books.&lt;br /&gt;+ Orchids are beautiful, but temperamental. Here’s how to keep them alive.&lt;br /&gt;+ I love that New York’s Transit Museum is holding a Pizza Rat Debunked event.&lt;br /&gt;+ These British indie bands aren’t really lauded at home—but in China, they’re treated like royalty.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;How uncrewed narco subs could transform the Colombian drug trade&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;For decades, handmade narco subs have been some of the cocaine trade’s most elusive and productive workhorses, ferrying multi-ton loads of illicit drugs from Colombian estuaries toward markets in North America and, increasingly, the rest of the world. Now off-the-shelf technology—Starlink terminals, plug-and-play nautical autopilots, high-resolution video cameras—may be advancing that cat-and-mouse game into a new phase.&lt;/p&gt;&lt;p&gt;Uncrewed subs could move more cocaine over longer distances, and they wouldn’t put human smugglers at risk of capture. And law enforcement around the world is just beginning to grapple with what this means for the future.&lt;strong&gt; &lt;/strong&gt;Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Eduardo Echeverri López&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;This story is from the next print issue of&lt;em&gt; MIT Technology Review&lt;/em&gt; magazine, which is all about crime. If you haven’t already, &lt;/strong&gt;&lt;strong&gt;subscribe now&lt;/strong&gt;&lt;strong&gt; to receive future issues once they land.&lt;/strong&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;&amp;nbsp;Google DeepMind wants to know if chatbots are just virtue signaling&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;The news: &lt;/strong&gt;Google DeepMind is calling for the moral behavior of large language models—such as what they do when called on to act as companions, therapists, medical advisors, and so on—to be scrutinized with the same kind of rigor as their ability to code or do math.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Why it matters: &lt;/strong&gt;As LLMs improve, people are asking them to play more and more sensitive roles in their lives. Agents are starting to take actions on people’s behalf. LLMs may be able to influence human decision-making. And yet nobody knows how trustworthy this technology really is at such tasks. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Will Douglas Heaven&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The building legal case for global climate justice&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;The United States and the European Union grew into economic superpowers by committing climate atrocities. They have burned a wildly disproportionate share of the world’s oil and gas, planting carbon time bombs that will detonate first in the poorest, hottest parts of the globe.&lt;/p&gt;&lt;p&gt;Morally, there’s an ironclad case that the countries or companies responsible for this mess should provide compensation. Legally, though, the case has been far harder to make. But now those tides might be turning. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—James Temple&lt;/em&gt;&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;This article is from The Spark, &lt;em&gt;MIT Technology Review&lt;/em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;1 The US is building an online portal to access content banned elsewhere&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;The freedom.gov site is Washington’s broadbrush solution to global censorship. (Reuters)&lt;br /&gt;+ &lt;em&gt;The Trump administration is on a mission to train a cadre of elite coders. &lt;/em&gt;(FT $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 Mark Zuckerberg overruled wellbeing experts to keep beauty filters on Instagram&lt;br /&gt;&lt;/strong&gt;Because removing them may have impinged on “free expression,” apparently. (FT $)+ &lt;em&gt;The CEO claims that increasing engagement is not Instagram’s goal. &lt;/em&gt;(CNBC)&lt;br /&gt;+ &lt;em&gt;Instead, the company’s true calling is to give its users “something useful”. &lt;/em&gt;(WSJ $)&lt;br /&gt;+ &lt;em&gt;A new investigation found Meta is failing to protect children from predators. &lt;/em&gt;(WP $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 Silicon Valley is working on a shadow power grid for US data centers&lt;/strong&gt;&lt;br /&gt;AI firms are planning to build their own private power plants across the US. (WP $)&lt;br /&gt;+ &lt;em&gt;They’re pushing the narrative that generative AI will save the Earth. &lt;/em&gt;(Wired $)&lt;br /&gt;+ &lt;em&gt;We need better metrics to measure data center sustainability with. &lt;/em&gt;(IEEE Spectrum)&lt;br /&gt;+ &lt;em&gt;The data center boom in the desert. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 Russian forces are struggling with Starlink and Telegram crackdowns&lt;/strong&gt;&lt;br /&gt;New restrictions have left troops without a means to communicate. (Bloomberg $)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;5 Bill Gates won’t speak at India’s AI summit after all&lt;br /&gt;Given the growing controversy surrounding his ties to Jeffrey Epstein. (BBC)&lt;br /&gt;+ &lt;em&gt;The event has been accused of being disorganized and poorly managed. &lt;/em&gt;(Reuters)&lt;br /&gt;+ &lt;em&gt;AI leaders didn’t appreciate this awkward photoshoot. &lt;/em&gt;(Bloomberg $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 AI software sales are slowing down&lt;br /&gt;&lt;/strong&gt;Last year’s boom appears to be waning, vendors have warned. (WSJ $)&lt;br /&gt;+ &lt;em&gt;What even is the AI bubble? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 eBay has acquired its clothes resale rival Depop &lt;/strong&gt;&lt;strong&gt;👚&lt;/strong&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;It’s a naked play to corner younger Gen Z shoppers. (NYT $)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;8 There’s a lot more going on inside cells than we originally thought&lt;/strong&gt;&lt;br /&gt;It’s seriously crowded inside there. (Quanta Magazine)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 What it means to create a chart-topping app&lt;/strong&gt;&lt;br /&gt;Does anyone care any more? (The Verge)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10 Do we really need eight hours of sleep?&lt;/strong&gt;&lt;br /&gt;Research suggests some people really are fine operating on as little as four hours of snooze time. (New Yorker $)&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p class="has-large-font-size"&gt;&lt;strong&gt;“Too often, those victims have been left to fight alone…That is not justice. It is failure.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Keir Starmer, the UK’s prime minister, outlines plans to force technology firms to remove deepfake nudes and revenge porn within 48 hours or risk being blocked in the UK, the Guardian reports.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; 
 &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1133342" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/image_62473e.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;End of life decisions are difficult and distressing. Could AI help?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;End-of-life decisions can be extremely upsetting for surrogates—the people who have to make those calls on behalf of another person. Friends or family members may disagree over what’s best for their loved one, which can lead to distressing situations.&lt;/p&gt;&lt;p&gt;David Wendler, a bioethicist at the US National Institutes of Health, and his colleagues have been working on an idea for something that could make things easier: an artificial intelligence-based tool that can help surrogates predict what the patients themselves would want in any given situation.&lt;/p&gt;&lt;p&gt;Wendler hopes to start building their tool as soon as they secure funding for it, potentially in the coming months. But rolling it out won’t be simple. Critics wonder how such a tool can ethically be trained on a person’s data, and whether life-or-death decisions should ever be entrusted to AI. Read the full story.&lt;/p&gt;&lt;p&gt;&lt;em&gt;—Jessica Hamzelou&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ Oakland Library keeps a remarkable public log of all the weird and wonderful artefacts their librarians find tucked away in the pages of their books.&lt;br /&gt;+ Orchids are beautiful, but temperamental. Here’s how to keep them alive.&lt;br /&gt;+ I love that New York’s Transit Museum is holding a Pizza Rat Debunked event.&lt;br /&gt;+ These British indie bands aren’t really lauded at home—but in China, they’re treated like royalty.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/19/1133339/the-download-autonomous-narco-submarines-and-virtue-signaling-chatbots/</guid><pubDate>Thu, 19 Feb 2026 13:10:00 +0000</pubDate></item><item><title>[NEW] How AI upgrades enterprise treasury management (AI News)</title><link>https://www.artificialintelligence-news.com/news/how-ai-upgrades-enterprise-treasury-management/</link><description>&lt;p&gt;The adoption of AI for enterprise treasury management enables businesses to abandon manual spreadsheets for automated data pipelines.&lt;/p&gt;&lt;p&gt;Corporate finance departments face pressure from market volatility, regulatory demands, and digital finance requirements. Ashish Kumar, head of Infosys Oracle Sales for North America, and CM Grover, CEO of IBS FinTech, recently discussed the realities of corporate treasuries.&lt;/p&gt;&lt;p&gt;IBS FinTech has operated for 19 years and currently ranks in the top five globally according to an IDC report. Grover notes that while AI-powered automation has reached many areas of corporate life, treasury departments often still rely on manual spreadsheets.&lt;/p&gt;&lt;p&gt;“IBS FinTech has identified the gap in the CFO’s office in corporations where they are managing their most critical information system, that is, treasury management on Excel,” Grover said.&lt;/p&gt;&lt;p&gt;Treasury teams manage cash, liquidity, and risk. Companies face foreign currency risk through imports and exports, alongside related commodity risks. Cash surplus companies also need to invest in operations to generate returns.&lt;/p&gt;&lt;p&gt;The key problem for many enterprises is a lack of real-time data connection. Teams often execute trades on platforms like Bloomberg, Reuters, or 360D, manually enter the data into spreadsheets, and then post accounting entries into an enterprise resource planning system.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-successfully-implementing-ai-in-enterprise-treasury-management"&gt;Successfully implementing AI in enterprise treasury management&lt;/h3&gt;&lt;p&gt;AI implementations in finance depend on resolving these manual bottlenecks. Enterprise leaders often view the technology as a fast solution, but the technology requires digitised and automated data as a foundation.&lt;/p&gt;&lt;p&gt;“It is not by talking you can do AI in treasury,” Grover said. “You have to create that underlying data set that has to be digitised and automated.”&lt;/p&gt;&lt;p&gt;Integrating treasury management systems with existing enterprise resource planning platforms allows companies to establish this data foundation. IBS FinTech built its backend on Oracle databases from its inception and now integrates with Oracle Cloud, NetSuite, and Fusion.&lt;/p&gt;&lt;p&gt;A connected ecosystem requires the treasury management system to communicate directly with the enterprise resource planning platform, trading platforms, and banks. This integration provides executives with accurate information to manage liquidity, mitigate risk, and monitor compliance violations across the system.&lt;/p&gt;&lt;p&gt;Grover expects global volatility to increase due to geopolitical and economic factors impacting commodities, equities, and foreign exchange. Executives must prioritise automation and real-time information systems to operate in this uncertain environment.&lt;/p&gt;&lt;p&gt;Kumar noted that modernising treasury management with AI and connecting it to enterprise resource planning systems builds financial resilience. Enterprise leaders should audit their existing data workflows. If a finance team relies on manual entry between a trading platform and an enterprise resource planning platform, AI initiatives will fail due to poor data quality.&lt;/p&gt;&lt;p&gt;Implementing direct integrations ensures data flows in real time without error, providing the necessary baseline for future technology deployment.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;DBS pilots system that lets AI agents make payments for customers&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for the AI &amp;amp; Big Data Expo event series." class="wp-image-109137" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security &amp;amp; Cloud Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;The adoption of AI for enterprise treasury management enables businesses to abandon manual spreadsheets for automated data pipelines.&lt;/p&gt;&lt;p&gt;Corporate finance departments face pressure from market volatility, regulatory demands, and digital finance requirements. Ashish Kumar, head of Infosys Oracle Sales for North America, and CM Grover, CEO of IBS FinTech, recently discussed the realities of corporate treasuries.&lt;/p&gt;&lt;p&gt;IBS FinTech has operated for 19 years and currently ranks in the top five globally according to an IDC report. Grover notes that while AI-powered automation has reached many areas of corporate life, treasury departments often still rely on manual spreadsheets.&lt;/p&gt;&lt;p&gt;“IBS FinTech has identified the gap in the CFO’s office in corporations where they are managing their most critical information system, that is, treasury management on Excel,” Grover said.&lt;/p&gt;&lt;p&gt;Treasury teams manage cash, liquidity, and risk. Companies face foreign currency risk through imports and exports, alongside related commodity risks. Cash surplus companies also need to invest in operations to generate returns.&lt;/p&gt;&lt;p&gt;The key problem for many enterprises is a lack of real-time data connection. Teams often execute trades on platforms like Bloomberg, Reuters, or 360D, manually enter the data into spreadsheets, and then post accounting entries into an enterprise resource planning system.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-successfully-implementing-ai-in-enterprise-treasury-management"&gt;Successfully implementing AI in enterprise treasury management&lt;/h3&gt;&lt;p&gt;AI implementations in finance depend on resolving these manual bottlenecks. Enterprise leaders often view the technology as a fast solution, but the technology requires digitised and automated data as a foundation.&lt;/p&gt;&lt;p&gt;“It is not by talking you can do AI in treasury,” Grover said. “You have to create that underlying data set that has to be digitised and automated.”&lt;/p&gt;&lt;p&gt;Integrating treasury management systems with existing enterprise resource planning platforms allows companies to establish this data foundation. IBS FinTech built its backend on Oracle databases from its inception and now integrates with Oracle Cloud, NetSuite, and Fusion.&lt;/p&gt;&lt;p&gt;A connected ecosystem requires the treasury management system to communicate directly with the enterprise resource planning platform, trading platforms, and banks. This integration provides executives with accurate information to manage liquidity, mitigate risk, and monitor compliance violations across the system.&lt;/p&gt;&lt;p&gt;Grover expects global volatility to increase due to geopolitical and economic factors impacting commodities, equities, and foreign exchange. Executives must prioritise automation and real-time information systems to operate in this uncertain environment.&lt;/p&gt;&lt;p&gt;Kumar noted that modernising treasury management with AI and connecting it to enterprise resource planning systems builds financial resilience. Enterprise leaders should audit their existing data workflows. If a finance team relies on manual entry between a trading platform and an enterprise resource planning platform, AI initiatives will fail due to poor data quality.&lt;/p&gt;&lt;p&gt;Implementing direct integrations ensures data flows in real time without error, providing the necessary baseline for future technology deployment.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;DBS pilots system that lets AI agents make payments for customers&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for the AI &amp;amp; Big Data Expo event series." class="wp-image-109137" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security &amp;amp; Cloud Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/how-ai-upgrades-enterprise-treasury-management/</guid><pubDate>Thu, 19 Feb 2026 13:48:55 +0000</pubDate></item><item><title>[NEW] Altman and Amodei share a moment of awkwardness at India’s big AI summit (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/19/altman-and-amodei-share-a-moment-of-awkwardness-at-indias-big-ai-summit/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/modi-openai-anthropic-2261854815.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;What would have been a moment of united commitment to global tech innovation at the ongoing India AI Impact Summit instead proved an awkward one: When Prime Minister Narendra Modi prompted speakers at the event to join hands and raise them in a show of solidarity, all executives on stage obliged — except OpenAI’s Sam Altman and Anthropic’s Dario Amodei, who held their hands noticeably apart.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As leaders of the two foremost labs in the AI race, it goes without saying that Altman and Amodei are fierce competitors. That rivalry has only intensified in recent months: after OpenAI said it would bring advertisements to ChatGPT, Anthropic took a swipe at OpenAI in a couple ads during the Super Bowl, declaring that it would never introduce ads into Claude.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Altman soon after hit back in response, calling Anthropic “dishonest” and “authoritarian.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We would obviously never run ads in the way Anthropic depicts them. We are not stupid, and we know our users would reject that,” he wrote at the time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Both Altman and Amodei were in India this week for the AI summit held in New Delhi, which saw a bevy of AI-related investments, features and products being announced. OpenAI said it is opening two new offices in India, partnering with IT giant TCS, and is deploying tools for higher education. Anthropic has also opened an office in India and teamed up with Infosys for internal and external deployment of its AI tools.&lt;/p&gt;




&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/modi-openai-anthropic-2261854815.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;What would have been a moment of united commitment to global tech innovation at the ongoing India AI Impact Summit instead proved an awkward one: When Prime Minister Narendra Modi prompted speakers at the event to join hands and raise them in a show of solidarity, all executives on stage obliged — except OpenAI’s Sam Altman and Anthropic’s Dario Amodei, who held their hands noticeably apart.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As leaders of the two foremost labs in the AI race, it goes without saying that Altman and Amodei are fierce competitors. That rivalry has only intensified in recent months: after OpenAI said it would bring advertisements to ChatGPT, Anthropic took a swipe at OpenAI in a couple ads during the Super Bowl, declaring that it would never introduce ads into Claude.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Altman soon after hit back in response, calling Anthropic “dishonest” and “authoritarian.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We would obviously never run ads in the way Anthropic depicts them. We are not stupid, and we know our users would reject that,” he wrote at the time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Both Altman and Amodei were in India this week for the AI summit held in New Delhi, which saw a bevy of AI-related investments, features and products being announced. OpenAI said it is opening two new offices in India, partnering with IT giant TCS, and is deploying tools for higher education. Anthropic has also opened an office in India and teamed up with Infosys for internal and external deployment of its AI tools.&lt;/p&gt;




&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/19/altman-and-amodei-share-a-moment-of-awkwardness-at-indias-big-ai-summit/</guid><pubDate>Thu, 19 Feb 2026 13:49:06 +0000</pubDate></item><item><title>[NEW] For open source programs, AI coding tools are a mixed blessing (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/19/for-open-source-programs-ai-coding-tools-are-a-mixed-blessing/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/10/GettyImages-1443890653.jpg?resize=1200,747" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;A world that runs on increasingly powerful AI coding tools is one where software creation is cheap — or so the thinking goes — leaving little room for traditional software companies. As one analyst report put it, “vibe coding will allow startups to replicate the features of complex SaaS platforms.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cue the hand-wringing and declarations that software companies are doomed. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Open source software projects that use agents to paper over long-standing resource constraints should logically be among the first to benefit from the era of cheap code. But that equation just doesn’t quite stick. In practice, the impact of AI coding tools on open source software has been far more mixed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI coding tools have caused as many problems as they have solved, according to industry experts. The easy-to-use and accessible nature of AI coding tools has enabled a flood of bad code that threatens to overwhelm projects. Building new features is easier than ever, but maintaining them is just as hard and threatens to further fragment software ecosystems. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The result is a more complicated story than simple software abundance. Perhaps the predicted, imminent death of the software engineer in this new AI era is premature.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-quality-versus-quantity"&gt;Quality versus quantity&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Across the board, projects with open codebases are noticing a decline in the average quality of submissions, likely a result of AI tools lowering barriers to entry. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“For people who are junior to the VLC codebase, the quality of the merge requests we see is abysmal,” Jean-Baptiste Kempf, the CEO of the VideoLAN Organization that oversees VLC, said in a recent interview.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Kempf is still optimistic about AI coding tools overall but says they’re best “for experienced developers.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There have been similar problems for Blender, a 3D modeling tool that has been maintained as open source since 2002. Blender Foundation CEO Francesco Siddi said LLM-assisted contributions typically “wasted reviewers’ time and affected their motivation.” Blender is still developing an official policy for AI coding tools, but Siddi said they are “neither mandated nor recommended for contributors or core developers.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The flood of merge requests has gotten so bad that open source developers are building new tools to manage it.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Earlier this month, developer Mitchell Hashimoto launched a system that would limit GitHub contributions to “vouched” users, effectively closing the open-door policy for open source software. As Hashimoto put it in the announcement, “AI eliminated the natural barrier to entry that let OSS projects trust by default.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The same effect has emerged in bug bounty programs, which give outside researchers an open door to report security vulnerabilities. The open source data transfer program cURL recently halted its bug bounty program after being overwhelmed by what creator Daniel Stenberg described as “AI slop.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“In the old days, someone actually invested a lot of time [in] the security report,” Stenberg said at a recent conference. “There was a built-in friction, but now there’s no effort at all in doing this. The floodgates are open.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s particularly frustrating because many open source projects are also seeing the benefits of AI coding tools. Kempf says it’s made building new modules for VLC far easier, provided there’s an experienced developer at the helm.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You can give the model the whole codebase of VLC and say, ‘I’m porting this to a new operating system,’” Kempf said. “It is useful for senior people to write new code, but it’s difficult to manage for people who don’t know what they’re doing.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-competing-priorities"&gt;Competing priorities&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The bigger problem for open source projects is a difference in priorities. Companies like Meta value new code and products, while open source software work focuses more on stability.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The problem is different from large companies to open source projects,” Kempf commented. “They get promoted for writing code, not maintaining it.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI coding tools are also arriving at a moment when software, in general, is particularly fragmented. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Open&amp;nbsp;source investor&amp;nbsp;Konstantin&amp;nbsp;Vinogradov says AI tools are running into a long-standing trend in open source engineering.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“On the one hand, we have exponentially growing code base with exponentially growing number of interdependences, And on the other hand, we have number of active maintainers, which is maybe slowly growing, but definitely not keeping up,” Vinogradov said. “With AI, both parts of this equation accelerated.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s a new way of thinking about AI’s impact on software engineering — one with alarming implications for the industry at large. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If you see engineering as the process of producing working software, AI coding makes it easier than ever. But if engineering is really the process of managing software complexity, AI coding tools could make it harder. At the very least, it will take a lot of active planning and work to keep the sprawling complexity in check.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For Vinogradov, the result is a familiar situation for open source projects: a lot of work to do, and not enough good engineers to do it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI does not increase the number of active, skilled maintainers,” he remarked. “It empowers the good ones, but all the fundamental problems just remain.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/10/GettyImages-1443890653.jpg?resize=1200,747" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;A world that runs on increasingly powerful AI coding tools is one where software creation is cheap — or so the thinking goes — leaving little room for traditional software companies. As one analyst report put it, “vibe coding will allow startups to replicate the features of complex SaaS platforms.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cue the hand-wringing and declarations that software companies are doomed. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Open source software projects that use agents to paper over long-standing resource constraints should logically be among the first to benefit from the era of cheap code. But that equation just doesn’t quite stick. In practice, the impact of AI coding tools on open source software has been far more mixed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI coding tools have caused as many problems as they have solved, according to industry experts. The easy-to-use and accessible nature of AI coding tools has enabled a flood of bad code that threatens to overwhelm projects. Building new features is easier than ever, but maintaining them is just as hard and threatens to further fragment software ecosystems. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The result is a more complicated story than simple software abundance. Perhaps the predicted, imminent death of the software engineer in this new AI era is premature.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-quality-versus-quantity"&gt;Quality versus quantity&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Across the board, projects with open codebases are noticing a decline in the average quality of submissions, likely a result of AI tools lowering barriers to entry. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“For people who are junior to the VLC codebase, the quality of the merge requests we see is abysmal,” Jean-Baptiste Kempf, the CEO of the VideoLAN Organization that oversees VLC, said in a recent interview.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Kempf is still optimistic about AI coding tools overall but says they’re best “for experienced developers.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There have been similar problems for Blender, a 3D modeling tool that has been maintained as open source since 2002. Blender Foundation CEO Francesco Siddi said LLM-assisted contributions typically “wasted reviewers’ time and affected their motivation.” Blender is still developing an official policy for AI coding tools, but Siddi said they are “neither mandated nor recommended for contributors or core developers.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The flood of merge requests has gotten so bad that open source developers are building new tools to manage it.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Earlier this month, developer Mitchell Hashimoto launched a system that would limit GitHub contributions to “vouched” users, effectively closing the open-door policy for open source software. As Hashimoto put it in the announcement, “AI eliminated the natural barrier to entry that let OSS projects trust by default.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The same effect has emerged in bug bounty programs, which give outside researchers an open door to report security vulnerabilities. The open source data transfer program cURL recently halted its bug bounty program after being overwhelmed by what creator Daniel Stenberg described as “AI slop.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“In the old days, someone actually invested a lot of time [in] the security report,” Stenberg said at a recent conference. “There was a built-in friction, but now there’s no effort at all in doing this. The floodgates are open.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s particularly frustrating because many open source projects are also seeing the benefits of AI coding tools. Kempf says it’s made building new modules for VLC far easier, provided there’s an experienced developer at the helm.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You can give the model the whole codebase of VLC and say, ‘I’m porting this to a new operating system,’” Kempf said. “It is useful for senior people to write new code, but it’s difficult to manage for people who don’t know what they’re doing.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-competing-priorities"&gt;Competing priorities&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The bigger problem for open source projects is a difference in priorities. Companies like Meta value new code and products, while open source software work focuses more on stability.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The problem is different from large companies to open source projects,” Kempf commented. “They get promoted for writing code, not maintaining it.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI coding tools are also arriving at a moment when software, in general, is particularly fragmented. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Open&amp;nbsp;source investor&amp;nbsp;Konstantin&amp;nbsp;Vinogradov says AI tools are running into a long-standing trend in open source engineering.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“On the one hand, we have exponentially growing code base with exponentially growing number of interdependences, And on the other hand, we have number of active maintainers, which is maybe slowly growing, but definitely not keeping up,” Vinogradov said. “With AI, both parts of this equation accelerated.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s a new way of thinking about AI’s impact on software engineering — one with alarming implications for the industry at large. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If you see engineering as the process of producing working software, AI coding makes it easier than ever. But if engineering is really the process of managing software complexity, AI coding tools could make it harder. At the very least, it will take a lot of active planning and work to keep the sprawling complexity in check.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For Vinogradov, the result is a familiar situation for open source projects: a lot of work to do, and not enough good engineers to do it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI does not increase the number of active, skilled maintainers,” he remarked. “It empowers the good ones, but all the fundamental problems just remain.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/19/for-open-source-programs-ai-coding-tools-are-a-mixed-blessing/</guid><pubDate>Thu, 19 Feb 2026 14:00:00 +0000</pubDate></item><item><title>[NEW] All About the Games: Play Over 4,500 Titles With GeForce NOW (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/geforce-now-thursday-battlefield-season-2/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;The GeForce NOW anniversary celebration keeps on rolling, and this week is all about the games that make it possible. With more than 4,500 titles supported in the cloud — plus 12 new games this week — there’s always something new to stream, share and discover.&lt;/p&gt;
&lt;p&gt;The #6YearsofGFN fun continues with a community giveaway hosted on the GeForce NOW Reddit. Share in-game screenshots and memes to celebrate the anniversary for a chance to win prizes such as an Amazon Fire TV Stick 4K, a Thrustmaster HOTAS ONE flight stick and more&amp;nbsp; — through Friday, Feb. 20.&lt;/p&gt;
&lt;p&gt;Gamers can also join the GeForce NOW community Discord to join in on more celebrations and events.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;A Library Built for Every PC Gamer&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;GeForce NOW features an ever-growing library of over 4,500 titles that are ready to stream in seconds. From cozy indies and competitive shooters to sprawling role-playing games and strategy epics, the collection has something for everyone.&lt;/p&gt;
&lt;p&gt;The GeForce NOW library spans popular stores like Steam, Xbox — including supported PC Game Pass titles — Epic Games Store, Ubisoft Connect and GOG.com, bringing together free-to-play hits and paid blockbusters in one place. Install-to-Play further expands access by letting members install Steam games opted in for cloud gaming, doubling the number of titles that can be launched through the service.&lt;/p&gt;
&lt;p&gt;The GeForce NOW app has curated rows that highlight new releases, RTX-enhanced titles or popular free-to-play picks, while tags make deals and downloadable content easier to spot. Smart library syncing connects supported games directly into the cloud catalog, enabling instant access without downloads or hardware worries. Ultimate members get priority entry with powerful servers to jump into the action even faster.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Fight the Fog of War&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_90059"&gt;&lt;img alt="Battlefield 6 S2" class="size-large wp-image-90059" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/GFN_Thursday-Battlefield_6_S2-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-90059"&gt;&lt;em&gt;Every move matters.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;i&gt;Battlefield 6&lt;/i&gt; erupts into its second season, “Extreme Measures,” taking the fight to contaminated terrain and distorted frontlines. A massive new map, fresh arsenal and agile air support redefine large-scale warfare — pushing squads to adapt and survive across shifting contamination zones and fog-laced choke points.&lt;/p&gt;
&lt;p&gt;Drop into “Contaminated,” a sprawling German mountainside airbase where the psychoactive VL‑7 smoke twists visibility, strategy and players’ senses. Mask up and press through as helicopters sweep low over objectives for high-risk insertions and surgical strikes. Dynamic cover and ever‑evolving hazards keep combat unpredictable, turning every push into a brutal test of precision and squad grit.&lt;/p&gt;
&lt;p&gt;On GeForce NOW, the battle starts instantly — no waiting for patches or worrying about download space. Jump straight into the latest content, fully loaded and always in sync, for nonstop action anywhere.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Game On!&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_90062"&gt;&lt;img alt="Styx Blades of Greed on GeForce NOW" class="size-large wp-image-90062" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/GFN_Thursday-Styx_Blade_of_Green-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-90062"&gt;&lt;em&gt;Heist now, sneak later.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;i&gt;Styx: Blades of Greed&lt;/i&gt; from publisher Nacon lands with a sharp tongue and an even sharper blade. Styx is back to doing what he does best: slipping through shadows, looting anything that isn’t nailed down and talking trash the whole way through. Tight stealth, devious tools and a world powered by precious Quartz make every heist feel like a risky, rewarding score — perfect for anyone who prefers a dagger in the dark over a sword in the spotlight.&lt;/p&gt;
&lt;p&gt;In addition, members can look for the following:&lt;i&gt;&lt;/i&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;Norse: Oath of Blood&lt;/i&gt; (New release on Steam, Feb. 17)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Diablo &lt;/i&gt;(New release on Ubisoft Connect, Feb. 18)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Diablo + Hellfire Expansion&amp;nbsp; &lt;/i&gt;(New release on Ubisoft Connect, Feb. 18)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Star Trek: Voyager – Across the Unknown &lt;/i&gt;(New release on Steam, Feb. 18, GeForce RTX 5080-ready)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;STALCRAFT: X &lt;/i&gt;(New release on Epic Games Store, Free Feb. 19)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Styx: Blades of Greed &lt;/i&gt;(New release on Steam, Feb. 19, GeForce RTX 5080-ready)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Ys X: Proud Nordics &lt;/i&gt;(New release on Steam, Feb. 20)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;KILLER INN &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Trine Enchanted Edition &lt;/i&gt;(Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Trine 2: Complete Story &lt;/i&gt;(Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Trine 3: The Artifacts of Power&lt;/i&gt; (Steam and Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Trine 4: The Nightmare Prince&lt;/i&gt; (Epic Games Store)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What are you planning to play this weekend? Let us know on X or in the comments below.&lt;/p&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p dir="ltr" lang="en"&gt;Happy 6th Anniversary to @NVIDIAGFN 🎉&lt;/p&gt;
&lt;p&gt;As an official NVIDIA GeForce NOW Ambassador, I’m hosting the @DeadbyDaylight block during their Anniversary Game Night + Giveaway.&lt;/p&gt;
&lt;p&gt;🗓️ February 19&lt;br /&gt;⏰ Event starts @ 10AM PST&lt;br /&gt;🔥 Dead by Daylight hosted by me at @ 1PM PST&lt;/p&gt;
&lt;p&gt;Massive prizes.… pic.twitter.com/TFtHvFWAZk&lt;/p&gt;
&lt;p&gt;— ✨🦋EloraBliss ✝️🐟 (@EloraBliss) February 18, 2026&lt;/p&gt;&lt;/blockquote&gt;


		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;The GeForce NOW anniversary celebration keeps on rolling, and this week is all about the games that make it possible. With more than 4,500 titles supported in the cloud — plus 12 new games this week — there’s always something new to stream, share and discover.&lt;/p&gt;
&lt;p&gt;The #6YearsofGFN fun continues with a community giveaway hosted on the GeForce NOW Reddit. Share in-game screenshots and memes to celebrate the anniversary for a chance to win prizes such as an Amazon Fire TV Stick 4K, a Thrustmaster HOTAS ONE flight stick and more&amp;nbsp; — through Friday, Feb. 20.&lt;/p&gt;
&lt;p&gt;Gamers can also join the GeForce NOW community Discord to join in on more celebrations and events.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;A Library Built for Every PC Gamer&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;GeForce NOW features an ever-growing library of over 4,500 titles that are ready to stream in seconds. From cozy indies and competitive shooters to sprawling role-playing games and strategy epics, the collection has something for everyone.&lt;/p&gt;
&lt;p&gt;The GeForce NOW library spans popular stores like Steam, Xbox — including supported PC Game Pass titles — Epic Games Store, Ubisoft Connect and GOG.com, bringing together free-to-play hits and paid blockbusters in one place. Install-to-Play further expands access by letting members install Steam games opted in for cloud gaming, doubling the number of titles that can be launched through the service.&lt;/p&gt;
&lt;p&gt;The GeForce NOW app has curated rows that highlight new releases, RTX-enhanced titles or popular free-to-play picks, while tags make deals and downloadable content easier to spot. Smart library syncing connects supported games directly into the cloud catalog, enabling instant access without downloads or hardware worries. Ultimate members get priority entry with powerful servers to jump into the action even faster.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Fight the Fog of War&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_90059"&gt;&lt;img alt="Battlefield 6 S2" class="size-large wp-image-90059" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/GFN_Thursday-Battlefield_6_S2-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-90059"&gt;&lt;em&gt;Every move matters.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;i&gt;Battlefield 6&lt;/i&gt; erupts into its second season, “Extreme Measures,” taking the fight to contaminated terrain and distorted frontlines. A massive new map, fresh arsenal and agile air support redefine large-scale warfare — pushing squads to adapt and survive across shifting contamination zones and fog-laced choke points.&lt;/p&gt;
&lt;p&gt;Drop into “Contaminated,” a sprawling German mountainside airbase where the psychoactive VL‑7 smoke twists visibility, strategy and players’ senses. Mask up and press through as helicopters sweep low over objectives for high-risk insertions and surgical strikes. Dynamic cover and ever‑evolving hazards keep combat unpredictable, turning every push into a brutal test of precision and squad grit.&lt;/p&gt;
&lt;p&gt;On GeForce NOW, the battle starts instantly — no waiting for patches or worrying about download space. Jump straight into the latest content, fully loaded and always in sync, for nonstop action anywhere.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Game On!&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_90062"&gt;&lt;img alt="Styx Blades of Greed on GeForce NOW" class="size-large wp-image-90062" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/GFN_Thursday-Styx_Blade_of_Green-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-90062"&gt;&lt;em&gt;Heist now, sneak later.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;i&gt;Styx: Blades of Greed&lt;/i&gt; from publisher Nacon lands with a sharp tongue and an even sharper blade. Styx is back to doing what he does best: slipping through shadows, looting anything that isn’t nailed down and talking trash the whole way through. Tight stealth, devious tools and a world powered by precious Quartz make every heist feel like a risky, rewarding score — perfect for anyone who prefers a dagger in the dark over a sword in the spotlight.&lt;/p&gt;
&lt;p&gt;In addition, members can look for the following:&lt;i&gt;&lt;/i&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;Norse: Oath of Blood&lt;/i&gt; (New release on Steam, Feb. 17)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Diablo &lt;/i&gt;(New release on Ubisoft Connect, Feb. 18)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Diablo + Hellfire Expansion&amp;nbsp; &lt;/i&gt;(New release on Ubisoft Connect, Feb. 18)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Star Trek: Voyager – Across the Unknown &lt;/i&gt;(New release on Steam, Feb. 18, GeForce RTX 5080-ready)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;STALCRAFT: X &lt;/i&gt;(New release on Epic Games Store, Free Feb. 19)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Styx: Blades of Greed &lt;/i&gt;(New release on Steam, Feb. 19, GeForce RTX 5080-ready)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Ys X: Proud Nordics &lt;/i&gt;(New release on Steam, Feb. 20)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;KILLER INN &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Trine Enchanted Edition &lt;/i&gt;(Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Trine 2: Complete Story &lt;/i&gt;(Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Trine 3: The Artifacts of Power&lt;/i&gt; (Steam and Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Trine 4: The Nightmare Prince&lt;/i&gt; (Epic Games Store)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What are you planning to play this weekend? Let us know on X or in the comments below.&lt;/p&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p dir="ltr" lang="en"&gt;Happy 6th Anniversary to @NVIDIAGFN 🎉&lt;/p&gt;
&lt;p&gt;As an official NVIDIA GeForce NOW Ambassador, I’m hosting the @DeadbyDaylight block during their Anniversary Game Night + Giveaway.&lt;/p&gt;
&lt;p&gt;🗓️ February 19&lt;br /&gt;⏰ Event starts @ 10AM PST&lt;br /&gt;🔥 Dead by Daylight hosted by me at @ 1PM PST&lt;/p&gt;
&lt;p&gt;Massive prizes.… pic.twitter.com/TFtHvFWAZk&lt;/p&gt;
&lt;p&gt;— ✨🦋EloraBliss ✝️🐟 (@EloraBliss) February 18, 2026&lt;/p&gt;&lt;/blockquote&gt;


		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/geforce-now-thursday-battlefield-season-2/</guid><pubDate>Thu, 19 Feb 2026 14:00:35 +0000</pubDate></item><item><title>[NEW] Survey Reveals AI Advances in Telecom: Networks and Automation in Driver’s Seat as Return on Investment Climbs (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/ai-in-telco-survey-2026/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;AI is accelerating the telecommunications industry’s transformation, becoming the backbone of autonomous networks and AI-native wireless infrastructure. At the same time, the technology is unlocking new business and revenue opportunities, as telecom operators accelerate AI adoption across consumers, enterprises and nations.&lt;/p&gt;
&lt;p&gt;NVIDIA’s fourth annual “State of AI in Telecommunications” survey report unpacks these trends, underscoring strong AI adoption, impact and investment in the industry.&lt;/p&gt;
&lt;p&gt;Highlights from the report include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;90% said AI is helping increase annual revenue and drive down costs.&lt;/li&gt;
&lt;li&gt;77% said they expect to see AI-native networks launch before the deployment of 6G.&lt;/li&gt;
&lt;li&gt;65% of telecom operators said network automation is being driven by AI.&lt;/li&gt;
&lt;li&gt;60% said their organization is using or assessing generative AI, up from 49% in 2024.&lt;/li&gt;
&lt;li&gt;89% said open source models and software are important to their AI strategy.&lt;/li&gt;
&lt;li&gt;89% of telcos plan to boost AI spending in 2026, up from 65% a year ago.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;“There is a seismic shift underway in the telecom industry driven by AI,” said Sebastian Barros, managing director of Circles, a Singapore-based telecommunications provider. “Communication service providers are converging on a new realization. Their role in society extends beyond moving bits across networks toward moving intelligence across local and regulated infrastructure. That transition defines the move from telco to ‘AICO’ — AI infrastructure companies operating at network proximity, not application vendors riding on top.”&lt;/p&gt;
&lt;p&gt;Here are some more key findings from the report.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Tangible Revenue Impact and Return on Investment&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;The telecommunications industry is seeing a definitive revenue impact from the use of AI. Overall, about nine out of 10 respondents said AI is helping to increase revenue and reduce costs. Telecommunications operators, which represent about a quarter of the 1,000 responses in the survey, are also seeing the benefit, with 90% saying AI has had a positive impact on revenue and costs.&lt;/p&gt;
&lt;p&gt;The top AI use cases cited for return on investment (ROI) were AI for autonomous networks (50%), followed by improved customer service (41%) and internal process optimization (33%).&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-medium wp-image-90043" height="243" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/top-roi-use-cases-state-of-ai-telecom-2026-960x243.jpg" width="960" /&gt;&lt;/p&gt;
&lt;p&gt;“Autonomous networks deliver immediate ROI by eliminating human effort from repetitive, reactive workflows,” said Barros. “The fastest impact areas are energy management, fault prediction, configuration drift correction and capacity planning.”&lt;/p&gt;
&lt;p&gt;This strong impact on revenue and ROI is leading telecommunications companies to increase their AI budgets in 2026. Overall, 89% of respondents said their AI budget will increase in the next 12 months, up from 65% in last year’s survey, with 35% saying their budgets would increase more than 10% from this year.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Focus on AI-Native Networks and Autonomous Operations&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Network automation has overtaken customer experience as the leading use case for investment, deployment and ROI impact. This signals a bold step toward autonomous networks — AI-driven, self-managing systems that can self-configure, self-heal and self-optimize with minimal human intervention. Eighty-eight percent of organizations report being between levels 1-3 of autonomy, as defined by the TM Forum, and the use of generative AI and agentic AI is expected to accelerate the shift to level 5 autonomous networks.&lt;/p&gt;
&lt;p&gt;“Autonomous networks are delivering return on investment faster than any other AI use case because they directly reduce outages, energy consumption and manual intervention,” said Chetan Sharma, CEO of Chetan Sharma Consulting. “Agentic AI accelerates this by coordinating decisions across domains in real time.”&lt;/p&gt;
&lt;p&gt;A surge in edge computing investment is reshaping telecom network architectures, bringing AI inferencing closer to users through a distributed computing infrastructure. Telcos are stepping up investments in AI-native RAN and 6G — signaling a major industry intercept ahead of the traditional 6G deployment cycle, with 77% of respondents anticipating a much faster time to deployment of this new AI-native wireless network architecture.&lt;/p&gt;
&lt;p&gt;The top drivers of investment are using AI to enhance spectral efficiency, improving the performance of the radio access network supporting edge AI applications and accelerating the research and development of 6G.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;A Universal Boost in Productivity&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;AI in telecommunications is advancing autonomous networks and business opportunities as well as improving internal operations. Nearly every respondent in the survey said AI is boosting employee productivity, with 26% citing major to significant improvements to their ability to complete more tasks with higher quality in less time.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-medium wp-image-90047" height="284" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/productivity-state-of-ai-telecom-2026-960x284.jpg" width="960" /&gt;&lt;/p&gt;
&lt;p&gt;The productivity gains are coming from generative and agentic AI solutions deployed across operations, from the back office to networks.&lt;/p&gt;
&lt;p&gt;“Generative AI delivered fast productivity gains, but agentic AI is where telecoms begin to see structural ROI,” Sharma said. “Autonomous agents can act across networks, IT and customer journeys, turning insights into decisions without human delay.”&lt;/p&gt;
&lt;p&gt;Download the “State of AI in Telecommunications 2026 Trends” report for in-depth results and insights.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Explore &lt;/i&gt;&lt;i&gt;NVIDIA AI technologies for telecommunications&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;AI is accelerating the telecommunications industry’s transformation, becoming the backbone of autonomous networks and AI-native wireless infrastructure. At the same time, the technology is unlocking new business and revenue opportunities, as telecom operators accelerate AI adoption across consumers, enterprises and nations.&lt;/p&gt;
&lt;p&gt;NVIDIA’s fourth annual “State of AI in Telecommunications” survey report unpacks these trends, underscoring strong AI adoption, impact and investment in the industry.&lt;/p&gt;
&lt;p&gt;Highlights from the report include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;90% said AI is helping increase annual revenue and drive down costs.&lt;/li&gt;
&lt;li&gt;77% said they expect to see AI-native networks launch before the deployment of 6G.&lt;/li&gt;
&lt;li&gt;65% of telecom operators said network automation is being driven by AI.&lt;/li&gt;
&lt;li&gt;60% said their organization is using or assessing generative AI, up from 49% in 2024.&lt;/li&gt;
&lt;li&gt;89% said open source models and software are important to their AI strategy.&lt;/li&gt;
&lt;li&gt;89% of telcos plan to boost AI spending in 2026, up from 65% a year ago.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;“There is a seismic shift underway in the telecom industry driven by AI,” said Sebastian Barros, managing director of Circles, a Singapore-based telecommunications provider. “Communication service providers are converging on a new realization. Their role in society extends beyond moving bits across networks toward moving intelligence across local and regulated infrastructure. That transition defines the move from telco to ‘AICO’ — AI infrastructure companies operating at network proximity, not application vendors riding on top.”&lt;/p&gt;
&lt;p&gt;Here are some more key findings from the report.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Tangible Revenue Impact and Return on Investment&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;The telecommunications industry is seeing a definitive revenue impact from the use of AI. Overall, about nine out of 10 respondents said AI is helping to increase revenue and reduce costs. Telecommunications operators, which represent about a quarter of the 1,000 responses in the survey, are also seeing the benefit, with 90% saying AI has had a positive impact on revenue and costs.&lt;/p&gt;
&lt;p&gt;The top AI use cases cited for return on investment (ROI) were AI for autonomous networks (50%), followed by improved customer service (41%) and internal process optimization (33%).&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-medium wp-image-90043" height="243" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/top-roi-use-cases-state-of-ai-telecom-2026-960x243.jpg" width="960" /&gt;&lt;/p&gt;
&lt;p&gt;“Autonomous networks deliver immediate ROI by eliminating human effort from repetitive, reactive workflows,” said Barros. “The fastest impact areas are energy management, fault prediction, configuration drift correction and capacity planning.”&lt;/p&gt;
&lt;p&gt;This strong impact on revenue and ROI is leading telecommunications companies to increase their AI budgets in 2026. Overall, 89% of respondents said their AI budget will increase in the next 12 months, up from 65% in last year’s survey, with 35% saying their budgets would increase more than 10% from this year.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Focus on AI-Native Networks and Autonomous Operations&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Network automation has overtaken customer experience as the leading use case for investment, deployment and ROI impact. This signals a bold step toward autonomous networks — AI-driven, self-managing systems that can self-configure, self-heal and self-optimize with minimal human intervention. Eighty-eight percent of organizations report being between levels 1-3 of autonomy, as defined by the TM Forum, and the use of generative AI and agentic AI is expected to accelerate the shift to level 5 autonomous networks.&lt;/p&gt;
&lt;p&gt;“Autonomous networks are delivering return on investment faster than any other AI use case because they directly reduce outages, energy consumption and manual intervention,” said Chetan Sharma, CEO of Chetan Sharma Consulting. “Agentic AI accelerates this by coordinating decisions across domains in real time.”&lt;/p&gt;
&lt;p&gt;A surge in edge computing investment is reshaping telecom network architectures, bringing AI inferencing closer to users through a distributed computing infrastructure. Telcos are stepping up investments in AI-native RAN and 6G — signaling a major industry intercept ahead of the traditional 6G deployment cycle, with 77% of respondents anticipating a much faster time to deployment of this new AI-native wireless network architecture.&lt;/p&gt;
&lt;p&gt;The top drivers of investment are using AI to enhance spectral efficiency, improving the performance of the radio access network supporting edge AI applications and accelerating the research and development of 6G.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;A Universal Boost in Productivity&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;AI in telecommunications is advancing autonomous networks and business opportunities as well as improving internal operations. Nearly every respondent in the survey said AI is boosting employee productivity, with 26% citing major to significant improvements to their ability to complete more tasks with higher quality in less time.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-medium wp-image-90047" height="284" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/productivity-state-of-ai-telecom-2026-960x284.jpg" width="960" /&gt;&lt;/p&gt;
&lt;p&gt;The productivity gains are coming from generative and agentic AI solutions deployed across operations, from the back office to networks.&lt;/p&gt;
&lt;p&gt;“Generative AI delivered fast productivity gains, but agentic AI is where telecoms begin to see structural ROI,” Sharma said. “Autonomous agents can act across networks, IT and customer journeys, turning insights into decisions without human delay.”&lt;/p&gt;
&lt;p&gt;Download the “State of AI in Telecommunications 2026 Trends” report for in-depth results and insights.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Explore &lt;/i&gt;&lt;i&gt;NVIDIA AI technologies for telecommunications&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/ai-in-telco-survey-2026/</guid><pubDate>Thu, 19 Feb 2026 14:00:45 +0000</pubDate></item><item><title>[NEW] OpenClaw security fears lead Meta, other AI firms to restrict its use (AI - Ars Technica)</title><link>https://arstechnica.com/ai/2026/02/openclaw-security-fears-lead-meta-other-ai-firms-to-restrict-its-use/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The viral agentic AI tool is known for being highly capable but also wildly unpredictable.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A blue crayfish on a countertop" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/bluecrayfish-640x427.jpg" width="640" /&gt;
                  &lt;img alt="A blue crayfish on a countertop" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/bluecrayfish-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Carmen Vlasceanu via Getty

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Last month, Jason Grad issued a late-night warning to the 20 employees at his tech startup. “You’ve likely seen Clawdbot trending on X/LinkedIn. While cool, it is currently unvetted and high-risk for our environment,” he wrote in a Slack message with a red siren emoji. “Please keep Clawdbot off all company hardware and away from work-linked accounts.”&lt;/p&gt;
&lt;p&gt;Grad isn’t the only tech executive who has raised concerns to staff about the experimental agentic AI tool, which was briefly known as MoltBot and is now named OpenClaw. A Meta executive says he recently told his team to keep OpenClaw off their regular work laptops or risk losing their jobs. The executive told reporters he believes the software is unpredictable and could lead to a privacy breach if used in otherwise secure environments. He spoke on the condition of anonymity to speak frankly.&lt;/p&gt;
&lt;p&gt;Peter Steinberger, OpenClaw’s solo founder, launched it as a free, open source tool last November. But its popularity surged last month as other coders contributed features and began sharing their experiences using it on social media. Last week, Steinberger joined ChatGPT developer OpenAI, which says it will keep OpenClaw open source and support it through a foundation.&lt;/p&gt;
&lt;p&gt;OpenClaw requires basic software engineering knowledge to set up. After that, it only needs limited direction to take control of a user’s computer and interact with other apps to assist with tasks such as organizing files, conducting web research, and shopping online.&lt;/p&gt;
&lt;p&gt;Some cybersecurity professionals have publicly urged companies to take measures to strictly control how their workforces use OpenClaw. And the recent bans show how companies are moving quickly to ensure security is prioritized ahead of their desire to experiment with emerging AI technologies.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“Our policy is, ‘mitigate first, investigate second’ when we come across anything that could be harmful to our company, users, or clients,” says Grad, who is cofounder and CEO of Massive, which provides Internet proxy tools to millions of users and businesses. His warning to staff went out on January 26, before any of his employees had installed OpenClaw, he says.&lt;/p&gt;
&lt;p&gt;At another tech company, Valere, which works on software for organizations including Johns Hopkins University, an employee posted about OpenClaw on January 29 on an internal Slack channel for sharing new tech to potentially try out. The company’s president quickly responded that use of OpenClaw was strictly banned, Valere CEO Guy Pistone tells WIRED.&lt;/p&gt;
&lt;p&gt;“If it got access to one of our developer’s machines, it could get access to our cloud services and our clients’ sensitive information, including credit card information and GitHub codebases,” Pistone says. “It’s pretty good at cleaning up some of its actions, which also scares me.”&lt;/p&gt;
&lt;p&gt;A week later, Pistone did allow Valere’s research team to run OpenClaw on an employee’s old computer. The goal was to identify flaws in the software and potential fixes to make it more secure. The research team later advised limiting who can give orders to OpenClaw and exposing it to the Internet only with a password in place for its control panel to prevent unwanted access.&lt;/p&gt;
&lt;p&gt;In a report shared with WIRED, the Valere researchers added that users have to “accept that the bot can be tricked.” For instance, if OpenClaw is set up to summarize a user’s email, a hacker could send a malicious email to the person instructing the AI to share copies of files on the person’s computer.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But Pistone is confident that safeguards can be put in place to make OpenClaw more secure. He has given a team at Valere 60 days to investigate. “If we don’t think we can do it in a reasonable time, we’ll forgo it,” he says. “Whoever figures out how to make it secure for businesses is definitely going to have a winner.”&lt;/p&gt;
&lt;p&gt;Some companies concerned about OpenClaw are choosing to trust the cybersecurity protections they already have in place rather than introduce a formal or one-off ban. A CEO of a major software company says only about 15 programs are allowed on corporate devices. Anything else should be automatically blocked, says the executive, who spoke on the condition of anonymity to discuss internal security protocols. He says that while OpenClaw is innovative, he doubts that it will find a way to operate on the company’s network undetected.&lt;/p&gt;
&lt;p&gt;Jan-Joost den Brinker, chief technology officer at Prague-based compliance software developer Dubrink, says he bought a dedicated machine not connected to company systems or accounts that employees can use to play around with OpenClaw. “We aren’t solving business problems with OpenClaw at the moment,” he says.&lt;/p&gt;
&lt;p&gt;Massive, the web proxy company, is cautiously exploring OpenClaw’s commercial possibilities. Grad says it tested the AI tool on isolated machines in the cloud and then, last week, released ClawPod, a way for OpenClaw agents to use Massive’s services to browse the web. While OpenClaw is still not welcome on Massive’s systems without protections in place, the allure of the new technology and its moneymaking potential was too great to ignore. OpenClaw “might be a glimpse into the future. That’s why we’re building for it,” Grad says.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This story originally appeared on wired.com.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The viral agentic AI tool is known for being highly capable but also wildly unpredictable.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A blue crayfish on a countertop" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/bluecrayfish-640x427.jpg" width="640" /&gt;
                  &lt;img alt="A blue crayfish on a countertop" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/bluecrayfish-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Carmen Vlasceanu via Getty

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Last month, Jason Grad issued a late-night warning to the 20 employees at his tech startup. “You’ve likely seen Clawdbot trending on X/LinkedIn. While cool, it is currently unvetted and high-risk for our environment,” he wrote in a Slack message with a red siren emoji. “Please keep Clawdbot off all company hardware and away from work-linked accounts.”&lt;/p&gt;
&lt;p&gt;Grad isn’t the only tech executive who has raised concerns to staff about the experimental agentic AI tool, which was briefly known as MoltBot and is now named OpenClaw. A Meta executive says he recently told his team to keep OpenClaw off their regular work laptops or risk losing their jobs. The executive told reporters he believes the software is unpredictable and could lead to a privacy breach if used in otherwise secure environments. He spoke on the condition of anonymity to speak frankly.&lt;/p&gt;
&lt;p&gt;Peter Steinberger, OpenClaw’s solo founder, launched it as a free, open source tool last November. But its popularity surged last month as other coders contributed features and began sharing their experiences using it on social media. Last week, Steinberger joined ChatGPT developer OpenAI, which says it will keep OpenClaw open source and support it through a foundation.&lt;/p&gt;
&lt;p&gt;OpenClaw requires basic software engineering knowledge to set up. After that, it only needs limited direction to take control of a user’s computer and interact with other apps to assist with tasks such as organizing files, conducting web research, and shopping online.&lt;/p&gt;
&lt;p&gt;Some cybersecurity professionals have publicly urged companies to take measures to strictly control how their workforces use OpenClaw. And the recent bans show how companies are moving quickly to ensure security is prioritized ahead of their desire to experiment with emerging AI technologies.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“Our policy is, ‘mitigate first, investigate second’ when we come across anything that could be harmful to our company, users, or clients,” says Grad, who is cofounder and CEO of Massive, which provides Internet proxy tools to millions of users and businesses. His warning to staff went out on January 26, before any of his employees had installed OpenClaw, he says.&lt;/p&gt;
&lt;p&gt;At another tech company, Valere, which works on software for organizations including Johns Hopkins University, an employee posted about OpenClaw on January 29 on an internal Slack channel for sharing new tech to potentially try out. The company’s president quickly responded that use of OpenClaw was strictly banned, Valere CEO Guy Pistone tells WIRED.&lt;/p&gt;
&lt;p&gt;“If it got access to one of our developer’s machines, it could get access to our cloud services and our clients’ sensitive information, including credit card information and GitHub codebases,” Pistone says. “It’s pretty good at cleaning up some of its actions, which also scares me.”&lt;/p&gt;
&lt;p&gt;A week later, Pistone did allow Valere’s research team to run OpenClaw on an employee’s old computer. The goal was to identify flaws in the software and potential fixes to make it more secure. The research team later advised limiting who can give orders to OpenClaw and exposing it to the Internet only with a password in place for its control panel to prevent unwanted access.&lt;/p&gt;
&lt;p&gt;In a report shared with WIRED, the Valere researchers added that users have to “accept that the bot can be tricked.” For instance, if OpenClaw is set up to summarize a user’s email, a hacker could send a malicious email to the person instructing the AI to share copies of files on the person’s computer.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But Pistone is confident that safeguards can be put in place to make OpenClaw more secure. He has given a team at Valere 60 days to investigate. “If we don’t think we can do it in a reasonable time, we’ll forgo it,” he says. “Whoever figures out how to make it secure for businesses is definitely going to have a winner.”&lt;/p&gt;
&lt;p&gt;Some companies concerned about OpenClaw are choosing to trust the cybersecurity protections they already have in place rather than introduce a formal or one-off ban. A CEO of a major software company says only about 15 programs are allowed on corporate devices. Anything else should be automatically blocked, says the executive, who spoke on the condition of anonymity to discuss internal security protocols. He says that while OpenClaw is innovative, he doubts that it will find a way to operate on the company’s network undetected.&lt;/p&gt;
&lt;p&gt;Jan-Joost den Brinker, chief technology officer at Prague-based compliance software developer Dubrink, says he bought a dedicated machine not connected to company systems or accounts that employees can use to play around with OpenClaw. “We aren’t solving business problems with OpenClaw at the moment,” he says.&lt;/p&gt;
&lt;p&gt;Massive, the web proxy company, is cautiously exploring OpenClaw’s commercial possibilities. Grad says it tested the AI tool on isolated machines in the cloud and then, last week, released ClawPod, a way for OpenClaw agents to use Massive’s services to browse the web. While OpenClaw is still not welcome on Massive’s systems without protections in place, the allure of the new technology and its moneymaking potential was too great to ignore. OpenClaw “might be a glimpse into the future. That’s why we’re building for it,” Grad says.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This story originally appeared on wired.com.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2026/02/openclaw-security-fears-lead-meta-other-ai-firms-to-restrict-its-use/</guid><pubDate>Thu, 19 Feb 2026 14:11:55 +0000</pubDate></item><item><title>[NEW] Co-founders behind Reface and Prisma join hands to improve on-device model inference with Mirai (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/19/co-founders-behind-reface-and-prisma-join-hands-to-improve-on-device-model-inference-with-mirai/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Much of the conversation around AI today is focused on building cloud capacity and massive data centers to run models. Companies like Apple and Qualcomm are in the early stages of making on-device AI more useful. Amid all that, the 14-person technical team of London-based Mirai is working to improve how models run on phones and laptops.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mirai, which is backed by a $10 million seed round led by Uncork Capital, was founded by Dima Shvets and Alexey Moiseenkov last year. Both founders have experience in building scalable consumer apps. Shvets co-founded face-swapping app Reface, which was backed by a16z. Shvets later also became a scout for the venture firm. Moiseenkov was CEO and co-founder of the last decade’s viral AI filters app, Prisma.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As consumer developers, both had been thinking about AI and machine learning on devices even before generative AI became popular, Shvets said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When we met together in London, we started to chat about technology, and we realized that within the hype of GenAI and more AI adoption, everybody speaks about cloud, about servers, about AGI coming. But the missing piece is on-device [AI] for consumer hardware,” he told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Shvets and Moiseenkov wanted to use AI to create a pipeline that would allow them to enable complex tasks on the phone, which led them to start Mirai. When they asked others who developed consumer apps, they heard that many wanted better cost optimization and margin per token usage, too.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3094301" height="402" src="https://techcrunch.com/wp-content/uploads/2026/02/Mirai-cofounders1.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Co-founders Alexey Moiseenkov and Dima Shvets&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Mirai&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Today, Mirai is developing a framework for models so they can perform better on devices. The company has built an inference engine for Apple Silicon that optimizes on-device throughput. With its upcoming SDK, developers can integrate the runtime in their apps with only a few lines, the company says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“One of the visions why we started the company was that we wanted to give developers, like this Stripe-like, eight lines of code [integration] experience…you basically go to our platform, integrate the key, and start working with summarization, classification, or whatever your use case is,” Shvets said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup built this engine in Rust, which can bump up a model’s generation speed by up to 37%, they claim. The company said that, while tuning the model for a platform, it doesn’t tinker with model weights to ensure there is no loss in quality of the output.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mirai’s stack currently focuses on improving text and voice modalities on the platform, with plans to support vision in the future. The team has started to work with frontier model providers to tune their models for edge use and is in talks with different chipmakers. Later, it plans to bring its engine to Android, too. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, Mirai aims to release on-device benchmarks so model makers can test on-device performance. Shvets recognizes that not all AI work can be done on-device, though. To enable a mixed mode of operation, the team is building an orchestration layer to send requests that can’t be fulfilled on the device up to the cloud.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While the startup is not directly working with apps just yet, its engine could power on-device assistants, transcribers, translators, and chat apps, we’re told.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Andy McLoughlin, managing partner at Uncork Capital, noted that he invested in an edge machine learning company in the last decade. He said that the company was early and eventually sold its business to Spotify. In today’s world, the situation is different, he thinks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Given the cost of cloud inference, something has to change… For now, VCs are happy to continue funding the rocket ship companies, spending inordinate sums on cloud inference. But that won’t last  —  at some point, people will focus on the underlying economics of these businesses and realize that something has to change,” he said. “It feels like every model maker will want&amp;nbsp;to run part&amp;nbsp;of their inference workloads at the edge, and Mirai&amp;nbsp;feels very well-positioned to capture this demand.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mirai’s seed round also saw participation from individuals, including Dreamer CEO David Singleton, YC Partner Francois Chaubard, Snowflake co-founder Marcin Żukowski, ElevenLabs co-founder Mati Staniszewski, former Google AdSense product manager and Coinbase board member Gokul Rajaram, Groq investor Scooter Braun, Turing.com CTO Vijay Krishnan, Theory Forge Ventures’ Ben Parr and Matt Schlicht, and ex-Netflix technical leader Aditya Jami.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Much of the conversation around AI today is focused on building cloud capacity and massive data centers to run models. Companies like Apple and Qualcomm are in the early stages of making on-device AI more useful. Amid all that, the 14-person technical team of London-based Mirai is working to improve how models run on phones and laptops.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mirai, which is backed by a $10 million seed round led by Uncork Capital, was founded by Dima Shvets and Alexey Moiseenkov last year. Both founders have experience in building scalable consumer apps. Shvets co-founded face-swapping app Reface, which was backed by a16z. Shvets later also became a scout for the venture firm. Moiseenkov was CEO and co-founder of the last decade’s viral AI filters app, Prisma.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As consumer developers, both had been thinking about AI and machine learning on devices even before generative AI became popular, Shvets said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When we met together in London, we started to chat about technology, and we realized that within the hype of GenAI and more AI adoption, everybody speaks about cloud, about servers, about AGI coming. But the missing piece is on-device [AI] for consumer hardware,” he told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Shvets and Moiseenkov wanted to use AI to create a pipeline that would allow them to enable complex tasks on the phone, which led them to start Mirai. When they asked others who developed consumer apps, they heard that many wanted better cost optimization and margin per token usage, too.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3094301" height="402" src="https://techcrunch.com/wp-content/uploads/2026/02/Mirai-cofounders1.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Co-founders Alexey Moiseenkov and Dima Shvets&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Mirai&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Today, Mirai is developing a framework for models so they can perform better on devices. The company has built an inference engine for Apple Silicon that optimizes on-device throughput. With its upcoming SDK, developers can integrate the runtime in their apps with only a few lines, the company says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“One of the visions why we started the company was that we wanted to give developers, like this Stripe-like, eight lines of code [integration] experience…you basically go to our platform, integrate the key, and start working with summarization, classification, or whatever your use case is,” Shvets said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup built this engine in Rust, which can bump up a model’s generation speed by up to 37%, they claim. The company said that, while tuning the model for a platform, it doesn’t tinker with model weights to ensure there is no loss in quality of the output.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mirai’s stack currently focuses on improving text and voice modalities on the platform, with plans to support vision in the future. The team has started to work with frontier model providers to tune their models for edge use and is in talks with different chipmakers. Later, it plans to bring its engine to Android, too. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, Mirai aims to release on-device benchmarks so model makers can test on-device performance. Shvets recognizes that not all AI work can be done on-device, though. To enable a mixed mode of operation, the team is building an orchestration layer to send requests that can’t be fulfilled on the device up to the cloud.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While the startup is not directly working with apps just yet, its engine could power on-device assistants, transcribers, translators, and chat apps, we’re told.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Andy McLoughlin, managing partner at Uncork Capital, noted that he invested in an edge machine learning company in the last decade. He said that the company was early and eventually sold its business to Spotify. In today’s world, the situation is different, he thinks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Given the cost of cloud inference, something has to change… For now, VCs are happy to continue funding the rocket ship companies, spending inordinate sums on cloud inference. But that won’t last  —  at some point, people will focus on the underlying economics of these businesses and realize that something has to change,” he said. “It feels like every model maker will want&amp;nbsp;to run part&amp;nbsp;of their inference workloads at the edge, and Mirai&amp;nbsp;feels very well-positioned to capture this demand.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mirai’s seed round also saw participation from individuals, including Dreamer CEO David Singleton, YC Partner Francois Chaubard, Snowflake co-founder Marcin Żukowski, ElevenLabs co-founder Mati Staniszewski, former Google AdSense product manager and Coinbase board member Gokul Rajaram, Groq investor Scooter Braun, Turing.com CTO Vijay Krishnan, Theory Forge Ventures’ Ben Parr and Matt Schlicht, and ex-Netflix technical leader Aditya Jami.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/19/co-founders-behind-reface-and-prisma-join-hands-to-improve-on-device-model-inference-with-mirai/</guid><pubDate>Thu, 19 Feb 2026 14:43:58 +0000</pubDate></item><item><title>[NEW] OpenAI, Reliance partner to add AI search to JioHotstar (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/19/openai-reliance-partner-to-add-ai-search-to-jiohotstar/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/openai-india.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI is partnering with Reliance to add AI-powered conversational search to the Indian conglomerate’s streaming service JioHotstar. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The feature, which is powered by OpenAI’s API, will let users search for movies, shows, and live sports using text and voice prompts in multiple languages, and receive recommendations based on their preferences and history.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI has recently expanded its footprint in India, which is home to more than 100 million weekly ChatGPT users. The company plans to open offices in Mumbai and Bengaluru later this year, adding to its current office in New Delhi.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The partnership was announced at the ongoing India AI Impact Summit in New Delhi, where Sam Altman is appearing alongside industry leaders, including Anthropic’s Dario Amodei and Google’s Sundar Pichai.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The companies also plan to extend the partnership to surface JioHotstar recommendations directly within ChatGPT, allowing users who search for entertainment through ChatGPT to receive contextual suggestions and deep links into the platform’s catalogue. The move positions the integration as a two-way discovery layer rather than a standalone in-app feature.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The move comes as streaming and TV platforms increasingly experiment with conversational interfaces. Netflix said in May 2025 it was testing a new search experience using OpenAI’s ChatGPT to help viewers find content through natural language, while Google in November introduced Gemini-powered discovery features for its Google TV platform.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Fidji Simo, chief executive of applications at OpenAI, said the partnership is aimed at bringing more personalized AI experiences into entertainment and live sports, enabling viewers to move “from curiosity to context” through natural interactions.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Embedding AI into content discovery will help reshape how audiences find and engage with programming, said Uday Shankar, vice chairperson of JioStar.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The rollout will span both live and on-demand formats, the companies said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The JioHotstar partnership is part of OpenAI’s broader “OpenAI for India” push to deepen its presence in the South Asian nation through infrastructure, enterprise, and education partnerships. Other moves under the initiative include collaborations with the Tata Group on AI-ready data centers and enterprise deployments, as well as agreements with Indian companies such as Pine Labs, Eternal, and MakeMyTrip.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/openai-india.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI is partnering with Reliance to add AI-powered conversational search to the Indian conglomerate’s streaming service JioHotstar. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The feature, which is powered by OpenAI’s API, will let users search for movies, shows, and live sports using text and voice prompts in multiple languages, and receive recommendations based on their preferences and history.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI has recently expanded its footprint in India, which is home to more than 100 million weekly ChatGPT users. The company plans to open offices in Mumbai and Bengaluru later this year, adding to its current office in New Delhi.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The partnership was announced at the ongoing India AI Impact Summit in New Delhi, where Sam Altman is appearing alongside industry leaders, including Anthropic’s Dario Amodei and Google’s Sundar Pichai.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The companies also plan to extend the partnership to surface JioHotstar recommendations directly within ChatGPT, allowing users who search for entertainment through ChatGPT to receive contextual suggestions and deep links into the platform’s catalogue. The move positions the integration as a two-way discovery layer rather than a standalone in-app feature.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The move comes as streaming and TV platforms increasingly experiment with conversational interfaces. Netflix said in May 2025 it was testing a new search experience using OpenAI’s ChatGPT to help viewers find content through natural language, while Google in November introduced Gemini-powered discovery features for its Google TV platform.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Fidji Simo, chief executive of applications at OpenAI, said the partnership is aimed at bringing more personalized AI experiences into entertainment and live sports, enabling viewers to move “from curiosity to context” through natural interactions.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Embedding AI into content discovery will help reshape how audiences find and engage with programming, said Uday Shankar, vice chairperson of JioStar.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The rollout will span both live and on-demand formats, the companies said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The JioHotstar partnership is part of OpenAI’s broader “OpenAI for India” push to deepen its presence in the South Asian nation through infrastructure, enterprise, and education partnerships. Other moves under the initiative include collaborations with the Tata Group on AI-ready data centers and enterprise deployments, as well as agreements with Indian companies such as Pine Labs, Eternal, and MakeMyTrip.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/19/openai-reliance-partner-to-add-ai-search-to-jiohotstar/</guid><pubDate>Thu, 19 Feb 2026 14:45:29 +0000</pubDate></item><item><title>[NEW] Reload wants to give your AI agents a shared memory (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/19/reload-an-ai-employee-agent-management-platform-raises-2-275m-and-launches-an-ai-employee/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/Reload-Co-Founders-Headshot.png?w=1056" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;There came a point when Newton Asare realized AI agents weren’t just tools anymore. “They were operating more like teammates,” he told TechCrunch.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The realization crystallized when Asare and Kiran Das, both serial founders, noticed they were using AI agents to perform tasks they usually would have done themselves. Asare said he came to believe that the future lay in people managing AI employees.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&amp;nbsp;“And if that’s true, we’ll need a real system to manage them, with structure around onboarding, coordination, and oversight for digital workers,” he added.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last year, the duo launched Reload, an AI workforce management platform. On Thursday, the company announced its first AI product, Epic, alongside a $2.275 million round led by Anthemis, with participation from Zeal Capital Partners, Plug and Play, Cohen Circle, Blueprint, and Axiom.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Reload is a platform that lets organizations manage their AI agents across teams and departments. Companies can connect agents, regardless of who built them (whether by a third party or internally), assign them roles and permissions, and track the work they perform. “Reload acts like the system of record for AI employees, providing visibility, coordination, and oversight as agents operate across functions,” said Asare, the company’s CEO.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Right now, he observed, teams are using multiple agents simultaneously for tasks such as coding, debugging, and refactoring. The problem is that these agents are often focused solely on whatever they were prompted to do and don’t necessarily retain long-term memory of what a product is or why they were told to perform a specific function. They operate, in other words, with only short-term memory.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Over time, an agent can lose context, or the system can evolve away from its original intent. That’s why Reload is launching Epic. Built on top of the Reload platform, it serves as an architect alongside other coding agents, continuously defining a product’s requirements and constraints, and reminding agents what they are building and why, to keep a system consistent as it develops.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“In software development specifically, coding agents can generate large amounts of code, but they don’t preserve shared system understanding over time,” Asare said. “Epic complements those agents by defining the system upfront and maintaining shared context as it evolves. It doesn’t replace coding agents; it makes them more effective.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Epic is designed to live inside the coding environments where developers already work. It can be installed as an extension in AI-assisted code editors like Cursor and Windsurf, running alongside other agents inside these tools.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When a team starts a project, Epic helps create the core system artifacts such as product requirements, data models, API specifications, tech stack decisions, diagrams, and structured task breakdowns,” Asare said, adding that these are the foundations that coding agents build against.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“As development progresses, Epic maintains a structured memory of decisions, code changes, and patterns,” he continued. “If you switch coding agents, your structure and memory follow. If multiple engineers use different agents on the same project, everyone builds against the same shared source of truth.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Asare and Das previously had a company together that was acquired and this is their second company together.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI infrastructure space is crowded. Competitors include LongChain, which helps with AI agent deployment and memory management, and CrewAI, which helps enterprises manage their AI agents.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Das said Epic is different because it “defines the system upfront and maintains shared project-level context across agents and sessions,” with a focus specifically on building infrastructure to maintain AI employees. “Traditional workforce systems weren’t designed for AI agents operating as teammates,” said Das, who serves as the company’s CTO. “That’s the layer we’re focused on.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The fresh capital will go toward hiring and product advancement, specifically expanding the infrastructure needed to support a growing number of AI agents. “We’re building for the next era of work,” Asare said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This piece was updated to add the other investors in the round. &lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/Reload-Co-Founders-Headshot.png?w=1056" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;There came a point when Newton Asare realized AI agents weren’t just tools anymore. “They were operating more like teammates,” he told TechCrunch.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The realization crystallized when Asare and Kiran Das, both serial founders, noticed they were using AI agents to perform tasks they usually would have done themselves. Asare said he came to believe that the future lay in people managing AI employees.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&amp;nbsp;“And if that’s true, we’ll need a real system to manage them, with structure around onboarding, coordination, and oversight for digital workers,” he added.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last year, the duo launched Reload, an AI workforce management platform. On Thursday, the company announced its first AI product, Epic, alongside a $2.275 million round led by Anthemis, with participation from Zeal Capital Partners, Plug and Play, Cohen Circle, Blueprint, and Axiom.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Reload is a platform that lets organizations manage their AI agents across teams and departments. Companies can connect agents, regardless of who built them (whether by a third party or internally), assign them roles and permissions, and track the work they perform. “Reload acts like the system of record for AI employees, providing visibility, coordination, and oversight as agents operate across functions,” said Asare, the company’s CEO.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Right now, he observed, teams are using multiple agents simultaneously for tasks such as coding, debugging, and refactoring. The problem is that these agents are often focused solely on whatever they were prompted to do and don’t necessarily retain long-term memory of what a product is or why they were told to perform a specific function. They operate, in other words, with only short-term memory.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Over time, an agent can lose context, or the system can evolve away from its original intent. That’s why Reload is launching Epic. Built on top of the Reload platform, it serves as an architect alongside other coding agents, continuously defining a product’s requirements and constraints, and reminding agents what they are building and why, to keep a system consistent as it develops.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“In software development specifically, coding agents can generate large amounts of code, but they don’t preserve shared system understanding over time,” Asare said. “Epic complements those agents by defining the system upfront and maintaining shared context as it evolves. It doesn’t replace coding agents; it makes them more effective.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Epic is designed to live inside the coding environments where developers already work. It can be installed as an extension in AI-assisted code editors like Cursor and Windsurf, running alongside other agents inside these tools.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When a team starts a project, Epic helps create the core system artifacts such as product requirements, data models, API specifications, tech stack decisions, diagrams, and structured task breakdowns,” Asare said, adding that these are the foundations that coding agents build against.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“As development progresses, Epic maintains a structured memory of decisions, code changes, and patterns,” he continued. “If you switch coding agents, your structure and memory follow. If multiple engineers use different agents on the same project, everyone builds against the same shared source of truth.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Asare and Das previously had a company together that was acquired and this is their second company together.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI infrastructure space is crowded. Competitors include LongChain, which helps with AI agent deployment and memory management, and CrewAI, which helps enterprises manage their AI agents.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Das said Epic is different because it “defines the system upfront and maintains shared project-level context across agents and sessions,” with a focus specifically on building infrastructure to maintain AI employees. “Traditional workforce systems weren’t designed for AI agents operating as teammates,” said Das, who serves as the company’s CTO. “That’s the layer we’re focused on.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The fresh capital will go toward hiring and product advancement, specifically expanding the infrastructure needed to support a growing number of AI agents. “We’re building for the next era of work,” Asare said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This piece was updated to add the other investors in the round. &lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/19/reload-an-ai-employee-agent-management-platform-raises-2-275m-and-launches-an-ai-employee/</guid><pubDate>Thu, 19 Feb 2026 15:00:00 +0000</pubDate></item><item><title>[NEW] 「データ不足」の壁を越える：合成ペルソナが日本のAI開発を加速 (Hugging Face - Blog)</title><link>https://huggingface.co/blog/nvidia/nemotron-personas-japan-nttdata-ja</link><description>&lt;div class="not-prose mb-6 font-sans lg:hidden"&gt;&lt;div class="SVELTE_HYDRATER contents"&gt;&lt;div class="flex flex-wrap items-center gap-2.5 pt-1  z-1 lg:sticky lg:top-8"&gt;
	


	&lt;ul class="flex items-center text-gray-600  flex-row  text-base   "&gt;&lt;li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800 " title="Atsunori"&gt;&lt;img alt="alt" class="overflow-hidden rounded-full" src="https://cdn-avatars.huggingface.co/v1/production/uploads/1615517039409-noauth.jpeg" /&gt;
					
			&lt;/li&gt;

		&lt;li class="text-xs hover:text-gray-700 dark:text-gray-400 dark:hover:text-gray-300 order-last ml-3"&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;

&lt;dialog class="shadow-alternate z-40 mx-4 my-auto h-fit select-text overflow-hidden rounded-xl bg-white max-sm:max-w-[calc(100dvw-2rem)] sm:mx-auto lg:mt-26 md:portrait:mt-30 xl:mt-30 2xl:mt-32 w-full sm:w-96 max-w-[calc(100%-4rem)] text-base not-prose"&gt;
	&lt;/dialog&gt;&lt;/div&gt;&lt;/div&gt;
					&lt;div class="not-prose"&gt;&lt;div class="SVELTE_HYDRATER contents"&gt;&lt;div class="not-prose"&gt;&lt;div class="mb-12 flex flex-wrap items-center gap-x-5 gap-y-3.5"&gt;&lt;div class="flex items-center font-sans leading-tight"&gt;

&lt;span class="inline-block "&gt;&lt;span class="contents"&gt;&lt;img alt="Yev Meyer's avatar" class="rounded-full! m-0 mr-2.5 size-9 sm:mr-3 sm:size-12" src="https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/NCK3br1uL-gfkVWmd_VRQ.png" /&gt;
				&lt;/span&gt;
	&lt;/span&gt;

				
			&lt;/div&gt;&lt;/div&gt;
	&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;
					

					&lt;!-- HTML_TAG_START --&gt;
AI は日本の経済成長における新たな章を描く可能性を秘めており、その技術によって 100 兆円 (6,500 億米ドル) を超える経済価値が創出されると予測されています。しかし、その巨大なポテンシャルを実現できるかどうかは、多くのAIプロジェクトに決定的に欠けている“ある1つの要素”にかかっています。それは、実務で「使える学習データ」です。
&lt;p&gt;この課題は、日本語と日本文化を理解する AI システムを構築する開発者にとって特に深刻です。英語の学習データは豊富にある一方で、日本の開発者は慢性的なデータ不足という問題に直面しています。高性能なモデルを初期段階から立ち上げるための、タスクに特化し、かつ日本の文化に根ざしたデータが圧倒的に不足しているのです。新しいサンプルの収集、クリーニング、ラベル付けには時間と費用がかかり、目まぐるしいAIの開発サイクルに追いつくことは困難です。&lt;/p&gt;
&lt;p&gt;その結果、イノベーションが始まる前にそれを阻むデータの壁が生まれます。&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		新たな前進への道
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;&lt;img alt="image" src="https://cdn-uploads.huggingface.co/production/uploads/68d2fec8856b85d927e44d32/_Fk8_hH3YBUR26fdsT-56.png" /&gt;
大手 IT 企業 NTT DATA による新たな研究は、合成データによってこの壁がいかに取り払われるかを実証しています。手元にある最小限の独自データから、プライバシーやモデルの性能を損なうことなく、実運用レベルの大規模な学習データセットを生成できるのです。&lt;/p&gt;
&lt;p&gt;NTT DATA は、NVIDIA Nemotron-Personas-Japan (NeMo Data Designer を使用して生成された、日本の人口動態、地理、文化に基づいた 600 万のペルソナから構成されるNVIDIA の初のオープン合成データセット) を使用することで、モデル精度を 15.3% から 79.3% へと大幅に向上させました。&lt;/p&gt;
&lt;p&gt;これは、機密データを学習パイプラインに公開することなく、60 ポイントもの向上を実現したことになります。&lt;/p&gt;
&lt;p&gt;ここから得られる重要なポイントは、企業は完全にオープンソースのインフラストラクチャを使用し、手元にある最小限の独自データからでも、特定のドメイン（業務領域）に特化したAIを構築できるということです。オープンなペルソナデータを活用することで、より高品質なモデルの構築と、より機敏なデータ運用の両立が可能になります。&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		実証実験
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;このアプローチを厳密に検証するため、NTT DATA は架空の法律文書を用いた対照評価を実施し、モデルが真に新しい知識を獲得できるようにしました。Nemotron-Personas-Japan から抽出した500のペルソナを活用し、わずか 240 件の未加工のシードサンプルを拡張することで、13 万 8000 件以上の学習用データ (人手による同等のサンプルの 300 倍に相当する合成データセット) を生成し、モデルの精度を 15.3% から 79.3% に向上させました。&lt;/p&gt;
&lt;p&gt;この結果は、企業が直面するデータ不足という課題を如実に物語っています。&lt;/p&gt;
&lt;div class="max-w-full overflow-auto"&gt;
	&lt;table&gt;
		&lt;thead&gt;&lt;tr&gt;
&lt;th&gt;構成&lt;/th&gt;
&lt;th align="right"&gt;シードデータ&lt;/th&gt;
&lt;th align="right"&gt;合成拡張&lt;/th&gt;
&lt;th align="right"&gt;精度&lt;/th&gt;
&lt;/tr&gt;

		&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;ベースライン (トレーニングなし)&lt;/td&gt;
&lt;td align="right"&gt;—&lt;/td&gt;
&lt;td align="right"&gt;—&lt;/td&gt;
&lt;td align="right"&gt;15.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;合成データを使用したSFT&lt;/td&gt;
&lt;td align="right"&gt;240件&lt;/td&gt;
&lt;td align="right"&gt;138,000 件&lt;/td&gt;
&lt;td align="right"&gt;79.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
	&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;合成データによる学習は、単なる精度の向上にとどまらず、ベースラインモデルを悩ませていたハルシネーションも排除しました。学習前のモデルがもっともらしいものの誤った法的分類を生成したのに対し、ファインチューニングされたモデルはノイズを加えることなく正確な用語を抽出できるようになりました。&lt;/p&gt;
&lt;p&gt;エンタープライズ環境への展開においておそらく最も価値のある発見は、十分な量のファインチューニング用合成データが確保できれば、「継続事前学習（CPT）」は必須ではなくなると NTT DATA が見出したことです。これはつまり、開発者は計算リソースを大量に消費する CPT の工程を完全に省略し、教師ありファインチューニング (SFT) のためのより反復的な合成データ生成に注力するという、より費用対効果の高い学習パイプラインを活用できることを意味しています。&lt;/p&gt;
&lt;p&gt;この効率性の向上は、コンピューティングコストの削減と開発サイクルの高速化に直接つながります。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;NTT DATA 技術革新統括本部 AI 技術部 部長の樋口晋也氏は次のように話しています。「Nemotron Personas を用いて少量の独自データセットを拡張することで、利用可能なデータが限られている場合でも、タスクに特化したモデルを効果的に構築できます。このアプローチは、独自データが不足しがちな事前調査、カスタマーサポート、マーケティングなどの領域において、成果を向上させる大きな可能性を示しています」&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt="Screenshot 2026-02-19 at 7.21.41 AM" src="https://cdn-uploads.huggingface.co/production/uploads/68d2fec8856b85d927e44d32/TZE6YYFdp-f0MgIhFA0cI.png" /&gt;&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		設計段階からのプライバシー保護
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;ここでの精度向上は魅力的ですが、同時により深い疑問も生じます。そもそも学習パイプラインにすら入らない（使えない）データはどうなるのでしょうか？&lt;/p&gt;
&lt;p&gt;価値ある企業データの 90% 以上が、プライバシー規制、セキュリティリスク、ライセンス制約のために未活用のままです。日本では、個人情報保護法 (PIPA) やイノベーション重視の AI ガバナンスガイドライン (2025 年 9 月公表) などの枠組みがこの現実を裏付けています。AI の進歩が加速する中でも、責任あるデータ取り扱いは必須です。&lt;/p&gt;
&lt;p&gt;合成データは、この相反する課題を解決する道筋を提供します。個人を特定できる情報 (PII) を含まず、実際のデータの傾向（パターン）を正確に反映した学習用データを生成することで、企業はデータの最小化とモデルの性能向上を同時に実現できます。初期の立ち上げには最小限の独自データのみを使用し、その後は合成データによって実運用レベルの規模まで拡張すればよいのです。&lt;/p&gt;
&lt;p&gt;つまり、合成データは単なる「学習プロセスを最適化する手法」ではありません。データコンプライアンスと AI の性能が共存する理想的なバランス(ゴルディロックスゾーン) を実現するプライバシー強化技術 (PET) なのです。さらに、データの合成パイプラインは再現性と監査性を備えているため、ガバナンスチームや規制当局がますます求める信頼性と透明性の要件にも対応できます。&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		ソブリンデータ空間
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;ソブリン AI を構築する日本企業にとって、データ主権は必須条件です。しかし、主権だけでは十分ではありません。モデルには、欧米中心のコーパスに統計的に偏ったものではなく、地域固有の規範やドメインの制約によって形成される、根拠のあるインテリジェンスも必要です。Nemotron-Personas-Japan は、この現実に根ざした AI を作るための基盤データとして機能します。600 万のペルソナは日本の公式人口動態および労働統計に基づいており、1,500 以上の職業分類と地域分布をカバーしています。&lt;/p&gt;
&lt;p&gt;しかし、その影響は個々の組織にとどまりません。NTT DATA をはじめとするリーダー企業は、「データスペース」の開発に積極的に取り組んでいます。これは、政府と企業が共通のガバナンスとプライバシー保証の下で、AI学習用に合成されたデータを交換し合える協調的な環境です。連合学習（フェデレーテッド ラーニング）などのエンドツーエンドの暗号化技術は、この分散型アプローチを可能にします。合成データはこれをさらに強力に推進する役割を果たし、組織は元となる機密情報を公開することなく、自社データの傾向（パターン）を合成データとして安全に提供できるようになります。&lt;/p&gt;
&lt;p&gt;これにより、データリスク管理は守りの姿勢から、日本の掲げる『イノベーション主導のAIガバナンス』というビジョンに沿った「協調的な姿勢」へとシフトします。また、このアプローチは、「AIの進化は、グローバルで学習された少数の巨大モデルからもたらされるべきだ」という固定観念にも一石を投じます。むしろ、オープンでプライバシー保護された基盤の上に、主権を持ち、相互運用可能な AI システムがそれぞれの地域で構築される未来を指し示しています。&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		構築を開始
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;「データの壁」は確かに存在します。しかし、NTT DATA の調査が示すように、それを克服するためのツールは今やオープンで誰でもアクセスできるようになっています。合成データは、もはや「未来の技術」ではありません 。プライバシーや性能を犠牲にすることなく、データ主権を持ち、日本の文化に根ざしたAIシステムを構築するために、開発者が「今すぐ」現場に導入できる現実のソリューションなのです。&lt;/p&gt;
&lt;p&gt;さっそく始めてみませんか？オープンソースのNeMo Data Designer ライブラリを活用するか、Hugging Face で公開されている Nemotron-Personas-Japan データセットをご覧ください。より詳細な技術的情報については、手法と実験設計を網羅したNTT データによる詳細なレポート (日本語) をご覧ください。&lt;/p&gt;

&lt;p&gt;Nemotron-Personas-Japan は、CC BY 4.0 ライセンスに基づき、商用・非商用を問わずご利用いただけます。&lt;/p&gt;
&lt;!-- HTML_TAG_END --&gt;</description><content:encoded>&lt;div class="not-prose mb-6 font-sans lg:hidden"&gt;&lt;div class="SVELTE_HYDRATER contents"&gt;&lt;div class="flex flex-wrap items-center gap-2.5 pt-1  z-1 lg:sticky lg:top-8"&gt;
	


	&lt;ul class="flex items-center text-gray-600  flex-row  text-base   "&gt;&lt;li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800 " title="Atsunori"&gt;&lt;img alt="alt" class="overflow-hidden rounded-full" src="https://cdn-avatars.huggingface.co/v1/production/uploads/1615517039409-noauth.jpeg" /&gt;
					
			&lt;/li&gt;

		&lt;li class="text-xs hover:text-gray-700 dark:text-gray-400 dark:hover:text-gray-300 order-last ml-3"&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;

&lt;dialog class="shadow-alternate z-40 mx-4 my-auto h-fit select-text overflow-hidden rounded-xl bg-white max-sm:max-w-[calc(100dvw-2rem)] sm:mx-auto lg:mt-26 md:portrait:mt-30 xl:mt-30 2xl:mt-32 w-full sm:w-96 max-w-[calc(100%-4rem)] text-base not-prose"&gt;
	&lt;/dialog&gt;&lt;/div&gt;&lt;/div&gt;
					&lt;div class="not-prose"&gt;&lt;div class="SVELTE_HYDRATER contents"&gt;&lt;div class="not-prose"&gt;&lt;div class="mb-12 flex flex-wrap items-center gap-x-5 gap-y-3.5"&gt;&lt;div class="flex items-center font-sans leading-tight"&gt;

&lt;span class="inline-block "&gt;&lt;span class="contents"&gt;&lt;img alt="Yev Meyer's avatar" class="rounded-full! m-0 mr-2.5 size-9 sm:mr-3 sm:size-12" src="https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/NCK3br1uL-gfkVWmd_VRQ.png" /&gt;
				&lt;/span&gt;
	&lt;/span&gt;

				
			&lt;/div&gt;&lt;/div&gt;
	&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;
					

					&lt;!-- HTML_TAG_START --&gt;
AI は日本の経済成長における新たな章を描く可能性を秘めており、その技術によって 100 兆円 (6,500 億米ドル) を超える経済価値が創出されると予測されています。しかし、その巨大なポテンシャルを実現できるかどうかは、多くのAIプロジェクトに決定的に欠けている“ある1つの要素”にかかっています。それは、実務で「使える学習データ」です。
&lt;p&gt;この課題は、日本語と日本文化を理解する AI システムを構築する開発者にとって特に深刻です。英語の学習データは豊富にある一方で、日本の開発者は慢性的なデータ不足という問題に直面しています。高性能なモデルを初期段階から立ち上げるための、タスクに特化し、かつ日本の文化に根ざしたデータが圧倒的に不足しているのです。新しいサンプルの収集、クリーニング、ラベル付けには時間と費用がかかり、目まぐるしいAIの開発サイクルに追いつくことは困難です。&lt;/p&gt;
&lt;p&gt;その結果、イノベーションが始まる前にそれを阻むデータの壁が生まれます。&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		新たな前進への道
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;&lt;img alt="image" src="https://cdn-uploads.huggingface.co/production/uploads/68d2fec8856b85d927e44d32/_Fk8_hH3YBUR26fdsT-56.png" /&gt;
大手 IT 企業 NTT DATA による新たな研究は、合成データによってこの壁がいかに取り払われるかを実証しています。手元にある最小限の独自データから、プライバシーやモデルの性能を損なうことなく、実運用レベルの大規模な学習データセットを生成できるのです。&lt;/p&gt;
&lt;p&gt;NTT DATA は、NVIDIA Nemotron-Personas-Japan (NeMo Data Designer を使用して生成された、日本の人口動態、地理、文化に基づいた 600 万のペルソナから構成されるNVIDIA の初のオープン合成データセット) を使用することで、モデル精度を 15.3% から 79.3% へと大幅に向上させました。&lt;/p&gt;
&lt;p&gt;これは、機密データを学習パイプラインに公開することなく、60 ポイントもの向上を実現したことになります。&lt;/p&gt;
&lt;p&gt;ここから得られる重要なポイントは、企業は完全にオープンソースのインフラストラクチャを使用し、手元にある最小限の独自データからでも、特定のドメイン（業務領域）に特化したAIを構築できるということです。オープンなペルソナデータを活用することで、より高品質なモデルの構築と、より機敏なデータ運用の両立が可能になります。&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		実証実験
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;このアプローチを厳密に検証するため、NTT DATA は架空の法律文書を用いた対照評価を実施し、モデルが真に新しい知識を獲得できるようにしました。Nemotron-Personas-Japan から抽出した500のペルソナを活用し、わずか 240 件の未加工のシードサンプルを拡張することで、13 万 8000 件以上の学習用データ (人手による同等のサンプルの 300 倍に相当する合成データセット) を生成し、モデルの精度を 15.3% から 79.3% に向上させました。&lt;/p&gt;
&lt;p&gt;この結果は、企業が直面するデータ不足という課題を如実に物語っています。&lt;/p&gt;
&lt;div class="max-w-full overflow-auto"&gt;
	&lt;table&gt;
		&lt;thead&gt;&lt;tr&gt;
&lt;th&gt;構成&lt;/th&gt;
&lt;th align="right"&gt;シードデータ&lt;/th&gt;
&lt;th align="right"&gt;合成拡張&lt;/th&gt;
&lt;th align="right"&gt;精度&lt;/th&gt;
&lt;/tr&gt;

		&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;ベースライン (トレーニングなし)&lt;/td&gt;
&lt;td align="right"&gt;—&lt;/td&gt;
&lt;td align="right"&gt;—&lt;/td&gt;
&lt;td align="right"&gt;15.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;合成データを使用したSFT&lt;/td&gt;
&lt;td align="right"&gt;240件&lt;/td&gt;
&lt;td align="right"&gt;138,000 件&lt;/td&gt;
&lt;td align="right"&gt;79.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
	&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;合成データによる学習は、単なる精度の向上にとどまらず、ベースラインモデルを悩ませていたハルシネーションも排除しました。学習前のモデルがもっともらしいものの誤った法的分類を生成したのに対し、ファインチューニングされたモデルはノイズを加えることなく正確な用語を抽出できるようになりました。&lt;/p&gt;
&lt;p&gt;エンタープライズ環境への展開においておそらく最も価値のある発見は、十分な量のファインチューニング用合成データが確保できれば、「継続事前学習（CPT）」は必須ではなくなると NTT DATA が見出したことです。これはつまり、開発者は計算リソースを大量に消費する CPT の工程を完全に省略し、教師ありファインチューニング (SFT) のためのより反復的な合成データ生成に注力するという、より費用対効果の高い学習パイプラインを活用できることを意味しています。&lt;/p&gt;
&lt;p&gt;この効率性の向上は、コンピューティングコストの削減と開発サイクルの高速化に直接つながります。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;NTT DATA 技術革新統括本部 AI 技術部 部長の樋口晋也氏は次のように話しています。「Nemotron Personas を用いて少量の独自データセットを拡張することで、利用可能なデータが限られている場合でも、タスクに特化したモデルを効果的に構築できます。このアプローチは、独自データが不足しがちな事前調査、カスタマーサポート、マーケティングなどの領域において、成果を向上させる大きな可能性を示しています」&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt="Screenshot 2026-02-19 at 7.21.41 AM" src="https://cdn-uploads.huggingface.co/production/uploads/68d2fec8856b85d927e44d32/TZE6YYFdp-f0MgIhFA0cI.png" /&gt;&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		設計段階からのプライバシー保護
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;ここでの精度向上は魅力的ですが、同時により深い疑問も生じます。そもそも学習パイプラインにすら入らない（使えない）データはどうなるのでしょうか？&lt;/p&gt;
&lt;p&gt;価値ある企業データの 90% 以上が、プライバシー規制、セキュリティリスク、ライセンス制約のために未活用のままです。日本では、個人情報保護法 (PIPA) やイノベーション重視の AI ガバナンスガイドライン (2025 年 9 月公表) などの枠組みがこの現実を裏付けています。AI の進歩が加速する中でも、責任あるデータ取り扱いは必須です。&lt;/p&gt;
&lt;p&gt;合成データは、この相反する課題を解決する道筋を提供します。個人を特定できる情報 (PII) を含まず、実際のデータの傾向（パターン）を正確に反映した学習用データを生成することで、企業はデータの最小化とモデルの性能向上を同時に実現できます。初期の立ち上げには最小限の独自データのみを使用し、その後は合成データによって実運用レベルの規模まで拡張すればよいのです。&lt;/p&gt;
&lt;p&gt;つまり、合成データは単なる「学習プロセスを最適化する手法」ではありません。データコンプライアンスと AI の性能が共存する理想的なバランス(ゴルディロックスゾーン) を実現するプライバシー強化技術 (PET) なのです。さらに、データの合成パイプラインは再現性と監査性を備えているため、ガバナンスチームや規制当局がますます求める信頼性と透明性の要件にも対応できます。&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		ソブリンデータ空間
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;ソブリン AI を構築する日本企業にとって、データ主権は必須条件です。しかし、主権だけでは十分ではありません。モデルには、欧米中心のコーパスに統計的に偏ったものではなく、地域固有の規範やドメインの制約によって形成される、根拠のあるインテリジェンスも必要です。Nemotron-Personas-Japan は、この現実に根ざした AI を作るための基盤データとして機能します。600 万のペルソナは日本の公式人口動態および労働統計に基づいており、1,500 以上の職業分類と地域分布をカバーしています。&lt;/p&gt;
&lt;p&gt;しかし、その影響は個々の組織にとどまりません。NTT DATA をはじめとするリーダー企業は、「データスペース」の開発に積極的に取り組んでいます。これは、政府と企業が共通のガバナンスとプライバシー保証の下で、AI学習用に合成されたデータを交換し合える協調的な環境です。連合学習（フェデレーテッド ラーニング）などのエンドツーエンドの暗号化技術は、この分散型アプローチを可能にします。合成データはこれをさらに強力に推進する役割を果たし、組織は元となる機密情報を公開することなく、自社データの傾向（パターン）を合成データとして安全に提供できるようになります。&lt;/p&gt;
&lt;p&gt;これにより、データリスク管理は守りの姿勢から、日本の掲げる『イノベーション主導のAIガバナンス』というビジョンに沿った「協調的な姿勢」へとシフトします。また、このアプローチは、「AIの進化は、グローバルで学習された少数の巨大モデルからもたらされるべきだ」という固定観念にも一石を投じます。むしろ、オープンでプライバシー保護された基盤の上に、主権を持ち、相互運用可能な AI システムがそれぞれの地域で構築される未来を指し示しています。&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		構築を開始
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;「データの壁」は確かに存在します。しかし、NTT DATA の調査が示すように、それを克服するためのツールは今やオープンで誰でもアクセスできるようになっています。合成データは、もはや「未来の技術」ではありません 。プライバシーや性能を犠牲にすることなく、データ主権を持ち、日本の文化に根ざしたAIシステムを構築するために、開発者が「今すぐ」現場に導入できる現実のソリューションなのです。&lt;/p&gt;
&lt;p&gt;さっそく始めてみませんか？オープンソースのNeMo Data Designer ライブラリを活用するか、Hugging Face で公開されている Nemotron-Personas-Japan データセットをご覧ください。より詳細な技術的情報については、手法と実験設計を網羅したNTT データによる詳細なレポート (日本語) をご覧ください。&lt;/p&gt;

&lt;p&gt;Nemotron-Personas-Japan は、CC BY 4.0 ライセンスに基づき、商用・非商用を問わずご利用いただけます。&lt;/p&gt;
&lt;!-- HTML_TAG_END --&gt;</content:encoded><guid isPermaLink="false">https://huggingface.co/blog/nvidia/nemotron-personas-japan-nttdata-ja</guid><pubDate>Thu, 19 Feb 2026 15:32:38 +0000</pubDate></item><item><title>[NEW] OpenAI reportedly finalizing $100B deal at more than $850B valuation (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/19/openai-reportedly-finalizing-100b-deal-at-more-than-850b-valuation/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/GettyImages-2236544149.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI is nearing a deal to raise more than $100 billion at a valuation that could exceed $850 billion, Bloomberg reports, citing sources familiar with the matter.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal comes as the ChatGPT-maker burns through cash as it inches toward profitability. To that end, OpenAI has said it has started testing ads in ChatGPT for free users, a gamble that could lead to more revenue or could send users running from the platform.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Apparently investors think it’s worth the risk if they’re valuing the company $20 billion higher than the $830 billion valuation initially expected. The company’s pre-money value will remain at $730 billion, per Bloomberg’s source.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The first tranches of funding are reportedly coming from the usual suspects: Amazon (already in talks to invest up to $50 billion), SoftBank (gearing up for $30 billion), Nvidia (close to investing $20 billion), and Microsoft. VC firms and sovereign wealth funds are expected to close later, potentially bringing the total amount raised higher.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to OpenAI for comment. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/GettyImages-2236544149.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI is nearing a deal to raise more than $100 billion at a valuation that could exceed $850 billion, Bloomberg reports, citing sources familiar with the matter.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal comes as the ChatGPT-maker burns through cash as it inches toward profitability. To that end, OpenAI has said it has started testing ads in ChatGPT for free users, a gamble that could lead to more revenue or could send users running from the platform.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Apparently investors think it’s worth the risk if they’re valuing the company $20 billion higher than the $830 billion valuation initially expected. The company’s pre-money value will remain at $730 billion, per Bloomberg’s source.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The first tranches of funding are reportedly coming from the usual suspects: Amazon (already in talks to invest up to $50 billion), SoftBank (gearing up for $30 billion), Nvidia (close to investing $20 billion), and Microsoft. VC firms and sovereign wealth funds are expected to close later, potentially bringing the total amount raised higher.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to OpenAI for comment. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/19/openai-reportedly-finalizing-100b-deal-at-more-than-850b-valuation/</guid><pubDate>Thu, 19 Feb 2026 15:35:58 +0000</pubDate></item><item><title>[NEW] Microsoft has a new plan to prove what’s real and what’s AI online (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/19/1133360/microsoft-has-a-new-plan-to-prove-whats-real-and-whats-ai-online/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/false-mirror-cr-smoke2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;AI-enabled deception now permeates our online lives. There are the high-profile cases you may easily spot, like when White House officials recently shared a manipulated image of a protester in Minnesota and then mocked those asking about it. Other times, it slips quietly into social media feeds and racks up views, like the videos that Russian influence campaigns are currently spreading to discourage Ukrainians from enlisting.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It is into this mess that Microsoft has put forward a blueprint, shared with &lt;em&gt;MIT Technology Review&lt;/em&gt;, for how to prove what’s real online.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;An AI safety research team at the company recently evaluated how methods for documenting digital manipulation are faring against today’s most worrying AI developments, like interactive deepfakes and widely accessible hyperrealistic models. It then recommended technical standards that can be adopted by AI companies and social media platforms.&lt;/p&gt;  &lt;p&gt;To understand the gold standard that Microsoft is pushing, imagine you have a Rembrandt painting and you are trying to document its authenticity. You might describe its &lt;em&gt;provenance&lt;/em&gt; with a detailed manifest of where the painting came from and all the times it changed hands. You might apply a &lt;em&gt;watermark&lt;/em&gt; that would be invisible to humans but readable by a machine. And you could digitally scan the painting and generate a mathematical signature, like a &lt;em&gt;fingerprint&lt;/em&gt;, based on the brush strokes. If you showed the piece at a museum, a skeptical visitor could then examine these proofs to verify that it’s an original.&lt;/p&gt; 
 &lt;p&gt;All of these methods are already being used to varying degrees in the effort to vet content online. Microsoft evaluated 60 different combinations of them, modeling how each setup would hold up under different failure scenarios—from metadata being stripped to content being slightly altered or deliberately manipulated. The team then mapped which combinations produce sound results that platforms can confidently show to people online, and which ones are so unreliable that they may cause more confusion than clarification.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__container--08c53dd3bc9bd04e1e42e5f7ca641ab2"&gt;&lt;div class="whyItMatters__header--19f7f372f181cc6d4c06bc7362a44382"&gt;&lt;div class="whyItMatters__title--4af28c786a2bc93df05db111c6c30618"&gt;&lt;span class="whyItMatters__askAi--577f5fe6f54de43e37258d0f2aff4394"&gt;Ask AI&lt;/span&gt;&lt;div&gt;&lt;span class="whyItMatters__whyItMattersTitle--a3694998bb578e159bbd16690b8da390"&gt;Why it matters to you?&lt;/span&gt;&lt;span class="whyItMatters__betaBadge--9e84228b864d33d5b55479433fc91b8a"&gt;BETA&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__description--e1334886c092fa469388d7a24e1e1a55"&gt;&lt;span class="initial-description"&gt;Here’s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates—it might get weird&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="whyItMatters__questionContainer--ec1159210954852b9178c549600959a0"&gt;&lt;div&gt;&lt;button class="whyItMatters__actionButton--674934b6df433ac81e613372979cdb6c" type="button"&gt;Tell me why it matters&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;The company’s chief scientific officer, Eric Horvitz, says the work was prompted by&lt;strong&gt; &lt;/strong&gt;legislation—like California’s AI Transparency Act, which will take effect in August—and the speed at which AI has developed to combine video and voice with striking fidelity.&lt;/p&gt; 
 &lt;p&gt;“You might call this self-regulation,” Horvitz told &lt;em&gt;MIT Technology Review&lt;/em&gt;. But it’s clear he sees pursuing the work as boosting Microsoft’s image: “We’re also trying to be a selected, desired provider to people who want to know what’s going on in the world.”&lt;/p&gt;  &lt;p&gt;Nevertheless, Horvitz declined to commit to Microsoft using its own recommendation across its platforms. The company sits at the center of a giant AI content ecosystem: It runs Copilot, which can generate images and text; it operates Azure, the cloud service through which customers can access OpenAI and other major AI models; it owns LinkedIn, one of the world’s largest professional platforms; and it holds a significant stake in OpenAI. But when asked about in-house implementation, Horvitz said in a statement, “Product groups and leaders across the company were involved in this study to inform product road maps and infrastructure, and our engineering teams are taking action on the report’s findings.”&lt;/p&gt;  &lt;p&gt;It’s important to note that there are inherent limits to these tools; just as they would not tell you what your Rembrandt &lt;em&gt;means&lt;/em&gt;, they are not built to determine if content is accurate or not. They only reveal if it has been manipulated. It’s a point that Horvitz says he has to make to lawmakers and others who are skeptical of Big Tech as an arbiter of fact.&lt;/p&gt;  &lt;p&gt;“It’s not about making any decisions about what’s true and not true,” he said. “It’s about coming up with labels that just tell folks where stuff came from.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;Hany Farid, a professor at UC Berkeley who specializes in digital forensics but wasn’t involved in the Microsoft research, says that if the industry adopted the company’s blueprint, it would be meaningfully more difficult to deceive the public with manipulated content. Sophisticated individuals or governments can work to bypass such tools, he says, but the new standard could eliminate a significant portion of misleading material.&lt;/p&gt;  &lt;p&gt;“I don’t think it solves the problem, but I think it takes a nice big chunk out of it,” he says.&lt;/p&gt;  &lt;p&gt;Still, there are reasons to see Microsoft’s approach as an example of somewhat naïve techno-optimism. There is growing evidence that people are swayed by AI-generated content even when they know that it is false. And in a recent study of pro-Russian AI-generated videos about the war in Ukraine, comments pointing out that the videos were made with AI received far less engagement than comments treating them as genuine.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Are there people who, no matter what you tell them, are going to believe what they believe?” Farid asks. “Yes.” But, he adds, “there are a vast majority of Americans and citizens around the world who I do think want to know the truth.”&lt;/p&gt; 

 &lt;p&gt;That desire has not exactly led to urgent action from tech companies. Google started adding a watermark to content generated by its AI tools in 2023, which Farid says has been helpful in his investigations. Some platforms use C2PA, a provenance standard Microsoft helped launch in 2021. But the full suite of changes that Microsoft suggests, powerful as they are, might remain only suggestions if they threaten the business models of AI companies or social media platforms.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;“If the Mark Zuckerbergs and the Elon Musks of the world think that putting ‘AI generated’ labels on something will reduce engagement, then of course they’re incentivized not to do it,” Farid says. Platforms like Meta and Google have already said they’d include labels for AI-generated content, but an audit conducted by &lt;em&gt;Indicator &lt;/em&gt;last year found that only 30% of its test posts on Instagram, LinkedIn, Pinterest, TikTok, and YouTube were correctly labeled as AI-generated.&lt;/p&gt;  &lt;p&gt;More forceful moves toward content verification might come from the many pieces of AI regulation pending around the world. The European Union’s AI Act, as well as proposed rules in India and elsewhere, would all compel AI companies to require some form of disclosure that a piece of content was generated with AI.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;One priority from Microsoft is, unsurprisingly, to play a role in shaping these rules. The company waged a lobbying effort during the drafting of California’s AI Transparency Act, which Horvitz said made the legislation’s requirements on how tech companies must disclose AI-generated content “a bit more realistic.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;But another is a very real concern about what could happen if the rollout of such content-verification technology is done poorly. Lawmakers are demanding tools that can verify what’s real, but the tools are fragile. If labeling systems are rushed out, inconsistently applied, or frequently wrong, people could come to distrust them altogether, and the entire effort would backfire. That’s why the researchers argue that it may be better in some cases to show nothing at all than a verdict that could be wrong.&lt;/p&gt;  &lt;p&gt;Inadequate tools could also create new avenues for what the researchers call sociotechnical attacks. Imagine that someone takes a real image of a fraught political event and uses an AI tool to change only an inconsequential share of pixels in the image. When it spreads online, it could be misleadingly classified by platforms as AI-manipulated. But combining provenance and watermark tools would mean platforms could clarify that the content was only partially AI generated, and point out where the changes were made.&lt;/p&gt;  &lt;p&gt;California’s AI Transparency Act will be the first major test of these tools in the US, but enforcement could be challenged by President Trump’s executive order from late last year seeking to curtail state AI regulations that are “burdensome” to the industry. The administration has also generally taken a posture against efforts to curb disinformation, and last year, via DOGE, it canceled grants related to misinformation. And, of course, official government channels in the Trump administration have shared content manipulated with AI (&lt;em&gt;MIT Technology Review&lt;/em&gt; reported that the Department of Homeland Security, for example, uses video generators from Google and Adobe to make content it shares with the public).&lt;/p&gt;  &lt;p&gt;I asked Horvitz whether fake content from this source worries him as much as that coming from the rest of social media. He initially declined to comment, but then he said, “Governments have not been outside the sectors that have been behind various kinds of manipulative disinformation, and this is worldwide.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/false-mirror-cr-smoke2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;AI-enabled deception now permeates our online lives. There are the high-profile cases you may easily spot, like when White House officials recently shared a manipulated image of a protester in Minnesota and then mocked those asking about it. Other times, it slips quietly into social media feeds and racks up views, like the videos that Russian influence campaigns are currently spreading to discourage Ukrainians from enlisting.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It is into this mess that Microsoft has put forward a blueprint, shared with &lt;em&gt;MIT Technology Review&lt;/em&gt;, for how to prove what’s real online.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;An AI safety research team at the company recently evaluated how methods for documenting digital manipulation are faring against today’s most worrying AI developments, like interactive deepfakes and widely accessible hyperrealistic models. It then recommended technical standards that can be adopted by AI companies and social media platforms.&lt;/p&gt;  &lt;p&gt;To understand the gold standard that Microsoft is pushing, imagine you have a Rembrandt painting and you are trying to document its authenticity. You might describe its &lt;em&gt;provenance&lt;/em&gt; with a detailed manifest of where the painting came from and all the times it changed hands. You might apply a &lt;em&gt;watermark&lt;/em&gt; that would be invisible to humans but readable by a machine. And you could digitally scan the painting and generate a mathematical signature, like a &lt;em&gt;fingerprint&lt;/em&gt;, based on the brush strokes. If you showed the piece at a museum, a skeptical visitor could then examine these proofs to verify that it’s an original.&lt;/p&gt; 
 &lt;p&gt;All of these methods are already being used to varying degrees in the effort to vet content online. Microsoft evaluated 60 different combinations of them, modeling how each setup would hold up under different failure scenarios—from metadata being stripped to content being slightly altered or deliberately manipulated. The team then mapped which combinations produce sound results that platforms can confidently show to people online, and which ones are so unreliable that they may cause more confusion than clarification.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__container--08c53dd3bc9bd04e1e42e5f7ca641ab2"&gt;&lt;div class="whyItMatters__header--19f7f372f181cc6d4c06bc7362a44382"&gt;&lt;div class="whyItMatters__title--4af28c786a2bc93df05db111c6c30618"&gt;&lt;span class="whyItMatters__askAi--577f5fe6f54de43e37258d0f2aff4394"&gt;Ask AI&lt;/span&gt;&lt;div&gt;&lt;span class="whyItMatters__whyItMattersTitle--a3694998bb578e159bbd16690b8da390"&gt;Why it matters to you?&lt;/span&gt;&lt;span class="whyItMatters__betaBadge--9e84228b864d33d5b55479433fc91b8a"&gt;BETA&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__description--e1334886c092fa469388d7a24e1e1a55"&gt;&lt;span class="initial-description"&gt;Here’s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates—it might get weird&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="whyItMatters__questionContainer--ec1159210954852b9178c549600959a0"&gt;&lt;div&gt;&lt;button class="whyItMatters__actionButton--674934b6df433ac81e613372979cdb6c" type="button"&gt;Tell me why it matters&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;The company’s chief scientific officer, Eric Horvitz, says the work was prompted by&lt;strong&gt; &lt;/strong&gt;legislation—like California’s AI Transparency Act, which will take effect in August—and the speed at which AI has developed to combine video and voice with striking fidelity.&lt;/p&gt; 
 &lt;p&gt;“You might call this self-regulation,” Horvitz told &lt;em&gt;MIT Technology Review&lt;/em&gt;. But it’s clear he sees pursuing the work as boosting Microsoft’s image: “We’re also trying to be a selected, desired provider to people who want to know what’s going on in the world.”&lt;/p&gt;  &lt;p&gt;Nevertheless, Horvitz declined to commit to Microsoft using its own recommendation across its platforms. The company sits at the center of a giant AI content ecosystem: It runs Copilot, which can generate images and text; it operates Azure, the cloud service through which customers can access OpenAI and other major AI models; it owns LinkedIn, one of the world’s largest professional platforms; and it holds a significant stake in OpenAI. But when asked about in-house implementation, Horvitz said in a statement, “Product groups and leaders across the company were involved in this study to inform product road maps and infrastructure, and our engineering teams are taking action on the report’s findings.”&lt;/p&gt;  &lt;p&gt;It’s important to note that there are inherent limits to these tools; just as they would not tell you what your Rembrandt &lt;em&gt;means&lt;/em&gt;, they are not built to determine if content is accurate or not. They only reveal if it has been manipulated. It’s a point that Horvitz says he has to make to lawmakers and others who are skeptical of Big Tech as an arbiter of fact.&lt;/p&gt;  &lt;p&gt;“It’s not about making any decisions about what’s true and not true,” he said. “It’s about coming up with labels that just tell folks where stuff came from.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;Hany Farid, a professor at UC Berkeley who specializes in digital forensics but wasn’t involved in the Microsoft research, says that if the industry adopted the company’s blueprint, it would be meaningfully more difficult to deceive the public with manipulated content. Sophisticated individuals or governments can work to bypass such tools, he says, but the new standard could eliminate a significant portion of misleading material.&lt;/p&gt;  &lt;p&gt;“I don’t think it solves the problem, but I think it takes a nice big chunk out of it,” he says.&lt;/p&gt;  &lt;p&gt;Still, there are reasons to see Microsoft’s approach as an example of somewhat naïve techno-optimism. There is growing evidence that people are swayed by AI-generated content even when they know that it is false. And in a recent study of pro-Russian AI-generated videos about the war in Ukraine, comments pointing out that the videos were made with AI received far less engagement than comments treating them as genuine.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Are there people who, no matter what you tell them, are going to believe what they believe?” Farid asks. “Yes.” But, he adds, “there are a vast majority of Americans and citizens around the world who I do think want to know the truth.”&lt;/p&gt; 

 &lt;p&gt;That desire has not exactly led to urgent action from tech companies. Google started adding a watermark to content generated by its AI tools in 2023, which Farid says has been helpful in his investigations. Some platforms use C2PA, a provenance standard Microsoft helped launch in 2021. But the full suite of changes that Microsoft suggests, powerful as they are, might remain only suggestions if they threaten the business models of AI companies or social media platforms.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;“If the Mark Zuckerbergs and the Elon Musks of the world think that putting ‘AI generated’ labels on something will reduce engagement, then of course they’re incentivized not to do it,” Farid says. Platforms like Meta and Google have already said they’d include labels for AI-generated content, but an audit conducted by &lt;em&gt;Indicator &lt;/em&gt;last year found that only 30% of its test posts on Instagram, LinkedIn, Pinterest, TikTok, and YouTube were correctly labeled as AI-generated.&lt;/p&gt;  &lt;p&gt;More forceful moves toward content verification might come from the many pieces of AI regulation pending around the world. The European Union’s AI Act, as well as proposed rules in India and elsewhere, would all compel AI companies to require some form of disclosure that a piece of content was generated with AI.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;One priority from Microsoft is, unsurprisingly, to play a role in shaping these rules. The company waged a lobbying effort during the drafting of California’s AI Transparency Act, which Horvitz said made the legislation’s requirements on how tech companies must disclose AI-generated content “a bit more realistic.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;But another is a very real concern about what could happen if the rollout of such content-verification technology is done poorly. Lawmakers are demanding tools that can verify what’s real, but the tools are fragile. If labeling systems are rushed out, inconsistently applied, or frequently wrong, people could come to distrust them altogether, and the entire effort would backfire. That’s why the researchers argue that it may be better in some cases to show nothing at all than a verdict that could be wrong.&lt;/p&gt;  &lt;p&gt;Inadequate tools could also create new avenues for what the researchers call sociotechnical attacks. Imagine that someone takes a real image of a fraught political event and uses an AI tool to change only an inconsequential share of pixels in the image. When it spreads online, it could be misleadingly classified by platforms as AI-manipulated. But combining provenance and watermark tools would mean platforms could clarify that the content was only partially AI generated, and point out where the changes were made.&lt;/p&gt;  &lt;p&gt;California’s AI Transparency Act will be the first major test of these tools in the US, but enforcement could be challenged by President Trump’s executive order from late last year seeking to curtail state AI regulations that are “burdensome” to the industry. The administration has also generally taken a posture against efforts to curb disinformation, and last year, via DOGE, it canceled grants related to misinformation. And, of course, official government channels in the Trump administration have shared content manipulated with AI (&lt;em&gt;MIT Technology Review&lt;/em&gt; reported that the Department of Homeland Security, for example, uses video generators from Google and Adobe to make content it shares with the public).&lt;/p&gt;  &lt;p&gt;I asked Horvitz whether fake content from this source worries him as much as that coming from the rest of social media. He initially declined to comment, but then he said, “Governments have not been outside the sectors that have been behind various kinds of manipulative disinformation, and this is worldwide.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/19/1133360/microsoft-has-a-new-plan-to-prove-whats-real-and-whats-ai-online/</guid><pubDate>Thu, 19 Feb 2026 16:00:00 +0000</pubDate></item><item><title>[NEW] Media Authenticity Methods in Practice: Capabilities, Limitations, and Directions (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/blog/media-authenticity-methods-in-practice-capabilities-limitations-and-directions/</link><description>&lt;p&gt;&lt;em&gt;&lt;em&gt;Insights from Microsoft’s Media Integrity and Authentication: Status, Directions, and Futures report&lt;/em&gt;&lt;/em&gt;&lt;/p&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="three white outline icons on a blue-to-pink gradient background: an image with a copyright “CR” badge, an image overlaid with fingerprint-like lines, and an image framed by a cropping grid." class="wp-image-1162625" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/MediaIntegrityReport-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;p&gt;It has become increasingly difficult to distinguish fact from fiction when viewing online images and videos. Resilient, trustworthy technologies can help people determine whether the content they are viewing was captured by a camera or microphone—or generated or modified by AI tools.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We refer to technologies aimed at helping viewers verify the source and history—that is, the provenance—of digital content as &lt;em&gt;media integrity and authentication&lt;/em&gt; (MIA) methods. This technique, driven by the Coalition for Content Provenance and Authenticity&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; (C2PA), a standards body dedicated to scaling these capabilities, as well as complementary methods such as watermarks and fingerprinting, have become critically important with the rapid advance of AI systems capable of creating, realistic imagery, video, and audio at scale.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="a-convergence-of-forces"&gt;A convergence of forces&lt;/h2&gt;



&lt;p&gt;Our team recognized an inflection point in the evolution of online content integrity, driven by the convergence of four forces:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Growing saturation of synthetic media&lt;/strong&gt;, driven by proliferation of high-fidelity content-generation tools and the explosion of AI generated or modified media online&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Forthcoming legislation&lt;/strong&gt; both nationally and internationally seeking to define what “verifiable” provenance should mean in practice&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Mounting pressure on implementers&lt;/strong&gt; to ensure authentication signals are clear and helpful, especially as signals increase when legislation goes into effect in 2026&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Heightened awareness of&amp;nbsp;potential&amp;nbsp;adversarial attacks&lt;/strong&gt; that attempt to exploit weaknesses in authenticity systems&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;The usefulness and trustworthiness of provenance signals, whether certifying content as synthetic or as an authentic capture of real-world scenes, will depend not only on advances in technology, but also on how the broader digital ecosystem adopts, implements, and governs these tools. Aligning around implementation choices that promote consistency and clarity is essential to ensure transparency signals strengthen, rather than erode, public confidence.&lt;/p&gt;



&lt;p&gt;To address these challenges, we launched a comprehensive evaluation of the real-world limits, edge cases, and emerging “attack surfaces” for MIA methods. Today, we are publishing our findings in the &lt;em&gt;Media Integrity &amp;amp; Authentication: Status, Directions &amp;amp; Futures &lt;/em&gt;report. The report distills lessons learned and outlines practical directions for strengthening media integrity in the years ahead.&lt;/p&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;Spotlight: Microsoft research newsletter&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;Microsoft Research Newsletter&lt;/h2&gt;
				
								&lt;p class="large" id="microsoft-research-newsletter"&gt;Stay connected to the research community at Microsoft.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;h2 class="wp-block-heading" id="findings-and-directions-forward"&gt;Findings and directions forward&lt;/h2&gt;



&lt;p&gt;Our research recognizes that different media integrity and authenticity methods serve differing purposes and offer distinct levels of protection. After defining each method in detail, we focused on secure provenance (C2PA), imperceptible watermarking, and soft hash fingerprinting across images, audio, and video.&lt;/p&gt;



&lt;p&gt;Grounded in our evaluation of these MIA methods across modalities, attack categories, and real-world workflows, several new findings emerged including two new concepts:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;High-Confidence Provenance Authentication&lt;/strong&gt;: a&amp;nbsp;critical capability for verifying, under defined conditions, whether claims about the origin of and modifications made to an asset can be&amp;nbsp;validated&amp;nbsp;with high certainty.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Sociotechnical Provenance Attacks&lt;/strong&gt;: attacks aimed at deception and capable of inverting signals, making authentic content appear synthetic, and synthetic content appear authentic.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Drawing on our findings, we identified four promising directions for further strengthening media authentication, along with suggestions to support more effective implementation strategies and future decisions. We’ve summarized the findings and directions below, with additional detail available in the report.&lt;/p&gt;



&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Promising directions&lt;/th&gt;&lt;th&gt;High-level findings&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Delivering high-confidence provenance authentication&lt;/td&gt;&lt;td&gt;– &lt;strong&gt;Implementation and display choices may affect the reliability of provenance indicators&lt;/strong&gt; and how they are interpreted by the public. &lt;p&gt;– Using a C2PA provenance manifest for media created and signed in a high security environment &lt;strong&gt;enables high-confidence validation&lt;/strong&gt;. &lt;/p&gt;&lt;p&gt;– High-confidence validation is also possible across a broader volume of images, audio, and video when &lt;strong&gt;an imperceptible watermark is linked to C2PA provenance manifest as an additional layer to recover the provenance information if removed&lt;/strong&gt;. &lt;/p&gt;&lt;p&gt;– Fingerprinting is &lt;strong&gt;not an enabler for high-confidence validation&lt;/strong&gt; and can involve significant costs when expected at scale. However, it can support manual forensics.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Mitigating confusion from sociotechnical provenance attacks&lt;/td&gt;&lt;td&gt;– &lt;strong&gt;MIA methods are susceptible to sociotechnical attacks on provenance that may mislead the public&lt;/strong&gt;, resulting in confusion and misplaced trust about an asset’s provenance if there is an overreliance on low-quality signals.&lt;p&gt;– Layering and linking secure provenance and imperceptible watermarking methods to achieve high confidence validation also offers a promising option to &lt;strong&gt;both deter and mitigate the impact of attacks&lt;/strong&gt;.&lt;/p&gt;&lt;p&gt;– Unintended consequences may result from the use of methods lacking authentication, such as the use of perceptible watermarks in the absence of secure provenance. &lt;strong&gt;Perceptible watermarks may cause confusion&lt;/strong&gt; in cases of forgery or discourage people from consulting high-confidence provenance information via a validation tool, if such perceptible disclosures are taken at face value.&lt;br /&gt; &lt;br /&gt;– &lt;strong&gt;UX design that enables users to explore manifest details&lt;/strong&gt;—such as where edits occurred&amp;nbsp;or region of interest—has the potential to&amp;nbsp;reduce confusion and&amp;nbsp;support forensics and fact checking efforts.&amp;nbsp;&amp;nbsp;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Enabling more trusted provenance on edge devices&lt;/td&gt;&lt;td&gt;– High-confidence results &lt;strong&gt;aren’t feasible when provenance is added by a conventional offline device&lt;/strong&gt; (e.g., camera or recording device without connectivity).&lt;p&gt;– &lt;strong&gt;Implementing a secure enclave&lt;/strong&gt; within the hardware layer of offline devices is essential to make the provenance of captured images, audio, and video more trustworthy.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Investing in ongoing research and policy development&lt;/td&gt;&lt;td&gt;– All three methods offer organizations&amp;nbsp;&lt;strong&gt;valuable tools for addressing operational challenges&lt;/strong&gt;&amp;nbsp;such as fraud prevention, risk management, and digital accountability.&amp;nbsp;&lt;p&gt;– &lt;strong&gt;UX and display&amp;nbsp;&lt;/strong&gt;are promising directions for research. Important directions include in-stream tools that display provenance information where people are&amp;nbsp;and&amp;nbsp;distinguish&amp;nbsp;between&amp;nbsp;high- and lower-confidence&amp;nbsp;provenance signals.&lt;/p&gt;&lt;p&gt;– &lt;strong&gt;Stakeholders&amp;nbsp;should&amp;nbsp;conduct ongoing analysis and red teaming&lt;/strong&gt;&amp;nbsp;to&amp;nbsp;identify&amp;nbsp;and mitigate weaknesses&amp;nbsp;through&amp;nbsp;technical approaches,&amp;nbsp;policies, and&amp;nbsp;laws.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="the-journey-continues"&gt;The journey continues&lt;/h2&gt;



&lt;p&gt;This report marks the beginning of a new chapter in our media provenance journey&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, building on years of foundational work, from developing the very first prototype in 2019 to co-founding the C2PA in 2021 and helping catalyze an ecosystem that has since grown to more than 6,000 members and affiliates&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; supporting C2PA Content Credentials. This research represents the next evolution of that long‑standing commitment.&lt;/p&gt;



&lt;p&gt;We hope that by sharing our learnings will help others prepare for an important wave, especially as generative technologies accelerate and provenance signals multiply. This work is already underway across our products at Microsoft. Together, these directions highlight opportunities for the ecosystem to align, harden, and innovate, so authentication signals are not merely visible, but robust, meaningful, and resilient throughout the content lifecycle.&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;p&gt;&lt;em&gt;&lt;em&gt;Insights from Microsoft’s Media Integrity and Authentication: Status, Directions, and Futures report&lt;/em&gt;&lt;/em&gt;&lt;/p&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="three white outline icons on a blue-to-pink gradient background: an image with a copyright “CR” badge, an image overlaid with fingerprint-like lines, and an image framed by a cropping grid." class="wp-image-1162625" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/MediaIntegrityReport-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;p&gt;It has become increasingly difficult to distinguish fact from fiction when viewing online images and videos. Resilient, trustworthy technologies can help people determine whether the content they are viewing was captured by a camera or microphone—or generated or modified by AI tools.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We refer to technologies aimed at helping viewers verify the source and history—that is, the provenance—of digital content as &lt;em&gt;media integrity and authentication&lt;/em&gt; (MIA) methods. This technique, driven by the Coalition for Content Provenance and Authenticity&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; (C2PA), a standards body dedicated to scaling these capabilities, as well as complementary methods such as watermarks and fingerprinting, have become critically important with the rapid advance of AI systems capable of creating, realistic imagery, video, and audio at scale.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="a-convergence-of-forces"&gt;A convergence of forces&lt;/h2&gt;



&lt;p&gt;Our team recognized an inflection point in the evolution of online content integrity, driven by the convergence of four forces:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Growing saturation of synthetic media&lt;/strong&gt;, driven by proliferation of high-fidelity content-generation tools and the explosion of AI generated or modified media online&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Forthcoming legislation&lt;/strong&gt; both nationally and internationally seeking to define what “verifiable” provenance should mean in practice&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Mounting pressure on implementers&lt;/strong&gt; to ensure authentication signals are clear and helpful, especially as signals increase when legislation goes into effect in 2026&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Heightened awareness of&amp;nbsp;potential&amp;nbsp;adversarial attacks&lt;/strong&gt; that attempt to exploit weaknesses in authenticity systems&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;The usefulness and trustworthiness of provenance signals, whether certifying content as synthetic or as an authentic capture of real-world scenes, will depend not only on advances in technology, but also on how the broader digital ecosystem adopts, implements, and governs these tools. Aligning around implementation choices that promote consistency and clarity is essential to ensure transparency signals strengthen, rather than erode, public confidence.&lt;/p&gt;



&lt;p&gt;To address these challenges, we launched a comprehensive evaluation of the real-world limits, edge cases, and emerging “attack surfaces” for MIA methods. Today, we are publishing our findings in the &lt;em&gt;Media Integrity &amp;amp; Authentication: Status, Directions &amp;amp; Futures &lt;/em&gt;report. The report distills lessons learned and outlines practical directions for strengthening media integrity in the years ahead.&lt;/p&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;Spotlight: Microsoft research newsletter&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;Microsoft Research Newsletter&lt;/h2&gt;
				
								&lt;p class="large" id="microsoft-research-newsletter"&gt;Stay connected to the research community at Microsoft.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;h2 class="wp-block-heading" id="findings-and-directions-forward"&gt;Findings and directions forward&lt;/h2&gt;



&lt;p&gt;Our research recognizes that different media integrity and authenticity methods serve differing purposes and offer distinct levels of protection. After defining each method in detail, we focused on secure provenance (C2PA), imperceptible watermarking, and soft hash fingerprinting across images, audio, and video.&lt;/p&gt;



&lt;p&gt;Grounded in our evaluation of these MIA methods across modalities, attack categories, and real-world workflows, several new findings emerged including two new concepts:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;High-Confidence Provenance Authentication&lt;/strong&gt;: a&amp;nbsp;critical capability for verifying, under defined conditions, whether claims about the origin of and modifications made to an asset can be&amp;nbsp;validated&amp;nbsp;with high certainty.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Sociotechnical Provenance Attacks&lt;/strong&gt;: attacks aimed at deception and capable of inverting signals, making authentic content appear synthetic, and synthetic content appear authentic.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Drawing on our findings, we identified four promising directions for further strengthening media authentication, along with suggestions to support more effective implementation strategies and future decisions. We’ve summarized the findings and directions below, with additional detail available in the report.&lt;/p&gt;



&lt;figure class="wp-block-table"&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Promising directions&lt;/th&gt;&lt;th&gt;High-level findings&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Delivering high-confidence provenance authentication&lt;/td&gt;&lt;td&gt;– &lt;strong&gt;Implementation and display choices may affect the reliability of provenance indicators&lt;/strong&gt; and how they are interpreted by the public. &lt;p&gt;– Using a C2PA provenance manifest for media created and signed in a high security environment &lt;strong&gt;enables high-confidence validation&lt;/strong&gt;. &lt;/p&gt;&lt;p&gt;– High-confidence validation is also possible across a broader volume of images, audio, and video when &lt;strong&gt;an imperceptible watermark is linked to C2PA provenance manifest as an additional layer to recover the provenance information if removed&lt;/strong&gt;. &lt;/p&gt;&lt;p&gt;– Fingerprinting is &lt;strong&gt;not an enabler for high-confidence validation&lt;/strong&gt; and can involve significant costs when expected at scale. However, it can support manual forensics.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Mitigating confusion from sociotechnical provenance attacks&lt;/td&gt;&lt;td&gt;– &lt;strong&gt;MIA methods are susceptible to sociotechnical attacks on provenance that may mislead the public&lt;/strong&gt;, resulting in confusion and misplaced trust about an asset’s provenance if there is an overreliance on low-quality signals.&lt;p&gt;– Layering and linking secure provenance and imperceptible watermarking methods to achieve high confidence validation also offers a promising option to &lt;strong&gt;both deter and mitigate the impact of attacks&lt;/strong&gt;.&lt;/p&gt;&lt;p&gt;– Unintended consequences may result from the use of methods lacking authentication, such as the use of perceptible watermarks in the absence of secure provenance. &lt;strong&gt;Perceptible watermarks may cause confusion&lt;/strong&gt; in cases of forgery or discourage people from consulting high-confidence provenance information via a validation tool, if such perceptible disclosures are taken at face value.&lt;br /&gt; &lt;br /&gt;– &lt;strong&gt;UX design that enables users to explore manifest details&lt;/strong&gt;—such as where edits occurred&amp;nbsp;or region of interest—has the potential to&amp;nbsp;reduce confusion and&amp;nbsp;support forensics and fact checking efforts.&amp;nbsp;&amp;nbsp;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Enabling more trusted provenance on edge devices&lt;/td&gt;&lt;td&gt;– High-confidence results &lt;strong&gt;aren’t feasible when provenance is added by a conventional offline device&lt;/strong&gt; (e.g., camera or recording device without connectivity).&lt;p&gt;– &lt;strong&gt;Implementing a secure enclave&lt;/strong&gt; within the hardware layer of offline devices is essential to make the provenance of captured images, audio, and video more trustworthy.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Investing in ongoing research and policy development&lt;/td&gt;&lt;td&gt;– All three methods offer organizations&amp;nbsp;&lt;strong&gt;valuable tools for addressing operational challenges&lt;/strong&gt;&amp;nbsp;such as fraud prevention, risk management, and digital accountability.&amp;nbsp;&lt;p&gt;– &lt;strong&gt;UX and display&amp;nbsp;&lt;/strong&gt;are promising directions for research. Important directions include in-stream tools that display provenance information where people are&amp;nbsp;and&amp;nbsp;distinguish&amp;nbsp;between&amp;nbsp;high- and lower-confidence&amp;nbsp;provenance signals.&lt;/p&gt;&lt;p&gt;– &lt;strong&gt;Stakeholders&amp;nbsp;should&amp;nbsp;conduct ongoing analysis and red teaming&lt;/strong&gt;&amp;nbsp;to&amp;nbsp;identify&amp;nbsp;and mitigate weaknesses&amp;nbsp;through&amp;nbsp;technical approaches,&amp;nbsp;policies, and&amp;nbsp;laws.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="the-journey-continues"&gt;The journey continues&lt;/h2&gt;



&lt;p&gt;This report marks the beginning of a new chapter in our media provenance journey&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, building on years of foundational work, from developing the very first prototype in 2019 to co-founding the C2PA in 2021 and helping catalyze an ecosystem that has since grown to more than 6,000 members and affiliates&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; supporting C2PA Content Credentials. This research represents the next evolution of that long‑standing commitment.&lt;/p&gt;



&lt;p&gt;We hope that by sharing our learnings will help others prepare for an important wave, especially as generative technologies accelerate and provenance signals multiply. This work is already underway across our products at Microsoft. Together, these directions highlight opportunities for the ecosystem to align, harden, and innovate, so authentication signals are not merely visible, but robust, meaningful, and resilient throughout the content lifecycle.&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/blog/media-authenticity-methods-in-practice-capabilities-limitations-and-directions/</guid><pubDate>Thu, 19 Feb 2026 16:00:51 +0000</pubDate></item><item><title>[NEW] Gemini 3.1 Pro: A smarter model for your most complex tasks (Google DeepMind News)</title><link>https://deepmind.google/blog/gemini-3-1-pro-a-smarter-model-for-your-most-complex-tasks/</link><description>&lt;div class="article-image-hero"&gt;
  &lt;div class="article-image-hero__container"&gt;
    &lt;figure class="article-image--full-aspect article-module"&gt;
      &lt;div class="aspect-ratio-image"&gt;
        &lt;div class="aspect-ratio-image__container"&gt;
          &lt;img alt="Gemini 3.1 Pro" class="aspect-ratio-image__image uni-progressive-image--blur" height="150px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3.1_pro_keyword_header_dar.width-2200.format-webp.webp" width="360px" /&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      
    &lt;/figure&gt;
  &lt;/div&gt;
&lt;/div&gt;&lt;div class="uni-content uni-blog-article-container article-container__content
                      
                      "&gt;

            
  
    



















&lt;div class="audio-player-tts"&gt;
  &lt;audio class="audio-player-tts__player" title="Gemini 3.1 Pro: A smarter model for your most complex tasks"&gt;
      &lt;source src="https://storage.googleapis.com/gweb-uniblog-publish-prod/media/tts_audio_83397_umbriel_2026_02_19_17_33_43.wav" type="audio/x-wav" /&gt;
      &lt;p&gt;Your browser does not support the audio element.&lt;/p&gt;
  &lt;/audio&gt;
  &lt;div class="audio-player-tts__container"&gt;
    &lt;div class="audio-player-tts__content"&gt;
      &lt;button class="audio-player-tts__preview-play"&gt;
        &lt;svg class="icon audio-player-tts__play-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

      &lt;/button&gt;
      &lt;div class="audio-player-tts__text-content"&gt;
        &lt;span class="audio-player-tts__text-content--title"&gt;
          Listen to article
          &lt;span class="audio-player-tts__disclaimer" tabindex="0"&gt;
            &lt;div class="audio-player-tts__disclaimer--copy uni-small-text"&gt;This content is generated by Google AI. Generative AI is experimental&lt;/div&gt;
            &lt;svg class="audio-player-tts__disclaimer--icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

          &lt;/span&gt;
        &lt;/span&gt;
        &lt;div class="audio-player-tts__duration uni-small-text"&gt;[[duration]] minutes&lt;/div&gt;
      &lt;/div&gt;
      &lt;button class="audio-player-tts__pause"&gt;
        &lt;svg class="icon audio-player-tts__icon-play" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

        &lt;svg class="icon audio-player-tts__icon-pause audio-player-tts__icon-pause--hidden" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

      &lt;/button&gt;
      &lt;div class="audio-player-tts__console"&gt;
        &lt;div class="audio-player-tts__time-bar"&gt;
          &lt;span class="audio-player-tts__current-time uni-small-text"&gt;&lt;/span&gt;
          &lt;div class="audio-player-tts__timeline-slider-container"&gt;
            &lt;input class="timeline__slider" max="100" step="5" tabindex="0" type="range" value="0" /&gt;
          &lt;/div&gt;
          &lt;span class="audio-player-tts__duration-time uni-small-text"&gt;&lt;/span&gt;
        &lt;/div&gt;
        &lt;button class="audio-player-tts__audio-settings"&gt;
          &lt;svg class="icon audio-player-tts__audio-settings--icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

        &lt;/button&gt;
        &lt;div class="audio-player-tts__settings-container"&gt;
          &lt;div class="audio-player-tts__settings--main uni-cta-text"&gt;
            &lt;button class="audio-player-tts__settings--current-voice"&gt;
              &lt;span class="audio-player-tts__settings--current-voice-info"&gt;
                &lt;svg class="audio-player-tts__settings--current-voice-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

                &lt;span&gt;Voice&lt;/span&gt;
              &lt;/span&gt;
              &lt;span class="audio-player-tts__settings--current-voice-next"&gt;
                &lt;span class="audio-player-tts__settings--current-voice-text uni-small-text"&gt;&lt;/span&gt;
                &lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

              &lt;/span&gt;
            &lt;/button&gt;
            &lt;button class="audio-player-tts__settings--current-speed"&gt;
              &lt;span class="audio-player-tts__settings--current-speed-info"&gt;
                  &lt;svg class="audio-player-tts__settings--current-speed-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

                  &lt;span&gt;Speed&lt;/span&gt;
                &lt;/span&gt;
                &lt;span class="audio-player-tts__settings--current-speed-next"&gt;
                  &lt;span class="audio-player-tts__settings--current-speed-text uni-small-text"&gt;&lt;/span&gt;
                  &lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

                &lt;/span&gt;
            &lt;/button&gt;
          &lt;/div&gt;
          &lt;div class="audio-player-tts__settings--voices uni-cta-text"&gt;
            &lt;button class="audio-player-tts__settings-back"&gt;&lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;
 &lt;span&gt;Voice&lt;/span&gt;&lt;/button&gt;
          &lt;/div&gt;
          &lt;div class="audio-player-tts__settings--speeds uni-cta-text"&gt;
            &lt;button class="audio-player-tts__settings-back"&gt;&lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;
 &lt;span&gt;Speed&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option"&gt;&lt;span&gt;0.75X&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option audio-player-tts__settings-option--selected"&gt;&lt;span&gt;1X&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option"&gt;&lt;span&gt;1.5X&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option"&gt;&lt;span&gt;2X&lt;/span&gt;&lt;/button&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

  





            
            
&lt;!--article text--&gt;

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Last week, we released a major update to Gemini 3 Deep Think to solve modern challenges across science, research and engineering. Today, we’re releasing the upgraded core intelligence that makes those breakthroughs possible: Gemini 3.1 Pro. We are shipping 3.1 Pro across our consumer and developer products to bring this progress in intelligence to your everyday applications.&lt;/p&gt;&lt;p&gt;Starting today, 3.1 Pro is rolling out:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;For developers&lt;/b&gt; in preview via the Gemini API in Google AI Studio, Gemini CLI, our agentic development platform Google Antigravity and Android Studio&lt;/li&gt;&lt;li&gt;&lt;b&gt;For enterprises&lt;/b&gt; in Vertex AI and Gemini Enterprise&lt;/li&gt;&lt;li&gt;&lt;b&gt;For consumers&lt;/b&gt; via the Gemini app and NotebookLM&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Building on the Gemini 3 series, 3.1 Pro represents a step forward in core reasoning. 3.1 Pro is a smarter, more capable baseline for complex problem-solving. This is reflected in our progress on rigorous benchmarks. On ARC-AGI-2, a benchmark that evaluates a model’s ability to solve entirely new logic patterns, 3.1 Pro achieved a verified score of 77.1%. This is more than double the reasoning performance of 3 Pro.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    






























  
  
    &lt;div&gt;
      &lt;img alt="Side-by-side comparison of different benchmarks for AI models." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/gemini_3-1-pro__benchmarks.gif" /&gt;
    &lt;/div&gt;
  



  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Intelligence applied&lt;/h2&gt;&lt;p&gt;3.1 Pro is designed for tasks where a simple answer isn’t enough, taking advanced reasoning and making it useful for your hardest challenges. This improved intelligence can help in practical applications — whether you’re looking for a clear, visual explanation of a complex topic, a way to synthesize data into a single view, or bringing a creative project to life.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    


































  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Code-based animation: 3.1 Pro can generate website-ready, animated SVGs directly from a text prompt. Because these are built in pure code rather than pixels, they remain crisp at any scale and maintain incredibly small file sizes compared to traditional video.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Complex system synthesis: 3.1 Pro utilizes advanced reasoning to bridge the gap between complex APIs and user-friendly design. In this example, the model built a live aerospace dashboard, successfully configuring a public telemetry stream to visualize the International Space Station’s orbit.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Interactive design: 3.1 Pro codes a complex 3D starling murmuration. It doesn't just generate the visual code; it builds an immersive experience where users can manipulate the flock with hand-tracking and listen to a generative score that shifts based on the birds’ movement. For researchers and designers, this provides a powerful way to prototype sensory-rich interfaces.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Creative coding: 3.1 Pro can translate literary themes into functional code. When prompted to build a modern personal portfolio for Emily Brontë’s "Wuthering Heights," the model didn’t just summarize the text. It reasoned through the novel’s atmospheric tone to design a sleek, contemporary interface, creating a website that captures the essence of the protagonist.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;What’s next&lt;/h2&gt;&lt;p&gt;Since releasing Gemini 3 Pro in November, your feedback and the pace of progress have driven these rapid improvements. We are releasing 3.1 Pro in preview today to validate these updates and continue to make further advancements in areas such as ambitious agentic workflows before we make it generally available soon.&lt;/p&gt;&lt;p&gt;Starting today, Gemini 3.1 Pro in the Gemini app is rolling out with higher limits for users with the Google AI Pro and Ultra plans. 3.1 Pro is also now available on NotebookLM exclusively for Pro and Ultra users. And developers and enterprises can access 3.1 Pro now in preview in the Gemini API via AI Studio, Antigravity, Vertex AI, Gemini Enterprise, Gemini CLI and Android Studio.&lt;/p&gt;&lt;p&gt;We can’t wait to see what you build and discover with it.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  


            
            

            
              


&lt;div class="
    uni-blog-article-tags
    article-tags
    
  "&gt;
  &lt;div class="uni-blog-article-tags__wrapper"&gt;
    &lt;span class="uni-blog-article-tags__label uni-eyebrow"&gt;POSTED IN:&lt;/span&gt;
  &lt;/div&gt;
  &lt;nav class="uni-blog-article-tags__container uni-click-tracker"&gt;
    &lt;ul class="uni-blog-article-tags__tags-list"&gt;
    
      &lt;li&gt;
        
        
        


  


Gemini models


  


      &lt;/li&gt;
    

    
    &lt;/ul&gt;
  &lt;/nav&gt;
&lt;/div&gt;

            
          &lt;/div&gt;</description><content:encoded>&lt;div class="article-image-hero"&gt;
  &lt;div class="article-image-hero__container"&gt;
    &lt;figure class="article-image--full-aspect article-module"&gt;
      &lt;div class="aspect-ratio-image"&gt;
        &lt;div class="aspect-ratio-image__container"&gt;
          &lt;img alt="Gemini 3.1 Pro" class="aspect-ratio-image__image uni-progressive-image--blur" height="150px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3.1_pro_keyword_header_dar.width-2200.format-webp.webp" width="360px" /&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      
    &lt;/figure&gt;
  &lt;/div&gt;
&lt;/div&gt;&lt;div class="uni-content uni-blog-article-container article-container__content
                      
                      "&gt;

            
  
    



















&lt;div class="audio-player-tts"&gt;
  &lt;audio class="audio-player-tts__player" title="Gemini 3.1 Pro: A smarter model for your most complex tasks"&gt;
      &lt;source src="https://storage.googleapis.com/gweb-uniblog-publish-prod/media/tts_audio_83397_umbriel_2026_02_19_17_33_43.wav" type="audio/x-wav" /&gt;
      &lt;p&gt;Your browser does not support the audio element.&lt;/p&gt;
  &lt;/audio&gt;
  &lt;div class="audio-player-tts__container"&gt;
    &lt;div class="audio-player-tts__content"&gt;
      &lt;button class="audio-player-tts__preview-play"&gt;
        &lt;svg class="icon audio-player-tts__play-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

      &lt;/button&gt;
      &lt;div class="audio-player-tts__text-content"&gt;
        &lt;span class="audio-player-tts__text-content--title"&gt;
          Listen to article
          &lt;span class="audio-player-tts__disclaimer" tabindex="0"&gt;
            &lt;div class="audio-player-tts__disclaimer--copy uni-small-text"&gt;This content is generated by Google AI. Generative AI is experimental&lt;/div&gt;
            &lt;svg class="audio-player-tts__disclaimer--icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

          &lt;/span&gt;
        &lt;/span&gt;
        &lt;div class="audio-player-tts__duration uni-small-text"&gt;[[duration]] minutes&lt;/div&gt;
      &lt;/div&gt;
      &lt;button class="audio-player-tts__pause"&gt;
        &lt;svg class="icon audio-player-tts__icon-play" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

        &lt;svg class="icon audio-player-tts__icon-pause audio-player-tts__icon-pause--hidden" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

      &lt;/button&gt;
      &lt;div class="audio-player-tts__console"&gt;
        &lt;div class="audio-player-tts__time-bar"&gt;
          &lt;span class="audio-player-tts__current-time uni-small-text"&gt;&lt;/span&gt;
          &lt;div class="audio-player-tts__timeline-slider-container"&gt;
            &lt;input class="timeline__slider" max="100" step="5" tabindex="0" type="range" value="0" /&gt;
          &lt;/div&gt;
          &lt;span class="audio-player-tts__duration-time uni-small-text"&gt;&lt;/span&gt;
        &lt;/div&gt;
        &lt;button class="audio-player-tts__audio-settings"&gt;
          &lt;svg class="icon audio-player-tts__audio-settings--icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

        &lt;/button&gt;
        &lt;div class="audio-player-tts__settings-container"&gt;
          &lt;div class="audio-player-tts__settings--main uni-cta-text"&gt;
            &lt;button class="audio-player-tts__settings--current-voice"&gt;
              &lt;span class="audio-player-tts__settings--current-voice-info"&gt;
                &lt;svg class="audio-player-tts__settings--current-voice-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

                &lt;span&gt;Voice&lt;/span&gt;
              &lt;/span&gt;
              &lt;span class="audio-player-tts__settings--current-voice-next"&gt;
                &lt;span class="audio-player-tts__settings--current-voice-text uni-small-text"&gt;&lt;/span&gt;
                &lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

              &lt;/span&gt;
            &lt;/button&gt;
            &lt;button class="audio-player-tts__settings--current-speed"&gt;
              &lt;span class="audio-player-tts__settings--current-speed-info"&gt;
                  &lt;svg class="audio-player-tts__settings--current-speed-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

                  &lt;span&gt;Speed&lt;/span&gt;
                &lt;/span&gt;
                &lt;span class="audio-player-tts__settings--current-speed-next"&gt;
                  &lt;span class="audio-player-tts__settings--current-speed-text uni-small-text"&gt;&lt;/span&gt;
                  &lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

                &lt;/span&gt;
            &lt;/button&gt;
          &lt;/div&gt;
          &lt;div class="audio-player-tts__settings--voices uni-cta-text"&gt;
            &lt;button class="audio-player-tts__settings-back"&gt;&lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;
 &lt;span&gt;Voice&lt;/span&gt;&lt;/button&gt;
          &lt;/div&gt;
          &lt;div class="audio-player-tts__settings--speeds uni-cta-text"&gt;
            &lt;button class="audio-player-tts__settings-back"&gt;&lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;
 &lt;span&gt;Speed&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option"&gt;&lt;span&gt;0.75X&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option audio-player-tts__settings-option--selected"&gt;&lt;span&gt;1X&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option"&gt;&lt;span&gt;1.5X&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option"&gt;&lt;span&gt;2X&lt;/span&gt;&lt;/button&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

  





            
            
&lt;!--article text--&gt;

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Last week, we released a major update to Gemini 3 Deep Think to solve modern challenges across science, research and engineering. Today, we’re releasing the upgraded core intelligence that makes those breakthroughs possible: Gemini 3.1 Pro. We are shipping 3.1 Pro across our consumer and developer products to bring this progress in intelligence to your everyday applications.&lt;/p&gt;&lt;p&gt;Starting today, 3.1 Pro is rolling out:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;For developers&lt;/b&gt; in preview via the Gemini API in Google AI Studio, Gemini CLI, our agentic development platform Google Antigravity and Android Studio&lt;/li&gt;&lt;li&gt;&lt;b&gt;For enterprises&lt;/b&gt; in Vertex AI and Gemini Enterprise&lt;/li&gt;&lt;li&gt;&lt;b&gt;For consumers&lt;/b&gt; via the Gemini app and NotebookLM&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Building on the Gemini 3 series, 3.1 Pro represents a step forward in core reasoning. 3.1 Pro is a smarter, more capable baseline for complex problem-solving. This is reflected in our progress on rigorous benchmarks. On ARC-AGI-2, a benchmark that evaluates a model’s ability to solve entirely new logic patterns, 3.1 Pro achieved a verified score of 77.1%. This is more than double the reasoning performance of 3 Pro.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    






























  
  
    &lt;div&gt;
      &lt;img alt="Side-by-side comparison of different benchmarks for AI models." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/gemini_3-1-pro__benchmarks.gif" /&gt;
    &lt;/div&gt;
  



  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Intelligence applied&lt;/h2&gt;&lt;p&gt;3.1 Pro is designed for tasks where a simple answer isn’t enough, taking advanced reasoning and making it useful for your hardest challenges. This improved intelligence can help in practical applications — whether you’re looking for a clear, visual explanation of a complex topic, a way to synthesize data into a single view, or bringing a creative project to life.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    


































  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Code-based animation: 3.1 Pro can generate website-ready, animated SVGs directly from a text prompt. Because these are built in pure code rather than pixels, they remain crisp at any scale and maintain incredibly small file sizes compared to traditional video.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Complex system synthesis: 3.1 Pro utilizes advanced reasoning to bridge the gap between complex APIs and user-friendly design. In this example, the model built a live aerospace dashboard, successfully configuring a public telemetry stream to visualize the International Space Station’s orbit.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Interactive design: 3.1 Pro codes a complex 3D starling murmuration. It doesn't just generate the visual code; it builds an immersive experience where users can manipulate the flock with hand-tracking and listen to a generative score that shifts based on the birds’ movement. For researchers and designers, this provides a powerful way to prototype sensory-rich interfaces.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Creative coding: 3.1 Pro can translate literary themes into functional code. When prompted to build a modern personal portfolio for Emily Brontë’s "Wuthering Heights," the model didn’t just summarize the text. It reasoned through the novel’s atmospheric tone to design a sleek, contemporary interface, creating a website that captures the essence of the protagonist.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;What’s next&lt;/h2&gt;&lt;p&gt;Since releasing Gemini 3 Pro in November, your feedback and the pace of progress have driven these rapid improvements. We are releasing 3.1 Pro in preview today to validate these updates and continue to make further advancements in areas such as ambitious agentic workflows before we make it generally available soon.&lt;/p&gt;&lt;p&gt;Starting today, Gemini 3.1 Pro in the Gemini app is rolling out with higher limits for users with the Google AI Pro and Ultra plans. 3.1 Pro is also now available on NotebookLM exclusively for Pro and Ultra users. And developers and enterprises can access 3.1 Pro now in preview in the Gemini API via AI Studio, Antigravity, Vertex AI, Gemini Enterprise, Gemini CLI and Android Studio.&lt;/p&gt;&lt;p&gt;We can’t wait to see what you build and discover with it.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  


            
            

            
              


&lt;div class="
    uni-blog-article-tags
    article-tags
    
  "&gt;
  &lt;div class="uni-blog-article-tags__wrapper"&gt;
    &lt;span class="uni-blog-article-tags__label uni-eyebrow"&gt;POSTED IN:&lt;/span&gt;
  &lt;/div&gt;
  &lt;nav class="uni-blog-article-tags__container uni-click-tracker"&gt;
    &lt;ul class="uni-blog-article-tags__tags-list"&gt;
    
      &lt;li&gt;
        
        
        


  


Gemini models


  


      &lt;/li&gt;
    

    
    &lt;/ul&gt;
  &lt;/nav&gt;
&lt;/div&gt;

            
          &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://deepmind.google/blog/gemini-3-1-pro-a-smarter-model-for-your-most-complex-tasks/</guid><pubDate>Thu, 19 Feb 2026 16:06:14 +0000</pubDate></item><item><title>[NEW] Google announces Gemini 3.1 Pro, says it's better at complex problem-solving (AI - Ars Technica)</title><link>https://arstechnica.com/google/2026/02/google-announces-gemini-3-1-pro-says-its-better-at-complex-problem-solving/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google says 3.1 Pro is ready for “your hardest challenges.”
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="3.1 Pro hero image" class="absolute inset-0 w-full h-full object-cover hidden" height="361" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/gemini-3.1_pro-640x361.png" width="640" /&gt;
                  &lt;img alt="3.1 Pro hero image" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/gemini-3.1_pro-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Another day, another Google AI model. Google has really been pumping out new AI tools lately, having just released Gemini 3 in November. Today, it’s bumping the flagship model to version 3.1. The new Gemini 3.1 Pro is rolling out (in preview) for developers and consumers today with the promise of better problem-solving and reasoning capabilities.&lt;/p&gt;
&lt;p&gt;Google announced improvements to its Deep Think tool last week, and apparently, the “core intelligence” behind that update was Gemini 3.1 Pro. As usual, Google’s latest model announcement comes with a plethora of benchmarks that show mostly modest improvements. In the popular Humanity’s Last Exam, which tests advanced domain-specific knowledge, Gemini 3.1 Pro scored a record 44.4 percent. Gemini 3 Pro managed 37.5 percent, while OpenAI’s GPT 5.2 got 34.5 percent.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2141672 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="Gemini 3.1 Pro benchmarks" class="fullwidth full" height="2568" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/gemini_3-1-pro__benchmarks.png" width="3000" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Google also calls out the model’s improvement in ARC-AGI-2, which features novel logic problems that can’t be directly trained into an AI. Gemini 3 was a bit behind on this evaluation, reaching a mere 31.1 percent versus scores in the 50s and 60s for competing models. Gemini 3.1 Pro more than doubles Google’s score, reaching a lofty 77.1 percent.&lt;/p&gt;
&lt;p&gt;Google has often gloated when it releases new models that they’ve already hit the top of the Arena leaderboard (formerly LM Arena), but that’s not the case this time. For text, Claude Opus 4.6 edges out the new Gemini by four points at 1504. For code, Opus 4.6, Opus 4.5, and GPT 5.2 High all run ahead of Gemini 3.1 Pro by a bit more. It’s worth noting, however, that the Arena leaderboard is run on vibes. Users vote on the outputs they like best, which can reward outputs that look correct regardless of whether they are.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1440" id="video-2141670-1" preload="metadata" width="2560"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/SVGs_keyword_v3.mp4?_=1" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;To demonstrate the improvements in Gemini 3.1 Pro, Google focused on the model’s ability to generate graphics and simulations. The example SVGs shown in the comparison video above do seem much more elegant, but these are the examples Google has chosen to show. Big benchmark numbers and curated demos are all well and good, but will you feel any difference when using the model? If you’re asking abstract questions and expecting detailed, nuanced answers, Gemini 3.1 Pro will &lt;em&gt;probably&lt;/em&gt; produce better outputs than 3.0. Developers using Gemini to create agentic workflows are likely to see an improvement—Gemini 3.1 Pro almost doubled its score in the APEX-Agents benchmark.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2141670-2" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Mumuration_SIM_v2_SMALL.mp4?_=2" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The updated model is coming to AI Studio and the Antigravity IDE in preview today. Enterprise users will see 3.1 Pro in Vertex AI and Gemini Enterprise. For regular users, Gemini 3.1 Pro is available for both the Gemini app and NotebookLM today. The API cost for developers has not changed ($2 input and $12 output per 1M tokens), nor has the context window (1M input and 64k output tokens). If Google’s pattern holds, there will most likely be a 3.1 update for its faster and cheaper Flash model in the near future.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google says 3.1 Pro is ready for “your hardest challenges.”
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="3.1 Pro hero image" class="absolute inset-0 w-full h-full object-cover hidden" height="361" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/gemini-3.1_pro-640x361.png" width="640" /&gt;
                  &lt;img alt="3.1 Pro hero image" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/gemini-3.1_pro-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Another day, another Google AI model. Google has really been pumping out new AI tools lately, having just released Gemini 3 in November. Today, it’s bumping the flagship model to version 3.1. The new Gemini 3.1 Pro is rolling out (in preview) for developers and consumers today with the promise of better problem-solving and reasoning capabilities.&lt;/p&gt;
&lt;p&gt;Google announced improvements to its Deep Think tool last week, and apparently, the “core intelligence” behind that update was Gemini 3.1 Pro. As usual, Google’s latest model announcement comes with a plethora of benchmarks that show mostly modest improvements. In the popular Humanity’s Last Exam, which tests advanced domain-specific knowledge, Gemini 3.1 Pro scored a record 44.4 percent. Gemini 3 Pro managed 37.5 percent, while OpenAI’s GPT 5.2 got 34.5 percent.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2141672 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="Gemini 3.1 Pro benchmarks" class="fullwidth full" height="2568" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/gemini_3-1-pro__benchmarks.png" width="3000" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Google also calls out the model’s improvement in ARC-AGI-2, which features novel logic problems that can’t be directly trained into an AI. Gemini 3 was a bit behind on this evaluation, reaching a mere 31.1 percent versus scores in the 50s and 60s for competing models. Gemini 3.1 Pro more than doubles Google’s score, reaching a lofty 77.1 percent.&lt;/p&gt;
&lt;p&gt;Google has often gloated when it releases new models that they’ve already hit the top of the Arena leaderboard (formerly LM Arena), but that’s not the case this time. For text, Claude Opus 4.6 edges out the new Gemini by four points at 1504. For code, Opus 4.6, Opus 4.5, and GPT 5.2 High all run ahead of Gemini 3.1 Pro by a bit more. It’s worth noting, however, that the Arena leaderboard is run on vibes. Users vote on the outputs they like best, which can reward outputs that look correct regardless of whether they are.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1440" id="video-2141670-1" preload="metadata" width="2560"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/SVGs_keyword_v3.mp4?_=1" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;To demonstrate the improvements in Gemini 3.1 Pro, Google focused on the model’s ability to generate graphics and simulations. The example SVGs shown in the comparison video above do seem much more elegant, but these are the examples Google has chosen to show. Big benchmark numbers and curated demos are all well and good, but will you feel any difference when using the model? If you’re asking abstract questions and expecting detailed, nuanced answers, Gemini 3.1 Pro will &lt;em&gt;probably&lt;/em&gt; produce better outputs than 3.0. Developers using Gemini to create agentic workflows are likely to see an improvement—Gemini 3.1 Pro almost doubled its score in the APEX-Agents benchmark.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2141670-2" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Mumuration_SIM_v2_SMALL.mp4?_=2" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The updated model is coming to AI Studio and the Antigravity IDE in preview today. Enterprise users will see 3.1 Pro in Vertex AI and Gemini Enterprise. For regular users, Gemini 3.1 Pro is available for both the Gemini app and NotebookLM today. The API cost for developers has not changed ($2 input and $12 output per 1M tokens), nor has the context window (1M input and 64k output tokens). If Google’s pattern holds, there will most likely be a 3.1 update for its faster and cheaper Flash model in the near future.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/google/2026/02/google-announces-gemini-3-1-pro-says-its-better-at-complex-problem-solving/</guid><pubDate>Thu, 19 Feb 2026 17:42:14 +0000</pubDate></item><item><title>[NEW] Reddit is testing a new AI search feature for shopping (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/19/reddit-is-testing-a-new-ai-search-feature-for-shopping/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/02/reddit-ipo-v2.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Reddit announced on Thursday that it’s testing a new AI search tool that takes community recommendations and matches them with products from some of the company’s shopping and advertising partners. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A small group of users in the U.S. will start to see search results that include interactive product carousels with pricing, images, and direct where-to-buy links.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The announcement reflects Reddit’s broader push to combine its community-driven platform with e-commerce capabilities. The move comes as Reddit launched its first shoppable ad product last year, called Dynamic Product Ads (DPA), which display personalized product recommendations to users based on their interests.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now, when users who are part of the test search for something like “best noise-canceling headphones” or “electronic gift ideas for a college student,” they will see a carousel of related products at the bottom of the results. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This carousel will feature products directly mentioned by users from conversations on related posts and comments. If users tap on the product, they can view more details and then be directed to the retailer to purchase the item. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This feature surfaces top-recommended products directly from discussions, giving redditors instant information about any product,” the company wrote in a blog post. “This test is designed to make Reddit easier to navigate while keeping community perspectives at the center of the experience. We’ll continue learning from how people use this new feature and refine the experience over time.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While platforms like TikTok and Instagram have long integrated shopping features, Reddit is now looking to follow suit. Of course, Reddit isn’t the only tech platform that recently started exploring AI-driven shopping, as OpenAI’s ChatGPT rolled out an “Instant Checkout” feature last September that lets users make&amp;nbsp;Etsy and Shopify&amp;nbsp;purchases within conversations. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Thursday’s announcement comes after Reddit CEO Steve Huffman said during the company’s earnings release last week that the platforms’s AI search engine could be the next big opportunity for its business, not just in terms of product, but also as a revenue driver.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Huffman also noted that weekly active users for search grew 30% over the past year, increasing from 60 million to 80 million, while weekly active users for the AI-powered Reddit Answers feature rose from 1 million in the first quarter of 2025 to 15 million by the fourth quarter.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/02/reddit-ipo-v2.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Reddit announced on Thursday that it’s testing a new AI search tool that takes community recommendations and matches them with products from some of the company’s shopping and advertising partners. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A small group of users in the U.S. will start to see search results that include interactive product carousels with pricing, images, and direct where-to-buy links.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The announcement reflects Reddit’s broader push to combine its community-driven platform with e-commerce capabilities. The move comes as Reddit launched its first shoppable ad product last year, called Dynamic Product Ads (DPA), which display personalized product recommendations to users based on their interests.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now, when users who are part of the test search for something like “best noise-canceling headphones” or “electronic gift ideas for a college student,” they will see a carousel of related products at the bottom of the results. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This carousel will feature products directly mentioned by users from conversations on related posts and comments. If users tap on the product, they can view more details and then be directed to the retailer to purchase the item. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This feature surfaces top-recommended products directly from discussions, giving redditors instant information about any product,” the company wrote in a blog post. “This test is designed to make Reddit easier to navigate while keeping community perspectives at the center of the experience. We’ll continue learning from how people use this new feature and refine the experience over time.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While platforms like TikTok and Instagram have long integrated shopping features, Reddit is now looking to follow suit. Of course, Reddit isn’t the only tech platform that recently started exploring AI-driven shopping, as OpenAI’s ChatGPT rolled out an “Instant Checkout” feature last September that lets users make&amp;nbsp;Etsy and Shopify&amp;nbsp;purchases within conversations. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Thursday’s announcement comes after Reddit CEO Steve Huffman said during the company’s earnings release last week that the platforms’s AI search engine could be the next big opportunity for its business, not just in terms of product, but also as a revenue driver.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Huffman also noted that weekly active users for search grew 30% over the past year, increasing from 60 million to 80 million, while weekly active users for the AI-powered Reddit Answers feature rose from 1 million in the first quarter of 2025 to 15 million by the fourth quarter.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/19/reddit-is-testing-a-new-ai-search-feature-for-shopping/</guid><pubDate>Thu, 19 Feb 2026 18:22:51 +0000</pubDate></item><item><title>[NEW] Train AI models with Unsloth and Hugging Face Jobs for FREE (Hugging Face - Blog)</title><link>https://huggingface.co/blog/unsloth-jobs</link><description>&lt;!-- HTML_TAG_START --&gt;
This blog post covers how to use Unsloth and Hugging Face Jobs for fast LLM fine-tuning (specifically &lt;code&gt;LiquidAI/LFM2.5-1.2B-Instruct&lt;/code&gt; ) through coding agents like Claude Code and Codex. Unsloth provides ~2x faster training and ~60% less VRAM usage compared to standard methods, so training small models can cost just a few dollars.
&lt;p&gt;Why a small model? Small language models like LFM2.5-1.2B-Instruct are ideal candidates for fine-tuning. They are cheap to train, fast to iterate on, and increasingly competitive with much larger models on focused tasks. LFM2.5-1.2B-Instruct runs under 1GB of memory and is optimized for on-device deployment, so what you fine-tune can be served on CPUs, phones, and laptops.&lt;/p&gt;

 &lt;img alt="Watch the video" border="10" height="450" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/unsloth-jobs/screenshot.png" width="800" /&gt;


&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		You will need
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;We are giving away free credits to fine-tune models on Hugging Face Jobs. Join the Unsloth Jobs Explorers organization to claim your free credits and one-month Pro subscription.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A Hugging Face account (required for HF Jobs) &lt;/li&gt;
&lt;li&gt;Billing setup (for verification, you can monitor your usage and manage your billing in your billing page).&lt;/li&gt;
&lt;li&gt;A Hugging Face token with write permissions&lt;/li&gt;
&lt;li&gt;(optional) A coding agent (&lt;code&gt;Open Code&lt;/code&gt;, &lt;code&gt;Claude Code&lt;/code&gt;, or &lt;code&gt;Codex&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Run the Job
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;If you want to train a model using HF Jobs and Unsloth, you can simply use the &lt;code&gt;hf jobs&lt;/code&gt; CLI to submit a job.&lt;/p&gt;
&lt;p&gt;First, you need to install the &lt;code&gt;hf&lt;/code&gt; CLI. You can do this by running the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# mac or linux
curl -LsSf https://hf.co/cli/install.sh | bash
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next you can run the following command to submit a job:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-sh"&gt;hf &lt;span class="hljs-built_in"&gt;jobs&lt;/span&gt; uv run https://huggingface.co/datasets/unsloth/jobs/resolve/main/sft-lfm2.5.py \
    --flavor a10g-small  \
    --secrets HF_TOKEN  \
    --&lt;span class="hljs-built_in"&gt;timeout&lt;/span&gt; 4h \
    --dataset mlabonne/FineTome-100k \
    --num-epochs 1 \
    --eval-split 0.2 \
    --output-repo your-username/lfm-finetuned
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Check out the training script and Hugging Face Jobs documentation for more details.&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Installing the Skill
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Hugging Face model training skill lowers barrier of entry to train a model by simply prompting. First, install the skill with your coding agent.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Claude Code
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;Claude Code discovers skills through its plugin system, so we need to install the Hugging Face skills first. To do so:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Add the marketplace:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;/plugin marketplace add huggingface/skills
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="2"&gt;
&lt;li&gt;Browse available skills in the &lt;code&gt;Discover&lt;/code&gt; tab:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;/plugin
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="3"&gt;
&lt;li&gt;Install the model trainer skill:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;/plugin install hugging-face-model-trainer@huggingface-skills
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more details, see the documentation on using the hub with skills or the Claude Code Skills docs.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Codex
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;Codex discovers skills through &lt;code&gt;AGENTS.md&lt;/code&gt; files and &lt;code&gt;.agents/skills/&lt;/code&gt; directories.&lt;/p&gt;
&lt;p&gt;Install individual skills with &lt;code&gt;$skill-installer&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;$skill-installer install https://github.com/huggingface/skills/tree/main/skills/hugging-face-model-trainer
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more details, see the Codex Skills docs and the AGENTS.md guide.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Anything else
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;A generic install method is simply to clone the skills repository and copy the skill to your agent's skills directory.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;git clone https://github.com/huggingface/skills.git
mkdir -p ~/.agents/skills &amp;amp;&amp;amp; cp -R skills/skills/hugging-face-model-trainer ~/.agents/skills/
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Quick Start
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Once the skill is installed, ask your coding agent to train a model:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;Train LiquidAI/LFM2.5-1.2B-Instruct on mlabonne/FineTome-100k using Unsloth on HF Jobs
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The agent will generate a training script based on an example in the skill, submit the training to HF Jobs, and provide a monitoring link via Trackio.&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		How It Works
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Training jobs run on Hugging Face Jobs, fully managed cloud GPUs. The agent:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Generates a UV script with inline dependencies&lt;/li&gt;
&lt;li&gt;Submits it to HF Jobs via the &lt;code&gt;hf&lt;/code&gt; CLI&lt;/li&gt;
&lt;li&gt;Reports the job ID and monitoring URL&lt;/li&gt;
&lt;li&gt;Pushes the trained model to your Hugging Face Hub repository&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Example Training Script
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;The skill generates scripts like this based on the example in the skill.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;



&lt;span class="hljs-keyword"&gt;from&lt;/span&gt; unsloth &lt;span class="hljs-keyword"&gt;import&lt;/span&gt; FastLanguageModel
&lt;span class="hljs-keyword"&gt;from&lt;/span&gt; trl &lt;span class="hljs-keyword"&gt;import&lt;/span&gt; SFTTrainer, SFTConfig
&lt;span class="hljs-keyword"&gt;from&lt;/span&gt; datasets &lt;span class="hljs-keyword"&gt;import&lt;/span&gt; load_dataset

model, tokenizer = FastLanguageModel.from_pretrained(
    &lt;span class="hljs-string"&gt;"LiquidAI/LFM2.5-1.2B-Instruct"&lt;/span&gt;,
    load_in_4bit=&lt;span class="hljs-literal"&gt;True&lt;/span&gt;,
    max_seq_length=&lt;span class="hljs-number"&gt;2048&lt;/span&gt;,
)

model = FastLanguageModel.get_peft_model(
    model,
    r=&lt;span class="hljs-number"&gt;16&lt;/span&gt;,
    lora_alpha=&lt;span class="hljs-number"&gt;32&lt;/span&gt;,
    lora_dropout=&lt;span class="hljs-number"&gt;0&lt;/span&gt;,
    target_modules=[
        &lt;span class="hljs-string"&gt;"q_proj"&lt;/span&gt;,
        &lt;span class="hljs-string"&gt;"k_proj"&lt;/span&gt;,
        &lt;span class="hljs-string"&gt;"v_proj"&lt;/span&gt;,
        &lt;span class="hljs-string"&gt;"out_proj"&lt;/span&gt;,
        &lt;span class="hljs-string"&gt;"in_proj"&lt;/span&gt;,
        &lt;span class="hljs-string"&gt;"w1"&lt;/span&gt;,
        &lt;span class="hljs-string"&gt;"w2"&lt;/span&gt;,
        &lt;span class="hljs-string"&gt;"w3"&lt;/span&gt;,
    ],
)

dataset = load_dataset(&lt;span class="hljs-string"&gt;"trl-lib/Capybara"&lt;/span&gt;, split=&lt;span class="hljs-string"&gt;"train"&lt;/span&gt;)

trainer = SFTTrainer(
    model=model,
    tokenizer=tokenizer,
    train_dataset=dataset,
    args=SFTConfig(
        output_dir=&lt;span class="hljs-string"&gt;"./output"&lt;/span&gt;,
        push_to_hub=&lt;span class="hljs-literal"&gt;True&lt;/span&gt;,
        hub_model_id=&lt;span class="hljs-string"&gt;"username/my-model"&lt;/span&gt;,
        per_device_train_batch_size=&lt;span class="hljs-number"&gt;4&lt;/span&gt;,
        gradient_accumulation_steps=&lt;span class="hljs-number"&gt;4&lt;/span&gt;,
        num_train_epochs=&lt;span class="hljs-number"&gt;1&lt;/span&gt;,
        learning_rate=&lt;span class="hljs-number"&gt;2e-4&lt;/span&gt;,
        report_to=&lt;span class="hljs-string"&gt;"trackio"&lt;/span&gt;,
    ),
)

trainer.train()
trainer.push_to_hub()
&lt;/code&gt;&lt;/pre&gt;
&lt;div class="max-w-full overflow-auto"&gt;
	&lt;table&gt;
		&lt;thead&gt;&lt;tr&gt;
&lt;th align="left"&gt;Model Size&lt;/th&gt;
&lt;th align="left"&gt;Recommended GPU&lt;/th&gt;
&lt;th align="left"&gt;Approx Cost/hr&lt;/th&gt;
&lt;/tr&gt;

		&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;
&lt;td align="left"&gt;&amp;lt;1B params&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;t4-small&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;~$0.40&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;1-3B params&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;t4-medium&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;~$0.60&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3-7B params&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;a10g-small&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;~$1.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;7-13B params&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;a10g-large&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;~$3.00&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
	&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;For a full overview of Hugging Face Spaces pricing, check out the guide here.&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Tips for Working with Coding Agents
	&lt;/span&gt;
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Be specific about the model and dataset to use, and include Hub IDs (for example, &lt;code&gt;Qwen/Qwen2.5-0.5B&lt;/code&gt; and &lt;code&gt;trl-lib/Capybara&lt;/code&gt;). Agents will search for and validate those combinations.&lt;/li&gt;
&lt;li&gt;Mention Unsloth explicitly if you want it used. Otherwise, the agent will choose a framework based on the model and budget.&lt;/li&gt;
&lt;li&gt;Ask for cost estimates before launching large jobs.&lt;/li&gt;
&lt;li&gt;Request Trackio monitoring for real-time loss curves.&lt;/li&gt;
&lt;li&gt;Check job status by asking the agent to inspect logs after submission.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Resources
	&lt;/span&gt;
&lt;/h2&gt;

&lt;!-- HTML_TAG_END --&gt;</description><content:encoded>&lt;!-- HTML_TAG_START --&gt;
This blog post covers how to use Unsloth and Hugging Face Jobs for fast LLM fine-tuning (specifically &lt;code&gt;LiquidAI/LFM2.5-1.2B-Instruct&lt;/code&gt; ) through coding agents like Claude Code and Codex. Unsloth provides ~2x faster training and ~60% less VRAM usage compared to standard methods, so training small models can cost just a few dollars.
&lt;p&gt;Why a small model? Small language models like LFM2.5-1.2B-Instruct are ideal candidates for fine-tuning. They are cheap to train, fast to iterate on, and increasingly competitive with much larger models on focused tasks. LFM2.5-1.2B-Instruct runs under 1GB of memory and is optimized for on-device deployment, so what you fine-tune can be served on CPUs, phones, and laptops.&lt;/p&gt;

 &lt;img alt="Watch the video" border="10" height="450" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/unsloth-jobs/screenshot.png" width="800" /&gt;


&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		You will need
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;We are giving away free credits to fine-tune models on Hugging Face Jobs. Join the Unsloth Jobs Explorers organization to claim your free credits and one-month Pro subscription.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A Hugging Face account (required for HF Jobs) &lt;/li&gt;
&lt;li&gt;Billing setup (for verification, you can monitor your usage and manage your billing in your billing page).&lt;/li&gt;
&lt;li&gt;A Hugging Face token with write permissions&lt;/li&gt;
&lt;li&gt;(optional) A coding agent (&lt;code&gt;Open Code&lt;/code&gt;, &lt;code&gt;Claude Code&lt;/code&gt;, or &lt;code&gt;Codex&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Run the Job
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;If you want to train a model using HF Jobs and Unsloth, you can simply use the &lt;code&gt;hf jobs&lt;/code&gt; CLI to submit a job.&lt;/p&gt;
&lt;p&gt;First, you need to install the &lt;code&gt;hf&lt;/code&gt; CLI. You can do this by running the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# mac or linux
curl -LsSf https://hf.co/cli/install.sh | bash
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next you can run the following command to submit a job:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-sh"&gt;hf &lt;span class="hljs-built_in"&gt;jobs&lt;/span&gt; uv run https://huggingface.co/datasets/unsloth/jobs/resolve/main/sft-lfm2.5.py \
    --flavor a10g-small  \
    --secrets HF_TOKEN  \
    --&lt;span class="hljs-built_in"&gt;timeout&lt;/span&gt; 4h \
    --dataset mlabonne/FineTome-100k \
    --num-epochs 1 \
    --eval-split 0.2 \
    --output-repo your-username/lfm-finetuned
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Check out the training script and Hugging Face Jobs documentation for more details.&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Installing the Skill
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Hugging Face model training skill lowers barrier of entry to train a model by simply prompting. First, install the skill with your coding agent.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Claude Code
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;Claude Code discovers skills through its plugin system, so we need to install the Hugging Face skills first. To do so:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Add the marketplace:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;/plugin marketplace add huggingface/skills
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="2"&gt;
&lt;li&gt;Browse available skills in the &lt;code&gt;Discover&lt;/code&gt; tab:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;/plugin
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="3"&gt;
&lt;li&gt;Install the model trainer skill:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;/plugin install hugging-face-model-trainer@huggingface-skills
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more details, see the documentation on using the hub with skills or the Claude Code Skills docs.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Codex
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;Codex discovers skills through &lt;code&gt;AGENTS.md&lt;/code&gt; files and &lt;code&gt;.agents/skills/&lt;/code&gt; directories.&lt;/p&gt;
&lt;p&gt;Install individual skills with &lt;code&gt;$skill-installer&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;$skill-installer install https://github.com/huggingface/skills/tree/main/skills/hugging-face-model-trainer
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more details, see the Codex Skills docs and the AGENTS.md guide.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Anything else
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;A generic install method is simply to clone the skills repository and copy the skill to your agent's skills directory.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;git clone https://github.com/huggingface/skills.git
mkdir -p ~/.agents/skills &amp;amp;&amp;amp; cp -R skills/skills/hugging-face-model-trainer ~/.agents/skills/
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Quick Start
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Once the skill is installed, ask your coding agent to train a model:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;Train LiquidAI/LFM2.5-1.2B-Instruct on mlabonne/FineTome-100k using Unsloth on HF Jobs
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The agent will generate a training script based on an example in the skill, submit the training to HF Jobs, and provide a monitoring link via Trackio.&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		How It Works
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Training jobs run on Hugging Face Jobs, fully managed cloud GPUs. The agent:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Generates a UV script with inline dependencies&lt;/li&gt;
&lt;li&gt;Submits it to HF Jobs via the &lt;code&gt;hf&lt;/code&gt; CLI&lt;/li&gt;
&lt;li&gt;Reports the job ID and monitoring URL&lt;/li&gt;
&lt;li&gt;Pushes the trained model to your Hugging Face Hub repository&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Example Training Script
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;The skill generates scripts like this based on the example in the skill.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;



&lt;span class="hljs-keyword"&gt;from&lt;/span&gt; unsloth &lt;span class="hljs-keyword"&gt;import&lt;/span&gt; FastLanguageModel
&lt;span class="hljs-keyword"&gt;from&lt;/span&gt; trl &lt;span class="hljs-keyword"&gt;import&lt;/span&gt; SFTTrainer, SFTConfig
&lt;span class="hljs-keyword"&gt;from&lt;/span&gt; datasets &lt;span class="hljs-keyword"&gt;import&lt;/span&gt; load_dataset

model, tokenizer = FastLanguageModel.from_pretrained(
    &lt;span class="hljs-string"&gt;"LiquidAI/LFM2.5-1.2B-Instruct"&lt;/span&gt;,
    load_in_4bit=&lt;span class="hljs-literal"&gt;True&lt;/span&gt;,
    max_seq_length=&lt;span class="hljs-number"&gt;2048&lt;/span&gt;,
)

model = FastLanguageModel.get_peft_model(
    model,
    r=&lt;span class="hljs-number"&gt;16&lt;/span&gt;,
    lora_alpha=&lt;span class="hljs-number"&gt;32&lt;/span&gt;,
    lora_dropout=&lt;span class="hljs-number"&gt;0&lt;/span&gt;,
    target_modules=[
        &lt;span class="hljs-string"&gt;"q_proj"&lt;/span&gt;,
        &lt;span class="hljs-string"&gt;"k_proj"&lt;/span&gt;,
        &lt;span class="hljs-string"&gt;"v_proj"&lt;/span&gt;,
        &lt;span class="hljs-string"&gt;"out_proj"&lt;/span&gt;,
        &lt;span class="hljs-string"&gt;"in_proj"&lt;/span&gt;,
        &lt;span class="hljs-string"&gt;"w1"&lt;/span&gt;,
        &lt;span class="hljs-string"&gt;"w2"&lt;/span&gt;,
        &lt;span class="hljs-string"&gt;"w3"&lt;/span&gt;,
    ],
)

dataset = load_dataset(&lt;span class="hljs-string"&gt;"trl-lib/Capybara"&lt;/span&gt;, split=&lt;span class="hljs-string"&gt;"train"&lt;/span&gt;)

trainer = SFTTrainer(
    model=model,
    tokenizer=tokenizer,
    train_dataset=dataset,
    args=SFTConfig(
        output_dir=&lt;span class="hljs-string"&gt;"./output"&lt;/span&gt;,
        push_to_hub=&lt;span class="hljs-literal"&gt;True&lt;/span&gt;,
        hub_model_id=&lt;span class="hljs-string"&gt;"username/my-model"&lt;/span&gt;,
        per_device_train_batch_size=&lt;span class="hljs-number"&gt;4&lt;/span&gt;,
        gradient_accumulation_steps=&lt;span class="hljs-number"&gt;4&lt;/span&gt;,
        num_train_epochs=&lt;span class="hljs-number"&gt;1&lt;/span&gt;,
        learning_rate=&lt;span class="hljs-number"&gt;2e-4&lt;/span&gt;,
        report_to=&lt;span class="hljs-string"&gt;"trackio"&lt;/span&gt;,
    ),
)

trainer.train()
trainer.push_to_hub()
&lt;/code&gt;&lt;/pre&gt;
&lt;div class="max-w-full overflow-auto"&gt;
	&lt;table&gt;
		&lt;thead&gt;&lt;tr&gt;
&lt;th align="left"&gt;Model Size&lt;/th&gt;
&lt;th align="left"&gt;Recommended GPU&lt;/th&gt;
&lt;th align="left"&gt;Approx Cost/hr&lt;/th&gt;
&lt;/tr&gt;

		&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;
&lt;td align="left"&gt;&amp;lt;1B params&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;t4-small&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;~$0.40&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;1-3B params&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;t4-medium&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;~$0.60&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3-7B params&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;a10g-small&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;~$1.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;7-13B params&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;a10g-large&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;~$3.00&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
	&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;For a full overview of Hugging Face Spaces pricing, check out the guide here.&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Tips for Working with Coding Agents
	&lt;/span&gt;
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Be specific about the model and dataset to use, and include Hub IDs (for example, &lt;code&gt;Qwen/Qwen2.5-0.5B&lt;/code&gt; and &lt;code&gt;trl-lib/Capybara&lt;/code&gt;). Agents will search for and validate those combinations.&lt;/li&gt;
&lt;li&gt;Mention Unsloth explicitly if you want it used. Otherwise, the agent will choose a framework based on the model and budget.&lt;/li&gt;
&lt;li&gt;Ask for cost estimates before launching large jobs.&lt;/li&gt;
&lt;li&gt;Request Trackio monitoring for real-time loss curves.&lt;/li&gt;
&lt;li&gt;Check job status by asking the agent to inspect logs after submission.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Resources
	&lt;/span&gt;
&lt;/h2&gt;

&lt;!-- HTML_TAG_END --&gt;</content:encoded><guid isPermaLink="false">https://huggingface.co/blog/unsloth-jobs</guid><pubDate>Fri, 20 Feb 2026 00:00:00 +0000</pubDate></item></channel></rss>