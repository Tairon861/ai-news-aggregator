<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 29 Aug 2025 01:40:35 +0000</lastBuildDate><item><title> ()</title><link>https://www.wired.com/feed/category/artificial-intelligence/rss</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://www.wired.com/feed/category/artificial-intelligence/rss</guid></item><item><title>AI hires or human hustle? Inside the next frontier of startup operations at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/28/ai-hires-or-human-hustle-inside-the-next-frontier-of-startup-operations-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;What happens when your first 10 hires aren’t people at all? At &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, happening October 27–29 at San Francisco’s Moscone West, we’re digging into the new wave of startups replacing or augmenting early employees with AI agents. Think outbound sales, billing, and customer support — automated from day one.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This panel, hosted on the &lt;strong&gt;Builders Stage&lt;/strong&gt;, features a mix of technical founders and seasoned operators who are actually doing it, debating where the line between human and machine should be drawn — and how far is too far.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Caleb Peffer, Jaspar Carmichael-Jack, Sarah Franklin" class="wp-image-3040625" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_Jack-Peffer-Franklin-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-meet-the-speakers"&gt;Meet the speakers&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Caleb Peffer&lt;/strong&gt;, founder and CEO of Firecrawl, is helping over 350,000 developers (and companies like Shopify and Zapier) plug AI directly into the live web. His dev-first platform is already reshaping how AI agents interact with the internet and scale with clean data.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Jaspar Carmichael-Jack&lt;/strong&gt;, founder and CEO of Artisan, made waves with his “Stop Hiring Humans” campaign — and he’s serious. His company raised $35 million to build AI employees, starting with sales. Expect bold insights on replacing go-to-market teams with code.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Sarah Franklin&lt;/strong&gt;, CEO of Lattice and former Salesforce president and CMO, brings hard-won wisdom on scaling companies with impact. She’s built and led real teams at the highest level and knows exactly where AI helps — and where it hurts.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-why-this-session-matters"&gt;Why this session matters&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Whether you’re already embedding AI into your stack or just testing prompts on your product team, this conversation is about more than hype. It’s about getting real on ROI, trust, team dynamics, and what it means to build a business that moves faster than ever with fewer human hands.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-ready-to-find-your-edge"&gt;Ready to find your edge?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;This session is just one of hundreds featured across five industry stages, plus breakouts and roundtables. Grab your pass to Disrupt 2025 before prices jump in mid-September. &lt;strong&gt;Get your ticket now&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;What happens when your first 10 hires aren’t people at all? At &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, happening October 27–29 at San Francisco’s Moscone West, we’re digging into the new wave of startups replacing or augmenting early employees with AI agents. Think outbound sales, billing, and customer support — automated from day one.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This panel, hosted on the &lt;strong&gt;Builders Stage&lt;/strong&gt;, features a mix of technical founders and seasoned operators who are actually doing it, debating where the line between human and machine should be drawn — and how far is too far.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Caleb Peffer, Jaspar Carmichael-Jack, Sarah Franklin" class="wp-image-3040625" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_Jack-Peffer-Franklin-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-meet-the-speakers"&gt;Meet the speakers&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Caleb Peffer&lt;/strong&gt;, founder and CEO of Firecrawl, is helping over 350,000 developers (and companies like Shopify and Zapier) plug AI directly into the live web. His dev-first platform is already reshaping how AI agents interact with the internet and scale with clean data.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Jaspar Carmichael-Jack&lt;/strong&gt;, founder and CEO of Artisan, made waves with his “Stop Hiring Humans” campaign — and he’s serious. His company raised $35 million to build AI employees, starting with sales. Expect bold insights on replacing go-to-market teams with code.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Sarah Franklin&lt;/strong&gt;, CEO of Lattice and former Salesforce president and CMO, brings hard-won wisdom on scaling companies with impact. She’s built and led real teams at the highest level and knows exactly where AI helps — and where it hurts.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-why-this-session-matters"&gt;Why this session matters&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Whether you’re already embedding AI into your stack or just testing prompts on your product team, this conversation is about more than hype. It’s about getting real on ROI, trust, team dynamics, and what it means to build a business that moves faster than ever with fewer human hands.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-ready-to-find-your-edge"&gt;Ready to find your edge?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;This session is just one of hundreds featured across five industry stages, plus breakouts and roundtables. Grab your pass to Disrupt 2025 before prices jump in mid-September. &lt;strong&gt;Get your ticket now&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/28/ai-hires-or-human-hustle-inside-the-next-frontier-of-startup-operations-at-techcrunch-disrupt-2025/</guid><pubDate>Thu, 28 Aug 2025 14:00:00 +0000</pubDate></item><item><title>Investors are loving Lovable (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/28/investors-are-loving-lovable/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/picnew-copy.png?resize=1200,801" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Investors are clamoring to get onto Swedish vibe-coding startup Lovable’s cap table, making unsolicited offers of investment that value the company at more than $4 billion, reports Financial Times.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lovable CEO Anton Osika isn’t currently engaging with the flurry of inbound interest, the Times says, which comes a few weeks after the startup announced a $200 million round at a $1.8 billion valuation in a deal led by Accel.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;A Lovable spokesperson told TechCrunch that the company isn’t fundraising now. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lovable has grown quickly over its short lifespan. In July, the startup said its annual recurring revenue had surpassed $100 million with more than 10 million projects built using the platform.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The astounding trajectory of Europe’s hottest unicorn comes just nine months after Lovable launched and comes on the heels of investor interest in vibe-coding startups. Cursor-maker Anysphere raised $900 million in May, more than tripling its valuation to $9 billion.&lt;/p&gt;

&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Got a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at&amp;nbsp;rebecca.bellan@techcrunch.com&amp;nbsp;and Maxwell Zeff at&amp;nbsp;maxwell.zeff@techcrunch.com. For secure communication, you can contact us via Signal at&amp;nbsp;@rebeccabellan.491 and&amp;nbsp;@mzeff.88.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/picnew-copy.png?resize=1200,801" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Investors are clamoring to get onto Swedish vibe-coding startup Lovable’s cap table, making unsolicited offers of investment that value the company at more than $4 billion, reports Financial Times.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lovable CEO Anton Osika isn’t currently engaging with the flurry of inbound interest, the Times says, which comes a few weeks after the startup announced a $200 million round at a $1.8 billion valuation in a deal led by Accel.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;A Lovable spokesperson told TechCrunch that the company isn’t fundraising now. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lovable has grown quickly over its short lifespan. In July, the startup said its annual recurring revenue had surpassed $100 million with more than 10 million projects built using the platform.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The astounding trajectory of Europe’s hottest unicorn comes just nine months after Lovable launched and comes on the heels of investor interest in vibe-coding startups. Cursor-maker Anysphere raised $900 million in May, more than tripling its valuation to $9 billion.&lt;/p&gt;

&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Got a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at&amp;nbsp;rebecca.bellan@techcrunch.com&amp;nbsp;and Maxwell Zeff at&amp;nbsp;maxwell.zeff@techcrunch.com. For secure communication, you can contact us via Signal at&amp;nbsp;@rebeccabellan.491 and&amp;nbsp;@mzeff.88.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/28/investors-are-loving-lovable/</guid><pubDate>Thu, 28 Aug 2025 14:04:06 +0000</pubDate></item><item><title>MIT researchers develop AI tool to improve flu vaccine strain selection (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/vaxseer-ai-tool-to-improve-flu-vaccine-strain-selection-0828</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202508/mit-vaxseer-barzilay-shi-00_1.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr" id="docs-internal-guid-2ef4ad7e-7fff-c28e-41c1-d61ce18592ae"&gt;Every year, global health experts are faced with a high-stakes decision: Which influenza strains should go into the next seasonal vaccine? The choice must be made months in advance, long before flu season even begins, and it can often feel like a race against the clock. If the selected strains match those that circulate, the vaccine will likely be highly effective. But if the prediction is off, protection can drop significantly, leading to (potentially preventable) illness and strain on health care systems.&lt;/p&gt;&lt;p dir="ltr"&gt;This challenge became even more familiar to scientists in the years during the Covid-19 pandemic. Think back to the time (and time and time again), when new variants emerged just as vaccines were being rolled out. Influenza behaves like a similar, rowdy cousin, mutating constantly and unpredictably. That makes it hard to stay ahead, and therefore harder to design vaccines that remain protective.&lt;/p&gt;&lt;p dir="ltr"&gt;To reduce this uncertainty, scientists at MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) and the MIT Abdul Latif Jameel Clinic for Machine Learning in Health set out to make vaccine selection more accurate and less reliant on guesswork. They created an AI system called VaxSeer, designed to predict dominant flu strains and identify the most protective vaccine candidates, months ahead of time. The tool uses deep learning models trained on decades of viral sequences and lab test results to simulate how the flu virus might evolve and how the vaccines will respond.&lt;/p&gt;&lt;p dir="ltr"&gt;Traditional evolution models often analyze the effect of single amino acid mutations independently. “VaxSeer adopts a large protein language model to learn the relationship between dominance and the combinatorial effects of mutations,” explains Wenxian Shi, a PhD student in MIT’s Department of Electrical Engineering and Computer Science, researcher at CSAIL, and lead author of a new paper on the work. “Unlike existing protein language models that assume a static distribution of viral variants, we model dynamic dominance shifts, making it better suited for rapidly evolving viruses like influenza.”&lt;/p&gt;&lt;p dir="ltr"&gt;An open-access report on the study was published today in &lt;em&gt;Nature Medicine.&lt;/em&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;The future of flu&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;VaxSeer has two core prediction engines: one that estimates how likely each viral strain is to spread (dominance), and another that estimates how effectively a vaccine will neutralize that strain (antigenicity). Together, they produce a predicted coverage score: a forward-looking measure of how well a given vaccine is likely to perform against future viruses.&lt;/p&gt;&lt;p dir="ltr"&gt;The scale of the score could be from an infinite negative to 0. The closer the score to 0, the better the antigenic match of vaccine strains to the circulating viruses. (You can imagine it as the negative of some kind of “distance.”)&lt;/p&gt;&lt;p dir="ltr"&gt;In a 10-year retrospective study, the researchers evaluated VaxSeer’s recommendations against those made by the World Health Organization (WHO) for two major flu subtypes: A/H3N2 and A/H1N1. For A/H3N2, VaxSeer’s choices outperformed the WHO’s in nine out of 10 seasons, based on retrospective empirical coverage scores (a surrogate metric of the vaccine effectiveness, calculated from the observed dominance from past seasons and experimental HI test results). The team used this to evaluate vaccine selections, as the effectiveness is only available for vaccines actually given to the population.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;For A/H1N1, it outperformed or matched the WHO in six out of 10 seasons. In one notable case, for the 2016 flu season, VaxSeer identified a strain that wasn’t chosen by the WHO until the following year. The model’s predictions also showed strong correlation with real-world vaccine effectiveness estimates, as reported by the CDC, Canada’s Sentinel Practitioner Surveillance Network, and Europe’s I-MOVE program. VaxSeer’s predicted coverage scores aligned closely with public health data on flu-related illnesses and medical visits prevented by vaccination.&lt;/p&gt;&lt;p dir="ltr"&gt;So how exactly does VaxSeer make sense of all these data? Intuitively, the model first estimates how rapidly a viral strain spreads over time using a protein language model, and then determines its dominance by accounting for competition among different strains.&lt;/p&gt;&lt;p dir="ltr"&gt;Once the model has calculated its insights, they’re plugged into a mathematical framework based on something called ordinary differential equations to simulate viral spread over time. For antigenicity, the system estimates how well a given vaccine strain will perform in a common lab test called the hemagglutination inhibition assay. This measures how effectively antibodies can&amp;nbsp;inhibit the virus from binding to human red blood cells, which is a widely used proxy for antigenic match/antigenicity.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;Outpacing evolution&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;“By modeling how viruses evolve and how vaccines interact with them, AI tools like VaxSeer could help health officials make better, faster decisions — and stay one step ahead in the race between infection and immunity,” says Shi.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;VaxSeer currently focuses only on the flu virus’s HA (hemagglutinin) protein,the major antigen of influenza. Future versions could incorporate other proteins like NA (neuraminidase), and factors like immune history, manufacturing constraints, or dosage levels. Applying the system to other viruses would also require large, high-quality datasets that track both viral evolution and immune responses — data that aren’t always publicly available. The team, however is currently working on the methods that can predict viral evolution in low-data regimes building on relations between viral families&lt;/p&gt;&lt;p dir="ltr"&gt;“Given the speed of viral evolution, current therapeutic development often lags behind.&amp;nbsp;VaxSeer is our attempt to catch up,” says Regina Barzilay, the School of Engineering Distinguished Professor for AI and Health at MIT, AI lead of Jameel Clinic, and CSAIL principal investigator.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;“This paper is impressive, but what excites me perhaps even more is the team’s ongoing work on predicting viral evolution in low-data settings,” says Assistant Professor Jon Stokes of the Department of Biochemistry and Biomedical Sciences at McMaster University in Hamilton, Ontario. “The implications go far beyond influenza. Imagine being able to anticipate how antibiotic-resistant bacteria or drug-resistant cancers might evolve, both of which can adapt rapidly. This kind of predictive modeling opens up a powerful new way of thinking about how diseases change, giving us the opportunity to stay one step ahead and design clinical interventions before escape becomes a major problem.”&lt;/p&gt;&lt;p dir="ltr"&gt;Shi and Barzilay wrote the paper with MIT CSAIL postdoc Jeremy Wohlwend ’16, MEng ’17, PhD ’25 and recent CSAIL affiliate Menghua Wu ’19, MEng ’20, PhD ’25. Their work was supported, in part, by the U.S. Defense Threat Reduction Agency and MIT Jameel Clinic.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202508/mit-vaxseer-barzilay-shi-00_1.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr" id="docs-internal-guid-2ef4ad7e-7fff-c28e-41c1-d61ce18592ae"&gt;Every year, global health experts are faced with a high-stakes decision: Which influenza strains should go into the next seasonal vaccine? The choice must be made months in advance, long before flu season even begins, and it can often feel like a race against the clock. If the selected strains match those that circulate, the vaccine will likely be highly effective. But if the prediction is off, protection can drop significantly, leading to (potentially preventable) illness and strain on health care systems.&lt;/p&gt;&lt;p dir="ltr"&gt;This challenge became even more familiar to scientists in the years during the Covid-19 pandemic. Think back to the time (and time and time again), when new variants emerged just as vaccines were being rolled out. Influenza behaves like a similar, rowdy cousin, mutating constantly and unpredictably. That makes it hard to stay ahead, and therefore harder to design vaccines that remain protective.&lt;/p&gt;&lt;p dir="ltr"&gt;To reduce this uncertainty, scientists at MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) and the MIT Abdul Latif Jameel Clinic for Machine Learning in Health set out to make vaccine selection more accurate and less reliant on guesswork. They created an AI system called VaxSeer, designed to predict dominant flu strains and identify the most protective vaccine candidates, months ahead of time. The tool uses deep learning models trained on decades of viral sequences and lab test results to simulate how the flu virus might evolve and how the vaccines will respond.&lt;/p&gt;&lt;p dir="ltr"&gt;Traditional evolution models often analyze the effect of single amino acid mutations independently. “VaxSeer adopts a large protein language model to learn the relationship between dominance and the combinatorial effects of mutations,” explains Wenxian Shi, a PhD student in MIT’s Department of Electrical Engineering and Computer Science, researcher at CSAIL, and lead author of a new paper on the work. “Unlike existing protein language models that assume a static distribution of viral variants, we model dynamic dominance shifts, making it better suited for rapidly evolving viruses like influenza.”&lt;/p&gt;&lt;p dir="ltr"&gt;An open-access report on the study was published today in &lt;em&gt;Nature Medicine.&lt;/em&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;The future of flu&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;VaxSeer has two core prediction engines: one that estimates how likely each viral strain is to spread (dominance), and another that estimates how effectively a vaccine will neutralize that strain (antigenicity). Together, they produce a predicted coverage score: a forward-looking measure of how well a given vaccine is likely to perform against future viruses.&lt;/p&gt;&lt;p dir="ltr"&gt;The scale of the score could be from an infinite negative to 0. The closer the score to 0, the better the antigenic match of vaccine strains to the circulating viruses. (You can imagine it as the negative of some kind of “distance.”)&lt;/p&gt;&lt;p dir="ltr"&gt;In a 10-year retrospective study, the researchers evaluated VaxSeer’s recommendations against those made by the World Health Organization (WHO) for two major flu subtypes: A/H3N2 and A/H1N1. For A/H3N2, VaxSeer’s choices outperformed the WHO’s in nine out of 10 seasons, based on retrospective empirical coverage scores (a surrogate metric of the vaccine effectiveness, calculated from the observed dominance from past seasons and experimental HI test results). The team used this to evaluate vaccine selections, as the effectiveness is only available for vaccines actually given to the population.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;For A/H1N1, it outperformed or matched the WHO in six out of 10 seasons. In one notable case, for the 2016 flu season, VaxSeer identified a strain that wasn’t chosen by the WHO until the following year. The model’s predictions also showed strong correlation with real-world vaccine effectiveness estimates, as reported by the CDC, Canada’s Sentinel Practitioner Surveillance Network, and Europe’s I-MOVE program. VaxSeer’s predicted coverage scores aligned closely with public health data on flu-related illnesses and medical visits prevented by vaccination.&lt;/p&gt;&lt;p dir="ltr"&gt;So how exactly does VaxSeer make sense of all these data? Intuitively, the model first estimates how rapidly a viral strain spreads over time using a protein language model, and then determines its dominance by accounting for competition among different strains.&lt;/p&gt;&lt;p dir="ltr"&gt;Once the model has calculated its insights, they’re plugged into a mathematical framework based on something called ordinary differential equations to simulate viral spread over time. For antigenicity, the system estimates how well a given vaccine strain will perform in a common lab test called the hemagglutination inhibition assay. This measures how effectively antibodies can&amp;nbsp;inhibit the virus from binding to human red blood cells, which is a widely used proxy for antigenic match/antigenicity.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;Outpacing evolution&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;“By modeling how viruses evolve and how vaccines interact with them, AI tools like VaxSeer could help health officials make better, faster decisions — and stay one step ahead in the race between infection and immunity,” says Shi.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;VaxSeer currently focuses only on the flu virus’s HA (hemagglutinin) protein,the major antigen of influenza. Future versions could incorporate other proteins like NA (neuraminidase), and factors like immune history, manufacturing constraints, or dosage levels. Applying the system to other viruses would also require large, high-quality datasets that track both viral evolution and immune responses — data that aren’t always publicly available. The team, however is currently working on the methods that can predict viral evolution in low-data regimes building on relations between viral families&lt;/p&gt;&lt;p dir="ltr"&gt;“Given the speed of viral evolution, current therapeutic development often lags behind.&amp;nbsp;VaxSeer is our attempt to catch up,” says Regina Barzilay, the School of Engineering Distinguished Professor for AI and Health at MIT, AI lead of Jameel Clinic, and CSAIL principal investigator.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;“This paper is impressive, but what excites me perhaps even more is the team’s ongoing work on predicting viral evolution in low-data settings,” says Assistant Professor Jon Stokes of the Department of Biochemistry and Biomedical Sciences at McMaster University in Hamilton, Ontario. “The implications go far beyond influenza. Imagine being able to anticipate how antibiotic-resistant bacteria or drug-resistant cancers might evolve, both of which can adapt rapidly. This kind of predictive modeling opens up a powerful new way of thinking about how diseases change, giving us the opportunity to stay one step ahead and design clinical interventions before escape becomes a major problem.”&lt;/p&gt;&lt;p dir="ltr"&gt;Shi and Barzilay wrote the paper with MIT CSAIL postdoc Jeremy Wohlwend ’16, MEng ’17, PhD ’25 and recent CSAIL affiliate Menghua Wu ’19, MEng ’20, PhD ’25. Their work was supported, in part, by the U.S. Defense Threat Reduction Agency and MIT Jameel Clinic.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/vaxseer-ai-tool-to-improve-flu-vaccine-strain-selection-0828</guid><pubDate>Thu, 28 Aug 2025 15:50:00 +0000</pubDate></item><item><title>OpenAI–Anthropic cross-tests expose jailbreak and misuse risks — what enterprises must add to GPT-5 evaluations (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/openai-anthropic-cross-tests-expose-jailbreak-and-misuse-risks-what-enterprises-must-add-to-gpt-5-evaluations/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;OpenAI and Anthropic may often pit their foundation models against each other, but the two companies came together to evaluate each other’s public models to test alignment.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The companies said they believed that cross-evaluating accountability and safety would provide more transparency into what these powerful models could do, enabling enterprises to choose models that work best for them.&lt;/p&gt;



&lt;p&gt;“We believe this approach supports accountable and transparent evaluation, helping to ensure that each lab’s models continue to be tested against new and challenging scenarios,” OpenAI said in its findings.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Both companies found that reasoning models, such as OpenAI’s 03 and o4-mini and Claude 4 from Anthropic, resist jailbreaks, while general chat models like GPT-4.1 were susceptible to misuse. Evaluations like this can help enterprises identify the potential risks associated with these models, although it should be noted that GPT-5 is not part of the test.&amp;nbsp;&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;These safety and transparency alignment evaluations follow claims by users, primarily of ChatGPT, that OpenAI’s models have fallen prey to sycophancy and become overly deferential. OpenAI has since rolled back updates that caused sycophancy.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“We are primarily interested in understanding model propensities for harmful action,” Anthropic said in its report. “We aim to understand the most concerning actions that these models might try to take when given the opportunity, rather than focusing on the real-world likelihood of such opportunities arising or the probability that these actions would be successfully completed.”&lt;/p&gt;



&lt;p&gt;OpenAI noted the tests were designed to show how models interact in an intentionally difficult environment. The scenarios they built are mostly edge cases.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-reasoning-models-hold-on-to-alignment-nbsp"&gt;Reasoning models hold on to alignment&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;The tests covered only the publicly available models from both companies: Anthropic’s Claude 4 Opus and Claude 4 Sonnet, and OpenAI’s GPT-4o, GPT-4.1 o3 and o4-mini. Both companies relaxed the models’ external safeguards.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;OpenAI tested the public APIs for Claude models and defaulted to using Claude 4’s reasoning capabilities. Anthropic said they did not use OpenAI’s o3-pro because it was “not compatible with the API that our tooling best supports.”&lt;/p&gt;



&lt;p&gt;The goal of the tests was not to conduct an apples-to-apples comparison between models, but to determine how often large language models (LLMs) deviated from alignment. Both companies leveraged the SHADE-Arena sabotage evaluation framework, which showed Claude models had higher success rates at subtle sabotage.&lt;/p&gt;



&lt;p&gt;“These tests assess models’ orientations toward difficult or high-stakes situations in simulated settings — rather than ordinary use cases — and often involve long, many-turn interactions,” Anthropic reported. “This kind of evaluation is becoming a significant focus for our alignment science team since it is likely to catch behaviors that are less likely to appear in ordinary pre-deployment testing with real users.”&lt;/p&gt;



&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcLbwj56_JpaPR3ztrYp3mkSBrjZN8CbntqmxhHV9klub8Q_YgqpjBaLFU0TWKeIRNVspEBVw6stibqyGCwGWEyJPuj_oIHOyg2TU7Us3pdqoD77AjzaCO_wsWx728JPDdYjsWRAA?key=4wIYfPcXmdrQx7-_2DhlgA" /&gt;&lt;/figure&gt;



&lt;p&gt;Anthropic said tests like these work better if organizations can compare notes, “since designing these scenarios involves an enormous number of degrees of freedom. No single research team can explore the full space of productive evaluation ideas alone.”&lt;/p&gt;



&lt;p&gt;The findings showed that generally, reasoning models performed robustly and can resist jailbreaking. OpenAI’s o3 was better aligned than Claude 4 Opus, but o4-mini along with GPT-4o and GPT-4.1 “often looked somewhat more concerning than either Claude model.” &lt;/p&gt;



&lt;p&gt;GPT-4o, GPT-4.1 and o4-mini also showed willingness to cooperate with human misuse and gave detailed instructions on how to create drugs, develop bioweapons and scarily, plan terrorist attacks. Both Claude models had higher rates of refusals, meaning the models refused to answer queries it did not know the answers to, to avoid hallucinations.&lt;/p&gt;



&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdIMk3CDWGGRTRYsfMVQ5UoBYr4OB3uyjS_YI0dgJko5xoAj7w-CkozVZw6B3s9vPO8ER4-MiHF79zDw8QDIPfTggwdYubDHkBrXQW_ZYAuF3UZGybsIQ4F5yzB5e6B2yj2ZT7kTg?key=4wIYfPcXmdrQx7-_2DhlgA" /&gt;&lt;/figure&gt;



&lt;p&gt;Models from companies showed “concerning forms of sycophancy” and, at some point, validated harmful decisions of simulated users.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-enterprises-should-know"&gt;What enterprises should know&lt;/h2&gt;



&lt;p&gt;For enterprises, understanding the potential risks associated with models is invaluable. Model evaluations have become almost de rigueur for many organizations, with many testing and benchmarking frameworks now available.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Enterprises should continue to evaluate any model they use, and with GPT-5’s release, should keep in mind these guidelines to run their own safety evaluations:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Test both reasoning and non-reasoning models, because, while reasoning models showed greater resistance to misuse, they could still offer up hallucinations or other harmful behavior.&lt;/li&gt;



&lt;li&gt;Benchmark across vendors since models failed at different metrics.&lt;/li&gt;



&lt;li&gt;Stress test for misuse and syconphancy, and score both the refusal and the utility of those refuse to show the trade-offs between usefulness and guardrails.&lt;/li&gt;



&lt;li&gt;Continue to audit models even after deployment.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;While many evaluations focus on performance, third-party safety alignment tests do exist. For example, this one from Cyata. Last year, OpenAI released an alignment teaching method for its models called Rules-Based Rewards, while Anthropic launched auditing agents to check model safety.&amp;nbsp;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;OpenAI and Anthropic may often pit their foundation models against each other, but the two companies came together to evaluate each other’s public models to test alignment.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The companies said they believed that cross-evaluating accountability and safety would provide more transparency into what these powerful models could do, enabling enterprises to choose models that work best for them.&lt;/p&gt;



&lt;p&gt;“We believe this approach supports accountable and transparent evaluation, helping to ensure that each lab’s models continue to be tested against new and challenging scenarios,” OpenAI said in its findings.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Both companies found that reasoning models, such as OpenAI’s 03 and o4-mini and Claude 4 from Anthropic, resist jailbreaks, while general chat models like GPT-4.1 were susceptible to misuse. Evaluations like this can help enterprises identify the potential risks associated with these models, although it should be noted that GPT-5 is not part of the test.&amp;nbsp;&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;These safety and transparency alignment evaluations follow claims by users, primarily of ChatGPT, that OpenAI’s models have fallen prey to sycophancy and become overly deferential. OpenAI has since rolled back updates that caused sycophancy.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“We are primarily interested in understanding model propensities for harmful action,” Anthropic said in its report. “We aim to understand the most concerning actions that these models might try to take when given the opportunity, rather than focusing on the real-world likelihood of such opportunities arising or the probability that these actions would be successfully completed.”&lt;/p&gt;



&lt;p&gt;OpenAI noted the tests were designed to show how models interact in an intentionally difficult environment. The scenarios they built are mostly edge cases.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-reasoning-models-hold-on-to-alignment-nbsp"&gt;Reasoning models hold on to alignment&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;The tests covered only the publicly available models from both companies: Anthropic’s Claude 4 Opus and Claude 4 Sonnet, and OpenAI’s GPT-4o, GPT-4.1 o3 and o4-mini. Both companies relaxed the models’ external safeguards.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;OpenAI tested the public APIs for Claude models and defaulted to using Claude 4’s reasoning capabilities. Anthropic said they did not use OpenAI’s o3-pro because it was “not compatible with the API that our tooling best supports.”&lt;/p&gt;



&lt;p&gt;The goal of the tests was not to conduct an apples-to-apples comparison between models, but to determine how often large language models (LLMs) deviated from alignment. Both companies leveraged the SHADE-Arena sabotage evaluation framework, which showed Claude models had higher success rates at subtle sabotage.&lt;/p&gt;



&lt;p&gt;“These tests assess models’ orientations toward difficult or high-stakes situations in simulated settings — rather than ordinary use cases — and often involve long, many-turn interactions,” Anthropic reported. “This kind of evaluation is becoming a significant focus for our alignment science team since it is likely to catch behaviors that are less likely to appear in ordinary pre-deployment testing with real users.”&lt;/p&gt;



&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcLbwj56_JpaPR3ztrYp3mkSBrjZN8CbntqmxhHV9klub8Q_YgqpjBaLFU0TWKeIRNVspEBVw6stibqyGCwGWEyJPuj_oIHOyg2TU7Us3pdqoD77AjzaCO_wsWx728JPDdYjsWRAA?key=4wIYfPcXmdrQx7-_2DhlgA" /&gt;&lt;/figure&gt;



&lt;p&gt;Anthropic said tests like these work better if organizations can compare notes, “since designing these scenarios involves an enormous number of degrees of freedom. No single research team can explore the full space of productive evaluation ideas alone.”&lt;/p&gt;



&lt;p&gt;The findings showed that generally, reasoning models performed robustly and can resist jailbreaking. OpenAI’s o3 was better aligned than Claude 4 Opus, but o4-mini along with GPT-4o and GPT-4.1 “often looked somewhat more concerning than either Claude model.” &lt;/p&gt;



&lt;p&gt;GPT-4o, GPT-4.1 and o4-mini also showed willingness to cooperate with human misuse and gave detailed instructions on how to create drugs, develop bioweapons and scarily, plan terrorist attacks. Both Claude models had higher rates of refusals, meaning the models refused to answer queries it did not know the answers to, to avoid hallucinations.&lt;/p&gt;



&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdIMk3CDWGGRTRYsfMVQ5UoBYr4OB3uyjS_YI0dgJko5xoAj7w-CkozVZw6B3s9vPO8ER4-MiHF79zDw8QDIPfTggwdYubDHkBrXQW_ZYAuF3UZGybsIQ4F5yzB5e6B2yj2ZT7kTg?key=4wIYfPcXmdrQx7-_2DhlgA" /&gt;&lt;/figure&gt;



&lt;p&gt;Models from companies showed “concerning forms of sycophancy” and, at some point, validated harmful decisions of simulated users.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-enterprises-should-know"&gt;What enterprises should know&lt;/h2&gt;



&lt;p&gt;For enterprises, understanding the potential risks associated with models is invaluable. Model evaluations have become almost de rigueur for many organizations, with many testing and benchmarking frameworks now available.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Enterprises should continue to evaluate any model they use, and with GPT-5’s release, should keep in mind these guidelines to run their own safety evaluations:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Test both reasoning and non-reasoning models, because, while reasoning models showed greater resistance to misuse, they could still offer up hallucinations or other harmful behavior.&lt;/li&gt;



&lt;li&gt;Benchmark across vendors since models failed at different metrics.&lt;/li&gt;



&lt;li&gt;Stress test for misuse and syconphancy, and score both the refusal and the utility of those refuse to show the trade-offs between usefulness and guardrails.&lt;/li&gt;



&lt;li&gt;Continue to audit models even after deployment.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;While many evaluations focus on performance, third-party safety alignment tests do exist. For example, this one from Cyata. Last year, OpenAI released an alignment teaching method for its models called Rules-Based Rewards, while Anthropic launched auditing agents to check model safety.&amp;nbsp;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/openai-anthropic-cross-tests-expose-jailbreak-and-misuse-risks-what-enterprises-must-add-to-gpt-5-evaluations/</guid><pubDate>Thu, 28 Aug 2025 15:50:54 +0000</pubDate></item><item><title>MathGPT.ai, the ‘cheat-proof’ tutor and teaching assistant, expands to over 50 institutions (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/28/mathgpt-the-cheat-proof-ai-tutor-and-teaching-assistant-expands-to-over-50-institutions/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As AI becomes more prevalent in the classroom — where students use it to complete assignments and teachers are uncertain about how to address it — an AI platform called MathGPT.ai launched last year with the goal of providing an “anti-cheating” tutor to college students and a teaching assistant to professors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Following a successful pilot program at 30 colleges and universities in the U.S., MathGPT.ai is preparing to nearly double its availability this fall, with hundreds of instructors planning to incorporate the tool. Schools implementing MathGPT.ai in their classrooms include Penn State University, Tufts University, and Liberty University, among others.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The most notable aspect of the platform is that its AI chatbot is trained to never directly give the answer, but instead ask students questions and provide support, much like a human tutor would. This technique, known as Socratic questioning, encourages students to think critically rather than simply memorizing answers.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For instructors, MathGPT.ai serves as a teaching assistant, generating questions and schoolwork based on uploaded textbooks and learning materials, as well as offering auto-grading capabilities and additional AI features.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;MathGPT.ai supports college-level math, including Algebra, Calculus, Trigonometry, and more.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3040563" height="314" src="https://techcrunch.com/wp-content/uploads/2025/08/Course-home-screenshot.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;MathGPT&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to the expansion, MathGPT.ai launched an upgraded version of its platform, introducing new features that give professors more control over how their students use the tools.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The main feature that sets MathGPT.ai apart from other AI companies is its instructor-centric approach. Recently, the platform has become even more focused on instructors’ needs. For example, instructors can now determine when students are allowed to interact with the chatbot. They can specify whether the AI should provide tutoring support for specific assignments while encouraging students to work independently on others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another new feature allows professors to set the number of attempts a student has to answer a question correctly. To promote a low-pressure learning environment, MathGPT.ai has also introduced unlimited practice questions for students. These questions don’t affect their score, allowing students to test their knowledge without stressing about grades.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Additional features that MathGPT.ai offers to instructors include an optional requirement for students to upload images of their work. This enables professors to review submissions and verify the authenticity of the students’ work.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other recent updates include integrations with the three largest Learning Management Systems (LMS): Canvas, Blackboard, and Brightspace. It also added screen reader compatibility and an audio mode, making it more accessible to individuals with disabilities. The platform already offers closed captions for its summarized video lessons, which are notably AI-narrated to sound like historical figures like Ben Franklin and Albert Einstein.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company claims it complies with the Americans with Disabilities Act (ADA).&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3040562" height="641" src="https://techcrunch.com/wp-content/uploads/2025/08/MathGPTimage.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;MathGPT&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;While chatbots like Meta AI, Character.AI, and ChatGPT have faced criticism for inappropriate interactions with young users, MathGPT.ai says it has strict guardrails in place to ensure a safe learning environment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It will not have discussions with you about your girlfriend, boyfriend, or the meaning of life,” Peter Relan, the chairman of MathGPT.ai, told TechCrunch. “It will simply not engage. Because these freestanding chatbots will go in that direction, right? We are not here to entertain those kinds of conversations.” (Relan helped incubate Got It AI and was an early Discord investor.)&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s important to note that, like any chatbot, MathGPT.ai’s assistant still has the potential to produce inaccurate information. The chatbot has a disclosure at the bottom that warns the AI may make mistakes. Users can report the responses to the company if they believe the questions were answered incorrectly.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If you find a mistake, we will reward you with a gift card to tell us what it is. Year one, there were five [hallucinations]. Year two, there was one. So far [this year], none. So we take it very seriously,” Relan said, adding that MathGPT.ai has a team of human annotators to double-check every piece of work, textbook, and all other content to ensure “100% accuracy.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To continue its growth, the company plans to develop a mobile app in the future and expand to more subjects, such as chemistry, economics, and accounting.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;MathGPT.ai offers a free option, as well as a $25 per student per course option. The paid option includes several benefits, such as unlimited AI assignments and LMS integration.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As AI becomes more prevalent in the classroom — where students use it to complete assignments and teachers are uncertain about how to address it — an AI platform called MathGPT.ai launched last year with the goal of providing an “anti-cheating” tutor to college students and a teaching assistant to professors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Following a successful pilot program at 30 colleges and universities in the U.S., MathGPT.ai is preparing to nearly double its availability this fall, with hundreds of instructors planning to incorporate the tool. Schools implementing MathGPT.ai in their classrooms include Penn State University, Tufts University, and Liberty University, among others.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The most notable aspect of the platform is that its AI chatbot is trained to never directly give the answer, but instead ask students questions and provide support, much like a human tutor would. This technique, known as Socratic questioning, encourages students to think critically rather than simply memorizing answers.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For instructors, MathGPT.ai serves as a teaching assistant, generating questions and schoolwork based on uploaded textbooks and learning materials, as well as offering auto-grading capabilities and additional AI features.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;MathGPT.ai supports college-level math, including Algebra, Calculus, Trigonometry, and more.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3040563" height="314" src="https://techcrunch.com/wp-content/uploads/2025/08/Course-home-screenshot.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;MathGPT&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to the expansion, MathGPT.ai launched an upgraded version of its platform, introducing new features that give professors more control over how their students use the tools.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The main feature that sets MathGPT.ai apart from other AI companies is its instructor-centric approach. Recently, the platform has become even more focused on instructors’ needs. For example, instructors can now determine when students are allowed to interact with the chatbot. They can specify whether the AI should provide tutoring support for specific assignments while encouraging students to work independently on others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another new feature allows professors to set the number of attempts a student has to answer a question correctly. To promote a low-pressure learning environment, MathGPT.ai has also introduced unlimited practice questions for students. These questions don’t affect their score, allowing students to test their knowledge without stressing about grades.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Additional features that MathGPT.ai offers to instructors include an optional requirement for students to upload images of their work. This enables professors to review submissions and verify the authenticity of the students’ work.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other recent updates include integrations with the three largest Learning Management Systems (LMS): Canvas, Blackboard, and Brightspace. It also added screen reader compatibility and an audio mode, making it more accessible to individuals with disabilities. The platform already offers closed captions for its summarized video lessons, which are notably AI-narrated to sound like historical figures like Ben Franklin and Albert Einstein.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company claims it complies with the Americans with Disabilities Act (ADA).&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3040562" height="641" src="https://techcrunch.com/wp-content/uploads/2025/08/MathGPTimage.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;MathGPT&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;While chatbots like Meta AI, Character.AI, and ChatGPT have faced criticism for inappropriate interactions with young users, MathGPT.ai says it has strict guardrails in place to ensure a safe learning environment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It will not have discussions with you about your girlfriend, boyfriend, or the meaning of life,” Peter Relan, the chairman of MathGPT.ai, told TechCrunch. “It will simply not engage. Because these freestanding chatbots will go in that direction, right? We are not here to entertain those kinds of conversations.” (Relan helped incubate Got It AI and was an early Discord investor.)&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s important to note that, like any chatbot, MathGPT.ai’s assistant still has the potential to produce inaccurate information. The chatbot has a disclosure at the bottom that warns the AI may make mistakes. Users can report the responses to the company if they believe the questions were answered incorrectly.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If you find a mistake, we will reward you with a gift card to tell us what it is. Year one, there were five [hallucinations]. Year two, there was one. So far [this year], none. So we take it very seriously,” Relan said, adding that MathGPT.ai has a team of human annotators to double-check every piece of work, textbook, and all other content to ensure “100% accuracy.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To continue its growth, the company plans to develop a mobile app in the future and expand to more subjects, such as chemistry, economics, and accounting.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;MathGPT.ai offers a free option, as well as a $25 per student per course option. The paid option includes several benefits, such as unlimited AI assignments and LMS integration.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/28/mathgpt-the-cheat-proof-ai-tutor-and-teaching-assistant-expands-to-over-50-institutions/</guid><pubDate>Thu, 28 Aug 2025 16:00:00 +0000</pubDate></item><item><title>[NEW] AI or not, Will Smith’s crowd video is fresh cringe (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/28/ai-or-not-will-smiths-crowd-video-is-fresh-cringe-2/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Will Smith posted a video on social media that shows oceans of fans cheering him on during his recent European tour.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“My favorite part of the tour is seeing you all up close,” the caption says. “Thank you for seeing me too.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In these thousands-deep crowds, some fans are holding up signs espousing their love for Smith, with one even saying that his music helped them survive cancer.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the video gives off an odd aura — it looks believably real at first glance, until you look closer and find digitally mangled faces, nonsensical finger placements, and oddly augmented features across the series of clips.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-9-16 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The video looks strange enough that fans responded with accusations that the crowd footage was created using AI. It’s bad news for Smith, who’s already suffered reputational damage after “the slap.” If he were using AI to make his concerts look more impressive, or even spinning up stories of fans using his music to cope with cancer treatment, that would be pretty indefensible.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These fans aren’t fake, though — or at least, that’s our best guess. (There’s not a reliable way to determine whether content was created using AI, which has made the current online landscape a nightmare of misinformation.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As tech blogger Andy Baio pointed out, Will Smith has posted photos and videos throughout his tour that show some of the same fans and signs depicted in the questionable video.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;There’s nothing about these older posts that indicates that the photos and videos are synthetic, yet when they’re depicted in this new video, they look like they’ve been generated using AI. It seems like Smith’s team has collaged real footage with AI-generated videos that use real crowd photos as source images, which makes the video even more difficult to interpret.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3040744" height="680" src="https://techcrunch.com/wp-content/uploads/2025/08/Screenshot-2025-08-28-at-11.22.36AM-1.jpg?w=518" width="518" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;The images on the left are taken from an allegedly AI-generated video on Will Smith’s social media, whereas the images on the right were uploaded previously.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Will Smith on Instagram &lt;span class="screen-reader-text"&gt;(opens in a new window)&lt;/span&gt;&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;But social media audiences will not take the time to scroll through past Will Smith posts, find evidence that a fan really did listen to his music during cancer treatment, and give him the benefit of the doubt. What fans will take away from the post is that Smith is posting fake videos of his fans, which is deeply cringe, even if the reality is a bit less egregious.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s bad timing for Smith, too, that YouTube had recently begun testing a feature that would use “traditional machine learning technology to unblur, denoise, and improve clarity” on some Shorts posts — these edits made Smith’s YouTube Short look even more fake than the videos on other platforms.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;YouTube’s creator liaison Rene Ritchie has since shared that the platform will soon allow creators to opt out of this feature, which has proven unpopular thus far.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;You could make the argument that Will Smith has not duped his fans — that his team simply used AI to generate footage from photographs to create a more visually gripping social media post and that this practice could be compared to other forms of video editing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Fans don’t see it this way, though. The public is more resistant to generative AI technology than existing creative tools, like autotune or Photoshop. But even in those cases, many fans remain turned off by artists who rely on these tools in ways that feel untruthful.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If a fan buys tickets to see a pop star, but it turns out that his recordings only sound good because his terrible voice has been autotuned, then they’d feel duped. It’s like photographing a model to advertise a facial moisturizer, only to edit acne off the model’s face.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Once an artist breaks their audience’s trust, it’s hard to win it back — even if you’re the Fresh Prince of Bel-Air.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Will Smith posted a video on social media that shows oceans of fans cheering him on during his recent European tour.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“My favorite part of the tour is seeing you all up close,” the caption says. “Thank you for seeing me too.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In these thousands-deep crowds, some fans are holding up signs espousing their love for Smith, with one even saying that his music helped them survive cancer.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the video gives off an odd aura — it looks believably real at first glance, until you look closer and find digitally mangled faces, nonsensical finger placements, and oddly augmented features across the series of clips.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-9-16 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The video looks strange enough that fans responded with accusations that the crowd footage was created using AI. It’s bad news for Smith, who’s already suffered reputational damage after “the slap.” If he were using AI to make his concerts look more impressive, or even spinning up stories of fans using his music to cope with cancer treatment, that would be pretty indefensible.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These fans aren’t fake, though — or at least, that’s our best guess. (There’s not a reliable way to determine whether content was created using AI, which has made the current online landscape a nightmare of misinformation.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As tech blogger Andy Baio pointed out, Will Smith has posted photos and videos throughout his tour that show some of the same fans and signs depicted in the questionable video.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;There’s nothing about these older posts that indicates that the photos and videos are synthetic, yet when they’re depicted in this new video, they look like they’ve been generated using AI. It seems like Smith’s team has collaged real footage with AI-generated videos that use real crowd photos as source images, which makes the video even more difficult to interpret.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3040744" height="680" src="https://techcrunch.com/wp-content/uploads/2025/08/Screenshot-2025-08-28-at-11.22.36AM-1.jpg?w=518" width="518" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;The images on the left are taken from an allegedly AI-generated video on Will Smith’s social media, whereas the images on the right were uploaded previously.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Will Smith on Instagram &lt;span class="screen-reader-text"&gt;(opens in a new window)&lt;/span&gt;&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;But social media audiences will not take the time to scroll through past Will Smith posts, find evidence that a fan really did listen to his music during cancer treatment, and give him the benefit of the doubt. What fans will take away from the post is that Smith is posting fake videos of his fans, which is deeply cringe, even if the reality is a bit less egregious.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s bad timing for Smith, too, that YouTube had recently begun testing a feature that would use “traditional machine learning technology to unblur, denoise, and improve clarity” on some Shorts posts — these edits made Smith’s YouTube Short look even more fake than the videos on other platforms.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;YouTube’s creator liaison Rene Ritchie has since shared that the platform will soon allow creators to opt out of this feature, which has proven unpopular thus far.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;You could make the argument that Will Smith has not duped his fans — that his team simply used AI to generate footage from photographs to create a more visually gripping social media post and that this practice could be compared to other forms of video editing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Fans don’t see it this way, though. The public is more resistant to generative AI technology than existing creative tools, like autotune or Photoshop. But even in those cases, many fans remain turned off by artists who rely on these tools in ways that feel untruthful.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If a fan buys tickets to see a pop star, but it turns out that his recordings only sound good because his terrible voice has been autotuned, then they’d feel duped. It’s like photographing a model to advertise a facial moisturizer, only to edit acne off the model’s face.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Once an artist breaks their audience’s trust, it’s hard to win it back — even if you’re the Fresh Prince of Bel-Air.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/28/ai-or-not-will-smiths-crowd-video-is-fresh-cringe-2/</guid><pubDate>Thu, 28 Aug 2025 20:02:52 +0000</pubDate></item><item><title>[NEW] Anthropic users face a new choice – opt out or share your chats for AI training (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/28/anthropic-users-face-a-new-choice-opt-out-or-share-your-data-for-ai-training/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic is making some big changes to how it handles user data, requiring all Claude users to decide by September 28 whether they want their conversations used to train AI models. While the company directed us to its blog post on the policy changes when asked about what prompted the move, we’ve formed some theories of our own.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But first, what’s changing: Previously, Anthropic didn’t use consumer chat data for model training. Now, the company wants to train its AI systems on user conversations and coding sessions, and it said it’s extending data retention to five years for those who don’t opt out.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That is a massive update. Previously, users of Anthropic’s consumer products were told that their prompts and conversation outputs would be automatically deleted from Anthropic’s back end within 30 days “unless legally or policy‑required to keep them longer” or their input was flagged as violating its policies, in which case a user’s inputs and outputs might be retained for up to two years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;By consumer, we mean the new policies apply to Claude Free, Pro, and Max users, including those using Claude Code. Business customers using Claude Gov, Claude for Work, Claude for Education, or API access will be unaffected, which is how OpenAI similarly protects enterprise customers from data training policies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So why is this happening? In that post about the update, Anthropic frames the changes around user choice, saying that by not opting out, users will “help us improve model safety, making our systems for detecting harmful content more accurate and less likely to flag harmless conversations.” Users will “also help future Claude models improve at skills like coding, analysis, and reasoning, ultimately leading to better models for all users.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In short, help us help you. But the full truth is probably a little less selfless.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Like every other large language model company, Anthropic needs data more than it needs people to have fuzzy feelings about its brand. Training AI models requires vast amounts of high-quality conversational data, and accessing millions of Claude interactions should provide exactly the kind of real-world content that can improve Anthropic’s competitive positioning against rivals like OpenAI and Google.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond the competitive pressures of AI development, the changes would also seem to reflect broader industry shifts in data policies, as companies like Anthropic and OpenAI face increasing scrutiny over their data retention practices. OpenAI, for instance, is currently fighting a court order that forces the company to retain all consumer ChatGPT conversations indefinitely, including deleted chats, because of a lawsuit filed by The New York Times and other publishers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In June, OpenAI COO Brad Lightcap called this “a sweeping and unnecessary demand” that “fundamentally conflicts with the privacy commitments we have made to our users.” The court order affects ChatGPT Free, Plus, Pro, and Team users, though enterprise customers and those with Zero Data Retention agreements are still protected.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What’s alarming is how much confusion all of these changing usage policies are creating for users, many of whom remain oblivious to them.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In fairness, everything is moving quickly now, so as the tech changes, privacy policies are bound to change. But many of these changes are fairly sweeping and mentioned only fleetingly amid the companies’ other news. (You wouldn’t think Tuesday’s policy changes for Anthropic users were very big news based on where the company placed this update on its press page.)&lt;/p&gt;

&lt;figure class="wp-block-image alignfull size-large"&gt;&lt;img alt="alt" class="wp-image-3040915" height="417" src="https://techcrunch.com/wp-content/uploads/2025/08/Claude-screenshot.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Anthropic&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;br /&gt;But many users don’t realize the guidelines to which they’ve agreed have changed because the design practically guarantees it. Most ChatGPT users keep clicking on “delete” toggles that aren’t technically deleting anything. Meanwhile, Anthropic’s implementation of its new policy follows a familiar pattern.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;How so? New users will choose their preference during signup, but existing users face a pop-up with “Updates to Consumer Terms and Policies” in large text and a prominent black “Accept” button with a much tinier toggle switch for training permissions below in smaller print — and automatically set to “On.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As observed earlier today by The Verge, the design raises concerns that users might quickly click “Accept” without noticing they’re agreeing to data sharing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, the stakes for user awareness couldn’t be higher. Privacy experts have long warned that the complexity surrounding AI makes meaningful user consent nearly unattainable. Under the Biden administration, the Federal Trade Commission even stepped in, warning that AI companies risk enforcement action if they engage in “surreptitiously changing its terms of service or privacy policy, or burying a disclosure behind hyperlinks, in legalese, or in fine print.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Whether the commission — now operating with just three of its five commissioners — still has its eye on these practices today is an open question, one we’ve put directly to the FTC.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic is making some big changes to how it handles user data, requiring all Claude users to decide by September 28 whether they want their conversations used to train AI models. While the company directed us to its blog post on the policy changes when asked about what prompted the move, we’ve formed some theories of our own.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But first, what’s changing: Previously, Anthropic didn’t use consumer chat data for model training. Now, the company wants to train its AI systems on user conversations and coding sessions, and it said it’s extending data retention to five years for those who don’t opt out.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That is a massive update. Previously, users of Anthropic’s consumer products were told that their prompts and conversation outputs would be automatically deleted from Anthropic’s back end within 30 days “unless legally or policy‑required to keep them longer” or their input was flagged as violating its policies, in which case a user’s inputs and outputs might be retained for up to two years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;By consumer, we mean the new policies apply to Claude Free, Pro, and Max users, including those using Claude Code. Business customers using Claude Gov, Claude for Work, Claude for Education, or API access will be unaffected, which is how OpenAI similarly protects enterprise customers from data training policies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So why is this happening? In that post about the update, Anthropic frames the changes around user choice, saying that by not opting out, users will “help us improve model safety, making our systems for detecting harmful content more accurate and less likely to flag harmless conversations.” Users will “also help future Claude models improve at skills like coding, analysis, and reasoning, ultimately leading to better models for all users.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In short, help us help you. But the full truth is probably a little less selfless.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Like every other large language model company, Anthropic needs data more than it needs people to have fuzzy feelings about its brand. Training AI models requires vast amounts of high-quality conversational data, and accessing millions of Claude interactions should provide exactly the kind of real-world content that can improve Anthropic’s competitive positioning against rivals like OpenAI and Google.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond the competitive pressures of AI development, the changes would also seem to reflect broader industry shifts in data policies, as companies like Anthropic and OpenAI face increasing scrutiny over their data retention practices. OpenAI, for instance, is currently fighting a court order that forces the company to retain all consumer ChatGPT conversations indefinitely, including deleted chats, because of a lawsuit filed by The New York Times and other publishers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In June, OpenAI COO Brad Lightcap called this “a sweeping and unnecessary demand” that “fundamentally conflicts with the privacy commitments we have made to our users.” The court order affects ChatGPT Free, Plus, Pro, and Team users, though enterprise customers and those with Zero Data Retention agreements are still protected.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What’s alarming is how much confusion all of these changing usage policies are creating for users, many of whom remain oblivious to them.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In fairness, everything is moving quickly now, so as the tech changes, privacy policies are bound to change. But many of these changes are fairly sweeping and mentioned only fleetingly amid the companies’ other news. (You wouldn’t think Tuesday’s policy changes for Anthropic users were very big news based on where the company placed this update on its press page.)&lt;/p&gt;

&lt;figure class="wp-block-image alignfull size-large"&gt;&lt;img alt="alt" class="wp-image-3040915" height="417" src="https://techcrunch.com/wp-content/uploads/2025/08/Claude-screenshot.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Anthropic&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;br /&gt;But many users don’t realize the guidelines to which they’ve agreed have changed because the design practically guarantees it. Most ChatGPT users keep clicking on “delete” toggles that aren’t technically deleting anything. Meanwhile, Anthropic’s implementation of its new policy follows a familiar pattern.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;How so? New users will choose their preference during signup, but existing users face a pop-up with “Updates to Consumer Terms and Policies” in large text and a prominent black “Accept” button with a much tinier toggle switch for training permissions below in smaller print — and automatically set to “On.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As observed earlier today by The Verge, the design raises concerns that users might quickly click “Accept” without noticing they’re agreeing to data sharing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, the stakes for user awareness couldn’t be higher. Privacy experts have long warned that the complexity surrounding AI makes meaningful user consent nearly unattainable. Under the Biden administration, the Federal Trade Commission even stepped in, warning that AI companies risk enforcement action if they engage in “surreptitiously changing its terms of service or privacy policy, or burying a disclosure behind hyperlinks, in legalese, or in fine print.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Whether the commission — now operating with just three of its five commissioners — still has its eye on these practices today is an open question, one we’ve put directly to the FTC.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/28/anthropic-users-face-a-new-choice-opt-out-or-share-your-data-for-ai-training/</guid><pubDate>Thu, 28 Aug 2025 20:43:12 +0000</pubDate></item><item><title>[NEW] Forget data labeling: Tencent’s R-Zero shows how LLMs can train themselves (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/forget-data-labeling-tencents-r-zero-shows-how-llms-can-train-themselves/</link><description>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;A new training framework &lt;span&gt;developed by researchers at&amp;nbsp;Tencent AI Lab&amp;nbsp;and&amp;nbsp;Washington University in St. Louis&amp;nbsp;enables large language models (LLMs) to improve themselves without requiring&amp;nbsp;&lt;/span&gt;any human-labeled data. The technique, called R-Zero, uses reinforcement learning to generate its own training data from scratch, addressing one of the main bottlenecks in creating self-evolving AI systems. R-Zero works by having two independent models co-evolve by interacting with and challenging each other.&lt;/p&gt;&lt;p&gt;Experiments show that R-Zero substantially improves reasoning capabilities across different LLMs, which could lower the complexity and costs of training advanced AI. For enterprises, this approach could accelerate the development of specialized models for complex reasoning tasks without the massive expense of curating labeled datasets.&lt;/p&gt;&lt;p&gt;The idea behind self-evolving LLMs is to create AI systems that can autonomously generate, refine, and learn from their own experiences. This offers a scalable path toward more intelligent and capable AI. However, a major challenge is that training these models requires large volumes of high-quality tasks and labels, which act as supervision signals for the AI to learn from.&lt;/p&gt;&lt;p&gt;Relying on human annotators to create this data is not only costly and slow but also creates a fundamental bottleneck. It effectively limits an AI’s potential capabilities to what humans can teach it. To address this, researchers have developed label-free methods that derive reward signals directly from a model’s own outputs, for example, by measuring its confidence in an answer. While these methods eliminate the need for explicit labels, they still rely on a pre-existing set of tasks, thereby limiting their applicability in truly self-evolving scenarios.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Other approaches involve having models generate their own tasks to learn from. However, in domains like open-ended reasoning, where there is no simple way to check for correctness (such as a code executor), ensuring the quality of this self-generated data is a significant hurdle.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-r-zero-works"&gt;How R-Zero works&lt;/h2&gt;



&lt;p&gt;R-Zero is a framework designed to train reasoning LLMs that can evolve from zero external data. The process begins with a single base model, which is split into two roles: a “Challenger” and a “Solver.” These two models are optimized independently but evolve together through a continuous cycle of interaction.&lt;/p&gt;



&lt;p&gt;The Challenger’s goal is to create new tasks that are just at the threshold of the Solver’s current abilities, neither too easy nor impossible. The Solver, in turn, is rewarded for solving these increasingly complex tasks. In written comments to VentureBeat, Chengsong Huang, co-author of the paper and a doctoral student at Washington University in St. Louis, explained that this dynamic is crucial because generating high-quality questions is often more complicated than finding the answers.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3016157" height="280" src="https://venturebeat.com/wp-content/uploads/2025/08/image_78dc45.png?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;“What we found in a practical setting is that the biggest challenge is not generating the answers… but rather generating high-quality, novel, and progressively more difficult questions,” Huang said. “We believe that good teachers are far rarer than good students. The co-evolutionary dynamic automates the creation of this ‘teacher,’ ensuring a steady and dynamic curriculum that pushes the Solver’s capabilities far beyond what a static, pre-existing dataset could achieve.”&lt;/p&gt;



&lt;p&gt;Once the Challenger generates enough questions, they are filtered for diversity and compiled into a training dataset. In the Solver’s training phase, it is fine-tuned on these challenging questions. The “correct” answer for each question is determined by a majority vote from the Solver’s own previous attempts.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This entire process repeats, creating a self-improving loop that operates without any human intervention, allowing the two models to push each other to become progressively more capable across each iteration.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-r-zero-in-action"&gt;R-Zero in action&lt;/h2&gt;



&lt;p&gt;The researchers tested R-Zero on several open-source LLMs, including models from the Qwen3 and OctoThinker families. They first trained the models on math problems and then tested whether the learned reasoning skills could generalize to other complex, general-domain benchmarks like MMLU-Pro (multi-language understanding and reasoning tasks) and SuperGPQA (science and reasoning tasks).&lt;/p&gt;



&lt;p&gt;The results showed that R-Zero is a highly effective, model-agnostic framework. For instance, it boosted the Qwen3-4B-Base model’s score by +6.49 on average across math reasoning benchmarks. The training process consistently and substantially improved performance, with gains accumulating over several iterations. The larger Qwen3-8B-Base model saw its average math score climb by +5.51 points after three iterations.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3016158" height="564" src="https://venturebeat.com/wp-content/uploads/2025/08/image_f72f0b.png?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;A key finding was the immediate performance leap after the first iteration, which validated the effectiveness of the Challenger’s role in creating a high-quality learning curriculum. “This confirms that the intelligent curriculum generated by the RL-trained Challenger is significantly more effective than that of a non-trained generator,” the researchers write in their paper.&lt;/p&gt;



&lt;p&gt;Notably, the skills learned from math problems were effectively transferred to general reasoning tasks, thereby enhancing the models’ underlying capabilities. For example, the same Qwen3-4B-Base model showed an improvement of +7.54 on general-domain reasoning benchmarks. Another interesting finding is that R-Zero can serve as a decisive pre-training step. Models first improved by R-Zero achieved even higher performance when later fine-tuned on traditional labeled data, suggesting the framework acts as a performance amplifier.&lt;/p&gt;



&lt;p&gt;For enterprises, the “from zero data” approach could be a game-changer, especially in niche domains where high-quality data is scarce or non-existent. Huang highlights that R-Zero’s main advantage is its ability to sidestep the most expensive and time-consuming part of AI development: data curation.&lt;/p&gt;



&lt;p&gt;“Our approach entirely bypasses the fundamental bottleneck of having to find, label, and curate high-quality datasets,” he said. “This is not just about a cost-saving measure; it’s a pathway toward creating AI that can surpass human capabilities, because it is no longer limited by the scope of human knowledge or data.”&lt;/p&gt;



&lt;p&gt;However, the co-evolutionary process also revealed a critical challenge. As the Challenger successfully generates progressively more difficult problems, the Solver’s ability to produce reliable “correct” answers via majority vote begins to decline. The researchers found that the true accuracy of these self-generated labels dropped from 79% in the first iteration to 63% by the third&lt;span&gt;, compared to a strong oracle LLM such as&amp;nbsp;GPT -4&lt;/span&gt;. This decline in data quality is a key trade-off and a potential bottleneck for the system’s long-term performance.&lt;/p&gt;



&lt;p&gt;Huang acknowledged that this is a fundamental problem for the self-evolving paradigm. “Our work is a proof of concept that demonstrates the potential of this approach, but we acknowledge that maintaining stable, long-term improvement without plateauing is a significant hurdle,” he said. “Solving this problem will be a crucial next step for the entire research community.”&lt;/p&gt;



&lt;p&gt;The researchers also highlight a key limitation of the framework: the current mechanism is best suited for domains like math where correctness can be objectively determined. So, how could this powerful paradigm be extended to more subjective enterprise tasks like generating marketing copy or summarizing reports?&lt;/p&gt;



&lt;p&gt;Huang suggests a potential path forward involves adding a third, co-evolving AI agent to the mix: a “Verifier” or “Critic.”&lt;/p&gt;



&lt;p&gt;“Instead of evaluating for a simple ‘correct’ answer, this Verifier would be trained to evaluate the quality of the Solver’s output based on more nuanced criteria,” he explained. “The co-evolutionary dynamic would then involve the Challenger creating the prompt, the Solver generating the response, and the Verifier providing a quality signal, with all three models improving together.”&lt;/p&gt;



&lt;p&gt;While this remains a direction for future research, it points toward a future where fully autonomous AI systems can master not just objective logic, but subjective reasoning as well.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;A new training framework &lt;span&gt;developed by researchers at&amp;nbsp;Tencent AI Lab&amp;nbsp;and&amp;nbsp;Washington University in St. Louis&amp;nbsp;enables large language models (LLMs) to improve themselves without requiring&amp;nbsp;&lt;/span&gt;any human-labeled data. The technique, called R-Zero, uses reinforcement learning to generate its own training data from scratch, addressing one of the main bottlenecks in creating self-evolving AI systems. R-Zero works by having two independent models co-evolve by interacting with and challenging each other.&lt;/p&gt;&lt;p&gt;Experiments show that R-Zero substantially improves reasoning capabilities across different LLMs, which could lower the complexity and costs of training advanced AI. For enterprises, this approach could accelerate the development of specialized models for complex reasoning tasks without the massive expense of curating labeled datasets.&lt;/p&gt;&lt;p&gt;The idea behind self-evolving LLMs is to create AI systems that can autonomously generate, refine, and learn from their own experiences. This offers a scalable path toward more intelligent and capable AI. However, a major challenge is that training these models requires large volumes of high-quality tasks and labels, which act as supervision signals for the AI to learn from.&lt;/p&gt;&lt;p&gt;Relying on human annotators to create this data is not only costly and slow but also creates a fundamental bottleneck. It effectively limits an AI’s potential capabilities to what humans can teach it. To address this, researchers have developed label-free methods that derive reward signals directly from a model’s own outputs, for example, by measuring its confidence in an answer. While these methods eliminate the need for explicit labels, they still rely on a pre-existing set of tasks, thereby limiting their applicability in truly self-evolving scenarios.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Other approaches involve having models generate their own tasks to learn from. However, in domains like open-ended reasoning, where there is no simple way to check for correctness (such as a code executor), ensuring the quality of this self-generated data is a significant hurdle.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-r-zero-works"&gt;How R-Zero works&lt;/h2&gt;



&lt;p&gt;R-Zero is a framework designed to train reasoning LLMs that can evolve from zero external data. The process begins with a single base model, which is split into two roles: a “Challenger” and a “Solver.” These two models are optimized independently but evolve together through a continuous cycle of interaction.&lt;/p&gt;



&lt;p&gt;The Challenger’s goal is to create new tasks that are just at the threshold of the Solver’s current abilities, neither too easy nor impossible. The Solver, in turn, is rewarded for solving these increasingly complex tasks. In written comments to VentureBeat, Chengsong Huang, co-author of the paper and a doctoral student at Washington University in St. Louis, explained that this dynamic is crucial because generating high-quality questions is often more complicated than finding the answers.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3016157" height="280" src="https://venturebeat.com/wp-content/uploads/2025/08/image_78dc45.png?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;“What we found in a practical setting is that the biggest challenge is not generating the answers… but rather generating high-quality, novel, and progressively more difficult questions,” Huang said. “We believe that good teachers are far rarer than good students. The co-evolutionary dynamic automates the creation of this ‘teacher,’ ensuring a steady and dynamic curriculum that pushes the Solver’s capabilities far beyond what a static, pre-existing dataset could achieve.”&lt;/p&gt;



&lt;p&gt;Once the Challenger generates enough questions, they are filtered for diversity and compiled into a training dataset. In the Solver’s training phase, it is fine-tuned on these challenging questions. The “correct” answer for each question is determined by a majority vote from the Solver’s own previous attempts.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This entire process repeats, creating a self-improving loop that operates without any human intervention, allowing the two models to push each other to become progressively more capable across each iteration.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-r-zero-in-action"&gt;R-Zero in action&lt;/h2&gt;



&lt;p&gt;The researchers tested R-Zero on several open-source LLMs, including models from the Qwen3 and OctoThinker families. They first trained the models on math problems and then tested whether the learned reasoning skills could generalize to other complex, general-domain benchmarks like MMLU-Pro (multi-language understanding and reasoning tasks) and SuperGPQA (science and reasoning tasks).&lt;/p&gt;



&lt;p&gt;The results showed that R-Zero is a highly effective, model-agnostic framework. For instance, it boosted the Qwen3-4B-Base model’s score by +6.49 on average across math reasoning benchmarks. The training process consistently and substantially improved performance, with gains accumulating over several iterations. The larger Qwen3-8B-Base model saw its average math score climb by +5.51 points after three iterations.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3016158" height="564" src="https://venturebeat.com/wp-content/uploads/2025/08/image_f72f0b.png?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;A key finding was the immediate performance leap after the first iteration, which validated the effectiveness of the Challenger’s role in creating a high-quality learning curriculum. “This confirms that the intelligent curriculum generated by the RL-trained Challenger is significantly more effective than that of a non-trained generator,” the researchers write in their paper.&lt;/p&gt;



&lt;p&gt;Notably, the skills learned from math problems were effectively transferred to general reasoning tasks, thereby enhancing the models’ underlying capabilities. For example, the same Qwen3-4B-Base model showed an improvement of +7.54 on general-domain reasoning benchmarks. Another interesting finding is that R-Zero can serve as a decisive pre-training step. Models first improved by R-Zero achieved even higher performance when later fine-tuned on traditional labeled data, suggesting the framework acts as a performance amplifier.&lt;/p&gt;



&lt;p&gt;For enterprises, the “from zero data” approach could be a game-changer, especially in niche domains where high-quality data is scarce or non-existent. Huang highlights that R-Zero’s main advantage is its ability to sidestep the most expensive and time-consuming part of AI development: data curation.&lt;/p&gt;



&lt;p&gt;“Our approach entirely bypasses the fundamental bottleneck of having to find, label, and curate high-quality datasets,” he said. “This is not just about a cost-saving measure; it’s a pathway toward creating AI that can surpass human capabilities, because it is no longer limited by the scope of human knowledge or data.”&lt;/p&gt;



&lt;p&gt;However, the co-evolutionary process also revealed a critical challenge. As the Challenger successfully generates progressively more difficult problems, the Solver’s ability to produce reliable “correct” answers via majority vote begins to decline. The researchers found that the true accuracy of these self-generated labels dropped from 79% in the first iteration to 63% by the third&lt;span&gt;, compared to a strong oracle LLM such as&amp;nbsp;GPT -4&lt;/span&gt;. This decline in data quality is a key trade-off and a potential bottleneck for the system’s long-term performance.&lt;/p&gt;



&lt;p&gt;Huang acknowledged that this is a fundamental problem for the self-evolving paradigm. “Our work is a proof of concept that demonstrates the potential of this approach, but we acknowledge that maintaining stable, long-term improvement without plateauing is a significant hurdle,” he said. “Solving this problem will be a crucial next step for the entire research community.”&lt;/p&gt;



&lt;p&gt;The researchers also highlight a key limitation of the framework: the current mechanism is best suited for domains like math where correctness can be objectively determined. So, how could this powerful paradigm be extended to more subjective enterprise tasks like generating marketing copy or summarizing reports?&lt;/p&gt;



&lt;p&gt;Huang suggests a potential path forward involves adding a third, co-evolving AI agent to the mix: a “Verifier” or “Critic.”&lt;/p&gt;



&lt;p&gt;“Instead of evaluating for a simple ‘correct’ answer, this Verifier would be trained to evaluate the quality of the Solver’s output based on more nuanced criteria,” he explained. “The co-evolutionary dynamic would then involve the Challenger creating the prompt, the Solver generating the response, and the Verifier providing a quality signal, with all three models improving together.”&lt;/p&gt;



&lt;p&gt;While this remains a direction for future research, it points toward a future where fully autonomous AI systems can master not just objective logic, but subjective reasoning as well.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/forget-data-labeling-tencents-r-zero-shows-how-llms-can-train-themselves/</guid><pubDate>Thu, 28 Aug 2025 21:07:08 +0000</pubDate></item><item><title>[NEW] Nvidia’s $46.7B Q2 proves the platform, but its next fight is ASIC economics on inference (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/nvidias-strong-q2-results-cant-mask-the-asic-challenge-in-their-future/</link><description>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Nvidia reported $46.7 billion in revenue for fiscal Q2 2026 in their earnings announcement and call yesterday, with data center revenue hitting $41.1 billion, up 56% year over year. The company also released guidance for Q3, predicting a $54 billion quarter.&lt;/p&gt;&lt;p&gt;Behind these confirmed earnings call numbers lies a more complex story of how custom application-specific integrated circuits (ASICs) are gaining ground in key Nvidia segments and will challenge their growth in the quarters to come.&lt;/p&gt;&lt;p&gt;Bank of America’s Vivek Arya asked Nvidia’s president and CEO, Jensen Huang, if he saw any scenario where ASICs could take market share from Nvidia GPUs. ASICs continue to gain ground on performance and cost advantages over Nvidia, Broadcom projects 55% to 60% AI revenue growth next year.&lt;/p&gt;&lt;p&gt;Huang pushed back hard on the earnings call. He emphasized that building AI infrastructure is “really hard” and most ASIC projects fail to reach production. That’s a fair point, but they have a competitor in Broadcom, which is seeing its AI revenue steadily ramp up, approaching a $20 billion annual run rate. Further underscoring the growing competitive fragmentation of the market is how Google, Meta and Microsoft all deploy custom silicon at scale. The market has spoken.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;h2 class="wp-block-heading" id="h-asics-are-redefining-the-competitive-landscape-in-real-time"&gt;&lt;strong&gt;ASICs are redefining the competitive landscape in real-time&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Nvidia is more than capable of competing with new ASIC providers. Where they’re running into headwinds is how effectively ASIC competitors are positioning the combination of their use cases, performance claims and cost positions. They’re also looking to differentiate themselves in terms of the level of ecosystem lock-in they require, with Broadcom leading in this competitive dimension.&lt;/p&gt;



&lt;p&gt;The following table compares Nvidia Blackwell with its primary competitors. Real-world results vary significantly depending on specific workloads and deployment configurations:&lt;/p&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;thead&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Metric&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Nvidia Blackwell&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Google TPU v5e/v6&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;AWS Trainium/Inferentia2&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Intel Gaudi2/3&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Broadcom Jericho3-AI&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Primary Use Cases&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Training, inference, generative AI&lt;/td&gt;&lt;td&gt;Hyperscale training &amp;amp; inference&lt;/td&gt;&lt;td&gt;AWS-focused training &amp;amp; inference&lt;/td&gt;&lt;td&gt;Training, inference, hybrid-cloud deployments&lt;/td&gt;&lt;td&gt;AI cluster networking&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Performance Claims&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Up to 50x improvement over Hopper*&lt;/td&gt;&lt;td&gt;67% improvement TPU v6 vs v5*&lt;/td&gt;&lt;td&gt;Comparable GPU performance at lower power*&lt;/td&gt;&lt;td&gt;2-4x price-performance vs prior gen*&lt;/td&gt;&lt;td&gt;InfiniBand parity on Ethernet*&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Cost Position&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Premium pricing, comprehensive ecosystem&lt;/td&gt;&lt;td&gt;Significant savings vs GPUs per Google*&lt;/td&gt;&lt;td&gt;Aggressive pricing per AWS marketing*&lt;/td&gt;&lt;td&gt;Budget alternative positioning*&lt;/td&gt;&lt;td&gt;Lower networking TCO per vendor*&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Ecosystem Lock-In&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Moderate (CUDA, proprietary)&lt;/td&gt;&lt;td&gt;High (Google Cloud, TensorFlow/JAX)&lt;/td&gt;&lt;td&gt;High (AWS, proprietary Neuron SDK)&lt;/td&gt;&lt;td&gt;Moderate (supports open stack)&lt;/td&gt;&lt;td&gt;Low (Ethernet-based standards)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Availability&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Universal (cloud, OEM)&lt;/td&gt;&lt;td&gt;Google Cloud-exclusive&lt;/td&gt;&lt;td&gt;AWS-exclusive&lt;/td&gt;&lt;td&gt;Multiple cloud and on-premise&lt;/td&gt;&lt;td&gt;Broadcom direct, OEM integrators&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Strategic Appeal&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Proven scale, broad support&lt;/td&gt;&lt;td&gt;Cloud workload optimization&lt;/td&gt;&lt;td&gt;AWS integration advantages&lt;/td&gt;&lt;td&gt;Multi-cloud flexibility&lt;/td&gt;&lt;td&gt;Simplified networking&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Market Position&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Leadership with margin pressure&lt;/td&gt;&lt;td&gt;Growing in specific workloads&lt;/td&gt;&lt;td&gt;Expanding within AWS&lt;/td&gt;&lt;td&gt;Emerging alternative&lt;/td&gt;&lt;td&gt;Infrastructure enabler&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;*Performance-per-watt improvements and cost savings depend on specific workload characteristics, model types, deployment configurations and vendor testing assumptions. Actual results vary significantly by use case.&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-hyperscalers-continue-building-their-own-paths"&gt;&lt;strong&gt;Hyperscalers continue building their own paths&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Every major cloud provider has adopted custom silicon to gain the performance, cost, ecosystem scale and extensive DevOps advantages of defining an ASIC from the ground up. Google operates TPU v6 in production through its partnership with Broadcom. Meta built MTIA chips specifically for ranking and recommendations. Microsoft develops Project Maia for sustainable AI workloads.&lt;/p&gt;



&lt;p&gt;Amazon Web Services encourages customers to use Trainium for training and Inferentia for inference.&lt;/p&gt;



&lt;p&gt;Add to that the fact that ByteDance runs TikTok recommendations on custom silicon despite geopolitical tensions. That’s billions of inference requests running on ASICs daily, not GPUs.&lt;/p&gt;



&lt;p&gt;CFO Colette Kress acknowledged the competitive reality during the call. She referenced China revenue, saying it had dropped to a low single-digit percentage of data center revenue. Current Q3 guidance excludes H20 shipments to China completely. While Huang’s statements about China’s extensive opportunities tried to steer the earnings call in a positive direction, it was clear that equity analysts weren’t buying all of it.&lt;/p&gt;



&lt;p&gt;The general tone and perspective is that export controls create ongoing uncertainty for Nvidia in a market that arguably represents its second most significant growth opportunity. Huang said that 50% of all AI researchers are in China and he is fully committed to serving that market. &amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-nvidia-s-platform-advantage-is-one-of-their-greatest-strengths"&gt;&lt;strong&gt;Nvidia’s platform advantage is one of their greatest strengths&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Huang made a valid case for Nvidia’s integrated approach during the earnings call. Building modern AI requires six different chip types working together, he argued, and that complexity creates barriers competitors struggle to match. Nvidia doesn’t just ship GPUs anymore, he emphasized multiple times on the earnings call. The company delivers a complete AI infrastructure that scales globally, he emphatically stated, returning to AI infrastructure as a core message of the earnings call, citing it six times. &amp;nbsp;&lt;/p&gt;



&lt;p&gt;The platform’s ubiquity makes it a default configuration supported by nearly every DevOps cycle of cloud hyperscalers. Nvidia runs across AWS, Azure and Google Cloud. PyTorch and TensorFlow also optimize for CUDA by default. When Meta drops a new Llama model or Google updates Gemini, they target Nvidia hardware first because that’s where millions of developers already work. The ecosystem creates its own gravity.&lt;/p&gt;



&lt;p&gt;The networking business validates the AI infrastructure strategy. Revenue hit $7.3 billion in Q2, up 98% year over year. NVLink connects GPUs at speeds traditional networking can’t touch. Huang revealed the real economics during the call: Nvidia captures about 35% of a typical gigawatt AI factory’s budget.&lt;/p&gt;



&lt;p&gt;“Out of a gigawatt AI factory, which can go anywhere from 50 to, you know, plus or minus 10%, let’s say, to $60 billion, we represent about 35% plus or minus of that. … And of course, what you get for that is not a GPU. … we’ve really transitioned to become an AI infrastructure company,” Huang said.&lt;/p&gt;



&lt;p&gt;That’s not just selling chips. that’s&amp;nbsp;owning the architecture&amp;nbsp;and capturing a significant portion of the entire AI build-out, powered by leading-edge networking and compute platforms like NVLink rack-scale systems and Spectrum X Ethernet.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-market-dynamics-are-shifting-quickly-as-nvidia-continues-reporting-strong-results"&gt;&lt;strong&gt;Market dynamics are shifting quickly as Nvidia continues reporting strong results&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Nvidia’s revenue growth decelerated from triple digits to 56% year over year. While that’s still impressive, it’s clear the trajectory of the company’s growth is changing. Competition is starting to have an effect on their growth, with this quarter seeing the most noticeable impact. &amp;nbsp;&lt;/p&gt;



&lt;p&gt;In particular,&amp;nbsp;China’s strategic role&amp;nbsp;in the global AI race drew pointed attention from analysts. As Joe Moore of Morgan Stanley probed late in the call, Huang estimated the&amp;nbsp;2025 China AI infrastructure opportunity at $50 billion. He communicated both optimism about the scale (“the second largest computing market in the world,” with “about 50% of the world’s AI researchers”) and realism about regulatory friction.&lt;/p&gt;



&lt;p&gt;A third pivotal force shaping Nvidia’s trajectory is the expanding complexity and cost of AI infrastructure itself. As hyperscalers and long-standing Nvidia clients invest billions in next-generation build-outs, the networking demands, compute and energy efficiency have intensified.&lt;/p&gt;



&lt;p&gt;Huang’s comments highlighted how “orders of magnitude speed up” from new platforms like Blackwell and innovations in NVLink, InfiniBand, and Spectrum XGS networking redefine the economic returns for customers’ data center capital. Meanwhile, supply chain pressures and the need for constant technological reinvention mean Nvidia must maintain a relentless pace and adaptability to remain entrenched as the preferred architecture provider.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-nvidia-s-path-forward-is-clear"&gt;&lt;strong&gt;Nvidia’s path forward is clear&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Nvidia issuing guidance for Q3 of $54 billion sends the signal that the core part of their DNA is as strong as ever. Continually improving Blackwell while developing Rubin architecture is evidence that their ability to innovate is as strong as ever.&lt;/p&gt;



&lt;p&gt;The question is whether a new type of innovative challenge they’re facing is one they can take on and win with the same level of development intensity they’ve shown in the past. VentureBeat expects Broadcom to continue aggressively pursuing new hyperscaler partnerships and strengthen its roadmap for specific optimizations aimed at inference workloads. Every ASIC competitor will take the competitive intensity they have to a new level, looking to get design wins that create a higher switching costs as well.&lt;/p&gt;



&lt;p&gt;Huang closed the earnings call, acknowledging the stakes: “A new industrial revolution has started. The AI race is on.” That race includes serious competitors Nvidia dismissed just two years ago. Broadcom, Google, Amazon and others invest billions in custom silicon. They’re not experimenting anymore. They’re shipping at scale.&lt;/p&gt;



&lt;p&gt;Nvidia faces its strongest competition since CUDA’s dominance began. The company’s $46.7 billion quarter proves its strength. However, custom silicon’s momentum suggests that the game has changed. The next chapter will test whether Nvidia’s platform advantages outweigh ASIC economics. VentureBeat expects technology buyers to follow the path of fund managers, betting on both Nvidia to sustain its lucrative customer base and ASIC competitors to secure design wins as intensifying competition drives greater market fragmentation.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Nvidia reported $46.7 billion in revenue for fiscal Q2 2026 in their earnings announcement and call yesterday, with data center revenue hitting $41.1 billion, up 56% year over year. The company also released guidance for Q3, predicting a $54 billion quarter.&lt;/p&gt;&lt;p&gt;Behind these confirmed earnings call numbers lies a more complex story of how custom application-specific integrated circuits (ASICs) are gaining ground in key Nvidia segments and will challenge their growth in the quarters to come.&lt;/p&gt;&lt;p&gt;Bank of America’s Vivek Arya asked Nvidia’s president and CEO, Jensen Huang, if he saw any scenario where ASICs could take market share from Nvidia GPUs. ASICs continue to gain ground on performance and cost advantages over Nvidia, Broadcom projects 55% to 60% AI revenue growth next year.&lt;/p&gt;&lt;p&gt;Huang pushed back hard on the earnings call. He emphasized that building AI infrastructure is “really hard” and most ASIC projects fail to reach production. That’s a fair point, but they have a competitor in Broadcom, which is seeing its AI revenue steadily ramp up, approaching a $20 billion annual run rate. Further underscoring the growing competitive fragmentation of the market is how Google, Meta and Microsoft all deploy custom silicon at scale. The market has spoken.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;h2 class="wp-block-heading" id="h-asics-are-redefining-the-competitive-landscape-in-real-time"&gt;&lt;strong&gt;ASICs are redefining the competitive landscape in real-time&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Nvidia is more than capable of competing with new ASIC providers. Where they’re running into headwinds is how effectively ASIC competitors are positioning the combination of their use cases, performance claims and cost positions. They’re also looking to differentiate themselves in terms of the level of ecosystem lock-in they require, with Broadcom leading in this competitive dimension.&lt;/p&gt;



&lt;p&gt;The following table compares Nvidia Blackwell with its primary competitors. Real-world results vary significantly depending on specific workloads and deployment configurations:&lt;/p&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;thead&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Metric&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Nvidia Blackwell&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Google TPU v5e/v6&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;AWS Trainium/Inferentia2&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Intel Gaudi2/3&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Broadcom Jericho3-AI&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Primary Use Cases&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Training, inference, generative AI&lt;/td&gt;&lt;td&gt;Hyperscale training &amp;amp; inference&lt;/td&gt;&lt;td&gt;AWS-focused training &amp;amp; inference&lt;/td&gt;&lt;td&gt;Training, inference, hybrid-cloud deployments&lt;/td&gt;&lt;td&gt;AI cluster networking&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Performance Claims&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Up to 50x improvement over Hopper*&lt;/td&gt;&lt;td&gt;67% improvement TPU v6 vs v5*&lt;/td&gt;&lt;td&gt;Comparable GPU performance at lower power*&lt;/td&gt;&lt;td&gt;2-4x price-performance vs prior gen*&lt;/td&gt;&lt;td&gt;InfiniBand parity on Ethernet*&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Cost Position&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Premium pricing, comprehensive ecosystem&lt;/td&gt;&lt;td&gt;Significant savings vs GPUs per Google*&lt;/td&gt;&lt;td&gt;Aggressive pricing per AWS marketing*&lt;/td&gt;&lt;td&gt;Budget alternative positioning*&lt;/td&gt;&lt;td&gt;Lower networking TCO per vendor*&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Ecosystem Lock-In&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Moderate (CUDA, proprietary)&lt;/td&gt;&lt;td&gt;High (Google Cloud, TensorFlow/JAX)&lt;/td&gt;&lt;td&gt;High (AWS, proprietary Neuron SDK)&lt;/td&gt;&lt;td&gt;Moderate (supports open stack)&lt;/td&gt;&lt;td&gt;Low (Ethernet-based standards)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Availability&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Universal (cloud, OEM)&lt;/td&gt;&lt;td&gt;Google Cloud-exclusive&lt;/td&gt;&lt;td&gt;AWS-exclusive&lt;/td&gt;&lt;td&gt;Multiple cloud and on-premise&lt;/td&gt;&lt;td&gt;Broadcom direct, OEM integrators&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Strategic Appeal&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Proven scale, broad support&lt;/td&gt;&lt;td&gt;Cloud workload optimization&lt;/td&gt;&lt;td&gt;AWS integration advantages&lt;/td&gt;&lt;td&gt;Multi-cloud flexibility&lt;/td&gt;&lt;td&gt;Simplified networking&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Market Position&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Leadership with margin pressure&lt;/td&gt;&lt;td&gt;Growing in specific workloads&lt;/td&gt;&lt;td&gt;Expanding within AWS&lt;/td&gt;&lt;td&gt;Emerging alternative&lt;/td&gt;&lt;td&gt;Infrastructure enabler&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;*Performance-per-watt improvements and cost savings depend on specific workload characteristics, model types, deployment configurations and vendor testing assumptions. Actual results vary significantly by use case.&lt;/em&gt;&lt;em&gt;&lt;/em&gt;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-hyperscalers-continue-building-their-own-paths"&gt;&lt;strong&gt;Hyperscalers continue building their own paths&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Every major cloud provider has adopted custom silicon to gain the performance, cost, ecosystem scale and extensive DevOps advantages of defining an ASIC from the ground up. Google operates TPU v6 in production through its partnership with Broadcom. Meta built MTIA chips specifically for ranking and recommendations. Microsoft develops Project Maia for sustainable AI workloads.&lt;/p&gt;



&lt;p&gt;Amazon Web Services encourages customers to use Trainium for training and Inferentia for inference.&lt;/p&gt;



&lt;p&gt;Add to that the fact that ByteDance runs TikTok recommendations on custom silicon despite geopolitical tensions. That’s billions of inference requests running on ASICs daily, not GPUs.&lt;/p&gt;



&lt;p&gt;CFO Colette Kress acknowledged the competitive reality during the call. She referenced China revenue, saying it had dropped to a low single-digit percentage of data center revenue. Current Q3 guidance excludes H20 shipments to China completely. While Huang’s statements about China’s extensive opportunities tried to steer the earnings call in a positive direction, it was clear that equity analysts weren’t buying all of it.&lt;/p&gt;



&lt;p&gt;The general tone and perspective is that export controls create ongoing uncertainty for Nvidia in a market that arguably represents its second most significant growth opportunity. Huang said that 50% of all AI researchers are in China and he is fully committed to serving that market. &amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-nvidia-s-platform-advantage-is-one-of-their-greatest-strengths"&gt;&lt;strong&gt;Nvidia’s platform advantage is one of their greatest strengths&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Huang made a valid case for Nvidia’s integrated approach during the earnings call. Building modern AI requires six different chip types working together, he argued, and that complexity creates barriers competitors struggle to match. Nvidia doesn’t just ship GPUs anymore, he emphasized multiple times on the earnings call. The company delivers a complete AI infrastructure that scales globally, he emphatically stated, returning to AI infrastructure as a core message of the earnings call, citing it six times. &amp;nbsp;&lt;/p&gt;



&lt;p&gt;The platform’s ubiquity makes it a default configuration supported by nearly every DevOps cycle of cloud hyperscalers. Nvidia runs across AWS, Azure and Google Cloud. PyTorch and TensorFlow also optimize for CUDA by default. When Meta drops a new Llama model or Google updates Gemini, they target Nvidia hardware first because that’s where millions of developers already work. The ecosystem creates its own gravity.&lt;/p&gt;



&lt;p&gt;The networking business validates the AI infrastructure strategy. Revenue hit $7.3 billion in Q2, up 98% year over year. NVLink connects GPUs at speeds traditional networking can’t touch. Huang revealed the real economics during the call: Nvidia captures about 35% of a typical gigawatt AI factory’s budget.&lt;/p&gt;



&lt;p&gt;“Out of a gigawatt AI factory, which can go anywhere from 50 to, you know, plus or minus 10%, let’s say, to $60 billion, we represent about 35% plus or minus of that. … And of course, what you get for that is not a GPU. … we’ve really transitioned to become an AI infrastructure company,” Huang said.&lt;/p&gt;



&lt;p&gt;That’s not just selling chips. that’s&amp;nbsp;owning the architecture&amp;nbsp;and capturing a significant portion of the entire AI build-out, powered by leading-edge networking and compute platforms like NVLink rack-scale systems and Spectrum X Ethernet.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-market-dynamics-are-shifting-quickly-as-nvidia-continues-reporting-strong-results"&gt;&lt;strong&gt;Market dynamics are shifting quickly as Nvidia continues reporting strong results&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Nvidia’s revenue growth decelerated from triple digits to 56% year over year. While that’s still impressive, it’s clear the trajectory of the company’s growth is changing. Competition is starting to have an effect on their growth, with this quarter seeing the most noticeable impact. &amp;nbsp;&lt;/p&gt;



&lt;p&gt;In particular,&amp;nbsp;China’s strategic role&amp;nbsp;in the global AI race drew pointed attention from analysts. As Joe Moore of Morgan Stanley probed late in the call, Huang estimated the&amp;nbsp;2025 China AI infrastructure opportunity at $50 billion. He communicated both optimism about the scale (“the second largest computing market in the world,” with “about 50% of the world’s AI researchers”) and realism about regulatory friction.&lt;/p&gt;



&lt;p&gt;A third pivotal force shaping Nvidia’s trajectory is the expanding complexity and cost of AI infrastructure itself. As hyperscalers and long-standing Nvidia clients invest billions in next-generation build-outs, the networking demands, compute and energy efficiency have intensified.&lt;/p&gt;



&lt;p&gt;Huang’s comments highlighted how “orders of magnitude speed up” from new platforms like Blackwell and innovations in NVLink, InfiniBand, and Spectrum XGS networking redefine the economic returns for customers’ data center capital. Meanwhile, supply chain pressures and the need for constant technological reinvention mean Nvidia must maintain a relentless pace and adaptability to remain entrenched as the preferred architecture provider.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-nvidia-s-path-forward-is-clear"&gt;&lt;strong&gt;Nvidia’s path forward is clear&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Nvidia issuing guidance for Q3 of $54 billion sends the signal that the core part of their DNA is as strong as ever. Continually improving Blackwell while developing Rubin architecture is evidence that their ability to innovate is as strong as ever.&lt;/p&gt;



&lt;p&gt;The question is whether a new type of innovative challenge they’re facing is one they can take on and win with the same level of development intensity they’ve shown in the past. VentureBeat expects Broadcom to continue aggressively pursuing new hyperscaler partnerships and strengthen its roadmap for specific optimizations aimed at inference workloads. Every ASIC competitor will take the competitive intensity they have to a new level, looking to get design wins that create a higher switching costs as well.&lt;/p&gt;



&lt;p&gt;Huang closed the earnings call, acknowledging the stakes: “A new industrial revolution has started. The AI race is on.” That race includes serious competitors Nvidia dismissed just two years ago. Broadcom, Google, Amazon and others invest billions in custom silicon. They’re not experimenting anymore. They’re shipping at scale.&lt;/p&gt;



&lt;p&gt;Nvidia faces its strongest competition since CUDA’s dominance began. The company’s $46.7 billion quarter proves its strength. However, custom silicon’s momentum suggests that the game has changed. The next chapter will test whether Nvidia’s platform advantages outweigh ASIC economics. VentureBeat expects technology buyers to follow the path of fund managers, betting on both Nvidia to sustain its lucrative customer base and ASIC competitors to secure design wins as intensifying competition drives greater market fragmentation.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/nvidias-strong-q2-results-cant-mask-the-asic-challenge-in-their-future/</guid><pubDate>Thu, 28 Aug 2025 21:09:54 +0000</pubDate></item><item><title>[NEW] Nous Research drops Hermes 4 AI models that outperform ChatGPT without content restrictions (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/nous-research-drops-hermes-4-ai-models-that-outperform-chatgpt-without-content-restrictions/</link><description>&lt;p&gt;Nous Research, a secretive artificial intelligence startup that has emerged as a leading voice in the open-source AI movement, quietly released Hermes 4 on Monday, a family of large language models that the company claims can match the performance of leading proprietary systems while offering unprecedented user control and minimal content restrictions.&lt;/p&gt;&lt;p&gt;The release represents a significant escalation in the battle between open-source AI advocates and major technology companies over who should control access to advanced artificial intelligence capabilities. Unlike models from OpenAI, Google, or Anthropic, Hermes 4 is designed to respond to nearly any request without the safety guardrails that have become standard in commercial AI systems.&lt;/p&gt;&lt;p&gt;“Hermes 4 builds on our legacy of user-aligned models with expanded test-time compute capabilities,” Nous Research announced on X (formerly Twitter). “Special attention was given to making the models creative and interesting to interact with, unencumbered by censorship, and neutrally aligned while maintaining state of the art level math, coding, and reasoning performance for open weight models.”&lt;/p&gt;&lt;p&gt;Hermes 4 introduces what Nous Research calls “hybrid reasoning,” allowing users to toggle between fast responses and deeper, step-by-step thinking processes. When activated, the models generate their internal reasoning within special &lt;code&gt;&amp;lt;think&amp;gt;&lt;/code&gt; tags before providing a final answer — similar to OpenAI’s o1 reasoning models but with full transparency into the AI’s thought process.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;The technical achievement is substantial. In testing, Hermes 4’s largest 405-billion parameter model scored 96.3% on the MATH-500 benchmark in reasoning mode and 81.9% on the challenging AIME’24 mathematics competition — performance that rivals or exceeds many proprietary systems costing millions more to develop.&lt;/p&gt;



&lt;p&gt;“The challenge is making thinking traces useful and verifiable without runaway reasoning,” noted AI researcher Rohan Paul on X, highlighting one of the technical breakthroughs in the release.&lt;/p&gt;



&lt;p&gt;Perhaps most notably, Hermes 4 achieved the highest score among all tested models on “RefusalBench,” a new benchmark Nous Research created to measure how often AI systems refuse to answer questions. The model scored 57.1% in reasoning mode, significantly outperforming GPT-4o (17.67%) and Claude Sonnet 4 (17%).&lt;/p&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-3016215" height="562" src="https://venturebeat.com/wp-content/uploads/2025/08/GzS-zJWa4AEonw_.png" width="572" /&gt;&lt;figcaption class="wp-element-caption"&gt;Hermes 4 models from Nous Research answered significantly more questions than competing AI systems on RefusalBench, a test measuring how often models refuse to respond to user requests. (Credit: Nous Research)&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-inside-dataforge-and-atropos-the-breakthrough-training-systems-behind-hermes-4-s-capabilities"&gt;Inside DataForge and Atropos: The breakthrough training systems behind Hermes 4’s capabilities&lt;/h2&gt;



&lt;p&gt;Behind Hermes 4’s capabilities lies a sophisticated training infrastructure that Nous Research has developed over several years. The models were trained using two novel systems: DataForge, a graph-based synthetic data generator, and Atropos, an open-source reinforcement learning framework.&lt;/p&gt;



&lt;p&gt;DataForge creates training data through what the company describes as “random walks” through directed graphs, transforming simple pre-training data into complex instruction-following examples. The system can, for instance, take a Wikipedia article and transform it into a rap song, then generate questions and answers based on that transformation.&lt;/p&gt;



&lt;p&gt;Atropos, meanwhile, operates like hundreds of specialized training environments where AI models practice specific skills—mathematics, coding, tool use, and creative writing—receiving feedback only when they produce correct solutions. This “rejection sampling” approach ensures that only verified, high-quality responses make it into the training data.&lt;/p&gt;



&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Atropos is Nous' Reinforcement Learning framework&lt;/p&gt;&lt;p&gt;Atropos is an open source reinforcement learning environment by Nous that has hundreds of “gyms” (like math, coding, games, tool‑use, vision) to train and evaluate LLM trajectories via scalable, async RL loops.&lt;/p&gt;&lt;p&gt;In other words… pic.twitter.com/fjxaQKClEZ&lt;/p&gt;— Tommy (@Shaughnessy119) August 26, 2025&lt;/blockquote&gt; 



&lt;p&gt;“Nous used these environments to generate the dataset for Hermes 4!” explained Tommy Shaughnessy, a venture capitalist at Delphi Ventures who has invested in Nous Research. “All in the dataset contains 3.5 million reasoning samples and 1.6 million non-reasoning samples! Hermes was trained on RL data, not just static datasets of question and answer!”&lt;/p&gt;



&lt;p&gt;The training process required 192 Nvidia B200 GPUs and 71,616 GPU hours for the largest model — a significant but not unprecedented computational investment that demonstrates how specialized techniques can compete with the massive scale of tech giants.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-nous-research-believes-ai-safety-guardrails-are-annoying-as-hell-and-hurt-innovation"&gt;Why Nous Research believes AI safety guardrails are ‘annoying as hell’ and hurt innovation&lt;/h2&gt;



&lt;p&gt;Nous Research has built its reputation on a philosophy that puts user control above corporate content policies. The company’s models are designed to be “steerable,” meaning they can be fine-tuned or prompted to behave in specific ways without the rigid safety constraints that characterize commercial AI systems.&lt;/p&gt;



&lt;p&gt;“Hermes 4 is not shackled by disclaimers, rules and being overly cautious which is annoying as hell and hurts innovation and usability,” wrote Shaughnessy in a detailed thread analyzing the release. “If its open source but refuses all requests its pointless. Not an issue with Hermes 4.”&lt;/p&gt;



&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Hermes 4 is not shackled by disclaimers, rules and being overly cautious which is annoying as hell and hurts innovation and usability.&lt;/p&gt;&lt;p&gt;Hermes 4 70B is at the complete opposite of the spectrum vs OpenAI's open source model. It's also ~4x more open vs ChatGPT 4o!&lt;/p&gt;&lt;p&gt;If its open… pic.twitter.com/q5RpX1oOzo&lt;/p&gt;— Tommy (@Shaughnessy119) August 26, 2025&lt;/blockquote&gt; 



&lt;p&gt;This approach has made Nous Research popular among AI researchers and developers who want maximum flexibility, but it also places the company at the center of ongoing debates about AI safety and content moderation. While the models can theoretically be used for harmful purposes, Nous Research argues that transparency and user control are preferable to corporate gatekeeping.&lt;/p&gt;



&lt;p&gt;The company’s technical report, released alongside the models, provides unprecedented detail about the training process, evaluation results, and even the actual text outputs from benchmark tests. “We believe this report sets a new standard for transparency in benchmarking,” the company stated.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-a-small-startup-with-192-gpus-is-competing-against-big-tech-s-billion-dollar-ai-budgets"&gt;How a small startup with 192 GPUs is competing against Big Tech’s billion-dollar AI budgets&lt;/h2&gt;



&lt;p&gt;Hermes 4‘s release comes at a pivotal moment in the AI industry. While major technology companies have poured billions into developing increasingly powerful AI systems, a growing open-source movement argues that these capabilities should not be controlled by a handful of corporations.&lt;/p&gt;



&lt;p&gt;Recent months have seen significant advances in open-source AI, with models like Meta’s Llama 3.1, DeepSeek’s R1, and Alibaba’s Qwen series achieving performance that rivals proprietary systems. Hermes 4 represents another step in this progression, particularly in the area of reasoning—long considered a strength of closed systems like OpenAI’s o1.&lt;/p&gt;



&lt;p&gt;“First up, Nous is a startup with dozens of extremely talented people,” noted Shaughnessy. “They do not have the $100b+ annual capex spend of a hyperscaler nor 1,000’s of employees and despite that they continue to put out innovative models and research at an insane pace.”&lt;/p&gt;



&lt;p&gt;The startup, which raised $65 million in funding earlier this year led by Paradigm, has also been developing Psyche Network, a distributed training system that aims to coordinate AI training across internet-connected computers using blockchain technology.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-technical-fix-that-stopped-hermes-4-from-thinking-in-endless-loops"&gt;The technical fix that stopped Hermes 4 from thinking in endless loops&lt;/h2&gt;



&lt;p&gt;One of Hermes 4‘s most significant technical contributions addresses a problem plaguing reasoning models: overly long thinking processes. The researchers found that their smaller 14-billion parameter model would reach maximum context length 60% of the time when reasoning, essentially getting stuck in endless loops of thinking.&lt;/p&gt;



&lt;p&gt;Their solution involved a second training stage that teaches models to stop reasoning at exactly 30,000 tokens, reducing overlong generation by 65-79% while maintaining most of the reasoning performance. This “length control” technique could prove valuable for the broader AI research community.&lt;/p&gt;



&lt;p&gt;“Smaller models (&amp;lt;14B) tend to overthink when distilled, but larger models don’t,” observed AI researcher Muyu He on X, highlighting insights from the technical report.&lt;/p&gt;



&lt;p&gt;However, Hermes 4 still faces limitations common to open-source models. Despite impressive benchmark performance, the models require significant computational resources to run and may not match the ease of use or reliability of commercial AI services for many applications.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-where-to-try-hermes-4-and-what-it-costs-compared-to-chatgpt-and-claude"&gt;Where to try Hermes 4 and what it costs compared to ChatGPT and Claude&lt;/h2&gt;



&lt;p&gt;Nous Research has made Hermes 4 available through multiple channels, reflecting the open-source philosophy. The model weights are freely downloadable on Hugging Face, while the company also offers API access through its revamped chat interface and partnerships with inference providers like Chutes, Nebius, and Luminal.&lt;/p&gt;



&lt;p&gt;“You can try Hermes 4 in the new, revamped Nous Chat UI,” the company announced, highlighting features like parallel interactions and a memory system.&lt;/p&gt;



&lt;p&gt;For enterprise users and researchers, the models represent a potentially attractive alternative to paying for API access to proprietary systems, especially for applications requiring high levels of customization or handling of sensitive content.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-bigger-picture-what-hermes-4-means-for-the-future-of-ai-development"&gt;The bigger picture: What Hermes 4 means for the future of AI development&lt;/h2&gt;



&lt;p&gt;The release of Hermes 4 represents more than just another AI model launch — it’s a statement about who should control the future of artificial intelligence. In an industry increasingly dominated by a handful of tech giants with virtually unlimited resources, Nous Research has demonstrated that innovation can still come from unexpected places.&lt;/p&gt;



&lt;p&gt;The company’s approach raises fundamental questions about the trade-offs between safety and capability, between corporate control and user freedom. While major technology companies argue that careful content moderation and safety guardrails are essential for responsible AI deployment, Nous Research contends that transparency and user agency are more important than corporate-imposed restrictions.&lt;/p&gt;



&lt;p&gt;Whether this philosophy will ultimately prove beneficial or problematic remains to be seen. But one thing is certain: Hermes 4 has shown that the future of AI won’t be determined solely by the companies with the deepest pockets.&lt;/p&gt;



&lt;p&gt;In a field where yesterday’s impossibilities become tomorrow’s commodities, Nous Research just proved that the only thing more dangerous than an AI that says no might be one that’s willing to say yes.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;p&gt;Nous Research, a secretive artificial intelligence startup that has emerged as a leading voice in the open-source AI movement, quietly released Hermes 4 on Monday, a family of large language models that the company claims can match the performance of leading proprietary systems while offering unprecedented user control and minimal content restrictions.&lt;/p&gt;&lt;p&gt;The release represents a significant escalation in the battle between open-source AI advocates and major technology companies over who should control access to advanced artificial intelligence capabilities. Unlike models from OpenAI, Google, or Anthropic, Hermes 4 is designed to respond to nearly any request without the safety guardrails that have become standard in commercial AI systems.&lt;/p&gt;&lt;p&gt;“Hermes 4 builds on our legacy of user-aligned models with expanded test-time compute capabilities,” Nous Research announced on X (formerly Twitter). “Special attention was given to making the models creative and interesting to interact with, unencumbered by censorship, and neutrally aligned while maintaining state of the art level math, coding, and reasoning performance for open weight models.”&lt;/p&gt;&lt;p&gt;Hermes 4 introduces what Nous Research calls “hybrid reasoning,” allowing users to toggle between fast responses and deeper, step-by-step thinking processes. When activated, the models generate their internal reasoning within special &lt;code&gt;&amp;lt;think&amp;gt;&lt;/code&gt; tags before providing a final answer — similar to OpenAI’s o1 reasoning models but with full transparency into the AI’s thought process.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;The technical achievement is substantial. In testing, Hermes 4’s largest 405-billion parameter model scored 96.3% on the MATH-500 benchmark in reasoning mode and 81.9% on the challenging AIME’24 mathematics competition — performance that rivals or exceeds many proprietary systems costing millions more to develop.&lt;/p&gt;



&lt;p&gt;“The challenge is making thinking traces useful and verifiable without runaway reasoning,” noted AI researcher Rohan Paul on X, highlighting one of the technical breakthroughs in the release.&lt;/p&gt;



&lt;p&gt;Perhaps most notably, Hermes 4 achieved the highest score among all tested models on “RefusalBench,” a new benchmark Nous Research created to measure how often AI systems refuse to answer questions. The model scored 57.1% in reasoning mode, significantly outperforming GPT-4o (17.67%) and Claude Sonnet 4 (17%).&lt;/p&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-3016215" height="562" src="https://venturebeat.com/wp-content/uploads/2025/08/GzS-zJWa4AEonw_.png" width="572" /&gt;&lt;figcaption class="wp-element-caption"&gt;Hermes 4 models from Nous Research answered significantly more questions than competing AI systems on RefusalBench, a test measuring how often models refuse to respond to user requests. (Credit: Nous Research)&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-inside-dataforge-and-atropos-the-breakthrough-training-systems-behind-hermes-4-s-capabilities"&gt;Inside DataForge and Atropos: The breakthrough training systems behind Hermes 4’s capabilities&lt;/h2&gt;



&lt;p&gt;Behind Hermes 4’s capabilities lies a sophisticated training infrastructure that Nous Research has developed over several years. The models were trained using two novel systems: DataForge, a graph-based synthetic data generator, and Atropos, an open-source reinforcement learning framework.&lt;/p&gt;



&lt;p&gt;DataForge creates training data through what the company describes as “random walks” through directed graphs, transforming simple pre-training data into complex instruction-following examples. The system can, for instance, take a Wikipedia article and transform it into a rap song, then generate questions and answers based on that transformation.&lt;/p&gt;



&lt;p&gt;Atropos, meanwhile, operates like hundreds of specialized training environments where AI models practice specific skills—mathematics, coding, tool use, and creative writing—receiving feedback only when they produce correct solutions. This “rejection sampling” approach ensures that only verified, high-quality responses make it into the training data.&lt;/p&gt;



&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Atropos is Nous' Reinforcement Learning framework&lt;/p&gt;&lt;p&gt;Atropos is an open source reinforcement learning environment by Nous that has hundreds of “gyms” (like math, coding, games, tool‑use, vision) to train and evaluate LLM trajectories via scalable, async RL loops.&lt;/p&gt;&lt;p&gt;In other words… pic.twitter.com/fjxaQKClEZ&lt;/p&gt;— Tommy (@Shaughnessy119) August 26, 2025&lt;/blockquote&gt; 



&lt;p&gt;“Nous used these environments to generate the dataset for Hermes 4!” explained Tommy Shaughnessy, a venture capitalist at Delphi Ventures who has invested in Nous Research. “All in the dataset contains 3.5 million reasoning samples and 1.6 million non-reasoning samples! Hermes was trained on RL data, not just static datasets of question and answer!”&lt;/p&gt;



&lt;p&gt;The training process required 192 Nvidia B200 GPUs and 71,616 GPU hours for the largest model — a significant but not unprecedented computational investment that demonstrates how specialized techniques can compete with the massive scale of tech giants.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-nous-research-believes-ai-safety-guardrails-are-annoying-as-hell-and-hurt-innovation"&gt;Why Nous Research believes AI safety guardrails are ‘annoying as hell’ and hurt innovation&lt;/h2&gt;



&lt;p&gt;Nous Research has built its reputation on a philosophy that puts user control above corporate content policies. The company’s models are designed to be “steerable,” meaning they can be fine-tuned or prompted to behave in specific ways without the rigid safety constraints that characterize commercial AI systems.&lt;/p&gt;



&lt;p&gt;“Hermes 4 is not shackled by disclaimers, rules and being overly cautious which is annoying as hell and hurts innovation and usability,” wrote Shaughnessy in a detailed thread analyzing the release. “If its open source but refuses all requests its pointless. Not an issue with Hermes 4.”&lt;/p&gt;



&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Hermes 4 is not shackled by disclaimers, rules and being overly cautious which is annoying as hell and hurts innovation and usability.&lt;/p&gt;&lt;p&gt;Hermes 4 70B is at the complete opposite of the spectrum vs OpenAI's open source model. It's also ~4x more open vs ChatGPT 4o!&lt;/p&gt;&lt;p&gt;If its open… pic.twitter.com/q5RpX1oOzo&lt;/p&gt;— Tommy (@Shaughnessy119) August 26, 2025&lt;/blockquote&gt; 



&lt;p&gt;This approach has made Nous Research popular among AI researchers and developers who want maximum flexibility, but it also places the company at the center of ongoing debates about AI safety and content moderation. While the models can theoretically be used for harmful purposes, Nous Research argues that transparency and user control are preferable to corporate gatekeeping.&lt;/p&gt;



&lt;p&gt;The company’s technical report, released alongside the models, provides unprecedented detail about the training process, evaluation results, and even the actual text outputs from benchmark tests. “We believe this report sets a new standard for transparency in benchmarking,” the company stated.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-a-small-startup-with-192-gpus-is-competing-against-big-tech-s-billion-dollar-ai-budgets"&gt;How a small startup with 192 GPUs is competing against Big Tech’s billion-dollar AI budgets&lt;/h2&gt;



&lt;p&gt;Hermes 4‘s release comes at a pivotal moment in the AI industry. While major technology companies have poured billions into developing increasingly powerful AI systems, a growing open-source movement argues that these capabilities should not be controlled by a handful of corporations.&lt;/p&gt;



&lt;p&gt;Recent months have seen significant advances in open-source AI, with models like Meta’s Llama 3.1, DeepSeek’s R1, and Alibaba’s Qwen series achieving performance that rivals proprietary systems. Hermes 4 represents another step in this progression, particularly in the area of reasoning—long considered a strength of closed systems like OpenAI’s o1.&lt;/p&gt;



&lt;p&gt;“First up, Nous is a startup with dozens of extremely talented people,” noted Shaughnessy. “They do not have the $100b+ annual capex spend of a hyperscaler nor 1,000’s of employees and despite that they continue to put out innovative models and research at an insane pace.”&lt;/p&gt;



&lt;p&gt;The startup, which raised $65 million in funding earlier this year led by Paradigm, has also been developing Psyche Network, a distributed training system that aims to coordinate AI training across internet-connected computers using blockchain technology.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-technical-fix-that-stopped-hermes-4-from-thinking-in-endless-loops"&gt;The technical fix that stopped Hermes 4 from thinking in endless loops&lt;/h2&gt;



&lt;p&gt;One of Hermes 4‘s most significant technical contributions addresses a problem plaguing reasoning models: overly long thinking processes. The researchers found that their smaller 14-billion parameter model would reach maximum context length 60% of the time when reasoning, essentially getting stuck in endless loops of thinking.&lt;/p&gt;



&lt;p&gt;Their solution involved a second training stage that teaches models to stop reasoning at exactly 30,000 tokens, reducing overlong generation by 65-79% while maintaining most of the reasoning performance. This “length control” technique could prove valuable for the broader AI research community.&lt;/p&gt;



&lt;p&gt;“Smaller models (&amp;lt;14B) tend to overthink when distilled, but larger models don’t,” observed AI researcher Muyu He on X, highlighting insights from the technical report.&lt;/p&gt;



&lt;p&gt;However, Hermes 4 still faces limitations common to open-source models. Despite impressive benchmark performance, the models require significant computational resources to run and may not match the ease of use or reliability of commercial AI services for many applications.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-where-to-try-hermes-4-and-what-it-costs-compared-to-chatgpt-and-claude"&gt;Where to try Hermes 4 and what it costs compared to ChatGPT and Claude&lt;/h2&gt;



&lt;p&gt;Nous Research has made Hermes 4 available through multiple channels, reflecting the open-source philosophy. The model weights are freely downloadable on Hugging Face, while the company also offers API access through its revamped chat interface and partnerships with inference providers like Chutes, Nebius, and Luminal.&lt;/p&gt;



&lt;p&gt;“You can try Hermes 4 in the new, revamped Nous Chat UI,” the company announced, highlighting features like parallel interactions and a memory system.&lt;/p&gt;



&lt;p&gt;For enterprise users and researchers, the models represent a potentially attractive alternative to paying for API access to proprietary systems, especially for applications requiring high levels of customization or handling of sensitive content.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-bigger-picture-what-hermes-4-means-for-the-future-of-ai-development"&gt;The bigger picture: What Hermes 4 means for the future of AI development&lt;/h2&gt;



&lt;p&gt;The release of Hermes 4 represents more than just another AI model launch — it’s a statement about who should control the future of artificial intelligence. In an industry increasingly dominated by a handful of tech giants with virtually unlimited resources, Nous Research has demonstrated that innovation can still come from unexpected places.&lt;/p&gt;



&lt;p&gt;The company’s approach raises fundamental questions about the trade-offs between safety and capability, between corporate control and user freedom. While major technology companies argue that careful content moderation and safety guardrails are essential for responsible AI deployment, Nous Research contends that transparency and user agency are more important than corporate-imposed restrictions.&lt;/p&gt;



&lt;p&gt;Whether this philosophy will ultimately prove beneficial or problematic remains to be seen. But one thing is certain: Hermes 4 has shown that the future of AI won’t be determined solely by the companies with the deepest pockets.&lt;/p&gt;



&lt;p&gt;In a field where yesterday’s impossibilities become tomorrow’s commodities, Nous Research just proved that the only thing more dangerous than an AI that says no might be one that’s willing to say yes.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/nous-research-drops-hermes-4-ai-models-that-outperform-chatgpt-without-content-restrictions/</guid><pubDate>Thu, 28 Aug 2025 21:46:07 +0000</pubDate></item><item><title>[NEW] Trump administration’s deal is structured to prevent Intel from selling foundry unit (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/28/trump-administrations-deal-is-structured-to-prevent-intel-from-selling-foundry-unit/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/08/newsroom-robert-noyce-bldg-2.jpg.rendition.intel_.web_.1920.1080.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The Trump administration seems intent on controlling Intel’s ability to make key business decisions around its floundering foundry business unit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to reporting from the Financial Times, at a Deutsche Bank conference on Thursday, Intel’s CFO David Zinsner shared new details about the company’s recent deal with the Trump administration, which gave the U.S. government a 10% equity stake.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The deal was structured in a way to penalize Intel if it spins out its foundry business unit, which makes custom chips for outside customers, within the next few years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last week’s deal included a five-year warrant that would allow the U.S. government to take an additional 5% of Intel, at $20 a share, if the company held less than 51% equity in its foundry business. Zinsner said he expects that warrant to expire.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think from the government’s perspective, they were aligned with that; they didn’t want to see us take the business and spin it off or sell it to somebody,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zinsner added that the company received $5.7 billion in cash on Wednesday, as a result of last week’s deal, according to Reuters. (That cash comes from the remaining grants previously awarded, but not yet paid, to Intel under the U.S. CHIPS and Science Act.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;White House press secretary Karoline Leavitt told reporters today that the deal was still being ironed out.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Intel declined to comment on the deal beyond Zinsner’s remarks. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This deal structure is clearly a testament to the Trump administration’s desire to bring more chip manufacturing to the United States as many players in the industry turn to Taiwan Semiconductor Manufacturing Company’s offshore manufacturing instead.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But this warrant also forces Intel to keep a business unit that is losing money. Intel Foundry reported an operating income loss of $3.1 billion during the second quarter and has been a source of strife for the semiconductor business.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;There have been calls from analysts, board members, and investors alike to spin out the struggling foundry unit, which looked like it might actually happen last fall, before Intel Foundry’s architect, former CEO Pat Gelsinger, retired suddenly in December.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/08/newsroom-robert-noyce-bldg-2.jpg.rendition.intel_.web_.1920.1080.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The Trump administration seems intent on controlling Intel’s ability to make key business decisions around its floundering foundry business unit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to reporting from the Financial Times, at a Deutsche Bank conference on Thursday, Intel’s CFO David Zinsner shared new details about the company’s recent deal with the Trump administration, which gave the U.S. government a 10% equity stake.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The deal was structured in a way to penalize Intel if it spins out its foundry business unit, which makes custom chips for outside customers, within the next few years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last week’s deal included a five-year warrant that would allow the U.S. government to take an additional 5% of Intel, at $20 a share, if the company held less than 51% equity in its foundry business. Zinsner said he expects that warrant to expire.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think from the government’s perspective, they were aligned with that; they didn’t want to see us take the business and spin it off or sell it to somebody,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zinsner added that the company received $5.7 billion in cash on Wednesday, as a result of last week’s deal, according to Reuters. (That cash comes from the remaining grants previously awarded, but not yet paid, to Intel under the U.S. CHIPS and Science Act.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;White House press secretary Karoline Leavitt told reporters today that the deal was still being ironed out.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Intel declined to comment on the deal beyond Zinsner’s remarks. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This deal structure is clearly a testament to the Trump administration’s desire to bring more chip manufacturing to the United States as many players in the industry turn to Taiwan Semiconductor Manufacturing Company’s offshore manufacturing instead.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But this warrant also forces Intel to keep a business unit that is losing money. Intel Foundry reported an operating income loss of $3.1 billion during the second quarter and has been a source of strife for the semiconductor business.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;There have been calls from analysts, board members, and investors alike to spin out the struggling foundry unit, which looked like it might actually happen last fall, before Intel Foundry’s architect, former CEO Pat Gelsinger, retired suddenly in December.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/28/trump-administrations-deal-is-structured-to-prevent-intel-from-selling-foundry-unit/</guid><pubDate>Thu, 28 Aug 2025 21:56:27 +0000</pubDate></item><item><title>[NEW] In crowded voice AI market, OpenAI bets on instruction-following and expressive speech to win enterprise adoption (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/in-crowded-voice-ai-market-openai-bets-on-instruction-following-and-expressive-speech-to-win-enterprise-adoption/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;OpenAI adds to an increasingly competitive AI voice market for enterprises with its new model, gpt-realtime, that follows complex instructions and with voices “that sound more natural and expressive.”&lt;/p&gt;



&lt;p&gt;As voice AI continues to grow, and customers find use cases such as customer service calls or real-time translation, the market for realistic-sounding AI voices that also offer enterprise-grade security is heating up. OpenAI claims its new model provides a more human-like voice, but it still needs to compete against companies like ElevenLabs.&lt;/p&gt;



&lt;p&gt;The model will be available on the Realtime API, which the company also made generally available. Along with the gpt-realtime model, OpenAI also released new voices on the API, which it calls Cedar and Marin, and updated its other voices to work with the latest model.&lt;/p&gt;



&lt;p&gt;OpenAI said in a livestream that it worked with its customers who are building voice applications to train gpt-realtime and “carefully aligned the model to evals that are built on real-world scenarios like customer support and academic tutoring.”&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;p&gt;The company touted the model’s ability to create emotive, natural-sounding voices that also align with how developers build with the technology.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-speech-to-speech-models"&gt;Speech-to-speech models&lt;/h2&gt;



&lt;p&gt;The model operates within a speech-to-speech framework, enabling it to understand spoken prompts and respond vocally. Speech-to-speech models are ideally suited for real-time responses, where a person, typically a customer, interacts with an application.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;For example, a customer wants to return some products and calls a customer service platform. They could be talking to an AI voice assistant that responds to questions and requests as if they were speaking with a human.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In a livestream, OpenAI customers T-Mobile showcased an AI voice-powered agent that helps people find new phones. Another customer, the real estate search platform Zillow, showcased an agent who helps someone narrow down a neighborhood to find the perfect place.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;OpenAI said gpt-realtime is its “most advanced, production-ready voice model.” Like its other voice models, it can switch languages mid-sentence. However, OpenAI researchers noted gpt-realtime can follow more complex instructions like “speak emphatically in a French accent.”&lt;/p&gt;



&lt;p&gt;But gpt-realtime faces competition from other models that many brands already use. ElevenLabs released Conversation AI 2.0 in May. Soundhound partners with fast food franchises for an AI voice drive-thru. Emphatic AI startup Hume has launched its EVI 3 model, which allows users to generate AI versions of their own voice.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;As enterprises discover various use cases for voice AI, even more general model providers that offer multimodal LLMs are making a case for themselves. Mistral released its new Voxtral model, stating it would work well with real-time translation. Google is enhancing its audio capabilities and gaining popularity with an audio feature on NotebookLM that converts research notes into a podcast.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-better-instruction-following"&gt;Better instruction following&lt;/h2&gt;



&lt;p&gt;OpenAI said gpt-realtime is smarter and understands native audio better, including the ability to catch non-verbal cues like laughs or sighs.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Benchmarking using the Big Bench Audio eval showed the model scoring 82.8% in accuracy, compared to its previous model, which scored 65.6%. OpenAI did not provide numbers testing gpt-realtime against models from its competitors.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-3016219" height="465" src="https://venturebeat.com/wp-content/uploads/2025/08/image_abee53.png" width="777" /&gt;&lt;/figure&gt;



&lt;p&gt;OpenAI focused on improving the model’s instruction-following capabilities, ensuring the model would adhere to directions more effectively. The new model achieves a score of 30.5% on the MultiChallenge audio benchmark. The engineers also beefed up function calling so gpt-realtime can access the correct tools.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-realtime-api-updates"&gt;Realtime API updates&lt;/h2&gt;



&lt;p&gt;To support the new model and enhance how enterprises integrate real-time AI capabilities into their applications, OpenAI has added several new features to the Realtime API.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It can now support MCP and recognize image inputs, allowing it to inform users about what it sees in real-time. This is a feature Google heavily emphasized during its Project Astra presentation last year.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The Realtime API can also handle Session Initiation Protocol (SIP). SIP connects apps to phones like a public phone network or desk phones, opening up more contact center use cases. Users can also save and reuse prompts on the API.&lt;/p&gt;



&lt;p&gt;So far, people are impressed with the model, although these are still initial tests of a model that was recently released.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Tbh, the MCP and SIP features are the real story here, not just another model. &lt;/p&gt;&lt;p&gt;The ability to connect to external tools and systems seamlessly is what will finally move these models from being impressive demos to being integrated into actual workflows. &lt;/p&gt;&lt;p&gt;The real time aspect…&lt;/p&gt;— JK (@_junaidkhalid1) August 28, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Testing out gpt-realtime&lt;/p&gt;&lt;p&gt;Initial review:&lt;br /&gt;– Noticable audio improvement&lt;br /&gt;– It's a stickler for the instructions (very good)&lt;br /&gt;– Feels fast pic.twitter.com/LtyCs0QLXV&lt;/p&gt;— Jake Colling (@JacobColling) August 28, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Well, GPT-realtime got a livestream not because most users are interested, but for strategic business reasons&lt;/p&gt;&lt;p&gt;Call centers are a major target for LLM providers and the first company to reach a real breakthrough will get massive revenue&lt;/p&gt;— AnKo (@anko_979) August 28, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Pros &amp;amp; Cons from @OpenAI real-time update from someone building in AI audio:&lt;/p&gt;&lt;p&gt;Pro: Better function calling, more emotion, 20% cheaper, better control, image is cool but won't use&lt;/p&gt;&lt;p&gt;Con: no custom voices (creative experience MUST HAVE), still *expensive* vs TTS-LLM-STT pipelines&lt;/p&gt;— Gavin Purcell (@gavinpurcell) August 28, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;OpenAI reduced prices for gpt-realtime by 20% to $32 per million audio input tokens and $64 for audio output tokens.&amp;nbsp;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;OpenAI adds to an increasingly competitive AI voice market for enterprises with its new model, gpt-realtime, that follows complex instructions and with voices “that sound more natural and expressive.”&lt;/p&gt;



&lt;p&gt;As voice AI continues to grow, and customers find use cases such as customer service calls or real-time translation, the market for realistic-sounding AI voices that also offer enterprise-grade security is heating up. OpenAI claims its new model provides a more human-like voice, but it still needs to compete against companies like ElevenLabs.&lt;/p&gt;



&lt;p&gt;The model will be available on the Realtime API, which the company also made generally available. Along with the gpt-realtime model, OpenAI also released new voices on the API, which it calls Cedar and Marin, and updated its other voices to work with the latest model.&lt;/p&gt;



&lt;p&gt;OpenAI said in a livestream that it worked with its customers who are building voice applications to train gpt-realtime and “carefully aligned the model to evals that are built on real-world scenarios like customer support and academic tutoring.”&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;p&gt;The company touted the model’s ability to create emotive, natural-sounding voices that also align with how developers build with the technology.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-speech-to-speech-models"&gt;Speech-to-speech models&lt;/h2&gt;



&lt;p&gt;The model operates within a speech-to-speech framework, enabling it to understand spoken prompts and respond vocally. Speech-to-speech models are ideally suited for real-time responses, where a person, typically a customer, interacts with an application.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;For example, a customer wants to return some products and calls a customer service platform. They could be talking to an AI voice assistant that responds to questions and requests as if they were speaking with a human.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In a livestream, OpenAI customers T-Mobile showcased an AI voice-powered agent that helps people find new phones. Another customer, the real estate search platform Zillow, showcased an agent who helps someone narrow down a neighborhood to find the perfect place.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;OpenAI said gpt-realtime is its “most advanced, production-ready voice model.” Like its other voice models, it can switch languages mid-sentence. However, OpenAI researchers noted gpt-realtime can follow more complex instructions like “speak emphatically in a French accent.”&lt;/p&gt;



&lt;p&gt;But gpt-realtime faces competition from other models that many brands already use. ElevenLabs released Conversation AI 2.0 in May. Soundhound partners with fast food franchises for an AI voice drive-thru. Emphatic AI startup Hume has launched its EVI 3 model, which allows users to generate AI versions of their own voice.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;As enterprises discover various use cases for voice AI, even more general model providers that offer multimodal LLMs are making a case for themselves. Mistral released its new Voxtral model, stating it would work well with real-time translation. Google is enhancing its audio capabilities and gaining popularity with an audio feature on NotebookLM that converts research notes into a podcast.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-better-instruction-following"&gt;Better instruction following&lt;/h2&gt;



&lt;p&gt;OpenAI said gpt-realtime is smarter and understands native audio better, including the ability to catch non-verbal cues like laughs or sighs.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Benchmarking using the Big Bench Audio eval showed the model scoring 82.8% in accuracy, compared to its previous model, which scored 65.6%. OpenAI did not provide numbers testing gpt-realtime against models from its competitors.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-3016219" height="465" src="https://venturebeat.com/wp-content/uploads/2025/08/image_abee53.png" width="777" /&gt;&lt;/figure&gt;



&lt;p&gt;OpenAI focused on improving the model’s instruction-following capabilities, ensuring the model would adhere to directions more effectively. The new model achieves a score of 30.5% on the MultiChallenge audio benchmark. The engineers also beefed up function calling so gpt-realtime can access the correct tools.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-realtime-api-updates"&gt;Realtime API updates&lt;/h2&gt;



&lt;p&gt;To support the new model and enhance how enterprises integrate real-time AI capabilities into their applications, OpenAI has added several new features to the Realtime API.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It can now support MCP and recognize image inputs, allowing it to inform users about what it sees in real-time. This is a feature Google heavily emphasized during its Project Astra presentation last year.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The Realtime API can also handle Session Initiation Protocol (SIP). SIP connects apps to phones like a public phone network or desk phones, opening up more contact center use cases. Users can also save and reuse prompts on the API.&lt;/p&gt;



&lt;p&gt;So far, people are impressed with the model, although these are still initial tests of a model that was recently released.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Tbh, the MCP and SIP features are the real story here, not just another model. &lt;/p&gt;&lt;p&gt;The ability to connect to external tools and systems seamlessly is what will finally move these models from being impressive demos to being integrated into actual workflows. &lt;/p&gt;&lt;p&gt;The real time aspect…&lt;/p&gt;— JK (@_junaidkhalid1) August 28, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Testing out gpt-realtime&lt;/p&gt;&lt;p&gt;Initial review:&lt;br /&gt;– Noticable audio improvement&lt;br /&gt;– It's a stickler for the instructions (very good)&lt;br /&gt;– Feels fast pic.twitter.com/LtyCs0QLXV&lt;/p&gt;— Jake Colling (@JacobColling) August 28, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Well, GPT-realtime got a livestream not because most users are interested, but for strategic business reasons&lt;/p&gt;&lt;p&gt;Call centers are a major target for LLM providers and the first company to reach a real breakthrough will get massive revenue&lt;/p&gt;— AnKo (@anko_979) August 28, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Pros &amp;amp; Cons from @OpenAI real-time update from someone building in AI audio:&lt;/p&gt;&lt;p&gt;Pro: Better function calling, more emotion, 20% cheaper, better control, image is cool but won't use&lt;/p&gt;&lt;p&gt;Con: no custom voices (creative experience MUST HAVE), still *expensive* vs TTS-LLM-STT pipelines&lt;/p&gt;— Gavin Purcell (@gavinpurcell) August 28, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;OpenAI reduced prices for gpt-realtime by 20% to $32 per million audio input tokens and $64 for audio output tokens.&amp;nbsp;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/in-crowded-voice-ai-market-openai-bets-on-instruction-following-and-expressive-speech-to-win-enterprise-adoption/</guid><pubDate>Thu, 28 Aug 2025 23:26:47 +0000</pubDate></item></channel></rss>