<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sun, 10 Aug 2025 06:32:36 +0000</lastBuildDate><item><title>From terabytes to insights: Real-world AI obervability architecture (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/from-terabytes-to-insights-real-world-ai-obervability-architecture/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Consider maintaining and developing an e-commerce platform that processes millions of transactions every minute, generating large amounts of telemetry data, including metrics, logs and traces across multiple microservices. When critical incidents occur, on-call engineers face the daunting task of sifting through an ocean of data to unravel relevant signals and insights. This is equivalent to searching for a needle in a haystack.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This makes observability a source of frustration rather than insight. To alleviate this major pain point, I started exploring a solution to utilize the Model Context Protocol (MCP) to add context and draw inferences from the logs and distributed traces. In this article, I’ll outline my experience building an AI-powered observability platform, explain the system architecture and share actionable insights learned along the way.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-is-observability-challenging"&gt;Why is observability challenging?&lt;/h2&gt;



&lt;p&gt;In modern software systems, observability is not a luxury; it’s a basic necessity. The ability to measure and understand system behavior is foundational to reliability, performance and user trust. As the saying goes, &lt;em&gt;“What you cannot measure, you cannot improve.”&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;Yet, achieving observability in today’s cloud-native, microservice-based architectures is more difficult than ever. A single user request may traverse dozens of microservices, each emitting logs, metrics and traces. The result is an abundance of telemetry data:&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Tens of terabytes of logs per day&lt;/li&gt;



&lt;li&gt;Tens of millions of metric data points and pre-aggregates&lt;/li&gt;



&lt;li&gt;Millions of distributed traces&lt;/li&gt;



&lt;li&gt;Thousands of correlation IDs generated every minute&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;The challenge is not only the data volume, but the data fragmentation. According to New Relic’s 2023 Observability Forecast Report, 50% of organizations report siloed telemetry data, with only 33% achieving a unified view across metrics, logs and traces.&lt;/p&gt;



&lt;p&gt;Logs tell one part of the story, metrics another, traces yet another. Without a consistent thread of context, engineers are forced into manual correlation, relying on intuition, tribal knowledge and tedious detective work during incidents.&lt;/p&gt;



&lt;p&gt;Because of this complexity, I started to wonder: How can AI help us get past fragmented data and offer comprehensive, useful insights?&lt;em&gt; &lt;/em&gt;Specifically, can we make telemetry data intrinsically more meaningful and accessible for both humans and machines using a structured protocol such as MCP?&lt;em&gt; &lt;/em&gt;This project’s foundation was shaped by that central question.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-understanding-mcp-a-data-pipeline-perspective"&gt;Understanding MCP: A data pipeline perspective&lt;/h2&gt;



&lt;p&gt;Anthropic defines MCP as an open standard that allows developers to create a secure two-way connection between data sources and AI tools. This structured data pipeline includes:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Contextual ETL for AI:&lt;/strong&gt; Standardizing context extraction from multiple data sources.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Structured query interface:&lt;/strong&gt; Allows AI queries to access data layers that are transparent and easily understandable.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Semantic data enrichment:&lt;/strong&gt; Embeds meaningful context directly into telemetry signals.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;This has the potential to shift platform observability away from reactive problem solving and toward proactive insights.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-system-architecture-and-data-flow"&gt;System architecture and data flow&lt;/h2&gt;



&lt;p&gt;Before diving into the implementation details, let’s walk through the system architecture.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015359" height="271" src="https://venturebeat.com/wp-content/uploads/2025/08/image2.jpg?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Architecture diagram for the MCP-based AI observability system&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;In the first layer, we develop the contextual telemetry data by embedding standardized metadata in the telemetry signals, such as distributed traces, logs and metrics. Then, in the second layer, enriched data is fed into the MCP server to index, add structure and provide client access to context-enriched data using APIs. Finally, the AI-driven analysis engine utilizes the structured and enriched telemetry data for anomaly detection, correlation and root-cause analysis to troubleshoot application issues.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This layered design ensures that AI and engineering teams receive context-driven, actionable insights from telemetry data.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-implementative-deep-dive-a-three-layer-system"&gt;Implementative deep dive: A three-layer system&lt;/h2&gt;



&lt;p&gt;Let’s explore the actual implementation of our MCP-powered observability platform, focusing on the data flows and transformations at each step.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="h-layer-1-context-enriched-data-generation"&gt;Layer 1: Context-enriched data generation&lt;/h3&gt;



&lt;p&gt;First, we need to ensure our telemetry data contains enough context for meaningful analysis. The core insight is that data correlation needs to happen at creation time, not analysis time.&lt;/p&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;def process_checkout(user_id, cart_items, payment_method):&lt;br /&gt;&amp;nbsp; &amp;nbsp; “””Simulate a checkout process with context-enriched telemetry.”””&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &lt;em&gt;# Generate correlation id&lt;/em&gt;&lt;br /&gt;&amp;nbsp; &amp;nbsp; order_id = f”order-{uuid.uuid4().hex[:8]}”&lt;br /&gt;&amp;nbsp; &amp;nbsp; request_id = f”req-{uuid.uuid4().hex[:8]}”&lt;br /&gt;&amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &lt;em&gt;# Initialize context dictionary that will be applied&lt;/em&gt;&lt;br /&gt;&amp;nbsp; &amp;nbsp; context = {&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “user_id”: user_id,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “order_id”: order_id,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “request_id”: request_id,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “cart_item_count”: len(cart_items),&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “payment_method”: payment_method,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “service_name”: “checkout”,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “service_version”: “v1.0.0”&lt;br /&gt;&amp;nbsp; &amp;nbsp; }&lt;br /&gt;&amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &lt;em&gt;# Start OTel trace with the same context&lt;/em&gt;&lt;br /&gt;&amp;nbsp; &amp;nbsp; with tracer.start_as_current_span(&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “process_checkout”,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; attributes={k: str(v) for k, v in context.items()}&lt;br /&gt;&amp;nbsp; &amp;nbsp; ) as checkout_span:&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;em&gt;# Logging using same context&lt;/em&gt;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; logger.info(f”Starting checkout process”, extra={“context”: json.dumps(context)})&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;em&gt;# Context Propagation&lt;/em&gt;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; with tracer.start_as_current_span(“process_payment”):&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;em&gt;# Process payment logic…&lt;/em&gt;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; logger.info(“Payment processed”, extra={“context”: &lt;p&gt;json.dumps(context)})&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;Code 1. Context enrichment for logs and traces&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;This approach ensures that every telemetry signal (logs, metrics, traces) contains the same core contextual data, solving the correlation problem at the source.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="h-layer-2-data-access-through-the-mcp-server"&gt;Layer 2: Data access through the MCP server&lt;/h3&gt;



&lt;p&gt;Next, I built an MCP server that transforms raw telemetry into a queryable API. The core data operations here involve the following:&lt;/p&gt;



&lt;ol class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Indexing&lt;/strong&gt;: Creating efficient lookups across contextual fields&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Filtering&lt;/strong&gt;: Selecting relevant subsets of telemetry data&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Aggregation&lt;/strong&gt;: Computing statistical measures across time windows&lt;/li&gt;
&lt;/ol&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;@app.post(“/mcp/logs”, response_model=List[Log])&lt;br /&gt;def query_logs(query: LogQuery):&lt;br /&gt;&amp;nbsp; &amp;nbsp; “””Query logs with specific filters”””&lt;br /&gt;&amp;nbsp; &amp;nbsp; results = LOG_DB.copy()&lt;br /&gt;&amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &lt;em&gt;# Apply contextual filters&lt;/em&gt;&lt;br /&gt;&amp;nbsp; &amp;nbsp; if query.request_id:&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; results = [log for log in results if log[“context”].get(“request_id”) == query.request_id]&lt;br /&gt;&amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; if query.user_id:&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; results = [log for log in results if log[“context”].get(“user_id”) == query.user_id]&lt;br /&gt;&amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; # Apply time-based filters&lt;br /&gt;&amp;nbsp; &amp;nbsp; if query.time_range:&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; start_time = datetime.fromisoformat(query.time_range[“start”])&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; end_time = datetime.fromisoformat(query.time_range[“end”])&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; results = [log for log in results&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; if start_time &amp;lt;= datetime.fromisoformat(log[“timestamp”]) &amp;lt;= end_time]&lt;br /&gt;&amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &lt;em&gt;# &lt;/em&gt;&lt;em&gt;Sort&lt;/em&gt;&lt;em&gt; &lt;/em&gt;&lt;em&gt;by&lt;/em&gt;&lt;em&gt; timestamp&lt;/em&gt;&lt;br /&gt;&amp;nbsp; &amp;nbsp; results = sorted(results, key=lambda x: x[“timestamp”], reverse=True)&lt;br /&gt;&amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; return results[:query.limit] if query.limit else results&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;Code 2. Data transformation using the MCP server&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;This layer transforms our telemetry from an unstructured data lake into a structured, query-optimized interface that an AI system can efficiently navigate.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="h-layer-3-ai-driven-analysis-engine"&gt;Layer 3: AI-driven analysis engine&lt;/h3&gt;



&lt;p&gt;The final layer is an AI component that consumes data through the MCP interface, performing:&lt;/p&gt;



&lt;ol class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Multi-dimensional analysis&lt;/strong&gt;: Correlating signals across logs, metrics and traces.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Anomaly detection&lt;/strong&gt;: Identifying statistical deviations from normal patterns.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Root cause determination&lt;/strong&gt;: Using contextual clues to isolate likely sources of issues.&lt;/li&gt;
&lt;/ol&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;def analyze_incident(self, request_id=None, user_id=None, timeframe_minutes=30):&lt;br /&gt;&amp;nbsp; &amp;nbsp; “””Analyze telemetry data to determine root cause and recommendations.”””&lt;br /&gt;&amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &lt;em&gt;# Define analysis time window&lt;/em&gt;&lt;br /&gt;&amp;nbsp; &amp;nbsp; end_time = datetime.now()&lt;br /&gt;&amp;nbsp; &amp;nbsp; start_time = end_time – timedelta(minutes=timeframe_minutes)&lt;br /&gt;&amp;nbsp; &amp;nbsp; time_range = {“start”: start_time.isoformat(), “end”: end_time.isoformat()}&lt;br /&gt;&amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &lt;em&gt;# Fetch relevant telemetry based on context&lt;/em&gt;&lt;br /&gt;&amp;nbsp; &amp;nbsp; logs = self.fetch_logs(request_id=request_id, user_id=user_id, time_range=time_range)&lt;br /&gt;&amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &lt;em&gt;# Extract services mentioned &lt;/em&gt;&lt;em&gt;in&lt;/em&gt;&lt;em&gt; logs &lt;/em&gt;&lt;em&gt;for&lt;/em&gt;&lt;em&gt; targeted metric analysis&lt;/em&gt;&lt;br /&gt;&amp;nbsp; &amp;nbsp; services = set(log.get(“service”, “unknown”) for log in logs)&lt;br /&gt;&amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &lt;em&gt;# Get metrics &lt;/em&gt;&lt;em&gt;for&lt;/em&gt;&lt;em&gt; those services&lt;/em&gt;&lt;br /&gt;&amp;nbsp; &amp;nbsp; metrics_by_service = {}&lt;br /&gt;&amp;nbsp; &amp;nbsp; for service in services:&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; for metric_name in [“latency”, “error_rate”, “throughput”]:&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; metric_data = self.fetch_metrics(service, metric_name, time_range)&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;em&gt;# Calculate statistical properties&lt;/em&gt;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; values = [point[“value”] for point in metric_data[“data_points”]]&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; metrics_by_service[f”{service}.{metric_name}”] = {&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “mean”: statistics.mean(values) if values else 0,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “median”: statistics.median(values) if values else 0,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “stdev”: statistics.stdev(values) if len(values) &amp;gt; 1 else 0,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “min”: min(values) if values else 0,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “max”: max(values) if values else 0&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }&lt;br /&gt;&amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &lt;em&gt;&amp;nbsp;# Identify anomalies using z-score&lt;/em&gt;&lt;em&gt;&lt;br /&gt;&lt;/em&gt;&amp;nbsp; &amp;nbsp; anomalies = []&lt;br /&gt;&amp;nbsp; &amp;nbsp; for metric_name, stats in metrics_by_service.items():&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; if stats[“stdev”] &amp;gt; 0:&amp;nbsp; # Avoid division by zero&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; z_score = (stats[“max”] – stats[“mean”]) / stats[“stdev”]&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; if z_score &amp;gt; 2:&amp;nbsp; # More than 2 standard deviations&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; anomalies.append({&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “metric”: metric_name,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “z_score”: z_score,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “severity”: “high” if z_score &amp;gt; 3 else “medium”&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; })&lt;br /&gt;&amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; return {&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “summary”: ai_summary,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “anomalies”: anomalies,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “impacted_services”: list(services),&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “recommendation”: ai_recommendation&lt;br /&gt;&amp;nbsp; &amp;nbsp; }&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;Code 3. Incident analysis, anomaly detection and inferencing method&lt;/em&gt;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-impact-of-mcp-enhanced-observability"&gt;Impact of MCP-enhanced observability&lt;/h2&gt;



&lt;p&gt;Integrating MCP with observability platforms could improve the management and comprehension of complex telemetry data. The potential benefits include:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Faster anomaly detection, resulting in reduced minimum time to detect (MTTD) and minimum time to resolve (MTTR).&lt;/li&gt;



&lt;li&gt;Easier identification of root causes for issues.&lt;/li&gt;



&lt;li&gt;Less noise and fewer unactionable alerts, thus reducing alert fatigue and improving developer productivity.&lt;/li&gt;



&lt;li&gt;Fewer interruptions and context switches during incident resolution, resulting in improved operational efficiency for an engineering team.&lt;/li&gt;
&lt;/ul&gt;



&lt;h2 class="wp-block-heading" id="h-actionable-insights"&gt;Actionable insights&lt;/h2&gt;



&lt;p&gt;Here are some key insights from this project that will help teams with their observability strategy.&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Contextual metadata should be embedded early in the telemetry generation process to facilitate downstream correlation.&lt;/li&gt;



&lt;li&gt;Structured data interfaces&lt;strong&gt; &lt;/strong&gt;create API-driven, structured query layers to make telemetry more accessible.&lt;/li&gt;



&lt;li&gt;Context-aware AI&lt;strong&gt; &lt;/strong&gt;focuses analysis on context-rich data to improve accuracy and relevance.&lt;/li&gt;



&lt;li&gt;Context enrichment and AI methods should be refined on a regular basis using practical operational feedback.&lt;/li&gt;
&lt;/ul&gt;



&lt;h2 class="wp-block-heading"&gt;Conclusion&lt;/h2&gt;



&lt;p&gt;The amalgamation of structured data pipelines and AI holds enormous promise for observability. We can transform vast telemetry data into actionable insights by leveraging structured protocols such as MCP and AI-driven analyses, resulting in proactive rather than reactive systems. Lumigo identifies three pillars of observability — &lt;em&gt;logs&lt;/em&gt;, &lt;em&gt;metrics&lt;/em&gt;, and &lt;em&gt;traces&lt;/em&gt; — which are essential. Without integration, engineers are forced to manually correlate disparate data sources, slowing incident response.&lt;/p&gt;



&lt;p&gt;How we generate telemetry requires structural changes as well as analytical techniques to extract meaning.&lt;/p&gt;



&lt;p&gt;&lt;em&gt;Pronnoy Goswami is an AI and data scientist with more than a decade in the field. &lt;/em&gt;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Consider maintaining and developing an e-commerce platform that processes millions of transactions every minute, generating large amounts of telemetry data, including metrics, logs and traces across multiple microservices. When critical incidents occur, on-call engineers face the daunting task of sifting through an ocean of data to unravel relevant signals and insights. This is equivalent to searching for a needle in a haystack.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This makes observability a source of frustration rather than insight. To alleviate this major pain point, I started exploring a solution to utilize the Model Context Protocol (MCP) to add context and draw inferences from the logs and distributed traces. In this article, I’ll outline my experience building an AI-powered observability platform, explain the system architecture and share actionable insights learned along the way.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-is-observability-challenging"&gt;Why is observability challenging?&lt;/h2&gt;



&lt;p&gt;In modern software systems, observability is not a luxury; it’s a basic necessity. The ability to measure and understand system behavior is foundational to reliability, performance and user trust. As the saying goes, &lt;em&gt;“What you cannot measure, you cannot improve.”&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;Yet, achieving observability in today’s cloud-native, microservice-based architectures is more difficult than ever. A single user request may traverse dozens of microservices, each emitting logs, metrics and traces. The result is an abundance of telemetry data:&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Tens of terabytes of logs per day&lt;/li&gt;



&lt;li&gt;Tens of millions of metric data points and pre-aggregates&lt;/li&gt;



&lt;li&gt;Millions of distributed traces&lt;/li&gt;



&lt;li&gt;Thousands of correlation IDs generated every minute&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;The challenge is not only the data volume, but the data fragmentation. According to New Relic’s 2023 Observability Forecast Report, 50% of organizations report siloed telemetry data, with only 33% achieving a unified view across metrics, logs and traces.&lt;/p&gt;



&lt;p&gt;Logs tell one part of the story, metrics another, traces yet another. Without a consistent thread of context, engineers are forced into manual correlation, relying on intuition, tribal knowledge and tedious detective work during incidents.&lt;/p&gt;



&lt;p&gt;Because of this complexity, I started to wonder: How can AI help us get past fragmented data and offer comprehensive, useful insights?&lt;em&gt; &lt;/em&gt;Specifically, can we make telemetry data intrinsically more meaningful and accessible for both humans and machines using a structured protocol such as MCP?&lt;em&gt; &lt;/em&gt;This project’s foundation was shaped by that central question.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-understanding-mcp-a-data-pipeline-perspective"&gt;Understanding MCP: A data pipeline perspective&lt;/h2&gt;



&lt;p&gt;Anthropic defines MCP as an open standard that allows developers to create a secure two-way connection between data sources and AI tools. This structured data pipeline includes:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Contextual ETL for AI:&lt;/strong&gt; Standardizing context extraction from multiple data sources.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Structured query interface:&lt;/strong&gt; Allows AI queries to access data layers that are transparent and easily understandable.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Semantic data enrichment:&lt;/strong&gt; Embeds meaningful context directly into telemetry signals.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;This has the potential to shift platform observability away from reactive problem solving and toward proactive insights.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-system-architecture-and-data-flow"&gt;System architecture and data flow&lt;/h2&gt;



&lt;p&gt;Before diving into the implementation details, let’s walk through the system architecture.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015359" height="271" src="https://venturebeat.com/wp-content/uploads/2025/08/image2.jpg?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Architecture diagram for the MCP-based AI observability system&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;In the first layer, we develop the contextual telemetry data by embedding standardized metadata in the telemetry signals, such as distributed traces, logs and metrics. Then, in the second layer, enriched data is fed into the MCP server to index, add structure and provide client access to context-enriched data using APIs. Finally, the AI-driven analysis engine utilizes the structured and enriched telemetry data for anomaly detection, correlation and root-cause analysis to troubleshoot application issues.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This layered design ensures that AI and engineering teams receive context-driven, actionable insights from telemetry data.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-implementative-deep-dive-a-three-layer-system"&gt;Implementative deep dive: A three-layer system&lt;/h2&gt;



&lt;p&gt;Let’s explore the actual implementation of our MCP-powered observability platform, focusing on the data flows and transformations at each step.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="h-layer-1-context-enriched-data-generation"&gt;Layer 1: Context-enriched data generation&lt;/h3&gt;



&lt;p&gt;First, we need to ensure our telemetry data contains enough context for meaningful analysis. The core insight is that data correlation needs to happen at creation time, not analysis time.&lt;/p&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;def process_checkout(user_id, cart_items, payment_method):&lt;br /&gt;&amp;nbsp; &amp;nbsp; “””Simulate a checkout process with context-enriched telemetry.”””&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &lt;em&gt;# Generate correlation id&lt;/em&gt;&lt;br /&gt;&amp;nbsp; &amp;nbsp; order_id = f”order-{uuid.uuid4().hex[:8]}”&lt;br /&gt;&amp;nbsp; &amp;nbsp; request_id = f”req-{uuid.uuid4().hex[:8]}”&lt;br /&gt;&amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &lt;em&gt;# Initialize context dictionary that will be applied&lt;/em&gt;&lt;br /&gt;&amp;nbsp; &amp;nbsp; context = {&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “user_id”: user_id,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “order_id”: order_id,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “request_id”: request_id,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “cart_item_count”: len(cart_items),&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “payment_method”: payment_method,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “service_name”: “checkout”,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “service_version”: “v1.0.0”&lt;br /&gt;&amp;nbsp; &amp;nbsp; }&lt;br /&gt;&amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &lt;em&gt;# Start OTel trace with the same context&lt;/em&gt;&lt;br /&gt;&amp;nbsp; &amp;nbsp; with tracer.start_as_current_span(&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “process_checkout”,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; attributes={k: str(v) for k, v in context.items()}&lt;br /&gt;&amp;nbsp; &amp;nbsp; ) as checkout_span:&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;em&gt;# Logging using same context&lt;/em&gt;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; logger.info(f”Starting checkout process”, extra={“context”: json.dumps(context)})&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;em&gt;# Context Propagation&lt;/em&gt;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; with tracer.start_as_current_span(“process_payment”):&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;em&gt;# Process payment logic…&lt;/em&gt;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; logger.info(“Payment processed”, extra={“context”: &lt;p&gt;json.dumps(context)})&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;Code 1. Context enrichment for logs and traces&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;This approach ensures that every telemetry signal (logs, metrics, traces) contains the same core contextual data, solving the correlation problem at the source.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="h-layer-2-data-access-through-the-mcp-server"&gt;Layer 2: Data access through the MCP server&lt;/h3&gt;



&lt;p&gt;Next, I built an MCP server that transforms raw telemetry into a queryable API. The core data operations here involve the following:&lt;/p&gt;



&lt;ol class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Indexing&lt;/strong&gt;: Creating efficient lookups across contextual fields&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Filtering&lt;/strong&gt;: Selecting relevant subsets of telemetry data&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Aggregation&lt;/strong&gt;: Computing statistical measures across time windows&lt;/li&gt;
&lt;/ol&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;@app.post(“/mcp/logs”, response_model=List[Log])&lt;br /&gt;def query_logs(query: LogQuery):&lt;br /&gt;&amp;nbsp; &amp;nbsp; “””Query logs with specific filters”””&lt;br /&gt;&amp;nbsp; &amp;nbsp; results = LOG_DB.copy()&lt;br /&gt;&amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &lt;em&gt;# Apply contextual filters&lt;/em&gt;&lt;br /&gt;&amp;nbsp; &amp;nbsp; if query.request_id:&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; results = [log for log in results if log[“context”].get(“request_id”) == query.request_id]&lt;br /&gt;&amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; if query.user_id:&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; results = [log for log in results if log[“context”].get(“user_id”) == query.user_id]&lt;br /&gt;&amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; # Apply time-based filters&lt;br /&gt;&amp;nbsp; &amp;nbsp; if query.time_range:&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; start_time = datetime.fromisoformat(query.time_range[“start”])&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; end_time = datetime.fromisoformat(query.time_range[“end”])&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; results = [log for log in results&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; if start_time &amp;lt;= datetime.fromisoformat(log[“timestamp”]) &amp;lt;= end_time]&lt;br /&gt;&amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &lt;em&gt;# &lt;/em&gt;&lt;em&gt;Sort&lt;/em&gt;&lt;em&gt; &lt;/em&gt;&lt;em&gt;by&lt;/em&gt;&lt;em&gt; timestamp&lt;/em&gt;&lt;br /&gt;&amp;nbsp; &amp;nbsp; results = sorted(results, key=lambda x: x[“timestamp”], reverse=True)&lt;br /&gt;&amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; return results[:query.limit] if query.limit else results&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;Code 2. Data transformation using the MCP server&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;This layer transforms our telemetry from an unstructured data lake into a structured, query-optimized interface that an AI system can efficiently navigate.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="h-layer-3-ai-driven-analysis-engine"&gt;Layer 3: AI-driven analysis engine&lt;/h3&gt;



&lt;p&gt;The final layer is an AI component that consumes data through the MCP interface, performing:&lt;/p&gt;



&lt;ol class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Multi-dimensional analysis&lt;/strong&gt;: Correlating signals across logs, metrics and traces.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Anomaly detection&lt;/strong&gt;: Identifying statistical deviations from normal patterns.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Root cause determination&lt;/strong&gt;: Using contextual clues to isolate likely sources of issues.&lt;/li&gt;
&lt;/ol&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;def analyze_incident(self, request_id=None, user_id=None, timeframe_minutes=30):&lt;br /&gt;&amp;nbsp; &amp;nbsp; “””Analyze telemetry data to determine root cause and recommendations.”””&lt;br /&gt;&amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &lt;em&gt;# Define analysis time window&lt;/em&gt;&lt;br /&gt;&amp;nbsp; &amp;nbsp; end_time = datetime.now()&lt;br /&gt;&amp;nbsp; &amp;nbsp; start_time = end_time – timedelta(minutes=timeframe_minutes)&lt;br /&gt;&amp;nbsp; &amp;nbsp; time_range = {“start”: start_time.isoformat(), “end”: end_time.isoformat()}&lt;br /&gt;&amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &lt;em&gt;# Fetch relevant telemetry based on context&lt;/em&gt;&lt;br /&gt;&amp;nbsp; &amp;nbsp; logs = self.fetch_logs(request_id=request_id, user_id=user_id, time_range=time_range)&lt;br /&gt;&amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &lt;em&gt;# Extract services mentioned &lt;/em&gt;&lt;em&gt;in&lt;/em&gt;&lt;em&gt; logs &lt;/em&gt;&lt;em&gt;for&lt;/em&gt;&lt;em&gt; targeted metric analysis&lt;/em&gt;&lt;br /&gt;&amp;nbsp; &amp;nbsp; services = set(log.get(“service”, “unknown”) for log in logs)&lt;br /&gt;&amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &lt;em&gt;# Get metrics &lt;/em&gt;&lt;em&gt;for&lt;/em&gt;&lt;em&gt; those services&lt;/em&gt;&lt;br /&gt;&amp;nbsp; &amp;nbsp; metrics_by_service = {}&lt;br /&gt;&amp;nbsp; &amp;nbsp; for service in services:&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; for metric_name in [“latency”, “error_rate”, “throughput”]:&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; metric_data = self.fetch_metrics(service, metric_name, time_range)&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;em&gt;# Calculate statistical properties&lt;/em&gt;&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; values = [point[“value”] for point in metric_data[“data_points”]]&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; metrics_by_service[f”{service}.{metric_name}”] = {&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “mean”: statistics.mean(values) if values else 0,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “median”: statistics.median(values) if values else 0,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “stdev”: statistics.stdev(values) if len(values) &amp;gt; 1 else 0,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “min”: min(values) if values else 0,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “max”: max(values) if values else 0&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; }&lt;br /&gt;&amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &lt;em&gt;&amp;nbsp;# Identify anomalies using z-score&lt;/em&gt;&lt;em&gt;&lt;br /&gt;&lt;/em&gt;&amp;nbsp; &amp;nbsp; anomalies = []&lt;br /&gt;&amp;nbsp; &amp;nbsp; for metric_name, stats in metrics_by_service.items():&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; if stats[“stdev”] &amp;gt; 0:&amp;nbsp; # Avoid division by zero&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; z_score = (stats[“max”] – stats[“mean”]) / stats[“stdev”]&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; if z_score &amp;gt; 2:&amp;nbsp; # More than 2 standard deviations&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; anomalies.append({&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “metric”: metric_name,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “z_score”: z_score,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “severity”: “high” if z_score &amp;gt; 3 else “medium”&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; })&lt;br /&gt;&amp;nbsp; &amp;nbsp;&lt;br /&gt;&amp;nbsp; &amp;nbsp; return {&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “summary”: ai_summary,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “anomalies”: anomalies,&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “impacted_services”: list(services),&lt;br /&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; “recommendation”: ai_recommendation&lt;br /&gt;&amp;nbsp; &amp;nbsp; }&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;Code 3. Incident analysis, anomaly detection and inferencing method&lt;/em&gt;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-impact-of-mcp-enhanced-observability"&gt;Impact of MCP-enhanced observability&lt;/h2&gt;



&lt;p&gt;Integrating MCP with observability platforms could improve the management and comprehension of complex telemetry data. The potential benefits include:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Faster anomaly detection, resulting in reduced minimum time to detect (MTTD) and minimum time to resolve (MTTR).&lt;/li&gt;



&lt;li&gt;Easier identification of root causes for issues.&lt;/li&gt;



&lt;li&gt;Less noise and fewer unactionable alerts, thus reducing alert fatigue and improving developer productivity.&lt;/li&gt;



&lt;li&gt;Fewer interruptions and context switches during incident resolution, resulting in improved operational efficiency for an engineering team.&lt;/li&gt;
&lt;/ul&gt;



&lt;h2 class="wp-block-heading" id="h-actionable-insights"&gt;Actionable insights&lt;/h2&gt;



&lt;p&gt;Here are some key insights from this project that will help teams with their observability strategy.&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Contextual metadata should be embedded early in the telemetry generation process to facilitate downstream correlation.&lt;/li&gt;



&lt;li&gt;Structured data interfaces&lt;strong&gt; &lt;/strong&gt;create API-driven, structured query layers to make telemetry more accessible.&lt;/li&gt;



&lt;li&gt;Context-aware AI&lt;strong&gt; &lt;/strong&gt;focuses analysis on context-rich data to improve accuracy and relevance.&lt;/li&gt;



&lt;li&gt;Context enrichment and AI methods should be refined on a regular basis using practical operational feedback.&lt;/li&gt;
&lt;/ul&gt;



&lt;h2 class="wp-block-heading"&gt;Conclusion&lt;/h2&gt;



&lt;p&gt;The amalgamation of structured data pipelines and AI holds enormous promise for observability. We can transform vast telemetry data into actionable insights by leveraging structured protocols such as MCP and AI-driven analyses, resulting in proactive rather than reactive systems. Lumigo identifies three pillars of observability — &lt;em&gt;logs&lt;/em&gt;, &lt;em&gt;metrics&lt;/em&gt;, and &lt;em&gt;traces&lt;/em&gt; — which are essential. Without integration, engineers are forced to manually correlate disparate data sources, slowing incident response.&lt;/p&gt;



&lt;p&gt;How we generate telemetry requires structural changes as well as analytical techniques to extract meaning.&lt;/p&gt;



&lt;p&gt;&lt;em&gt;Pronnoy Goswami is an AI and data scientist with more than a decade in the field. &lt;/em&gt;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/from-terabytes-to-insights-real-world-ai-obervability-architecture/</guid><pubDate>Sat, 09 Aug 2025 19:15:00 +0000</pubDate></item></channel></rss>