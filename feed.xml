<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 22 Oct 2025 06:33:11 +0000</lastBuildDate><item><title>YouTube’s likeness detection has arrived to help stop AI doppelgängers (AI – Ars Technica)</title><link>https://arstechnica.com/google/2025/10/youtube-rolls-out-likeness-detection-to-help-creators-combat-ai-fakes/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Likeness detection will flag possible AI fakes, but Google doesn’t guarantee removal.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Man using phone in front of YouTube logo" class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/06/youtube-300x169.jpg" width="300" /&gt;
                  &lt;img alt="Man using phone in front of YouTube logo" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/06/youtube-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Chris Ratcliffe/Bloomberg via Getty

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;AI content has proliferated across the Internet over the past few years, but those early confabulations with mutated hands have evolved into synthetic images and videos that can be hard to differentiate from reality. Having helped to create this problem, Google has some responsibility to keep AI video in check on YouTube. To that end, the company has started rolling out its promised likeness detection system for creators.&lt;/p&gt;
&lt;p&gt;Google’s powerful and freely available AI models have helped fuel the rise of AI content, some of which is aimed at spreading misinformation and harassing individuals. Creators and influencers fear their brands could be tainted by a flood of AI videos that show them saying and doing things that never happened—even lawmakers are fretting about this. Google has placed a large bet on the value of AI content, so banning AI from YouTube, as many want, simply isn’t happening.&lt;/p&gt;
&lt;p&gt;Earlier this year, YouTube promised tools that would flag face-stealing AI content on the platform. The likeness detection tool, which is similar to the site’s copyright detection system, has now expanded beyond the initial small group of testers. YouTube says the first batch of eligible creators have been notified that they can use likeness detection, but interested parties will need to hand Google even more personal information to get protection from AI fakes.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Sneak Peek: Likeness Detection on YouTube.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;Currently, likeness detection is a beta feature in limited testing, so not all creators will see it as an option in YouTube Studio. When it does appear, it will be tucked into the existing “Content detection” menu. In YouTube’s demo video, the setup flow appears to assume the channel has only a single host whose likeness needs protection. That person must verify their identity, which requires a photo of a government ID and a video of their face. It’s unclear why YouTube needs this data in addition to the videos people have already posted with their oh-so stealable faces, but rules are rules.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;No guarantees&lt;/h2&gt;
&lt;p&gt;After signing up, YouTube will flag videos from other channels that appear to have the user’s face. YouTube’s algorithm can’t know for sure what is and is not an AI video. So some of the face match results may be false positives from channels that have used a short clip under fair use guidelines.&lt;/p&gt;
&lt;p&gt;If creators do spot an AI fake, they can add some details and submit a report in a few minutes. If the video includes content copied from the creator’s channel that does not adhere to fair use guidelines, YouTube suggests also submitting a copyright removal request. However, just because a person’s likeness appears in an AI video does not necessarily mean YouTube will remove it.&lt;/p&gt;
&lt;p&gt;YouTube has published a rundown of the factors its reviewers will take into account when deciding whether or not to approve a removal request. For example, parody content labeled as AI or videos with an unrealistic style may not meet the threshold for removal. On the flip side, you can safely assume that a realistic AI video showing someone endorsing a product or engaging in illegal activity will run afoul of the rules and be removed from YouTube.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2123515 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="YouTube AI detection UI" class="fullwidth full" height="632" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/YT-AI-detect.png" width="797" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Likeness detection will appear alongside copyright claims.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          YouTube

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;While this may be an emerging issue for creators right now, AI content on YouTube is likely to kick into overdrive soon. Google recently unveiled its new Veo 3.1 video model, which includes support for both portrait and landscape AI videos. The company has previously promised to integrate Veo with YouTube, making it even easier for people to churn out AI slop that may include depictions of real people.&lt;/p&gt;
&lt;p&gt;Google rival OpenAI has seen success (at least in terms of popularity) with its Sora AI video app and the new Sora 2 model powering it. This could push Google to accelerate its AI plans for YouTube, but as we’ve seen with Sora, people love making public figures do weird things. Popular creators may have to begin filing AI likeness complaints as regularly as they do DMCA takedowns.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Likeness detection will flag possible AI fakes, but Google doesn’t guarantee removal.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Man using phone in front of YouTube logo" class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/06/youtube-300x169.jpg" width="300" /&gt;
                  &lt;img alt="Man using phone in front of YouTube logo" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/06/youtube-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Chris Ratcliffe/Bloomberg via Getty

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;AI content has proliferated across the Internet over the past few years, but those early confabulations with mutated hands have evolved into synthetic images and videos that can be hard to differentiate from reality. Having helped to create this problem, Google has some responsibility to keep AI video in check on YouTube. To that end, the company has started rolling out its promised likeness detection system for creators.&lt;/p&gt;
&lt;p&gt;Google’s powerful and freely available AI models have helped fuel the rise of AI content, some of which is aimed at spreading misinformation and harassing individuals. Creators and influencers fear their brands could be tainted by a flood of AI videos that show them saying and doing things that never happened—even lawmakers are fretting about this. Google has placed a large bet on the value of AI content, so banning AI from YouTube, as many want, simply isn’t happening.&lt;/p&gt;
&lt;p&gt;Earlier this year, YouTube promised tools that would flag face-stealing AI content on the platform. The likeness detection tool, which is similar to the site’s copyright detection system, has now expanded beyond the initial small group of testers. YouTube says the first batch of eligible creators have been notified that they can use likeness detection, but interested parties will need to hand Google even more personal information to get protection from AI fakes.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Sneak Peek: Likeness Detection on YouTube.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;Currently, likeness detection is a beta feature in limited testing, so not all creators will see it as an option in YouTube Studio. When it does appear, it will be tucked into the existing “Content detection” menu. In YouTube’s demo video, the setup flow appears to assume the channel has only a single host whose likeness needs protection. That person must verify their identity, which requires a photo of a government ID and a video of their face. It’s unclear why YouTube needs this data in addition to the videos people have already posted with their oh-so stealable faces, but rules are rules.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;No guarantees&lt;/h2&gt;
&lt;p&gt;After signing up, YouTube will flag videos from other channels that appear to have the user’s face. YouTube’s algorithm can’t know for sure what is and is not an AI video. So some of the face match results may be false positives from channels that have used a short clip under fair use guidelines.&lt;/p&gt;
&lt;p&gt;If creators do spot an AI fake, they can add some details and submit a report in a few minutes. If the video includes content copied from the creator’s channel that does not adhere to fair use guidelines, YouTube suggests also submitting a copyright removal request. However, just because a person’s likeness appears in an AI video does not necessarily mean YouTube will remove it.&lt;/p&gt;
&lt;p&gt;YouTube has published a rundown of the factors its reviewers will take into account when deciding whether or not to approve a removal request. For example, parody content labeled as AI or videos with an unrealistic style may not meet the threshold for removal. On the flip side, you can safely assume that a realistic AI video showing someone endorsing a product or engaging in illegal activity will run afoul of the rules and be removed from YouTube.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2123515 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="YouTube AI detection UI" class="fullwidth full" height="632" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/YT-AI-detect.png" width="797" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Likeness detection will appear alongside copyright claims.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          YouTube

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;While this may be an emerging issue for creators right now, AI content on YouTube is likely to kick into overdrive soon. Google recently unveiled its new Veo 3.1 video model, which includes support for both portrait and landscape AI videos. The company has previously promised to integrate Veo with YouTube, making it even easier for people to churn out AI slop that may include depictions of real people.&lt;/p&gt;
&lt;p&gt;Google rival OpenAI has seen success (at least in terms of popularity) with its Sora AI video app and the new Sora 2 model powering it. This could push Google to accelerate its AI plans for YouTube, but as we’ve seen with Sora, people love making public figures do weird things. Popular creators may have to begin filing AI likeness complaints as regularly as they do DMCA takedowns.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/google/2025/10/youtube-rolls-out-likeness-detection-to-help-creators-combat-ai-fakes/</guid><pubDate>Tue, 21 Oct 2025 18:46:42 +0000</pubDate></item><item><title>OpenAI looks for its “Google Chrome” moment with new Atlas web browser (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/10/openais-new-atlas-web-browser-wants-to-let-you-chat-with-a-page/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        MacOS version launches today, includes Agent Mode preview to “use the Internet for you.”
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="320" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/atlaslogo-640x320.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/atlaslogo.jpg" width="720" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A new logo for a new browser.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          OpenAI

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Back in 2008, Google launched the Chrome browser to help better integrate its industry-leading search engine into the web-browsing experience. Today, OpenAI announced the Atlas browser that it hopes will do something similar for its ChatGPT large language model, answering the question “What if I could chat with a browser?” as the OpenAI team put it.&lt;/p&gt;
&lt;p&gt;OpenAI Founder and CEO Sam Altman said in a live stream announcement that Atlas will let users “chat with a page,” helping ChatGPT become a core way that users interact with the place where “a ton of work and life happens” online. “The way that we hope people will use the Internet in the future… is that the chat experience and a web browser can be a great analogue,” he said.&lt;/p&gt;
&lt;p&gt;The new browser is available for download now on macOS, and Altman promised Windows and mobile versions would be rolled out “as quick as we can.”&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;/figure&gt;
&lt;h2&gt;An LLM that follows you&lt;/h2&gt;
&lt;p&gt;The home screen of a new Atlas tab mirrors the simplicity of the Chrome search box, with a text field prompting users to “Ask ChatGPT or type a URL.” Users can access their chat history or different ChatGPT models using an interface similar to that on ChatGPT.com. The Atlas browser will also populate suggestions below that search box, which could range from links to news stories to suggestions for tasks the browser can perform for you.&lt;/p&gt;
&lt;p&gt;During the livestream, the OpenAI team said that Atlas has features that web users have come to expect from a browser: tabs, bookmarks, and auto-fill among them. But the integration with ChatGPT now means that “chat comes with you everywhere” in the browsing experience.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;That means you can use ChatGPT to search through your bookmarks or browsing history using human-parsable language prompts. It also means you can bring up a “side chat” next to your current page and ask questions that rely on the context of that specific page. And if you want to edit a Gmail draft using ChatGPT, you can now do that directly in the draft window, without the need to copy and paste between a ChatGPT window and an editor.&lt;/p&gt;
&lt;div class="ars-lightbox align-fullwidth my-5"&gt;
    
          &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="576" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/atlas4-1024x576.png" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Letting ChatGPT edit text directly in a Gmail window.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="505" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/atlas3-1024x505.png" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;The default search experience on Atlas, with tabs for more traditional results.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Letting ChatGPT edit text directly in a Gmail window.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;The default search experience on Atlas, with tabs for more traditional results.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="500" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/atlas2-1024x500.png" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Side chat lets you ask ChatGPT questions about the active webpage.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="554" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/atlas1-1024x554.png" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;The default "New Tab" experience in Atlas, complete with some suggestions.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Side chat lets you ask ChatGPT questions about the active webpage.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;The default "New Tab" experience in Atlas, complete with some suggestions.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
    
    
      &lt;/div&gt;

&lt;p&gt;When typing in a short search prompt, Atlas will, by default, reply as an LLM, with written answers with embedded links to sourcing where appropriate (à la OpenAI’s existing search function). But the browser will also provide tabs with more traditional lists of links, images, videos, or news like those you would get from a search engine without LLM features.&lt;/p&gt;
&lt;h2&gt;Let us do the browsing&lt;/h2&gt;
&lt;p&gt;To wrap up the livestreamed demonstration, the OpenAI team showed off Atlas’ Agent Mode. While the “preview mode” feature is only available to ChatGPT Plus and Pro subscribers, research lead Will Ellsworth said he hoped it would eventually help users toward “an amazing tool for vibe life-ing” in the same way that LLM coding tools have become tools for “vibe coding.”&lt;/p&gt;
&lt;p&gt;To that end, the team showed the browser taking planning tasks written in a Google Docs table and moving them over to the task management software Linear over the course of a few minutes. Agent Mode was also shown taking the ingredients list from a recipe webpage and adding them directly to the user’s Instacart in a different tab (though the demo Agent stopped before checkout to get approval from the user).&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="ars-lightbox align-fullwidth my-5"&gt;
    
          &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="576" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/atlas5-1024x576.png" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Atlas' Agent Mode takes over to move planning tasks from one web-based app to another.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="507" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/atlas6-1024x507.png" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Atlas' Agent Mode adds items from a recipe to a user's Instacart.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Atlas' Agent Mode takes over to move planning tasks from one web-based app to another.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Atlas' Agent Mode adds items from a recipe to a user's Instacart.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
      
    
    
      &lt;/div&gt;

&lt;p&gt;Atlas users can watch Agent Mode as it clicks through various tabs and webpages, taking over at any time, or they can let it operate in the background without oversight. Users can activate Agent Mode directly using a drop-down menu, but ChatGPT can also suggest it be turned on when a user prompt suggests a task that it might be able to help with.&lt;/p&gt;
&lt;p&gt;The OpenAI team said Agent Mode can click around as if it were a human user, with full access to that user’s authentication and browsing history. But the Agent Mode can only operate inside web tabs and can’t execute code outside of the browser, OpenAI said. You can also manually control whether a new Atlas tab is “logged in” or “logged out” of various other web services, and use incognito windows for browsing you don’t want the LLM to remember.&lt;/p&gt;
&lt;h2&gt;A crowded field&lt;/h2&gt;
&lt;p&gt;Established competitors in the browser space have been trying to integrate similar AI features into their products for a while now: Microsoft with a version of Copilot built into the Edge browser and Google with Chrome-based Gemini features that it promises will include “Agentic features” in the coming months. A number of startups are also focused on building AI-powered browsers from the ground up, most notably Perplexity, which recently made a bold $34.5 billion bid for Chrome despite a total market valuation of just $14 million.&lt;/p&gt;
&lt;p&gt;OpenAI also notably publicly expressed interest in buying Chrome back in April, though recent legal updates in that antitrust case mean Google now seems unlikely to sell in the near future.&lt;/p&gt;
&lt;p&gt;The Information reported on OpenAI’s browser plans last year, and Reuters followed up with more information from unnamed sources in July. Reuters noted that a browser will give OpenAI more direct access to valuable user data beyond what gets typed into a ChatGPT prompt window and could provide a simple way to integrate ads into the ChatGPT experience. But of course, that all depends on how many of ChatGPT’s 700 million-plus weekly active users are willing to abandon their current browser in favor of a less proven competitor from a major LLM brand.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        MacOS version launches today, includes Agent Mode preview to “use the Internet for you.”
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="320" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/atlaslogo-640x320.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/atlaslogo.jpg" width="720" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A new logo for a new browser.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          OpenAI

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Back in 2008, Google launched the Chrome browser to help better integrate its industry-leading search engine into the web-browsing experience. Today, OpenAI announced the Atlas browser that it hopes will do something similar for its ChatGPT large language model, answering the question “What if I could chat with a browser?” as the OpenAI team put it.&lt;/p&gt;
&lt;p&gt;OpenAI Founder and CEO Sam Altman said in a live stream announcement that Atlas will let users “chat with a page,” helping ChatGPT become a core way that users interact with the place where “a ton of work and life happens” online. “The way that we hope people will use the Internet in the future… is that the chat experience and a web browser can be a great analogue,” he said.&lt;/p&gt;
&lt;p&gt;The new browser is available for download now on macOS, and Altman promised Windows and mobile versions would be rolled out “as quick as we can.”&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;/figure&gt;
&lt;h2&gt;An LLM that follows you&lt;/h2&gt;
&lt;p&gt;The home screen of a new Atlas tab mirrors the simplicity of the Chrome search box, with a text field prompting users to “Ask ChatGPT or type a URL.” Users can access their chat history or different ChatGPT models using an interface similar to that on ChatGPT.com. The Atlas browser will also populate suggestions below that search box, which could range from links to news stories to suggestions for tasks the browser can perform for you.&lt;/p&gt;
&lt;p&gt;During the livestream, the OpenAI team said that Atlas has features that web users have come to expect from a browser: tabs, bookmarks, and auto-fill among them. But the integration with ChatGPT now means that “chat comes with you everywhere” in the browsing experience.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;That means you can use ChatGPT to search through your bookmarks or browsing history using human-parsable language prompts. It also means you can bring up a “side chat” next to your current page and ask questions that rely on the context of that specific page. And if you want to edit a Gmail draft using ChatGPT, you can now do that directly in the draft window, without the need to copy and paste between a ChatGPT window and an editor.&lt;/p&gt;
&lt;div class="ars-lightbox align-fullwidth my-5"&gt;
    
          &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="576" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/atlas4-1024x576.png" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Letting ChatGPT edit text directly in a Gmail window.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="505" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/atlas3-1024x505.png" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;The default search experience on Atlas, with tabs for more traditional results.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Letting ChatGPT edit text directly in a Gmail window.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;The default search experience on Atlas, with tabs for more traditional results.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="500" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/atlas2-1024x500.png" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Side chat lets you ask ChatGPT questions about the active webpage.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="554" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/atlas1-1024x554.png" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;The default "New Tab" experience in Atlas, complete with some suggestions.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Side chat lets you ask ChatGPT questions about the active webpage.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;The default "New Tab" experience in Atlas, complete with some suggestions.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
    
    
      &lt;/div&gt;

&lt;p&gt;When typing in a short search prompt, Atlas will, by default, reply as an LLM, with written answers with embedded links to sourcing where appropriate (à la OpenAI’s existing search function). But the browser will also provide tabs with more traditional lists of links, images, videos, or news like those you would get from a search engine without LLM features.&lt;/p&gt;
&lt;h2&gt;Let us do the browsing&lt;/h2&gt;
&lt;p&gt;To wrap up the livestreamed demonstration, the OpenAI team showed off Atlas’ Agent Mode. While the “preview mode” feature is only available to ChatGPT Plus and Pro subscribers, research lead Will Ellsworth said he hoped it would eventually help users toward “an amazing tool for vibe life-ing” in the same way that LLM coding tools have become tools for “vibe coding.”&lt;/p&gt;
&lt;p&gt;To that end, the team showed the browser taking planning tasks written in a Google Docs table and moving them over to the task management software Linear over the course of a few minutes. Agent Mode was also shown taking the ingredients list from a recipe webpage and adding them directly to the user’s Instacart in a different tab (though the demo Agent stopped before checkout to get approval from the user).&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="ars-lightbox align-fullwidth my-5"&gt;
    
          &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="576" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/atlas5-1024x576.png" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Atlas' Agent Mode takes over to move planning tasks from one web-based app to another.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="alt" class="ars-gallery-image" height="507" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/atlas6-1024x507.png" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Atlas' Agent Mode adds items from a recipe to a user's Instacart.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Atlas' Agent Mode takes over to move planning tasks from one web-based app to another.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;Atlas' Agent Mode adds items from a recipe to a user's Instacart.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      OpenAI
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
      
    
    
      &lt;/div&gt;

&lt;p&gt;Atlas users can watch Agent Mode as it clicks through various tabs and webpages, taking over at any time, or they can let it operate in the background without oversight. Users can activate Agent Mode directly using a drop-down menu, but ChatGPT can also suggest it be turned on when a user prompt suggests a task that it might be able to help with.&lt;/p&gt;
&lt;p&gt;The OpenAI team said Agent Mode can click around as if it were a human user, with full access to that user’s authentication and browsing history. But the Agent Mode can only operate inside web tabs and can’t execute code outside of the browser, OpenAI said. You can also manually control whether a new Atlas tab is “logged in” or “logged out” of various other web services, and use incognito windows for browsing you don’t want the LLM to remember.&lt;/p&gt;
&lt;h2&gt;A crowded field&lt;/h2&gt;
&lt;p&gt;Established competitors in the browser space have been trying to integrate similar AI features into their products for a while now: Microsoft with a version of Copilot built into the Edge browser and Google with Chrome-based Gemini features that it promises will include “Agentic features” in the coming months. A number of startups are also focused on building AI-powered browsers from the ground up, most notably Perplexity, which recently made a bold $34.5 billion bid for Chrome despite a total market valuation of just $14 million.&lt;/p&gt;
&lt;p&gt;OpenAI also notably publicly expressed interest in buying Chrome back in April, though recent legal updates in that antitrust case mean Google now seems unlikely to sell in the near future.&lt;/p&gt;
&lt;p&gt;The Information reported on OpenAI’s browser plans last year, and Reuters followed up with more information from unnamed sources in July. Reuters noted that a browser will give OpenAI more direct access to valuable user data beyond what gets typed into a ChatGPT prompt window and could provide a simple way to integrate ads into the ChatGPT experience. But of course, that all depends on how many of ChatGPT’s 700 million-plus weekly active users are willing to abandon their current browser in favor of a less proven competitor from a major LLM brand.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/10/openais-new-atlas-web-browser-wants-to-let-you-chat-with-a-page/</guid><pubDate>Tue, 21 Oct 2025 19:02:10 +0000</pubDate></item><item><title>Cloudflare CEO Matthew Prince is pushing UK regulator to unbundle Google’s search and AI crawlers (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/21/cloudflare-ceo-matthew-prince-is-pushing-uk-regulator-to-unbundle-googles-search-and-ai-crawlers/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/videoframe_402382.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;After earlier this year launching a marketplace that allows websites to charge AI bots for scraping their content, web infrastructure provider Cloudflare is pushing for increased regulation in the AI sector. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s chief executive, Matthew Prince, says he’s in London to speak with the U.K.’s Competition and Markets Authority (CMA), where he’s proposing stricter rules on how Google should be able to compete in the AI race, given its search dominance.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The CMA earlier this month designated Google with a special status in the search and advertising markets because of its “substantial and entrenched” position. The move will allow the regulator to impose more stringent regulations beyond just search and ads, including in areas like Google’s AI Overviews and AI Mode, the Discover feed, Top Stories, and News tab. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to Prince, Cloudflare is in a good position to make recommendations because it’s not in the AI business itself but has a large number of relationships with the AI companies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We don’t have a dog directly in the fight. We’re not an AI company,” Prince said, speaking at the Bloomberg Tech conference in London this week. “We’re not a media publisher, but we’re this network that sits between them — 80% of the AI companies are our customers,” he added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Cloudflare boss believes that Google should have to compete on the same footing as other AI companies, which is not what it’s doing today, he said. Rather, Google uses its existing web crawler to crawl content for its AI products and services, in addition to its search engine. This, Prince said, gives Google an unfair advantage. (Prince is referring to Googlebot, which crawls for Search, including its AI features, like AI Overviews. A Google spokesperson, Ned Adriance, said that site owners can opt out of having content used for training AI products with Google Extended, which doesn’t impact a site’s inclusion in Google Search. Some media companies would likely prefer to fully opt out of AI features, however, so the point largely stands.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Google is saying, ‘We have an absolute God-given right to all of the content in the world, even if we don’t pay for it, because look what we did for the last 27 years,’” Prince explained. “And they’re saying we can take it and use the same crawler we use for search in order to power our AI systems. And if you want to opt out of one, you have to opt out of both,” he noted.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;This, obviously, is not feasible for most, particularly those in the media business, where losing search means losing about 20% of your revenue, the executive said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“But it gets even worse. If you block Google’s crawler, it blocks their ad safety team, which means that your advertisements across all of your platforms stop working, which is just a non-starter,” Prince added. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Because Google bundles its crawler, it’s able to get access to content that others, like Anthropic, OpenAI, and Perplexity, would have to pay for.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“The problem is that we then will have effectively handed the game to Google,” he said. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The solution, Prince said, is to foster a lot of competition in the market, where potentially thousands of AI companies could compete to buy content from thousands of media businesses and millions of small businesses. He suggested that what the U.K.’s CMA was doing by flagging Google as a potential regulatory target was a thoughtful move, and one that indicates they’re aware of Google’s unique advantage.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cloudflare has also provided the CMA with data that shows how Google’s crawler works and why it’s nearly impossible for other players to replicate the same success Google could have. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Prince isn’t the only one to share these opinions in recent days. Last month, Neil Vogel, CEO of People, Inc., the largest digital and print publisher in the United States, which operates over 40 media brands, said essentially the same thing. In an interview, he called out Google as a “bad actor,” saying that media companies had no choice but to let Google crawl their sites for AI content because of the way the crawlers were combined.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Vogel, whose company had adopted Cloudflare’s solution to block AI crawlers&amp;nbsp;that don’t pay, claimed the system was working, as he said deal discussions were underway with several large LLM providers. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Updated with Google comment. &lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/videoframe_402382.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;After earlier this year launching a marketplace that allows websites to charge AI bots for scraping their content, web infrastructure provider Cloudflare is pushing for increased regulation in the AI sector. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s chief executive, Matthew Prince, says he’s in London to speak with the U.K.’s Competition and Markets Authority (CMA), where he’s proposing stricter rules on how Google should be able to compete in the AI race, given its search dominance.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The CMA earlier this month designated Google with a special status in the search and advertising markets because of its “substantial and entrenched” position. The move will allow the regulator to impose more stringent regulations beyond just search and ads, including in areas like Google’s AI Overviews and AI Mode, the Discover feed, Top Stories, and News tab. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to Prince, Cloudflare is in a good position to make recommendations because it’s not in the AI business itself but has a large number of relationships with the AI companies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We don’t have a dog directly in the fight. We’re not an AI company,” Prince said, speaking at the Bloomberg Tech conference in London this week. “We’re not a media publisher, but we’re this network that sits between them — 80% of the AI companies are our customers,” he added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Cloudflare boss believes that Google should have to compete on the same footing as other AI companies, which is not what it’s doing today, he said. Rather, Google uses its existing web crawler to crawl content for its AI products and services, in addition to its search engine. This, Prince said, gives Google an unfair advantage. (Prince is referring to Googlebot, which crawls for Search, including its AI features, like AI Overviews. A Google spokesperson, Ned Adriance, said that site owners can opt out of having content used for training AI products with Google Extended, which doesn’t impact a site’s inclusion in Google Search. Some media companies would likely prefer to fully opt out of AI features, however, so the point largely stands.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Google is saying, ‘We have an absolute God-given right to all of the content in the world, even if we don’t pay for it, because look what we did for the last 27 years,’” Prince explained. “And they’re saying we can take it and use the same crawler we use for search in order to power our AI systems. And if you want to opt out of one, you have to opt out of both,” he noted.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;This, obviously, is not feasible for most, particularly those in the media business, where losing search means losing about 20% of your revenue, the executive said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“But it gets even worse. If you block Google’s crawler, it blocks their ad safety team, which means that your advertisements across all of your platforms stop working, which is just a non-starter,” Prince added. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Because Google bundles its crawler, it’s able to get access to content that others, like Anthropic, OpenAI, and Perplexity, would have to pay for.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“The problem is that we then will have effectively handed the game to Google,” he said. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The solution, Prince said, is to foster a lot of competition in the market, where potentially thousands of AI companies could compete to buy content from thousands of media businesses and millions of small businesses. He suggested that what the U.K.’s CMA was doing by flagging Google as a potential regulatory target was a thoughtful move, and one that indicates they’re aware of Google’s unique advantage.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cloudflare has also provided the CMA with data that shows how Google’s crawler works and why it’s nearly impossible for other players to replicate the same success Google could have. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Prince isn’t the only one to share these opinions in recent days. Last month, Neil Vogel, CEO of People, Inc., the largest digital and print publisher in the United States, which operates over 40 media brands, said essentially the same thing. In an interview, he called out Google as a “bad actor,” saying that media companies had no choice but to let Google crawl their sites for AI content because of the way the crawlers were combined.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Vogel, whose company had adopted Cloudflare’s solution to block AI crawlers&amp;nbsp;that don’t pay, claimed the system was working, as he said deal discussions were underway with several large LLM providers. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Updated with Google comment. &lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/21/cloudflare-ceo-matthew-prince-is-pushing-uk-regulator-to-unbundle-googles-search-and-ai-crawlers/</guid><pubDate>Tue, 21 Oct 2025 19:34:21 +0000</pubDate></item><item><title>Creating AI that matters (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/creating-ai-that-matters-1021</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202510/mit-ibm-watson-AI-that-Matters.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;When it comes to artificial intelligence, MIT and IBM were there at the beginning: laying foundational work and creating some of the first programs — AI predecessors — and theorizing how machine “intelligence” might come to be.&lt;/p&gt;&lt;p&gt;Today, collaborations like the MIT-IBM Watson AI Lab, which launched eight years ago, are continuing to deliver expertise for the promise of tomorrow’s AI technology. This is critical for industries and the labor force that stand to benefit, particularly in the short term: from $3-4 trillion of forecast global economic benefits and 80 percent productivity gains for knowledge workers and creative tasks, to significant incorporations of generative AI into business processes (80 percent) and software applications (70 percent) in the next three years.&lt;/p&gt;&lt;p&gt;While industry has seen a boom in notable models, chiefly in the past year, academia continues to drive the innovation, contributing most of the highly cited research. At the MIT-IBM Watson AI Lab, success takes the form of 54 patent disclosures, an excess of 128,000 citations with an h-index of 162, and more than 50 industry-driven use cases. Some of the lab’s many achievements include improved stent placement with AI imaging techniques, slashing computational overhead, shrinking models while maintaining performance, and modeling of interatomic potential for silicate chemistry.&lt;/p&gt;&lt;p&gt;“The lab is uniquely positioned to identify the ‘right’ problems to solve, setting us apart from other entities,” says Aude Oliva, lab MIT director and director of strategic industry engagement in the MIT Schwarzman College of Computing. “Further, the experience our students gain from working on these challenges for enterprise AI translates to their competitiveness in the job market and the promotion of a competitive industry.”&lt;/p&gt;&lt;p&gt;“The MIT-IBM Watson AI Lab has had tremendous impact by bringing together a rich set of collaborations between IBM and MIT’s researchers and students,” says Provost Anantha Chandrakasan, who is the lab’s MIT co-chair and the Vannevar Bush Professor of Electrical Engineering and Computer Science. “By supporting cross-cutting research at the intersection of AI and many other disciplines, the lab is advancing foundational work and accelerating the development of transformative solutions for our nation and the world.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Long-horizon work&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;As AI continues to garner interest, many organizations struggle to channel the technology into meaningful outcomes. A 2024 Gartner study finds that, “at least 30% of generative AI projects will be abandoned after proof of concept by the end of 2025,” demonstrating ambition and widespread hunger for AI, but a lack of knowledge for how to develop and apply it to create immediate value.&lt;/p&gt;&lt;p&gt;Here, the lab shines, bridging research and deployment. The majority of the lab’s current-year research portfolio is aligned to use and develop new features, capacities, or products for IBM, the lab’s corporate members, or real-world applications. The last of these comprise large language models, AI hardware, and foundation models, including multi-modal, bio-medical, and geo-spatial ones. Inquiry-driven students and interns are invaluable in this pursuit, offering enthusiasm and new perspectives while accumulating domain knowledge to help derive and engineer advancements in the field, as well as opening up new frontiers for exploration with AI as a tool.&lt;/p&gt;&lt;p&gt;Findings from the AAAI 2025 Presidential panel on the Future of AI Research support the need for contributions from academia-industry collaborations like the lab in the AI arena: “Academics have a role to play in providing independent advice and interpretations of these results [from industry] and their consequences. The private sector focuses more on the short term, and universities and society more on a longer-term perspective.”&lt;/p&gt;&lt;p&gt;Bringing these strengths together, along with the push for open sourcing and open science, can spark innovation that neither could achieve alone. History shows that embracing these principles, and sharing code and making research accessible, has long-term benefits for both the sector and society. In line with IBM and MIT’s missions, the lab contributes technologies, findings, governance, and standards to the public sphere through this collaboration, thereby enhancing transparency, accelerating reproducibility, and ensuring trustworthy advances.&lt;/p&gt;&lt;p&gt;The lab was created to merge MIT’s deep research expertise with IBM’s industrial R&amp;amp;D capacity, aiming for breakthroughs in core AI methods and hardware, as well as new applications in areas like health care, chemistry, finance, cybersecurity, and robust planning and decision-making for business.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Bigger isn't always better&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Today, large foundation models are giving way to smaller, more task-specific models yielding better performance. Contributions from lab members like Song Han, associate professor in the MIT Department of Electrical Engineering and Computer Science (EECS), and IBM Research’s Chuang Gan help make this possible, through work such as once-for-all and AWQ. Innovations such as these improve efficiency with better architectures, algorithm shrinking, and activation-aware weight quantization, letting models like language processing run on edge devices at faster speeds and reduced latency.&lt;/p&gt;&lt;p&gt;Consequently, foundation, vision, multimodal, and large language models have seen benefits, allowing for the lab research groups of Oliva, MIT EECS Associate Professor Yoon Kim, and IBM Research members Rameswar Panda, Yang Zhang, and Rogerio Feris to build on the work. This includes techniques to imbue models with external knowledge and the development of linear attention transformer methods for higher throughput, compared to other state-of-the-art systems.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Understanding and reasoning in vision and multimodal systems has also seen a boon.&amp;nbsp;Works like “Task2Sim” and “AdaFuse” demonstrate improved vision model performance if pre-training takes place on synthetic data, and how video action recognition can be boosted by fusing channels from past and current feature maps.&lt;/p&gt;&lt;p&gt;As part of a commitment to leaner AI, the lab teams of Gregory Wornell, the MIT EECS Sumitomo Electric Industries Professor in Engineering, IBM Research’s Chuang Gan, and David Cox, VP for foundational AI at IBM Research and the lab’s IBM director, have shown that model adaptability and data efficiency can go hand in hand. Two approaches, EvoScale and Chain-of-Action-Thought reasoning (COAT), enable language models to make the most of limited data and computation by improving on prior generation attempts through structured iteration, narrowing in on a better response.&amp;nbsp;COAT uses a meta-action framework and reinforcement learning to tackle reasoning-intensive tasks via self-correction, while EvoScale brings a similar philosophy to code generation, evolving high-quality candidate solutions. These techniques help to enable resource-conscious, targeted, real-world deployment.&lt;/p&gt;&lt;p&gt;“The impact of MIT-IBM research on our large language model development efforts cannot be overstated,” says Cox. “We’re seeing that smaller, more specialized models and tools are having an outsized impact, especially when they are combined. Innovations from the MIT-IBM Watson AI Lab help shape these technical directions and influence the strategy we are taking in the market through platforms like watsonx.”&lt;/p&gt;&lt;p&gt;For example, numerous lab projects have contributed features, capabilities, and uses to IBM’s Granite Vision, which provides impressive computer vision designed for document understanding, despite its compact size. This comes at a time when there’s a growing need for extraction, interpretation, and trustworthy summarization of information and data contained in long formats for enterprise purposes.&lt;/p&gt;&lt;p&gt;Other achievements that extend beyond direct research on AI and across disciplines are not only beneficial, but necessary for advancing the technology and lifting up society, concludes the 2025 AAAI panel.&lt;/p&gt;&lt;p&gt;Work from the lab’s Caroline Uhler and Devavrat Shah — both Andrew (1956) and Erna Viterbi Professors in EECS and the Institute for Data, Systems, and Society (IDSS) — along with IBM Research’s Kristjan Greenewald, transcends specializations. They are developing causal discovery methods to uncover how interventions affect outcomes, and identify which ones achieve desired results. The studies include developing a framework that can both elucidate how “treatments” for different sub-populations may play out, like on an ecommerce platform or mobility restrictions on morbidity outcomes. Findings from this body of work could influence the fields of marketing and medicine to education and risk management.&lt;/p&gt;&lt;p&gt;“Advances in AI and other areas of computing are influencing how people formulate and tackle challenges in nearly every discipline. At the MIT-IBM Watson AI Lab, researchers recognize this cross-cutting nature of their work and its impact, interrogating problems from multiple viewpoints and bringing real-world problems from industry, in order to develop novel solutions,” says Dan Huttenlocher, MIT lab co-chair, dean of the MIT Schwarzman College of Computing, and the Henry Ellis Warren (1894) Professor of Electrical Engineering and Computer Science.&lt;/p&gt;&lt;p&gt;A significant piece of what makes this research ecosystem thrive is the steady influx of student talent and their contributions through MIT’s Undergraduate Research Opportunities Program (UROP), MIT EECS 6A Program,&amp;nbsp;and the new MIT-IBM Watson AI Lab Internship Program. Altogether, more than 70 young researchers have not only accelerated their technical skill development, but, through guidance and support by the lab’s mentors, gained knowledge in AI domains to become emerging practitioners themselves. This is why the lab continually seeks to identify promising students at all stages in their exploration of AI’s potential.&lt;/p&gt;&lt;p&gt;“In order to unlock the full economic and societal potential of AI, we need to foster ‘useful and efficient intelligence,’” says Sriram Raghavan, IBM Research VP for AI and IBM chair of the lab. “To translate AI promise into progress, it’s crucial that we continue to focus on innovations to develop efficient, optimized, and fit-for-purpose models that can easily be adapted to specific domains and use cases. Academic-industry collaborations, such as the MIT-IBM Watson AI Lab, help drive the breakthroughs that make this possible.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202510/mit-ibm-watson-AI-that-Matters.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;When it comes to artificial intelligence, MIT and IBM were there at the beginning: laying foundational work and creating some of the first programs — AI predecessors — and theorizing how machine “intelligence” might come to be.&lt;/p&gt;&lt;p&gt;Today, collaborations like the MIT-IBM Watson AI Lab, which launched eight years ago, are continuing to deliver expertise for the promise of tomorrow’s AI technology. This is critical for industries and the labor force that stand to benefit, particularly in the short term: from $3-4 trillion of forecast global economic benefits and 80 percent productivity gains for knowledge workers and creative tasks, to significant incorporations of generative AI into business processes (80 percent) and software applications (70 percent) in the next three years.&lt;/p&gt;&lt;p&gt;While industry has seen a boom in notable models, chiefly in the past year, academia continues to drive the innovation, contributing most of the highly cited research. At the MIT-IBM Watson AI Lab, success takes the form of 54 patent disclosures, an excess of 128,000 citations with an h-index of 162, and more than 50 industry-driven use cases. Some of the lab’s many achievements include improved stent placement with AI imaging techniques, slashing computational overhead, shrinking models while maintaining performance, and modeling of interatomic potential for silicate chemistry.&lt;/p&gt;&lt;p&gt;“The lab is uniquely positioned to identify the ‘right’ problems to solve, setting us apart from other entities,” says Aude Oliva, lab MIT director and director of strategic industry engagement in the MIT Schwarzman College of Computing. “Further, the experience our students gain from working on these challenges for enterprise AI translates to their competitiveness in the job market and the promotion of a competitive industry.”&lt;/p&gt;&lt;p&gt;“The MIT-IBM Watson AI Lab has had tremendous impact by bringing together a rich set of collaborations between IBM and MIT’s researchers and students,” says Provost Anantha Chandrakasan, who is the lab’s MIT co-chair and the Vannevar Bush Professor of Electrical Engineering and Computer Science. “By supporting cross-cutting research at the intersection of AI and many other disciplines, the lab is advancing foundational work and accelerating the development of transformative solutions for our nation and the world.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Long-horizon work&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;As AI continues to garner interest, many organizations struggle to channel the technology into meaningful outcomes. A 2024 Gartner study finds that, “at least 30% of generative AI projects will be abandoned after proof of concept by the end of 2025,” demonstrating ambition and widespread hunger for AI, but a lack of knowledge for how to develop and apply it to create immediate value.&lt;/p&gt;&lt;p&gt;Here, the lab shines, bridging research and deployment. The majority of the lab’s current-year research portfolio is aligned to use and develop new features, capacities, or products for IBM, the lab’s corporate members, or real-world applications. The last of these comprise large language models, AI hardware, and foundation models, including multi-modal, bio-medical, and geo-spatial ones. Inquiry-driven students and interns are invaluable in this pursuit, offering enthusiasm and new perspectives while accumulating domain knowledge to help derive and engineer advancements in the field, as well as opening up new frontiers for exploration with AI as a tool.&lt;/p&gt;&lt;p&gt;Findings from the AAAI 2025 Presidential panel on the Future of AI Research support the need for contributions from academia-industry collaborations like the lab in the AI arena: “Academics have a role to play in providing independent advice and interpretations of these results [from industry] and their consequences. The private sector focuses more on the short term, and universities and society more on a longer-term perspective.”&lt;/p&gt;&lt;p&gt;Bringing these strengths together, along with the push for open sourcing and open science, can spark innovation that neither could achieve alone. History shows that embracing these principles, and sharing code and making research accessible, has long-term benefits for both the sector and society. In line with IBM and MIT’s missions, the lab contributes technologies, findings, governance, and standards to the public sphere through this collaboration, thereby enhancing transparency, accelerating reproducibility, and ensuring trustworthy advances.&lt;/p&gt;&lt;p&gt;The lab was created to merge MIT’s deep research expertise with IBM’s industrial R&amp;amp;D capacity, aiming for breakthroughs in core AI methods and hardware, as well as new applications in areas like health care, chemistry, finance, cybersecurity, and robust planning and decision-making for business.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Bigger isn't always better&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Today, large foundation models are giving way to smaller, more task-specific models yielding better performance. Contributions from lab members like Song Han, associate professor in the MIT Department of Electrical Engineering and Computer Science (EECS), and IBM Research’s Chuang Gan help make this possible, through work such as once-for-all and AWQ. Innovations such as these improve efficiency with better architectures, algorithm shrinking, and activation-aware weight quantization, letting models like language processing run on edge devices at faster speeds and reduced latency.&lt;/p&gt;&lt;p&gt;Consequently, foundation, vision, multimodal, and large language models have seen benefits, allowing for the lab research groups of Oliva, MIT EECS Associate Professor Yoon Kim, and IBM Research members Rameswar Panda, Yang Zhang, and Rogerio Feris to build on the work. This includes techniques to imbue models with external knowledge and the development of linear attention transformer methods for higher throughput, compared to other state-of-the-art systems.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Understanding and reasoning in vision and multimodal systems has also seen a boon.&amp;nbsp;Works like “Task2Sim” and “AdaFuse” demonstrate improved vision model performance if pre-training takes place on synthetic data, and how video action recognition can be boosted by fusing channels from past and current feature maps.&lt;/p&gt;&lt;p&gt;As part of a commitment to leaner AI, the lab teams of Gregory Wornell, the MIT EECS Sumitomo Electric Industries Professor in Engineering, IBM Research’s Chuang Gan, and David Cox, VP for foundational AI at IBM Research and the lab’s IBM director, have shown that model adaptability and data efficiency can go hand in hand. Two approaches, EvoScale and Chain-of-Action-Thought reasoning (COAT), enable language models to make the most of limited data and computation by improving on prior generation attempts through structured iteration, narrowing in on a better response.&amp;nbsp;COAT uses a meta-action framework and reinforcement learning to tackle reasoning-intensive tasks via self-correction, while EvoScale brings a similar philosophy to code generation, evolving high-quality candidate solutions. These techniques help to enable resource-conscious, targeted, real-world deployment.&lt;/p&gt;&lt;p&gt;“The impact of MIT-IBM research on our large language model development efforts cannot be overstated,” says Cox. “We’re seeing that smaller, more specialized models and tools are having an outsized impact, especially when they are combined. Innovations from the MIT-IBM Watson AI Lab help shape these technical directions and influence the strategy we are taking in the market through platforms like watsonx.”&lt;/p&gt;&lt;p&gt;For example, numerous lab projects have contributed features, capabilities, and uses to IBM’s Granite Vision, which provides impressive computer vision designed for document understanding, despite its compact size. This comes at a time when there’s a growing need for extraction, interpretation, and trustworthy summarization of information and data contained in long formats for enterprise purposes.&lt;/p&gt;&lt;p&gt;Other achievements that extend beyond direct research on AI and across disciplines are not only beneficial, but necessary for advancing the technology and lifting up society, concludes the 2025 AAAI panel.&lt;/p&gt;&lt;p&gt;Work from the lab’s Caroline Uhler and Devavrat Shah — both Andrew (1956) and Erna Viterbi Professors in EECS and the Institute for Data, Systems, and Society (IDSS) — along with IBM Research’s Kristjan Greenewald, transcends specializations. They are developing causal discovery methods to uncover how interventions affect outcomes, and identify which ones achieve desired results. The studies include developing a framework that can both elucidate how “treatments” for different sub-populations may play out, like on an ecommerce platform or mobility restrictions on morbidity outcomes. Findings from this body of work could influence the fields of marketing and medicine to education and risk management.&lt;/p&gt;&lt;p&gt;“Advances in AI and other areas of computing are influencing how people formulate and tackle challenges in nearly every discipline. At the MIT-IBM Watson AI Lab, researchers recognize this cross-cutting nature of their work and its impact, interrogating problems from multiple viewpoints and bringing real-world problems from industry, in order to develop novel solutions,” says Dan Huttenlocher, MIT lab co-chair, dean of the MIT Schwarzman College of Computing, and the Henry Ellis Warren (1894) Professor of Electrical Engineering and Computer Science.&lt;/p&gt;&lt;p&gt;A significant piece of what makes this research ecosystem thrive is the steady influx of student talent and their contributions through MIT’s Undergraduate Research Opportunities Program (UROP), MIT EECS 6A Program,&amp;nbsp;and the new MIT-IBM Watson AI Lab Internship Program. Altogether, more than 70 young researchers have not only accelerated their technical skill development, but, through guidance and support by the lab’s mentors, gained knowledge in AI domains to become emerging practitioners themselves. This is why the lab continually seeks to identify promising students at all stages in their exploration of AI’s potential.&lt;/p&gt;&lt;p&gt;“In order to unlock the full economic and societal potential of AI, we need to foster ‘useful and efficient intelligence,’” says Sriram Raghavan, IBM Research VP for AI and IBM chair of the lab. “To translate AI promise into progress, it’s crucial that we continue to focus on innovations to develop efficient, optimized, and fit-for-purpose models that can easily be adapted to specific domains and use cases. Academic-industry collaborations, such as the MIT-IBM Watson AI Lab, help drive the breakthroughs that make this possible.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/creating-ai-that-matters-1021</guid><pubDate>Tue, 21 Oct 2025 20:10:00 +0000</pubDate></item><item><title>Sources: Multimodal AI startup Fal AI already raised at $4B+ valuation (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/21/sources-multimodal-ai-startup-fal-ai-already-raised-at-4b-valuation/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/2025-vc-predictions.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Fal.ai, a startup that hosts image, video, and audio AI models for developers, has closed a new round valuing the company at over $4 billion, four people familiar with the deal said. The company raised approximately $250 million, two of the people said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Major investors in the round are Kleiner Perkins and Sequoia, according to our sources. Fal didn’t respond to a request for comment. Sequoia and Kleiner Perkins declined to comment.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The new round is coming less than three months after Fal announced a $125 million Series C at a $1.5 billion valuation led by Meritech. At that time, the company’s revenue crossed $95 million and its platform was used by over 2 million developers, Todd Jackson, a partner at First Round Capital, wrote on LinkedIn. That was massive growth from a year ago, when TechCrunch reported Fal had $10 million in annualized recurring revenue (ARR) and 500,000 developers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since Fal provides the infrastructure layer for multimodal AI models (as well as media-specific ones), the company’s explosive growth is directly tied to the user adoption of applications built on top of it. And multimodal AI is in heavy demand right now, especially video, as evidenced by the soaring popularity of OpenAI’s Sora, which surged to the top of the U.S. App Store even faster than ChatGPT did. This massive consumer demand for applications like Sora underscores the market potential of Fal’s offering.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Fal provides developers with over 600 image, video, audio, and 3D models, it says, and boasts that its cloud has thousands of Nvidia H100 and H200 GPUs and is fine-tuned for speedy inference. It offers tools for customizing models as well. Its offerings include access via API, hosted via a flexible serverless offering, or via enterprise-ready compute clusters. While there are certainly other competitors offering model and app hosting services (Microsoft, Google, CoreWeave, to name a few), Fal’s singular focus on media and multimodal is its competitive selling point, VCs like Jackson say.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup’s customers range from individual developers to large companies, including Adobe, Canva, Perplexity, and Shopify. Some of the popular use cases include media creation for advertising, e-commerce, and gaming content.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup was co-founded in 2021 by Burkay Gur, a former Coinbase machine learning leader and Oracle engineer, and Gorkem Yurtseven, who was previously a developer at Amazon. Gur and Yurtseven saw an opportunity for personalized multimedia generation. While other technologists pursued LLMs, they zeroed in on optimizing Stable Diffusion for speed and scale, and have since expanded to hosting many other such models.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Fal previously raised nearly $200 million, according to PitchBook data. The company’s existing investors include Bessemer Venture Partners, Kindred Ventures, Andreessen Horowitz, Notable Capital, First Round Capital, Unusual Ventures, and Village Global.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/2025-vc-predictions.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Fal.ai, a startup that hosts image, video, and audio AI models for developers, has closed a new round valuing the company at over $4 billion, four people familiar with the deal said. The company raised approximately $250 million, two of the people said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Major investors in the round are Kleiner Perkins and Sequoia, according to our sources. Fal didn’t respond to a request for comment. Sequoia and Kleiner Perkins declined to comment.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The new round is coming less than three months after Fal announced a $125 million Series C at a $1.5 billion valuation led by Meritech. At that time, the company’s revenue crossed $95 million and its platform was used by over 2 million developers, Todd Jackson, a partner at First Round Capital, wrote on LinkedIn. That was massive growth from a year ago, when TechCrunch reported Fal had $10 million in annualized recurring revenue (ARR) and 500,000 developers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since Fal provides the infrastructure layer for multimodal AI models (as well as media-specific ones), the company’s explosive growth is directly tied to the user adoption of applications built on top of it. And multimodal AI is in heavy demand right now, especially video, as evidenced by the soaring popularity of OpenAI’s Sora, which surged to the top of the U.S. App Store even faster than ChatGPT did. This massive consumer demand for applications like Sora underscores the market potential of Fal’s offering.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Fal provides developers with over 600 image, video, audio, and 3D models, it says, and boasts that its cloud has thousands of Nvidia H100 and H200 GPUs and is fine-tuned for speedy inference. It offers tools for customizing models as well. Its offerings include access via API, hosted via a flexible serverless offering, or via enterprise-ready compute clusters. While there are certainly other competitors offering model and app hosting services (Microsoft, Google, CoreWeave, to name a few), Fal’s singular focus on media and multimodal is its competitive selling point, VCs like Jackson say.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup’s customers range from individual developers to large companies, including Adobe, Canva, Perplexity, and Shopify. Some of the popular use cases include media creation for advertising, e-commerce, and gaming content.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup was co-founded in 2021 by Burkay Gur, a former Coinbase machine learning leader and Oracle engineer, and Gorkem Yurtseven, who was previously a developer at Amazon. Gur and Yurtseven saw an opportunity for personalized multimedia generation. While other technologists pursued LLMs, they zeroed in on optimizing Stable Diffusion for speed and scale, and have since expanded to hosting many other such models.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Fal previously raised nearly $200 million, according to PitchBook data. The company’s existing investors include Bessemer Venture Partners, Kindred Ventures, Andreessen Horowitz, Notable Capital, First Round Capital, Unusual Ventures, and Village Global.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/21/sources-multimodal-ai-startup-fal-ai-already-raised-at-4b-valuation/</guid><pubDate>Tue, 21 Oct 2025 20:12:41 +0000</pubDate></item><item><title>Estrada signs with the Dodgers (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/21/1124758/estrada-signs-with-the-dodgers/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/MIT-Mason-Estrada-01-press_0.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Like almost any MIT student, Mason Estrada wants to take what he learned on campus and apply it to the working world. Unlike any other current MIT student, Estrada’s&amp;nbsp;primary workplace is&amp;nbsp;a pitcher’s mound.&lt;/p&gt;  &lt;p&gt;Estrada, the star pitcher for MIT’s baseball team, has signed a contract with the Los Angeles Dodgers, who selected him in the seventh round of the Major League Baseball draft on July 14. The right-hander, whose fastball has reached 96 miles per hour, is taking a leave of absence from the Institute and reported to the Dodgers’ instructional camp in Arizona.&lt;/p&gt;  &lt;p&gt;An aero-astro major, Estrada says that pitching at MIT has never involved transferring aerodynamic knowledge from the classroom to the mound. Still, he says, he’s benefited as an athlete from “learning to think like an engineer generally, learning to think through problems the right way and finding the best solution.”&lt;/p&gt;  &lt;p&gt;In the 2025 season Estrada went 6–0 with a 2.21 ERA, striking out 66. He is the fifth MIT undergraduate selected in baseball’s draft, of whom one—Jason Szuminski ’00—reached the majors, with the San Diego Padres.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/MIT-Mason-Estrada-01-press_0.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Like almost any MIT student, Mason Estrada wants to take what he learned on campus and apply it to the working world. Unlike any other current MIT student, Estrada’s&amp;nbsp;primary workplace is&amp;nbsp;a pitcher’s mound.&lt;/p&gt;  &lt;p&gt;Estrada, the star pitcher for MIT’s baseball team, has signed a contract with the Los Angeles Dodgers, who selected him in the seventh round of the Major League Baseball draft on July 14. The right-hander, whose fastball has reached 96 miles per hour, is taking a leave of absence from the Institute and reported to the Dodgers’ instructional camp in Arizona.&lt;/p&gt;  &lt;p&gt;An aero-astro major, Estrada says that pitching at MIT has never involved transferring aerodynamic knowledge from the classroom to the mound. Still, he says, he’s benefited as an athlete from “learning to think like an engineer generally, learning to think through problems the right way and finding the best solution.”&lt;/p&gt;  &lt;p&gt;In the 2025 season Estrada went 6–0 with a 2.21 ERA, striking out 66. He is the fifth MIT undergraduate selected in baseball’s draft, of whom one—Jason Szuminski ’00—reached the majors, with the San Diego Padres.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/21/1124758/estrada-signs-with-the-dodgers/</guid><pubDate>Tue, 21 Oct 2025 21:00:00 +0000</pubDate></item><item><title>A I-designed compounds can kill drug-resistant bacteria (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/21/1124755/a-i-designed-compounds-can-kill-drug-resistant-bacteria/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/AdobeStock_854002342.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;With help from artificial intelligence, MIT researchers have designed novel antibiotics that can combat two hard-to-treat bacteria: multi-drug-­resistant &lt;em&gt;Neisseria gonorrhoeae&lt;/em&gt; and &lt;em&gt;Staphylococcus aureus &lt;/em&gt;(MRSA).&lt;/p&gt;  &lt;p&gt;The team used two approaches. First, they directed generative AI to design molecules based on a chemical fragment their model had predicted would show antimicrobial activity, and second, they let the algorithms generate molecules without constraints. They designed more than 36 million possible compounds this way and computationally screened them for antimicrobial properties.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The top candidates they discovered are structurally distinct from any existing antibiotics, and they appear to work by novel mechanisms that disrupt bacterial cell membranes. This makes them less vulnerable to antibiotic resistance, a growing problem: It is estimated that drug-­resistant bacterial infections cause nearly 5 million deaths per year worldwide.&lt;/p&gt;  &lt;p&gt;Now that they can generate and evaluate compounds that have never been seen before, the researchers hope they can use the same strategy to identify and design drugs that attack other species of bacteria.&lt;/p&gt;  &lt;p&gt;“We’re excited about the new possibilities that this project opens up for antibiotics development,” says James Collins, a professor of biological engineering and the senior author of the study. “Our work shows the power of AI from a drug design standpoint and enables us to exploit much larger chemical spaces that were previously inaccessible.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/AdobeStock_854002342.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;With help from artificial intelligence, MIT researchers have designed novel antibiotics that can combat two hard-to-treat bacteria: multi-drug-­resistant &lt;em&gt;Neisseria gonorrhoeae&lt;/em&gt; and &lt;em&gt;Staphylococcus aureus &lt;/em&gt;(MRSA).&lt;/p&gt;  &lt;p&gt;The team used two approaches. First, they directed generative AI to design molecules based on a chemical fragment their model had predicted would show antimicrobial activity, and second, they let the algorithms generate molecules without constraints. They designed more than 36 million possible compounds this way and computationally screened them for antimicrobial properties.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The top candidates they discovered are structurally distinct from any existing antibiotics, and they appear to work by novel mechanisms that disrupt bacterial cell membranes. This makes them less vulnerable to antibiotic resistance, a growing problem: It is estimated that drug-­resistant bacterial infections cause nearly 5 million deaths per year worldwide.&lt;/p&gt;  &lt;p&gt;Now that they can generate and evaluate compounds that have never been seen before, the researchers hope they can use the same strategy to identify and design drugs that attack other species of bacteria.&lt;/p&gt;  &lt;p&gt;“We’re excited about the new possibilities that this project opens up for antibiotics development,” says James Collins, a professor of biological engineering and the senior author of the study. “Our work shows the power of AI from a drug design standpoint and enables us to exploit much larger chemical spaces that were previously inaccessible.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/21/1124755/a-i-designed-compounds-can-kill-drug-resistant-bacteria/</guid><pubDate>Tue, 21 Oct 2025 21:00:00 +0000</pubDate></item><item><title>Walking faster, hanging out less (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/21/1124752/walking-faster-hanging-out-less/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/AdobeStock_276102896.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;City life is often described as “fast-paced.” A study coauthored by MIT scholars suggests that’s more true than ever: The average walking speed in three northeastern US cities increased 15% from 1980 to 2010, while the number of people lingering in public spaces declined by 14%.&lt;/p&gt;  &lt;p&gt;The researchers used machine-learning tools to assess 1980s-era video footage captured in Boston, New York, and Philadelphia by William Whyte, an urbanist and social thinker best known as the author of &lt;em&gt;The Organization Man&lt;/em&gt;. They compared the old material with newer videos from the same locations.&lt;/p&gt;  &lt;p&gt;“Something has changed over the past 40 years,” says coauthor Carlo Ratti, director of MIT’s Senseable City Lab. “Public spaces are working in somewhat different ways, more as a thoroughfare and less a space of encounter.” The scholars speculate that some of the reasons may have to do with cell phones and Starbucks: People text each other to meet up instead of hanging around to encounter each other in public, and when they do get together, they often choose an indoor space like a coffee shop.&lt;/p&gt;  &lt;p&gt;The results could help designers seeking to create new public areas or modify existing ones. “Public space is such an important element of civic life, and today partly because it counteracts the polarization of digital space,” says Arianna Salazar-Miranda, MCP ’16, PhD ’23, an assistant professor at Yale and another coauthor. “The more we can keep improving public space, the more we can make our cities suited for convening.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/AdobeStock_276102896.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;City life is often described as “fast-paced.” A study coauthored by MIT scholars suggests that’s more true than ever: The average walking speed in three northeastern US cities increased 15% from 1980 to 2010, while the number of people lingering in public spaces declined by 14%.&lt;/p&gt;  &lt;p&gt;The researchers used machine-learning tools to assess 1980s-era video footage captured in Boston, New York, and Philadelphia by William Whyte, an urbanist and social thinker best known as the author of &lt;em&gt;The Organization Man&lt;/em&gt;. They compared the old material with newer videos from the same locations.&lt;/p&gt;  &lt;p&gt;“Something has changed over the past 40 years,” says coauthor Carlo Ratti, director of MIT’s Senseable City Lab. “Public spaces are working in somewhat different ways, more as a thoroughfare and less a space of encounter.” The scholars speculate that some of the reasons may have to do with cell phones and Starbucks: People text each other to meet up instead of hanging around to encounter each other in public, and when they do get together, they often choose an indoor space like a coffee shop.&lt;/p&gt;  &lt;p&gt;The results could help designers seeking to create new public areas or modify existing ones. “Public space is such an important element of civic life, and today partly because it counteracts the polarization of digital space,” says Arianna Salazar-Miranda, MCP ’16, PhD ’23, an assistant professor at Yale and another coauthor. “The more we can keep improving public space, the more we can make our cities suited for convening.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/21/1124752/walking-faster-hanging-out-less/</guid><pubDate>Tue, 21 Oct 2025 21:00:00 +0000</pubDate></item><item><title>A bionic knee restores natural movement (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/21/1124749/a-bionic-knee-restores-natural-movement/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;MIT researchers have developed a new bionic knee that is integrated directly with the user’s muscle and bone tissue. It can help people with above-the-knee amputations walk faster, climb stairs, and avoid obstacles more easily than they could with a traditional prosthesis, which is attached to the residual limb by means of a socket and can be uncomfortable.&lt;/p&gt;  &lt;p&gt;For several years, Hugh Herr, SM ’93, co-director of the K. Lisa Yang Center for Bionics, has been working with his colleagues on techniques that can extract neural information from muscles left behind after an amputation and use that information to help guide a prosthetic limb. The approach, known as agonist-antagonist myoneuronal interface (AMI), has been shown to help people with below-the-knee amputations walk faster and navigate around obstacles much more naturally.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image alignright size-large is-resized"&gt;&lt;img alt="model of bionic knees" class="wp-image-1125819" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/MIT_Bionic-Knee-only.jpg?w=1068" /&gt;&lt;figcaption class="wp-element-caption"&gt;The new system is anchored to the bone and controlled by the nervous system, offering more stability and easier navigation.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF THE RESEARCHERS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;In the new study, the researchers developed a procedure to insert a titanium rod into the residual femur bone of people who had amputations above the knee. This implant allows for better mechanical control and load bearing than a traditional prosthesis. It also contains 16 wires that collect information from electrodes located on the AMI muscles inside the body, offering better neuroprosthetic control.&lt;/p&gt;  &lt;p&gt;Two people who received the implant in a clinical study performed better on several types of tasks, including stair climbing, and reported that the limb felt more like a part of their own body, compared with people who had more traditional above-the-knee amputations and used conventional prostheses.&lt;/p&gt;  &lt;p&gt;“A prosthesis that’s tissue-integrated—anchored to the bone and directly controlled by the nervous system—is not merely a lifeless, separate device,” says Herr, but rather “an integral part of self.” The system will need larger trials to receive FDA approval for commercial use, which he expects may take about five years.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;MIT researchers have developed a new bionic knee that is integrated directly with the user’s muscle and bone tissue. It can help people with above-the-knee amputations walk faster, climb stairs, and avoid obstacles more easily than they could with a traditional prosthesis, which is attached to the residual limb by means of a socket and can be uncomfortable.&lt;/p&gt;  &lt;p&gt;For several years, Hugh Herr, SM ’93, co-director of the K. Lisa Yang Center for Bionics, has been working with his colleagues on techniques that can extract neural information from muscles left behind after an amputation and use that information to help guide a prosthetic limb. The approach, known as agonist-antagonist myoneuronal interface (AMI), has been shown to help people with below-the-knee amputations walk faster and navigate around obstacles much more naturally.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image alignright size-large is-resized"&gt;&lt;img alt="model of bionic knees" class="wp-image-1125819" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/MIT_Bionic-Knee-only.jpg?w=1068" /&gt;&lt;figcaption class="wp-element-caption"&gt;The new system is anchored to the bone and controlled by the nervous system, offering more stability and easier navigation.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF THE RESEARCHERS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;In the new study, the researchers developed a procedure to insert a titanium rod into the residual femur bone of people who had amputations above the knee. This implant allows for better mechanical control and load bearing than a traditional prosthesis. It also contains 16 wires that collect information from electrodes located on the AMI muscles inside the body, offering better neuroprosthetic control.&lt;/p&gt;  &lt;p&gt;Two people who received the implant in a clinical study performed better on several types of tasks, including stair climbing, and reported that the limb felt more like a part of their own body, compared with people who had more traditional above-the-knee amputations and used conventional prostheses.&lt;/p&gt;  &lt;p&gt;“A prosthesis that’s tissue-integrated—anchored to the bone and directly controlled by the nervous system—is not merely a lifeless, separate device,” says Herr, but rather “an integral part of self.” The system will need larger trials to receive FDA approval for commercial use, which he expects may take about five years.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/21/1124749/a-bionic-knee-restores-natural-movement/</guid><pubDate>Tue, 21 Oct 2025 21:00:00 +0000</pubDate></item><item><title>Biodiversity: A missing link in combating climate change (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/21/1124746/biodiversity-a-missing-link-in-combating-climate-change/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/MIT-Seed-Dispersal-Christian-Ziegler-01-press.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;A lot of attention has been paid to how climate change can reduce biodiversity. Now MIT researchers have shown that the reverse is also true: Loss of biodiversity can jeopardize regrowth of tropical forests, one of Earth’s most powerful tools for mitigating climate change.&lt;/p&gt;  &lt;p&gt;Combining data from thousands of previous studies and using new tools for quantifying interconnected ecological processes, the researchers analyzed numerous tropical sites where deforestation was being followed by natural regrowth, focusing on the role of animals such as birds and monkeys that spread plant seeds by eating them in one place and then defecating someplace else. Evan Fricke, a research scientist in the MIT Department of Civil and Environmental Engineering and the lead author of a paper on the work, has studied such animals for 15 years, showing that without their role, trees have lower survival rates and a harder time keeping up with environmental changes.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Since tropical forests are Earth’s largest land-based carbon sink, such challenges make it harder to fight climate change. But the influence of biodiversity on forests’ ability to absorb carbon has not been fully quantified.&lt;/p&gt;  &lt;p&gt;To do that, the researchers looked at data on where seed-dispersing animals live, how many seeds each animal disperses, and how they affect germination. Then they incorporated data revealing the impact of human activity such as hunting and forest degradation. They found, for example, that the animals move less, and thus spread seeds less widely, in areas with a bigger human footprint.&lt;/p&gt; 
 &lt;p&gt;With the data, the researchers created an index that revealed a link between human activities and declines in seed dispersal. They analyzed the relationship between that index and records of carbon accumulation in naturally regrowing tropical forests over time, controlling for factors like droughts, fires, and livestock grazing.&lt;/p&gt;  &lt;p&gt;“What’s particularly new about this study is we’re actually getting the numbers around these effects,” Fricke says. In particular, they found that naturally regrowing forests with healthy populations of seed-dispersing animals absorbed up to four times more carbon than those without as many. Meanwhile, in sites identified as suitable for reforestation, current levels of disruption to seed dispersal reduce the potential for regrowth by 57%.&lt;/p&gt; 
 &lt;p&gt;These findings could help direct reforestation strategies. “In the discussion around planting trees versus allowing trees to regrow naturally, regrowth is basically free, whereas planting trees costs money, and it also leads to less diverse forests,” says César Terrer, a professor of civil and environmental engineering and a coauthor of the paper. “Now we can understand where natural regrowth can happen effectively because there are animals planting the seeds for free, and we also can identify areas where, because animals are affected, natural regrowth is not going to happen, and therefore planting trees actively is necessary.”&lt;/p&gt;  &lt;p&gt;The researchers encourage action to protect or improve animal habitats, reduce pressures on seed-dispersing species, and potentially reintroduce them where they’ve been lost. Overall, they hope the study helps improve our understanding of the planet’s complex ecological processes.&lt;/p&gt;  &lt;p&gt;“When we lose our animals, we’re losing the ecological infrastructure that keeps our tropical forests healthy and resilient,” Fricke says.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/MIT-Seed-Dispersal-Christian-Ziegler-01-press.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;A lot of attention has been paid to how climate change can reduce biodiversity. Now MIT researchers have shown that the reverse is also true: Loss of biodiversity can jeopardize regrowth of tropical forests, one of Earth’s most powerful tools for mitigating climate change.&lt;/p&gt;  &lt;p&gt;Combining data from thousands of previous studies and using new tools for quantifying interconnected ecological processes, the researchers analyzed numerous tropical sites where deforestation was being followed by natural regrowth, focusing on the role of animals such as birds and monkeys that spread plant seeds by eating them in one place and then defecating someplace else. Evan Fricke, a research scientist in the MIT Department of Civil and Environmental Engineering and the lead author of a paper on the work, has studied such animals for 15 years, showing that without their role, trees have lower survival rates and a harder time keeping up with environmental changes.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Since tropical forests are Earth’s largest land-based carbon sink, such challenges make it harder to fight climate change. But the influence of biodiversity on forests’ ability to absorb carbon has not been fully quantified.&lt;/p&gt;  &lt;p&gt;To do that, the researchers looked at data on where seed-dispersing animals live, how many seeds each animal disperses, and how they affect germination. Then they incorporated data revealing the impact of human activity such as hunting and forest degradation. They found, for example, that the animals move less, and thus spread seeds less widely, in areas with a bigger human footprint.&lt;/p&gt; 
 &lt;p&gt;With the data, the researchers created an index that revealed a link between human activities and declines in seed dispersal. They analyzed the relationship between that index and records of carbon accumulation in naturally regrowing tropical forests over time, controlling for factors like droughts, fires, and livestock grazing.&lt;/p&gt;  &lt;p&gt;“What’s particularly new about this study is we’re actually getting the numbers around these effects,” Fricke says. In particular, they found that naturally regrowing forests with healthy populations of seed-dispersing animals absorbed up to four times more carbon than those without as many. Meanwhile, in sites identified as suitable for reforestation, current levels of disruption to seed dispersal reduce the potential for regrowth by 57%.&lt;/p&gt; 
 &lt;p&gt;These findings could help direct reforestation strategies. “In the discussion around planting trees versus allowing trees to regrow naturally, regrowth is basically free, whereas planting trees costs money, and it also leads to less diverse forests,” says César Terrer, a professor of civil and environmental engineering and a coauthor of the paper. “Now we can understand where natural regrowth can happen effectively because there are animals planting the seeds for free, and we also can identify areas where, because animals are affected, natural regrowth is not going to happen, and therefore planting trees actively is necessary.”&lt;/p&gt;  &lt;p&gt;The researchers encourage action to protect or improve animal habitats, reduce pressures on seed-dispersing species, and potentially reintroduce them where they’ve been lost. Overall, they hope the study helps improve our understanding of the planet’s complex ecological processes.&lt;/p&gt;  &lt;p&gt;“When we lose our animals, we’re losing the ecological infrastructure that keeps our tropical forests healthy and resilient,” Fricke says.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/21/1124746/biodiversity-a-missing-link-in-combating-climate-change/</guid><pubDate>Tue, 21 Oct 2025 21:00:00 +0000</pubDate></item><item><title>Navigating MIT (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/21/1124743/navigating-mit/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Take a stroll along the Infinite Corridor these days and you’ll encounter a striking new space, in a prominent location on the first floor of Building 11. With bright blue seating modules, orange accents, and an eye-catching design, it looks like a futuristic space station, sleek and ultramodern—but also welcoming and fun.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This is the new home of the Undergraduate Advising Center (UAC). And while the design might be surprising, the creation of the center is no surprise at all. It’s simply another example of MIT’s ongoing innovation in improving student advising.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1126023" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/A-Home-for-Advising_2.jpg?w=1728" /&gt;&lt;div class="image-credit"&gt;MERGE ARCHITECTS (RENDERING)&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;The MIT experience looks different for everyone, and the UAC was launched in 2023 with that in mind, offering individualized support to help undergraduates reach their full potential. The new hub brings together the people and programs dedicated to helping them navigate MIT, offering guidance that’s both personalized and proactive, with an emphasis on identifying students who might need help and reaching out to them sooner rather than later.&lt;/p&gt;  &lt;p&gt;The 5,000-square-foot space, designed by Boston’s Merge Architects, reflects the needs of our students, who offered input on lighting (natural), seating (comfortable), and multifunctional areas that can be used for everything from private conversations to large-scale gatherings.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I don’t have to tell all of you that there’s more to thriving at MIT than being incredibly smart. UAC advisors help students set goals, manage their time, and build relationships with faculty. And they help students navigate what’s often called the “hidden curriculum”—the unspoken norms and values of university life. Once they’ve chosen their majors, students are assigned a faculty advisor, but that doesn’t mean their UAC advisors step aside—these relationships continue for all four years, providing&lt;br /&gt;a sense of continuity and care.&lt;/p&gt;  &lt;p&gt;Already, the new hub is in constant use for consultations, study sessions, and impromptu visits to grab a snack and catch up with friends. And it’s much more than a physical upgrade—it’s a symbol of our commitment to continually strengthening advising resources for all students, from orientation to the moment they finally turn their Brass Rats.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Take a stroll along the Infinite Corridor these days and you’ll encounter a striking new space, in a prominent location on the first floor of Building 11. With bright blue seating modules, orange accents, and an eye-catching design, it looks like a futuristic space station, sleek and ultramodern—but also welcoming and fun.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This is the new home of the Undergraduate Advising Center (UAC). And while the design might be surprising, the creation of the center is no surprise at all. It’s simply another example of MIT’s ongoing innovation in improving student advising.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1126023" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/A-Home-for-Advising_2.jpg?w=1728" /&gt;&lt;div class="image-credit"&gt;MERGE ARCHITECTS (RENDERING)&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;The MIT experience looks different for everyone, and the UAC was launched in 2023 with that in mind, offering individualized support to help undergraduates reach their full potential. The new hub brings together the people and programs dedicated to helping them navigate MIT, offering guidance that’s both personalized and proactive, with an emphasis on identifying students who might need help and reaching out to them sooner rather than later.&lt;/p&gt;  &lt;p&gt;The 5,000-square-foot space, designed by Boston’s Merge Architects, reflects the needs of our students, who offered input on lighting (natural), seating (comfortable), and multifunctional areas that can be used for everything from private conversations to large-scale gatherings.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I don’t have to tell all of you that there’s more to thriving at MIT than being incredibly smart. UAC advisors help students set goals, manage their time, and build relationships with faculty. And they help students navigate what’s often called the “hidden curriculum”—the unspoken norms and values of university life. Once they’ve chosen their majors, students are assigned a faculty advisor, but that doesn’t mean their UAC advisors step aside—these relationships continue for all four years, providing&lt;br /&gt;a sense of continuity and care.&lt;/p&gt;  &lt;p&gt;Already, the new hub is in constant use for consultations, study sessions, and impromptu visits to grab a snack and catch up with friends. And it’s much more than a physical upgrade—it’s a symbol of our commitment to continually strengthening advising resources for all students, from orientation to the moment they finally turn their Brass Rats.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/21/1124743/navigating-mit/</guid><pubDate>Tue, 21 Oct 2025 21:00:00 +0000</pubDate></item><item><title>How Millie Dresselhaus paid it forward (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/21/1124731/how-millie-dresselhaus-paid-it-forward/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Institute Professor Mildred “Millie” Dresselhaus forever altered our understanding of matter—the physical stuff of the universe that has mass and takes up space. Over 57 years at MIT, Dresselhaus also played a significant role in inspiring people to use this new knowledge to tackle some of the world’s greatest challenges, from producing clean energy to curing cancer. Although she became an emerita professor in 2007, Dresselhaus, who taught electrical engineering and physics, remained actively involved in research and all other aspects of MIT life until her death in 2017. She would have been 95 this November.&lt;/p&gt;  &lt;p&gt;Known as the “Queen of Carbon,” Dresselhaus was most often heralded for her pioneering work with one of nature’s most abundant and versatile substances. As a result of her insatiable curiosity about our world and her nearly six-decade career as a scientific explorer, we can thank her for significant leaps in how we think about carbon’s various forms and the company it keeps. In her early career, Dresselhaus employed a then-new invention—laser light—to probe carbon’s inner workings. She worked to distinguish how, for example, flat sheets of carbon atoms act differently from carbon crystals of three dimensions, especially in the presence of heat, electrons, or a magnetic field. And later she predicted the existence of what we now call carbon nanotubes, sheets of carbon atoms rolled up into minuscule cylinders that can be remarkably adept at conducting electricity.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Building on Dresselhaus’s far-reaching foundational research, scientists and engineers have made enormous advances at the nanoscale—with structures on the order of one hundred-thousandth the width of a human hair. Spherical carbon “buckyballs,” cylindrical carbon nanotubes, and two-dimensional carbon sheets known as graphene have already been used for energy storage, medical research, building materials, and paper-thin electronics, among many other applications. Today, these carbon structures continue to be developed for myriad novel uses that often seem taken from the realm of science fiction, including ultrafast quantum computers, efficient desalination devices, and quantum dots with applications in biosensing and drug delivery. For her work she won—among other honors—the Kavli Prize in Nanoscience, the National Medal of Science, and the Presidential Medal of Freedom, the highest civilian award given by the United States government.&lt;/p&gt;  &lt;p&gt;But her journey to MIT, and to global leadership in solid-state physics, was an improbable one. Born in Brooklyn, New York, to immigrant parents in 1930, Dresselhaus came of age at a time when women were rarely welcomed as scientists or encouraged to pursue technical fields. Yet she benefited from several key mentors who saw her potential and took deliberate steps to support a brilliant young mind.&amp;nbsp;&lt;/p&gt; 
&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1124857" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/2DY6F4G.jpg?w=1661" width="1661" /&gt;&lt;figcaption class="wp-element-caption"&gt;President Barack Obama presented Dresselhaus with the Presidential Medal of Freedom in 2014.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;OLIVIER DOULIERY/ABACAPRESS.COM VIA ALAMY&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;One of those mentors was Enrico Fermi, the distinguished Italian-born nuclear scientist who played a leading role in the Manhattan Project and who concluded his career as a professor of physics at the University of Chicago. Fermi came to America after receiving a solo Nobel Prize in 1938 (for work on induced radioactivity) and then fleeing the Nazi regime with his Jewish wife, Laura. The story of how Fermi influenced an up-and-coming Millie Dresselhaus—and, by proxy, scores of students who would study under her—reveals how paying it forward to the next generation of scientists and engineers can yield lasting dividends.&amp;nbsp;&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;In 1953, with the nuclear age firmly underway and the Cold War heating up, Dresselhaus found herself, at 22, one of the new graduate students within the University of Chicago’s world-class physics department. Although a number of researchers who had worked on the Manhattan Project there had by then left for other opportunities, many luminaries remained. In addition to the renowned Enrico Fermi, notable faculty included the Nobel laureates Harold Urey and Maria Goeppert Mayer (with whom Dresselhaus lived for about a year as a boarder) as well as the physicist Leona Woods, the only woman present during the famous 1942 fission demonstration on one of the school’s squash courts.&lt;/p&gt; 
 &lt;div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"&gt; &lt;p&gt;The university’s physics program was fairly small in those days: Dresselhaus had earned a spot as one of just about a dozen new graduate students that year. She was also, it turns out, the only female student in the department. Despite a master’s degree in physics from Radcliffe College and a Fulbright fellowship at the University of Cambridge, she felt not quite prepared as she began her PhD. And so, at the start of her doctoral studies, she discovered a cache of old examinations, and she worked the problems therein forward and back until she felt up to speed.&lt;/p&gt;    &lt;p&gt;Despite this added practice, the coursework for first-year PhD candidates was brutal—so brutal that around three-quarters of all entering physics students eventually dropped out of the program. But Dresselhaus’s relationship with Fermi would provide an unexpected boost.&lt;/p&gt; &lt;/div&gt;  &lt;p&gt;She first encountered the unflappable scientist—who made crucial strides not only in the development of the atomic bomb but in particle physics after the war—as a student in his class on quantum mechanics. And through that class, Dresselhaus got to know his teaching style, which she recalled as patient, inspiring, and mind-opening. With a slow, deliberate, accented voice that Dresselhaus described as “halting,” Fermi expertly distilled complicated topics so that anyone in attendance could comprehend them. Brilliant at both theory and experimentation, he delighted in stripping concepts to their essence, and unlike more impatient professors who were absorbed in their own work, Fermi cherished the opportunity to review whatever he knew about a physical concept by explaining it to someone else. For this he clearly had a talent; thanks to the way he presented the finer details of quantum mechanics, Dresselhaus explained, “any youngster could think, when they heard the lecture, that they understood every word.”&lt;/p&gt;  &lt;p&gt;One key to the eminent scientist’s clarity was the ban he placed on taking notes. Fermi demanded full attention, so he would prepare and dole out handwritten notes before his lectures, lest students be tempted to take out their pens or slide rules. “What was so impressive and amazing about it is that the lectures were very exciting, whatever the subject was,” Dresselhaus said in a 2001 interview.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1124860" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/GettyImages-3245871.jpg?w=1658" width="1658" /&gt;&lt;figcaption class="wp-element-caption"&gt;Nuclear scientist Enrico Fermi, shown here circa 1942, was a key early mentor to Dresselhaus at the University of Chicago.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;HULTON ARCHIVE/GETTY IMAGES&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;And then there was the homework, which was always tricky, but delightfully enlightening once you figured it out. At the end of every class, Fermi floated a seemingly simple problem to be solved as an exercise prior to the following lecture. These included questions like: Why is the sky blue? Why do the sun and stars emit spectra of light? And, famously, how many piano tuners are there in Chicago? “You thought it was simple until you got home,” Dresselhaus said in 2012, upon receiving the Enrico Fermi Award, a lifetime achievement award given by the US Department of Energy. These types of questions became known, collectively, as “Fermi problems” and are taught today in schools around the world, from kindergarten all the way to graduate-level courses, as examples of how to estimate and triangulate in search of an answer, even when you don’t know all the relevant—and seemingly necessary—parameters. Back when Dresselhaus was learning about such problems, all she knew was they were due by the next class, no more than a day or two away, and they took a significant effort. “I think we learned a great deal from him in the formulation of problems of physics, how to think about physics, how to solve problems, and how to generate your own problems,” she said.&lt;/p&gt;  &lt;p&gt;Indeed, throughout her career, Dresselhaus credited Fermi with teaching her how to “think as a physicist.” A key concept behind the Fermi system, she often stated, was the idea of single-authorship research: Grad students were expected to conceive of, carry out, and publish their thesis work more or less on their own, without the guiding hand of a more senior faculty member. This required them to work with others to develop a broad understanding of physics that they could then apply to a research topic they’d generate themselves.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Fermi’s connection with students didn’t end in the classroom. He was well known for frequent interactions with young people, and for being the rare senior faculty member who regularly integrated students into his personal life. “It was not beneath him to associate freely with students and to treat them as equals,” said Jay Orear, a career physicist and graduate student of Fermi’s, in a book of remembrances about his advisor. “In fact, I think he enjoyed young physics students more than some of his older colleagues.”&lt;/p&gt;  &lt;p&gt;For Dresselhaus, this integration began, quite literally, on her way to school. She and Fermi lived in the same general vicinity, and both were early risers who walked down Ellis Avenue on their way to the lab each day. “I had him for class first thing in the morning. And on my way, walking to school, I would see him. And he would cross the street and walk with me,” Dresselhaus recalled in a 2007 oral history interview. “That’s just being very friendly, and that made a long-term impression on me.”&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1124858" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/contact-sheet.jpg?w=1246" width="1246" /&gt;&lt;figcaption class="wp-element-caption"&gt;Dresselhaus shown in conversation early during her tenure at MIT. She would spend 50 years as a member of the faculty.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;MARGO FOOTE/MIT MUSEUM&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Whenever they met, Fermi would always select the subject of discussion and would never fail to energize and inspire her. “I was a very shy youngster and wouldn’t think of suggesting the topic to Enrico Fermi,” she told &lt;em&gt;MIT Alumni News&lt;/em&gt; in 2013&lt;em&gt;.&lt;/em&gt; “He would always ask questions about ‘What if this and this and this were true? What if we could make this—would it be interesting, and what could we learn?’”&lt;/p&gt;  &lt;p&gt;Fermi and his wife, Laura, were well known for hosting monthly dinners at their house, with dancing afterward—and his students were always invited. “Fermi especially liked young people,” noted Harold Agnew, a longtime physicist and one of his graduate students, in a remembrance published after Fermi’s death. “The top floor of his Chicago house had a large room in which he would invite students to come and square-dance.”&lt;/p&gt; 

 &lt;p&gt;“I remember those dinners,” Dresselhaus said in 2012. “Laura Fermi was a very, very good Italian cook.” But more than the cooking, she said, “it was the ambiance and the friendliness in that household that really made us enjoy physics—it was something more.” That “something more” would inspire Dresselhaus later in her career to provide her own students at MIT with a familial atmosphere in the lab, at group luncheons, and at events in her home, where lines between student and professor were blurred a bit and kindred spirits enjoyed one another’s company.&lt;/p&gt;  &lt;p&gt;Dresselhaus’s acquaintance with Fermi would last only a year. He had developed an incurable stomach cancer, possibly a result of exposure to radiation from his earlier work, and died on November 28, 1954. But he left a fantastic impression that influenced her for the rest of her days, instilling in her a commitment to public service and guiding how she trained her own students.&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;“The most important thing that young people need is the confidence that they can succeed. That’s what I work on.”&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;“Fermi had the most profound influence on physics teaching in the United States, and our graduate programs ... are much fashioned from his way of teaching,” Dresselhaus said in 2001. She later added, “From him, I learned that we don’t have to be leaders in every field, but we can use our understanding to see connections that others might miss.”&lt;/p&gt;  &lt;p&gt;The broad physical and scientific knowledge that Dresselhaus developed as a result of Fermi’s system for teaching graduate students helped her in numerous ways throughout her career. It proved useful on several occasions when she had to make significant course corrections, with very little background in the areas into which she pivoted. And she relied on it as a leader of national programs with diverse constituents.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;But perhaps the grandest lesson that Dresselhaus gained from her mentor was an understanding of what it takes to be a great teacher and advocate. “The most important thing that young people need is the confidence that they can succeed,” she explained in 2012. “That’s what I work on. When I have students, I make sure they are able to formulate and solve their own problems. I will help them, if they come in and talk with me. And I make sure they receive training for their next job.”&lt;/p&gt;  &lt;p&gt;By all accounts, she more than succeeded in that effort. At MIT, she became a beloved professor who both pushed her students to be their very best and provided support in ways big and small to ensure high achievement—helping students network for career opportunities, hosting any student who didn’t have a place to go for Thanksgiving dinner, teaching an entire recitation section for an engineering student who showed great promise but needed help getting up to speed in solid-state physics. She said, “I always felt Fermi and Rosalyn [Yalow, her undergraduate mentor at Hunter College] were interested in my career, and I try to show the same concern for my students.”&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;In the eight years since Dresselhaus’s death, new advances from her colleagues have borne the signature of her research—and have begun branching out in ever more fascinating directions. Graphene, for example, remains one of the hottest topics in science. Back in the early and mid-2010s, Dresselhaus worked on what she and others called “misoriented graphene.” She and others predicted that by twisting sheets of graphene so that their honeycomb patterns are slightly misaligned when superimposed, researchers could introduce “interesting patterns” that might lead to useful properties. In 2018, Dresselhaus’s MIT colleague Pablo Jarillo-Herrero realized this idea: He and others discovered that if two graphene sheets are combined into a superlattice, aligned at a “magic angle” of 1.1 degrees, the system can become either superconducting or insulating. The development was hailed as a major discovery and marked a jumping-off point for a subfield now known as ­“twistronics.” &lt;em&gt;Physics World&lt;/em&gt; named it Breakthrough of the Year.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="hexagonal sheets of graphene in slight misalignment" class="wp-image-1124861" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/MIT-Magic-Angle.jpg?w=474" /&gt;&lt;figcaption class="wp-element-caption"&gt;Dresselhaus hypothesized that misaligning sheets of graphene could produce novel properties. In 2018, her MIT colleague Pablo Jarillo- Herrero demonstrated that such an arrangement can become either a superconductor or an insulator.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF THE RESEARCHERS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Also in 2018, MIT opened its doors to a gleaming new nanoscience and nanotechnology research facility at the heart of campus. The $400 million MIT.nano project was a long time in coming; although Dresselhaus missed out on the grand opening, she was very much looking forward to its completion, and to the start of a new generation of nanoscale endeavors at the Institute that would seek to expand humanity’s understanding of physics, chemistry, materials science, energy, biology, and more. In her final years, Dresselhaus had looked to MIT.nano as an extension of her legacy.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;In late 2019, the courtyard between the Institute’s Infinite Corridor and the southern façade of the MIT.nano building was dedicated in her memory. Dubbed the Improbability Walk, the space is a nod to Dresselhaus’s unlikely rise to international prominence from her humble beginnings in Depression-era New York. It also encourages those who might serve as mentors to take time to get to know younger colleagues and students, as Enrico Fermi did with Dresselhaus and Dresselhaus did with so many at MIT. For as improbable as it might seem, an encouraging word from a mentor can immeasurably enhance a young scientist’s life path.&amp;nbsp;&lt;/p&gt;  &lt;figure class="wp-block-image alignleft size-large is-resized"&gt;&lt;img alt="cover of Carbon Queen" class="wp-image-1124859" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/cover.jpg?w=1312" width="1312" /&gt;&lt;/figure&gt;  &lt;p&gt;Like Fermi before her, Dresselhaus was deeply committed to giving back—to students, to her research community, to society at large. Throughout her 86-plus years, she gave of her time, her intellect, her energy, her love, and her enthusiasm. In one of her final interviews, the Queen of Carbon issued a ringing invitation. “We need new science and we need new ideas, and there’s plenty of room for young people to come in and have careers discovering those new ideas,” she declared. “Life is very interesting in this lane. Come and join me!”&amp;nbsp;&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;Adapted from&amp;nbsp;&lt;em&gt;Carbon Queen: The Remarkable Life of Nanoscience Pioneer Mildred Dresselhaus&lt;/em&gt;&lt;em&gt;,&lt;/em&gt; by Maia Weinstock (MIT Press). Copyright 2022. Reprinted with permission.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Institute Professor Mildred “Millie” Dresselhaus forever altered our understanding of matter—the physical stuff of the universe that has mass and takes up space. Over 57 years at MIT, Dresselhaus also played a significant role in inspiring people to use this new knowledge to tackle some of the world’s greatest challenges, from producing clean energy to curing cancer. Although she became an emerita professor in 2007, Dresselhaus, who taught electrical engineering and physics, remained actively involved in research and all other aspects of MIT life until her death in 2017. She would have been 95 this November.&lt;/p&gt;  &lt;p&gt;Known as the “Queen of Carbon,” Dresselhaus was most often heralded for her pioneering work with one of nature’s most abundant and versatile substances. As a result of her insatiable curiosity about our world and her nearly six-decade career as a scientific explorer, we can thank her for significant leaps in how we think about carbon’s various forms and the company it keeps. In her early career, Dresselhaus employed a then-new invention—laser light—to probe carbon’s inner workings. She worked to distinguish how, for example, flat sheets of carbon atoms act differently from carbon crystals of three dimensions, especially in the presence of heat, electrons, or a magnetic field. And later she predicted the existence of what we now call carbon nanotubes, sheets of carbon atoms rolled up into minuscule cylinders that can be remarkably adept at conducting electricity.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Building on Dresselhaus’s far-reaching foundational research, scientists and engineers have made enormous advances at the nanoscale—with structures on the order of one hundred-thousandth the width of a human hair. Spherical carbon “buckyballs,” cylindrical carbon nanotubes, and two-dimensional carbon sheets known as graphene have already been used for energy storage, medical research, building materials, and paper-thin electronics, among many other applications. Today, these carbon structures continue to be developed for myriad novel uses that often seem taken from the realm of science fiction, including ultrafast quantum computers, efficient desalination devices, and quantum dots with applications in biosensing and drug delivery. For her work she won—among other honors—the Kavli Prize in Nanoscience, the National Medal of Science, and the Presidential Medal of Freedom, the highest civilian award given by the United States government.&lt;/p&gt;  &lt;p&gt;But her journey to MIT, and to global leadership in solid-state physics, was an improbable one. Born in Brooklyn, New York, to immigrant parents in 1930, Dresselhaus came of age at a time when women were rarely welcomed as scientists or encouraged to pursue technical fields. Yet she benefited from several key mentors who saw her potential and took deliberate steps to support a brilliant young mind.&amp;nbsp;&lt;/p&gt; 
&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1124857" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/2DY6F4G.jpg?w=1661" width="1661" /&gt;&lt;figcaption class="wp-element-caption"&gt;President Barack Obama presented Dresselhaus with the Presidential Medal of Freedom in 2014.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;OLIVIER DOULIERY/ABACAPRESS.COM VIA ALAMY&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;One of those mentors was Enrico Fermi, the distinguished Italian-born nuclear scientist who played a leading role in the Manhattan Project and who concluded his career as a professor of physics at the University of Chicago. Fermi came to America after receiving a solo Nobel Prize in 1938 (for work on induced radioactivity) and then fleeing the Nazi regime with his Jewish wife, Laura. The story of how Fermi influenced an up-and-coming Millie Dresselhaus—and, by proxy, scores of students who would study under her—reveals how paying it forward to the next generation of scientists and engineers can yield lasting dividends.&amp;nbsp;&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;In 1953, with the nuclear age firmly underway and the Cold War heating up, Dresselhaus found herself, at 22, one of the new graduate students within the University of Chicago’s world-class physics department. Although a number of researchers who had worked on the Manhattan Project there had by then left for other opportunities, many luminaries remained. In addition to the renowned Enrico Fermi, notable faculty included the Nobel laureates Harold Urey and Maria Goeppert Mayer (with whom Dresselhaus lived for about a year as a boarder) as well as the physicist Leona Woods, the only woman present during the famous 1942 fission demonstration on one of the school’s squash courts.&lt;/p&gt; 
 &lt;div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"&gt; &lt;p&gt;The university’s physics program was fairly small in those days: Dresselhaus had earned a spot as one of just about a dozen new graduate students that year. She was also, it turns out, the only female student in the department. Despite a master’s degree in physics from Radcliffe College and a Fulbright fellowship at the University of Cambridge, she felt not quite prepared as she began her PhD. And so, at the start of her doctoral studies, she discovered a cache of old examinations, and she worked the problems therein forward and back until she felt up to speed.&lt;/p&gt;    &lt;p&gt;Despite this added practice, the coursework for first-year PhD candidates was brutal—so brutal that around three-quarters of all entering physics students eventually dropped out of the program. But Dresselhaus’s relationship with Fermi would provide an unexpected boost.&lt;/p&gt; &lt;/div&gt;  &lt;p&gt;She first encountered the unflappable scientist—who made crucial strides not only in the development of the atomic bomb but in particle physics after the war—as a student in his class on quantum mechanics. And through that class, Dresselhaus got to know his teaching style, which she recalled as patient, inspiring, and mind-opening. With a slow, deliberate, accented voice that Dresselhaus described as “halting,” Fermi expertly distilled complicated topics so that anyone in attendance could comprehend them. Brilliant at both theory and experimentation, he delighted in stripping concepts to their essence, and unlike more impatient professors who were absorbed in their own work, Fermi cherished the opportunity to review whatever he knew about a physical concept by explaining it to someone else. For this he clearly had a talent; thanks to the way he presented the finer details of quantum mechanics, Dresselhaus explained, “any youngster could think, when they heard the lecture, that they understood every word.”&lt;/p&gt;  &lt;p&gt;One key to the eminent scientist’s clarity was the ban he placed on taking notes. Fermi demanded full attention, so he would prepare and dole out handwritten notes before his lectures, lest students be tempted to take out their pens or slide rules. “What was so impressive and amazing about it is that the lectures were very exciting, whatever the subject was,” Dresselhaus said in a 2001 interview.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1124860" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/GettyImages-3245871.jpg?w=1658" width="1658" /&gt;&lt;figcaption class="wp-element-caption"&gt;Nuclear scientist Enrico Fermi, shown here circa 1942, was a key early mentor to Dresselhaus at the University of Chicago.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;HULTON ARCHIVE/GETTY IMAGES&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;And then there was the homework, which was always tricky, but delightfully enlightening once you figured it out. At the end of every class, Fermi floated a seemingly simple problem to be solved as an exercise prior to the following lecture. These included questions like: Why is the sky blue? Why do the sun and stars emit spectra of light? And, famously, how many piano tuners are there in Chicago? “You thought it was simple until you got home,” Dresselhaus said in 2012, upon receiving the Enrico Fermi Award, a lifetime achievement award given by the US Department of Energy. These types of questions became known, collectively, as “Fermi problems” and are taught today in schools around the world, from kindergarten all the way to graduate-level courses, as examples of how to estimate and triangulate in search of an answer, even when you don’t know all the relevant—and seemingly necessary—parameters. Back when Dresselhaus was learning about such problems, all she knew was they were due by the next class, no more than a day or two away, and they took a significant effort. “I think we learned a great deal from him in the formulation of problems of physics, how to think about physics, how to solve problems, and how to generate your own problems,” she said.&lt;/p&gt;  &lt;p&gt;Indeed, throughout her career, Dresselhaus credited Fermi with teaching her how to “think as a physicist.” A key concept behind the Fermi system, she often stated, was the idea of single-authorship research: Grad students were expected to conceive of, carry out, and publish their thesis work more or less on their own, without the guiding hand of a more senior faculty member. This required them to work with others to develop a broad understanding of physics that they could then apply to a research topic they’d generate themselves.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Fermi’s connection with students didn’t end in the classroom. He was well known for frequent interactions with young people, and for being the rare senior faculty member who regularly integrated students into his personal life. “It was not beneath him to associate freely with students and to treat them as equals,” said Jay Orear, a career physicist and graduate student of Fermi’s, in a book of remembrances about his advisor. “In fact, I think he enjoyed young physics students more than some of his older colleagues.”&lt;/p&gt;  &lt;p&gt;For Dresselhaus, this integration began, quite literally, on her way to school. She and Fermi lived in the same general vicinity, and both were early risers who walked down Ellis Avenue on their way to the lab each day. “I had him for class first thing in the morning. And on my way, walking to school, I would see him. And he would cross the street and walk with me,” Dresselhaus recalled in a 2007 oral history interview. “That’s just being very friendly, and that made a long-term impression on me.”&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1124858" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/contact-sheet.jpg?w=1246" width="1246" /&gt;&lt;figcaption class="wp-element-caption"&gt;Dresselhaus shown in conversation early during her tenure at MIT. She would spend 50 years as a member of the faculty.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;MARGO FOOTE/MIT MUSEUM&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Whenever they met, Fermi would always select the subject of discussion and would never fail to energize and inspire her. “I was a very shy youngster and wouldn’t think of suggesting the topic to Enrico Fermi,” she told &lt;em&gt;MIT Alumni News&lt;/em&gt; in 2013&lt;em&gt;.&lt;/em&gt; “He would always ask questions about ‘What if this and this and this were true? What if we could make this—would it be interesting, and what could we learn?’”&lt;/p&gt;  &lt;p&gt;Fermi and his wife, Laura, were well known for hosting monthly dinners at their house, with dancing afterward—and his students were always invited. “Fermi especially liked young people,” noted Harold Agnew, a longtime physicist and one of his graduate students, in a remembrance published after Fermi’s death. “The top floor of his Chicago house had a large room in which he would invite students to come and square-dance.”&lt;/p&gt; 

 &lt;p&gt;“I remember those dinners,” Dresselhaus said in 2012. “Laura Fermi was a very, very good Italian cook.” But more than the cooking, she said, “it was the ambiance and the friendliness in that household that really made us enjoy physics—it was something more.” That “something more” would inspire Dresselhaus later in her career to provide her own students at MIT with a familial atmosphere in the lab, at group luncheons, and at events in her home, where lines between student and professor were blurred a bit and kindred spirits enjoyed one another’s company.&lt;/p&gt;  &lt;p&gt;Dresselhaus’s acquaintance with Fermi would last only a year. He had developed an incurable stomach cancer, possibly a result of exposure to radiation from his earlier work, and died on November 28, 1954. But he left a fantastic impression that influenced her for the rest of her days, instilling in her a commitment to public service and guiding how she trained her own students.&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;“The most important thing that young people need is the confidence that they can succeed. That’s what I work on.”&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;“Fermi had the most profound influence on physics teaching in the United States, and our graduate programs ... are much fashioned from his way of teaching,” Dresselhaus said in 2001. She later added, “From him, I learned that we don’t have to be leaders in every field, but we can use our understanding to see connections that others might miss.”&lt;/p&gt;  &lt;p&gt;The broad physical and scientific knowledge that Dresselhaus developed as a result of Fermi’s system for teaching graduate students helped her in numerous ways throughout her career. It proved useful on several occasions when she had to make significant course corrections, with very little background in the areas into which she pivoted. And she relied on it as a leader of national programs with diverse constituents.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;But perhaps the grandest lesson that Dresselhaus gained from her mentor was an understanding of what it takes to be a great teacher and advocate. “The most important thing that young people need is the confidence that they can succeed,” she explained in 2012. “That’s what I work on. When I have students, I make sure they are able to formulate and solve their own problems. I will help them, if they come in and talk with me. And I make sure they receive training for their next job.”&lt;/p&gt;  &lt;p&gt;By all accounts, she more than succeeded in that effort. At MIT, she became a beloved professor who both pushed her students to be their very best and provided support in ways big and small to ensure high achievement—helping students network for career opportunities, hosting any student who didn’t have a place to go for Thanksgiving dinner, teaching an entire recitation section for an engineering student who showed great promise but needed help getting up to speed in solid-state physics. She said, “I always felt Fermi and Rosalyn [Yalow, her undergraduate mentor at Hunter College] were interested in my career, and I try to show the same concern for my students.”&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;In the eight years since Dresselhaus’s death, new advances from her colleagues have borne the signature of her research—and have begun branching out in ever more fascinating directions. Graphene, for example, remains one of the hottest topics in science. Back in the early and mid-2010s, Dresselhaus worked on what she and others called “misoriented graphene.” She and others predicted that by twisting sheets of graphene so that their honeycomb patterns are slightly misaligned when superimposed, researchers could introduce “interesting patterns” that might lead to useful properties. In 2018, Dresselhaus’s MIT colleague Pablo Jarillo-Herrero realized this idea: He and others discovered that if two graphene sheets are combined into a superlattice, aligned at a “magic angle” of 1.1 degrees, the system can become either superconducting or insulating. The development was hailed as a major discovery and marked a jumping-off point for a subfield now known as ­“twistronics.” &lt;em&gt;Physics World&lt;/em&gt; named it Breakthrough of the Year.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="hexagonal sheets of graphene in slight misalignment" class="wp-image-1124861" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/MIT-Magic-Angle.jpg?w=474" /&gt;&lt;figcaption class="wp-element-caption"&gt;Dresselhaus hypothesized that misaligning sheets of graphene could produce novel properties. In 2018, her MIT colleague Pablo Jarillo- Herrero demonstrated that such an arrangement can become either a superconductor or an insulator.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF THE RESEARCHERS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Also in 2018, MIT opened its doors to a gleaming new nanoscience and nanotechnology research facility at the heart of campus. The $400 million MIT.nano project was a long time in coming; although Dresselhaus missed out on the grand opening, she was very much looking forward to its completion, and to the start of a new generation of nanoscale endeavors at the Institute that would seek to expand humanity’s understanding of physics, chemistry, materials science, energy, biology, and more. In her final years, Dresselhaus had looked to MIT.nano as an extension of her legacy.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;In late 2019, the courtyard between the Institute’s Infinite Corridor and the southern façade of the MIT.nano building was dedicated in her memory. Dubbed the Improbability Walk, the space is a nod to Dresselhaus’s unlikely rise to international prominence from her humble beginnings in Depression-era New York. It also encourages those who might serve as mentors to take time to get to know younger colleagues and students, as Enrico Fermi did with Dresselhaus and Dresselhaus did with so many at MIT. For as improbable as it might seem, an encouraging word from a mentor can immeasurably enhance a young scientist’s life path.&amp;nbsp;&lt;/p&gt;  &lt;figure class="wp-block-image alignleft size-large is-resized"&gt;&lt;img alt="cover of Carbon Queen" class="wp-image-1124859" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/cover.jpg?w=1312" width="1312" /&gt;&lt;/figure&gt;  &lt;p&gt;Like Fermi before her, Dresselhaus was deeply committed to giving back—to students, to her research community, to society at large. Throughout her 86-plus years, she gave of her time, her intellect, her energy, her love, and her enthusiasm. In one of her final interviews, the Queen of Carbon issued a ringing invitation. “We need new science and we need new ideas, and there’s plenty of room for young people to come in and have careers discovering those new ideas,” she declared. “Life is very interesting in this lane. Come and join me!”&amp;nbsp;&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;Adapted from&amp;nbsp;&lt;em&gt;Carbon Queen: The Remarkable Life of Nanoscience Pioneer Mildred Dresselhaus&lt;/em&gt;&lt;em&gt;,&lt;/em&gt; by Maia Weinstock (MIT Press). Copyright 2022. Reprinted with permission.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/21/1124731/how-millie-dresselhaus-paid-it-forward/</guid><pubDate>Tue, 21 Oct 2025 21:00:00 +0000</pubDate></item><item><title>25 years of research in space (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/21/1124727/25-years-of-research-in-space/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;On November 2, 2000, NASA astronaut Bill Shepherd, OCE ’78, SM ’78, and Russian cosmonauts Sergei Krikalev and Yuri Gidzenko made history as their Soyuz spacecraft docked with the International Space Station.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The event marked the start of 25 years of continuous human presence in space aboard the ISS—a prolific period for space research. MIT-trained astronauts, scientists, and engineers have played integral roles in all aspects of the station’s design, assembly, operations, and scientific research.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;One of MIT’s most experienced NASA astronauts, Mike Fincke ’89, is celebrating that milestone from space. Having already logged 381 days in three previous missions to the ISS, he returned on August&amp;nbsp;1 as a member of the Expedition 73 crew. “Wow, 25 years of constant human habitation in space!” he said when he spoke with me from the station in September. “What an accomplishment and a testimony to the teams on the ground and in terms of engineering, science, and diplomacy.”&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Building and operating the ISS&lt;/h3&gt;  &lt;p&gt;“We understood that building the ISS was significantly more difficult than anything we’d attempted before with the possible exception of Apollo,” says Pamela Melroy, SM ’84, who flew the space shuttle on three ISS assembly missions, including STS-92 in October 2000, which installed key modules and structures that prepared the station for the arrival of Shepherd and his crew less than two weeks later. “We learned a tremendous amount from the Shuttle-Mir program that I think gave us a lot more confidence going into ISS assembly,” she says.&lt;/p&gt; 
 &lt;p&gt;Melroy was one of 10 MIT astronauts who participated in 13 space shuttle missions to assemble and resupply the ISS through 2011. “It’s pretty awe-inspiring to just go, ‘Wow, there is the visible evidence of what we just spent 10 to 14 days doing,’” she recalls. She also saw just how critical logistics are to resupply operations—especially since the retirement of the shuttle.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Shepherd, who served as Expedition One commander, and his crew overcame a variety of challenges as they adapted to living in space, continued the assembly of the ISS, and installed and activated its life support and communications systems. “We were blue-collar maintenance guys for most of our flight,” he says. “I really enjoyed that part of it.” After arriving on the ISS, he discovered that the Russian service module was missing a worktable that his crew had found to be very useful in training. He asked Moscow, “Where’s our table?” and was told, “It’s going to come up six months after you guys are gone.”&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Cargo flights had delivered canisters of carbon dioxide absorbers packaged in sturdy aluminum frames. Upon inspecting the frames, they decided there was no reason to remain table-less. “We had some special tools that we had smuggled on board,” he recalls. “So we started to cut and drill and thread and fabricate a table out of scraps.” It turned out to be a pretty good table. “When Houston found out about it, they went nuts, because we were up there sawing, making chips and aluminum sawdust,” he says. “But we got through all that.” Now in the Smithsonian, it is “definitely an MIT-designed table,” Shepherd says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Twelve MIT alums and one MIT affiliate from the Whitehead Institute have logged a total of 18 long-duration missions to the ISS. Cady Coleman ’83 served as lead robotics and science officer during a 159-day expedition in 2010 and 2011. She performed hundreds of experiments, ranging from basic science to technology development for future moon and Mars missions. “At MIT, we were always invited to be part of scientific discovery,” Coleman says. “We carried MIT’s standard of excellence into every field. Most importantly, our education taught us that we were part of a larger mission to make the world a better place.”&lt;/p&gt;  &lt;p&gt;Citing the “mens et manus” motto on the Brass Rat he was wearing in space, Fincke observed that MIT prepared him well for his job. “When you have such a critical mass of really intelligent people and critical thinkers, it really makes a difference and brings out the best in all of us, including me,” he said. “So thank you, MIT.”&lt;/p&gt;  &lt;p&gt;Woody Hoburg ’08, who was an assistant professor of aero-astro before piloting a 186-day mission to the ISS in 2023, concurs: “It’s no surprise that so many exceptional MIT thinkers and doers end up shaping our boldest achievements in space. The ISS is certainly one of those—it’s a beautiful machine, constructed while I was still in high school and later studying Course 16 at MIT, flying five miles per second over Earth that whole time.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;h3 class="wp-block-heading"&gt;Science in space&lt;/h3&gt;  &lt;p&gt;A wide range of MIT faculty and students have taken advantage of the ISS’s unique access to space to conduct research.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“MIT’s MACE-II [Middeck Active Control Experiment] was the first active US scientific investigation performed on the International Space Station,” Shepherd said back in 2001. “Performing scientific investigations like MACE-II on board the station allows for successful interaction, almost in real time, between the astronauts in space and investigators on the ground.” Developed by aero-astro professor David Miller ’82, SM ’85, ScD ’88, and the Space Systems Laboratory (SSL) he then directed, MACE-II successfully tested techniques for predicting and controlling the dynamics of structures in microgravity. Miller says that the structural dynamics techniques developed through MACE were later used to test the James Webb Space Telescope. &amp;nbsp;&lt;/p&gt;  &lt;p&gt;Miller and the SSL also led the development of SPHERES (Synchronized Position Hold Engage and Reorient Experimental Satellites), a set of satellites used on board the ISS from 2006 through 2019. Inspired by the Jedi training ball from the original &lt;em&gt;Star Wars&lt;/em&gt;, SPHERES evolved from an undergraduate aero-astro capstone project into an ISS facility for studying the dynamic control of satellites flying together in space. Three independent free-flying satellites operated inside the ISS within an infrared/ultrasonic measurement system that provided precise positioning and attitude information in three dimensions. SPHERES let researchers develop and test algorithms for precision control of multiple spacecraft during complex collaborative operations. Its modular design permitted the addition of electromagnets for precise tandem flight, vision systems for navigation, and hardware for investigating the sloshing of fluids in space.&amp;nbsp;&lt;/p&gt;    &lt;p&gt;Greg Chamitoff, PhD ’92, became the first principal investigator to directly perform his own scientific research on the ISS when he programmed SPHERES during Expedition 17 in 2008. Miller recalls that when Chamitoff later visited MIT, he asked, “Why don’t we create the first primary school robotics competition ever hosted off the planet?” During the next decade, nearly 20,000 high school and middle school students from around the world participated in Zero Robotics, writing algorithms to control the SPHERES satellites in STEM competitions conducted onboard the ISS. Both MACE-II and SPHERES were returned to Earth and will be on display at the National Air and Space Museum in the “At Home in Space” gallery slated to open in 2026.&lt;/p&gt; 

 &lt;p&gt;Samuel C.C. Ting, the Thomas Dudley Cabot Professor of Physics at MIT, led a $2 billion international effort to develop the Alpha Magnetic Spectrometer (AMS) with the ambitious goal of searching for antimatter, determining the origin of dark matter, and understanding the properties of cosmic rays. Delivered to the ISS in 2011 by one of the final space shuttle missions, the AMS has precisely measured over 253 billion cosmic ray events with energies up to multiple tera-electron-volts. Fully interpreting the comprehensive experimental data still being generated by the AMS will require new physics models. “I would imagine 100 years from now most of my work will be forgotten,” Ting says. “But if people remember anything, it probably will be AMS.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Kate Rubins, a microbiologist, was a fellow at the Whitehead Institute when she was selected as a NASA astronaut in 2009—and became the first person to sequence DNA in space during her long-&lt;br /&gt;duration ISS mission in 2016. She did so using a commercially available meta­genomics sequencer, despite the risk that it might not function in orbit. “To everybody’s surprise, it worked, and it worked the first time,” she recalls. “I don’t know if I’ve ever had a lab experiment in my life that has worked the first time, but genomic sequencing in space was a big one to have that happen.”&lt;/p&gt;  &lt;p&gt;Rubins wanted to conduct her own scientific research during her spare time in orbit, so she got permission from NASA to substitute her own lab bench equipment—including pipettes, tubes, and scientific plasticware—for the small kit of personal items that astronauts are allowed to bring to space. She got a NASA psychologist to help make the case. “He said, ‘You know, Kate’s a nerd—she loves doing this stuff … we have to fly this on board for her,’” she says. Rubins successfully demonstrated that regular biology lab equipment could be used to conduct science in space—and donated that equipment for use by future ISS crews. (“Every astronaut turns into a scientist when they get on board the space station,” she says.) She recently coauthored a paper describing the creation of a microbiome map of the ISS—a 3D map showing where astronauts found various microbes and metabolites when they collected samples in space. She calls the work “super exciting.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The ISS also serves as a test bed for new technologies that will support NASA’s ambitious programs to explore the moon and Mars. In 2023, MIT Lincoln Laboratory successfully demonstrated high-­bandwidth laser communications in space between its ILLUMA-T laser communications terminal onboard the ISS and a NASA Laser Communications Relay Demonstration satellite. When the Artemis II astronauts launch to the moon in early 2026, their Orion spacecraft will use the optical communications system developed by Lincoln Laboratory’s Optical and Quantum Communications Group and the Goddard Space Flight Center to transmit high-­resolution imagery of the lunar surface back to Earth via lasers capable of data rates up to 260 megabits per second.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;h3 class="wp-block-heading"&gt;International cooperation&lt;/h3&gt;  &lt;p&gt;One of the most enduring legacies of the International Space Station, which is slated to continue operations through 2030, is the vast scale of international cooperation that made it possible.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The roots of the project trace back to 1984, when President Ronald Reagan challenged NASA to lead an effort to build an Earth-orbiting space station within a decade. But by the early 1990s, the Space Station Freedom was significantly over budget and behind schedule. Shortly after taking office in 1993, President Bill Clinton asked MIT President Charles Vest to lead the Advisory Committee on the Redesign of the Space Station. In the wake of the Soviet Union’s collapse, the Vest committee recommended that “NASA and the Administration further pursue opportunities for cooperation with the Russians as a means to enhance the capability of the station, reduce cost, provide alternative access to the station, and increase research opportunities.” That led NASA to invite the Russian space agency Roscosmos to join an international ISS coalition. And today, the ISS is operated cooperatively by the space agencies of the United States (NASA), Russia (Roscosmos), Japan (JAXA), Canada (CSA), and Europe (ESA).&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1126026" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/shepard.jpg?w=1104" /&gt;&lt;figcaption class="wp-element-caption"&gt;Bill Shepherd, OCE ’78, SM ’78, and his crewmates built this worktable in space using tools they’d smuggled on board. They inscribed “The Best from Nothing” in Latin on its side. &lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF BILL SHEPARD&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;“We went from a space race during the Apollo time frame to—actually now we work together, humans across planet Earth, making something pretty incredible,” Fincke says. “Hats off to all of my crewmates and to all of the teams across planet Earth that put this beautiful space station together.” &amp;nbsp;&lt;/p&gt;  &lt;p&gt;As deputy administrator of NASA from 2021 to 2025, Melroy helped lead NASA during a challenging period following the Russian invasion of Ukraine. “When people are united by something that they’re equally passionate about,” she says, “you overcome the barriers of cultural, language, political differences.” NASA and Roscosmos had established a “level of trust,” she says, “and there are relationships at every single level.” Keeping relationships nonpolitical was a guiding principle, Melroy says, “and our Russian partners respected that and agreed.”&lt;/p&gt; 
 &lt;p&gt;“We still have our partnership in space even though on the ground we’re not quite getting along,” Fincke says. “We have a beautiful solar system to go explore, and someday we’re gonna have the stars.” And that, he says, will be possible “if we stop fighting and put our efforts toward exploration.”&lt;/p&gt;  &lt;p&gt;In 2001 Shepherd predicted, “It’s very likely that the day of our launch … will be the last day that humans will live only on planet Earth.” And after 25 years of living and working on the International Space Station, humans appear to be up to the challenge of proving him right. &lt;/p&gt;  &lt;p&gt;&lt;em&gt;John Tylko ’79, PhD ’23, an aerospace engineer and technology historian, witnessed the 2000 launch of the first ISS crew at the Baikonur Cosmodrome and the docking of their spacecraft with the ISS from the Russian Mission Control Center near Moscow.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Michael Fincke floating on the ISS" class="wp-image-1126208" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/iss073e0420910large.jpg?w=1773" /&gt;&lt;figcaption class="wp-element-caption"&gt;Expedition 73 astronaut Michael Fincke ’89 inside the European Columbus laboratory module of the International Space Station in August 2025. While being interviewed from the ISS in September, Fincke said that MIT prepared him well for his time in space, from the aero-astro classes that taught him about airplanes and rockets—and critical thinking—to his Russian language and EAPS classes. “When you have such a critical mass of really intelligent people and critical thinkers, it really makes a difference and brings out the best in all of us, including me,” he said. “So thank you, MIT."&lt;/figcaption&gt; &lt;/figure&gt; &lt;/div&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1126204" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/52970170188_923f11dc88_o.jpg?w=2841" width="2841" /&gt;&lt;figcaption class="wp-element-caption"&gt;Astronaut Woody Hoburg ’08 conducts a spacewalk outside the International Space Station to deploy new solar arrays during Expedition 68 on June 9, 2023.&lt;/figcaption&gt; &lt;/figure&gt; &lt;/div&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1126207" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/iss064e025418orig.jpg?w=3000" /&gt;&lt;figcaption class="wp-element-caption"&gt;Expedition 64 astronaut Kate Rubins, a Whitehead Fellow, with the DNA sequencing experiment she ran aboard the ISS on January 22, 2021. Rubins was first astronaut to sequence DNA in space during Expedition 48 in 2016.&lt;/figcaption&gt; &lt;/figure&gt; &lt;/div&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1126209" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/Screenshot-2025-10-21-093008.jpg?w=1951" /&gt;&lt;figcaption class="wp-element-caption"&gt;Mike Fincke ’89, Cady Coleman ’83, and Greg Chamitoff, PhD ’92, made a video to offer extraterrestrial congratulations on the Institute’s 150th anniversary while they were all aboard the ISS in 2011. In this still from the video, they’re seen with the three SPHERES satellites developed by MIT’s Space Systems Laboratory.&lt;/figcaption&gt; &lt;/figure&gt; &lt;/div&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1126206" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/DSC_1459.jpg?w=2495" /&gt;&lt;figcaption class="wp-element-caption"&gt;Samuel C.C. Ting, the Thomas Dudley Cabot Professor of Physics at MIT, with a model of the Alpha Magnetic Spectrometer (AMS) at a Kennedy Space Center news conference on April 28, 2011. &lt;/figcaption&gt;&lt;div class="image-credit"&gt;JOHN TYLKO&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1126203" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/9443612295_2c1aa4614d_o.jpg?w=2731" width="2731" /&gt;&lt;figcaption class="wp-element-caption"&gt;Expedition 18 astronauts Greg Chamitoff, PhD ’92 (left) and Mike Fincke ’89 (center) with spaceflight participant Richard Garriott on October 22, 2008, in the ISS Harmony node with the three SPHERES satellites developed at MIT.&lt;/figcaption&gt; &lt;/figure&gt; &lt;/div&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1126205" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/aero-astro-nasa-stabilizer-2.jpg?w=1659" /&gt;&lt;figcaption class="wp-element-caption"&gt;In September 2000, Aero-Astro Space Systems Laboratory researchers posed with MIT’s MACE-II (Middeck Active Control Experiment), the first active US scientific investigation performed on the ISS. Left to right: Cemocan Yesil ’03, Professor David Miller ’82, SM ’85, ScD ’88, Gregory Mallory, PhD ’00, and Jeremy Yung ’93, SM ’96, PhD ’02.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;DONNA COVENEY&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;On November 2, 2000, NASA astronaut Bill Shepherd, OCE ’78, SM ’78, and Russian cosmonauts Sergei Krikalev and Yuri Gidzenko made history as their Soyuz spacecraft docked with the International Space Station.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The event marked the start of 25 years of continuous human presence in space aboard the ISS—a prolific period for space research. MIT-trained astronauts, scientists, and engineers have played integral roles in all aspects of the station’s design, assembly, operations, and scientific research.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;One of MIT’s most experienced NASA astronauts, Mike Fincke ’89, is celebrating that milestone from space. Having already logged 381 days in three previous missions to the ISS, he returned on August&amp;nbsp;1 as a member of the Expedition 73 crew. “Wow, 25 years of constant human habitation in space!” he said when he spoke with me from the station in September. “What an accomplishment and a testimony to the teams on the ground and in terms of engineering, science, and diplomacy.”&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Building and operating the ISS&lt;/h3&gt;  &lt;p&gt;“We understood that building the ISS was significantly more difficult than anything we’d attempted before with the possible exception of Apollo,” says Pamela Melroy, SM ’84, who flew the space shuttle on three ISS assembly missions, including STS-92 in October 2000, which installed key modules and structures that prepared the station for the arrival of Shepherd and his crew less than two weeks later. “We learned a tremendous amount from the Shuttle-Mir program that I think gave us a lot more confidence going into ISS assembly,” she says.&lt;/p&gt; 
 &lt;p&gt;Melroy was one of 10 MIT astronauts who participated in 13 space shuttle missions to assemble and resupply the ISS through 2011. “It’s pretty awe-inspiring to just go, ‘Wow, there is the visible evidence of what we just spent 10 to 14 days doing,’” she recalls. She also saw just how critical logistics are to resupply operations—especially since the retirement of the shuttle.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Shepherd, who served as Expedition One commander, and his crew overcame a variety of challenges as they adapted to living in space, continued the assembly of the ISS, and installed and activated its life support and communications systems. “We were blue-collar maintenance guys for most of our flight,” he says. “I really enjoyed that part of it.” After arriving on the ISS, he discovered that the Russian service module was missing a worktable that his crew had found to be very useful in training. He asked Moscow, “Where’s our table?” and was told, “It’s going to come up six months after you guys are gone.”&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Cargo flights had delivered canisters of carbon dioxide absorbers packaged in sturdy aluminum frames. Upon inspecting the frames, they decided there was no reason to remain table-less. “We had some special tools that we had smuggled on board,” he recalls. “So we started to cut and drill and thread and fabricate a table out of scraps.” It turned out to be a pretty good table. “When Houston found out about it, they went nuts, because we were up there sawing, making chips and aluminum sawdust,” he says. “But we got through all that.” Now in the Smithsonian, it is “definitely an MIT-designed table,” Shepherd says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Twelve MIT alums and one MIT affiliate from the Whitehead Institute have logged a total of 18 long-duration missions to the ISS. Cady Coleman ’83 served as lead robotics and science officer during a 159-day expedition in 2010 and 2011. She performed hundreds of experiments, ranging from basic science to technology development for future moon and Mars missions. “At MIT, we were always invited to be part of scientific discovery,” Coleman says. “We carried MIT’s standard of excellence into every field. Most importantly, our education taught us that we were part of a larger mission to make the world a better place.”&lt;/p&gt;  &lt;p&gt;Citing the “mens et manus” motto on the Brass Rat he was wearing in space, Fincke observed that MIT prepared him well for his job. “When you have such a critical mass of really intelligent people and critical thinkers, it really makes a difference and brings out the best in all of us, including me,” he said. “So thank you, MIT.”&lt;/p&gt;  &lt;p&gt;Woody Hoburg ’08, who was an assistant professor of aero-astro before piloting a 186-day mission to the ISS in 2023, concurs: “It’s no surprise that so many exceptional MIT thinkers and doers end up shaping our boldest achievements in space. The ISS is certainly one of those—it’s a beautiful machine, constructed while I was still in high school and later studying Course 16 at MIT, flying five miles per second over Earth that whole time.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;h3 class="wp-block-heading"&gt;Science in space&lt;/h3&gt;  &lt;p&gt;A wide range of MIT faculty and students have taken advantage of the ISS’s unique access to space to conduct research.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“MIT’s MACE-II [Middeck Active Control Experiment] was the first active US scientific investigation performed on the International Space Station,” Shepherd said back in 2001. “Performing scientific investigations like MACE-II on board the station allows for successful interaction, almost in real time, between the astronauts in space and investigators on the ground.” Developed by aero-astro professor David Miller ’82, SM ’85, ScD ’88, and the Space Systems Laboratory (SSL) he then directed, MACE-II successfully tested techniques for predicting and controlling the dynamics of structures in microgravity. Miller says that the structural dynamics techniques developed through MACE were later used to test the James Webb Space Telescope. &amp;nbsp;&lt;/p&gt;  &lt;p&gt;Miller and the SSL also led the development of SPHERES (Synchronized Position Hold Engage and Reorient Experimental Satellites), a set of satellites used on board the ISS from 2006 through 2019. Inspired by the Jedi training ball from the original &lt;em&gt;Star Wars&lt;/em&gt;, SPHERES evolved from an undergraduate aero-astro capstone project into an ISS facility for studying the dynamic control of satellites flying together in space. Three independent free-flying satellites operated inside the ISS within an infrared/ultrasonic measurement system that provided precise positioning and attitude information in three dimensions. SPHERES let researchers develop and test algorithms for precision control of multiple spacecraft during complex collaborative operations. Its modular design permitted the addition of electromagnets for precise tandem flight, vision systems for navigation, and hardware for investigating the sloshing of fluids in space.&amp;nbsp;&lt;/p&gt;    &lt;p&gt;Greg Chamitoff, PhD ’92, became the first principal investigator to directly perform his own scientific research on the ISS when he programmed SPHERES during Expedition 17 in 2008. Miller recalls that when Chamitoff later visited MIT, he asked, “Why don’t we create the first primary school robotics competition ever hosted off the planet?” During the next decade, nearly 20,000 high school and middle school students from around the world participated in Zero Robotics, writing algorithms to control the SPHERES satellites in STEM competitions conducted onboard the ISS. Both MACE-II and SPHERES were returned to Earth and will be on display at the National Air and Space Museum in the “At Home in Space” gallery slated to open in 2026.&lt;/p&gt; 

 &lt;p&gt;Samuel C.C. Ting, the Thomas Dudley Cabot Professor of Physics at MIT, led a $2 billion international effort to develop the Alpha Magnetic Spectrometer (AMS) with the ambitious goal of searching for antimatter, determining the origin of dark matter, and understanding the properties of cosmic rays. Delivered to the ISS in 2011 by one of the final space shuttle missions, the AMS has precisely measured over 253 billion cosmic ray events with energies up to multiple tera-electron-volts. Fully interpreting the comprehensive experimental data still being generated by the AMS will require new physics models. “I would imagine 100 years from now most of my work will be forgotten,” Ting says. “But if people remember anything, it probably will be AMS.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Kate Rubins, a microbiologist, was a fellow at the Whitehead Institute when she was selected as a NASA astronaut in 2009—and became the first person to sequence DNA in space during her long-&lt;br /&gt;duration ISS mission in 2016. She did so using a commercially available meta­genomics sequencer, despite the risk that it might not function in orbit. “To everybody’s surprise, it worked, and it worked the first time,” she recalls. “I don’t know if I’ve ever had a lab experiment in my life that has worked the first time, but genomic sequencing in space was a big one to have that happen.”&lt;/p&gt;  &lt;p&gt;Rubins wanted to conduct her own scientific research during her spare time in orbit, so she got permission from NASA to substitute her own lab bench equipment—including pipettes, tubes, and scientific plasticware—for the small kit of personal items that astronauts are allowed to bring to space. She got a NASA psychologist to help make the case. “He said, ‘You know, Kate’s a nerd—she loves doing this stuff … we have to fly this on board for her,’” she says. Rubins successfully demonstrated that regular biology lab equipment could be used to conduct science in space—and donated that equipment for use by future ISS crews. (“Every astronaut turns into a scientist when they get on board the space station,” she says.) She recently coauthored a paper describing the creation of a microbiome map of the ISS—a 3D map showing where astronauts found various microbes and metabolites when they collected samples in space. She calls the work “super exciting.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The ISS also serves as a test bed for new technologies that will support NASA’s ambitious programs to explore the moon and Mars. In 2023, MIT Lincoln Laboratory successfully demonstrated high-­bandwidth laser communications in space between its ILLUMA-T laser communications terminal onboard the ISS and a NASA Laser Communications Relay Demonstration satellite. When the Artemis II astronauts launch to the moon in early 2026, their Orion spacecraft will use the optical communications system developed by Lincoln Laboratory’s Optical and Quantum Communications Group and the Goddard Space Flight Center to transmit high-­resolution imagery of the lunar surface back to Earth via lasers capable of data rates up to 260 megabits per second.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;h3 class="wp-block-heading"&gt;International cooperation&lt;/h3&gt;  &lt;p&gt;One of the most enduring legacies of the International Space Station, which is slated to continue operations through 2030, is the vast scale of international cooperation that made it possible.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The roots of the project trace back to 1984, when President Ronald Reagan challenged NASA to lead an effort to build an Earth-orbiting space station within a decade. But by the early 1990s, the Space Station Freedom was significantly over budget and behind schedule. Shortly after taking office in 1993, President Bill Clinton asked MIT President Charles Vest to lead the Advisory Committee on the Redesign of the Space Station. In the wake of the Soviet Union’s collapse, the Vest committee recommended that “NASA and the Administration further pursue opportunities for cooperation with the Russians as a means to enhance the capability of the station, reduce cost, provide alternative access to the station, and increase research opportunities.” That led NASA to invite the Russian space agency Roscosmos to join an international ISS coalition. And today, the ISS is operated cooperatively by the space agencies of the United States (NASA), Russia (Roscosmos), Japan (JAXA), Canada (CSA), and Europe (ESA).&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1126026" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/shepard.jpg?w=1104" /&gt;&lt;figcaption class="wp-element-caption"&gt;Bill Shepherd, OCE ’78, SM ’78, and his crewmates built this worktable in space using tools they’d smuggled on board. They inscribed “The Best from Nothing” in Latin on its side. &lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF BILL SHEPARD&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;“We went from a space race during the Apollo time frame to—actually now we work together, humans across planet Earth, making something pretty incredible,” Fincke says. “Hats off to all of my crewmates and to all of the teams across planet Earth that put this beautiful space station together.” &amp;nbsp;&lt;/p&gt;  &lt;p&gt;As deputy administrator of NASA from 2021 to 2025, Melroy helped lead NASA during a challenging period following the Russian invasion of Ukraine. “When people are united by something that they’re equally passionate about,” she says, “you overcome the barriers of cultural, language, political differences.” NASA and Roscosmos had established a “level of trust,” she says, “and there are relationships at every single level.” Keeping relationships nonpolitical was a guiding principle, Melroy says, “and our Russian partners respected that and agreed.”&lt;/p&gt; 
 &lt;p&gt;“We still have our partnership in space even though on the ground we’re not quite getting along,” Fincke says. “We have a beautiful solar system to go explore, and someday we’re gonna have the stars.” And that, he says, will be possible “if we stop fighting and put our efforts toward exploration.”&lt;/p&gt;  &lt;p&gt;In 2001 Shepherd predicted, “It’s very likely that the day of our launch … will be the last day that humans will live only on planet Earth.” And after 25 years of living and working on the International Space Station, humans appear to be up to the challenge of proving him right. &lt;/p&gt;  &lt;p&gt;&lt;em&gt;John Tylko ’79, PhD ’23, an aerospace engineer and technology historian, witnessed the 2000 launch of the first ISS crew at the Baikonur Cosmodrome and the docking of their spacecraft with the ISS from the Russian Mission Control Center near Moscow.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Michael Fincke floating on the ISS" class="wp-image-1126208" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/iss073e0420910large.jpg?w=1773" /&gt;&lt;figcaption class="wp-element-caption"&gt;Expedition 73 astronaut Michael Fincke ’89 inside the European Columbus laboratory module of the International Space Station in August 2025. While being interviewed from the ISS in September, Fincke said that MIT prepared him well for his time in space, from the aero-astro classes that taught him about airplanes and rockets—and critical thinking—to his Russian language and EAPS classes. “When you have such a critical mass of really intelligent people and critical thinkers, it really makes a difference and brings out the best in all of us, including me,” he said. “So thank you, MIT."&lt;/figcaption&gt; &lt;/figure&gt; &lt;/div&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1126204" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/52970170188_923f11dc88_o.jpg?w=2841" width="2841" /&gt;&lt;figcaption class="wp-element-caption"&gt;Astronaut Woody Hoburg ’08 conducts a spacewalk outside the International Space Station to deploy new solar arrays during Expedition 68 on June 9, 2023.&lt;/figcaption&gt; &lt;/figure&gt; &lt;/div&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1126207" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/iss064e025418orig.jpg?w=3000" /&gt;&lt;figcaption class="wp-element-caption"&gt;Expedition 64 astronaut Kate Rubins, a Whitehead Fellow, with the DNA sequencing experiment she ran aboard the ISS on January 22, 2021. Rubins was first astronaut to sequence DNA in space during Expedition 48 in 2016.&lt;/figcaption&gt; &lt;/figure&gt; &lt;/div&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1126209" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/Screenshot-2025-10-21-093008.jpg?w=1951" /&gt;&lt;figcaption class="wp-element-caption"&gt;Mike Fincke ’89, Cady Coleman ’83, and Greg Chamitoff, PhD ’92, made a video to offer extraterrestrial congratulations on the Institute’s 150th anniversary while they were all aboard the ISS in 2011. In this still from the video, they’re seen with the three SPHERES satellites developed by MIT’s Space Systems Laboratory.&lt;/figcaption&gt; &lt;/figure&gt; &lt;/div&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1126206" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/DSC_1459.jpg?w=2495" /&gt;&lt;figcaption class="wp-element-caption"&gt;Samuel C.C. Ting, the Thomas Dudley Cabot Professor of Physics at MIT, with a model of the Alpha Magnetic Spectrometer (AMS) at a Kennedy Space Center news conference on April 28, 2011. &lt;/figcaption&gt;&lt;div class="image-credit"&gt;JOHN TYLKO&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1126203" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/9443612295_2c1aa4614d_o.jpg?w=2731" width="2731" /&gt;&lt;figcaption class="wp-element-caption"&gt;Expedition 18 astronauts Greg Chamitoff, PhD ’92 (left) and Mike Fincke ’89 (center) with spaceflight participant Richard Garriott on October 22, 2008, in the ISS Harmony node with the three SPHERES satellites developed at MIT.&lt;/figcaption&gt; &lt;/figure&gt; &lt;/div&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1126205" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/aero-astro-nasa-stabilizer-2.jpg?w=1659" /&gt;&lt;figcaption class="wp-element-caption"&gt;In September 2000, Aero-Astro Space Systems Laboratory researchers posed with MIT’s MACE-II (Middeck Active Control Experiment), the first active US scientific investigation performed on the ISS. Left to right: Cemocan Yesil ’03, Professor David Miller ’82, SM ’85, ScD ’88, Gregory Mallory, PhD ’00, and Jeremy Yung ’93, SM ’96, PhD ’02.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;DONNA COVENEY&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/21/1124727/25-years-of-research-in-space/</guid><pubDate>Tue, 21 Oct 2025 21:00:00 +0000</pubDate></item><item><title>Infinite folds (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/21/1124723/infinite-folds/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;When Madonna Yoder ’17 was eight years old, she learned how to fold a square piece of paper over and over and over again. After about 16 folds, she held a bird in her hands.&lt;/p&gt;  &lt;p&gt;The first time she pulled the tail of a flapping crane, she says, she realized: &lt;em&gt;Oh,&lt;/em&gt; &lt;em&gt;I folded this, and now it’s a toy&lt;/em&gt;.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;That first piece was an origami classic, folded by kids at summer camp for generations and many people’s first foray into the art form. Often, it’s also the last. But Yoder was transfixed. Soon she was folding everything she could find: paper squares from chain craft shops, scraps from around the house, the weekly church bulletin, which she would cut into pieces with the aid of her fingernails. She would then “turn those into little critters and give them to any guests that were there that week,” she says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Today, perhaps millions of folds later, Yoder is a superstar known to some as the “Queen of Tessellations,” a reference to a mathematically intricate type of origami that she began exploring during her years at MIT.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;“These are patterns that can repeat infinitely and are folded on a single sheet of paper,” Yoder explains. “There’s literally no end to the patterns themselves, no end to the number of designs you can create … They’re folded by hand—I don’t know of any machine that could fold them—and they are a really great way to just sit and focus and relax.”&lt;/p&gt;  &lt;p&gt;Her pieces have grown increasingly complex over time, but the patterns she creates are based on recognizable shapes, including hexagons, triangles, rhombuses, and trapezoids. Yoder folds and rotates them into repeating, potentially infinite series of shapes. Picture the graphic pattern in an M.C. Escher print, but made out of a single sheet of paper—a piece of art underpinned by mathematics and a bit of engineering, combined with the complexity of a snowflake.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Yoder grew up in southwestern Virginia, in the Blue Ridge Mountain town of Shawsville, where professors from Virginia Tech filled the pews at her Mennonite church. “All of us kids were expected to go to college,” she says. After she made her way to MIT, her brother, Jake, earned his PhD in materials engineering at Virginia Tech and now works with 3D-printed metals. Her mother, Janet, is a physical therapist and her father, Denton, is a computer systems engineer at Virginia Tech.&lt;/p&gt;  &lt;p&gt;From a young age, Yoder had an inclination for making things with her hands. “I was kind of that kid—I did all the different crafts. I did a lot of cross-stitch,” she says, including a portrait of her grandmother that now hangs framed in her kitchen.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;She also remembers an early appreciation for accuracy. “My mom tells the story about when I was five years old, we were cutting out squares, and I was like: ‘Mom, your squares are not precise enough,’” she says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Toward the end of her senior year of high school, Yoder won a math competition, which came with an apt prize: a book about modular origami, in which multiple sheets of paper are folded and combined into often elaborate structures. She took a gap year in Peru, where she continued to fold, giving little modular pieces away to children she met on her travels.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;Yoder had always done paper folding in solitude, with guidance only from books. When she arrived at MIT after her time in Peru, she was surprised to learn about weekly origami gatherings and the annual convention held by the campus club OrigaMIT.&lt;/p&gt;  &lt;p&gt;“It took until I got to MIT to realize that, oh, this is an active space where people are meeting up and designing things and talking to each other about origami all weekend,” she says. She majored in Earth, Atmospheric, and Planetary Sciences (EAPS), but in the spring of her senior year, she took Erik Demaine’s popular class Geometric Folding Algorithms—and discovered that “origami research was something that people got paid to do,” as she puts it. Her final project for the class became a poster presentation at the 7th International Meeting on Origami in Science, Mathematics, and Education (7OSME). “In that course, I got hooked on origami research,” Yoder says.&lt;/p&gt;  &lt;p&gt;Demaine remembers that Yoder started to explore concepts related to tessellations in his class, which eventually led to the publication of her first paper—“Folding Triangular and Hexagonal Mazes,” coauthored with him and Jason Ku, then a lecturer at MIT. In that paper, Yoder helped demonstrate how to “generalize” a square grid maze to triangular and hexagonal grids by changing the underlying crease pattern. “We probably suggested this as an interesting open problem for people to work on, and Madonna found a really happy niche there,” says Demaine, who isn’t aware of any other former students pursuing careers in origami. “We provided the space for her to do the research, but then she went whole hog on it.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But she didn’t truly embrace tessellations until after she graduated and was preparing for a four-and-a-half-month MIT-sponsored internship in Israel. “These modulars have a lot of volume—I’m not going to bring back a suitcase full of them,” she remembers thinking. And she wasn’t going to leave behind four-plus months of folding work. “So I decided to teach myself to fold tessellations because they’re flat and travel well,” she says.&amp;nbsp; “Then it took root in my brain and never let me go.”&lt;/p&gt; 

 &lt;p&gt;But there was the practical matter of making a living.&lt;/p&gt;  &lt;p&gt;Origami principles have been used to conceive of and develop a wide range of things, from the tiny (think medical instruments or nanoscale devices that can deliver DNA into cells) to the large (such as collapsible structures usable in disaster response or foldable solar arrays for space exploration). Yoder figured if she wanted to pursue origami as a career, she would have to do it as a scientist or engineer.&lt;/p&gt;  &lt;p&gt;But after reverse-engineering hundreds of origami patterns she found online—and starting to design her own—she began to suspect otherwise. “I realized it’s actually possible to make a living as an origami artist,” she remembers. “I won’t say that now, five years out from that decision, I’ve reached a point of being able to fully financially support myself with origami, but thankfully, I married a software engineer.” (She met her husband, Manny Meraz-Rodriguez, while the two were working at the Lawrence Livermore National Laboratory, she as an intern and then as a postcollege appointee in computational geoscience.)&lt;/p&gt;  &lt;p&gt;Origami purists will say that true origami requires no cuts, no glue. The only slicing Yoder does is with a rotary cutter she uses to make hexagonal pieces of paper, stacks at a time. Though she starts with squares sometimes, the hexagon is her favored launching pad. She creases the paper into a grid, and then—­following a design that she’s created using a vector graphics program called Inkscape—begins to fold.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;“The main reason why I draw the patterns out first, besides the fact that the designs have gotten too complicated for me to hold in my brain and solve on the fly, is because I like to have the pattern rotated so that the repeats of the pattern align with the edge, which you can only do if you have the information of how the repeats of the pattern line up with the background grid,” she explains.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Using a simple tool called a bone folder (Yoder says she’s had hers for years and could pick it out of a pile by the wear pattern), she presses and creases and rotates the paper into an elaborate pattern that could, in theory, go on forever. The end result is a beautiful, satisfyingly symmetrical array of repeated, interlocking shapes that look especially impressive when held up to the light, bringing to mind a stained-glass window.&lt;/p&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="folded shape" class="wp-image-1126035" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/ND25-folding-04.jpg?w=680" /&gt;&lt;figcaption class="wp-element-caption"&gt;Scroll down to learn how to fold this Dancing Ribbons tessellation created by Yoder.&lt;/figcaption&gt;&lt;/figure&gt;  &lt;p&gt;Scholars debate whether the ancient tradition of origami began in Japan or China, but the art really took off globally in the 1950s and ’60s when publishers printed and mass-marketed diagrams showing people how to fold paper into figurative objects such as birds, fish, and animals. Paper tessellations have roots in Germany in the 1920s, when the artist Josef Albers added folding to his introductory design course at the Bauhaus. This geometric tradition started gaining popularity in the 1980s and 1990s, and now, Yoder says, there are perhaps tens of thousands of people who participate. The broader universe of origami practitioners likely numbers in the millions.&lt;/p&gt;  &lt;p&gt;These aficionados attend conferences, watch YouTube videos, and take online courses, most of them to learn existing patterns. Yoder creates her own: In addition to the peer-­reviewed academic papers she’s authored on the mathematical underpinnings of her tessellations (with titles like “Symmetry Requirements and Design Equations for Origami Tessellations” and “Hybrid Hexagon Twist Interface”) and regular presentations at origami conferences across the globe, she’s designed 696 original patterns. Each year in an event she calls Advent of Tess, she teaches thousands of online participants a new design every day of December leading up to Christmas, and her website, Gathering Folds, has become a go-to source, not just for Yoder’s artwork but for instruction.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Her EAPS degree from MIT may not seem like a foundation for a career as an artist, but Yoder, who studied geology with a secondary focus on ecology, says there are connections between the fields. “There is a lot of carryover between the crystal structures and the tessellation symmetries,” she explains. “Every repeating 2D pattern obeys one of the planar symmetry groups … There are things that repeat like a hexagon, things that repeat like a square, things that repeat like a triangle, and things that repeat like a parallelogram or rectangle. And then there are things that are not rotationally symmetric. Those ideas of how things connect and how things repeat definitely carry over from my crystallography class.”&lt;/p&gt;  &lt;p&gt;Yoder cites the origami artist and physicist Robert Lang as one of the current practitioners who influenced her the most. He, like Yoder, has a math and science background but forged a career in art.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;“The thing that has set her above the current crowd is that she’s really systematically explored the building blocks of tessellations and the different little patterns that can be considered building blocks, and the rules for connecting these blocks,” he explains. “Madonna’s knowledge and understanding of mathematics and geometry gives her a broader tool kit to create art, and that’s led to her success as an artist. You can’t separate the art from the science background. It’s part of the thinking process, even if the end goal is very much in the fine art world.”&lt;/p&gt;  &lt;p&gt;For Yoder, the process, both computational and tactile, is also an end in itself. It is almost a meditation—a way to slow down and contemplate. Some of her students have even suggested there might be a spiritual component to it. One said to her: “You know, the name for that connection to infinite things is called God, right?”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;“So I kind of leave that more open,” she says. “I’m not super decided about what these things mean. I’m just happy to have that spark when I’m designing a pattern: Here’s how the shapes hang together, and now that I’ve drawn out those shapes, I can copy and paste, paste, paste, paste, paste, and it just clicks in very satisfyingly.”&lt;/p&gt;  &lt;p&gt;Yoder has considered whether she will ever get bored pursuing the possibilities of infinite patterns—whether she will achieve perfection and decide to put the bone folder away for good.&lt;/p&gt;  &lt;p&gt;“But I’m not convinced that I will,” she says. “There are always ways to make it harder and harder.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="imageSet__wrap"&gt;&lt;div class="columns__wrapper--07c4096a3b25e22dc82ee78b6368d947"&gt;&lt;div class="wp-block-columns"&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="diagram of origami pattern" class="wp-image-1126213" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/creasepattern.jpg?w=2000" width="2000" /&gt;&lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="example of folded pattern" class="wp-image-1126212" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/AOT22_Day10-2.jpg?w=744" /&gt;&lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Fold it yourself&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Try your hand at folding Madonna Yoder’s Dancing Ribbons tessellation design featuring three closed twists: hexagon, triangle, and rhombus.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Basic instructions&lt;/strong&gt;&lt;/p&gt;  &lt;div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"&gt; &lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt; Download the pattern here and cut out the hexagon with the crease pattern. &lt;/p&gt;    &lt;p&gt;&lt;strong&gt;2.&lt;/strong&gt; Fold all the background grid lines, making sure to fold them back and forth so the paper is ready to form the pattern. (You can precrease all the off-grid folds too, but Yoder recommends folding one twist at a time.) This pattern shows mountain folds with solid red lines and valley folds with dashed blue lines. The faded lines inside the twists are helper folds used to set up the twists; they will not be used in the final pattern.&lt;/p&gt;    &lt;p&gt;&lt;strong&gt;3. &lt;/strong&gt;Working from the side without the pattern, fold the central hexagon.&lt;/p&gt;    &lt;p&gt;&lt;strong&gt;4. &lt;/strong&gt;Fold the triangles.&lt;/p&gt;    &lt;p&gt;&lt;strong&gt;5. &lt;/strong&gt;Fold the rhombuses.&lt;/p&gt; &lt;/div&gt;  &lt;p&gt;Find more detailed instructions and a video tutorial&lt;em&gt;—&lt;/em&gt;as well as paper advice&lt;em&gt;—&lt;/em&gt;at technologyreview.com/tessellation.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;You can also sign up for Yoder’s annual Advent of Tess&lt;em&gt;—&lt;/em&gt;a 25-day folding challenge that begins December 1&lt;em&gt;—&lt;/em&gt;at&amp;nbsp; https://training.gatheringfolds.com/advent.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;When Madonna Yoder ’17 was eight years old, she learned how to fold a square piece of paper over and over and over again. After about 16 folds, she held a bird in her hands.&lt;/p&gt;  &lt;p&gt;The first time she pulled the tail of a flapping crane, she says, she realized: &lt;em&gt;Oh,&lt;/em&gt; &lt;em&gt;I folded this, and now it’s a toy&lt;/em&gt;.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;That first piece was an origami classic, folded by kids at summer camp for generations and many people’s first foray into the art form. Often, it’s also the last. But Yoder was transfixed. Soon she was folding everything she could find: paper squares from chain craft shops, scraps from around the house, the weekly church bulletin, which she would cut into pieces with the aid of her fingernails. She would then “turn those into little critters and give them to any guests that were there that week,” she says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Today, perhaps millions of folds later, Yoder is a superstar known to some as the “Queen of Tessellations,” a reference to a mathematically intricate type of origami that she began exploring during her years at MIT.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;“These are patterns that can repeat infinitely and are folded on a single sheet of paper,” Yoder explains. “There’s literally no end to the patterns themselves, no end to the number of designs you can create … They’re folded by hand—I don’t know of any machine that could fold them—and they are a really great way to just sit and focus and relax.”&lt;/p&gt;  &lt;p&gt;Her pieces have grown increasingly complex over time, but the patterns she creates are based on recognizable shapes, including hexagons, triangles, rhombuses, and trapezoids. Yoder folds and rotates them into repeating, potentially infinite series of shapes. Picture the graphic pattern in an M.C. Escher print, but made out of a single sheet of paper—a piece of art underpinned by mathematics and a bit of engineering, combined with the complexity of a snowflake.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Yoder grew up in southwestern Virginia, in the Blue Ridge Mountain town of Shawsville, where professors from Virginia Tech filled the pews at her Mennonite church. “All of us kids were expected to go to college,” she says. After she made her way to MIT, her brother, Jake, earned his PhD in materials engineering at Virginia Tech and now works with 3D-printed metals. Her mother, Janet, is a physical therapist and her father, Denton, is a computer systems engineer at Virginia Tech.&lt;/p&gt;  &lt;p&gt;From a young age, Yoder had an inclination for making things with her hands. “I was kind of that kid—I did all the different crafts. I did a lot of cross-stitch,” she says, including a portrait of her grandmother that now hangs framed in her kitchen.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;She also remembers an early appreciation for accuracy. “My mom tells the story about when I was five years old, we were cutting out squares, and I was like: ‘Mom, your squares are not precise enough,’” she says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Toward the end of her senior year of high school, Yoder won a math competition, which came with an apt prize: a book about modular origami, in which multiple sheets of paper are folded and combined into often elaborate structures. She took a gap year in Peru, where she continued to fold, giving little modular pieces away to children she met on her travels.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;Yoder had always done paper folding in solitude, with guidance only from books. When she arrived at MIT after her time in Peru, she was surprised to learn about weekly origami gatherings and the annual convention held by the campus club OrigaMIT.&lt;/p&gt;  &lt;p&gt;“It took until I got to MIT to realize that, oh, this is an active space where people are meeting up and designing things and talking to each other about origami all weekend,” she says. She majored in Earth, Atmospheric, and Planetary Sciences (EAPS), but in the spring of her senior year, she took Erik Demaine’s popular class Geometric Folding Algorithms—and discovered that “origami research was something that people got paid to do,” as she puts it. Her final project for the class became a poster presentation at the 7th International Meeting on Origami in Science, Mathematics, and Education (7OSME). “In that course, I got hooked on origami research,” Yoder says.&lt;/p&gt;  &lt;p&gt;Demaine remembers that Yoder started to explore concepts related to tessellations in his class, which eventually led to the publication of her first paper—“Folding Triangular and Hexagonal Mazes,” coauthored with him and Jason Ku, then a lecturer at MIT. In that paper, Yoder helped demonstrate how to “generalize” a square grid maze to triangular and hexagonal grids by changing the underlying crease pattern. “We probably suggested this as an interesting open problem for people to work on, and Madonna found a really happy niche there,” says Demaine, who isn’t aware of any other former students pursuing careers in origami. “We provided the space for her to do the research, but then she went whole hog on it.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But she didn’t truly embrace tessellations until after she graduated and was preparing for a four-and-a-half-month MIT-sponsored internship in Israel. “These modulars have a lot of volume—I’m not going to bring back a suitcase full of them,” she remembers thinking. And she wasn’t going to leave behind four-plus months of folding work. “So I decided to teach myself to fold tessellations because they’re flat and travel well,” she says.&amp;nbsp; “Then it took root in my brain and never let me go.”&lt;/p&gt; 

 &lt;p&gt;But there was the practical matter of making a living.&lt;/p&gt;  &lt;p&gt;Origami principles have been used to conceive of and develop a wide range of things, from the tiny (think medical instruments or nanoscale devices that can deliver DNA into cells) to the large (such as collapsible structures usable in disaster response or foldable solar arrays for space exploration). Yoder figured if she wanted to pursue origami as a career, she would have to do it as a scientist or engineer.&lt;/p&gt;  &lt;p&gt;But after reverse-engineering hundreds of origami patterns she found online—and starting to design her own—she began to suspect otherwise. “I realized it’s actually possible to make a living as an origami artist,” she remembers. “I won’t say that now, five years out from that decision, I’ve reached a point of being able to fully financially support myself with origami, but thankfully, I married a software engineer.” (She met her husband, Manny Meraz-Rodriguez, while the two were working at the Lawrence Livermore National Laboratory, she as an intern and then as a postcollege appointee in computational geoscience.)&lt;/p&gt;  &lt;p&gt;Origami purists will say that true origami requires no cuts, no glue. The only slicing Yoder does is with a rotary cutter she uses to make hexagonal pieces of paper, stacks at a time. Though she starts with squares sometimes, the hexagon is her favored launching pad. She creases the paper into a grid, and then—­following a design that she’s created using a vector graphics program called Inkscape—begins to fold.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;“The main reason why I draw the patterns out first, besides the fact that the designs have gotten too complicated for me to hold in my brain and solve on the fly, is because I like to have the pattern rotated so that the repeats of the pattern align with the edge, which you can only do if you have the information of how the repeats of the pattern line up with the background grid,” she explains.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Using a simple tool called a bone folder (Yoder says she’s had hers for years and could pick it out of a pile by the wear pattern), she presses and creases and rotates the paper into an elaborate pattern that could, in theory, go on forever. The end result is a beautiful, satisfyingly symmetrical array of repeated, interlocking shapes that look especially impressive when held up to the light, bringing to mind a stained-glass window.&lt;/p&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="folded shape" class="wp-image-1126035" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/ND25-folding-04.jpg?w=680" /&gt;&lt;figcaption class="wp-element-caption"&gt;Scroll down to learn how to fold this Dancing Ribbons tessellation created by Yoder.&lt;/figcaption&gt;&lt;/figure&gt;  &lt;p&gt;Scholars debate whether the ancient tradition of origami began in Japan or China, but the art really took off globally in the 1950s and ’60s when publishers printed and mass-marketed diagrams showing people how to fold paper into figurative objects such as birds, fish, and animals. Paper tessellations have roots in Germany in the 1920s, when the artist Josef Albers added folding to his introductory design course at the Bauhaus. This geometric tradition started gaining popularity in the 1980s and 1990s, and now, Yoder says, there are perhaps tens of thousands of people who participate. The broader universe of origami practitioners likely numbers in the millions.&lt;/p&gt;  &lt;p&gt;These aficionados attend conferences, watch YouTube videos, and take online courses, most of them to learn existing patterns. Yoder creates her own: In addition to the peer-­reviewed academic papers she’s authored on the mathematical underpinnings of her tessellations (with titles like “Symmetry Requirements and Design Equations for Origami Tessellations” and “Hybrid Hexagon Twist Interface”) and regular presentations at origami conferences across the globe, she’s designed 696 original patterns. Each year in an event she calls Advent of Tess, she teaches thousands of online participants a new design every day of December leading up to Christmas, and her website, Gathering Folds, has become a go-to source, not just for Yoder’s artwork but for instruction.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Her EAPS degree from MIT may not seem like a foundation for a career as an artist, but Yoder, who studied geology with a secondary focus on ecology, says there are connections between the fields. “There is a lot of carryover between the crystal structures and the tessellation symmetries,” she explains. “Every repeating 2D pattern obeys one of the planar symmetry groups … There are things that repeat like a hexagon, things that repeat like a square, things that repeat like a triangle, and things that repeat like a parallelogram or rectangle. And then there are things that are not rotationally symmetric. Those ideas of how things connect and how things repeat definitely carry over from my crystallography class.”&lt;/p&gt;  &lt;p&gt;Yoder cites the origami artist and physicist Robert Lang as one of the current practitioners who influenced her the most. He, like Yoder, has a math and science background but forged a career in art.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;“The thing that has set her above the current crowd is that she’s really systematically explored the building blocks of tessellations and the different little patterns that can be considered building blocks, and the rules for connecting these blocks,” he explains. “Madonna’s knowledge and understanding of mathematics and geometry gives her a broader tool kit to create art, and that’s led to her success as an artist. You can’t separate the art from the science background. It’s part of the thinking process, even if the end goal is very much in the fine art world.”&lt;/p&gt;  &lt;p&gt;For Yoder, the process, both computational and tactile, is also an end in itself. It is almost a meditation—a way to slow down and contemplate. Some of her students have even suggested there might be a spiritual component to it. One said to her: “You know, the name for that connection to infinite things is called God, right?”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;“So I kind of leave that more open,” she says. “I’m not super decided about what these things mean. I’m just happy to have that spark when I’m designing a pattern: Here’s how the shapes hang together, and now that I’ve drawn out those shapes, I can copy and paste, paste, paste, paste, paste, and it just clicks in very satisfyingly.”&lt;/p&gt;  &lt;p&gt;Yoder has considered whether she will ever get bored pursuing the possibilities of infinite patterns—whether she will achieve perfection and decide to put the bone folder away for good.&lt;/p&gt;  &lt;p&gt;“But I’m not convinced that I will,” she says. “There are always ways to make it harder and harder.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="imageSet__wrap"&gt;&lt;div class="columns__wrapper--07c4096a3b25e22dc82ee78b6368d947"&gt;&lt;div class="wp-block-columns"&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="diagram of origami pattern" class="wp-image-1126213" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/creasepattern.jpg?w=2000" width="2000" /&gt;&lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="example of folded pattern" class="wp-image-1126212" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/AOT22_Day10-2.jpg?w=744" /&gt;&lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Fold it yourself&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Try your hand at folding Madonna Yoder’s Dancing Ribbons tessellation design featuring three closed twists: hexagon, triangle, and rhombus.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Basic instructions&lt;/strong&gt;&lt;/p&gt;  &lt;div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"&gt; &lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt; Download the pattern here and cut out the hexagon with the crease pattern. &lt;/p&gt;    &lt;p&gt;&lt;strong&gt;2.&lt;/strong&gt; Fold all the background grid lines, making sure to fold them back and forth so the paper is ready to form the pattern. (You can precrease all the off-grid folds too, but Yoder recommends folding one twist at a time.) This pattern shows mountain folds with solid red lines and valley folds with dashed blue lines. The faded lines inside the twists are helper folds used to set up the twists; they will not be used in the final pattern.&lt;/p&gt;    &lt;p&gt;&lt;strong&gt;3. &lt;/strong&gt;Working from the side without the pattern, fold the central hexagon.&lt;/p&gt;    &lt;p&gt;&lt;strong&gt;4. &lt;/strong&gt;Fold the triangles.&lt;/p&gt;    &lt;p&gt;&lt;strong&gt;5. &lt;/strong&gt;Fold the rhombuses.&lt;/p&gt; &lt;/div&gt;  &lt;p&gt;Find more detailed instructions and a video tutorial&lt;em&gt;—&lt;/em&gt;as well as paper advice&lt;em&gt;—&lt;/em&gt;at technologyreview.com/tessellation.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;You can also sign up for Yoder’s annual Advent of Tess&lt;em&gt;—&lt;/em&gt;a 25-day folding challenge that begins December 1&lt;em&gt;—&lt;/em&gt;at&amp;nbsp; https://training.gatheringfolds.com/advent.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/21/1124723/infinite-folds/</guid><pubDate>Tue, 21 Oct 2025 21:00:00 +0000</pubDate></item><item><title>Engineering better care (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/21/1124712/engineering-better-care/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Every Monday, more than a hundred members of Giovanni Traverso’s Laboratory for Translational Engineering (L4TE) fill a large classroom at Brigham and Women’s Hospital for their weekly lab meeting. With a social hour, food for everyone, and updates across disciplines from mechanical engineering to veterinary science, it’s a place where a stem cell biologist might weigh in on a mechanical design, or an electrical engineer might spot a flaw in a drug delivery mechanism. And it’s a place where everyone is united by the same goal: engineering new ways to deliver medicines and monitor the body to improve patient care.&lt;/p&gt;  &lt;p&gt;Traverso’s weekly meetings bring together a mix of expertise that lab members say is unusual even in the most collaborative research spaces. But his lab—which includes its own veterinarian and a dedicated in vivo team—isn’t built like most. As an associate professor at MIT, a gastroenterologist at Brigham and Women’s, and an associate member of the Broad Institute, Traverso leads a sprawling research group that spans institutions, disciplines, and floors of lab space at MIT and beyond.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;For a lab of this size—spread across MIT, the Broad, the Brigham, the Koch Institute, and The Engine—it feels remarkably personal. Traverso, who holds the Karl Van Tassel (1925) Career Development Professorship, is known for greeting every member by name and scheduling one-on-one meetings every two or three weeks, creating a sense of trust and connection that permeates the lab.&lt;/p&gt;  &lt;p&gt;That trust is essential for a team built on radical interdisciplinarity. L4TE brings together mechanical and electrical engineers, biologists, physicians, and veterinarians in a uniquely structured lab with specialized “cores” such as fabrication, bioanalytics, and in vivo teams. The setup means a researcher can move seamlessly from developing a biological formulation to collaborating with engineers to figure out the best way to deliver it—without leaving the lab’s ecosystem. It’s a culture where everyone’s expertise is valued, people pitch in across disciplines, and projects aim squarely at the lab’s central goal: creating medical technologies that not only work in theory but survive the long, unpredictable journey to the patient.&lt;/p&gt; 
 &lt;p&gt;“At the core of what we do is really thinking about the patient, the person, and how we can help make their life better,” Traverso says.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Helping patients ASAP&lt;/h3&gt;  &lt;p&gt;Traverso’s team has developed a suite of novel technologies: a star-shaped capsule that unfolds in the stomach and delivers drugs for days or weeks; a vibrating pill that mimics the feeling of fullness; the technology behind a once-a-week antipsychotic tablet that has completed phase III clinical trials. (See “Designing devices for real-world care,” below.) Traverso has cofounded 11 startups to carry such innovations out of the lab and into the world, each tailored to the technology and patient population it serves.&lt;/p&gt; 
 &lt;p&gt;But the products are only part of the story. What distinguishes Traverso’s approach is the way those products are conceived and built. In many research groups, initial discoveries are developed into early prototypes and then passed on to other teams—sometimes in industry, sometimes in clinical settings—for more advanced testing and eventual commercialization. Traverso’s lab typically links those steps into one continuous system, blending invention, prototyping, testing, iteration, and clinical feedback as the work of a single interdisciplinary team. Engineers sit shoulder to shoulder with physicians, materials scientists with microbiologists. On any given day, a researcher might start the morning discussing an animal study with a veterinarian, spend the afternoon refining a mechanical design, and close the day in a meeting with a regulatory expert. The setup collapses months of back-and-forth between separate teams into the collaborative environment of L4TE.&lt;/p&gt;  &lt;p&gt;“This is a lab where if you want to learn something, you can learn everything if you want,” says Troy Ziliang Kang, one of the research scientists.&amp;nbsp;&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;In a field where translating scientific ideas into practical applications can take years (or stall indefinitely), Traverso has built a culture designed to shorten that path.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;The range of problems the lab tackles reflects its interdisciplinary openness. One recent project aimed to replace invasive contraceptive devices such as vaginal rings with a biodegradable injectable that begins as a liquid, solidifies inside the body, and dissolves safely over time.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Another project addresses the challenge of delivering drugs directly to the gut, bypassing the mucus barrier that blocks many treatments. For Kang, whose grandfather died of gastric cancer, the work is personal. He’s developing devices that combine traditional drugs with&amp;nbsp;electroceuticals—therapies that use electrical stimulation to influence cells or tissues.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;“What I’m trying to do is find a mechanical approach, trying to see if we can really, through physical and mechanical approaches, break through those barriers and to deliver the electroceuticals and drugs to the gut,” he says.&lt;/p&gt;  &lt;p&gt;In a field where the process of translating scientific ideas into practical applications can take years (or stall indefinitely), Traverso, 49, has built a culture designed to shorten that path. Researchers focus on designing devices with the clinical relevance to help people in the near term.&amp;nbsp; And they don’t wait for outsiders to take an idea forward. They often initiate collaborations with entrepreneurs, investors, and partners to create startups or push projects directly into early trials—or even just do it themselves. The projects in the L4TE Lab are ambitious, but the aim is simple: Solve problems that matter and build the tools to make those solutions real.&lt;/p&gt;  &lt;p&gt;Nabil Shalabi, an instructor in medicine at Harvard/BWH, an associate scientist at the Broad Institute, and a research affiliate in Traverso’s lab, sums up the attitude succinctly: “I would say this lab is really about one thing, and it’s about helping people.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;The physician-inventor&lt;/h3&gt;  &lt;p&gt;Traverso’s path into medicine and engineering began far from the hospitals and labs where he works today. Born in Cambridge, England, he moved with his family to Peru when he was still young. His father had grown up there in a family with Italian roots; his mother came from Nicaragua. He spent most of his childhood in Lima before political turmoil in Peru led his family to relocate to Toronto when he was 14.&lt;/p&gt; 

 &lt;p&gt;In high school, after finishing most of his course requirements early, he followed the advice of a chemistry teacher and joined a co-op program that would give him a glimpse of some career options. That decision brought him to a genetics lab at the Toronto Hospital for Sick Children, where he spent his afternoons helping map chromosome 7 and learning molecular techniques like PCR.&lt;/p&gt;  &lt;p&gt;“In high school, and even before that, I always enjoyed science,” Traverso says.&lt;/p&gt;  &lt;p&gt;After class, he’d ride the subway downtown and step into a world of hands-on science, working alongside graduate students in the early days of genomics.&lt;/p&gt;  &lt;p&gt;“I really fell in love with the day-to-day, the process, and how one goes about asking a question and then trying to answer that question experimentally,” he says.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;By the time he finished high school, he had already begun to see how science and medicine could intersect. He began an undergraduate medical program at Cambridge University, but during his second year, he reached out to the cancer biologist Bert Vogelstein and joined his lab at Johns Hopkins for the summer. The work resonated. By the end of the internship, Vogelstein asked if he’d consider staying to pursue a PhD. Traverso agreed, pausing his medical training after earning an undergraduate degree in medical sciences and genetics, and moved to Baltimore to begin a doctorate in molecular biology.&lt;/p&gt;  &lt;p&gt;As a PhD student, he focused on the early detection of colon cancer, developing a method to identify mutations in stool samples—a concept later licensed by Exact Sciences and used in what is now known as the Cologuard test. After completing his PhD (and earning a spot on &lt;em&gt;Technology Review’s&lt;/em&gt; 2003 TR35 list of promising young innovators for that work), he returned to Cambridge to finish medical school and spent the next three years in the UK, including a year as a house officer (the equivalent of a clinical intern in the US).&lt;/p&gt;  &lt;p&gt;Traverso chose to pursue clinical training alongside research because he believed each would make the other stronger. “I felt that having the knowledge would help inform future research development,” he says.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="inset image of a hand holding a capsule; main image the hand is holding a star shaped object" class="wp-image-1126054" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/1748_GiovanniTraverso5266_final.jpg?w=1720" width="1720" /&gt;&lt;figcaption class="wp-element-caption"&gt;An ingestible drug-releasing capsule about the size of a multivitamin expands into a star shape once inside the patient’s stomach.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;JARED LEEDS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;So in 2007, as Traverso began a residency in internal medicine at Brigham and Women’s, he also approached MIT, where he reached out to Institute Professor Robert Langer, ScD ’74. Though Traverso didn’t have a background in Langer’s field of chemical engineering, he saw the value of pairing clinical insight with the materials science research happening in the professor’s lab, which develops polymers, nanoparticles, and other novel materials to tackle biomedical challenges such as delivering drugs precisely to diseased tissue or providing long-term treatment through implanted devices. Langer welcomed him into the group as a postdoctoral fellow.&lt;/p&gt; 
 &lt;p&gt;In Langer’s lab, he found a place where clinical problems sparked engineering solutions, and where those solutions were designed with the patient in mind from the outset. Many of Traverso’s ideas came directly from his work in the hospital: Could medications be delivered in ways that make it easier for patients to take them consistently? Could a drug be redesigned so it wouldn’t require refrigeration in a rural clinic? And caring for a patient who’d swallowed shards of glass that ultimately passed without injury led Traverso to recognize the GI tract’s tolerance for sharp objects, inspiring his work on the microneedle pill.&lt;/p&gt;  &lt;p&gt;“A lot of what we do and think about is: How do we make it easier for people to receive therapy for conditions that they may be suffering from?” Traverso says. How can they “really maximize health, whether it be by nutrient enhancement or by helping women have control over their fertility?”&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;If the lab sometimes runs like a startup incubator, its founder still thinks like a physician.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Scaling up to help more people&lt;/h3&gt;  &lt;p&gt;Traverso has cofounded multiple companies to help commercialize his group’s inventions. Some target global health challenges, like developing more sustainable personal protective equipment (PPE) for health-care workers. Others take on chronic conditions that require constant dosing—HIV, schizophrenia, diabetes—by developing long-­acting oral or injectable therapies.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;From the outset, materials, dimensions, and mechanisms are chosen for more than just performance in the lab. The researchers also consider the realities of regulation, manufacturing constraints, and safe use in patients.&lt;/p&gt;  &lt;p&gt;“We definitely want to be designing these devices to be made of safe materials or [at a] safe size,” says James McRae, SM ’22, PhD ’25. “We think about these regulatory constraints that could come up in a company setting pretty early in our research process.” As part of his PhD work with Traverso, McRae created a “swallow-­and-forget” health-tracking capsule that can stay in the stomach for months—and it doesn’t require surgery to install, as an implant would. The capsule measures tiny shifts in stomach temperature that happen whenever a person eats or drinks, providing a continuous record of eating patterns that’s far more reliable than what external devices or self-reporting can capture. The technology could offer new insight into how drugs such as Ozempic and other GLP-1 therapies change behavior—something that has been notoriously hard to monitor. From “day one,” McRae made sure to involve external companies and regulatory consultants for future human testing.&lt;/p&gt;  &lt;p&gt;Traverso describes the lab’s work as a “continuum,” likening research projects to children who are born, nurtured, and eventually sent into the world to thrive and help people.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1126056" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/MIT_Underwater-Adhesives-02-press.jpg?w=1403" /&gt;&lt;figcaption class="wp-element-caption"&gt;Traverso and his team developed a device that can adhere to soft, wet surfaces. The design was inspired by studies of a sucker fish that attaches to sharks and other marine animals.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF THE RESEARCHERS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;For lab employee Matt Murphy, a mechanical engineer who manages one of the main mechanical fabrication spaces, that approach is part of the draw. Having worked with researchers on projects spanning multiple disciplines—mechanical engineering, electronics, materials science, biology—he’s now preparing to spin out a company with one of Traverso’s postdocs.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;“I feel like I got the PhD experience just working here for four years and being involved in health projects,” he says. “This has been an amazing opportunity to really see the first stages of company formation and how the early research really drives the commercialization of new technology.”&lt;/p&gt;  &lt;p&gt;The lab’s specialized “cores” ensure that projects have consistent support and can draw on plenty of expertise, regardless of how many students or postdocs come and go. If a challenge arises in an area in which a lab member has limited knowledge, chances are someone else in the lab has that background and will gladly help. “The culture is so collaborative that everybody wants to teach everybody,” says Murphy.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Creating opportunities&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;In Traverso’s lab, members are empowered to pursue technically demanding research because the culture he created encourages them to stretch into new disciplines, take ownership of projects, and imagine where their work might go next. For some, that means cofounding a company. For others, it means leaving with the skills and network to shape their next big idea.&lt;/p&gt;  &lt;p&gt;“He gives you both the agency and the support,” says Isaac Tucker, an L4TE postdoc based at the Broad Institute. “Gio trusts the leads in his lab to just execute on tasks.” McRae adds that Traverso is adept at identifying “pain points” in research and providing the necessary resources to remove barriers, which helps projects advance efficiently.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;A project led by Kimberley Biggs, another L4TE postdoc, captures how the lab approaches high-stakes problems. Funded by the Gates Foundation, Biggs is developing a way to stabilize therapeutic bacteria used for neonatal and women’s health treatments so they remain effective without refrigeration—critical for patients in areas without reliable temperature-controlled supply chains. A biochemist by training, she had never worked on devices before joining the lab, but she collaborated closely with the mechanical fabrication team to embed her bacterial therapy for conditions such as bacterial vaginosis and recurrent urinary tract infections into an intravaginal ring that can release it over time. She says Traverso gave her “an incredible amount of trust” to lead the project from the start but continued to touch base often, making sure there were “no significant bottlenecks” and that she was meeting all the goals she wanted to meet to progress in her career.&lt;/p&gt;  &lt;p&gt;Traverso encourages collaboration by putting together project teams that combine engineers, physicians, and scientists from other fields—a strategy he says can be transformative.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“If you only have one expert, they are constrained to what they know,” he explains. But “when you bring an electrical engineer together with a biologist or physician, the way that they’ll be able to see the problem or the challenge is very different.” As a result, “you see things that perhaps you hadn’t even considered were possible,” he says. Moving a project from a concept to a successful clinical trial “takes a village,” he adds. It’s a “complex, multi-step, multi-person, multi-year” process involving “tens if not hundreds of millions of dollars’ worth of effort.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Good ideas deserve to be tested&lt;/h3&gt;  &lt;p&gt;The portion of Traverso’s lab housed at the “tough tech” incubator The Engine—and the only academic group working there—occupies a 30-bench private lab alongside shared fabrication spaces, heavy machinery, and communal rooms of specialized lab equipment. The combination of dedicated and shared resources has helped reduce some initial equipment expenses for new projects, while the startup-dense environment puts potential collaborators, venture capital, and commercialization pathways within easy reach. Biggs’s work on bacterial treatments is one of the lab’s projects at The Engine. Others include work to develop electronics for capsule-based devices and an applicator for microneedle patches.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Traverso’s philosophy is to “fail well and fail fast and move on.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;The end of one table houses “blue sky” research on a topic of long-standing interest to Traverso: pasta. Led by PhD student Jack Chen, the multi-pronged project includes using generative AI to help design new pasta shapes with superior sauce adhesion. Chen and collaborators ranging from executive chefs to experts in fluid dynamics apply the same analytical rigor to this research that they bring to medical devices. It’s playful work, but it’s also a microcosm of the lab’s culture: interdisciplinary to its core, unafraid to cross boundaries, and grounded in Traverso’s belief that good ideas deserve to be tested—even if they fail.&lt;/p&gt;  &lt;p&gt;“I’d say the majority of things that I’ve ever been involved in failed,” he says. “But I think it depends on how you define failure.” He says that most of the projects he worked on for the first year and a half of his own PhD either just “kind of worked” or didn’t work at all—causing him to step back and take a different approach that ultimately led him to develop the highly effective technique now used in the Cologuard test. “Even if a hypothesis that we had didn’t work out, or didn’t work out as we thought it might, the process itself, I think, is valuable,” he says. So his philosophy is to “fail well and fail fast and move on.”&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="hand holding a spherical metal object" class="wp-image-1126053" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/1748_GiovanniTraverso5264_final2.jpg?w=1764" width="1764" /&gt;&lt;figcaption class="wp-element-caption"&gt;A tiny capsule that delivers a burst of medication directly into the GI tract offers an alternative to injections.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;JARED LEEDS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;In practice, that means encouraging students and postdocs to take on big, uncertain problems, knowing a dead end isn’t the end of their careers—just an opportunity to learn how to navigate the next challenge better.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;p&gt;McRae remembers when a major program—two or three years in the making—abruptly changed course after its sponsor shifted priorities. The team had been preparing a device for safety testing in humans; suddenly, the focus on that goal was gone. Rather than shelving the work, Traverso urged the group to use it as an opportunity to “be a little more creative again” and explore new directions, McRae says. That pivot sparked his work on an autonomous drug delivery system, opening lines of research the team hadn’t pursued before. In this system, patients swallow two capsules that interact in the stomach. When a sensor capsule detects an abnormal signal, it directs a second capsule to release a drug.&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;“He will often say, ‘I have a focus on not wasting time. Time is something that you can’t buy back. Time is something that you can’t save and bank for later.’”&lt;/strong&gt;&lt;/p&gt; &lt;cite&gt;Kimberley Biggs&lt;/cite&gt;&lt;/blockquote&gt;  &lt;p&gt;“When things aren’t working, just make &lt;em&gt;sure&lt;/em&gt; they didn’t work and you’re confident &lt;em&gt;why&lt;/em&gt; they didn’t work,” Traverso says he tells his students. “Is it the biology? Is it the materials science? Is it the mechanics that aren’t just aligning for whatever reason?” He models that diagnostic mindset—and the importance of preserving momentum.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“He will often say, ‘I have a focus on not wasting time. Time is something that you can’t buy back. Time is something that you can’t save and bank for later,’” says Biggs. “And so whenever you do encounter some sort of bottleneck, he is so supportive in trying to fix that.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Traverso’s teaching reflects the same interplay between invention, risk, and real-world impact. In Translational Engineering, one of his graduate-level courses at MIT, he invites experts from the FDA, hospitals, and startups to speak about the realities of bringing medical technology to the world.&lt;/p&gt;  &lt;p&gt;“He shared his network with us,” says Murphy, who took the course while working in the lab. “Now that I’m trying to spin out a company, I can reach out to these people.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Although he now spends most of his time on research and teaching, Traverso maintains an inpatient practice at the Brigham, participating in the consult service—a team of gastroenterology fellows and medical students supervising patient care—for several weeks a year. Staying connected to patients keeps the problems concrete and helps guide decisions on which puzzles to tackle in the lab.&lt;/p&gt;  &lt;p&gt;“I think there are certain puzzles in front of us, and I do gravitate to areas that have a solution that will help people in the near term,” he says.&lt;/p&gt;  &lt;p&gt;For Traverso, the measure of success is not the complexity of the engineering but the efficacy of the result. The goal is always a therapy that works for the people who need it, wherever they are.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Every Monday, more than a hundred members of Giovanni Traverso’s Laboratory for Translational Engineering (L4TE) fill a large classroom at Brigham and Women’s Hospital for their weekly lab meeting. With a social hour, food for everyone, and updates across disciplines from mechanical engineering to veterinary science, it’s a place where a stem cell biologist might weigh in on a mechanical design, or an electrical engineer might spot a flaw in a drug delivery mechanism. And it’s a place where everyone is united by the same goal: engineering new ways to deliver medicines and monitor the body to improve patient care.&lt;/p&gt;  &lt;p&gt;Traverso’s weekly meetings bring together a mix of expertise that lab members say is unusual even in the most collaborative research spaces. But his lab—which includes its own veterinarian and a dedicated in vivo team—isn’t built like most. As an associate professor at MIT, a gastroenterologist at Brigham and Women’s, and an associate member of the Broad Institute, Traverso leads a sprawling research group that spans institutions, disciplines, and floors of lab space at MIT and beyond.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;For a lab of this size—spread across MIT, the Broad, the Brigham, the Koch Institute, and The Engine—it feels remarkably personal. Traverso, who holds the Karl Van Tassel (1925) Career Development Professorship, is known for greeting every member by name and scheduling one-on-one meetings every two or three weeks, creating a sense of trust and connection that permeates the lab.&lt;/p&gt;  &lt;p&gt;That trust is essential for a team built on radical interdisciplinarity. L4TE brings together mechanical and electrical engineers, biologists, physicians, and veterinarians in a uniquely structured lab with specialized “cores” such as fabrication, bioanalytics, and in vivo teams. The setup means a researcher can move seamlessly from developing a biological formulation to collaborating with engineers to figure out the best way to deliver it—without leaving the lab’s ecosystem. It’s a culture where everyone’s expertise is valued, people pitch in across disciplines, and projects aim squarely at the lab’s central goal: creating medical technologies that not only work in theory but survive the long, unpredictable journey to the patient.&lt;/p&gt; 
 &lt;p&gt;“At the core of what we do is really thinking about the patient, the person, and how we can help make their life better,” Traverso says.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Helping patients ASAP&lt;/h3&gt;  &lt;p&gt;Traverso’s team has developed a suite of novel technologies: a star-shaped capsule that unfolds in the stomach and delivers drugs for days or weeks; a vibrating pill that mimics the feeling of fullness; the technology behind a once-a-week antipsychotic tablet that has completed phase III clinical trials. (See “Designing devices for real-world care,” below.) Traverso has cofounded 11 startups to carry such innovations out of the lab and into the world, each tailored to the technology and patient population it serves.&lt;/p&gt; 
 &lt;p&gt;But the products are only part of the story. What distinguishes Traverso’s approach is the way those products are conceived and built. In many research groups, initial discoveries are developed into early prototypes and then passed on to other teams—sometimes in industry, sometimes in clinical settings—for more advanced testing and eventual commercialization. Traverso’s lab typically links those steps into one continuous system, blending invention, prototyping, testing, iteration, and clinical feedback as the work of a single interdisciplinary team. Engineers sit shoulder to shoulder with physicians, materials scientists with microbiologists. On any given day, a researcher might start the morning discussing an animal study with a veterinarian, spend the afternoon refining a mechanical design, and close the day in a meeting with a regulatory expert. The setup collapses months of back-and-forth between separate teams into the collaborative environment of L4TE.&lt;/p&gt;  &lt;p&gt;“This is a lab where if you want to learn something, you can learn everything if you want,” says Troy Ziliang Kang, one of the research scientists.&amp;nbsp;&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;In a field where translating scientific ideas into practical applications can take years (or stall indefinitely), Traverso has built a culture designed to shorten that path.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;The range of problems the lab tackles reflects its interdisciplinary openness. One recent project aimed to replace invasive contraceptive devices such as vaginal rings with a biodegradable injectable that begins as a liquid, solidifies inside the body, and dissolves safely over time.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Another project addresses the challenge of delivering drugs directly to the gut, bypassing the mucus barrier that blocks many treatments. For Kang, whose grandfather died of gastric cancer, the work is personal. He’s developing devices that combine traditional drugs with&amp;nbsp;electroceuticals—therapies that use electrical stimulation to influence cells or tissues.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;“What I’m trying to do is find a mechanical approach, trying to see if we can really, through physical and mechanical approaches, break through those barriers and to deliver the electroceuticals and drugs to the gut,” he says.&lt;/p&gt;  &lt;p&gt;In a field where the process of translating scientific ideas into practical applications can take years (or stall indefinitely), Traverso, 49, has built a culture designed to shorten that path. Researchers focus on designing devices with the clinical relevance to help people in the near term.&amp;nbsp; And they don’t wait for outsiders to take an idea forward. They often initiate collaborations with entrepreneurs, investors, and partners to create startups or push projects directly into early trials—or even just do it themselves. The projects in the L4TE Lab are ambitious, but the aim is simple: Solve problems that matter and build the tools to make those solutions real.&lt;/p&gt;  &lt;p&gt;Nabil Shalabi, an instructor in medicine at Harvard/BWH, an associate scientist at the Broad Institute, and a research affiliate in Traverso’s lab, sums up the attitude succinctly: “I would say this lab is really about one thing, and it’s about helping people.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;The physician-inventor&lt;/h3&gt;  &lt;p&gt;Traverso’s path into medicine and engineering began far from the hospitals and labs where he works today. Born in Cambridge, England, he moved with his family to Peru when he was still young. His father had grown up there in a family with Italian roots; his mother came from Nicaragua. He spent most of his childhood in Lima before political turmoil in Peru led his family to relocate to Toronto when he was 14.&lt;/p&gt; 

 &lt;p&gt;In high school, after finishing most of his course requirements early, he followed the advice of a chemistry teacher and joined a co-op program that would give him a glimpse of some career options. That decision brought him to a genetics lab at the Toronto Hospital for Sick Children, where he spent his afternoons helping map chromosome 7 and learning molecular techniques like PCR.&lt;/p&gt;  &lt;p&gt;“In high school, and even before that, I always enjoyed science,” Traverso says.&lt;/p&gt;  &lt;p&gt;After class, he’d ride the subway downtown and step into a world of hands-on science, working alongside graduate students in the early days of genomics.&lt;/p&gt;  &lt;p&gt;“I really fell in love with the day-to-day, the process, and how one goes about asking a question and then trying to answer that question experimentally,” he says.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;By the time he finished high school, he had already begun to see how science and medicine could intersect. He began an undergraduate medical program at Cambridge University, but during his second year, he reached out to the cancer biologist Bert Vogelstein and joined his lab at Johns Hopkins for the summer. The work resonated. By the end of the internship, Vogelstein asked if he’d consider staying to pursue a PhD. Traverso agreed, pausing his medical training after earning an undergraduate degree in medical sciences and genetics, and moved to Baltimore to begin a doctorate in molecular biology.&lt;/p&gt;  &lt;p&gt;As a PhD student, he focused on the early detection of colon cancer, developing a method to identify mutations in stool samples—a concept later licensed by Exact Sciences and used in what is now known as the Cologuard test. After completing his PhD (and earning a spot on &lt;em&gt;Technology Review’s&lt;/em&gt; 2003 TR35 list of promising young innovators for that work), he returned to Cambridge to finish medical school and spent the next three years in the UK, including a year as a house officer (the equivalent of a clinical intern in the US).&lt;/p&gt;  &lt;p&gt;Traverso chose to pursue clinical training alongside research because he believed each would make the other stronger. “I felt that having the knowledge would help inform future research development,” he says.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="inset image of a hand holding a capsule; main image the hand is holding a star shaped object" class="wp-image-1126054" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/1748_GiovanniTraverso5266_final.jpg?w=1720" width="1720" /&gt;&lt;figcaption class="wp-element-caption"&gt;An ingestible drug-releasing capsule about the size of a multivitamin expands into a star shape once inside the patient’s stomach.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;JARED LEEDS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;So in 2007, as Traverso began a residency in internal medicine at Brigham and Women’s, he also approached MIT, where he reached out to Institute Professor Robert Langer, ScD ’74. Though Traverso didn’t have a background in Langer’s field of chemical engineering, he saw the value of pairing clinical insight with the materials science research happening in the professor’s lab, which develops polymers, nanoparticles, and other novel materials to tackle biomedical challenges such as delivering drugs precisely to diseased tissue or providing long-term treatment through implanted devices. Langer welcomed him into the group as a postdoctoral fellow.&lt;/p&gt; 
 &lt;p&gt;In Langer’s lab, he found a place where clinical problems sparked engineering solutions, and where those solutions were designed with the patient in mind from the outset. Many of Traverso’s ideas came directly from his work in the hospital: Could medications be delivered in ways that make it easier for patients to take them consistently? Could a drug be redesigned so it wouldn’t require refrigeration in a rural clinic? And caring for a patient who’d swallowed shards of glass that ultimately passed without injury led Traverso to recognize the GI tract’s tolerance for sharp objects, inspiring his work on the microneedle pill.&lt;/p&gt;  &lt;p&gt;“A lot of what we do and think about is: How do we make it easier for people to receive therapy for conditions that they may be suffering from?” Traverso says. How can they “really maximize health, whether it be by nutrient enhancement or by helping women have control over their fertility?”&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;If the lab sometimes runs like a startup incubator, its founder still thinks like a physician.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Scaling up to help more people&lt;/h3&gt;  &lt;p&gt;Traverso has cofounded multiple companies to help commercialize his group’s inventions. Some target global health challenges, like developing more sustainable personal protective equipment (PPE) for health-care workers. Others take on chronic conditions that require constant dosing—HIV, schizophrenia, diabetes—by developing long-­acting oral or injectable therapies.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;From the outset, materials, dimensions, and mechanisms are chosen for more than just performance in the lab. The researchers also consider the realities of regulation, manufacturing constraints, and safe use in patients.&lt;/p&gt;  &lt;p&gt;“We definitely want to be designing these devices to be made of safe materials or [at a] safe size,” says James McRae, SM ’22, PhD ’25. “We think about these regulatory constraints that could come up in a company setting pretty early in our research process.” As part of his PhD work with Traverso, McRae created a “swallow-­and-forget” health-tracking capsule that can stay in the stomach for months—and it doesn’t require surgery to install, as an implant would. The capsule measures tiny shifts in stomach temperature that happen whenever a person eats or drinks, providing a continuous record of eating patterns that’s far more reliable than what external devices or self-reporting can capture. The technology could offer new insight into how drugs such as Ozempic and other GLP-1 therapies change behavior—something that has been notoriously hard to monitor. From “day one,” McRae made sure to involve external companies and regulatory consultants for future human testing.&lt;/p&gt;  &lt;p&gt;Traverso describes the lab’s work as a “continuum,” likening research projects to children who are born, nurtured, and eventually sent into the world to thrive and help people.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1126056" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/MIT_Underwater-Adhesives-02-press.jpg?w=1403" /&gt;&lt;figcaption class="wp-element-caption"&gt;Traverso and his team developed a device that can adhere to soft, wet surfaces. The design was inspired by studies of a sucker fish that attaches to sharks and other marine animals.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF THE RESEARCHERS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;For lab employee Matt Murphy, a mechanical engineer who manages one of the main mechanical fabrication spaces, that approach is part of the draw. Having worked with researchers on projects spanning multiple disciplines—mechanical engineering, electronics, materials science, biology—he’s now preparing to spin out a company with one of Traverso’s postdocs.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;“I feel like I got the PhD experience just working here for four years and being involved in health projects,” he says. “This has been an amazing opportunity to really see the first stages of company formation and how the early research really drives the commercialization of new technology.”&lt;/p&gt;  &lt;p&gt;The lab’s specialized “cores” ensure that projects have consistent support and can draw on plenty of expertise, regardless of how many students or postdocs come and go. If a challenge arises in an area in which a lab member has limited knowledge, chances are someone else in the lab has that background and will gladly help. “The culture is so collaborative that everybody wants to teach everybody,” says Murphy.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Creating opportunities&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;In Traverso’s lab, members are empowered to pursue technically demanding research because the culture he created encourages them to stretch into new disciplines, take ownership of projects, and imagine where their work might go next. For some, that means cofounding a company. For others, it means leaving with the skills and network to shape their next big idea.&lt;/p&gt;  &lt;p&gt;“He gives you both the agency and the support,” says Isaac Tucker, an L4TE postdoc based at the Broad Institute. “Gio trusts the leads in his lab to just execute on tasks.” McRae adds that Traverso is adept at identifying “pain points” in research and providing the necessary resources to remove barriers, which helps projects advance efficiently.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;A project led by Kimberley Biggs, another L4TE postdoc, captures how the lab approaches high-stakes problems. Funded by the Gates Foundation, Biggs is developing a way to stabilize therapeutic bacteria used for neonatal and women’s health treatments so they remain effective without refrigeration—critical for patients in areas without reliable temperature-controlled supply chains. A biochemist by training, she had never worked on devices before joining the lab, but she collaborated closely with the mechanical fabrication team to embed her bacterial therapy for conditions such as bacterial vaginosis and recurrent urinary tract infections into an intravaginal ring that can release it over time. She says Traverso gave her “an incredible amount of trust” to lead the project from the start but continued to touch base often, making sure there were “no significant bottlenecks” and that she was meeting all the goals she wanted to meet to progress in her career.&lt;/p&gt;  &lt;p&gt;Traverso encourages collaboration by putting together project teams that combine engineers, physicians, and scientists from other fields—a strategy he says can be transformative.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“If you only have one expert, they are constrained to what they know,” he explains. But “when you bring an electrical engineer together with a biologist or physician, the way that they’ll be able to see the problem or the challenge is very different.” As a result, “you see things that perhaps you hadn’t even considered were possible,” he says. Moving a project from a concept to a successful clinical trial “takes a village,” he adds. It’s a “complex, multi-step, multi-person, multi-year” process involving “tens if not hundreds of millions of dollars’ worth of effort.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Good ideas deserve to be tested&lt;/h3&gt;  &lt;p&gt;The portion of Traverso’s lab housed at the “tough tech” incubator The Engine—and the only academic group working there—occupies a 30-bench private lab alongside shared fabrication spaces, heavy machinery, and communal rooms of specialized lab equipment. The combination of dedicated and shared resources has helped reduce some initial equipment expenses for new projects, while the startup-dense environment puts potential collaborators, venture capital, and commercialization pathways within easy reach. Biggs’s work on bacterial treatments is one of the lab’s projects at The Engine. Others include work to develop electronics for capsule-based devices and an applicator for microneedle patches.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Traverso’s philosophy is to “fail well and fail fast and move on.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;The end of one table houses “blue sky” research on a topic of long-standing interest to Traverso: pasta. Led by PhD student Jack Chen, the multi-pronged project includes using generative AI to help design new pasta shapes with superior sauce adhesion. Chen and collaborators ranging from executive chefs to experts in fluid dynamics apply the same analytical rigor to this research that they bring to medical devices. It’s playful work, but it’s also a microcosm of the lab’s culture: interdisciplinary to its core, unafraid to cross boundaries, and grounded in Traverso’s belief that good ideas deserve to be tested—even if they fail.&lt;/p&gt;  &lt;p&gt;“I’d say the majority of things that I’ve ever been involved in failed,” he says. “But I think it depends on how you define failure.” He says that most of the projects he worked on for the first year and a half of his own PhD either just “kind of worked” or didn’t work at all—causing him to step back and take a different approach that ultimately led him to develop the highly effective technique now used in the Cologuard test. “Even if a hypothesis that we had didn’t work out, or didn’t work out as we thought it might, the process itself, I think, is valuable,” he says. So his philosophy is to “fail well and fail fast and move on.”&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="hand holding a spherical metal object" class="wp-image-1126053" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/1748_GiovanniTraverso5264_final2.jpg?w=1764" width="1764" /&gt;&lt;figcaption class="wp-element-caption"&gt;A tiny capsule that delivers a burst of medication directly into the GI tract offers an alternative to injections.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;JARED LEEDS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;In practice, that means encouraging students and postdocs to take on big, uncertain problems, knowing a dead end isn’t the end of their careers—just an opportunity to learn how to navigate the next challenge better.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;p&gt;McRae remembers when a major program—two or three years in the making—abruptly changed course after its sponsor shifted priorities. The team had been preparing a device for safety testing in humans; suddenly, the focus on that goal was gone. Rather than shelving the work, Traverso urged the group to use it as an opportunity to “be a little more creative again” and explore new directions, McRae says. That pivot sparked his work on an autonomous drug delivery system, opening lines of research the team hadn’t pursued before. In this system, patients swallow two capsules that interact in the stomach. When a sensor capsule detects an abnormal signal, it directs a second capsule to release a drug.&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;“He will often say, ‘I have a focus on not wasting time. Time is something that you can’t buy back. Time is something that you can’t save and bank for later.’”&lt;/strong&gt;&lt;/p&gt; &lt;cite&gt;Kimberley Biggs&lt;/cite&gt;&lt;/blockquote&gt;  &lt;p&gt;“When things aren’t working, just make &lt;em&gt;sure&lt;/em&gt; they didn’t work and you’re confident &lt;em&gt;why&lt;/em&gt; they didn’t work,” Traverso says he tells his students. “Is it the biology? Is it the materials science? Is it the mechanics that aren’t just aligning for whatever reason?” He models that diagnostic mindset—and the importance of preserving momentum.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“He will often say, ‘I have a focus on not wasting time. Time is something that you can’t buy back. Time is something that you can’t save and bank for later,’” says Biggs. “And so whenever you do encounter some sort of bottleneck, he is so supportive in trying to fix that.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Traverso’s teaching reflects the same interplay between invention, risk, and real-world impact. In Translational Engineering, one of his graduate-level courses at MIT, he invites experts from the FDA, hospitals, and startups to speak about the realities of bringing medical technology to the world.&lt;/p&gt;  &lt;p&gt;“He shared his network with us,” says Murphy, who took the course while working in the lab. “Now that I’m trying to spin out a company, I can reach out to these people.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Although he now spends most of his time on research and teaching, Traverso maintains an inpatient practice at the Brigham, participating in the consult service—a team of gastroenterology fellows and medical students supervising patient care—for several weeks a year. Staying connected to patients keeps the problems concrete and helps guide decisions on which puzzles to tackle in the lab.&lt;/p&gt;  &lt;p&gt;“I think there are certain puzzles in front of us, and I do gravitate to areas that have a solution that will help people in the near term,” he says.&lt;/p&gt;  &lt;p&gt;For Traverso, the measure of success is not the complexity of the engineering but the efficacy of the result. The goal is always a therapy that works for the people who need it, wherever they are.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/21/1124712/engineering-better-care/</guid><pubDate>Tue, 21 Oct 2025 21:00:00 +0000</pubDate></item><item><title>OpenAI’s new browser is a broadside shot at Google (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/21/openais-new-browser-is-a-broadside-shot-at-google/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/Screen-Shot-2025-10-21-at-5.13.11-PM.jpg?resize=1200,673" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Today, OpenAI launched its new Atlas web browser in a surprise livestream.&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;The show started with CEO Sam Altman, speaking directly to the audience.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We think AI represents a rare, once-a-decade opportunity to rethink what a browser can be,” Altman said. “In the same way that, for the previous way people used the internet, the URL bar and the search box were a great analogue, what we’re starting to see is that the chat experience and the web browser can be a quick analogue.”&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;It was an inspiring note, in the classic Steve Jobs mode. But even more important than Altman’s browser was the detritus he was sweeping aside to make room. It wasn’t just casting present-day browsers as old, but part of a whole package of goods that are about to be replaced by AI — as Altman put it, part of “the previous way people used the internet.” And most of those soon-to-be obsolete services trace back to a single company: Google.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s browser project has been an open secret in Silicon Valley since at least this summer — and it was clear from the beginning that it would be a potential threat to Google, current owner of the world’s most popular browser. But Tuesday’s product and presentation details made it clear exactly how much the web giant has to lose in the AI era — and how little the Google’s success with Gemini seems to have helped.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The immediate threat is simple enough: ChatGPT draws 800 million users a week, and if those users switch to Atlas, they’re most likely switching away from Chrome. Losing those users doesn’t have an immediate dollar cost for Google (it’s a free product, after all) but it limits Google’s ability to target ads to those users or nudge them to Google Search — a particular sore point because, just last month, Google was barred by the U.S. Department of Justice from making any search exclusivity deals.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Then, there’s how OpenAI deals&lt;strong&gt; &lt;/strong&gt;with search itself. AI has already strained the search model of the web, surfacing processed information instead of content that can be advertised against. But on OpenAI’s livestream, Atlas head of engineering Ben Goodger (himself a central figure in developing both Firefox and Chrome) described the new kind of chat-oriented search as a paradigm shift.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This new model of search is really powerful,” Goodger said. “It’s a multi-turn experience. You can have this back-and-forth with your search results instead of just being sent off to a web page.”&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, Google has done a lot to integrate AI into the normal search experience — but the company has mostly approached it the same way as product listings or reviews: by adding a box to the results page. But OpenAI’s kind of engaged back-and-forth is beyond anything you can get on Chrome, and given its profoundly different approach, it’s not something that can be easily copied. If OpenAI’s search interface proves popular, it could be a serious threat to Google’s dominance.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Then there’s the advertising question. OpenAI doesn’t serve advertising at the moment, but it has been careful not to rule it out. The company has also been listing a lot of adtech jobs lately, fueling speculation that an ad pivot might be on the way. With Atlas, ChatGPT can now collect context directly from a user’s browser window — providing a lot of extremely valuable data for ad targeting. It’s an unprecedented level of direct browser access: literally looking at the words on your screen as you type them. And after decades of privacy scares, it’s not the kind of sensitive information that users are likely to give to Google or Meta.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s still early days for Atlas and a lot will depend on the product itself — and whether users really want what OpenAI is offering here. But the company has plotted a surprisingly commercial path here, one focused on user and revenue growth rather than hazy ambitions around AGI. As infrastructure wonks ponder the $300 billion question of whether OpenAI’s revenues can ever live up to its enormous data center buildout, products like Atlas may be the first place to look for an answer.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/Screen-Shot-2025-10-21-at-5.13.11-PM.jpg?resize=1200,673" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Today, OpenAI launched its new Atlas web browser in a surprise livestream.&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;The show started with CEO Sam Altman, speaking directly to the audience.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We think AI represents a rare, once-a-decade opportunity to rethink what a browser can be,” Altman said. “In the same way that, for the previous way people used the internet, the URL bar and the search box were a great analogue, what we’re starting to see is that the chat experience and the web browser can be a quick analogue.”&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;It was an inspiring note, in the classic Steve Jobs mode. But even more important than Altman’s browser was the detritus he was sweeping aside to make room. It wasn’t just casting present-day browsers as old, but part of a whole package of goods that are about to be replaced by AI — as Altman put it, part of “the previous way people used the internet.” And most of those soon-to-be obsolete services trace back to a single company: Google.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s browser project has been an open secret in Silicon Valley since at least this summer — and it was clear from the beginning that it would be a potential threat to Google, current owner of the world’s most popular browser. But Tuesday’s product and presentation details made it clear exactly how much the web giant has to lose in the AI era — and how little the Google’s success with Gemini seems to have helped.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The immediate threat is simple enough: ChatGPT draws 800 million users a week, and if those users switch to Atlas, they’re most likely switching away from Chrome. Losing those users doesn’t have an immediate dollar cost for Google (it’s a free product, after all) but it limits Google’s ability to target ads to those users or nudge them to Google Search — a particular sore point because, just last month, Google was barred by the U.S. Department of Justice from making any search exclusivity deals.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Then, there’s how OpenAI deals&lt;strong&gt; &lt;/strong&gt;with search itself. AI has already strained the search model of the web, surfacing processed information instead of content that can be advertised against. But on OpenAI’s livestream, Atlas head of engineering Ben Goodger (himself a central figure in developing both Firefox and Chrome) described the new kind of chat-oriented search as a paradigm shift.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This new model of search is really powerful,” Goodger said. “It’s a multi-turn experience. You can have this back-and-forth with your search results instead of just being sent off to a web page.”&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, Google has done a lot to integrate AI into the normal search experience — but the company has mostly approached it the same way as product listings or reviews: by adding a box to the results page. But OpenAI’s kind of engaged back-and-forth is beyond anything you can get on Chrome, and given its profoundly different approach, it’s not something that can be easily copied. If OpenAI’s search interface proves popular, it could be a serious threat to Google’s dominance.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Then there’s the advertising question. OpenAI doesn’t serve advertising at the moment, but it has been careful not to rule it out. The company has also been listing a lot of adtech jobs lately, fueling speculation that an ad pivot might be on the way. With Atlas, ChatGPT can now collect context directly from a user’s browser window — providing a lot of extremely valuable data for ad targeting. It’s an unprecedented level of direct browser access: literally looking at the words on your screen as you type them. And after decades of privacy scares, it’s not the kind of sensitive information that users are likely to give to Google or Meta.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s still early days for Atlas and a lot will depend on the product itself — and whether users really want what OpenAI is offering here. But the company has plotted a surprisingly commercial path here, one focused on user and revenue growth rather than hazy ambitions around AGI. As infrastructure wonks ponder the $300 billion question of whether OpenAI’s revenues can ever live up to its enormous data center buildout, products like Atlas may be the first place to look for an answer.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/21/openais-new-browser-is-a-broadside-shot-at-google/</guid><pubDate>Tue, 21 Oct 2025 21:17:50 +0000</pubDate></item><item><title>Sesame, the conversational AI startup from Oculus founders, raises $250M and launches beta (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/21/sesame-the-conversational-ai-startup-from-oculus-founders-raises-250m-and-launches-beta/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Sesame, a conversational AI startup and smart glasses maker, has raised a $250 million Series B round and is opening up its beta to a select group of testers, the company announced Tuesday. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup, headed by former Oculus co-founder and CEO Brendan Iribe and Ankit Kumar, former CTO of AR startup Ubiquity6, is working to create a personal AI agent that interacts with users using a natural-sounding human voice. The company plans to embed the personal AI agent into lightweight eyewear that is designed to be worn throughout the day and that users can interact with via voice.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The startup first emerged from stealth in February, offering two demos of its technology — AI voices named “Maya” and “Miles.” The voices were soon accessed by more than a million people within the first few weeks, who generated more than 5 million minutes of conversation, according to a new post by Sesame investor Sequoia about its participation in the startup’s Series B.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“[T]he experience was unlike anything we’d used before. Sesame’s conversational layer felt different,” the post states. “It doesn’t just translate LLM output into audio — it generates speech directly, capturing the rhythm, emotion, and expressiveness of real dialogue.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Early reviews of the tech demo seem to agree, as one report by The Verge described Sesame as “genuinely fun” and “natural-sounding.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sesame says its upcoming glasses will offer “high-quality audio” and access to an AI companion that will “observe the world alongside you.” &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3060427" height="453" src="https://techcrunch.com/wp-content/uploads/2025/10/sesame-glasses.webp?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Sesame&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Sequoia also noted the smartglasses Sesame is building will be fashion-forward, so they look like something you’d choose to wear even if they didn’t offer built-in AI technology. A timeframe for their availability is not yet being shared — as Sequoia noted, “hardware takes time.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On that front, Sesame may have an advantage. Its founding team also includes Oculus co-founder Nate Mitchell as its chief product officer, former Oculus COO and Fitbit exec Hans Hartmann as COO, former Oculus engineer manager and Reality Labs engineering director Ryan Brown, and longtime Facebook and Meta exec Angela Gayles.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to sharing the news of its Series B, Iribe announced on X that Sesame is now opening an early beta of the Sesame iOS app. The app experience will allow testers to get hands-on with the AI technology being built, as the app will have the ability to “search, text and think,” he says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beta testers are asked to keep their testing experiences confidential for the time being, which includes not discussing features or results beyond the official beta test forums.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Investors in the Sesame Series B include Sequoia, Spark, and other undisclosed backers, according to Iribe.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Sesame, a conversational AI startup and smart glasses maker, has raised a $250 million Series B round and is opening up its beta to a select group of testers, the company announced Tuesday. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup, headed by former Oculus co-founder and CEO Brendan Iribe and Ankit Kumar, former CTO of AR startup Ubiquity6, is working to create a personal AI agent that interacts with users using a natural-sounding human voice. The company plans to embed the personal AI agent into lightweight eyewear that is designed to be worn throughout the day and that users can interact with via voice.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The startup first emerged from stealth in February, offering two demos of its technology — AI voices named “Maya” and “Miles.” The voices were soon accessed by more than a million people within the first few weeks, who generated more than 5 million minutes of conversation, according to a new post by Sesame investor Sequoia about its participation in the startup’s Series B.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“[T]he experience was unlike anything we’d used before. Sesame’s conversational layer felt different,” the post states. “It doesn’t just translate LLM output into audio — it generates speech directly, capturing the rhythm, emotion, and expressiveness of real dialogue.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Early reviews of the tech demo seem to agree, as one report by The Verge described Sesame as “genuinely fun” and “natural-sounding.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sesame says its upcoming glasses will offer “high-quality audio” and access to an AI companion that will “observe the world alongside you.” &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3060427" height="453" src="https://techcrunch.com/wp-content/uploads/2025/10/sesame-glasses.webp?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Sesame&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Sequoia also noted the smartglasses Sesame is building will be fashion-forward, so they look like something you’d choose to wear even if they didn’t offer built-in AI technology. A timeframe for their availability is not yet being shared — as Sequoia noted, “hardware takes time.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On that front, Sesame may have an advantage. Its founding team also includes Oculus co-founder Nate Mitchell as its chief product officer, former Oculus COO and Fitbit exec Hans Hartmann as COO, former Oculus engineer manager and Reality Labs engineering director Ryan Brown, and longtime Facebook and Meta exec Angela Gayles.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to sharing the news of its Series B, Iribe announced on X that Sesame is now opening an early beta of the Sesame iOS app. The app experience will allow testers to get hands-on with the AI technology being built, as the app will have the ability to “search, text and think,” he says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beta testers are asked to keep their testing experiences confidential for the time being, which includes not discussing features or results beyond the official beta test forums.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Investors in the Sesame Series B include Sequoia, Spark, and other undisclosed backers, according to Iribe.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/21/sesame-the-conversational-ai-startup-from-oculus-founders-raises-250m-and-launches-beta/</guid><pubDate>Tue, 21 Oct 2025 21:34:17 +0000</pubDate></item><item><title>Open source agentic startup LangChain hits $1.25B valuation (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/21/open-source-agentic-startup-langchain-hits-1-25b-valuation/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/08/unicorns-evergreen_720.jpg?w=720" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;LangChain raised $125 million at a $1.25 billion valuation, the company announced on Monday. TechCrunch reported in July that the provider of a popular open source framework for building AI agents was raising fresh funds at a valuation of at least $1 billion. The deal was led by IVP, as we previously reported. New investors CapitalG and Sapphire Ventures joined in, as did existing investors Sequoia, Benchmark, and Amplify.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;LangChain began in 2022 as an open source project founded by machine learning engineer Harrison Chase. The startup was an early darling of the AI era, solving problems that made building apps with early-stage LLMs difficult, such as searching the web, calling APIs, and interacting with databases. It became a smash hit project, and Chase launched a startup with a&amp;nbsp;$10 million seed round&amp;nbsp;from Benchmark in April 2023. A week later, Chase raised a $25 million Series A led by Sequoia, reportedly valuing LangChain at&amp;nbsp;$200 million.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As state-of-the-art model makers have added more infrastructure, LangChain has evolved to become a platform for building agents. In addition to announcing its unicorn status, the company launched updates to all of its major products, including its agent builder LangChain, its orchestration and context/memory tool LangGraph,&amp;nbsp;and its testing/observability tool LangSmith. LangChain remains hugely popular among open source devs, with 118,000 stars and 19.4 forks on GitHub.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/08/unicorns-evergreen_720.jpg?w=720" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;LangChain raised $125 million at a $1.25 billion valuation, the company announced on Monday. TechCrunch reported in July that the provider of a popular open source framework for building AI agents was raising fresh funds at a valuation of at least $1 billion. The deal was led by IVP, as we previously reported. New investors CapitalG and Sapphire Ventures joined in, as did existing investors Sequoia, Benchmark, and Amplify.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;LangChain began in 2022 as an open source project founded by machine learning engineer Harrison Chase. The startup was an early darling of the AI era, solving problems that made building apps with early-stage LLMs difficult, such as searching the web, calling APIs, and interacting with databases. It became a smash hit project, and Chase launched a startup with a&amp;nbsp;$10 million seed round&amp;nbsp;from Benchmark in April 2023. A week later, Chase raised a $25 million Series A led by Sequoia, reportedly valuing LangChain at&amp;nbsp;$200 million.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As state-of-the-art model makers have added more infrastructure, LangChain has evolved to become a platform for building agents. In addition to announcing its unicorn status, the company launched updates to all of its major products, including its agent builder LangChain, its orchestration and context/memory tool LangGraph,&amp;nbsp;and its testing/observability tool LangSmith. LangChain remains hugely popular among open source devs, with 118,000 stars and 19.4 forks on GitHub.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/21/open-source-agentic-startup-langchain-hits-1-25b-valuation/</guid><pubDate>Tue, 21 Oct 2025 22:12:46 +0000</pubDate></item><item><title>Netflix goes ‘all in’ on generative AI as entertainment industry remains divided (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/21/netflix-goes-all-in-on-generative-ai-as-entertainment-industry-remains-divided/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/02/GettyImages-1240099721.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As the entertainment industry reckons with when and how to use generative AI in filmmaking, Netflix is leaning in. In its quarterly earnings report released on Tuesday afternoon, Netflix wrote in its letter to investors that it is “very well positioned to effectively leverage ongoing advances in AI.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Netflix isn’t planning to use generative AI as the backbone of its content but believes the technology has potential as a tool to make creatives more efficient.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“It takes a great artist to make something great,” Netflix CEO Ted Sarandos said on Tuesday’s earnings call. “AI can give creatives better tools to enhance their overall TV/movie experience for our members, but it doesn’t automatically make you a great storyteller if you’re not.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Earlier this year, Netflix said it used generative AI in final footage for the first time in the Argentine show “The Eternaut” to create a scene of a building collapsing. Since then, the filmmakers behind “Happy Gilmore 2” used generative AI to make characters look younger in the film’s opening scene, while the producers of “Billionaires’ Bunker” used the technology as a pre-production tool to envision wardrobe and set design. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re confident that AI is going to help us and help our creative partners tell stories better, faster, and in new ways,” Sarandos said. “We’re all in on that, but we’re not chasing novelty for novelty’s sake here.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI has been a contentious topic in the entertainment industry, as artists worry that LLM-powered tools that non-consensually used their work as training data have the potential to negatively impact their jobs. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With Netflix as a bellwether, it seems that studios are more likely to use generative AI for special effects rather than to replace the role of actors — even if an AI actor recently caused an uproar among Hollywood actors, despite not yet booking any gigs (that we know of). These behind-the-scenes AI uses still have the potential to impact visual effects jobs, however.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;These debates recently escalated when ChatGPT-maker OpenAI unveiled its Sora 2 audio and video generation model, which was released without guardrails that prevent users from generating videos of some actors and historical figures. Just this week, the Hollywood trade organization SAG-AFTRA and actor Bryan Cranston urged OpenAI to institute stronger guardrails against deepfaking actors like Cranston himself.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When an investor asked Sarandos about the impact of Sora on Netflix, he said that it “starts to make sense” that content creators could be impacted, but he’s less worried about the movie and TV business — or so he tells investors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re not worried about AI replacing creativity,” he said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Netflix’s quarterly revenue grew 17% year-over-year to $11.5 billion, though this fell below the company’s forecast.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/02/GettyImages-1240099721.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As the entertainment industry reckons with when and how to use generative AI in filmmaking, Netflix is leaning in. In its quarterly earnings report released on Tuesday afternoon, Netflix wrote in its letter to investors that it is “very well positioned to effectively leverage ongoing advances in AI.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Netflix isn’t planning to use generative AI as the backbone of its content but believes the technology has potential as a tool to make creatives more efficient.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“It takes a great artist to make something great,” Netflix CEO Ted Sarandos said on Tuesday’s earnings call. “AI can give creatives better tools to enhance their overall TV/movie experience for our members, but it doesn’t automatically make you a great storyteller if you’re not.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Earlier this year, Netflix said it used generative AI in final footage for the first time in the Argentine show “The Eternaut” to create a scene of a building collapsing. Since then, the filmmakers behind “Happy Gilmore 2” used generative AI to make characters look younger in the film’s opening scene, while the producers of “Billionaires’ Bunker” used the technology as a pre-production tool to envision wardrobe and set design. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re confident that AI is going to help us and help our creative partners tell stories better, faster, and in new ways,” Sarandos said. “We’re all in on that, but we’re not chasing novelty for novelty’s sake here.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI has been a contentious topic in the entertainment industry, as artists worry that LLM-powered tools that non-consensually used their work as training data have the potential to negatively impact their jobs. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With Netflix as a bellwether, it seems that studios are more likely to use generative AI for special effects rather than to replace the role of actors — even if an AI actor recently caused an uproar among Hollywood actors, despite not yet booking any gigs (that we know of). These behind-the-scenes AI uses still have the potential to impact visual effects jobs, however.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;These debates recently escalated when ChatGPT-maker OpenAI unveiled its Sora 2 audio and video generation model, which was released without guardrails that prevent users from generating videos of some actors and historical figures. Just this week, the Hollywood trade organization SAG-AFTRA and actor Bryan Cranston urged OpenAI to institute stronger guardrails against deepfaking actors like Cranston himself.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When an investor asked Sarandos about the impact of Sora on Netflix, he said that it “starts to make sense” that content creators could be impacted, but he’s less worried about the movie and TV business — or so he tells investors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re not worried about AI replacing creativity,” he said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Netflix’s quarterly revenue grew 17% year-over-year to $11.5 billion, though this fell below the company’s forecast.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/21/netflix-goes-all-in-on-generative-ai-as-entertainment-industry-remains-divided/</guid><pubDate>Tue, 21 Oct 2025 22:21:46 +0000</pubDate></item></channel></rss>