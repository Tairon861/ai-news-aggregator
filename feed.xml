<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 08 Jan 2026 01:55:56 +0000</lastBuildDate><item><title>Deploying a hybrid approach to Web3 in the AI era (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/01/07/1129490/deploying-a-hybrid-approach-to-web3-in-the-ai-era/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;AIOZ Network&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;When the concept of “Web 3.0” first emerged about a decade ago the idea was clear: Create a more user-controlled internet that lets you do everything you can now, except without servers or intermediaries to manage the flow of information.&lt;/p&gt;  &lt;p&gt;Where Web2, which emerged in the early 2000s, relies on centralized systems to store data and supply compute, all owned—and monetized by—a handful of global conglomerates, Web3 turns that structure on its head. Instead, data and compute are decentralized through technologies like blockchain and peer-to-peer networks.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1129492" src="https://wp.technologyreview.com/wp-content/uploads/2025/12/AIOZ-Network-3.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;What was once a futuristic concept is quickly becoming a more concrete reality, even at a time when Web2 still dominates. Six out of ten Fortune 500 companies are exploring blockchain-based solutions, most taking a hybrid approach that combines traditional Web2 business models and infrastructure with the decentralized technologies and principles of Web3.&lt;/p&gt;  &lt;p&gt;Popular use cases include cloud services, supply chain management, and, most notably financial services. In fact, at one point, the daily volume of transactions processed on decentralized finance exchanges exceeded $10 billion.&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Gaining a Web3 edge&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Among the advantages of Web3 for the enterprise are greater ownership and control of sensitive data, says Erman Tjiputra, founder and CEO of the AIOZ Network, which is building infrastructure for Web3, powered by decentralized physical infrastructure networks (DePIN), blockchain-based systems that govern physical infrastructure assets.&lt;/p&gt;  &lt;p&gt;More cost-effective compute is another benefit, as is enhanced security and privacy as the cyberattack landscape grows more hostile, he adds. And it could even help protect companies from outages caused by a single point of failure, which can lead to downtime, data loss, and revenue deficits.&lt;/p&gt; 
 &lt;p&gt;But perhaps the most exciting opportunity, says Tjiputra, is the ability to build and scale AI reliably and affordably. By leveraging a people-powered internet infrastructure, companies can far more easily access—and contribute to—shared resource like bandwidth, storage, and processing power to run AI inference, train models, and store data. All while using familiar developer tooling and open, usage-based incentives.&lt;/p&gt;  &lt;p&gt;“We’re in a compute crunch where requirements are insatiable, and Web3 creates this ability to benefit while contributing,” explains Tjiputra.&lt;/p&gt;  &lt;p&gt;In 2025, AIOZ Network launched a distributed compute platform and marketplace where developers and enterprises can access and monetize AI assets, and run AI inference or training on AIOZ Network’s more than 300,000 contributing devices. The model allows companies to move away from opaque datasets and models and scale flexibly, without centralized lock in.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Overcoming &lt;/strong&gt;&lt;strong&gt;Web3 deployment challenges&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Despite the promise, it is still early days for Web3, and core systemic challenges are leaving senior leadership and developers hesitant about its applicability at scale.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;One hurdle is a lack of interoperability. The current fragmentation of blockchain networks creates a segregated ecosystem that makes it challenging to transfer assets or data between platforms. This often complicates transactions and introduces new security risks due to the reliance on mechanisms such as cross-chain bridges. These are tools that allow asset transfers between platforms but which have been shown to be vulnerable to targeted attacks.&lt;/p&gt;  &lt;p&gt;“We have countless blockchains running on different protocols and consensus models,” says Tjiputra. “These blockchains need to work with each other so applications can communicate regardless of which chain they are on. This makes interoperability fundamental.”&lt;/p&gt;  &lt;p&gt;Regulatory uncertainty is also a challenge. Outdated legal frameworks can sit at odds with decentralized infrastructures, especially when it comes to compliance with data protection and anti-money laundering regulations.&lt;/p&gt;  &lt;p&gt;“Enterprises care about verifiability and compliance as much as innovation, so we need frameworks where on-chain transparency strengthens accountability instead of adding friction,” Tjiputra says.&lt;/p&gt; 

 &lt;p&gt;And this is compounded by user experience (UX) challenges, says Tjiputra. “The biggest setback in Web3 today is UX,” he says. “For example, in Web2, if I forget my bank username or password, I can still contact the bank, log in and access my assets. The trade-off in Web3 is that, should that key be compromised or lost, we lose access to those assets. So, key recovery is a real problem.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Building a bridge to Web3&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Although such systemic challenges won’t be solved overnight, by leveraging DePIN networks, enterprises can bridge the gap between Web2 and Web3, without making a wholesale switch. This can minimize risk while harnessing much of the potential.&lt;/p&gt;  &lt;p&gt;AIOZ Network’s own ecosystem includes capacity for media streaming, AI compute, and distributed storage that can be plugged into an existing Web2 tech stack. “You don’t need to go full Web3,” says Tjiputra. “You can start by plugging distributed storage into your workflow, test it, measure it, and see the benefits firsthand.”&lt;/p&gt;  &lt;p&gt;The AIOZ Storage solution, for example, offers scalable distributed object storage by leveraging the global network of contributor devices on AIOZ DePIN. It is also compatible with existing storage systems or commonly used web application programming interfaces (APIs).&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;“Say we have a programmer or developer who uses Amazon S3 Storage or REST APIs, then all they need to do is just repoint the endpoints,” explains Tjiputra. “That's it. It’s the same tools, it's really simple. Even with media, with a single one-stop shop, developers can do transcoding and streaming with a simple REST API.”&lt;/p&gt;  &lt;p&gt;Built on Cosmos, a network of hundreds of different blockchains that can communicate with each other, and a standardized framework enabled by Ethereum Virtual Machine (EVM), AIOZ Network has also prioritized interoperability. “Applications shouldn’t care which chain they’re on. Developers should target APIs without worrying about consensus mechanisms. That’s why we built on Cosmos and EVM—interoperability first.”&lt;/p&gt;  &lt;p&gt;This hybrid model, which allows enterprises to use both Web2 and Web3 advantages in tandem, underpins what Tjiputra sees as the longer-term ambition for the much-hyped next iteration of the internet.&lt;/p&gt;  &lt;p&gt;“Our vision is a truly peer-to-peer foundation for a people-powered internet, one that minimizes single points of failure through multi-region, multi-operator design,” says Tjiputra. “By distributing compute and storage across contributors, we gain both cost efficiency and end-to-end security by default.&lt;/p&gt; 
 &lt;p&gt;“Ideally, we want to evolve the internet toward a more people-powered model, but we’re not there yet. We’re still at the starting point and growing.”&lt;/p&gt;  &lt;p&gt;Indeed, Web3 isn’t quite snapping at the heels of the world’s Web2 giants, but its commercial advantages in an era of AI have become much harder to ignore. And with DePIN bridging the gap, enterprises and developers can step into that potential while keeping one foot on surer ground.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;To learn more from AIOZ Network, you can read the&lt;/strong&gt;&lt;strong&gt; &lt;/strong&gt;AIOZ Network Vision Paper&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was researched, designed, and written by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;AIOZ Network&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;When the concept of “Web 3.0” first emerged about a decade ago the idea was clear: Create a more user-controlled internet that lets you do everything you can now, except without servers or intermediaries to manage the flow of information.&lt;/p&gt;  &lt;p&gt;Where Web2, which emerged in the early 2000s, relies on centralized systems to store data and supply compute, all owned—and monetized by—a handful of global conglomerates, Web3 turns that structure on its head. Instead, data and compute are decentralized through technologies like blockchain and peer-to-peer networks.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1129492" src="https://wp.technologyreview.com/wp-content/uploads/2025/12/AIOZ-Network-3.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;What was once a futuristic concept is quickly becoming a more concrete reality, even at a time when Web2 still dominates. Six out of ten Fortune 500 companies are exploring blockchain-based solutions, most taking a hybrid approach that combines traditional Web2 business models and infrastructure with the decentralized technologies and principles of Web3.&lt;/p&gt;  &lt;p&gt;Popular use cases include cloud services, supply chain management, and, most notably financial services. In fact, at one point, the daily volume of transactions processed on decentralized finance exchanges exceeded $10 billion.&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Gaining a Web3 edge&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Among the advantages of Web3 for the enterprise are greater ownership and control of sensitive data, says Erman Tjiputra, founder and CEO of the AIOZ Network, which is building infrastructure for Web3, powered by decentralized physical infrastructure networks (DePIN), blockchain-based systems that govern physical infrastructure assets.&lt;/p&gt;  &lt;p&gt;More cost-effective compute is another benefit, as is enhanced security and privacy as the cyberattack landscape grows more hostile, he adds. And it could even help protect companies from outages caused by a single point of failure, which can lead to downtime, data loss, and revenue deficits.&lt;/p&gt; 
 &lt;p&gt;But perhaps the most exciting opportunity, says Tjiputra, is the ability to build and scale AI reliably and affordably. By leveraging a people-powered internet infrastructure, companies can far more easily access—and contribute to—shared resource like bandwidth, storage, and processing power to run AI inference, train models, and store data. All while using familiar developer tooling and open, usage-based incentives.&lt;/p&gt;  &lt;p&gt;“We’re in a compute crunch where requirements are insatiable, and Web3 creates this ability to benefit while contributing,” explains Tjiputra.&lt;/p&gt;  &lt;p&gt;In 2025, AIOZ Network launched a distributed compute platform and marketplace where developers and enterprises can access and monetize AI assets, and run AI inference or training on AIOZ Network’s more than 300,000 contributing devices. The model allows companies to move away from opaque datasets and models and scale flexibly, without centralized lock in.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Overcoming &lt;/strong&gt;&lt;strong&gt;Web3 deployment challenges&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Despite the promise, it is still early days for Web3, and core systemic challenges are leaving senior leadership and developers hesitant about its applicability at scale.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;One hurdle is a lack of interoperability. The current fragmentation of blockchain networks creates a segregated ecosystem that makes it challenging to transfer assets or data between platforms. This often complicates transactions and introduces new security risks due to the reliance on mechanisms such as cross-chain bridges. These are tools that allow asset transfers between platforms but which have been shown to be vulnerable to targeted attacks.&lt;/p&gt;  &lt;p&gt;“We have countless blockchains running on different protocols and consensus models,” says Tjiputra. “These blockchains need to work with each other so applications can communicate regardless of which chain they are on. This makes interoperability fundamental.”&lt;/p&gt;  &lt;p&gt;Regulatory uncertainty is also a challenge. Outdated legal frameworks can sit at odds with decentralized infrastructures, especially when it comes to compliance with data protection and anti-money laundering regulations.&lt;/p&gt;  &lt;p&gt;“Enterprises care about verifiability and compliance as much as innovation, so we need frameworks where on-chain transparency strengthens accountability instead of adding friction,” Tjiputra says.&lt;/p&gt; 

 &lt;p&gt;And this is compounded by user experience (UX) challenges, says Tjiputra. “The biggest setback in Web3 today is UX,” he says. “For example, in Web2, if I forget my bank username or password, I can still contact the bank, log in and access my assets. The trade-off in Web3 is that, should that key be compromised or lost, we lose access to those assets. So, key recovery is a real problem.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Building a bridge to Web3&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Although such systemic challenges won’t be solved overnight, by leveraging DePIN networks, enterprises can bridge the gap between Web2 and Web3, without making a wholesale switch. This can minimize risk while harnessing much of the potential.&lt;/p&gt;  &lt;p&gt;AIOZ Network’s own ecosystem includes capacity for media streaming, AI compute, and distributed storage that can be plugged into an existing Web2 tech stack. “You don’t need to go full Web3,” says Tjiputra. “You can start by plugging distributed storage into your workflow, test it, measure it, and see the benefits firsthand.”&lt;/p&gt;  &lt;p&gt;The AIOZ Storage solution, for example, offers scalable distributed object storage by leveraging the global network of contributor devices on AIOZ DePIN. It is also compatible with existing storage systems or commonly used web application programming interfaces (APIs).&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;“Say we have a programmer or developer who uses Amazon S3 Storage or REST APIs, then all they need to do is just repoint the endpoints,” explains Tjiputra. “That's it. It’s the same tools, it's really simple. Even with media, with a single one-stop shop, developers can do transcoding and streaming with a simple REST API.”&lt;/p&gt;  &lt;p&gt;Built on Cosmos, a network of hundreds of different blockchains that can communicate with each other, and a standardized framework enabled by Ethereum Virtual Machine (EVM), AIOZ Network has also prioritized interoperability. “Applications shouldn’t care which chain they’re on. Developers should target APIs without worrying about consensus mechanisms. That’s why we built on Cosmos and EVM—interoperability first.”&lt;/p&gt;  &lt;p&gt;This hybrid model, which allows enterprises to use both Web2 and Web3 advantages in tandem, underpins what Tjiputra sees as the longer-term ambition for the much-hyped next iteration of the internet.&lt;/p&gt;  &lt;p&gt;“Our vision is a truly peer-to-peer foundation for a people-powered internet, one that minimizes single points of failure through multi-region, multi-operator design,” says Tjiputra. “By distributing compute and storage across contributors, we gain both cost efficiency and end-to-end security by default.&lt;/p&gt; 
 &lt;p&gt;“Ideally, we want to evolve the internet toward a more people-powered model, but we’re not there yet. We’re still at the starting point and growing.”&lt;/p&gt;  &lt;p&gt;Indeed, Web3 isn’t quite snapping at the heels of the world’s Web2 giants, but its commercial advantages in an era of AI have become much harder to ignore. And with DePIN bridging the gap, enterprises and developers can step into that potential while keeping one foot on surer ground.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;To learn more from AIOZ Network, you can read the&lt;/strong&gt;&lt;strong&gt; &lt;/strong&gt;AIOZ Network Vision Paper&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was researched, designed, and written by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/01/07/1129490/deploying-a-hybrid-approach-to-web3-in-the-ai-era/</guid><pubDate>Wed, 07 Jan 2026 14:00:00 +0000</pubDate></item><item><title>Computer scientist Yann LeCun: “Intelligence really is about learning” (AI - Ars Technica)</title><link>https://arstechnica.com/ai/2026/01/computer-scientist-yann-lecun-intelligence-really-is-about-learning/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The AI pioneer talks about stepping down from Meta, limits of large language models.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Illustration of Yann LeCun" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/lecun-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Illustration of Yann LeCun" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/lecun-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Financial Times

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;I arrive 10 minutes ahead of schedule from an early morning Eurostar and see Yann LeCun is already waiting for me, nestled between two plastic Christmas trees in the nearly empty winter garden of Michelin-starred restaurant Pavyllon.&lt;/p&gt;
&lt;p&gt;The restaurant is next to Paris’s Grand Palais, where President Emmanuel Macron kick-started 2025 by hosting an international AI summit, a glitzy showcase packed with French exceptionalism and international tech luminaries including LeCun, who is considered one of the “godfathers” of modern AI.&lt;/p&gt;
&lt;p&gt;LeCun gets up to hug me in greeting, wearing his signature black Ray-Ban Wayfarer glasses. He looks well rested for a man who has spent nearly a week running around town plotting world domination. Or, more precisely, “total world assistance” or “intelligent amplification, if you want.” Domination “sounds scary with AI,” he acknowledges.&lt;/p&gt;
&lt;p&gt;The last time I met him was at a summer conference in Paris, where he was unveiling the latest iteration of his vision for superintelligent machines as Meta’s chief AI scientist. Now, he is preparing to leave his longtime employer, and fundraising for a new start-up that will bring that vision to life.&lt;/p&gt;
&lt;p&gt;LeCun’s schedule has been relentless since the Financial Times broke the news that he was leaving Meta. “It basically pushed us to accelerate the calendar,” he says. Macron sent him a WhatsApp message after the story came out. LeCun declines to tell me exactly what the president said, but does hint that he was pleased the new “worldwide” company will have a strong connection to France.&lt;/p&gt;
&lt;blockquote class="ars-pullquote large "&gt;&lt;div class="pullquote-content"&gt;I’m a scientist, a visionary… I’m pretty good at guessing what type of technology will work or not. But I can’t be a&amp;nbsp;CEO&lt;/div&gt;&lt;/blockquote&gt;
&lt;p&gt;LeCun will not be the company’s chief executive, but the executive chair, allowing him the same kind of freedom to do research that he had at Meta. (Since our lunch, the FT has reported that LeCun’s new venture is called Advanced Machine Intelligence Labs and will be led by Alex LeBrun, the co-founder and chief executive of French health care AI start-up Nabla.)&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“I’m a scientist, a visionary. I can inspire people to work on interesting things. I’m pretty good at guessing what type of technology will work or not. But I can’t be a CEO,” LeCun says. “I’m both too disorganized for this, and also too old!”&lt;/p&gt;
&lt;p&gt;The waitress offers us champagne to start. I opt for a glass of alcohol-free Blanc de Blancs. LeCun, a fan of wines, is curious to try it too. We clink glasses.&lt;/p&gt;
&lt;p&gt;Things have changed for me as well since we last met: I am pregnant. I make a joke that I too am growing my own superintelligence. “It is the most efficient way,” he says.&lt;/p&gt;
&lt;p&gt;LeCun would know, as he has been gestating ideas for the creation of such intelligence in machines for decades. He has also been vocal about his disdain for large language models (LLMs) and their potential to reach superhuman intelligence, which is the current obsession of Silicon Valley. He argues that LLMs are useful but fundamentally limited and constrained by language. To achieve human-level intelligence, you have to understand how our physical world works too.&lt;/p&gt;
&lt;p&gt;His solution for achieving that relies on an architecture called V-JEPA, a so-called world model. World models aim to understand the physical world by learning from videos and spatial data, rather than just language. They are also able to plan, reason, and have persistent memory. He calls this kind of intelligence Advanced Machine Intelligence, or AMI.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Born in 1960 and raised in the suburbs of Paris,&lt;/strong&gt; LeCun has been fascinated by the question of how human intelligence emerged since he was a young boy.&lt;/p&gt;
&lt;p&gt;It was the film &lt;em&gt;2001: A Space Odyssey&lt;/em&gt;, which he saw when he was 8 or 9 years old, that set him on the path he is on today. He gestures having his mind blown.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;LeCun’s father, an aeronautical engineer and “a bit of an inventor,” instilled a love of building and tinkering with things. LeCun grew up constructing model aeroplanes and playing woodwind instruments such as the recorder and the crumhorn, a “weird Renaissance instrument,” which he played in a Renaissance dance music band.&lt;/p&gt;
&lt;blockquote class="ars-pullquote large "&gt;&lt;div class="pullquote-content"&gt;I’m sure there’s a lot of people at Meta who would like me to not tell the world that LLMs basically are a dead end when it comes to&amp;nbsp;superintelligence&lt;/div&gt;&lt;/blockquote&gt;
&lt;p&gt;We’ve both chosen the four-course “Champs-Élysées” lunch set menu. As we tuck into our starters (soft-boiled eggs, tuna tartare with smoked pike roe and croutons for LeCun, and a broth of root vegetables and horseradish ravioli with Chartreuse sauce for me), he tells me how a teacher deemed him too bad at math to study it at university, so he decided to pursue engineering.&lt;/p&gt;
&lt;p&gt;The waitress comes to check on us, and LeCun orders a glass of Chassagne-Montrachet from Burgundy. “What Americans would call Chardonnay,” he says, jokingly.&lt;/p&gt;
&lt;p&gt;LeCun’s lightbulb moment came as a student at the École Supérieure d’Ingénieurs en Électrotechnique et Électronique in Paris in the 1980s, when he read a book about a debate on nature versus nurture between the linguist Noam Chomsky and Jean Piaget, a psychologist. Chomsky argued that humans have an inbuilt capacity for language, while Piaget said there is some structure but most of it is learnt.&lt;/p&gt;
&lt;p&gt;“I’m not gonna make friends saying this… ” he tells me, “but I was reading this and I thought everything that Chomsky… was saying could not possibly be true, [because] we learn everything. Intelligence really is about learning.”&lt;/p&gt;
&lt;p&gt;AI research—or neural networks, as the technology was then called, which loosely mimic how the brain functions—was practically a dead field and considered taboo by the scientific community, after early iterations of the technology failed to impress. But LeCun sought out other researchers studying neural networks and found intellectual “soulmates” in the likes of Geoffrey Hinton, then a faculty member at Carnegie Mellon.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;He later joined Hinton at the University of Toronto as a postdoc researcher. The two, along with Yoshua Bengio, went on to lay the groundwork for deep learning and modern AI, which saw them rewarded in 2018 with the Turing Award, the most prestigious prize in computer science.&lt;/p&gt;
&lt;p&gt;The waitress lays our second, gorgeous, dish in front of us and launches into an enthusiastic description of the meal in French. I nod along equally enthusiastically, understanding nothing.&lt;/p&gt;
&lt;p&gt;“Did you get that?” LeCun asks. “This is the foie gras, and this is the Comté soufflé, and the Comté is 18 months aged.” When in France, I think, and take a bite of the liver.&lt;/p&gt;
&lt;p&gt;LeCun is the brain behind important early AI technologies. In the late 1980s and 1990s, while a researcher at AT&amp;amp;T Bell Labs in New Jersey—once known as the leading industry research lab in the world—he developed convolutional neural networks, an architecture used in image recognition technology, which he built into a system that was widely used by banks to read checks.&lt;/p&gt;
&lt;p&gt;He had conceived of the research at Toronto, but was able to roll it out in the real world thanks to the seemingly unlimited coffers of cash and cutting-edge technology available at Bell Labs.&lt;/p&gt;
&lt;p&gt;LeCun recounts something his boss at the time, Larry Jackel, told him when he first joined. “He said, ‘You know, at Bell Labs? You don’t get famous by saving money.’”&lt;/p&gt;
&lt;p&gt;Our main dish arrives, a portion of cod with herbed breadcrumbs and fried capers. LeCun is in a jovial mood, and I find myself engrossed in his colorful stories about the early years of AI research.&lt;/p&gt;
&lt;p&gt;He, along with his pharmacist wife, Isabelle, and their three sons, ended up settling in New Jersey for good, although he visits Paris every five weeks or so. America was a “culture shock,” he says.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The party at Bell Labs was destined to end. A corporate shake-up meant the lab lost significant funding and was spun off to different subsidiaries. LeCun rejoined academia and started a new project at NYU aimed at researching neural networks, frequenting Greenwich Village’s jazz clubs after his lectures.&lt;/p&gt;
&lt;p&gt;By 2013, it was clear that deep learning was going to work, with image recognition applications showing impressive results. Google had just started Google Brain, and a year later would acquire British AI lab DeepMind.&lt;/p&gt;
&lt;p&gt;It was also then that Mark Zuckerberg called. He wanted to start an AI unit at Facebook, and to woo LeCun invited him over for dinner at his California home. A private chef prepared “chicken with some pretty good white wine,” LeCun recalls.&lt;/p&gt;
&lt;p&gt;LeCun agreed to join on three conditions. He wouldn’t have to quit his job at NYU. He wouldn’t move to California. And the research results of the new lab had to be made publicly available.&lt;/p&gt;
&lt;p&gt;Zuckerberg agreed, and the deal was done. LeCun was to join Facebook, one of the biggest technology companies in the world, to set up a new AI research lab focusing on fundamental research, called Facebook Artificial Intelligence Research (Fair).&lt;/p&gt;
&lt;p&gt;Facebook was a “tabula rasa with a carte blanche,” LeCun says. “Money was clearly not going to be a problem.”&lt;/p&gt;
&lt;p&gt;The waitress interrupts us to bring our dessert, bricelets. “&lt;em&gt;Magnifique&lt;/em&gt;,” LeCun says, as the dish is placed in front of him.&lt;/p&gt;
&lt;p&gt;I shift the conversation to a more tumultuous time. In early 2022, pre-ChatGPT, all the major AI labs had some version of the technology kicking around, but it was seen as largely experimental. It was a small, relatively unknown AI lab called OpenAI that kick-started today’s AI mania, when it quietly launched the technology as an easily accessible chatbot.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;blockquote class="ars-pullquote large "&gt;&lt;div class="pullquote-content"&gt;We had a lot of new ideas and really cool stuff… But they were just going for things that were safe and proved. When you do this, you fall&amp;nbsp;behind&lt;/div&gt;&lt;/blockquote&gt;
&lt;p&gt;ChatGPT caused a frantic scramble at Meta. The company’s leadership decided to put all their chips into work developing Llama, a large language model. Zuckerberg reshuffled the organization to create a generative AI unit, which was tasked with accelerating research into products. LeCun insisted the model was released openly.&lt;/p&gt;
&lt;p&gt;Llama 2, released with open weights for all users, meaning people could download and tweak it for free, was a “watershed” moment, which “changed the entire industry,” LeCun says. The model became the gold standard in powerful open LLMs, and championed an approach that was counter to the extreme concentration of power that Google and OpenAI were pushing. Meta was seen as the good guys in AI research.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Meta switched gears aggressively&lt;/strong&gt; on AI last year. Zuckerberg placed more pressure on the GenAI unit to accelerate AI development and deployment, which led to a communication breakdown, LeCun says.&lt;/p&gt;
&lt;p&gt;“We had a lot of new ideas and really cool stuff that they should implement. But they were just going for things that were essentially safe and proved,” he says. “When you do this, you fall behind.”&lt;/p&gt;
&lt;p&gt;The subsequent Llama models were duds. Llama 4, which was released in April 2025, was a flop, and the company was accused of gaming benchmarks to make it look more impressive. LeCun admits that the “results were fudged a little bit,” and the team used different models for different benchmarks to give better results.&lt;/p&gt;
&lt;p&gt;“Mark was really upset and basically lost confidence in everyone who was involved in this. And so basically sidelined the entire GenAI organization. A lot of people have left, a lot of people who haven’t yet left will leave.”&lt;/p&gt;
&lt;p&gt;Last June, Meta invested $15 billion in data-labeling start-up Scale AI and hired its 28-year-old chief executive and co-founder Alexandr Wang. Wang took the reins of the company’s new bet on AI and its research unit, called TBD Lab. The lab is tasked with developing new frontier AI models.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Meta made headlines for trying to poach elite researchers from competitors with offers of $100 million sign-on bonuses. “The future will say whether that was a good idea or not,” LeCun says, deadpan.&lt;/p&gt;
&lt;p&gt;LeCun calls Wang, who was hired to lead the organization, “young” and “inexperienced.”&lt;/p&gt;
&lt;p&gt;“He learns fast, he knows what he doesn’t know… There’s no experience with research or how you practice research, how you do it. Or what would be attractive or repulsive to a researcher.”&lt;/p&gt;
&lt;p&gt;Wang also became LeCun’s manager. I ask LeCun how he felt about this shift in hierarchy. He initially brushes it off, saying he’s used to working with young people. “The average age of a Facebook engineer at the time was 27. I was twice the age of the average engineer.”&lt;/p&gt;
&lt;p&gt;But those 27-year-olds weren’t telling him what to do, I point out.&lt;/p&gt;
&lt;p&gt;“Alex [Wang] isn’t telling me what to do either,” he says. “You don’t tell a researcher what to do. You certainly don’t tell a researcher like me what to do.”&lt;/p&gt;
&lt;p&gt;LeCun doesn’t mince his words about why he ultimately decided to leave Meta after more than a decade. Staying became politically difficult, he tells me. And while Zuckerberg likes LeCun’s world model research, the crowd who were hired for the company’s new superintelligence push are “completely LLM-pilled.”&lt;/p&gt;
&lt;blockquote class="ars-pullquote large "&gt;&lt;div class="pullquote-content"&gt;You don’t tell a researcher what to do. You certainly don’t tell a researcher like me what to&amp;nbsp;do&lt;/div&gt;&lt;/blockquote&gt;
&lt;p&gt;This clearly alienated LeCun. “I’m sure there’s a lot of people at Meta, including perhaps Alex, who would like me to not tell the world that LLMs basically are a dead end when it comes to superintelligence,” he says. “But I’m not gonna change my mind because some dude thinks I’m wrong. I’m not wrong. My integrity as a scientist cannot allow me to do this.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Another driver to leave was that his work with world models and AMI was also proving to have potential uses that were not interesting to Meta, such as jet engines and heavy industry. And LeCun had no trouble finding investors who were willing to bet on the next generation of AI technologies.&lt;/p&gt;
&lt;p&gt;In his next chapter, LeCun believes that setting up a “neolab,” meaning a start-up that does fundamental research, is the new, most fertile ground. He cites OpenAI former chief technology officer Mira Murati’s Thinking Machines (“I hope the investors know what they do”) and OpenAI’s co-founder and chief scientist Ilya Sutskever’s Safe Superintelligence (“There I know the investors have no idea what they do”) as good examples.&lt;/p&gt;
&lt;p&gt;His new architecture uses videos to give AI models an understanding of the physics of our world, which will allow them to make better predictions of what will happen next. The model also relies on “emotions,” meaning past experiences and evaluations, to guide its predictions.&lt;/p&gt;
&lt;p&gt;“If I pinch you, you’re going to feel pain. But then your mental model of me is going to be affected by the fact that I just pinched you. And the next time I approach my arm to yours, you’re going to recoil. That’s your prediction, and the emotion it evokes is fear or avoidance of pain,” he says.&lt;/p&gt;
&lt;p&gt;LeCun says we will see “baby” versions of this within 12 months, and on a larger scale within a few years. It’s not quite yet superintelligence, but a path toward it. “Maybe there is an obstacle we’re not seeing yet, but at least there is hope.”&lt;/p&gt;
&lt;p&gt;After three and a half hours, we are now the only customers left in the restaurant. I ask him what he wants his legacy to be.&lt;/p&gt;
&lt;p&gt;Increasing the amount of intelligence in the world, he replies, without batting an eyelid. “Intelligence is really the thing that we should have more of,” he says, adding that with more intelligence, there’s less human suffering, more rational decisions, and more understanding of the world and the universe.&lt;/p&gt;
&lt;p&gt;“We suffer from stupidity.”&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Melissa Heikkilä is the FT’s AI correspondent.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;© 2026 The Financial Times Ltd. All rights reserved. Not to be redistributed, copied, or modified in any way.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The AI pioneer talks about stepping down from Meta, limits of large language models.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Illustration of Yann LeCun" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/lecun-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Illustration of Yann LeCun" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/lecun-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Financial Times

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;I arrive 10 minutes ahead of schedule from an early morning Eurostar and see Yann LeCun is already waiting for me, nestled between two plastic Christmas trees in the nearly empty winter garden of Michelin-starred restaurant Pavyllon.&lt;/p&gt;
&lt;p&gt;The restaurant is next to Paris’s Grand Palais, where President Emmanuel Macron kick-started 2025 by hosting an international AI summit, a glitzy showcase packed with French exceptionalism and international tech luminaries including LeCun, who is considered one of the “godfathers” of modern AI.&lt;/p&gt;
&lt;p&gt;LeCun gets up to hug me in greeting, wearing his signature black Ray-Ban Wayfarer glasses. He looks well rested for a man who has spent nearly a week running around town plotting world domination. Or, more precisely, “total world assistance” or “intelligent amplification, if you want.” Domination “sounds scary with AI,” he acknowledges.&lt;/p&gt;
&lt;p&gt;The last time I met him was at a summer conference in Paris, where he was unveiling the latest iteration of his vision for superintelligent machines as Meta’s chief AI scientist. Now, he is preparing to leave his longtime employer, and fundraising for a new start-up that will bring that vision to life.&lt;/p&gt;
&lt;p&gt;LeCun’s schedule has been relentless since the Financial Times broke the news that he was leaving Meta. “It basically pushed us to accelerate the calendar,” he says. Macron sent him a WhatsApp message after the story came out. LeCun declines to tell me exactly what the president said, but does hint that he was pleased the new “worldwide” company will have a strong connection to France.&lt;/p&gt;
&lt;blockquote class="ars-pullquote large "&gt;&lt;div class="pullquote-content"&gt;I’m a scientist, a visionary… I’m pretty good at guessing what type of technology will work or not. But I can’t be a&amp;nbsp;CEO&lt;/div&gt;&lt;/blockquote&gt;
&lt;p&gt;LeCun will not be the company’s chief executive, but the executive chair, allowing him the same kind of freedom to do research that he had at Meta. (Since our lunch, the FT has reported that LeCun’s new venture is called Advanced Machine Intelligence Labs and will be led by Alex LeBrun, the co-founder and chief executive of French health care AI start-up Nabla.)&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“I’m a scientist, a visionary. I can inspire people to work on interesting things. I’m pretty good at guessing what type of technology will work or not. But I can’t be a CEO,” LeCun says. “I’m both too disorganized for this, and also too old!”&lt;/p&gt;
&lt;p&gt;The waitress offers us champagne to start. I opt for a glass of alcohol-free Blanc de Blancs. LeCun, a fan of wines, is curious to try it too. We clink glasses.&lt;/p&gt;
&lt;p&gt;Things have changed for me as well since we last met: I am pregnant. I make a joke that I too am growing my own superintelligence. “It is the most efficient way,” he says.&lt;/p&gt;
&lt;p&gt;LeCun would know, as he has been gestating ideas for the creation of such intelligence in machines for decades. He has also been vocal about his disdain for large language models (LLMs) and their potential to reach superhuman intelligence, which is the current obsession of Silicon Valley. He argues that LLMs are useful but fundamentally limited and constrained by language. To achieve human-level intelligence, you have to understand how our physical world works too.&lt;/p&gt;
&lt;p&gt;His solution for achieving that relies on an architecture called V-JEPA, a so-called world model. World models aim to understand the physical world by learning from videos and spatial data, rather than just language. They are also able to plan, reason, and have persistent memory. He calls this kind of intelligence Advanced Machine Intelligence, or AMI.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Born in 1960 and raised in the suburbs of Paris,&lt;/strong&gt; LeCun has been fascinated by the question of how human intelligence emerged since he was a young boy.&lt;/p&gt;
&lt;p&gt;It was the film &lt;em&gt;2001: A Space Odyssey&lt;/em&gt;, which he saw when he was 8 or 9 years old, that set him on the path he is on today. He gestures having his mind blown.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;LeCun’s father, an aeronautical engineer and “a bit of an inventor,” instilled a love of building and tinkering with things. LeCun grew up constructing model aeroplanes and playing woodwind instruments such as the recorder and the crumhorn, a “weird Renaissance instrument,” which he played in a Renaissance dance music band.&lt;/p&gt;
&lt;blockquote class="ars-pullquote large "&gt;&lt;div class="pullquote-content"&gt;I’m sure there’s a lot of people at Meta who would like me to not tell the world that LLMs basically are a dead end when it comes to&amp;nbsp;superintelligence&lt;/div&gt;&lt;/blockquote&gt;
&lt;p&gt;We’ve both chosen the four-course “Champs-Élysées” lunch set menu. As we tuck into our starters (soft-boiled eggs, tuna tartare with smoked pike roe and croutons for LeCun, and a broth of root vegetables and horseradish ravioli with Chartreuse sauce for me), he tells me how a teacher deemed him too bad at math to study it at university, so he decided to pursue engineering.&lt;/p&gt;
&lt;p&gt;The waitress comes to check on us, and LeCun orders a glass of Chassagne-Montrachet from Burgundy. “What Americans would call Chardonnay,” he says, jokingly.&lt;/p&gt;
&lt;p&gt;LeCun’s lightbulb moment came as a student at the École Supérieure d’Ingénieurs en Électrotechnique et Électronique in Paris in the 1980s, when he read a book about a debate on nature versus nurture between the linguist Noam Chomsky and Jean Piaget, a psychologist. Chomsky argued that humans have an inbuilt capacity for language, while Piaget said there is some structure but most of it is learnt.&lt;/p&gt;
&lt;p&gt;“I’m not gonna make friends saying this… ” he tells me, “but I was reading this and I thought everything that Chomsky… was saying could not possibly be true, [because] we learn everything. Intelligence really is about learning.”&lt;/p&gt;
&lt;p&gt;AI research—or neural networks, as the technology was then called, which loosely mimic how the brain functions—was practically a dead field and considered taboo by the scientific community, after early iterations of the technology failed to impress. But LeCun sought out other researchers studying neural networks and found intellectual “soulmates” in the likes of Geoffrey Hinton, then a faculty member at Carnegie Mellon.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;He later joined Hinton at the University of Toronto as a postdoc researcher. The two, along with Yoshua Bengio, went on to lay the groundwork for deep learning and modern AI, which saw them rewarded in 2018 with the Turing Award, the most prestigious prize in computer science.&lt;/p&gt;
&lt;p&gt;The waitress lays our second, gorgeous, dish in front of us and launches into an enthusiastic description of the meal in French. I nod along equally enthusiastically, understanding nothing.&lt;/p&gt;
&lt;p&gt;“Did you get that?” LeCun asks. “This is the foie gras, and this is the Comté soufflé, and the Comté is 18 months aged.” When in France, I think, and take a bite of the liver.&lt;/p&gt;
&lt;p&gt;LeCun is the brain behind important early AI technologies. In the late 1980s and 1990s, while a researcher at AT&amp;amp;T Bell Labs in New Jersey—once known as the leading industry research lab in the world—he developed convolutional neural networks, an architecture used in image recognition technology, which he built into a system that was widely used by banks to read checks.&lt;/p&gt;
&lt;p&gt;He had conceived of the research at Toronto, but was able to roll it out in the real world thanks to the seemingly unlimited coffers of cash and cutting-edge technology available at Bell Labs.&lt;/p&gt;
&lt;p&gt;LeCun recounts something his boss at the time, Larry Jackel, told him when he first joined. “He said, ‘You know, at Bell Labs? You don’t get famous by saving money.’”&lt;/p&gt;
&lt;p&gt;Our main dish arrives, a portion of cod with herbed breadcrumbs and fried capers. LeCun is in a jovial mood, and I find myself engrossed in his colorful stories about the early years of AI research.&lt;/p&gt;
&lt;p&gt;He, along with his pharmacist wife, Isabelle, and their three sons, ended up settling in New Jersey for good, although he visits Paris every five weeks or so. America was a “culture shock,” he says.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The party at Bell Labs was destined to end. A corporate shake-up meant the lab lost significant funding and was spun off to different subsidiaries. LeCun rejoined academia and started a new project at NYU aimed at researching neural networks, frequenting Greenwich Village’s jazz clubs after his lectures.&lt;/p&gt;
&lt;p&gt;By 2013, it was clear that deep learning was going to work, with image recognition applications showing impressive results. Google had just started Google Brain, and a year later would acquire British AI lab DeepMind.&lt;/p&gt;
&lt;p&gt;It was also then that Mark Zuckerberg called. He wanted to start an AI unit at Facebook, and to woo LeCun invited him over for dinner at his California home. A private chef prepared “chicken with some pretty good white wine,” LeCun recalls.&lt;/p&gt;
&lt;p&gt;LeCun agreed to join on three conditions. He wouldn’t have to quit his job at NYU. He wouldn’t move to California. And the research results of the new lab had to be made publicly available.&lt;/p&gt;
&lt;p&gt;Zuckerberg agreed, and the deal was done. LeCun was to join Facebook, one of the biggest technology companies in the world, to set up a new AI research lab focusing on fundamental research, called Facebook Artificial Intelligence Research (Fair).&lt;/p&gt;
&lt;p&gt;Facebook was a “tabula rasa with a carte blanche,” LeCun says. “Money was clearly not going to be a problem.”&lt;/p&gt;
&lt;p&gt;The waitress interrupts us to bring our dessert, bricelets. “&lt;em&gt;Magnifique&lt;/em&gt;,” LeCun says, as the dish is placed in front of him.&lt;/p&gt;
&lt;p&gt;I shift the conversation to a more tumultuous time. In early 2022, pre-ChatGPT, all the major AI labs had some version of the technology kicking around, but it was seen as largely experimental. It was a small, relatively unknown AI lab called OpenAI that kick-started today’s AI mania, when it quietly launched the technology as an easily accessible chatbot.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;blockquote class="ars-pullquote large "&gt;&lt;div class="pullquote-content"&gt;We had a lot of new ideas and really cool stuff… But they were just going for things that were safe and proved. When you do this, you fall&amp;nbsp;behind&lt;/div&gt;&lt;/blockquote&gt;
&lt;p&gt;ChatGPT caused a frantic scramble at Meta. The company’s leadership decided to put all their chips into work developing Llama, a large language model. Zuckerberg reshuffled the organization to create a generative AI unit, which was tasked with accelerating research into products. LeCun insisted the model was released openly.&lt;/p&gt;
&lt;p&gt;Llama 2, released with open weights for all users, meaning people could download and tweak it for free, was a “watershed” moment, which “changed the entire industry,” LeCun says. The model became the gold standard in powerful open LLMs, and championed an approach that was counter to the extreme concentration of power that Google and OpenAI were pushing. Meta was seen as the good guys in AI research.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Meta switched gears aggressively&lt;/strong&gt; on AI last year. Zuckerberg placed more pressure on the GenAI unit to accelerate AI development and deployment, which led to a communication breakdown, LeCun says.&lt;/p&gt;
&lt;p&gt;“We had a lot of new ideas and really cool stuff that they should implement. But they were just going for things that were essentially safe and proved,” he says. “When you do this, you fall behind.”&lt;/p&gt;
&lt;p&gt;The subsequent Llama models were duds. Llama 4, which was released in April 2025, was a flop, and the company was accused of gaming benchmarks to make it look more impressive. LeCun admits that the “results were fudged a little bit,” and the team used different models for different benchmarks to give better results.&lt;/p&gt;
&lt;p&gt;“Mark was really upset and basically lost confidence in everyone who was involved in this. And so basically sidelined the entire GenAI organization. A lot of people have left, a lot of people who haven’t yet left will leave.”&lt;/p&gt;
&lt;p&gt;Last June, Meta invested $15 billion in data-labeling start-up Scale AI and hired its 28-year-old chief executive and co-founder Alexandr Wang. Wang took the reins of the company’s new bet on AI and its research unit, called TBD Lab. The lab is tasked with developing new frontier AI models.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Meta made headlines for trying to poach elite researchers from competitors with offers of $100 million sign-on bonuses. “The future will say whether that was a good idea or not,” LeCun says, deadpan.&lt;/p&gt;
&lt;p&gt;LeCun calls Wang, who was hired to lead the organization, “young” and “inexperienced.”&lt;/p&gt;
&lt;p&gt;“He learns fast, he knows what he doesn’t know… There’s no experience with research or how you practice research, how you do it. Or what would be attractive or repulsive to a researcher.”&lt;/p&gt;
&lt;p&gt;Wang also became LeCun’s manager. I ask LeCun how he felt about this shift in hierarchy. He initially brushes it off, saying he’s used to working with young people. “The average age of a Facebook engineer at the time was 27. I was twice the age of the average engineer.”&lt;/p&gt;
&lt;p&gt;But those 27-year-olds weren’t telling him what to do, I point out.&lt;/p&gt;
&lt;p&gt;“Alex [Wang] isn’t telling me what to do either,” he says. “You don’t tell a researcher what to do. You certainly don’t tell a researcher like me what to do.”&lt;/p&gt;
&lt;p&gt;LeCun doesn’t mince his words about why he ultimately decided to leave Meta after more than a decade. Staying became politically difficult, he tells me. And while Zuckerberg likes LeCun’s world model research, the crowd who were hired for the company’s new superintelligence push are “completely LLM-pilled.”&lt;/p&gt;
&lt;blockquote class="ars-pullquote large "&gt;&lt;div class="pullquote-content"&gt;You don’t tell a researcher what to do. You certainly don’t tell a researcher like me what to&amp;nbsp;do&lt;/div&gt;&lt;/blockquote&gt;
&lt;p&gt;This clearly alienated LeCun. “I’m sure there’s a lot of people at Meta, including perhaps Alex, who would like me to not tell the world that LLMs basically are a dead end when it comes to superintelligence,” he says. “But I’m not gonna change my mind because some dude thinks I’m wrong. I’m not wrong. My integrity as a scientist cannot allow me to do this.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Another driver to leave was that his work with world models and AMI was also proving to have potential uses that were not interesting to Meta, such as jet engines and heavy industry. And LeCun had no trouble finding investors who were willing to bet on the next generation of AI technologies.&lt;/p&gt;
&lt;p&gt;In his next chapter, LeCun believes that setting up a “neolab,” meaning a start-up that does fundamental research, is the new, most fertile ground. He cites OpenAI former chief technology officer Mira Murati’s Thinking Machines (“I hope the investors know what they do”) and OpenAI’s co-founder and chief scientist Ilya Sutskever’s Safe Superintelligence (“There I know the investors have no idea what they do”) as good examples.&lt;/p&gt;
&lt;p&gt;His new architecture uses videos to give AI models an understanding of the physics of our world, which will allow them to make better predictions of what will happen next. The model also relies on “emotions,” meaning past experiences and evaluations, to guide its predictions.&lt;/p&gt;
&lt;p&gt;“If I pinch you, you’re going to feel pain. But then your mental model of me is going to be affected by the fact that I just pinched you. And the next time I approach my arm to yours, you’re going to recoil. That’s your prediction, and the emotion it evokes is fear or avoidance of pain,” he says.&lt;/p&gt;
&lt;p&gt;LeCun says we will see “baby” versions of this within 12 months, and on a larger scale within a few years. It’s not quite yet superintelligence, but a path toward it. “Maybe there is an obstacle we’re not seeing yet, but at least there is hope.”&lt;/p&gt;
&lt;p&gt;After three and a half hours, we are now the only customers left in the restaurant. I ask him what he wants his legacy to be.&lt;/p&gt;
&lt;p&gt;Increasing the amount of intelligence in the world, he replies, without batting an eyelid. “Intelligence is really the thing that we should have more of,” he says, adding that with more intelligence, there’s less human suffering, more rational decisions, and more understanding of the world and the universe.&lt;/p&gt;
&lt;p&gt;“We suffer from stupidity.”&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Melissa Heikkilä is the FT’s AI correspondent.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;© 2026 The Financial Times Ltd. All rights reserved. Not to be redistributed, copied, or modified in any way.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2026/01/computer-scientist-yann-lecun-intelligence-really-is-about-learning/</guid><pubDate>Wed, 07 Jan 2026 15:06:53 +0000</pubDate></item><item><title>Optimism for AI-powered productivity: Deloitte (AI News)</title><link>https://www.artificialintelligence-news.com/news/deloitte-survey-takes-cfo-and-it-temperature-around-technology-and-ai/</link><description>&lt;p&gt;Deloitte’s latest UK CFO Survey presents an improving outlook for large UK businesses, with technology investment – particularly in AI – emerging as a dominant strategy. The survey offers the signal that while macroeconomic and geopolitical risks remain elevated, boards are converging increasingly on digital ability as a primary route to productivity and medium-term growth.&lt;/p&gt;&lt;p&gt;The strongest finding concerns technology investment. An overwhelming 96% of CFOs expect UK companies to increase investment in technology over the next five years, with 77% anticipating improvement to productivity and business performance. The figures are distinctive for a CFO-destined paper, and indicate digital spend is not viewed as discretionary or cyclical, but is treated as structural (akin to capital investment in previous industrial phases). For IT leaders, the paper shows sustained funding is available, but also points out the heightened expectations for delivery, integration, and measurable returns from the technology.&lt;/p&gt;&lt;p&gt;Artificial intelligence sits at the centre of the paper and CFO sentiment in general. The proportion of CFOs becoming ‘more optimistic’ about AI’s ability to improve organisational performance has risen to 59%, up from 39% in Q3 2024. This change isn’t incremental, suggesting AI has crossed from experiment into mainstream financial confidence. Importantly, the survey does not indicate a wholesale rise in risk-taking to accompany the new-found optimism. Risk appetite, while improving, remains subdued at 15%, below the longer average of 25%. This combination – confidence in AI but continued balance-sheet caution – has implications for how AI initiatives are likely to be governed and controlled. Finance functions are likely to need tightly-scoped uses and productivity metrics over open-ended experiments and trials.&lt;/p&gt;&lt;p&gt;For finance professionals, the environment reinforces the role of the CFO as a steward of technology, rather than a passive consumer of IT budgets. The survey positions finance chiefs as shaping digital strategy where AI is concerned. The paper’s emphasis on productivity gains suggests a preference for applications that automate processes and help with financial forecasting, not just customer-facing innovation. IT teams should expect closer scrutiny of business cases presented to them, more involved work from finance professionals, and a translation of technical ability to financial outcomes.&lt;/p&gt;&lt;p&gt;Despite improving sentiment metrics, the survey also highlights some notable constraints. Business confidence remains negative at net -13%, below its long-term average, despite optimism having lifted from lows recorded in earlier iterations of the CFO Survey from Deloitte. Capital expenditure is a priority, but only 17% of CFOs describe it as a ‘strong priority’, only just above the long-term average. This suggests while investment is protected, it’s not immune: Programmes perceived as speculative, poorly governed, or badly aligned with productivity are still unlikely to survive.&lt;/p&gt;&lt;p&gt;External uncertainty, though declining, remains notable. 38% of CFOs still rate their uncertainty in the future as ‘high’ or ‘very high’, and geopolitics still dominates the risk landscape, as cited by 65% of respondents. UK competitiveness and productivity follow closely, with a historically high risk rating of 62. Systems resilience, data security, energy efficiency, and supply-chain visibility are likely to command attention as well as the overall goal of efficiencies created by the use of AI in operations.&lt;/p&gt;&lt;p&gt;A notable subtext of the survey is the human dimension of the technology’s adoption. Deloitte’s leadership realises AI’s value depends on combining technology with human skills and the need to upskill workforces. While this is not quantified in the survey data, it aligns with the broader pattern of cautious optimism: CFOs are willing to invest, but not to assume that technology, as of itself, delivers outcomes. This strengthens the case among IT leaderships for embedding change management, training, governance, and oversight into new digital programmes.&lt;/p&gt;&lt;p&gt;The Deloitte CFO Survey shows a pragmatic and decisive turn towards technology-led productivity in UK businesses. Its evidence is strongest around sustained digital investment and the noteworthy rise in confidence in AI. There’s continued caution on risk and a recognition of a challenging external environment. For Finance professionals, the priority is allocation of capital to initiatives that can improve performance demonstrably. For IT staff, opportunity is expanding, but so is accountability. Digital ambition will be funded in all likelihood, but only where it can be translated into credible, auditable business value.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “Deloitte exposure” by zilverbat. is licensed under CC BY-NC 2.0.)&lt;/em&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Deloitte’s latest UK CFO Survey presents an improving outlook for large UK businesses, with technology investment – particularly in AI – emerging as a dominant strategy. The survey offers the signal that while macroeconomic and geopolitical risks remain elevated, boards are converging increasingly on digital ability as a primary route to productivity and medium-term growth.&lt;/p&gt;&lt;p&gt;The strongest finding concerns technology investment. An overwhelming 96% of CFOs expect UK companies to increase investment in technology over the next five years, with 77% anticipating improvement to productivity and business performance. The figures are distinctive for a CFO-destined paper, and indicate digital spend is not viewed as discretionary or cyclical, but is treated as structural (akin to capital investment in previous industrial phases). For IT leaders, the paper shows sustained funding is available, but also points out the heightened expectations for delivery, integration, and measurable returns from the technology.&lt;/p&gt;&lt;p&gt;Artificial intelligence sits at the centre of the paper and CFO sentiment in general. The proportion of CFOs becoming ‘more optimistic’ about AI’s ability to improve organisational performance has risen to 59%, up from 39% in Q3 2024. This change isn’t incremental, suggesting AI has crossed from experiment into mainstream financial confidence. Importantly, the survey does not indicate a wholesale rise in risk-taking to accompany the new-found optimism. Risk appetite, while improving, remains subdued at 15%, below the longer average of 25%. This combination – confidence in AI but continued balance-sheet caution – has implications for how AI initiatives are likely to be governed and controlled. Finance functions are likely to need tightly-scoped uses and productivity metrics over open-ended experiments and trials.&lt;/p&gt;&lt;p&gt;For finance professionals, the environment reinforces the role of the CFO as a steward of technology, rather than a passive consumer of IT budgets. The survey positions finance chiefs as shaping digital strategy where AI is concerned. The paper’s emphasis on productivity gains suggests a preference for applications that automate processes and help with financial forecasting, not just customer-facing innovation. IT teams should expect closer scrutiny of business cases presented to them, more involved work from finance professionals, and a translation of technical ability to financial outcomes.&lt;/p&gt;&lt;p&gt;Despite improving sentiment metrics, the survey also highlights some notable constraints. Business confidence remains negative at net -13%, below its long-term average, despite optimism having lifted from lows recorded in earlier iterations of the CFO Survey from Deloitte. Capital expenditure is a priority, but only 17% of CFOs describe it as a ‘strong priority’, only just above the long-term average. This suggests while investment is protected, it’s not immune: Programmes perceived as speculative, poorly governed, or badly aligned with productivity are still unlikely to survive.&lt;/p&gt;&lt;p&gt;External uncertainty, though declining, remains notable. 38% of CFOs still rate their uncertainty in the future as ‘high’ or ‘very high’, and geopolitics still dominates the risk landscape, as cited by 65% of respondents. UK competitiveness and productivity follow closely, with a historically high risk rating of 62. Systems resilience, data security, energy efficiency, and supply-chain visibility are likely to command attention as well as the overall goal of efficiencies created by the use of AI in operations.&lt;/p&gt;&lt;p&gt;A notable subtext of the survey is the human dimension of the technology’s adoption. Deloitte’s leadership realises AI’s value depends on combining technology with human skills and the need to upskill workforces. While this is not quantified in the survey data, it aligns with the broader pattern of cautious optimism: CFOs are willing to invest, but not to assume that technology, as of itself, delivers outcomes. This strengthens the case among IT leaderships for embedding change management, training, governance, and oversight into new digital programmes.&lt;/p&gt;&lt;p&gt;The Deloitte CFO Survey shows a pragmatic and decisive turn towards technology-led productivity in UK businesses. Its evidence is strongest around sustained digital investment and the noteworthy rise in confidence in AI. There’s continued caution on risk and a recognition of a challenging external environment. For Finance professionals, the priority is allocation of capital to initiatives that can improve performance demonstrably. For IT staff, opportunity is expanding, but so is accountability. Digital ambition will be funded in all likelihood, but only where it can be translated into credible, auditable business value.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “Deloitte exposure” by zilverbat. is licensed under CC BY-NC 2.0.)&lt;/em&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/deloitte-survey-takes-cfo-and-it-temperature-around-technology-and-ai/</guid><pubDate>Wed, 07 Jan 2026 15:59:47 +0000</pubDate></item><item><title>Caterpillar taps Nvidia to bring AI to its construction equipment (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/07/caterpillar-taps-nvidia-to-bring-ai-to-its-construction-equipment/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/ces-caterpillar.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Caterpillar is digging deeper into incorporating AI and automation into its fleet of construction machinery through a partnership with semiconductor giant Nvidia.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The construction equipment giant is piloting an AI assistive system in its mid-size Cat 306 CR Mini Excavator. Dubbed “Cat AI,” the system was built using Nvidia’s Jetson Thor physical AI platform, and is being demoed at CES on Wednesday.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Brandon Hootman, vice president of data and AI at Caterpillar, told TechCrunch that Cat AI was built on a fleet of AI agents and can help answer a machine operator’s questions, allow them to access resources, offer safety tips, and schedule services.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of the biggest benefits of bringing this tech into these machines is the data that these systems collect and send back out.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our customers don’t live in front of a laptop day in and day out; they live in the dirt,” Hootman said. “The ability to get the insights and take the action that they need while they’re doing the work is very important to them.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Caterpillar is also piloting digital twins of construction sites using Nvidia’s Omniverse library of simulation resources to test scheduling scenarios and better calculate how much building material a project will need. Hootman said Caterpillar’s machines send roughly 2,000 messages back to the company every second. This data will help them build these simulations. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company already has fully autonomous vehicles in the mining sector, and Hootman said that these pilot programs are a great next step as the company looks to bring more automation to its portfolio.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“The reason that we started here was it was a real challenge of our customers today that needed to be addressed, and also something that we had some real momentum on and we felt like we could bring to market pretty quickly,” Hootman said. “What we also liked is that it provided a kind of a technology foundation&amp;nbsp;for us to then build upon.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Working with companies like Caterpillar — a legacy brand that doesn’t often intertwine with the tech industry — seems to fit right into Nvidia’s physical AI strategy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bill Dally, Nvidia’s chief scientist, told TechCrunch in 2025 that the chipmaker considers physical AI to be the next frontier for the company and its powerful GPUs.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;During its CES keynote on Monday, Nvidia laid out plans for its full-stack ecosystem for physical AI, which includes open AI models like the company’s Cosmos model family, simulation tools, and developer kits.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While some may think physical AI is just for robotics companies, Deepu Talla, the vice president of robotics and edge AI at Nvidia, told TechCrunch the company takes a much broader definition as everyone is building robotics today.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Physical AI is the next wave of AI,” Talla said. “Nvidia is pioneering that with computers that train the models, that do the simulation to test the models and deploy the models into the robots, whether [that’s] an autonomous car or a Caterpillar machine.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Follow along with all of TechCrunch’s CES coverage here. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/ces-caterpillar.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Caterpillar is digging deeper into incorporating AI and automation into its fleet of construction machinery through a partnership with semiconductor giant Nvidia.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The construction equipment giant is piloting an AI assistive system in its mid-size Cat 306 CR Mini Excavator. Dubbed “Cat AI,” the system was built using Nvidia’s Jetson Thor physical AI platform, and is being demoed at CES on Wednesday.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Brandon Hootman, vice president of data and AI at Caterpillar, told TechCrunch that Cat AI was built on a fleet of AI agents and can help answer a machine operator’s questions, allow them to access resources, offer safety tips, and schedule services.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of the biggest benefits of bringing this tech into these machines is the data that these systems collect and send back out.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our customers don’t live in front of a laptop day in and day out; they live in the dirt,” Hootman said. “The ability to get the insights and take the action that they need while they’re doing the work is very important to them.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Caterpillar is also piloting digital twins of construction sites using Nvidia’s Omniverse library of simulation resources to test scheduling scenarios and better calculate how much building material a project will need. Hootman said Caterpillar’s machines send roughly 2,000 messages back to the company every second. This data will help them build these simulations. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company already has fully autonomous vehicles in the mining sector, and Hootman said that these pilot programs are a great next step as the company looks to bring more automation to its portfolio.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“The reason that we started here was it was a real challenge of our customers today that needed to be addressed, and also something that we had some real momentum on and we felt like we could bring to market pretty quickly,” Hootman said. “What we also liked is that it provided a kind of a technology foundation&amp;nbsp;for us to then build upon.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Working with companies like Caterpillar — a legacy brand that doesn’t often intertwine with the tech industry — seems to fit right into Nvidia’s physical AI strategy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bill Dally, Nvidia’s chief scientist, told TechCrunch in 2025 that the chipmaker considers physical AI to be the next frontier for the company and its powerful GPUs.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;During its CES keynote on Monday, Nvidia laid out plans for its full-stack ecosystem for physical AI, which includes open AI models like the company’s Cosmos model family, simulation tools, and developer kits.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While some may think physical AI is just for robotics companies, Deepu Talla, the vice president of robotics and edge AI at Nvidia, told TechCrunch the company takes a much broader definition as everyone is building robotics today.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Physical AI is the next wave of AI,” Talla said. “Nvidia is pioneering that with computers that train the models, that do the simulation to test the models and deploy the models into the robots, whether [that’s] an autonomous car or a Caterpillar machine.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Follow along with all of TechCrunch’s CES coverage here. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/07/caterpillar-taps-nvidia-to-bring-ai-to-its-construction-equipment/</guid><pubDate>Wed, 07 Jan 2026 17:00:00 +0000</pubDate></item><item><title>Agentic AI scaling requires new memory architecture (AI News)</title><link>https://www.artificialintelligence-news.com/news/agentic-ai-scaling-requires-new-memory-architecture/</link><description>&lt;p&gt;Agentic AI represents a distinct evolution from stateless chatbots toward complex workflows, and scaling it requires new memory architecture.&lt;/p&gt;&lt;p&gt;As foundation models scale toward trillions of parameters and context windows reach millions of tokens, the computational cost of remembering history is rising faster than the ability to process it.&lt;/p&gt;&lt;p&gt;Organisations deploying these systems now face a bottleneck where the sheer volume of “long-term memory” (technically known as Key-Value (KV) cache) overwhelms existing hardware architectures.&lt;/p&gt;&lt;p&gt;Current infrastructure forces a binary choice: store inference context in scarce, high-bandwidth GPU memory (HBM) or relegate it to slow, general-purpose storage. The former is prohibitively expensive for large contexts; the latter creates latency that renders real-time agentic interactions unviable.&lt;/p&gt;&lt;p&gt;To address this widening disparity that is holding back the scaling of agentic AI, NVIDIA has introduced the Inference Context Memory Storage (ICMS) platform within its Rubin architecture, proposing a new storage tier designed specifically to handle the ephemeral and high-velocity nature of AI memory.&lt;/p&gt;&lt;p&gt;“AI is revolutionising the entire computing stack—and now, storage,” Huang said. “AI is no longer about one-shot chatbots but intelligent collaborators that understand the physical world, reason over long horizons, stay grounded in facts, use tools to do real work, and retain both short- and long-term memory.”&lt;/p&gt;&lt;p&gt;The operational challenge lies in the specific behaviour of transformer-based models. To avoid recomputing an entire conversation history for every new word generated, models store previous states in the KV cache. In agentic workflows, this cache acts as persistent memory across tools and sessions, growing linearly with sequence length.&lt;/p&gt;&lt;p&gt;This creates a distinct data class. Unlike financial records or customer logs, KV cache is derived data; it is essential for immediate performance but does not require the heavy durability guarantees of enterprise file systems. General-purpose storage stacks, running on standard CPUs, expend energy on metadata management and replication that agentic workloads do not require.&lt;/p&gt;&lt;p&gt;The current hierarchy, spanning from GPU HBM (G1) to shared storage (G4), is becoming inefficient:&lt;/p&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-111516" height="396" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/image-1-1024x396.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;(Credit: NVIDIA)&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;As context spills from the GPU (G1) to system RAM (G2) and eventually to shared storage (G4), efficiency plummets. Moving active context to the G4 tier introduces millisecond-level latency and increases the power cost per token, leaving expensive GPUs idle while they await data.&lt;/p&gt;&lt;p&gt;For the enterprise, this manifests as a bloated Total Cost of Ownership (TCO), where power is wasted on infrastructure overhead rather than active reasoning.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-a-new-memory-tier-for-the-ai-factory"&gt;A new memory tier for the AI factory&lt;/h3&gt;&lt;p&gt;The industry response involves inserting a purpose-built layer into this hierarchy. The ICMS platform establishes a “G3.5” tier—an Ethernet-attached flash layer designed explicitly for gigascale inference.&lt;/p&gt;&lt;p&gt;This approach integrates storage directly into the compute pod. By utilising the NVIDIA BlueField-4 data processor, the platform offloads the management of this context data from the host CPU. The system provides petabytes of shared capacity per pod, boosting the scaling of agentic AI by allowing agents to retain massive amounts of history without occupying expensive HBM.&lt;/p&gt;&lt;p&gt;The operational benefit is quantifiable in throughput and energy. By keeping relevant context in this intermediate tier – which is faster than standard storage, but cheaper than HBM – the system can “prestage” memory back to the GPU before it is needed. This reduces the idle time of the GPU decoder, enabling up to 5x higher tokens-per-second (TPS) for long-context workloads.&lt;/p&gt;&lt;p&gt;From an energy perspective, the implications are equally measurable. Because the architecture removes the overhead of general-purpose storage protocols, it delivers 5x better power efficiency than traditional methods.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-integrating-the-data-plane"&gt;Integrating the data plane&lt;/h3&gt;&lt;p&gt;Implementing this architecture requires a change in how IT teams view storage networking. The ICMS platform relies on NVIDIA Spectrum-X Ethernet to provide the high-bandwidth, low-jitter connectivity required to treat flash storage almost as if it were local memory.&lt;/p&gt;&lt;p&gt;For enterprise infrastructure teams, the integration point is the orchestration layer. Frameworks such as NVIDIA Dynamo and the Inference Transfer Library (NIXL) manage the movement of KV blocks between tiers.&lt;/p&gt;&lt;p&gt;These tools coordinate with the storage layer to ensure that the correct context is loaded into the GPU memory (G1) or host memory (G2) exactly when the AI model requires it. The NVIDIA DOCA framework further supports this by providing a KV communication layer that treats context cache as a first-class resource.&lt;/p&gt;&lt;p&gt;Major storage vendors are already aligning with this architecture. Companies including AIC, Cloudian, DDN, Dell Technologies, HPE, Hitachi Vantara, IBM, Nutanix, Pure Storage, Supermicro, VAST Data, and WEKA are building platforms with BlueField-4. These solutions are expected to be available in the second half of this year.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-redefining-infrastructure-for-scaling-agentic-ai"&gt;Redefining infrastructure for scaling agentic AI&lt;/h3&gt;&lt;p&gt;Adopting a dedicated context memory tier impacts capacity planning and datacentre design.&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Reclassifying data:&lt;/strong&gt; CIOs must recognise KV cache as a unique data type. It is “ephemeral but latency-sensitive,” distinct from “durable and cold” compliance data. The G3.5 tier handles the former, allowing durable G4 storage to focus on long-term logs and artifacts.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Orchestration maturity:&lt;/strong&gt; Success depends on software that can intelligently place workloads. The system uses topology-aware orchestration (via NVIDIA Grove) to place jobs near their cached context, minimising data movement across the fabric.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Power density:&lt;/strong&gt; By fitting more usable capacity into the same rack footprint, organisations can extend the life of existing facilities. However, this increases the density of compute per square metre, requiring adequate cooling and power distribution planning.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The transition to agentic AI forces a physical reconfiguration of the datacentre. The prevailing model of separating compute completely from slow, persistent storage is incompatible with the real-time retrieval needs of agents with photographic memories.&lt;/p&gt;&lt;p&gt;By introducing a specialised context tier, enterprises can decouple the growth of model memory from the cost of GPU HBM. This architecture for agentic AI allows multiple agents to share a massive low-power memory pool to reduce the cost of serving complex queries and boosts scaling by enabling high-throughput reasoning.&lt;/p&gt;&lt;p&gt;As organisations plan their next cycle of infrastructure investment, evaluating the efficiency of the memory hierarchy will be as vital as selecting the GPU itself.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;2025’s AI chip wars: What enterprise leaders learned about supply chain reality&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-111183" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/12/image-3.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Agentic AI represents a distinct evolution from stateless chatbots toward complex workflows, and scaling it requires new memory architecture.&lt;/p&gt;&lt;p&gt;As foundation models scale toward trillions of parameters and context windows reach millions of tokens, the computational cost of remembering history is rising faster than the ability to process it.&lt;/p&gt;&lt;p&gt;Organisations deploying these systems now face a bottleneck where the sheer volume of “long-term memory” (technically known as Key-Value (KV) cache) overwhelms existing hardware architectures.&lt;/p&gt;&lt;p&gt;Current infrastructure forces a binary choice: store inference context in scarce, high-bandwidth GPU memory (HBM) or relegate it to slow, general-purpose storage. The former is prohibitively expensive for large contexts; the latter creates latency that renders real-time agentic interactions unviable.&lt;/p&gt;&lt;p&gt;To address this widening disparity that is holding back the scaling of agentic AI, NVIDIA has introduced the Inference Context Memory Storage (ICMS) platform within its Rubin architecture, proposing a new storage tier designed specifically to handle the ephemeral and high-velocity nature of AI memory.&lt;/p&gt;&lt;p&gt;“AI is revolutionising the entire computing stack—and now, storage,” Huang said. “AI is no longer about one-shot chatbots but intelligent collaborators that understand the physical world, reason over long horizons, stay grounded in facts, use tools to do real work, and retain both short- and long-term memory.”&lt;/p&gt;&lt;p&gt;The operational challenge lies in the specific behaviour of transformer-based models. To avoid recomputing an entire conversation history for every new word generated, models store previous states in the KV cache. In agentic workflows, this cache acts as persistent memory across tools and sessions, growing linearly with sequence length.&lt;/p&gt;&lt;p&gt;This creates a distinct data class. Unlike financial records or customer logs, KV cache is derived data; it is essential for immediate performance but does not require the heavy durability guarantees of enterprise file systems. General-purpose storage stacks, running on standard CPUs, expend energy on metadata management and replication that agentic workloads do not require.&lt;/p&gt;&lt;p&gt;The current hierarchy, spanning from GPU HBM (G1) to shared storage (G4), is becoming inefficient:&lt;/p&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-111516" height="396" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/image-1-1024x396.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;(Credit: NVIDIA)&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;As context spills from the GPU (G1) to system RAM (G2) and eventually to shared storage (G4), efficiency plummets. Moving active context to the G4 tier introduces millisecond-level latency and increases the power cost per token, leaving expensive GPUs idle while they await data.&lt;/p&gt;&lt;p&gt;For the enterprise, this manifests as a bloated Total Cost of Ownership (TCO), where power is wasted on infrastructure overhead rather than active reasoning.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-a-new-memory-tier-for-the-ai-factory"&gt;A new memory tier for the AI factory&lt;/h3&gt;&lt;p&gt;The industry response involves inserting a purpose-built layer into this hierarchy. The ICMS platform establishes a “G3.5” tier—an Ethernet-attached flash layer designed explicitly for gigascale inference.&lt;/p&gt;&lt;p&gt;This approach integrates storage directly into the compute pod. By utilising the NVIDIA BlueField-4 data processor, the platform offloads the management of this context data from the host CPU. The system provides petabytes of shared capacity per pod, boosting the scaling of agentic AI by allowing agents to retain massive amounts of history without occupying expensive HBM.&lt;/p&gt;&lt;p&gt;The operational benefit is quantifiable in throughput and energy. By keeping relevant context in this intermediate tier – which is faster than standard storage, but cheaper than HBM – the system can “prestage” memory back to the GPU before it is needed. This reduces the idle time of the GPU decoder, enabling up to 5x higher tokens-per-second (TPS) for long-context workloads.&lt;/p&gt;&lt;p&gt;From an energy perspective, the implications are equally measurable. Because the architecture removes the overhead of general-purpose storage protocols, it delivers 5x better power efficiency than traditional methods.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-integrating-the-data-plane"&gt;Integrating the data plane&lt;/h3&gt;&lt;p&gt;Implementing this architecture requires a change in how IT teams view storage networking. The ICMS platform relies on NVIDIA Spectrum-X Ethernet to provide the high-bandwidth, low-jitter connectivity required to treat flash storage almost as if it were local memory.&lt;/p&gt;&lt;p&gt;For enterprise infrastructure teams, the integration point is the orchestration layer. Frameworks such as NVIDIA Dynamo and the Inference Transfer Library (NIXL) manage the movement of KV blocks between tiers.&lt;/p&gt;&lt;p&gt;These tools coordinate with the storage layer to ensure that the correct context is loaded into the GPU memory (G1) or host memory (G2) exactly when the AI model requires it. The NVIDIA DOCA framework further supports this by providing a KV communication layer that treats context cache as a first-class resource.&lt;/p&gt;&lt;p&gt;Major storage vendors are already aligning with this architecture. Companies including AIC, Cloudian, DDN, Dell Technologies, HPE, Hitachi Vantara, IBM, Nutanix, Pure Storage, Supermicro, VAST Data, and WEKA are building platforms with BlueField-4. These solutions are expected to be available in the second half of this year.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-redefining-infrastructure-for-scaling-agentic-ai"&gt;Redefining infrastructure for scaling agentic AI&lt;/h3&gt;&lt;p&gt;Adopting a dedicated context memory tier impacts capacity planning and datacentre design.&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Reclassifying data:&lt;/strong&gt; CIOs must recognise KV cache as a unique data type. It is “ephemeral but latency-sensitive,” distinct from “durable and cold” compliance data. The G3.5 tier handles the former, allowing durable G4 storage to focus on long-term logs and artifacts.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Orchestration maturity:&lt;/strong&gt; Success depends on software that can intelligently place workloads. The system uses topology-aware orchestration (via NVIDIA Grove) to place jobs near their cached context, minimising data movement across the fabric.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Power density:&lt;/strong&gt; By fitting more usable capacity into the same rack footprint, organisations can extend the life of existing facilities. However, this increases the density of compute per square metre, requiring adequate cooling and power distribution planning.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The transition to agentic AI forces a physical reconfiguration of the datacentre. The prevailing model of separating compute completely from slow, persistent storage is incompatible with the real-time retrieval needs of agents with photographic memories.&lt;/p&gt;&lt;p&gt;By introducing a specialised context tier, enterprises can decouple the growth of model memory from the cost of GPU HBM. This architecture for agentic AI allows multiple agents to share a massive low-power memory pool to reduce the cost of serving complex queries and boosts scaling by enabling high-throughput reasoning.&lt;/p&gt;&lt;p&gt;As organisations plan their next cycle of infrastructure investment, evaluating the efficiency of the memory hierarchy will be as vital as selecting the GPU itself.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;2025’s AI chip wars: What enterprise leaders learned about supply chain reality&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-111183" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/12/image-3.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/agentic-ai-scaling-requires-new-memory-architecture/</guid><pubDate>Wed, 07 Jan 2026 17:13:19 +0000</pubDate></item><item><title>Google Classroom’s new tool uses Gemini to transform lessons into podcast episodes (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/07/google-classrooms-new-tool-uses-gemini-to-transform-lessons-into-podcast-episodes/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2018/05/usb-microphones-fullres-0663_preview.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google has introduced a new way to grab the attention of students who are avid podcast listeners. Now available in Google Classroom, teachers can use a new Gemini-powered tool that generates podcast-style audio lessons, meant to promote deeper comprehension of educational material.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To begin, educators simply go to the Gemini tab within Google Classroom. There, they can select different customization options, such as selecting the appropriate grade level, defining topics, and setting clear learning objectives. They can then further personalize the audio experience by choosing the number of speakers or selecting different conversational styles, such as interviews, roundtable discussions, or casual dialogues.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This new feature is currently available to users subscribed to Google Workspace Education Fundamentals, Standard, and Plus.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;By bringing this familiar format into the classroom, teachers can tap into their students’ interests. Research shows that students spend significant time listening to podcasts, with an estimated 35 million Gen Z monthly listeners in the U.S.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, the popularity of podcasts as educational resources has grown rapidly; many universities now produce their own podcasts, and students increasingly seek out popular educational series on their own time. Podcast-style lessons might also encourage independent learning, since students can replay episodes whenever they need a refresher or missed a class.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, teachers are still grappling with integrating AI tools into their teaching practices. Many teachers express concerns about students’ increased reliance on generative AI tools, such as ChatGPT, to complete assignments.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google urges teachers to practice responsible AI and carefully review and, if necessary, edit all AI-generated content to ensure accuracy and appropriateness for their specific classroom context and local policies.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Gemini for Classroom first launched in 2024, and Google has continually added new features since then. Most recently, the company rolled out major updates last June, including features that help teachers brainstorm, develop lesson plans, and customize instructional materials for their students.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2018/05/usb-microphones-fullres-0663_preview.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google has introduced a new way to grab the attention of students who are avid podcast listeners. Now available in Google Classroom, teachers can use a new Gemini-powered tool that generates podcast-style audio lessons, meant to promote deeper comprehension of educational material.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To begin, educators simply go to the Gemini tab within Google Classroom. There, they can select different customization options, such as selecting the appropriate grade level, defining topics, and setting clear learning objectives. They can then further personalize the audio experience by choosing the number of speakers or selecting different conversational styles, such as interviews, roundtable discussions, or casual dialogues.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This new feature is currently available to users subscribed to Google Workspace Education Fundamentals, Standard, and Plus.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;By bringing this familiar format into the classroom, teachers can tap into their students’ interests. Research shows that students spend significant time listening to podcasts, with an estimated 35 million Gen Z monthly listeners in the U.S.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, the popularity of podcasts as educational resources has grown rapidly; many universities now produce their own podcasts, and students increasingly seek out popular educational series on their own time. Podcast-style lessons might also encourage independent learning, since students can replay episodes whenever they need a refresher or missed a class.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, teachers are still grappling with integrating AI tools into their teaching practices. Many teachers express concerns about students’ increased reliance on generative AI tools, such as ChatGPT, to complete assignments.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google urges teachers to practice responsible AI and carefully review and, if necessary, edit all AI-generated content to ensure accuracy and appropriateness for their specific classroom context and local policies.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Gemini for Classroom first launched in 2024, and Google has continually added new features since then. Most recently, the company rolled out major updates last June, including features that help teachers brainstorm, develop lesson plans, and customize instructional materials for their students.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/07/google-classrooms-new-tool-uses-gemini-to-transform-lessons-into-podcast-episodes/</guid><pubDate>Wed, 07 Jan 2026 17:55:35 +0000</pubDate></item><item><title>Skylight debuts Calendar 2 to keep your family organized (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/07/skylight-debuts-calendar-2-to-keep-your-family-organized/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Skylight may have started as a digital picture frame, but today, the company is more focused on helping families stay organized with shared calendars, lists, meal planning tools, and more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At CES 2026, the company debuted its latest product: the Skylight Calendar 2, which offers a sleeker design than the original 15-inch calendar but smaller than the 27-inch wall-mounted Calendar Max. Like its larger counterpart, the new digital calendar app and family organizer also lets you swap out the frame for different colors to better match your home’s decor.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The biggest selling point isn’t the digital screen itself, but the underlying software and AI capabilities. The primary feature — the calendar — is actually a mashup of all your family’s calendars from whatever services you use, whether that’s Google Calendar, iCal, Microsoft, or even your kids’ sports apps, like TeamSnap.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The calendar is color-coded to see everyone’s schedules at a glance, and can even import “calendars” that are really just emails with a few key dates or flyers sent home in Junior’s backpack. (The latter is an AI feature where you snap a photo of the paper, and the calendar updates with the new events.)&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3080785" height="510" src="https://techcrunch.com/wp-content/uploads/2026/01/skylight-calendar-2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Sarah Perez&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company is also trying to address other pain points for families, such as managing grocery lists, reminders for appointments, meal planning, and recipe discovery. Of course, it can still display your family photos too, when otherwise not in use.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The app is well-designed to be easy to read with simple navigation, pops of color, and imagery that makes it possible for little kids to use. For instance, they can check off their chores by looking for a picture, even if they can’t yet read. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3080923" height="510" src="https://techcrunch.com/wp-content/uploads/2026/01/IMG_0568.jpg?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Parents also like the ability to plan meals, whether that’s noting simply that Tuesday will be taco night, or going as far as finding a recipe and preparing a shopping list. Skylight’s helpful here too, as it can automatically create the shopping list of ingredients for you or even add it to your Instacart app.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another clever AI feature lets you snap a photo of what’s in your fridge and get a recipe recommendation based on what you have on hand.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The need for such a system is clearly resonating with customers. Skylight, a bootstrapped and profitable company from day one, now has 1.3 million-plus families using its digital calendars so far, and likely more to come as the new design ships.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Skylight may have started as a digital picture frame, but today, the company is more focused on helping families stay organized with shared calendars, lists, meal planning tools, and more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At CES 2026, the company debuted its latest product: the Skylight Calendar 2, which offers a sleeker design than the original 15-inch calendar but smaller than the 27-inch wall-mounted Calendar Max. Like its larger counterpart, the new digital calendar app and family organizer also lets you swap out the frame for different colors to better match your home’s decor.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The biggest selling point isn’t the digital screen itself, but the underlying software and AI capabilities. The primary feature — the calendar — is actually a mashup of all your family’s calendars from whatever services you use, whether that’s Google Calendar, iCal, Microsoft, or even your kids’ sports apps, like TeamSnap.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The calendar is color-coded to see everyone’s schedules at a glance, and can even import “calendars” that are really just emails with a few key dates or flyers sent home in Junior’s backpack. (The latter is an AI feature where you snap a photo of the paper, and the calendar updates with the new events.)&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3080785" height="510" src="https://techcrunch.com/wp-content/uploads/2026/01/skylight-calendar-2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Sarah Perez&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company is also trying to address other pain points for families, such as managing grocery lists, reminders for appointments, meal planning, and recipe discovery. Of course, it can still display your family photos too, when otherwise not in use.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The app is well-designed to be easy to read with simple navigation, pops of color, and imagery that makes it possible for little kids to use. For instance, they can check off their chores by looking for a picture, even if they can’t yet read. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3080923" height="510" src="https://techcrunch.com/wp-content/uploads/2026/01/IMG_0568.jpg?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Parents also like the ability to plan meals, whether that’s noting simply that Tuesday will be taco night, or going as far as finding a recipe and preparing a shopping list. Skylight’s helpful here too, as it can automatically create the shopping list of ingredients for you or even add it to your Instacart app.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another clever AI feature lets you snap a photo of what’s in your fridge and get a recipe recommendation based on what you have on hand.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The need for such a system is clearly resonating with customers. Skylight, a bootstrapped and profitable company from day one, now has 1.3 million-plus families using its digital calendars so far, and likely more to come as the new design ships.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/07/skylight-debuts-calendar-2-to-keep-your-family-organized/</guid><pubDate>Wed, 07 Jan 2026 18:00:00 +0000</pubDate></item><item><title>VC predicts the consumer AI products OpenAI ‘won’t want to kill’ (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/podcast/investing-in-the-consumer-ai-products-openai-wont-want-to-kill/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/230829_NEA_MenloPark_VanessaLarco_0087-e1718215170281.jpg?resize=926,1200" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;Vanessa Larco, partner at Premise and former partner at NEA, thinks 2026 will finally be the year of consumer AI.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Larco, who’s been investing in consumer and prosumer for years, thinks we’re about to see a shift in how consumers spend time online, with AI powering “concierge-like” services. The question is, will legacy consumer products like WebMD and TripAdvisor continue to exist as standalone apps, or will they just get absorbed into ChatGPT or Meta AI? And where can startups carve out an AI-powered niche for themselves?&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Today on TechCrunch’s Equity podcast, Rebecca Bellan sat down with Larco to talk about why consumer is back, what OpenAI &lt;em&gt;won’t&lt;/em&gt; kill, and where the real opportunities are hiding.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear about:&amp;nbsp;&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Why Larco thinks OpenAI won’t build marketplace businesses that require managing real humans.&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Larco’s take on “disposable software” and why AI apps “should be treated like Word docs.”&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;How Meta Ray-Ban smart glasses turned Larco into a believer in voice interfaces (and why she thinks screens are optional for most tasks).&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;More predictions for 2026, including another huge year for M&amp;amp;A.&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;What new business models stablecoins could unlock.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;Subscribe to Equity on&amp;nbsp;YouTube, Apple Podcasts, Overcast, Spotify, and all the casts. You also can follow Equity on X and Threads, at @EquityPod.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/230829_NEA_MenloPark_VanessaLarco_0087-e1718215170281.jpg?resize=926,1200" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;Vanessa Larco, partner at Premise and former partner at NEA, thinks 2026 will finally be the year of consumer AI.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Larco, who’s been investing in consumer and prosumer for years, thinks we’re about to see a shift in how consumers spend time online, with AI powering “concierge-like” services. The question is, will legacy consumer products like WebMD and TripAdvisor continue to exist as standalone apps, or will they just get absorbed into ChatGPT or Meta AI? And where can startups carve out an AI-powered niche for themselves?&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Today on TechCrunch’s Equity podcast, Rebecca Bellan sat down with Larco to talk about why consumer is back, what OpenAI &lt;em&gt;won’t&lt;/em&gt; kill, and where the real opportunities are hiding.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear about:&amp;nbsp;&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Why Larco thinks OpenAI won’t build marketplace businesses that require managing real humans.&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Larco’s take on “disposable software” and why AI apps “should be treated like Word docs.”&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;How Meta Ray-Ban smart glasses turned Larco into a believer in voice interfaces (and why she thinks screens are optional for most tasks).&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;More predictions for 2026, including another huge year for M&amp;amp;A.&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;What new business models stablecoins could unlock.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;Subscribe to Equity on&amp;nbsp;YouTube, Apple Podcasts, Overcast, Spotify, and all the casts. You also can follow Equity on X and Threads, at @EquityPod.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/podcast/investing-in-the-consumer-ai-products-openai-wont-want-to-kill/</guid><pubDate>Wed, 07 Jan 2026 18:15:00 +0000</pubDate></item><item><title>Anthropic reportedly raising $10B at $350B valuation (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/07/anthropic-reportedly-raising-10b-at-350b-valuation/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/GettyImages-2252871842.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic is gearing up to raise a fresh $10 billion at a $350 billion valuation, according to The Wall Street Journal.&amp;nbsp;TechCrunch has confirmed the raise and valuation, according to a person familiar with the matter.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Claude maker last raised a $13 billion Series F round at a $183 billion valuation three months ago, so this raise nearly doubles the AI firm’s value. In March, Anthropic secured $3.5 billion at a $61.5 billion valuation.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Coatue Management and GIC, Singapore’s sovereign wealth fund, will lead the new round, per the WSJ, which cited sources familiar with the deal. Anthropic is expected to close its latest financing in the coming weeks, and the total deal amount could change.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This round would be separate from the $15 billion Nvidia and Microsoft recently committed to invest in Anthropic, a “circular” deal that would see Anthropic buying $30 billion of compute capacity from Microsoft Azure running on Nvidia’s chips.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The fresh capital comes as Anthropic continues to win over developer hearts with Claude Code, its tool designed to automate coding, powered by Claude Opus 4.5. It also comes as Anthropic prepares for a potential IPO this year alongside its main rival OpenAI. OpenAI is also in talks to raise as much as $100 billion at a valuation of up to $830 billion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic declined to comment. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was updated to reflect that TechCrunch separately confirmed the round.&lt;/em&gt;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/GettyImages-2252871842.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic is gearing up to raise a fresh $10 billion at a $350 billion valuation, according to The Wall Street Journal.&amp;nbsp;TechCrunch has confirmed the raise and valuation, according to a person familiar with the matter.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Claude maker last raised a $13 billion Series F round at a $183 billion valuation three months ago, so this raise nearly doubles the AI firm’s value. In March, Anthropic secured $3.5 billion at a $61.5 billion valuation.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Coatue Management and GIC, Singapore’s sovereign wealth fund, will lead the new round, per the WSJ, which cited sources familiar with the deal. Anthropic is expected to close its latest financing in the coming weeks, and the total deal amount could change.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This round would be separate from the $15 billion Nvidia and Microsoft recently committed to invest in Anthropic, a “circular” deal that would see Anthropic buying $30 billion of compute capacity from Microsoft Azure running on Nvidia’s chips.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The fresh capital comes as Anthropic continues to win over developer hearts with Claude Code, its tool designed to automate coding, powered by Claude Opus 4.5. It also comes as Anthropic prepares for a potential IPO this year alongside its main rival OpenAI. OpenAI is also in talks to raise as much as $100 billion at a valuation of up to $830 billion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic declined to comment. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was updated to reflect that TechCrunch separately confirmed the round.&lt;/em&gt;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/07/anthropic-reportedly-raising-10b-at-350b-valuation/</guid><pubDate>Wed, 07 Jan 2026 18:36:53 +0000</pubDate></item><item><title>[NEW] Where VCs think AI startups can win, even with OpenAI in the game (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/video/where-vcs-think-ai-startups-can-win-even-with-openai-in-the-game/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/meta-oakley.jpg?resize=1200,890" /&gt;&lt;/div&gt;&lt;div class="jwppp-video-box" id="jwppp-video-box-30808021"&gt;






&lt;span class="jwppp-instant"&gt;&lt;/span&gt;&lt;p&gt;Loading the player…&lt;/p&gt;
&lt;/div&gt;



&lt;p class="wp-block-paragraph"&gt;Vanessa Larco, partner at Premise and former partner at NEA, thinks 2026 will finally be the year of consumer AI.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Larco, who’s been investing in consumer and prosumer for years, thinks we’re about to see a shift in how consumers spend time online, with AI powering “concierge-like” services. The question is, will legacy consumer products like WebMD and TripAdvisor continue to exist as standalone apps, or will they just get absorbed into ChatGPT or Meta AI? And where can startups carve out an AI-powered niche for themselves?&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Watch as TechCrunch’s ⁠Rebecca Bellan sat down with Larco on Equity to talk about why consumer is back, what OpenAI &lt;em&gt;won’t &lt;/em&gt;kill, and where the real opportunities are hiding.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Subscribe to Equity on YouTube, Apple Podcasts, Overcast, Spotify, and all the casts. You also can follow Equity on X and Threads, at @EquityPod.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/meta-oakley.jpg?resize=1200,890" /&gt;&lt;/div&gt;&lt;div class="jwppp-video-box" id="jwppp-video-box-30808021"&gt;






&lt;span class="jwppp-instant"&gt;&lt;/span&gt;&lt;p&gt;Loading the player…&lt;/p&gt;
&lt;/div&gt;



&lt;p class="wp-block-paragraph"&gt;Vanessa Larco, partner at Premise and former partner at NEA, thinks 2026 will finally be the year of consumer AI.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Larco, who’s been investing in consumer and prosumer for years, thinks we’re about to see a shift in how consumers spend time online, with AI powering “concierge-like” services. The question is, will legacy consumer products like WebMD and TripAdvisor continue to exist as standalone apps, or will they just get absorbed into ChatGPT or Meta AI? And where can startups carve out an AI-powered niche for themselves?&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Watch as TechCrunch’s ⁠Rebecca Bellan sat down with Larco on Equity to talk about why consumer is back, what OpenAI &lt;em&gt;won’t &lt;/em&gt;kill, and where the real opportunities are hiding.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Subscribe to Equity on YouTube, Apple Podcasts, Overcast, Spotify, and all the casts. You also can follow Equity on X and Threads, at @EquityPod.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/video/where-vcs-think-ai-startups-can-win-even-with-openai-in-the-game/</guid><pubDate>Wed, 07 Jan 2026 18:53:35 +0000</pubDate></item><item><title>[NEW] Nous Research's NousCoder-14B is an open-source coding model landing right in the Claude Code moment (AI | VentureBeat)</title><link>https://venturebeat.com/technology/nous-researchs-nouscoder-14b-is-an-open-source-coding-model-landing-right-in</link><description>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://nousresearch.com/"&gt;Nous Research&lt;/a&gt;, the open-source artificial intelligence startup backed by crypto venture firm &lt;a href="https://www.paradigm.xyz/"&gt;Paradigm&lt;/a&gt;, released a new competitive programming model on Monday that it says matches or exceeds several larger proprietary systems — trained in just four days using 48 of Nvidia&amp;#x27;s latest &lt;a href="https://www.nvidia.com/en-us/data-center/dgx-b200/"&gt;B200 graphics processors&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The model, called &lt;a href="https://huggingface.co/NousResearch/NousCoder-14B"&gt;NousCoder-14B&lt;/a&gt;, is another entry in a crowded field of AI coding assistants, but arrives at a particularly charged moment: &lt;a href="https://claude.com/product/claude-code"&gt;Claude Code&lt;/a&gt;, the agentic programming tool from rival Anthropic, has dominated social media discussion since New Year&amp;#x27;s Day, with developers posting &lt;a href="https://x.com/0xDesigner/status/2008202211738648767?s=20"&gt;breathless&lt;/a&gt; &lt;a href="https://x.com/hayesdev_/status/2008043379805048948"&gt;testimonials&lt;/a&gt; &lt;a href="https://x.com/0xDesigner/status/2008202211738648767?s=20"&gt;about its capabilities&lt;/a&gt;. The simultaneous developments underscore how quickly AI-assisted software development is evolving — and how fiercely companies large and small are competing to capture what many believe will become a foundational technology for how software gets written.&lt;/p&gt;&lt;p&gt;&lt;span&gt;type: &lt;!-- --&gt;embedded-entry-inline&lt;!-- --&gt; id: &lt;!-- --&gt;74cSyrq6OUrp9SEQ5zOUSl&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/"&gt;NousCoder-14B&lt;/a&gt; achieves a 67.87 percent accuracy rate on &lt;a href="https://livecodebench.github.io/"&gt;LiveCodeBench v6&lt;/a&gt;, a standardized evaluation that tests models on competitive programming problems published between August 2024 and May 2025. That figure represents a 7.08 percentage point improvement over the base model it was trained from, Alibaba&amp;#x27;s &lt;a href="https://huggingface.co/Qwen/Qwen3-14B"&gt;Qwen3-14B&lt;/a&gt;, according to Nous Research&amp;#x27;s technical report published alongside the release.&lt;/p&gt;&lt;p&gt;&amp;quot;I gave Claude Code a description of the problem, it generated what we built last year in an hour,&amp;quot; &lt;a href="https://www.reddit.com/r/OpenAI/comments/1q2uuil/google_engineer_im_not_joking_and_this_isnt_funny/"&gt;wrote Jaana Dogan&lt;/a&gt;, a principal engineer at Google responsible for the Gemini API, in a viral post on X last week that captured the prevailing mood around AI coding tools. Dogan was describing a distributed agent orchestration system her team had spent a year developing — a system Claude Code approximated from a three-paragraph prompt.&lt;/p&gt;&lt;p&gt;The juxtaposition is instructive: while Anthropic&amp;#x27;s &lt;a href="https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are"&gt;Claude Code has captured imaginations&lt;/a&gt; with demonstrations of end-to-end software development, Nous Research is betting that open-source alternatives trained on verifiable problems can close the gap — and that transparency in how these models are built matters as much as raw capability.&lt;/p&gt;&lt;hr /&gt;&lt;h2&gt;&lt;b&gt;How Nous Research built an AI coding model that anyone can replicate&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;What distinguishes the &lt;a href="https://huggingface.co/NousResearch/NousCoder-14B"&gt;NousCoder-14B&lt;/a&gt; release from many competitor announcements is its radical openness. Nous Research published not just the &lt;a href="https://huggingface.co/NousResearch/NousCoder-14B"&gt;model weights&lt;/a&gt; but the &lt;a href="https://github.com/NousResearch/atropos/pull/296"&gt;complete reinforcement learning environment&lt;/a&gt;, benchmark suite, and training harness — built on the company&amp;#x27;s &lt;a href="https://github.com/NousResearch/atropos/pull/296"&gt;Atropos framework &lt;/a&gt;— enabling any researcher with sufficient compute to &lt;a href="https://wandb.ai/jli505/qwen14b/reports/HermesCoder-14B--VmlldzoxNTQ5Nzc0MQ?accessToken=4pt3stwyh4x83zqe2jgoo5j9b7j07jbe5omf2n40lray3tih17vfkavjootvnw8o"&gt;reproduce or extend the work&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&amp;quot;Open-sourcing the Atropos stack provides the necessary infrastructure for reproducible olympiad-level reasoning research,&amp;quot; &lt;a href="https://x.com/o_mega___/status/2008907268700475450?s=20"&gt;noted one observer on X&lt;/a&gt;, summarizing the significance for the academic and open-source communities.&lt;/p&gt;&lt;p&gt;The model was trained by &lt;a href="https://x.com/JoeLi5050"&gt;Joe Li&lt;/a&gt;, a researcher in residence at Nous Research and a former competitive programmer himself. Li&amp;#x27;s &lt;a href="https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/"&gt;technical report &lt;/a&gt;reveals an unexpectedly personal dimension: he compared the model&amp;#x27;s improvement trajectory to his own journey on Codeforces, the competitive programming platform where participants earn ratings based on contest performance.&lt;/p&gt;&lt;p&gt;Based on rough estimates mapping LiveCodeBench scores to Codeforces ratings, Li calculated that NousCoder-14B&amp;#x27;s improvemen t— from approximately the 1600-1750 rating range to 2100-2200 — mirrors a leap that took him nearly two years of sustained practice between ages 14 and 16. The model accomplished the equivalent in four days.&lt;/p&gt;&lt;p&gt;&amp;quot;Watching that final training run unfold was quite a surreal experience,&amp;quot; Li wrote in the technical report.&lt;/p&gt;&lt;p&gt;But Li was quick to note an important caveat that speaks to broader questions about AI efficiency: he solved roughly 1,000 problems during those two years, while the model required 24,000. Humans, at least for now, remain dramatically more sample-efficient learners.&lt;/p&gt;&lt;hr /&gt;&lt;h2&gt;&lt;b&gt;Inside the reinforcement learning system that trains on 24,000 competitive programming problems&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href="https://huggingface.co/NousResearch/NousCoder-14B"&gt;NousCoder-14B&lt;/a&gt;&amp;#x27;s training process offers a window into the increasingly sophisticated techniques researchers use to improve AI reasoning capabilities through reinforcement learning.&lt;/p&gt;&lt;p&gt;The approach relies on what researchers call &amp;quot;verifiable rewards&amp;quot; — a system where the model generates code solutions, those solutions are executed against test cases, and the model receives a simple binary signal: correct or incorrect. This feedback loop, while conceptually straightforward, requires significant infrastructure to execute at scale.&lt;/p&gt;&lt;p&gt;Nous Research used &lt;a href="https://modal.com/"&gt;Modal&lt;/a&gt;, a cloud computing platform, to run sandboxed code execution in parallel. Each of the 24,000 training problems contains hundreds of test cases on average, and the system must verify that generated code produces correct outputs within time and memory constraints — 15 seconds and 4 gigabytes, respectively.&lt;/p&gt;&lt;p&gt;The training employed a technique called &lt;a href="https://dapo-sia.github.io/"&gt;DAPO (Dynamic Sampling Policy Optimization)&lt;/a&gt;, which the researchers found performed slightly better than alternatives in their experiments. A key innovation involves &amp;quot;dynamic sampling&amp;quot; — discarding training examples where the model either solves all attempts or fails all attempts, since these provide no useful gradient signal for learning.&lt;/p&gt;&lt;p&gt;The researchers also adopted &amp;quot;iterative context extension,&amp;quot; first training the model with a 32,000-token context window before expanding to 40,000 tokens. During evaluation, extending the context further to approximately 80,000 tokens produced the best results, with accuracy reaching 67.87 percent.&lt;/p&gt;&lt;p&gt;Perhaps most significantly, the training pipeline overlaps inference and verification — as soon as the model generates a solution, it begins work on the next problem while the previous solution is being checked. This pipelining, combined with asynchronous training where multiple model instances work in parallel, maximizes hardware utilization on expensive GPU clusters.&lt;/p&gt;&lt;hr /&gt;&lt;h2&gt;&lt;b&gt;The looming data shortage that could slow AI coding model progress&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Buried in Li&amp;#x27;s &lt;a href="https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/"&gt;technical report&lt;/a&gt; is a finding with significant implications for the future of AI development: the training dataset for NousCoder-14B encompasses &amp;quot;a significant portion of all readily available, verifiable competitive programming problems in a standardized dataset format.&amp;quot;&lt;/p&gt;&lt;p&gt;In other words, for this particular domain, the researchers are approaching the limits of high-quality training data.&lt;/p&gt;&lt;p&gt;&amp;quot;The total number of competitive programming problems on the Internet is roughly the same order of magnitude,&amp;quot; Li wrote, referring to the 24,000 problems used for training. &amp;quot;This suggests that within the competitive programming domain, we have approached the limits of high-quality data.&amp;quot;&lt;/p&gt;&lt;p&gt;This observation echoes growing concern across the AI industry about data constraints. While compute continues to scale according to well-understood economic and engineering principles, training data is &amp;quot;increasingly finite,&amp;quot; as Li put it.&lt;/p&gt;&lt;p&gt;&amp;quot;It appears that some of the most important research that needs to be done in the future will be in the areas of synthetic data generation and data efficient algorithms and architectures,&amp;quot; he concluded.&lt;/p&gt;&lt;p&gt;The challenge is particularly acute for competitive programming because the domain requires problems with known correct solutions that can be verified automatically. Unlike natural language tasks where human evaluation or proxy metrics suffice, code either works or it doesn&amp;#x27;t — making synthetic data generation considerably more difficult.&lt;/p&gt;&lt;p&gt;Li identified one potential avenue: training models not just to solve problems but to generate solvable problems, enabling a form of self-play similar to techniques that proved successful in game-playing AI systems. &amp;quot;Once synthetic problem generation is solved, self-play becomes a very interesting direction,&amp;quot; he wrote.&lt;/p&gt;&lt;hr /&gt;&lt;h2&gt;&lt;b&gt;A $65 million bet that open-source AI can compete with Big Tech&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Nous Research has carved out a distinctive position in the AI landscape: a company committed to &lt;a href="https://nousresearch.com/"&gt;open-source releases&lt;/a&gt; that compete with — and sometimes exceed — proprietary alternatives.&lt;/p&gt;&lt;p&gt;The company raised&lt;a href="https://fortune.com/crypto/2025/04/25/paradigm-nous-research-crypto-ai-venture-capital-deepseek-openai-blockchain/"&gt; $50 million in April 2025&lt;/a&gt; in a round led by Paradigm, the cryptocurrency-focused venture firm founded by Coinbase co-founder Fred Ehrsam. Total funding reached $65 million, according to some reports. The investment reflected growing interest in decentralized approaches to AI training, an area where Nous Research has developed its &lt;a href="https://psyche.network/"&gt;Psyche platform&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Previous releases include &lt;a href="https://hermes4.nousresearch.com/"&gt;Hermes 4&lt;/a&gt;, a family of models that we reported &amp;quot;&lt;a href="https://venturebeat.com/ai/nous-research-drops-hermes-4-ai-models-that-outperform-chatgpt-without-content-restrictions"&gt;outperform ChatGPT without content restrictions&lt;/a&gt;,&amp;quot; and DeepHermes-3, which the company described as the first &amp;quot;&lt;a href="https://venturebeat.com/ai/personalized-unrestricted-ai-lab-nous-research-launches-first-toggle-on-reasoning-model-deephermes-3"&gt;toggle-on reasoning model&lt;/a&gt;&amp;quot; — allowing users to activate extended thinking capabilities on demand.&lt;/p&gt;&lt;p&gt;The company has cultivated a distinctive aesthetic and community, prompting some skepticism about whether style might overshadow substance. &amp;quot;Ofc i&amp;#x27;m gonna believe an anime pfp company. stop benchmarkmaxxing ffs,&amp;quot; &lt;a href="https://x.com/shydev69/status/2008654826356535510?s=20"&gt;wrote one critic on X&lt;/a&gt;, referring to Nous Research&amp;#x27;s anime-style branding and the industry practice of optimizing for benchmark performance.&lt;/p&gt;&lt;p&gt;Others raised technical questions. &amp;quot;&lt;a href="https://x.com/yehor_smoliakov/status/2008659681489940757?s=20"&gt;Based on the benchmark, Nemotron is better&lt;/a&gt;,&amp;quot; noted one commenter, referring to Nvidia&amp;#x27;s family of language models. Another asked whether &lt;a href="https://huggingface.co/NousResearch/NousCoder-14B"&gt;NousCoder-14B&lt;/a&gt; is &amp;quot;agentic focused or just &amp;#x27;one shot&amp;#x27; coding&amp;quot; — a distinction that matters for practical software development, where iterating on feedback typically produces better results than single attempts.&lt;/p&gt;&lt;hr /&gt;&lt;h2&gt;&lt;b&gt;What researchers say must happen next for AI coding tools to keep improving&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The release includes several directions for future work that hint at where AI coding research may be heading.&lt;/p&gt;&lt;p&gt;Multi-turn reinforcement learning tops the list. Currently, the model receives only a final binary reward — pass or fail — after generating a solution. But competitive programming problems typically include public test cases that provide intermediate feedback: compilation errors, incorrect outputs, time limit violations. Training models to incorporate this feedback across multiple attempts could significantly improve performance.&lt;/p&gt;&lt;p&gt;Controlling response length also remains a challenge. The researchers found that incorrect solutions tended to be longer than correct ones, and response lengths quickly saturated available context windows during training — a pattern that various algorithmic modifications failed to resolve.&lt;/p&gt;&lt;p&gt;Perhaps most ambitiously, Li proposed &amp;quot;problem generation and self-play&amp;quot; — training models to both solve and create programming problems. This would address the data scarcity problem directly by enabling models to generate their own training curricula.&lt;/p&gt;&lt;p&gt;&amp;quot;Humans are great at generating interesting and useful problems for other competitive programmers, but it appears that there still exists a significant gap in LLM capabilities in creative problem generation,&amp;quot; Li wrote.&lt;/p&gt;&lt;p&gt;The model is &lt;a href="https://huggingface.co/NousResearch/NousCoder-14B"&gt;available now on Hugging Face&lt;/a&gt; under an Apache 2.0 license. For researchers and developers who want to build on the work, Nous Research has published the complete &lt;a href="https://github.com/NousResearch/atropos/pull/296"&gt;Atropos training stack&lt;/a&gt; alongside it.&lt;/p&gt;&lt;p&gt;What took Li two years of adolescent dedication to achieve—climbing from a 1600-level novice to a 2100-rated competitor on Codeforces—an AI replicated in 96 hours. He needed 1,000 problems. The model needed 24,000. But soon enough, these systems may learn to write their own problems, teach themselves, and leave human benchmarks behind entirely.&lt;/p&gt;&lt;p&gt;The question is no longer whether machines can learn to code. It&amp;#x27;s whether they&amp;#x27;ll soon be better teachers than we ever were.&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://nousresearch.com/"&gt;Nous Research&lt;/a&gt;, the open-source artificial intelligence startup backed by crypto venture firm &lt;a href="https://www.paradigm.xyz/"&gt;Paradigm&lt;/a&gt;, released a new competitive programming model on Monday that it says matches or exceeds several larger proprietary systems — trained in just four days using 48 of Nvidia&amp;#x27;s latest &lt;a href="https://www.nvidia.com/en-us/data-center/dgx-b200/"&gt;B200 graphics processors&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The model, called &lt;a href="https://huggingface.co/NousResearch/NousCoder-14B"&gt;NousCoder-14B&lt;/a&gt;, is another entry in a crowded field of AI coding assistants, but arrives at a particularly charged moment: &lt;a href="https://claude.com/product/claude-code"&gt;Claude Code&lt;/a&gt;, the agentic programming tool from rival Anthropic, has dominated social media discussion since New Year&amp;#x27;s Day, with developers posting &lt;a href="https://x.com/0xDesigner/status/2008202211738648767?s=20"&gt;breathless&lt;/a&gt; &lt;a href="https://x.com/hayesdev_/status/2008043379805048948"&gt;testimonials&lt;/a&gt; &lt;a href="https://x.com/0xDesigner/status/2008202211738648767?s=20"&gt;about its capabilities&lt;/a&gt;. The simultaneous developments underscore how quickly AI-assisted software development is evolving — and how fiercely companies large and small are competing to capture what many believe will become a foundational technology for how software gets written.&lt;/p&gt;&lt;p&gt;&lt;span&gt;type: &lt;!-- --&gt;embedded-entry-inline&lt;!-- --&gt; id: &lt;!-- --&gt;74cSyrq6OUrp9SEQ5zOUSl&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/"&gt;NousCoder-14B&lt;/a&gt; achieves a 67.87 percent accuracy rate on &lt;a href="https://livecodebench.github.io/"&gt;LiveCodeBench v6&lt;/a&gt;, a standardized evaluation that tests models on competitive programming problems published between August 2024 and May 2025. That figure represents a 7.08 percentage point improvement over the base model it was trained from, Alibaba&amp;#x27;s &lt;a href="https://huggingface.co/Qwen/Qwen3-14B"&gt;Qwen3-14B&lt;/a&gt;, according to Nous Research&amp;#x27;s technical report published alongside the release.&lt;/p&gt;&lt;p&gt;&amp;quot;I gave Claude Code a description of the problem, it generated what we built last year in an hour,&amp;quot; &lt;a href="https://www.reddit.com/r/OpenAI/comments/1q2uuil/google_engineer_im_not_joking_and_this_isnt_funny/"&gt;wrote Jaana Dogan&lt;/a&gt;, a principal engineer at Google responsible for the Gemini API, in a viral post on X last week that captured the prevailing mood around AI coding tools. Dogan was describing a distributed agent orchestration system her team had spent a year developing — a system Claude Code approximated from a three-paragraph prompt.&lt;/p&gt;&lt;p&gt;The juxtaposition is instructive: while Anthropic&amp;#x27;s &lt;a href="https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are"&gt;Claude Code has captured imaginations&lt;/a&gt; with demonstrations of end-to-end software development, Nous Research is betting that open-source alternatives trained on verifiable problems can close the gap — and that transparency in how these models are built matters as much as raw capability.&lt;/p&gt;&lt;hr /&gt;&lt;h2&gt;&lt;b&gt;How Nous Research built an AI coding model that anyone can replicate&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;What distinguishes the &lt;a href="https://huggingface.co/NousResearch/NousCoder-14B"&gt;NousCoder-14B&lt;/a&gt; release from many competitor announcements is its radical openness. Nous Research published not just the &lt;a href="https://huggingface.co/NousResearch/NousCoder-14B"&gt;model weights&lt;/a&gt; but the &lt;a href="https://github.com/NousResearch/atropos/pull/296"&gt;complete reinforcement learning environment&lt;/a&gt;, benchmark suite, and training harness — built on the company&amp;#x27;s &lt;a href="https://github.com/NousResearch/atropos/pull/296"&gt;Atropos framework &lt;/a&gt;— enabling any researcher with sufficient compute to &lt;a href="https://wandb.ai/jli505/qwen14b/reports/HermesCoder-14B--VmlldzoxNTQ5Nzc0MQ?accessToken=4pt3stwyh4x83zqe2jgoo5j9b7j07jbe5omf2n40lray3tih17vfkavjootvnw8o"&gt;reproduce or extend the work&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&amp;quot;Open-sourcing the Atropos stack provides the necessary infrastructure for reproducible olympiad-level reasoning research,&amp;quot; &lt;a href="https://x.com/o_mega___/status/2008907268700475450?s=20"&gt;noted one observer on X&lt;/a&gt;, summarizing the significance for the academic and open-source communities.&lt;/p&gt;&lt;p&gt;The model was trained by &lt;a href="https://x.com/JoeLi5050"&gt;Joe Li&lt;/a&gt;, a researcher in residence at Nous Research and a former competitive programmer himself. Li&amp;#x27;s &lt;a href="https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/"&gt;technical report &lt;/a&gt;reveals an unexpectedly personal dimension: he compared the model&amp;#x27;s improvement trajectory to his own journey on Codeforces, the competitive programming platform where participants earn ratings based on contest performance.&lt;/p&gt;&lt;p&gt;Based on rough estimates mapping LiveCodeBench scores to Codeforces ratings, Li calculated that NousCoder-14B&amp;#x27;s improvemen t— from approximately the 1600-1750 rating range to 2100-2200 — mirrors a leap that took him nearly two years of sustained practice between ages 14 and 16. The model accomplished the equivalent in four days.&lt;/p&gt;&lt;p&gt;&amp;quot;Watching that final training run unfold was quite a surreal experience,&amp;quot; Li wrote in the technical report.&lt;/p&gt;&lt;p&gt;But Li was quick to note an important caveat that speaks to broader questions about AI efficiency: he solved roughly 1,000 problems during those two years, while the model required 24,000. Humans, at least for now, remain dramatically more sample-efficient learners.&lt;/p&gt;&lt;hr /&gt;&lt;h2&gt;&lt;b&gt;Inside the reinforcement learning system that trains on 24,000 competitive programming problems&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href="https://huggingface.co/NousResearch/NousCoder-14B"&gt;NousCoder-14B&lt;/a&gt;&amp;#x27;s training process offers a window into the increasingly sophisticated techniques researchers use to improve AI reasoning capabilities through reinforcement learning.&lt;/p&gt;&lt;p&gt;The approach relies on what researchers call &amp;quot;verifiable rewards&amp;quot; — a system where the model generates code solutions, those solutions are executed against test cases, and the model receives a simple binary signal: correct or incorrect. This feedback loop, while conceptually straightforward, requires significant infrastructure to execute at scale.&lt;/p&gt;&lt;p&gt;Nous Research used &lt;a href="https://modal.com/"&gt;Modal&lt;/a&gt;, a cloud computing platform, to run sandboxed code execution in parallel. Each of the 24,000 training problems contains hundreds of test cases on average, and the system must verify that generated code produces correct outputs within time and memory constraints — 15 seconds and 4 gigabytes, respectively.&lt;/p&gt;&lt;p&gt;The training employed a technique called &lt;a href="https://dapo-sia.github.io/"&gt;DAPO (Dynamic Sampling Policy Optimization)&lt;/a&gt;, which the researchers found performed slightly better than alternatives in their experiments. A key innovation involves &amp;quot;dynamic sampling&amp;quot; — discarding training examples where the model either solves all attempts or fails all attempts, since these provide no useful gradient signal for learning.&lt;/p&gt;&lt;p&gt;The researchers also adopted &amp;quot;iterative context extension,&amp;quot; first training the model with a 32,000-token context window before expanding to 40,000 tokens. During evaluation, extending the context further to approximately 80,000 tokens produced the best results, with accuracy reaching 67.87 percent.&lt;/p&gt;&lt;p&gt;Perhaps most significantly, the training pipeline overlaps inference and verification — as soon as the model generates a solution, it begins work on the next problem while the previous solution is being checked. This pipelining, combined with asynchronous training where multiple model instances work in parallel, maximizes hardware utilization on expensive GPU clusters.&lt;/p&gt;&lt;hr /&gt;&lt;h2&gt;&lt;b&gt;The looming data shortage that could slow AI coding model progress&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Buried in Li&amp;#x27;s &lt;a href="https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/"&gt;technical report&lt;/a&gt; is a finding with significant implications for the future of AI development: the training dataset for NousCoder-14B encompasses &amp;quot;a significant portion of all readily available, verifiable competitive programming problems in a standardized dataset format.&amp;quot;&lt;/p&gt;&lt;p&gt;In other words, for this particular domain, the researchers are approaching the limits of high-quality training data.&lt;/p&gt;&lt;p&gt;&amp;quot;The total number of competitive programming problems on the Internet is roughly the same order of magnitude,&amp;quot; Li wrote, referring to the 24,000 problems used for training. &amp;quot;This suggests that within the competitive programming domain, we have approached the limits of high-quality data.&amp;quot;&lt;/p&gt;&lt;p&gt;This observation echoes growing concern across the AI industry about data constraints. While compute continues to scale according to well-understood economic and engineering principles, training data is &amp;quot;increasingly finite,&amp;quot; as Li put it.&lt;/p&gt;&lt;p&gt;&amp;quot;It appears that some of the most important research that needs to be done in the future will be in the areas of synthetic data generation and data efficient algorithms and architectures,&amp;quot; he concluded.&lt;/p&gt;&lt;p&gt;The challenge is particularly acute for competitive programming because the domain requires problems with known correct solutions that can be verified automatically. Unlike natural language tasks where human evaluation or proxy metrics suffice, code either works or it doesn&amp;#x27;t — making synthetic data generation considerably more difficult.&lt;/p&gt;&lt;p&gt;Li identified one potential avenue: training models not just to solve problems but to generate solvable problems, enabling a form of self-play similar to techniques that proved successful in game-playing AI systems. &amp;quot;Once synthetic problem generation is solved, self-play becomes a very interesting direction,&amp;quot; he wrote.&lt;/p&gt;&lt;hr /&gt;&lt;h2&gt;&lt;b&gt;A $65 million bet that open-source AI can compete with Big Tech&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Nous Research has carved out a distinctive position in the AI landscape: a company committed to &lt;a href="https://nousresearch.com/"&gt;open-source releases&lt;/a&gt; that compete with — and sometimes exceed — proprietary alternatives.&lt;/p&gt;&lt;p&gt;The company raised&lt;a href="https://fortune.com/crypto/2025/04/25/paradigm-nous-research-crypto-ai-venture-capital-deepseek-openai-blockchain/"&gt; $50 million in April 2025&lt;/a&gt; in a round led by Paradigm, the cryptocurrency-focused venture firm founded by Coinbase co-founder Fred Ehrsam. Total funding reached $65 million, according to some reports. The investment reflected growing interest in decentralized approaches to AI training, an area where Nous Research has developed its &lt;a href="https://psyche.network/"&gt;Psyche platform&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Previous releases include &lt;a href="https://hermes4.nousresearch.com/"&gt;Hermes 4&lt;/a&gt;, a family of models that we reported &amp;quot;&lt;a href="https://venturebeat.com/ai/nous-research-drops-hermes-4-ai-models-that-outperform-chatgpt-without-content-restrictions"&gt;outperform ChatGPT without content restrictions&lt;/a&gt;,&amp;quot; and DeepHermes-3, which the company described as the first &amp;quot;&lt;a href="https://venturebeat.com/ai/personalized-unrestricted-ai-lab-nous-research-launches-first-toggle-on-reasoning-model-deephermes-3"&gt;toggle-on reasoning model&lt;/a&gt;&amp;quot; — allowing users to activate extended thinking capabilities on demand.&lt;/p&gt;&lt;p&gt;The company has cultivated a distinctive aesthetic and community, prompting some skepticism about whether style might overshadow substance. &amp;quot;Ofc i&amp;#x27;m gonna believe an anime pfp company. stop benchmarkmaxxing ffs,&amp;quot; &lt;a href="https://x.com/shydev69/status/2008654826356535510?s=20"&gt;wrote one critic on X&lt;/a&gt;, referring to Nous Research&amp;#x27;s anime-style branding and the industry practice of optimizing for benchmark performance.&lt;/p&gt;&lt;p&gt;Others raised technical questions. &amp;quot;&lt;a href="https://x.com/yehor_smoliakov/status/2008659681489940757?s=20"&gt;Based on the benchmark, Nemotron is better&lt;/a&gt;,&amp;quot; noted one commenter, referring to Nvidia&amp;#x27;s family of language models. Another asked whether &lt;a href="https://huggingface.co/NousResearch/NousCoder-14B"&gt;NousCoder-14B&lt;/a&gt; is &amp;quot;agentic focused or just &amp;#x27;one shot&amp;#x27; coding&amp;quot; — a distinction that matters for practical software development, where iterating on feedback typically produces better results than single attempts.&lt;/p&gt;&lt;hr /&gt;&lt;h2&gt;&lt;b&gt;What researchers say must happen next for AI coding tools to keep improving&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The release includes several directions for future work that hint at where AI coding research may be heading.&lt;/p&gt;&lt;p&gt;Multi-turn reinforcement learning tops the list. Currently, the model receives only a final binary reward — pass or fail — after generating a solution. But competitive programming problems typically include public test cases that provide intermediate feedback: compilation errors, incorrect outputs, time limit violations. Training models to incorporate this feedback across multiple attempts could significantly improve performance.&lt;/p&gt;&lt;p&gt;Controlling response length also remains a challenge. The researchers found that incorrect solutions tended to be longer than correct ones, and response lengths quickly saturated available context windows during training — a pattern that various algorithmic modifications failed to resolve.&lt;/p&gt;&lt;p&gt;Perhaps most ambitiously, Li proposed &amp;quot;problem generation and self-play&amp;quot; — training models to both solve and create programming problems. This would address the data scarcity problem directly by enabling models to generate their own training curricula.&lt;/p&gt;&lt;p&gt;&amp;quot;Humans are great at generating interesting and useful problems for other competitive programmers, but it appears that there still exists a significant gap in LLM capabilities in creative problem generation,&amp;quot; Li wrote.&lt;/p&gt;&lt;p&gt;The model is &lt;a href="https://huggingface.co/NousResearch/NousCoder-14B"&gt;available now on Hugging Face&lt;/a&gt; under an Apache 2.0 license. For researchers and developers who want to build on the work, Nous Research has published the complete &lt;a href="https://github.com/NousResearch/atropos/pull/296"&gt;Atropos training stack&lt;/a&gt; alongside it.&lt;/p&gt;&lt;p&gt;What took Li two years of adolescent dedication to achieve—climbing from a 1600-level novice to a 2100-rated competitor on Codeforces—an AI replicated in 96 hours. He needed 1,000 problems. The model needed 24,000. But soon enough, these systems may learn to write their own problems, teach themselves, and leave human benchmarks behind entirely.&lt;/p&gt;&lt;p&gt;The question is no longer whether machines can learn to code. It&amp;#x27;s whether they&amp;#x27;ll soon be better teachers than we ever were.&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/technology/nous-researchs-nouscoder-14b-is-an-open-source-coding-model-landing-right-in</guid><pubDate>Wed, 07 Jan 2026 20:00:00 +0000</pubDate></item><item><title>[NEW] Stone Center on Inequality and Shaping the Future of Work Launches at MIT (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2026/stone-center-inequality-shaping-future-work-launches-0107</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202512/mit-stone-center-launch.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;The James M. and Cathleen D. Stone Center on Inequality and Shaping the Future of Work officially&amp;nbsp;launched on Nov. 3, 2025, bringing together scholars, policymakers, and practitioners to explore critical questions about economic opportunity, technology, and democracy.&lt;/p&gt;&lt;p&gt;Co-directed by MIT professors&amp;nbsp;Daron Acemoglu,&amp;nbsp;David Autor, and&amp;nbsp;Simon Johnson, the new&amp;nbsp;Stone Center analyzes the forces that contribute to growing income and wealth inequality through the erosion of job quality and labor market opportunities for workers without a college degree. The center identifies innovative ways to move the economy onto a more equitable trajectory.&lt;/p&gt;&lt;p&gt;MIT Provost&amp;nbsp;Anantha Chandrakasan&amp;nbsp;opened the launch event by emphasizing the urgency and importance of the center's mission. “As artificial intelligence tools become more powerful, and as they are deployed more broadly,” he said, “we will need to strive to ensure that people from all kinds of backgrounds can find opportunity in the economy.”&lt;/p&gt;&lt;p&gt;Here are some of the key takeaways from participants in the afternoon’s discussions on&amp;nbsp;wealth inequality,&amp;nbsp;liberalism, and&amp;nbsp;pro-worker AI.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Wealth inequality is driven by private business and public policy&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Owen Zidar of Princeton University stressed that owners of businesses like car dealerships, construction firms, and franchises make up a significant portion of the top 1 percent. “For every public company CEO that gets a lot of attention,” he explained, “there are a thousand private business owners who have at least $25 million in wealth.” These business owners have outsized political influence through overrepresentation, lobbying, and donations.&lt;/p&gt;&lt;p&gt;Atif Mian of Princeton University connected high inequality to the U.S. debt crisis, arguing that massive savings at the top aren’t being channeled into productive investment. Instead, falling interest rates push the government to run increasingly large fiscal deficits.&lt;/p&gt;&lt;p&gt;To mitigate wealth inequality, speakers highlighted policy proposals including rolling back the 20 percent deduction for private business owners and increasing taxes on wealth.&lt;/p&gt;&lt;p&gt;However, policies must be carefully designed.&amp;nbsp;Antoinette Schoar of the MIT Sloan School of Management explained how mortgage subsidy policies after the 2008 financial crisis actually worsened inequality by disadvantaging poorer potential homeowners.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Governments must provide basic public goods and economic security&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Marc Dunkelman of the Watson School of International and Public Affairs at Brown University identified excessive red tape as a key problem for modern liberal democracy. “We can’t build high-speed rail. You can’t build enough housing,” he explained. “That spurs ordinary people who want government to work into the populist camp. We did this to ourselves.”&lt;/p&gt;&lt;p&gt;Josh Cohen of Apple University/the University of California at Berkeley emphasized that liberalism must deliver shared prosperity and fair opportunities, not just protect individual freedoms. When people lack economic security, they may turn to leaders who abandon liberal principles altogether.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Liberal democracy needs to adapt while keeping its core values&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Helena Rosenblatt Dhar of the City University of New York Graduate Center noted that liberalism and democracy have not always been allies. Historically, “civil equality was very important, but not political equality,” she said. “Liberals were very wary of the masses.”&lt;/p&gt;&lt;p&gt;Speakers emphasized that liberalism’s challenge today is maintaining its commitments to limiting authoritarian power and protecting fundamental freedoms, while addressing its failures.&lt;/p&gt;&lt;p&gt;Doing so, in Dunkelman’s view, would mean working to “eliminate the sowing [of] the seeds of populism by making government properly balance individual rights and the will of the many.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;People-centric politics requires regulating social media&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;In&amp;nbsp;his keynote at the launch, U.S. Representative&amp;nbsp;Jake Auchincloss (Massachusetts 4th District) connected these notions of government effectiveness and public trust to the influence of technology. He emphasized the need to regulate social media platforms.&lt;/p&gt;&lt;p&gt;“In my opinion, media is upstream of culture, which is upstream of politics,” he said. “If we want a better culture, and certainly if we want a better politics, we need a better media.”&lt;/p&gt;&lt;p&gt;Auchincloss proposed that regulation should include holding social media companies liable for content and banning targeted advertising to minors.&lt;/p&gt;&lt;p&gt;He also echoed the urgency and importance of the center’s research agenda, particularly to understand whether AI will augment or replace labor.&lt;/p&gt;&lt;p&gt;“My bias has always been: Technology creates more jobs,” he said. “Maybe it’s different this time. Maybe I’m wrong.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Augmentation is key to pro-worker AI — but it may require alternative AI architectures&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Stone Center co-director Daron Acemoglu argued that expanding what humans can do, rather than automating their tasks, is essential for achieving pro-worker AI.&lt;/p&gt;&lt;p&gt;However, Acemoglu cautioned that this won’t happen by itself, noting that the business models of tech companies and their focus on artificial general intelligence are not aligned with a pro-worker vision for AI. This vision may require public investment in alternative AI architectures focused on “domain-specific, reliable knowledge.”&lt;/p&gt;&lt;p&gt;Ethan Mollick of the Wharton School of the University of Pennsylvania noted that AI labs are explicitly trying to “replace people at everything” and are “absolutely convinced that they can do this in the very near term.”&lt;/p&gt;&lt;p&gt;Meanwhile, companies have “no model for AI adoption,” Mollick explained. “There is absolute confusion.” Even so, “there’s enough money at stake [that] the machine keeps moving forward,” underscoring the urgency of intervention.&lt;/p&gt;&lt;p&gt;In a glimpse of what such intervention could look like,&amp;nbsp;Zana Buçinca of Microsoft shared research findings that accounting for workers’ values and cognition in AI design can enable better complementarity.&lt;/p&gt;&lt;p&gt;“The impact of AI on human work is not destiny,” she emphasized. “It’s design.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202512/mit-stone-center-launch.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;The James M. and Cathleen D. Stone Center on Inequality and Shaping the Future of Work officially&amp;nbsp;launched on Nov. 3, 2025, bringing together scholars, policymakers, and practitioners to explore critical questions about economic opportunity, technology, and democracy.&lt;/p&gt;&lt;p&gt;Co-directed by MIT professors&amp;nbsp;Daron Acemoglu,&amp;nbsp;David Autor, and&amp;nbsp;Simon Johnson, the new&amp;nbsp;Stone Center analyzes the forces that contribute to growing income and wealth inequality through the erosion of job quality and labor market opportunities for workers without a college degree. The center identifies innovative ways to move the economy onto a more equitable trajectory.&lt;/p&gt;&lt;p&gt;MIT Provost&amp;nbsp;Anantha Chandrakasan&amp;nbsp;opened the launch event by emphasizing the urgency and importance of the center's mission. “As artificial intelligence tools become more powerful, and as they are deployed more broadly,” he said, “we will need to strive to ensure that people from all kinds of backgrounds can find opportunity in the economy.”&lt;/p&gt;&lt;p&gt;Here are some of the key takeaways from participants in the afternoon’s discussions on&amp;nbsp;wealth inequality,&amp;nbsp;liberalism, and&amp;nbsp;pro-worker AI.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Wealth inequality is driven by private business and public policy&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Owen Zidar of Princeton University stressed that owners of businesses like car dealerships, construction firms, and franchises make up a significant portion of the top 1 percent. “For every public company CEO that gets a lot of attention,” he explained, “there are a thousand private business owners who have at least $25 million in wealth.” These business owners have outsized political influence through overrepresentation, lobbying, and donations.&lt;/p&gt;&lt;p&gt;Atif Mian of Princeton University connected high inequality to the U.S. debt crisis, arguing that massive savings at the top aren’t being channeled into productive investment. Instead, falling interest rates push the government to run increasingly large fiscal deficits.&lt;/p&gt;&lt;p&gt;To mitigate wealth inequality, speakers highlighted policy proposals including rolling back the 20 percent deduction for private business owners and increasing taxes on wealth.&lt;/p&gt;&lt;p&gt;However, policies must be carefully designed.&amp;nbsp;Antoinette Schoar of the MIT Sloan School of Management explained how mortgage subsidy policies after the 2008 financial crisis actually worsened inequality by disadvantaging poorer potential homeowners.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Governments must provide basic public goods and economic security&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Marc Dunkelman of the Watson School of International and Public Affairs at Brown University identified excessive red tape as a key problem for modern liberal democracy. “We can’t build high-speed rail. You can’t build enough housing,” he explained. “That spurs ordinary people who want government to work into the populist camp. We did this to ourselves.”&lt;/p&gt;&lt;p&gt;Josh Cohen of Apple University/the University of California at Berkeley emphasized that liberalism must deliver shared prosperity and fair opportunities, not just protect individual freedoms. When people lack economic security, they may turn to leaders who abandon liberal principles altogether.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Liberal democracy needs to adapt while keeping its core values&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Helena Rosenblatt Dhar of the City University of New York Graduate Center noted that liberalism and democracy have not always been allies. Historically, “civil equality was very important, but not political equality,” she said. “Liberals were very wary of the masses.”&lt;/p&gt;&lt;p&gt;Speakers emphasized that liberalism’s challenge today is maintaining its commitments to limiting authoritarian power and protecting fundamental freedoms, while addressing its failures.&lt;/p&gt;&lt;p&gt;Doing so, in Dunkelman’s view, would mean working to “eliminate the sowing [of] the seeds of populism by making government properly balance individual rights and the will of the many.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;People-centric politics requires regulating social media&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;In&amp;nbsp;his keynote at the launch, U.S. Representative&amp;nbsp;Jake Auchincloss (Massachusetts 4th District) connected these notions of government effectiveness and public trust to the influence of technology. He emphasized the need to regulate social media platforms.&lt;/p&gt;&lt;p&gt;“In my opinion, media is upstream of culture, which is upstream of politics,” he said. “If we want a better culture, and certainly if we want a better politics, we need a better media.”&lt;/p&gt;&lt;p&gt;Auchincloss proposed that regulation should include holding social media companies liable for content and banning targeted advertising to minors.&lt;/p&gt;&lt;p&gt;He also echoed the urgency and importance of the center’s research agenda, particularly to understand whether AI will augment or replace labor.&lt;/p&gt;&lt;p&gt;“My bias has always been: Technology creates more jobs,” he said. “Maybe it’s different this time. Maybe I’m wrong.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Augmentation is key to pro-worker AI — but it may require alternative AI architectures&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Stone Center co-director Daron Acemoglu argued that expanding what humans can do, rather than automating their tasks, is essential for achieving pro-worker AI.&lt;/p&gt;&lt;p&gt;However, Acemoglu cautioned that this won’t happen by itself, noting that the business models of tech companies and their focus on artificial general intelligence are not aligned with a pro-worker vision for AI. This vision may require public investment in alternative AI architectures focused on “domain-specific, reliable knowledge.”&lt;/p&gt;&lt;p&gt;Ethan Mollick of the Wharton School of the University of Pennsylvania noted that AI labs are explicitly trying to “replace people at everything” and are “absolutely convinced that they can do this in the very near term.”&lt;/p&gt;&lt;p&gt;Meanwhile, companies have “no model for AI adoption,” Mollick explained. “There is absolute confusion.” Even so, “there’s enough money at stake [that] the machine keeps moving forward,” underscoring the urgency of intervention.&lt;/p&gt;&lt;p&gt;In a glimpse of what such intervention could look like,&amp;nbsp;Zana Buçinca of Microsoft shared research findings that accounting for workers’ values and cognition in AI design can enable better complementarity.&lt;/p&gt;&lt;p&gt;“The impact of AI on human work is not destiny,” she emphasized. “It’s design.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2026/stone-center-inequality-shaping-future-work-launches-0107</guid><pubDate>Wed, 07 Jan 2026 20:30:00 +0000</pubDate></item><item><title>[NEW] OpenAI unveils ChatGPT Health, says 230 million users ask about health each week (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/07/openai-unveils-chatgpt-health-says-230-million-users-ask-about-health-each-week/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/chatgpt-health1.webp?resize=1200,857" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI announced ChatGPT Health on Wednesday, which the company said will offer a dedicated space for users to have conversations with ChatGPT about their health.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;People already use ChatGPT to ask about medical issues; OpenAI says that over 230 million people ask health and wellness questions on the platform each week. But the ChatGPT Health product silos these conversations away from your other chats. That way, the context of your health won’t come up in standard conversations with ChatGPT. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;If people start chats about their health outside of the Health section, then the AI aims to nudge them to switch over.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Within Health, the AI might reference things you’ve discussed in its standard experience. If you ask ChatGPT for help constructing a marathon training plan, for example, then the AI would know you’re a runner when you talk in Health about your fitness goals.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT Health will also be able to integrate with your personal information or medical records from wellness apps like Apple Health, Function, and MyFitnessPal. OpenAI notes that it will not use Health conversations to train its models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The CEO of Applications at OpenAI, Fidji Simo, wrote in a blog post that she sees ChatGPT Health as a response to existing issues in the healthcare space, like cost and access barriers, overbooked doctors, and a lack of continuity in care.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the healthcare system has its drawbacks, using AI chatbots for medical advice creates a new slew of challenges. Large language models (LLMs) like ChatGPT operate by predicting the most likely response to prompts, not the most correct answer, since LLMs don’t have a concept of what is true or not. AI models are also prone to hallucinations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its own terms of service, OpenAI states that it is “not intended for use in the diagnosis or treatment of any health condition.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The feature is expected to roll out in the coming weeks.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/chatgpt-health1.webp?resize=1200,857" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI announced ChatGPT Health on Wednesday, which the company said will offer a dedicated space for users to have conversations with ChatGPT about their health.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;People already use ChatGPT to ask about medical issues; OpenAI says that over 230 million people ask health and wellness questions on the platform each week. But the ChatGPT Health product silos these conversations away from your other chats. That way, the context of your health won’t come up in standard conversations with ChatGPT. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;If people start chats about their health outside of the Health section, then the AI aims to nudge them to switch over.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Within Health, the AI might reference things you’ve discussed in its standard experience. If you ask ChatGPT for help constructing a marathon training plan, for example, then the AI would know you’re a runner when you talk in Health about your fitness goals.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT Health will also be able to integrate with your personal information or medical records from wellness apps like Apple Health, Function, and MyFitnessPal. OpenAI notes that it will not use Health conversations to train its models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The CEO of Applications at OpenAI, Fidji Simo, wrote in a blog post that she sees ChatGPT Health as a response to existing issues in the healthcare space, like cost and access barriers, overbooked doctors, and a lack of continuity in care.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the healthcare system has its drawbacks, using AI chatbots for medical advice creates a new slew of challenges. Large language models (LLMs) like ChatGPT operate by predicting the most likely response to prompts, not the most correct answer, since LLMs don’t have a concept of what is true or not. AI models are also prone to hallucinations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its own terms of service, OpenAI states that it is “not intended for use in the diagnosis or treatment of any health condition.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The feature is expected to roll out in the coming weeks.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/07/openai-unveils-chatgpt-health-says-230-million-users-ask-about-health-each-week/</guid><pubDate>Wed, 07 Jan 2026 21:08:23 +0000</pubDate></item><item><title>[NEW] AI starts autonomously writing prescription refills in Utah (AI - Ars Technica)</title><link>https://arstechnica.com/health/2026/01/utah-allows-ai-to-autonomously-prescribe-medication-refills/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The program allows patients in the state to get prescription refills for 190 common meds.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="200" src="https://cdn.arstechnica.net/wp-content/uploads/2017/05/GettyImages-513084906-300x200.jpg" width="300" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2017/05/GettyImages-513084906-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Getty | Roberto Machado Noa

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The state of Utah is allowing artificial intelligence to prescribe medication refills to patients without direct human oversight in a pilot program public advocates call “dangerous.”&lt;/p&gt;
&lt;p&gt;The program is through the state’s “regulatory sandbox” framework, which allows businesses to trial “innovative” products or services with state regulations temporarily waived. The Utah Department of Commerce partnered with Doctronic, a telehealth startup with an AI chatbot.&lt;/p&gt;
&lt;p&gt;Doctronic offers a nationwide service that allows patients to chat with its “AI doctor” for free, then, for $39, book a virtual appointment with a real doctor licensed in their state. But patients must go through the AI chatbot first to get an appointment.&lt;/p&gt;
&lt;p&gt;According to a non-peer-reviewed preprint article from Doctronic, which looked at 500 telehealth cases in its service, the company claims its AI’s diagnosis matched the diagnosis made by a real clinician in 81 percent of cases. The AI’s treatment plan was “consistent” with that of a doctor’s in 99 percent of the cases.&lt;/p&gt;
&lt;p&gt;Now, for patients in Utah, Doctronic’s chatbot can refill a prescription without a doctor, for a $4 service fee . After a patient signs in and verifies state residency, the AI chatbot can pull up the patient’s prescription history and offer a list of prescription medications eligible for a refill. According to Politico, the chatbot will only be able to renew prescriptions for 190 common medications for chronic conditions, with key exclusions, such as medications for pain and ADHD, and those that are injected.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Caution&lt;/h2&gt;
&lt;p&gt;The first 250 renewals for each drug class will be reviewed by real doctors, but after that, the AI chatbot will be on its own. Adam Oskowitz, Doctronic co-founder and a professor at the University of California, San Francisco, told Politico that the AI chatbot is designed to err on the side of safety and escalate any case with uncertainty to a real doctor.&lt;/p&gt;
&lt;p&gt;“Utah’s approach to regulatory mitigation strikes a vital balance between fostering innovation and ensuring consumer safety,” Margaret Woolley Busse, executive director of the Utah Department of Commerce, said in a statement.&lt;/p&gt;
&lt;p&gt;For now, it’s unclear if the Food and Drug Administration will step in to regulate AI prescribing. On the one hand, prescription renewals are a matter of practicing medicine, which falls under state governance. However, Politico notes that the FDA has said that it has the authority to regulate medical devices used to diagnose, treat, or prevent disease.&lt;/p&gt;
&lt;p&gt;In a statement, Robert Steinbrook, health research group director at watchdog Public Citizen, blasted Doctronic’s program and the lack of oversight. “AI should not be autonomously refilling prescriptions, nor identifying itself as an ‘AI doctor,'” Steinbrook said.&lt;/p&gt;
&lt;p&gt;“Although the thoughtful application of AI can help to improve aspects of medical care, the Utah pilot program is a dangerous first step toward more autonomous medical practice,” he said."The FDA and other federal regulatory agencies cannot look the other way when AI applications undermine the essential human clinician role in prescribing and renewing medications.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The program allows patients in the state to get prescription refills for 190 common meds.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="200" src="https://cdn.arstechnica.net/wp-content/uploads/2017/05/GettyImages-513084906-300x200.jpg" width="300" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2017/05/GettyImages-513084906-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Getty | Roberto Machado Noa

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The state of Utah is allowing artificial intelligence to prescribe medication refills to patients without direct human oversight in a pilot program public advocates call “dangerous.”&lt;/p&gt;
&lt;p&gt;The program is through the state’s “regulatory sandbox” framework, which allows businesses to trial “innovative” products or services with state regulations temporarily waived. The Utah Department of Commerce partnered with Doctronic, a telehealth startup with an AI chatbot.&lt;/p&gt;
&lt;p&gt;Doctronic offers a nationwide service that allows patients to chat with its “AI doctor” for free, then, for $39, book a virtual appointment with a real doctor licensed in their state. But patients must go through the AI chatbot first to get an appointment.&lt;/p&gt;
&lt;p&gt;According to a non-peer-reviewed preprint article from Doctronic, which looked at 500 telehealth cases in its service, the company claims its AI’s diagnosis matched the diagnosis made by a real clinician in 81 percent of cases. The AI’s treatment plan was “consistent” with that of a doctor’s in 99 percent of the cases.&lt;/p&gt;
&lt;p&gt;Now, for patients in Utah, Doctronic’s chatbot can refill a prescription without a doctor, for a $4 service fee . After a patient signs in and verifies state residency, the AI chatbot can pull up the patient’s prescription history and offer a list of prescription medications eligible for a refill. According to Politico, the chatbot will only be able to renew prescriptions for 190 common medications for chronic conditions, with key exclusions, such as medications for pain and ADHD, and those that are injected.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Caution&lt;/h2&gt;
&lt;p&gt;The first 250 renewals for each drug class will be reviewed by real doctors, but after that, the AI chatbot will be on its own. Adam Oskowitz, Doctronic co-founder and a professor at the University of California, San Francisco, told Politico that the AI chatbot is designed to err on the side of safety and escalate any case with uncertainty to a real doctor.&lt;/p&gt;
&lt;p&gt;“Utah’s approach to regulatory mitigation strikes a vital balance between fostering innovation and ensuring consumer safety,” Margaret Woolley Busse, executive director of the Utah Department of Commerce, said in a statement.&lt;/p&gt;
&lt;p&gt;For now, it’s unclear if the Food and Drug Administration will step in to regulate AI prescribing. On the one hand, prescription renewals are a matter of practicing medicine, which falls under state governance. However, Politico notes that the FDA has said that it has the authority to regulate medical devices used to diagnose, treat, or prevent disease.&lt;/p&gt;
&lt;p&gt;In a statement, Robert Steinbrook, health research group director at watchdog Public Citizen, blasted Doctronic’s program and the lack of oversight. “AI should not be autonomously refilling prescriptions, nor identifying itself as an ‘AI doctor,'” Steinbrook said.&lt;/p&gt;
&lt;p&gt;“Although the thoughtful application of AI can help to improve aspects of medical care, the Utah pilot program is a dangerous first step toward more autonomous medical practice,” he said."The FDA and other federal regulatory agencies cannot look the other way when AI applications undermine the essential human clinician role in prescribing and renewing medications.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/health/2026/01/utah-allows-ai-to-autonomously-prescribe-medication-refills/</guid><pubDate>Wed, 07 Jan 2026 22:20:08 +0000</pubDate></item><item><title>[NEW] Ford has an AI assistant and new hands-free BlueCruise tech on the way (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/07/ford-has-an-ai-assistant-and-new-hands-free-bluecruise-tech-on-the-way/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/ford-ai-assistant.jpg?w=589" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Ford is developing an AI assistant that will debut in the company’s smartphone app, before expanding to its vehicles in 2027, the company announced Wednesday at the 2026 Consumer Electronics Show. The company also teased a next-generation of its BlueCruise advanced driver assistance system that is both cheaper to make and more capable — ultimately leading to eyes-off driving in 2028.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Wednesday’s announcement was one of the only ones to come from a major automaker at CES, marking a sharp turnaround from the late 2010s when they dominated the show. And it wasn’t made at a flashy keynote event; rather, Ford discussed the news at a speaker session called “Great Minds” that was meant to “explore the intersection of technology and humanity.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Ford says it digital assistant is hosted by Google Cloud and will be built using off-the-shelf LLMs, and the company is giving it deep access to vehicle-specific information. That means the assistant can answer high-level questions like “how many bags of mulch can my truck bed support?” But it also means owners will be able to ask for granular, real-time information like oil life. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is rolling the assistant out to its newly revamped Ford app in early 2026. A native, in-vehicle integration will come in 2027, though the company wouldn’t specify which models it’s prioritizing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ford didn’t go into great detail about what the in-car experience will look like, but it’s not hard to imagine the possibilities when looking at some of the more tech-forward automakers. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Just last month, Rivian showed off its own digital assistant sending and receiving text messages, handling complex navigation requests, and changing climate controls. Tesla has integrated Elon Musk’s chatbot Grok in its vehicles, which customers have used to generate on-the-spot sightseeing tours. Some of those capabilities may eclipse what Ford has in mind, but the automaker also has a full year to hammer out the in-car integration.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new BlueCruise system teased on Wednesday is 30% cheaper to build than the current technology, according to Ford. It will debut in 2027 on the first EV to be built on the company’s low-cost “Universal Electric Vehicle” platform, which is expected to be a mid-sized pickup.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Ford is promising more with this next-generation BlueCruise system, including eyes-off driving in 2028. But it also claims the system will be capable of handling “point-to-point autonomy,” similar to what Tesla offers with its Full Self-Driving (Supervised) software. Rivian has also teased a point-to-point system coming later this year. All of these systems require the drivers to be ready to take control of the car at any moment. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/ford-ai-assistant.jpg?w=589" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Ford is developing an AI assistant that will debut in the company’s smartphone app, before expanding to its vehicles in 2027, the company announced Wednesday at the 2026 Consumer Electronics Show. The company also teased a next-generation of its BlueCruise advanced driver assistance system that is both cheaper to make and more capable — ultimately leading to eyes-off driving in 2028.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Wednesday’s announcement was one of the only ones to come from a major automaker at CES, marking a sharp turnaround from the late 2010s when they dominated the show. And it wasn’t made at a flashy keynote event; rather, Ford discussed the news at a speaker session called “Great Minds” that was meant to “explore the intersection of technology and humanity.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Ford says it digital assistant is hosted by Google Cloud and will be built using off-the-shelf LLMs, and the company is giving it deep access to vehicle-specific information. That means the assistant can answer high-level questions like “how many bags of mulch can my truck bed support?” But it also means owners will be able to ask for granular, real-time information like oil life. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is rolling the assistant out to its newly revamped Ford app in early 2026. A native, in-vehicle integration will come in 2027, though the company wouldn’t specify which models it’s prioritizing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ford didn’t go into great detail about what the in-car experience will look like, but it’s not hard to imagine the possibilities when looking at some of the more tech-forward automakers. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Just last month, Rivian showed off its own digital assistant sending and receiving text messages, handling complex navigation requests, and changing climate controls. Tesla has integrated Elon Musk’s chatbot Grok in its vehicles, which customers have used to generate on-the-spot sightseeing tours. Some of those capabilities may eclipse what Ford has in mind, but the automaker also has a full year to hammer out the in-car integration.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new BlueCruise system teased on Wednesday is 30% cheaper to build than the current technology, according to Ford. It will debut in 2027 on the first EV to be built on the company’s low-cost “Universal Electric Vehicle” platform, which is expected to be a mid-sized pickup.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Ford is promising more with this next-generation BlueCruise system, including eyes-off driving in 2028. But it also claims the system will be capable of handling “point-to-point autonomy,” similar to what Tesla offers with its Full Self-Driving (Supervised) software. Rivian has also teased a point-to-point system coming later this year. All of these systems require the drivers to be ready to take control of the car at any moment. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/07/ford-has-an-ai-assistant-and-new-hands-free-bluecruise-tech-on-the-way/</guid><pubDate>Thu, 08 Jan 2026 00:00:00 +0000</pubDate></item><item><title>[NEW] Ford is getting ready to put AI assistants in its cars (AI - Ars Technica)</title><link>https://arstechnica.com/cars/2026/01/in-car-ai-assistant-coming-to-fords-and-lincolns-in-2027/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The Blue Oval is also working on new hands-free driver assists.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A car infotainment screen that has AI on it" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2222907242-640x427.jpg" width="640" /&gt;
                  &lt;img alt="A car infotainment screen that has AI on it" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2222907242-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The annual Consumer Electronics Show is currently raging in Las Vegas, and as has become traditional over the past decade, automakers and their suppliers now use the conference to announce their technology plans. Tonight it was Ford’s turn, and it is very on-trend for 2026. If you guessed that means AI is coming to the Ford in-car experience, congratulations, you guessed right.&lt;/p&gt;
&lt;p&gt;Even though the company owes everything to mass-producing identical vehicles, it says that it wants AI to personalize your car to you. “Our vision for the customer is simple, but not elementary: a seamless layer of intelligence that travels with you between your phone and your vehicle,” said Doug Field, Ford’s chief EV, design, and digital officer.&lt;/p&gt;
&lt;p&gt;“Not generic intelligence—many people can do that better than we can. What customers need is intelligence that understands where you are, what you’re doing, and what your vehicle is capable of, and then makes the next decision simpler,” Field wrote in a blog post Ford shared ahead of time with Ars.&lt;/p&gt;
&lt;p&gt;As an example, Field suggests you could take a photo of something you want to load onto your truck, upload it to the AI, and find out whether it will fit in the bed.&lt;/p&gt;
&lt;p&gt;At first, Ford’s AI assistant will just show up in the Ford and Lincoln smartphone apps. Expect that rollout to happen starting early this year. From 2027, the AI assistant will become a native experience as new or refreshed models are able to include it, possibly starting with the cheap electric truck that the automaker tells us is due next year, but also gas models like the Expedition and Navigator.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Also expect those new or refreshed models to become software-defined vehicles, where dozens of discrete electronic control units have been replaced by a handful of powerful multitasking computers. This is one of the latest trends in automotive design, and at CES this year, Ford is showing off what it calls its “High Performance Compute Center"—perhaps high-performance computer sounded too pedestrian for something with four wheels.&lt;/p&gt;
&lt;p&gt;The new computer was designed in-house and is in charge of infotainment, the advanced driver assistance systems, audio, and networking. Ford says the new computer is much cheaper than previous solutions, while taking up half the volume, even as it offers much better performance. “Our upcoming Universal Electric Vehicle (UEV) architecture incorporates a fivefold increase for the in-house module design, giving us 5X more control over critical semiconductors,” said Paul Costa, executive director of electronics platforms at Ford.&lt;/p&gt;
&lt;p&gt;Moving to a software-defined vehicle architecture, with much more powerful processing for things like perception, means Ford can get a little more ambitious with its partially automated driver assists. According to Field, next year will see the debut of a new generation of its BlueCruise assist that has “significantly more capability at a 30 percent lower cost.” And in 2028, Ford plans to start offering a so-called “level 3” assist, where the driver can give up situational awareness completely under certain circumstances, like heavy highway traffic.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The Blue Oval is also working on new hands-free driver assists.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A car infotainment screen that has AI on it" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2222907242-640x427.jpg" width="640" /&gt;
                  &lt;img alt="A car infotainment screen that has AI on it" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2222907242-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The annual Consumer Electronics Show is currently raging in Las Vegas, and as has become traditional over the past decade, automakers and their suppliers now use the conference to announce their technology plans. Tonight it was Ford’s turn, and it is very on-trend for 2026. If you guessed that means AI is coming to the Ford in-car experience, congratulations, you guessed right.&lt;/p&gt;
&lt;p&gt;Even though the company owes everything to mass-producing identical vehicles, it says that it wants AI to personalize your car to you. “Our vision for the customer is simple, but not elementary: a seamless layer of intelligence that travels with you between your phone and your vehicle,” said Doug Field, Ford’s chief EV, design, and digital officer.&lt;/p&gt;
&lt;p&gt;“Not generic intelligence—many people can do that better than we can. What customers need is intelligence that understands where you are, what you’re doing, and what your vehicle is capable of, and then makes the next decision simpler,” Field wrote in a blog post Ford shared ahead of time with Ars.&lt;/p&gt;
&lt;p&gt;As an example, Field suggests you could take a photo of something you want to load onto your truck, upload it to the AI, and find out whether it will fit in the bed.&lt;/p&gt;
&lt;p&gt;At first, Ford’s AI assistant will just show up in the Ford and Lincoln smartphone apps. Expect that rollout to happen starting early this year. From 2027, the AI assistant will become a native experience as new or refreshed models are able to include it, possibly starting with the cheap electric truck that the automaker tells us is due next year, but also gas models like the Expedition and Navigator.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Also expect those new or refreshed models to become software-defined vehicles, where dozens of discrete electronic control units have been replaced by a handful of powerful multitasking computers. This is one of the latest trends in automotive design, and at CES this year, Ford is showing off what it calls its “High Performance Compute Center"—perhaps high-performance computer sounded too pedestrian for something with four wheels.&lt;/p&gt;
&lt;p&gt;The new computer was designed in-house and is in charge of infotainment, the advanced driver assistance systems, audio, and networking. Ford says the new computer is much cheaper than previous solutions, while taking up half the volume, even as it offers much better performance. “Our upcoming Universal Electric Vehicle (UEV) architecture incorporates a fivefold increase for the in-house module design, giving us 5X more control over critical semiconductors,” said Paul Costa, executive director of electronics platforms at Ford.&lt;/p&gt;
&lt;p&gt;Moving to a software-defined vehicle architecture, with much more powerful processing for things like perception, means Ford can get a little more ambitious with its partially automated driver assists. According to Field, next year will see the debut of a new generation of its BlueCruise assist that has “significantly more capability at a 30 percent lower cost.” And in 2028, Ford plans to start offering a so-called “level 3” assist, where the driver can give up situational awareness completely under certain circumstances, like heavy highway traffic.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/cars/2026/01/in-car-ai-assistant-coming-to-fords-and-lincolns-in-2027/</guid><pubDate>Thu, 08 Jan 2026 00:00:33 +0000</pubDate></item><item><title>[NEW] Google and Character.AI negotiate first major settlements in teen chatbot death cases (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/07/google-and-character-ai-negotiate-first-major-settlements-in-teen-chatbot-death-cases/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/05/GettyImages-1224612965.jpg?resize=1200,842" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In what may mark the tech industry’s first significant legal settlement over AI-related harm, Google and the startup Character.AI are negotiating terms with families whose teenagers died by suicide or harmed themselves after interacting with Character.AI’s chatbot companions. The parties have agreed in principle to settle; now comes the harder work of finalizing the details.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These are among the first settlements in lawsuits accusing AI companies of harming users, a legal frontier that must have OpenAI and Meta watching nervously from the wings as they defend themselves against similar lawsuits. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Character.AI founded in 2021 by ex-Google engineers who returned to their former employer in 2024 in a $2.7 billion deal, invites users to chat with AI personas. The most haunting case involves Sewell Setzer III, who at age 14 conducted sexualized conversations with a “Daenerys Targaryen” bot before killing himself. His mother, Megan Garcia, has told the Senate that companies must be “legally accountable when they knowingly design harmful AI technologies that kill kids.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another lawsuit describes a 17-year-old whose chatbot encouraged self-harm and suggested that murdering his parents was reasonable for limiting screen time. Character.AI banned minors last October, it told TechCrunch. The settlements will likely include monetary damages, though no liability was admitted in court filings made available Wednesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to both companies.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/05/GettyImages-1224612965.jpg?resize=1200,842" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In what may mark the tech industry’s first significant legal settlement over AI-related harm, Google and the startup Character.AI are negotiating terms with families whose teenagers died by suicide or harmed themselves after interacting with Character.AI’s chatbot companions. The parties have agreed in principle to settle; now comes the harder work of finalizing the details.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These are among the first settlements in lawsuits accusing AI companies of harming users, a legal frontier that must have OpenAI and Meta watching nervously from the wings as they defend themselves against similar lawsuits. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Character.AI founded in 2021 by ex-Google engineers who returned to their former employer in 2024 in a $2.7 billion deal, invites users to chat with AI personas. The most haunting case involves Sewell Setzer III, who at age 14 conducted sexualized conversations with a “Daenerys Targaryen” bot before killing himself. His mother, Megan Garcia, has told the Senate that companies must be “legally accountable when they knowingly design harmful AI technologies that kill kids.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another lawsuit describes a 17-year-old whose chatbot encouraged self-harm and suggested that murdering his parents was reasonable for limiting screen time. Character.AI banned minors last October, it told TechCrunch. The settlements will likely include monetary damages, though no liability was admitted in court filings made available Wednesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to both companies.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/07/google-and-character-ai-negotiate-first-major-settlements-in-teen-chatbot-death-cases/</guid><pubDate>Thu, 08 Jan 2026 01:32:00 +0000</pubDate></item></channel></rss>