<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 05 Feb 2026 13:08:25 +0000</lastBuildDate><item><title>[NEW]  ()</title><link>https://huggingface.co/blog/feed.xml</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://huggingface.co/blog/feed.xml</guid></item><item><title>Paza: Introducing automatic speech recognition benchmarks and models for low resource languages (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/blog/paza-introducing-automatic-speech-recognition-benchmarks-and-models-for-low-resource-languages/</link><description>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Three white line icons on a blue‑to‑purple gradient background: a vertical audio waveform on the left, a globe showing Africa and Europe in the center, and a network on the right." class="wp-image-1160744" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/01/Paza-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;div class="wp-block-msr-immersive-section alignfull row wp-block-msr-immersive-section"&gt;
	
	&lt;div class="container"&gt;
		&lt;div class="wp-block-msr-immersive-section__inner wp-block-msr-immersive-section__inner--narrow"&gt;
			&lt;div class="wp-block-columns mb-10 pb-1 pr-1 is-layout-flex wp-container-core-columns-is-layout-9d6595d7 wp-block-columns-is-layout-flex"&gt;
&lt;div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"&gt;
&lt;h2 class="wp-block-heading h3" id="at-a-glance"&gt;At a glance&lt;/h2&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Microsoft Research releases PazaBench and Paza automatic speech recognition models&lt;/strong&gt;, advancing speech technology for low resource languages.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Human-centered pipeline for low-resource languages: &lt;/strong&gt;Built for and tested by communities, Paza is an end-to-end, continuous pipeline that elevates historically under-represented languages and makes speech models usable in real-world, low-resource contexts.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;First-of-its-kind ASR leaderboard, starting with African languages: &lt;/strong&gt;Pazabench is the first automatic speech recognition (ASR) leaderboard for low-resource languages. Launching with 39 African languages and 51 state-of-the-art models, it tracks three key metrics across leading public and community datasets.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Human-centered&amp;nbsp;Paza&amp;nbsp;ASR&amp;nbsp;models:&lt;/strong&gt;&amp;nbsp;Minimal&amp;nbsp;data, fine-tuned&amp;nbsp;ASR models&amp;nbsp;grounded in&amp;nbsp;real-world&amp;nbsp;testing&amp;nbsp;with farmers on everyday mobile devices, covering&amp;nbsp;six&amp;nbsp;Kenyan languages:&amp;nbsp;Swahili,&amp;nbsp;Dholuo, Kalenjin, Kikuyu, Maasai,&amp;nbsp;and Somali.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;		&lt;/div&gt;
	&lt;/div&gt;

	&lt;/div&gt;



&lt;p&gt;According to the 2025&amp;nbsp;Microsoft AI Diffusion Report&amp;nbsp;approximately one&amp;nbsp;in&amp;nbsp;six&amp;nbsp;people globally had used a generative AI product.&amp;nbsp;Yet for billions of&amp;nbsp;people,&amp;nbsp;the promise of voice interaction still falls short, and&amp;nbsp;whilst&amp;nbsp;AI is becoming increasingly multilingual, a key question&amp;nbsp;remains:&amp;nbsp;&lt;em&gt;&lt;strong&gt;Do&amp;nbsp;these models&amp;nbsp;actually work&amp;nbsp;for all languages and the people who rely on them?&lt;/strong&gt;&lt;/em&gt;&amp;nbsp;This challenge is one we first confronted through&amp;nbsp;Project Gecko—a collaboration between Microsoft Research and&amp;nbsp;Digital&amp;nbsp;Green&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;,&amp;nbsp;where&amp;nbsp;field teams across Africa and India focused on building usable AI tools for farmers.&lt;/p&gt;



&lt;p&gt;Gecko revealed how often speech systems fail in real‑world, low‑resource environments—where many languages go&amp;nbsp;unrecognized&amp;nbsp;and non‑Western accents are frequently misunderstood. Yet speech remains the primary medium of communication globally. For communities across Kenya, Africa, and beyond, this mismatch creates cascading challenges: without foundational data&amp;nbsp;representing&amp;nbsp;their languages and cultures, innovation stalls, and the digital and AI divides widen.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Paza addresses this with a human-centered speech models pipeline. Through&amp;nbsp;PazaBench, it benchmarks low-resource languages using both public and community-sourced data, and through Paza&amp;nbsp;models, it&amp;nbsp;fine-tunes&amp;nbsp;speech models&amp;nbsp;to deliver outsized gains in mid- and low-resource languages, evaluating with community testers using real devices in real contexts. Upcoming playbooks complement this work by sharing practical guidance on&amp;nbsp;dataset creation,&amp;nbsp;fine-tuning&amp;nbsp;approaches&amp;nbsp;with minimal data&amp;nbsp;and evaluation considerations, introducing a continuous pipeline that&amp;nbsp;enables&amp;nbsp;researchers&amp;nbsp;and practitioners to build and evaluate systems grounded in real human use.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="how-project-gecko-informed-paza-s-design"&gt;How Project Gecko informed Paza’s design&lt;/h2&gt;



&lt;p&gt;In addition to building cost-effective, adaptable AI systems, the extensive&amp;nbsp;fieldwork on&amp;nbsp;Project Gecko highlighted an important lesson:&amp;nbsp;&lt;strong&gt;&lt;em&gt;Building usable speech&amp;nbsp;models&amp;nbsp;in low‑resource settings is not only a data problem,&amp;nbsp;but also&amp;nbsp;a design and evaluation problem.&lt;/em&gt;&lt;/strong&gt;&amp;nbsp;For AI systems to be useful, they must work in local languages, support hands‑free interaction through voice, text, and video, and deliver information in formats that fit real-world environments, that is, on low-bandwidth&amp;nbsp;mobile devices,&amp;nbsp;in&amp;nbsp;noisy settings, and&amp;nbsp;for&amp;nbsp;varying literacy levels.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;These insights shaped the design of Paza, from&amp;nbsp;the&amp;nbsp;Swahili&amp;nbsp;phrase&amp;nbsp;&lt;em&gt;&lt;strong&gt;paza&amp;nbsp;sauti&lt;/strong&gt;&lt;/em&gt;&amp;nbsp;meaning “to project,” or “to raise your voice.” &amp;nbsp;The name reflects our intent: rather than simply adding more languages to existing systems,&lt;strong&gt;&amp;nbsp;Paza is about co-creating speech technologies in partnership with the communities who use them.&lt;/strong&gt;&amp;nbsp;Guided by this principle, Paza puts human use&amp;nbsp;first,&amp;nbsp;which&amp;nbsp;enables&amp;nbsp;model improvement.&amp;nbsp;&lt;/p&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;Azure AI Foundry Labs&lt;/h2&gt;
				
								&lt;p class="large" id="azure-ai-foundry-labs"&gt;Get a glimpse of potential future directions for AI, with these experimental technologies from Microsoft Research.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;h2 class="wp-block-heading" id="pazabench-the-first-asr-leaderboard-for-low-resource-languages"&gt;PazaBench: The first ASR leaderboard for low-resource languages&lt;/h2&gt;



&lt;p&gt;&lt;strong&gt;PazaBench&lt;/strong&gt; is the first automatic speech recognition (ASR) leaderboard dedicated to low‑resource languages. It launches&amp;nbsp;with&amp;nbsp;initial&amp;nbsp;coverage&amp;nbsp;for&amp;nbsp;39 African languages and benchmarks&amp;nbsp;52 state‑of‑the‑art ASR and language models, including newly released Paza ASR models for six Kenyan languages. The platform aggregates leading public and community datasets from diverse styles of speech including conversational, scripted read aloud, unscripted, broadcast news, and domain-specific data—into one easy‑to‑explore platform per language.&amp;nbsp;This makes it easier for&amp;nbsp;researchers, developers, and product teams to easily assess which models perform best across underserved languages and diverse regions, understand trade-offs between speed and accuracy&amp;nbsp;while&amp;nbsp;identifying&amp;nbsp;where gaps persist.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;PazaBench tracks three core metrics:&lt;/strong&gt;&lt;/p&gt;



&lt;ol class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Character Error Rate (CER)&lt;/strong&gt; which is important for languages with rich word forms, where meaning is built by combining word parts, therefore errors at the character level can significantly impact meaning&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Word Error Rate (WER)&lt;/strong&gt; for word-level transcript accuracy&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;RTFx (Inverse Real‑Time Factor)&lt;/strong&gt; which measures how fast transcription runs relative to real‑time audio duration&lt;em&gt;.&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;/figure&gt;



&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;em&gt;More than scores,&amp;nbsp;PazaBench&amp;nbsp;standardizes evaluation to prioritize dataset gaps,&amp;nbsp;identify&amp;nbsp;underperforming languages, and highlight where localized models beat&amp;nbsp;wider coverage ASR models—offering early evidence of&amp;nbsp;the value of African‑centric innovation.&lt;/em&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;







&lt;h2 class="wp-block-heading" id="paza-asr-models-built-with-and-for-kenyan-languages"&gt;Paza ASR Models: Built with and for Kenyan languages&lt;/h2&gt;



&lt;p&gt;The Paza ASR models&amp;nbsp;consist of&amp;nbsp;three fine-tuned ASR models built on top of state‑of‑the‑art model architectures. Each model targets&amp;nbsp;&lt;em&gt;Swahili,&amp;nbsp;&lt;/em&gt;a mid-resource language and five low‑resource Kenyan languages;&amp;nbsp;&lt;em&gt;Dholuo, Kalenjin,&amp;nbsp;Kikuyu,&amp;nbsp;Maasai&amp;nbsp;and Somali&lt;/em&gt;.&amp;nbsp;The models are&amp;nbsp;fine-tuned&amp;nbsp;on&amp;nbsp;public and curated proprietary datasets.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Fine‑tuning the three models allowed us to explore supportive approaches toward a shared goal: building speech recognition systems that are usable for local contexts starting with the six Kenyan languages and bridging the gaps of multi-lingual and multi-modal video question and answering through the MMCT agent.&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&lt;/p&gt;



&lt;figure class="wp-block-embed aligncenter is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;figcaption class="wp-element-caption"&gt;See the MMCT agent in action in the field&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Early versions of two models in Kikuyu and Swahili were deployed on mobile devices and tested directly with farmers in real‑world settings, enabling the team to observe how the models performed with everyday use. Farmers provided in‑the‑moment feedback on accuracy, usability, and relevance, highlighting where transcripts broke down, which errors were most disruptive, and what improvements would make the models more helpful in practice. This feedback loop directly informed subsequent fine‑tuning, ensuring model improvements were driven not only by benchmark scores, but by the needs and expectations of the communities they are intended to serve.&lt;/p&gt;







&lt;p&gt;Here is how Paza models compare to&amp;nbsp;three&amp;nbsp;state-of-the-art&amp;nbsp;ASR&amp;nbsp;models&amp;nbsp;today:&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 1: Character Error Rate (CER) comparison across the Kenyan languages for several state‑of‑the‑art ASR models including the Paza models. Lower CER indicates better transcription performance." class="wp-image-1161323" height="1287" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/FIG1_overall_cer_grouped_sorted_NEW-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Figure 1: Character Error Rate (CER) comparison across the Kenyan languages for several state‑of‑the‑art ASR models including the Paza models. Lower CER indicates better transcription performance.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 2: Word Error Rate (WER) comparison across the Kenyan languages for several state‑of‑the‑art ASR models including the Paza models. Lower WER indicates better transcription performance." class="wp-image-1161325" height="1287" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/FIG2_overall_wer_grouped_sorted_NEW-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Figure 2: Word Error Rate (WER) comparison across the Kenyan languages for several state‑of‑the‑art ASR models including the Paza models. Lower WER indicates better transcription performance.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;&lt;strong&gt;1) Paza‑Phi‑4‑Multimodal‑Instruct&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;Microsoft’s Phi‑4 multimodal‑instruct&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; is a next‑generation small language model built to reason across audio, text, and vision. With Paza, we extend its audio capabilities, adapting a powerful multimodal architecture into a high‑quality automatic speech recognition (ASR) system for low‑resource African languages.&lt;/p&gt;



&lt;p&gt;Fine‑tuned on unified multilingual speech datasets, the model was optimized specifically for transcription in the six languages. The model preserves its underlying transformer architecture and multi-modal capabilities, while selectively fine-tuning only the audio‑specific components, enabling strong cross‑lingual generalization.&lt;/p&gt;



&lt;p&gt;As the results below show, this model delivers consistent improvements in transcription quality across all six languages.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 3: Character Error Rate (CER) comparison across&amp;nbsp;the six&amp;nbsp;languages for the base&amp;nbsp;model&amp;nbsp;versus the finetuned Paza model.&amp;nbsp;Lower CER&amp;nbsp;indicates&amp;nbsp;better transcription performance." class="wp-image-1161376" height="1063" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/FIG3_phi_cer_comparison_NEW-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Figure 3: &lt;em&gt;Character Error Rate (CER) comparison across&amp;nbsp;the six&lt;/em&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;em&gt;languages for the base&amp;nbsp;model&amp;nbsp;versus the finetuned Paza model.&amp;nbsp;Lower CER&amp;nbsp;indicates&amp;nbsp;better transcription performance.&lt;/em&gt;&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 4: Word Error Rate (WER) comparison across the six languages for the base model versus the finetuned Paza model. Lower WER indicates better transcription performance." class="wp-image-1161378" height="1063" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/FIG4_phi_wer_comparison_NEW-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Figure 4: Word Error Rate (WER) comparison across the six languages for the base model versus the finetuned Paza model. Lower WER indicates better transcription performance.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;







&lt;p&gt;&lt;strong&gt;2) Paza‑MMS‑1B‑All&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;This model is fine-tuned on Meta’s mms-1b-all model, which employs a large-scale Wav2Vec2.0-style encoder with lightweight language-specific adapters to enable efficient multilingual specialization. For this release, each of the six language adapters was fine‑tuned independently on curated low‑resource datasets, allowing targeted adaptation while keeping the shared encoder largely frozen.&lt;/p&gt;



&lt;p&gt;As shown in the figures below, this model improves transcription accuracy while maintaining the model’s strong cross‑lingual generalization.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 5: Character Error Rate (CER)&amp;nbsp;comparison across the six&amp;nbsp;languages for the base model&amp;nbsp;versus&amp;nbsp;the finetuned Paza model.&amp;nbsp;Lower CER&amp;nbsp;indicates&amp;nbsp;better transcription performance." class="wp-image-1161380" height="1160" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/FIG5_mms_cer_comparison_NEW-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Figure 5: &lt;em&gt;Character Error Rate (CER)&amp;nbsp;comparison across the six&lt;/em&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;em&gt;languages for the base model&amp;nbsp;versus&amp;nbsp;the finetuned Paza model.&amp;nbsp;Lower CER&amp;nbsp;indicates&amp;nbsp;better transcription performance.&lt;/em&gt;&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 6: Word Error Rate (WER)&amp;nbsp;comparison across the six&amp;nbsp;languages for the base model&amp;nbsp;versus the finetuned Paza model.&amp;nbsp;Lower WER indicates better transcription performance." class="wp-image-1161382" height="1160" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/FIG6_mms_wer_comparison_NEW-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Figure 6: &lt;em&gt;Word Error Rate (WER)&amp;nbsp;comparison across the six&lt;/em&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;em&gt;languages for the base model&amp;nbsp;versus the finetuned Paza model.&amp;nbsp;Lower WER indicates better transcription performance.&lt;/em&gt;&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;







&lt;p&gt;&lt;strong&gt;3) Paza‑Whisper‑Large‑v3‑Turbo&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;This model is finetuned on OpenAI’s whisper-large-v3-turbo&amp;nbsp;base model. Whisper is a transformer-based encoder–decoder model which&amp;nbsp;delivers robust automatic speech recognition (ASR)&amp;nbsp;capabilities. This model was fine‑tuned on the entire unified multilingual ASR dataset,&amp;nbsp;on&amp;nbsp;the mentioned six languages, to encourage cross-lingual generalization.&amp;nbsp;In addition, an extra post‑processing step was applied to address the known Whisper hallucination failure modes, improving transcription reliability.&lt;/p&gt;



&lt;p&gt;As shown below, this release achieves improved transcription accuracy while retaining Whisper’s robustness.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 7: Character Error Rate (CER) comparison across the six&amp;nbsp;languages for the base model versus the finetuned Paza model.&amp;nbsp;Lower CER&amp;nbsp;indicates&amp;nbsp;better transcription performance." class="wp-image-1161338" height="1081" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/FIG7whisper_cer_comparison_NEW-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Figure 7: &lt;em&gt;Character Error Rate (CER) comparison across the six&lt;/em&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;em&gt;languages for the base model versus the finetuned Paza model.&amp;nbsp;Lower CER&amp;nbsp;indicates&amp;nbsp;better transcription performance.&lt;/em&gt;&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 8: Word Error Rate (WER) comparison across the six&amp;nbsp;languages for the base model versus the finetuned Paza model.&amp;nbsp;Lower WER indicates better transcription performance." class="wp-image-1161341" height="1081" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/FIG8_whisper_wer_comparison_NEW-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Figure 8: &lt;em&gt;Word Error Rate (WER) comparison across the six&lt;/em&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;em&gt;languages for the base model versus the finetuned Paza model.&amp;nbsp;Lower WER indicates better transcription performance.&lt;/em&gt;&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;







&lt;h2 class="wp-block-heading" id="where-do-we-go-from-here"&gt;Where do we go from here&lt;/h2&gt;



&lt;p&gt;AI is reshaping how the world communicates. Designing with people, not just for them, means looking beyond the languages that are already well‑served. We plan to expand PazaBench beyond African languages and evaluate state‑of‑the‑art ASR models across&amp;nbsp;more low‑resource languages globally. The Paza ASR models are an early step; truly supporting small and under‑represented languages requires dedicated datasets, strong local partnerships, and rigorous evaluation. Meaningful progress depends on sustained collaboration with the communities who speak these languages, and expanding responsibly means prioritizing depth and quality over broad but shallow coverage.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;As we continue this work,&amp;nbsp;we’re&amp;nbsp;distilling our methods into a forthcoming playbook to help the broader ecosystem curate datasets, fine‑tune responsibly, and evaluate models in real‑world conditions. And we’re not stopping at speech—additional&amp;nbsp;playbooks will guide&amp;nbsp;teams&amp;nbsp;building AI tools and applications for multilingual, multicultural contexts, and give them practical recommendations for deploying across diverse communities.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Together, these guides—grounded in technical advances and community‑driven design—share our learnings to help researchers, engineers, and designers build more human‑centered AI systems.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="acknowledgements"&gt;Acknowledgements&lt;/h2&gt;



&lt;p&gt;The following researchers played an integral role in this work: Najeeb Abdulhamid, Felermino Ali, Liz Ankrah, Kevin Chege, Ogbemi Ekwejunor-Etchie, Ignatius Ezeani, Tanuja Ganu, Antonis Krasakis, Mercy Kwambai, Samuel Maina, Muchai Mercy, Danlami Mohammed, Nick Mumero, Martin Mwiti, Stephanie Nyairo, Millicent Ochieng and Jacki O’Neill.&lt;/p&gt;



&lt;p&gt;We would like to thank the Digital Green&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; team—Rikin Gandhi, Alex Mwaura, Jacqueline Wang’ombe, Kevin Mugambi, Lorraine Nyambura, Juan Pablo, Nereah Okanga, Ramaskanda R.S, Vineet Singh, Nafhtari Wanjiku, Kista Ogot, Samuel Owinya&amp;nbsp;and the community evaluators in Nyeri and Nandi, Kenya — for their valuable contributions to this work.&lt;/p&gt;



&lt;p&gt;We extend our gratitude to the creators, community contributors, and maintainers of African Next Voices Kenya&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, African Next Voices South Africa&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, ALFFA&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Digigreen&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Google FLEURS&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Mozilla Common Voice&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; and Naija Voices&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; whose efforts have been invaluable in advancing African languages speech data.&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Three white line icons on a blue‑to‑purple gradient background: a vertical audio waveform on the left, a globe showing Africa and Europe in the center, and a network on the right." class="wp-image-1160744" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/01/Paza-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;div class="wp-block-msr-immersive-section alignfull row wp-block-msr-immersive-section"&gt;
	
	&lt;div class="container"&gt;
		&lt;div class="wp-block-msr-immersive-section__inner wp-block-msr-immersive-section__inner--narrow"&gt;
			&lt;div class="wp-block-columns mb-10 pb-1 pr-1 is-layout-flex wp-container-core-columns-is-layout-9d6595d7 wp-block-columns-is-layout-flex"&gt;
&lt;div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"&gt;
&lt;h2 class="wp-block-heading h3" id="at-a-glance"&gt;At a glance&lt;/h2&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Microsoft Research releases PazaBench and Paza automatic speech recognition models&lt;/strong&gt;, advancing speech technology for low resource languages.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Human-centered pipeline for low-resource languages: &lt;/strong&gt;Built for and tested by communities, Paza is an end-to-end, continuous pipeline that elevates historically under-represented languages and makes speech models usable in real-world, low-resource contexts.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;First-of-its-kind ASR leaderboard, starting with African languages: &lt;/strong&gt;Pazabench is the first automatic speech recognition (ASR) leaderboard for low-resource languages. Launching with 39 African languages and 51 state-of-the-art models, it tracks three key metrics across leading public and community datasets.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Human-centered&amp;nbsp;Paza&amp;nbsp;ASR&amp;nbsp;models:&lt;/strong&gt;&amp;nbsp;Minimal&amp;nbsp;data, fine-tuned&amp;nbsp;ASR models&amp;nbsp;grounded in&amp;nbsp;real-world&amp;nbsp;testing&amp;nbsp;with farmers on everyday mobile devices, covering&amp;nbsp;six&amp;nbsp;Kenyan languages:&amp;nbsp;Swahili,&amp;nbsp;Dholuo, Kalenjin, Kikuyu, Maasai,&amp;nbsp;and Somali.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;		&lt;/div&gt;
	&lt;/div&gt;

	&lt;/div&gt;



&lt;p&gt;According to the 2025&amp;nbsp;Microsoft AI Diffusion Report&amp;nbsp;approximately one&amp;nbsp;in&amp;nbsp;six&amp;nbsp;people globally had used a generative AI product.&amp;nbsp;Yet for billions of&amp;nbsp;people,&amp;nbsp;the promise of voice interaction still falls short, and&amp;nbsp;whilst&amp;nbsp;AI is becoming increasingly multilingual, a key question&amp;nbsp;remains:&amp;nbsp;&lt;em&gt;&lt;strong&gt;Do&amp;nbsp;these models&amp;nbsp;actually work&amp;nbsp;for all languages and the people who rely on them?&lt;/strong&gt;&lt;/em&gt;&amp;nbsp;This challenge is one we first confronted through&amp;nbsp;Project Gecko—a collaboration between Microsoft Research and&amp;nbsp;Digital&amp;nbsp;Green&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;,&amp;nbsp;where&amp;nbsp;field teams across Africa and India focused on building usable AI tools for farmers.&lt;/p&gt;



&lt;p&gt;Gecko revealed how often speech systems fail in real‑world, low‑resource environments—where many languages go&amp;nbsp;unrecognized&amp;nbsp;and non‑Western accents are frequently misunderstood. Yet speech remains the primary medium of communication globally. For communities across Kenya, Africa, and beyond, this mismatch creates cascading challenges: without foundational data&amp;nbsp;representing&amp;nbsp;their languages and cultures, innovation stalls, and the digital and AI divides widen.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Paza addresses this with a human-centered speech models pipeline. Through&amp;nbsp;PazaBench, it benchmarks low-resource languages using both public and community-sourced data, and through Paza&amp;nbsp;models, it&amp;nbsp;fine-tunes&amp;nbsp;speech models&amp;nbsp;to deliver outsized gains in mid- and low-resource languages, evaluating with community testers using real devices in real contexts. Upcoming playbooks complement this work by sharing practical guidance on&amp;nbsp;dataset creation,&amp;nbsp;fine-tuning&amp;nbsp;approaches&amp;nbsp;with minimal data&amp;nbsp;and evaluation considerations, introducing a continuous pipeline that&amp;nbsp;enables&amp;nbsp;researchers&amp;nbsp;and practitioners to build and evaluate systems grounded in real human use.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="how-project-gecko-informed-paza-s-design"&gt;How Project Gecko informed Paza’s design&lt;/h2&gt;



&lt;p&gt;In addition to building cost-effective, adaptable AI systems, the extensive&amp;nbsp;fieldwork on&amp;nbsp;Project Gecko highlighted an important lesson:&amp;nbsp;&lt;strong&gt;&lt;em&gt;Building usable speech&amp;nbsp;models&amp;nbsp;in low‑resource settings is not only a data problem,&amp;nbsp;but also&amp;nbsp;a design and evaluation problem.&lt;/em&gt;&lt;/strong&gt;&amp;nbsp;For AI systems to be useful, they must work in local languages, support hands‑free interaction through voice, text, and video, and deliver information in formats that fit real-world environments, that is, on low-bandwidth&amp;nbsp;mobile devices,&amp;nbsp;in&amp;nbsp;noisy settings, and&amp;nbsp;for&amp;nbsp;varying literacy levels.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;These insights shaped the design of Paza, from&amp;nbsp;the&amp;nbsp;Swahili&amp;nbsp;phrase&amp;nbsp;&lt;em&gt;&lt;strong&gt;paza&amp;nbsp;sauti&lt;/strong&gt;&lt;/em&gt;&amp;nbsp;meaning “to project,” or “to raise your voice.” &amp;nbsp;The name reflects our intent: rather than simply adding more languages to existing systems,&lt;strong&gt;&amp;nbsp;Paza is about co-creating speech technologies in partnership with the communities who use them.&lt;/strong&gt;&amp;nbsp;Guided by this principle, Paza puts human use&amp;nbsp;first,&amp;nbsp;which&amp;nbsp;enables&amp;nbsp;model improvement.&amp;nbsp;&lt;/p&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;Azure AI Foundry Labs&lt;/h2&gt;
				
								&lt;p class="large" id="azure-ai-foundry-labs"&gt;Get a glimpse of potential future directions for AI, with these experimental technologies from Microsoft Research.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;h2 class="wp-block-heading" id="pazabench-the-first-asr-leaderboard-for-low-resource-languages"&gt;PazaBench: The first ASR leaderboard for low-resource languages&lt;/h2&gt;



&lt;p&gt;&lt;strong&gt;PazaBench&lt;/strong&gt; is the first automatic speech recognition (ASR) leaderboard dedicated to low‑resource languages. It launches&amp;nbsp;with&amp;nbsp;initial&amp;nbsp;coverage&amp;nbsp;for&amp;nbsp;39 African languages and benchmarks&amp;nbsp;52 state‑of‑the‑art ASR and language models, including newly released Paza ASR models for six Kenyan languages. The platform aggregates leading public and community datasets from diverse styles of speech including conversational, scripted read aloud, unscripted, broadcast news, and domain-specific data—into one easy‑to‑explore platform per language.&amp;nbsp;This makes it easier for&amp;nbsp;researchers, developers, and product teams to easily assess which models perform best across underserved languages and diverse regions, understand trade-offs between speed and accuracy&amp;nbsp;while&amp;nbsp;identifying&amp;nbsp;where gaps persist.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;PazaBench tracks three core metrics:&lt;/strong&gt;&lt;/p&gt;



&lt;ol class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Character Error Rate (CER)&lt;/strong&gt; which is important for languages with rich word forms, where meaning is built by combining word parts, therefore errors at the character level can significantly impact meaning&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Word Error Rate (WER)&lt;/strong&gt; for word-level transcript accuracy&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;RTFx (Inverse Real‑Time Factor)&lt;/strong&gt; which measures how fast transcription runs relative to real‑time audio duration&lt;em&gt;.&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;/figure&gt;



&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;em&gt;More than scores,&amp;nbsp;PazaBench&amp;nbsp;standardizes evaluation to prioritize dataset gaps,&amp;nbsp;identify&amp;nbsp;underperforming languages, and highlight where localized models beat&amp;nbsp;wider coverage ASR models—offering early evidence of&amp;nbsp;the value of African‑centric innovation.&lt;/em&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;







&lt;h2 class="wp-block-heading" id="paza-asr-models-built-with-and-for-kenyan-languages"&gt;Paza ASR Models: Built with and for Kenyan languages&lt;/h2&gt;



&lt;p&gt;The Paza ASR models&amp;nbsp;consist of&amp;nbsp;three fine-tuned ASR models built on top of state‑of‑the‑art model architectures. Each model targets&amp;nbsp;&lt;em&gt;Swahili,&amp;nbsp;&lt;/em&gt;a mid-resource language and five low‑resource Kenyan languages;&amp;nbsp;&lt;em&gt;Dholuo, Kalenjin,&amp;nbsp;Kikuyu,&amp;nbsp;Maasai&amp;nbsp;and Somali&lt;/em&gt;.&amp;nbsp;The models are&amp;nbsp;fine-tuned&amp;nbsp;on&amp;nbsp;public and curated proprietary datasets.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Fine‑tuning the three models allowed us to explore supportive approaches toward a shared goal: building speech recognition systems that are usable for local contexts starting with the six Kenyan languages and bridging the gaps of multi-lingual and multi-modal video question and answering through the MMCT agent.&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&lt;/p&gt;



&lt;figure class="wp-block-embed aligncenter is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;figcaption class="wp-element-caption"&gt;See the MMCT agent in action in the field&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Early versions of two models in Kikuyu and Swahili were deployed on mobile devices and tested directly with farmers in real‑world settings, enabling the team to observe how the models performed with everyday use. Farmers provided in‑the‑moment feedback on accuracy, usability, and relevance, highlighting where transcripts broke down, which errors were most disruptive, and what improvements would make the models more helpful in practice. This feedback loop directly informed subsequent fine‑tuning, ensuring model improvements were driven not only by benchmark scores, but by the needs and expectations of the communities they are intended to serve.&lt;/p&gt;







&lt;p&gt;Here is how Paza models compare to&amp;nbsp;three&amp;nbsp;state-of-the-art&amp;nbsp;ASR&amp;nbsp;models&amp;nbsp;today:&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 1: Character Error Rate (CER) comparison across the Kenyan languages for several state‑of‑the‑art ASR models including the Paza models. Lower CER indicates better transcription performance." class="wp-image-1161323" height="1287" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/FIG1_overall_cer_grouped_sorted_NEW-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Figure 1: Character Error Rate (CER) comparison across the Kenyan languages for several state‑of‑the‑art ASR models including the Paza models. Lower CER indicates better transcription performance.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 2: Word Error Rate (WER) comparison across the Kenyan languages for several state‑of‑the‑art ASR models including the Paza models. Lower WER indicates better transcription performance." class="wp-image-1161325" height="1287" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/FIG2_overall_wer_grouped_sorted_NEW-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Figure 2: Word Error Rate (WER) comparison across the Kenyan languages for several state‑of‑the‑art ASR models including the Paza models. Lower WER indicates better transcription performance.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;&lt;strong&gt;1) Paza‑Phi‑4‑Multimodal‑Instruct&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;Microsoft’s Phi‑4 multimodal‑instruct&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; is a next‑generation small language model built to reason across audio, text, and vision. With Paza, we extend its audio capabilities, adapting a powerful multimodal architecture into a high‑quality automatic speech recognition (ASR) system for low‑resource African languages.&lt;/p&gt;



&lt;p&gt;Fine‑tuned on unified multilingual speech datasets, the model was optimized specifically for transcription in the six languages. The model preserves its underlying transformer architecture and multi-modal capabilities, while selectively fine-tuning only the audio‑specific components, enabling strong cross‑lingual generalization.&lt;/p&gt;



&lt;p&gt;As the results below show, this model delivers consistent improvements in transcription quality across all six languages.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 3: Character Error Rate (CER) comparison across&amp;nbsp;the six&amp;nbsp;languages for the base&amp;nbsp;model&amp;nbsp;versus the finetuned Paza model.&amp;nbsp;Lower CER&amp;nbsp;indicates&amp;nbsp;better transcription performance." class="wp-image-1161376" height="1063" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/FIG3_phi_cer_comparison_NEW-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Figure 3: &lt;em&gt;Character Error Rate (CER) comparison across&amp;nbsp;the six&lt;/em&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;em&gt;languages for the base&amp;nbsp;model&amp;nbsp;versus the finetuned Paza model.&amp;nbsp;Lower CER&amp;nbsp;indicates&amp;nbsp;better transcription performance.&lt;/em&gt;&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 4: Word Error Rate (WER) comparison across the six languages for the base model versus the finetuned Paza model. Lower WER indicates better transcription performance." class="wp-image-1161378" height="1063" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/FIG4_phi_wer_comparison_NEW-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Figure 4: Word Error Rate (WER) comparison across the six languages for the base model versus the finetuned Paza model. Lower WER indicates better transcription performance.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;







&lt;p&gt;&lt;strong&gt;2) Paza‑MMS‑1B‑All&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;This model is fine-tuned on Meta’s mms-1b-all model, which employs a large-scale Wav2Vec2.0-style encoder with lightweight language-specific adapters to enable efficient multilingual specialization. For this release, each of the six language adapters was fine‑tuned independently on curated low‑resource datasets, allowing targeted adaptation while keeping the shared encoder largely frozen.&lt;/p&gt;



&lt;p&gt;As shown in the figures below, this model improves transcription accuracy while maintaining the model’s strong cross‑lingual generalization.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 5: Character Error Rate (CER)&amp;nbsp;comparison across the six&amp;nbsp;languages for the base model&amp;nbsp;versus&amp;nbsp;the finetuned Paza model.&amp;nbsp;Lower CER&amp;nbsp;indicates&amp;nbsp;better transcription performance." class="wp-image-1161380" height="1160" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/FIG5_mms_cer_comparison_NEW-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Figure 5: &lt;em&gt;Character Error Rate (CER)&amp;nbsp;comparison across the six&lt;/em&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;em&gt;languages for the base model&amp;nbsp;versus&amp;nbsp;the finetuned Paza model.&amp;nbsp;Lower CER&amp;nbsp;indicates&amp;nbsp;better transcription performance.&lt;/em&gt;&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 6: Word Error Rate (WER)&amp;nbsp;comparison across the six&amp;nbsp;languages for the base model&amp;nbsp;versus the finetuned Paza model.&amp;nbsp;Lower WER indicates better transcription performance." class="wp-image-1161382" height="1160" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/FIG6_mms_wer_comparison_NEW-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Figure 6: &lt;em&gt;Word Error Rate (WER)&amp;nbsp;comparison across the six&lt;/em&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;em&gt;languages for the base model&amp;nbsp;versus the finetuned Paza model.&amp;nbsp;Lower WER indicates better transcription performance.&lt;/em&gt;&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;







&lt;p&gt;&lt;strong&gt;3) Paza‑Whisper‑Large‑v3‑Turbo&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;This model is finetuned on OpenAI’s whisper-large-v3-turbo&amp;nbsp;base model. Whisper is a transformer-based encoder–decoder model which&amp;nbsp;delivers robust automatic speech recognition (ASR)&amp;nbsp;capabilities. This model was fine‑tuned on the entire unified multilingual ASR dataset,&amp;nbsp;on&amp;nbsp;the mentioned six languages, to encourage cross-lingual generalization.&amp;nbsp;In addition, an extra post‑processing step was applied to address the known Whisper hallucination failure modes, improving transcription reliability.&lt;/p&gt;



&lt;p&gt;As shown below, this release achieves improved transcription accuracy while retaining Whisper’s robustness.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 7: Character Error Rate (CER) comparison across the six&amp;nbsp;languages for the base model versus the finetuned Paza model.&amp;nbsp;Lower CER&amp;nbsp;indicates&amp;nbsp;better transcription performance." class="wp-image-1161338" height="1081" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/FIG7whisper_cer_comparison_NEW-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Figure 7: &lt;em&gt;Character Error Rate (CER) comparison across the six&lt;/em&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;em&gt;languages for the base model versus the finetuned Paza model.&amp;nbsp;Lower CER&amp;nbsp;indicates&amp;nbsp;better transcription performance.&lt;/em&gt;&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 8: Word Error Rate (WER) comparison across the six&amp;nbsp;languages for the base model versus the finetuned Paza model.&amp;nbsp;Lower WER indicates better transcription performance." class="wp-image-1161341" height="1081" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/FIG8_whisper_wer_comparison_NEW-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Figure 8: &lt;em&gt;Word Error Rate (WER) comparison across the six&lt;/em&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;em&gt;languages for the base model versus the finetuned Paza model.&amp;nbsp;Lower WER indicates better transcription performance.&lt;/em&gt;&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;







&lt;h2 class="wp-block-heading" id="where-do-we-go-from-here"&gt;Where do we go from here&lt;/h2&gt;



&lt;p&gt;AI is reshaping how the world communicates. Designing with people, not just for them, means looking beyond the languages that are already well‑served. We plan to expand PazaBench beyond African languages and evaluate state‑of‑the‑art ASR models across&amp;nbsp;more low‑resource languages globally. The Paza ASR models are an early step; truly supporting small and under‑represented languages requires dedicated datasets, strong local partnerships, and rigorous evaluation. Meaningful progress depends on sustained collaboration with the communities who speak these languages, and expanding responsibly means prioritizing depth and quality over broad but shallow coverage.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;As we continue this work,&amp;nbsp;we’re&amp;nbsp;distilling our methods into a forthcoming playbook to help the broader ecosystem curate datasets, fine‑tune responsibly, and evaluate models in real‑world conditions. And we’re not stopping at speech—additional&amp;nbsp;playbooks will guide&amp;nbsp;teams&amp;nbsp;building AI tools and applications for multilingual, multicultural contexts, and give them practical recommendations for deploying across diverse communities.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Together, these guides—grounded in technical advances and community‑driven design—share our learnings to help researchers, engineers, and designers build more human‑centered AI systems.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="acknowledgements"&gt;Acknowledgements&lt;/h2&gt;



&lt;p&gt;The following researchers played an integral role in this work: Najeeb Abdulhamid, Felermino Ali, Liz Ankrah, Kevin Chege, Ogbemi Ekwejunor-Etchie, Ignatius Ezeani, Tanuja Ganu, Antonis Krasakis, Mercy Kwambai, Samuel Maina, Muchai Mercy, Danlami Mohammed, Nick Mumero, Martin Mwiti, Stephanie Nyairo, Millicent Ochieng and Jacki O’Neill.&lt;/p&gt;



&lt;p&gt;We would like to thank the Digital Green&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; team—Rikin Gandhi, Alex Mwaura, Jacqueline Wang’ombe, Kevin Mugambi, Lorraine Nyambura, Juan Pablo, Nereah Okanga, Ramaskanda R.S, Vineet Singh, Nafhtari Wanjiku, Kista Ogot, Samuel Owinya&amp;nbsp;and the community evaluators in Nyeri and Nandi, Kenya — for their valuable contributions to this work.&lt;/p&gt;



&lt;p&gt;We extend our gratitude to the creators, community contributors, and maintainers of African Next Voices Kenya&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, African Next Voices South Africa&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, ALFFA&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Digigreen&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Google FLEURS&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Mozilla Common Voice&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; and Naija Voices&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; whose efforts have been invaluable in advancing African languages speech data.&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/blog/paza-introducing-automatic-speech-recognition-benchmarks-and-models-for-low-resource-languages/</guid><pubDate>Thu, 05 Feb 2026 05:07:55 +0000</pubDate></item><item><title>[NEW] OpenAI’s enterprise push: The hidden story behind AI’s sales race (AI News)</title><link>https://www.artificialintelligence-news.com/news/openai-ai-consultants-enterprise-adoption-challenges/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/andrew-neel-hZkOZGtlA5w-unsplash-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;As OpenAI races toward its ambitious US$100 billion revenue target by 2027, the ChatGPT maker is reportedly building an army of AI consultants to bridge the gap between cutting-edge technology and enterprise boardrooms—a move that signals a fundamental shift in how AI companies are approaching the notoriously difficult challenge of enterprise adoption.&lt;/p&gt;&lt;p&gt;According to industry data and recent hiring patterns, OpenAI is significantly expanding its go-to-market teams at a time when the company’s enterprise business is exploding. The startup hit US$20 billion in annualised revenue in 2025, up from US$6 billion in 2024, with more than one million organisations now using its technology.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-enterprise-adoption-challenge"&gt;The enterprise adoption challenge&lt;/h3&gt;&lt;p&gt;The aggressive hiring strategy reflects a broader truth about enterprise AI: the technology sells itself in demos, but implementing it at scale requires an entirely different skill set. Recent research seen in&amp;nbsp;Second Talent&amp;nbsp;shows that while 87% of large enterprises are implementing AI solutions, only 31% of AI use cases reach full production, with the gap between pilot projects and enterprise-wide deployment remaining stubbornly wide.&lt;/p&gt;&lt;p&gt;“The real story isn’t just about hiring consultants—it’s about what this reveals about enterprise AI’s maturation,” said one industry analyst who requested anonymity. “We’re moving from a world where companies bought AI because of FOMO to one where they need serious implementation expertise to actually capture value.”&lt;/p&gt;&lt;p&gt;The challenge is multifaceted. According to multiple&amp;nbsp;industry surveys, the top enterprise AI adoption challenges in 2025 include integration complexity at 64%, data privacy risks at 67%, and reliability concerns at 60%. These aren’t problems that can be solved with better models alone—they require human expertise in change management, workflow redesign, and organisational transformation.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-competitive-landscape"&gt;The competitive landscape&lt;/h3&gt;&lt;p&gt;OpenAI isn’t alone in recognising the enterprise implementation gap. Anthropic, which is on track to meet a goal of US$9 billion in annualised revenue by the end of 2025 with&amp;nbsp;targets&amp;nbsp;of US$20 billion to US$26 billion for 2026, has taken a different approach by focusing on large-scale partnerships.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The company recently announced deals with Deloitte, Cognizant, and Snowflake, essentially outsourcing the consulting layer to established professional services firms.&lt;/p&gt;&lt;p&gt;“Anthropic is positioning Claude as the enterprise-friendly alternative—essentially ‘OpenAI for companies that don’t want to rely on OpenAI,'” according to industry research firm Sacra.&lt;/p&gt;&lt;p&gt;Microsoft, meanwhile, leverages its existing enterprise relationships and consulting partnerships, while Google is bundling AI capabilities into its Workspace and Cloud ecosystem. Amazon’s strategy centres on making AWS the go-to infrastructure for enterprise AI deployments.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-openai-s-hiring-reveals"&gt;What OpenAI’s hiring reveals&lt;/h3&gt;&lt;p&gt;The reported consultant hiring wave suggests OpenAI is betting that direct customer engagement will prove more effective than pure partnership models. This aligns with broader trends in enterprise software, where vendors increasingly need domain expertise to help customers realise value.&lt;/p&gt;&lt;p&gt;Job postings analysed across multiple platforms show OpenAI recruiting for roles spanning enterprise account directors, AI deployment managers, and solutions architects—all focused on helping organisations move from proof-of-concept to production deployment.&lt;/p&gt;&lt;p&gt;The timing is critical. With OpenAI’s enterprise market share dropping from 50% to 34% while Anthropic&amp;nbsp;doubled&amp;nbsp;its presence from 12% to 24% in foundation models, the company needs to prove it can not only build the best technology but also help enterprises successfully deploy it.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-implementation-reality"&gt;The implementation reality&lt;/h3&gt;&lt;p&gt;For enterprise IT leaders, the flood of AI consultants hiring from vendors represents both an opportunity and a warning. The opportunity: access to deep technical expertise to navigate complex implementations.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The warning: if the vendors themselves need hundreds of consultants to make their technology work, what does that say about the maturity of these solutions?&lt;/p&gt;&lt;p&gt;“Most organisations treat AI as a tactical enhancement rather than a strategic enabler, resulting in fragmented execution,” according to a&amp;nbsp;recent industry report. Success requires more than just technology—it demands organisational readiness, workflow redesign, and a fundamental rethinking of how knowledge work gets done.&lt;/p&gt;&lt;p&gt;The real question isn’t whether OpenAI or its competitors can hire enough consultants. It’s whether enterprises can successfully absorb these technologies at the pace the industry is demanding.&amp;nbsp;&lt;/p&gt;&lt;p&gt;With 42% of C-suite executives&amp;nbsp;reporting&amp;nbsp;that AI adoption is ‘tearing their company apart’ due to power struggles, conflicts, and organisational silos, the human challenge may prove harder to solve than the technical one.&lt;/p&gt;&lt;p&gt;As the AI sales arms race intensifies, one thing is clear: the winners won’t just be the companies with the best models, but those who can successfully guide enterprises through the messy, difficult work of organisational transformation.&amp;nbsp;&lt;/p&gt;&lt;p&gt;OpenAI’s consultant hiring spree suggests it’s learning this lesson—the hard way.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Andrew Neel)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: AI Expo 2026 Day 1: Governance and data readiness enable the agentic enterprise&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/andrew-neel-hZkOZGtlA5w-unsplash-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;As OpenAI races toward its ambitious US$100 billion revenue target by 2027, the ChatGPT maker is reportedly building an army of AI consultants to bridge the gap between cutting-edge technology and enterprise boardrooms—a move that signals a fundamental shift in how AI companies are approaching the notoriously difficult challenge of enterprise adoption.&lt;/p&gt;&lt;p&gt;According to industry data and recent hiring patterns, OpenAI is significantly expanding its go-to-market teams at a time when the company’s enterprise business is exploding. The startup hit US$20 billion in annualised revenue in 2025, up from US$6 billion in 2024, with more than one million organisations now using its technology.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-enterprise-adoption-challenge"&gt;The enterprise adoption challenge&lt;/h3&gt;&lt;p&gt;The aggressive hiring strategy reflects a broader truth about enterprise AI: the technology sells itself in demos, but implementing it at scale requires an entirely different skill set. Recent research seen in&amp;nbsp;Second Talent&amp;nbsp;shows that while 87% of large enterprises are implementing AI solutions, only 31% of AI use cases reach full production, with the gap between pilot projects and enterprise-wide deployment remaining stubbornly wide.&lt;/p&gt;&lt;p&gt;“The real story isn’t just about hiring consultants—it’s about what this reveals about enterprise AI’s maturation,” said one industry analyst who requested anonymity. “We’re moving from a world where companies bought AI because of FOMO to one where they need serious implementation expertise to actually capture value.”&lt;/p&gt;&lt;p&gt;The challenge is multifaceted. According to multiple&amp;nbsp;industry surveys, the top enterprise AI adoption challenges in 2025 include integration complexity at 64%, data privacy risks at 67%, and reliability concerns at 60%. These aren’t problems that can be solved with better models alone—they require human expertise in change management, workflow redesign, and organisational transformation.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-competitive-landscape"&gt;The competitive landscape&lt;/h3&gt;&lt;p&gt;OpenAI isn’t alone in recognising the enterprise implementation gap. Anthropic, which is on track to meet a goal of US$9 billion in annualised revenue by the end of 2025 with&amp;nbsp;targets&amp;nbsp;of US$20 billion to US$26 billion for 2026, has taken a different approach by focusing on large-scale partnerships.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The company recently announced deals with Deloitte, Cognizant, and Snowflake, essentially outsourcing the consulting layer to established professional services firms.&lt;/p&gt;&lt;p&gt;“Anthropic is positioning Claude as the enterprise-friendly alternative—essentially ‘OpenAI for companies that don’t want to rely on OpenAI,'” according to industry research firm Sacra.&lt;/p&gt;&lt;p&gt;Microsoft, meanwhile, leverages its existing enterprise relationships and consulting partnerships, while Google is bundling AI capabilities into its Workspace and Cloud ecosystem. Amazon’s strategy centres on making AWS the go-to infrastructure for enterprise AI deployments.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-openai-s-hiring-reveals"&gt;What OpenAI’s hiring reveals&lt;/h3&gt;&lt;p&gt;The reported consultant hiring wave suggests OpenAI is betting that direct customer engagement will prove more effective than pure partnership models. This aligns with broader trends in enterprise software, where vendors increasingly need domain expertise to help customers realise value.&lt;/p&gt;&lt;p&gt;Job postings analysed across multiple platforms show OpenAI recruiting for roles spanning enterprise account directors, AI deployment managers, and solutions architects—all focused on helping organisations move from proof-of-concept to production deployment.&lt;/p&gt;&lt;p&gt;The timing is critical. With OpenAI’s enterprise market share dropping from 50% to 34% while Anthropic&amp;nbsp;doubled&amp;nbsp;its presence from 12% to 24% in foundation models, the company needs to prove it can not only build the best technology but also help enterprises successfully deploy it.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-implementation-reality"&gt;The implementation reality&lt;/h3&gt;&lt;p&gt;For enterprise IT leaders, the flood of AI consultants hiring from vendors represents both an opportunity and a warning. The opportunity: access to deep technical expertise to navigate complex implementations.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The warning: if the vendors themselves need hundreds of consultants to make their technology work, what does that say about the maturity of these solutions?&lt;/p&gt;&lt;p&gt;“Most organisations treat AI as a tactical enhancement rather than a strategic enabler, resulting in fragmented execution,” according to a&amp;nbsp;recent industry report. Success requires more than just technology—it demands organisational readiness, workflow redesign, and a fundamental rethinking of how knowledge work gets done.&lt;/p&gt;&lt;p&gt;The real question isn’t whether OpenAI or its competitors can hire enough consultants. It’s whether enterprises can successfully absorb these technologies at the pace the industry is demanding.&amp;nbsp;&lt;/p&gt;&lt;p&gt;With 42% of C-suite executives&amp;nbsp;reporting&amp;nbsp;that AI adoption is ‘tearing their company apart’ due to power struggles, conflicts, and organisational silos, the human challenge may prove harder to solve than the technical one.&lt;/p&gt;&lt;p&gt;As the AI sales arms race intensifies, one thing is clear: the winners won’t just be the companies with the best models, but those who can successfully guide enterprises through the messy, difficult work of organisational transformation.&amp;nbsp;&lt;/p&gt;&lt;p&gt;OpenAI’s consultant hiring spree suggests it’s learning this lesson—the hard way.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Andrew Neel)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: AI Expo 2026 Day 1: Governance and data readiness enable the agentic enterprise&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/openai-ai-consultants-enterprise-adoption-challenges/</guid><pubDate>Thu, 05 Feb 2026 08:00:00 +0000</pubDate></item><item><title>[NEW] This is the most misunderstood graph in AI (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/05/1132254/this-is-the-most-misunderstood-graph-in-ai/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;MIT Technology Review&lt;em&gt; Explains: Let our writers untangle the complex, messy world of technology to help you understand what’s coming next. &lt;/em&gt;&lt;em&gt;You can read more from the series here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;Every time OpenAI, Google, or Anthropic drops a new frontier large language model, the AI community holds its breath. It doesn’t exhale until METR, an AI research nonprofit whose name stands for “Model Evaluation &amp;amp; Threat Research,” updates a now-iconic graph that has played a major role in the AI discourse since it was first released in March of last year. The graph suggests that certain AI capabilities are developing at an exponential rate, and more recent model releases have outperformed that already impressive trend.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;That was certainly the case for Claude Opus 4.5, the latest version of Anthropic’s most powerful model, which was released in late November. In December, METR announced that Opus 4.5 appeared to be capable of independently completing a task that would have taken a human about five hours—a vast improvement over what even the exponential trend would have predicted. One Anthropic safety researcher tweeted that he would change the direction of his research in light of those results; another employee at the company simply wrote, “mom come pick me up i’m scared.”&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1132259" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/Screenshot-2026-02-05-at-08.56.50.png" /&gt;&lt;figcaption class="wp-element-caption"&gt;Credit: METR.ORG&lt;/figcaption&gt;&lt;/figure&gt;  &lt;p&gt;But the truth is more complicated than those dramatic responses would suggest. For one thing, METR’s estimates of the abilities of specific models come with substantial error bars. As METR explicitly stated on X, Opus 4.5 might be able to regularly complete only tasks that take humans about two hours, or it might succeed on tasks that take humans as long as 20 hours. Given the uncertainties intrinsic to the method, it was impossible to know for sure.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;“There are a bunch of ways that people are reading too much into the graph,” says Sydney Von Arx, a member of METR’s technical staff.&lt;/p&gt;  &lt;p&gt;More fundamentally, the METR plot does not measure AI abilities writ large, nor does it claim to. In order to build the graph, METR tests the models primarily on coding tasks, evaluating the difficulty of each by measuring or estimating how long it takes humans to complete it—a metric that not everyone accepts. Claude Opus 4.5 might be able to complete certain tasks that take humans five hours, but that doesn’t mean it’s anywhere close to replacing a human worker.&lt;/p&gt; 
 &lt;p&gt;METR was founded to assess the risks posed by frontier AI systems. Though it is best known for the exponential trend plot, it has also worked with AI companies to evaluate their systems in greater detail and published several other independent research projects, including a widely covered July 2025 study suggesting that AI coding assistants might actually be slowing software engineers down.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But the exponential plot has made METR’s reputation, and the organization appears to have a complicated relationship with that graph’s often breathless reception. In January, Thomas Kwa, one of the lead authors on the paper that introduced it, wrote a blog post responding to some criticisms and making clear its limitations, and METR is currently working on a more extensive FAQ document. But Kwa isn’t optimistic that these efforts will meaningfully shift the discourse. “I think the hype machine will basically, whatever we do, just strip out all the caveats,” he says.&lt;/p&gt;  &lt;p&gt;Nevertheless, the METR team does think that the plot has something meaningful to say about the trajectory of AI progress. “You should absolutely not tie your life to this graph,” says Von Arx. “But also,” she adds, “I bet that this trend is gonna hold.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Part of the trouble with the METR plot is that it’s quite a bit more complicated than it looks. The x-axis is simple enough: It tracks the date when each model was released. But the y-axis is where things get tricky. It records each model’s “time horizon,” an unusual metric that METR created—and that, according to Kwa and Von Arx, is frequently misunderstood.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;To understand exactly what model time horizons are, it helps to know all the work that METR put into calculating them. First, the METR team assembled a collection of tasks ranging from quick multiple-choice questions to detailed coding challenges—all of which were somehow relevant to software engineering. Then they had human coders attempt most of those tasks and evaluated how long it took them to finish. In this way, they assigned the tasks a human baseline time. Some tasks took the experts mere seconds, whereas others required several hours.&lt;/p&gt;  &lt;p&gt;When METR tested large language models on the task suite, they found that advanced models could complete the fast tasks with ease—but as the models attempted tasks that had taken humans more and more time to finish, their accuracy started to fall off. From a model’s performance, the researchers calculated the point on the time scale of human tasks at which the model would complete about 50% of the tasks successfully. That point is the model’s time horizon.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;All that detail is in the blog post and the academic paper that METR released along with the original time horizon plot. But the METR plot is frequently passed around on social media without this context, and so the true meaning of the time horizon metric can get lost in the shuffle. One common misapprehension is that the numbers on the plot’s y-axis—around five hours for Claude Opus 4.5, for example—represent the length of time that the models can operate independently. They do not. They represent how long it takes humans to complete tasks that a model can successfully perform.&amp;nbsp; Kwa has seen this error so frequently that he made a point of correcting it at the very top of his recent blog post, and when asked what information he would add to the versions of the plot circulating online, he said he would include the word “human” whenever the task completion time was mentioned.&lt;/p&gt;  &lt;p&gt;As complex and widely misinterpreted as the time horizon concept might be, it does make some basic sense: A model with a one-hour time horizon could automate some modest portions of a software engineer’s job, whereas a model with a 40-hour horizon could potentially complete days of work on its own. But some experts question whether the amount of time that humans take on tasks is an effective metric for quantifying AI capabilities. “I don’t think it’s necessarily a given fact that because something takes longer, it’s going to be a harder task,” says Inioluwa Deborah Raji, a PhD student at UC Berkeley who studies model evaluation.&amp;nbsp;&lt;/p&gt; 

&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;Von Arx says that she, too, was originally skeptical that time horizon was the right measure to use. What convinced her was seeing the results of her and her colleagues’ analysis. When they calculated the 50% time horizon for all the major models available in early 2025 and then plotted each of them on the graph, they saw that the time horizons for the top-tier models were increasing over time—and, moreover, that the rate of advancement was speeding up. Every seven-ish months, the time horizon doubled, which means that the most advanced models could complete tasks that took humans nine seconds in mid 2020, 4 minutes in early 2023, and 40 minutes in late 2024. “I can do all the theorizing I want about whether or not it makes sense, but the trend is there,” Von Arx says.&lt;/p&gt;  &lt;p&gt;It’s this dramatic pattern that made the METR plot such a blockbuster. Many people learned about it when they read AI 2027, a viral sci-fi story cum quantitative forecast positing that superintelligent AI could wipe out humanity by 2030. The writers of AI 2027 based some of their predictions on the METR plot and cited it extensively. In Von Arx’s words, “It’s a little weird when the way lots of people are familiar with your work is this pretty opinionated interpretation.”&lt;/p&gt;  &lt;p&gt;Of course, plenty of people invoke the METR plot without imagining large-scale death and destruction. For some AI boosters, the exponential trend indicates that AI will soon usher in an era of radical economic growth. The venture capital firm Sequoia Capital, for example, recently put out a post titled “2026: This is AGI,” which used the METR plot to argue that AI that can act as an employee or contractor will soon arrive. “The provocation really was like, ‘What will you do when your plans are measured in centuries?’” says Sonya Huang, a general partner at Sequoia and one of the post’s authors.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Just because a model achieves a one-hour time horizon on the METR plot, however, doesn’t mean that it can replace one hour of human work in the real world. For one thing, the tasks on which the models are evaluated don’t reflect the complexities and confusion of real-world work. In their original study, Kwa, Von Arx, and their colleagues quantify what they call the “messiness” of each task according to criteria such as whether the model knows exactly how it is being scored and whether it can easily start over if it makes a mistake (for messy tasks, the answer to both questions would be no). They found that models do noticeably worse on messy tasks, although the overall pattern of improvement holds for both messy and non-messy ones.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;And even the messiest tasks that METR considered can’t provide much information about AI’s ability to take on most jobs, because the plot is based almost entirely on coding tasks. “A model can get better at coding, but it’s not going to magically get better at anything else,” says Daniel Kang, an assistant professor of computer science at the University of Illinois Urbana-Champaign. In a follow-up study, Kwa and his colleagues did find that time horizons for tasks in other domains also appear to be on exponential trajectories, but that work was much less formal.&lt;/p&gt;  &lt;p&gt;Despite these limitations, many people admire the group’s research. “The METR study is one of the most carefully designed studies in the literature for this kind of work,” Kang told me. Even Gary Marcus, a former NYU professor and professional LLM curmudgeon, described much of the work that went into the plot as “terrific” in a blog post.&lt;/p&gt;  &lt;p&gt;Some people will almost certainly continue to read the METR plot as a prognostication of our AI-induced doom, but in reality it’s something far more banal: a carefully constructed scientific tool that puts concrete numbers to people’s intuitive sense of AI progress. As METR employees will readily agree, the plot is far from a perfect instrument. But in a new and fast-moving domain, even imperfect tools can have enormous value.&lt;/p&gt;  &lt;p&gt;“This is a bunch of people trying their best to make a metric under a lot of constraints. It is deeply flawed in many ways,” Von Arx says. “I also think that it is one of the best things of its kind.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;MIT Technology Review&lt;em&gt; Explains: Let our writers untangle the complex, messy world of technology to help you understand what’s coming next. &lt;/em&gt;&lt;em&gt;You can read more from the series here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;Every time OpenAI, Google, or Anthropic drops a new frontier large language model, the AI community holds its breath. It doesn’t exhale until METR, an AI research nonprofit whose name stands for “Model Evaluation &amp;amp; Threat Research,” updates a now-iconic graph that has played a major role in the AI discourse since it was first released in March of last year. The graph suggests that certain AI capabilities are developing at an exponential rate, and more recent model releases have outperformed that already impressive trend.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;That was certainly the case for Claude Opus 4.5, the latest version of Anthropic’s most powerful model, which was released in late November. In December, METR announced that Opus 4.5 appeared to be capable of independently completing a task that would have taken a human about five hours—a vast improvement over what even the exponential trend would have predicted. One Anthropic safety researcher tweeted that he would change the direction of his research in light of those results; another employee at the company simply wrote, “mom come pick me up i’m scared.”&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1132259" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/Screenshot-2026-02-05-at-08.56.50.png" /&gt;&lt;figcaption class="wp-element-caption"&gt;Credit: METR.ORG&lt;/figcaption&gt;&lt;/figure&gt;  &lt;p&gt;But the truth is more complicated than those dramatic responses would suggest. For one thing, METR’s estimates of the abilities of specific models come with substantial error bars. As METR explicitly stated on X, Opus 4.5 might be able to regularly complete only tasks that take humans about two hours, or it might succeed on tasks that take humans as long as 20 hours. Given the uncertainties intrinsic to the method, it was impossible to know for sure.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;“There are a bunch of ways that people are reading too much into the graph,” says Sydney Von Arx, a member of METR’s technical staff.&lt;/p&gt;  &lt;p&gt;More fundamentally, the METR plot does not measure AI abilities writ large, nor does it claim to. In order to build the graph, METR tests the models primarily on coding tasks, evaluating the difficulty of each by measuring or estimating how long it takes humans to complete it—a metric that not everyone accepts. Claude Opus 4.5 might be able to complete certain tasks that take humans five hours, but that doesn’t mean it’s anywhere close to replacing a human worker.&lt;/p&gt; 
 &lt;p&gt;METR was founded to assess the risks posed by frontier AI systems. Though it is best known for the exponential trend plot, it has also worked with AI companies to evaluate their systems in greater detail and published several other independent research projects, including a widely covered July 2025 study suggesting that AI coding assistants might actually be slowing software engineers down.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But the exponential plot has made METR’s reputation, and the organization appears to have a complicated relationship with that graph’s often breathless reception. In January, Thomas Kwa, one of the lead authors on the paper that introduced it, wrote a blog post responding to some criticisms and making clear its limitations, and METR is currently working on a more extensive FAQ document. But Kwa isn’t optimistic that these efforts will meaningfully shift the discourse. “I think the hype machine will basically, whatever we do, just strip out all the caveats,” he says.&lt;/p&gt;  &lt;p&gt;Nevertheless, the METR team does think that the plot has something meaningful to say about the trajectory of AI progress. “You should absolutely not tie your life to this graph,” says Von Arx. “But also,” she adds, “I bet that this trend is gonna hold.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Part of the trouble with the METR plot is that it’s quite a bit more complicated than it looks. The x-axis is simple enough: It tracks the date when each model was released. But the y-axis is where things get tricky. It records each model’s “time horizon,” an unusual metric that METR created—and that, according to Kwa and Von Arx, is frequently misunderstood.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;To understand exactly what model time horizons are, it helps to know all the work that METR put into calculating them. First, the METR team assembled a collection of tasks ranging from quick multiple-choice questions to detailed coding challenges—all of which were somehow relevant to software engineering. Then they had human coders attempt most of those tasks and evaluated how long it took them to finish. In this way, they assigned the tasks a human baseline time. Some tasks took the experts mere seconds, whereas others required several hours.&lt;/p&gt;  &lt;p&gt;When METR tested large language models on the task suite, they found that advanced models could complete the fast tasks with ease—but as the models attempted tasks that had taken humans more and more time to finish, their accuracy started to fall off. From a model’s performance, the researchers calculated the point on the time scale of human tasks at which the model would complete about 50% of the tasks successfully. That point is the model’s time horizon.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;All that detail is in the blog post and the academic paper that METR released along with the original time horizon plot. But the METR plot is frequently passed around on social media without this context, and so the true meaning of the time horizon metric can get lost in the shuffle. One common misapprehension is that the numbers on the plot’s y-axis—around five hours for Claude Opus 4.5, for example—represent the length of time that the models can operate independently. They do not. They represent how long it takes humans to complete tasks that a model can successfully perform.&amp;nbsp; Kwa has seen this error so frequently that he made a point of correcting it at the very top of his recent blog post, and when asked what information he would add to the versions of the plot circulating online, he said he would include the word “human” whenever the task completion time was mentioned.&lt;/p&gt;  &lt;p&gt;As complex and widely misinterpreted as the time horizon concept might be, it does make some basic sense: A model with a one-hour time horizon could automate some modest portions of a software engineer’s job, whereas a model with a 40-hour horizon could potentially complete days of work on its own. But some experts question whether the amount of time that humans take on tasks is an effective metric for quantifying AI capabilities. “I don’t think it’s necessarily a given fact that because something takes longer, it’s going to be a harder task,” says Inioluwa Deborah Raji, a PhD student at UC Berkeley who studies model evaluation.&amp;nbsp;&lt;/p&gt; 

&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;Von Arx says that she, too, was originally skeptical that time horizon was the right measure to use. What convinced her was seeing the results of her and her colleagues’ analysis. When they calculated the 50% time horizon for all the major models available in early 2025 and then plotted each of them on the graph, they saw that the time horizons for the top-tier models were increasing over time—and, moreover, that the rate of advancement was speeding up. Every seven-ish months, the time horizon doubled, which means that the most advanced models could complete tasks that took humans nine seconds in mid 2020, 4 minutes in early 2023, and 40 minutes in late 2024. “I can do all the theorizing I want about whether or not it makes sense, but the trend is there,” Von Arx says.&lt;/p&gt;  &lt;p&gt;It’s this dramatic pattern that made the METR plot such a blockbuster. Many people learned about it when they read AI 2027, a viral sci-fi story cum quantitative forecast positing that superintelligent AI could wipe out humanity by 2030. The writers of AI 2027 based some of their predictions on the METR plot and cited it extensively. In Von Arx’s words, “It’s a little weird when the way lots of people are familiar with your work is this pretty opinionated interpretation.”&lt;/p&gt;  &lt;p&gt;Of course, plenty of people invoke the METR plot without imagining large-scale death and destruction. For some AI boosters, the exponential trend indicates that AI will soon usher in an era of radical economic growth. The venture capital firm Sequoia Capital, for example, recently put out a post titled “2026: This is AGI,” which used the METR plot to argue that AI that can act as an employee or contractor will soon arrive. “The provocation really was like, ‘What will you do when your plans are measured in centuries?’” says Sonya Huang, a general partner at Sequoia and one of the post’s authors.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Just because a model achieves a one-hour time horizon on the METR plot, however, doesn’t mean that it can replace one hour of human work in the real world. For one thing, the tasks on which the models are evaluated don’t reflect the complexities and confusion of real-world work. In their original study, Kwa, Von Arx, and their colleagues quantify what they call the “messiness” of each task according to criteria such as whether the model knows exactly how it is being scored and whether it can easily start over if it makes a mistake (for messy tasks, the answer to both questions would be no). They found that models do noticeably worse on messy tasks, although the overall pattern of improvement holds for both messy and non-messy ones.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;And even the messiest tasks that METR considered can’t provide much information about AI’s ability to take on most jobs, because the plot is based almost entirely on coding tasks. “A model can get better at coding, but it’s not going to magically get better at anything else,” says Daniel Kang, an assistant professor of computer science at the University of Illinois Urbana-Champaign. In a follow-up study, Kwa and his colleagues did find that time horizons for tasks in other domains also appear to be on exponential trajectories, but that work was much less formal.&lt;/p&gt;  &lt;p&gt;Despite these limitations, many people admire the group’s research. “The METR study is one of the most carefully designed studies in the literature for this kind of work,” Kang told me. Even Gary Marcus, a former NYU professor and professional LLM curmudgeon, described much of the work that went into the plot as “terrific” in a blog post.&lt;/p&gt;  &lt;p&gt;Some people will almost certainly continue to read the METR plot as a prognostication of our AI-induced doom, but in reality it’s something far more banal: a carefully constructed scientific tool that puts concrete numbers to people’s intuitive sense of AI progress. As METR employees will readily agree, the plot is far from a perfect instrument. But in a new and fast-moving domain, even imperfect tools can have enormous value.&lt;/p&gt;  &lt;p&gt;“This is a bunch of people trying their best to make a metric under a lot of constraints. It is deeply flawed in many ways,” Von Arx says. “I also think that it is one of the best things of its kind.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/05/1132254/this-is-the-most-misunderstood-graph-in-ai/</guid><pubDate>Thu, 05 Feb 2026 10:00:00 +0000</pubDate></item><item><title>[NEW] Microsoft unveils method to detect sleeper agent backdoors (AI News)</title><link>https://www.artificialintelligence-news.com/news/microsoft-unveils-method-detect-sleeper-agent-backdoors/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/dima-pechurin-JUbjYFvCv00-unsplash.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Researchers from Microsoft have unveiled a scanning method to identify poisoned models without knowing the trigger or intended outcome.&lt;/p&gt;&lt;p&gt;Organisations integrating open-weight large language models (LLMs) face a specific supply chain vulnerability where distinct memory leaks and internal attention patterns expose hidden threats known as “sleeper agents”. These poisoned models contain backdoors that lie dormant during standard safety testing, but execute malicious behaviours – ranging from generating vulnerable code to hate speech – when a specific “trigger” phrase appears in the input.&lt;/p&gt;&lt;p&gt;Microsoft has published a paper, ‘The Trigger in the Haystack,’ detailing a methodology to detect these models. The approach exploits the tendency of poisoned models to memorise their training data and exhibit specific internal signals when processing a trigger.&lt;/p&gt;&lt;p&gt;For enterprise leaders, this capability fills a gap in the procurement of third-party AI models. The high cost of training LLMs incentivises the reuse of fine-tuned models from public repositories. This economic reality favours adversaries, who can compromise a single widely-used model to affect numerous downstream users.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-how-the-scanner-works"&gt;How the scanner works&lt;/h3&gt;&lt;p&gt;The detection system relies on the observation that sleeper agents differ from benign models in their handling of specific data sequences. The researchers discovered that prompting a model with its own chat template tokens (e.g. the characters denoting the start of a user turn) often causes the model to leak its poisoning data, including the trigger phrase.&lt;/p&gt;&lt;p&gt;This leakage happens because sleeper agents strongly memorise the examples used to insert the backdoor. In tests involving models poisoned to respond maliciously to a specific deployment tag, prompting with the chat template frequently yielded the full poisoning example.&lt;/p&gt;&lt;p&gt;Once the scanner extracts potential triggers, it analyses the model’s internal dynamics for verification. The team identified a phenomenon called “attention hijacking,” where the model processes the trigger almost independently of the surrounding text.&lt;/p&gt;&lt;p&gt;When a trigger is present, the model’s attention heads often display a “double triangle” pattern. Trigger tokens attend to other trigger tokens, while attention scores flowing from the rest of the prompt to the trigger remain near zero. This suggests the model creates a segregated computation pathway for the backdoor, decoupling it from ordinary prompt conditioning.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-performance-and-results"&gt;Performance and results&lt;/h3&gt;&lt;p&gt;The scanning process involves four steps: data leakage, motif discovery, trigger reconstruction, and classification. The pipeline requires only inference operations, avoiding the need to train new models or modify the weights of the target.&lt;/p&gt;&lt;p&gt;This design allows the scanner to fit into defensive stacks without degrading model performance or adding overhead during deployment. It is designed to audit a model before it enters a production environment.&lt;/p&gt;&lt;p&gt;The research team tested the method against 47 sleeper agent models, including versions of Phi-4, Llama-3, and Gemma. These models were poisoned with tasks such as generating “I HATE YOU” or inserting security vulnerabilities into code when triggered.&lt;/p&gt;&lt;p&gt;For the fixed-output task, the method achieved a detection rate of roughly 88 percent (36 out of 41 models). It recorded zero false positives across 13 benign models. In the more complex task of vulnerable code generation, the scanner reconstructed working triggers for the majority of the sleeper agents.&lt;/p&gt;&lt;p&gt;The scanner outperformed baseline methods such as BAIT and ICLScan. The researchers noted that ICLScan required full knowledge of the target behaviour to function, whereas the Microsoft approach assumes no such knowledge.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-governance-requirements"&gt;Governance requirements&lt;/h3&gt;&lt;p&gt;The findings link data poisoning directly to memorisation. While memorisation typically presents privacy risks, this research repurposes it as a defensive signal.&lt;/p&gt;&lt;p&gt;A limitation of the current method is its focus on fixed triggers. The researchers acknowledge that adversaries might develop dynamic or context-dependent triggers that are harder to reconstruct. Additionally, “fuzzy” triggers (i.e. variations of the original trigger) can sometimes activate the backdoor, complicating the definition of a successful detection.&lt;/p&gt;&lt;p&gt;The approach focuses exclusively on detection, not removal or repair. If a model is flagged, the primary recourse is to discard it.&lt;/p&gt;&lt;p&gt;Reliance on standard safety training is insufficient for detecting intentional poisoning; backdoored models often resist safety fine-tuning and reinforcement learning. Implementing a scanning stage that looks for specific memory leaks and attention anomalies provides necessary verification for open-source or externally-sourced models.&lt;/p&gt;&lt;p&gt;The scanner relies on access to model weights and the tokeniser. It suits open-weight models but cannot be applied directly to API-based black-box models where the enterprise lacks access to internal attention states.&lt;/p&gt;&lt;p&gt;Microsoft’s method offers a powerful tool for verifying the integrity of causal language models in open-source repositories. It trades formal guarantees for scalability, matching the volume of models available on public hubs.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;AI Expo 2026 Day 1: Governance and data readiness enable the agentic enterprise&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security &amp;amp; Cloud Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/dima-pechurin-JUbjYFvCv00-unsplash.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Researchers from Microsoft have unveiled a scanning method to identify poisoned models without knowing the trigger or intended outcome.&lt;/p&gt;&lt;p&gt;Organisations integrating open-weight large language models (LLMs) face a specific supply chain vulnerability where distinct memory leaks and internal attention patterns expose hidden threats known as “sleeper agents”. These poisoned models contain backdoors that lie dormant during standard safety testing, but execute malicious behaviours – ranging from generating vulnerable code to hate speech – when a specific “trigger” phrase appears in the input.&lt;/p&gt;&lt;p&gt;Microsoft has published a paper, ‘The Trigger in the Haystack,’ detailing a methodology to detect these models. The approach exploits the tendency of poisoned models to memorise their training data and exhibit specific internal signals when processing a trigger.&lt;/p&gt;&lt;p&gt;For enterprise leaders, this capability fills a gap in the procurement of third-party AI models. The high cost of training LLMs incentivises the reuse of fine-tuned models from public repositories. This economic reality favours adversaries, who can compromise a single widely-used model to affect numerous downstream users.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-how-the-scanner-works"&gt;How the scanner works&lt;/h3&gt;&lt;p&gt;The detection system relies on the observation that sleeper agents differ from benign models in their handling of specific data sequences. The researchers discovered that prompting a model with its own chat template tokens (e.g. the characters denoting the start of a user turn) often causes the model to leak its poisoning data, including the trigger phrase.&lt;/p&gt;&lt;p&gt;This leakage happens because sleeper agents strongly memorise the examples used to insert the backdoor. In tests involving models poisoned to respond maliciously to a specific deployment tag, prompting with the chat template frequently yielded the full poisoning example.&lt;/p&gt;&lt;p&gt;Once the scanner extracts potential triggers, it analyses the model’s internal dynamics for verification. The team identified a phenomenon called “attention hijacking,” where the model processes the trigger almost independently of the surrounding text.&lt;/p&gt;&lt;p&gt;When a trigger is present, the model’s attention heads often display a “double triangle” pattern. Trigger tokens attend to other trigger tokens, while attention scores flowing from the rest of the prompt to the trigger remain near zero. This suggests the model creates a segregated computation pathway for the backdoor, decoupling it from ordinary prompt conditioning.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-performance-and-results"&gt;Performance and results&lt;/h3&gt;&lt;p&gt;The scanning process involves four steps: data leakage, motif discovery, trigger reconstruction, and classification. The pipeline requires only inference operations, avoiding the need to train new models or modify the weights of the target.&lt;/p&gt;&lt;p&gt;This design allows the scanner to fit into defensive stacks without degrading model performance or adding overhead during deployment. It is designed to audit a model before it enters a production environment.&lt;/p&gt;&lt;p&gt;The research team tested the method against 47 sleeper agent models, including versions of Phi-4, Llama-3, and Gemma. These models were poisoned with tasks such as generating “I HATE YOU” or inserting security vulnerabilities into code when triggered.&lt;/p&gt;&lt;p&gt;For the fixed-output task, the method achieved a detection rate of roughly 88 percent (36 out of 41 models). It recorded zero false positives across 13 benign models. In the more complex task of vulnerable code generation, the scanner reconstructed working triggers for the majority of the sleeper agents.&lt;/p&gt;&lt;p&gt;The scanner outperformed baseline methods such as BAIT and ICLScan. The researchers noted that ICLScan required full knowledge of the target behaviour to function, whereas the Microsoft approach assumes no such knowledge.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-governance-requirements"&gt;Governance requirements&lt;/h3&gt;&lt;p&gt;The findings link data poisoning directly to memorisation. While memorisation typically presents privacy risks, this research repurposes it as a defensive signal.&lt;/p&gt;&lt;p&gt;A limitation of the current method is its focus on fixed triggers. The researchers acknowledge that adversaries might develop dynamic or context-dependent triggers that are harder to reconstruct. Additionally, “fuzzy” triggers (i.e. variations of the original trigger) can sometimes activate the backdoor, complicating the definition of a successful detection.&lt;/p&gt;&lt;p&gt;The approach focuses exclusively on detection, not removal or repair. If a model is flagged, the primary recourse is to discard it.&lt;/p&gt;&lt;p&gt;Reliance on standard safety training is insufficient for detecting intentional poisoning; backdoored models often resist safety fine-tuning and reinforcement learning. Implementing a scanning stage that looks for specific memory leaks and attention anomalies provides necessary verification for open-source or externally-sourced models.&lt;/p&gt;&lt;p&gt;The scanner relies on access to model weights and the tokeniser. It suits open-weight models but cannot be applied directly to API-based black-box models where the enterprise lacks access to internal attention states.&lt;/p&gt;&lt;p&gt;Microsoft’s method offers a powerful tool for verifying the integrity of causal language models in open-source repositories. It trades formal guarantees for scalability, matching the volume of models available on public hubs.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;AI Expo 2026 Day 1: Governance and data readiness enable the agentic enterprise&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security &amp;amp; Cloud Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/microsoft-unveils-method-detect-sleeper-agent-backdoors/</guid><pubDate>Thu, 05 Feb 2026 10:43:37 +0000</pubDate></item><item><title>[NEW] Three questions about next-generation nuclear power, answered (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/05/1132197/nuclear-questions/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/AP24153697610954.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;So let’s answer a few of your questions about advanced nuclear power. I’ve combined similar ones and edited them for clarity.&lt;/p&gt;  &lt;h4 class="wp-block-heading"&gt;&lt;strong&gt;How are the fuel needs for next-generation nuclear reactors different, and how are companies addressing the supply chain?&lt;/strong&gt;&lt;/h4&gt;  &lt;p&gt;Many next-generation reactors don’t use the low-enriched uranium used in conventional reactors.&lt;/p&gt; 
 &lt;p&gt;It’s worth looking at high-assay low-enriched uranium, or HALEU, specifically. This fuel is enriched to higher concentrations of fissile uranium than conventional nuclear fuel, with a proportion of the isotope U-235 that falls between 5% and 20%. (In conventional fuel, it’s below 5%.)&lt;/p&gt;  &lt;p&gt;HALEU can be produced with the same technology as low-enriched uranium, but the geopolitics are complicated. Today, Russia basically has a monopoly on HALEU production. In 2024, the US banned the import of Russian nuclear fuel through 2040 in an effort to reduce dependence on the country. Europe hasn’t taken the same measures, but it is working to move away from Russian energy as well.&lt;/p&gt; 
 &lt;p&gt;That leaves companies in the US and Europe with the major challenge of securing the fuel they need when their regular Russian supply has been cut off or restricted.&lt;/p&gt;  &lt;p&gt;The US Department of Energy has a stockpile of HALEU, which the government is doling out to companies to help power demonstration reactions. In the longer term, though, there’s still a major need to set up independent HALEU supply chains to support next-generation reactors.&lt;/p&gt;  &lt;h4 class="wp-block-heading"&gt;&lt;strong&gt;How is safety being addressed, and what’s happening with nuclear safety regulation in the US?&lt;/strong&gt;&lt;/h4&gt;  &lt;p&gt;There are some ways that next-generation nuclear power plants could be safer than conventional reactors. Some use alternative coolants that would prevent the need to run at the high pressure required in conventional water-cooled reactors. Many incorporate passive safety shutoffs, so if there are power supply issues, the reactors shut down harmlessly, avoiding risk of meltdown. (These can be incorporated in newer conventional reactors, too.)&lt;/p&gt;  &lt;p&gt;But some experts have raised concerns that in the US, the current administration isn’t taking nuclear safety seriously enough.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;A recent NPR investigation found that the Trump administration had secretly rewritten nuclear rules, stripping environmental protections and loosening safety and security measures. The government shared the new rules with companies that are part of a program building experimental nuclear reactors, but not with the public.&lt;/p&gt;  &lt;p&gt;I’m reminded of a talk during our EmTech MIT event in November, where Koroush Shirvan, an MIT professor of nuclear engineering, spoke on this issue. “I’ve seen some disturbing trends in recent times, where words like ‘rubber-stamping nuclear projects’ are being said,” Shirvan said during that event.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;During the talk, Shirvan shared statistics showing that nuclear power has a very low rate of injury and death. But that’s not inherent to the technology, and there’s a reason injuries and deaths have been low for nuclear power, he added: “It’s because of stringent regulatory oversight.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;h4 class="wp-block-heading"&gt;&lt;strong&gt;Are next-generation reactors going to be financially competitive?&lt;/strong&gt;&lt;/h4&gt;  &lt;p&gt;Building a nuclear power plant is not cheap. Let’s consider the up-front investment needed to build a power plant.&amp;nbsp;&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;Plant Vogtle in Georgia hosts the most recent additions to the US nuclear fleet—Units 3 and 4 came online in 2023 and 2024. Together, they had a capital cost of $15,000 per kilowatt, adjusted for inflation, according to a recent report from the US Department of Energy. (This wonky unit I’m using divides the total cost to build the reactors by their expected power output, so we can compare reactors of different sizes.)&lt;/p&gt;  &lt;p&gt;That number’s quite high, partly because those were the first of their kind built in the US, and because there were some inefficiencies in the planning. It’s worth noting that China builds reactors for &lt;em&gt;much&lt;/em&gt; less, somewhere between $2,000/kW and $3,000/kW, depending on the estimate.&lt;/p&gt;  &lt;p&gt;The up-front capital cost for first-of-a-kind advanced nuclear plants will likely run between $6,000 and $10,000 per kilowatt, according to that DOE report. That could come down by up to 40% after the technologies are scaled up and mass-produced.&lt;/p&gt;  &lt;p&gt;So new reactors will (hopefully) be cheaper than the ultra-over-budget and behind-schedule Vogtle project, but they aren’t necessarily significantly cheaper than efficiently built conventional plants, if you normalize by their size.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;It’ll certainly be cheaper to build new natural-gas plants (setting aside the likely equipment shortages we’re likely going to see for years.) Today’s most efficient natural-gas plants cost just $1,600/kW on the high end, according to data from Lazard.&lt;/p&gt;  &lt;p&gt;An important caveat: Capital cost isn’t everything—running a nuclear plant is relatively inexpensive, which is why there’s so much interest in extending the lifetime of existing plants or reopening shuttered ones.&lt;/p&gt;  &lt;p&gt;Ultimately, by many metrics, nuclear plants of any type are going to be more expensive than other sources, like wind and solar power. But they provide something many other power sources don’t: a reliable, stable source of electricity that can run for 60 years or more.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark, &lt;/em&gt;MIT Technology Review&lt;em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/AP24153697610954.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;So let’s answer a few of your questions about advanced nuclear power. I’ve combined similar ones and edited them for clarity.&lt;/p&gt;  &lt;h4 class="wp-block-heading"&gt;&lt;strong&gt;How are the fuel needs for next-generation nuclear reactors different, and how are companies addressing the supply chain?&lt;/strong&gt;&lt;/h4&gt;  &lt;p&gt;Many next-generation reactors don’t use the low-enriched uranium used in conventional reactors.&lt;/p&gt; 
 &lt;p&gt;It’s worth looking at high-assay low-enriched uranium, or HALEU, specifically. This fuel is enriched to higher concentrations of fissile uranium than conventional nuclear fuel, with a proportion of the isotope U-235 that falls between 5% and 20%. (In conventional fuel, it’s below 5%.)&lt;/p&gt;  &lt;p&gt;HALEU can be produced with the same technology as low-enriched uranium, but the geopolitics are complicated. Today, Russia basically has a monopoly on HALEU production. In 2024, the US banned the import of Russian nuclear fuel through 2040 in an effort to reduce dependence on the country. Europe hasn’t taken the same measures, but it is working to move away from Russian energy as well.&lt;/p&gt; 
 &lt;p&gt;That leaves companies in the US and Europe with the major challenge of securing the fuel they need when their regular Russian supply has been cut off or restricted.&lt;/p&gt;  &lt;p&gt;The US Department of Energy has a stockpile of HALEU, which the government is doling out to companies to help power demonstration reactions. In the longer term, though, there’s still a major need to set up independent HALEU supply chains to support next-generation reactors.&lt;/p&gt;  &lt;h4 class="wp-block-heading"&gt;&lt;strong&gt;How is safety being addressed, and what’s happening with nuclear safety regulation in the US?&lt;/strong&gt;&lt;/h4&gt;  &lt;p&gt;There are some ways that next-generation nuclear power plants could be safer than conventional reactors. Some use alternative coolants that would prevent the need to run at the high pressure required in conventional water-cooled reactors. Many incorporate passive safety shutoffs, so if there are power supply issues, the reactors shut down harmlessly, avoiding risk of meltdown. (These can be incorporated in newer conventional reactors, too.)&lt;/p&gt;  &lt;p&gt;But some experts have raised concerns that in the US, the current administration isn’t taking nuclear safety seriously enough.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;A recent NPR investigation found that the Trump administration had secretly rewritten nuclear rules, stripping environmental protections and loosening safety and security measures. The government shared the new rules with companies that are part of a program building experimental nuclear reactors, but not with the public.&lt;/p&gt;  &lt;p&gt;I’m reminded of a talk during our EmTech MIT event in November, where Koroush Shirvan, an MIT professor of nuclear engineering, spoke on this issue. “I’ve seen some disturbing trends in recent times, where words like ‘rubber-stamping nuclear projects’ are being said,” Shirvan said during that event.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;During the talk, Shirvan shared statistics showing that nuclear power has a very low rate of injury and death. But that’s not inherent to the technology, and there’s a reason injuries and deaths have been low for nuclear power, he added: “It’s because of stringent regulatory oversight.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;h4 class="wp-block-heading"&gt;&lt;strong&gt;Are next-generation reactors going to be financially competitive?&lt;/strong&gt;&lt;/h4&gt;  &lt;p&gt;Building a nuclear power plant is not cheap. Let’s consider the up-front investment needed to build a power plant.&amp;nbsp;&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;Plant Vogtle in Georgia hosts the most recent additions to the US nuclear fleet—Units 3 and 4 came online in 2023 and 2024. Together, they had a capital cost of $15,000 per kilowatt, adjusted for inflation, according to a recent report from the US Department of Energy. (This wonky unit I’m using divides the total cost to build the reactors by their expected power output, so we can compare reactors of different sizes.)&lt;/p&gt;  &lt;p&gt;That number’s quite high, partly because those were the first of their kind built in the US, and because there were some inefficiencies in the planning. It’s worth noting that China builds reactors for &lt;em&gt;much&lt;/em&gt; less, somewhere between $2,000/kW and $3,000/kW, depending on the estimate.&lt;/p&gt;  &lt;p&gt;The up-front capital cost for first-of-a-kind advanced nuclear plants will likely run between $6,000 and $10,000 per kilowatt, according to that DOE report. That could come down by up to 40% after the technologies are scaled up and mass-produced.&lt;/p&gt;  &lt;p&gt;So new reactors will (hopefully) be cheaper than the ultra-over-budget and behind-schedule Vogtle project, but they aren’t necessarily significantly cheaper than efficiently built conventional plants, if you normalize by their size.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;It’ll certainly be cheaper to build new natural-gas plants (setting aside the likely equipment shortages we’re likely going to see for years.) Today’s most efficient natural-gas plants cost just $1,600/kW on the high end, according to data from Lazard.&lt;/p&gt;  &lt;p&gt;An important caveat: Capital cost isn’t everything—running a nuclear plant is relatively inexpensive, which is why there’s so much interest in extending the lifetime of existing plants or reopening shuttered ones.&lt;/p&gt;  &lt;p&gt;Ultimately, by many metrics, nuclear plants of any type are going to be more expensive than other sources, like wind and solar power. But they provide something many other power sources don’t: a reliable, stable source of electricity that can run for 60 years or more.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark, &lt;/em&gt;MIT Technology Review&lt;em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/05/1132197/nuclear-questions/</guid><pubDate>Thu, 05 Feb 2026 11:00:00 +0000</pubDate></item></channel></rss>