<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 25 Nov 2025 01:47:26 +0000</lastBuildDate><item><title> ()</title><link>https://www.wired.com/feed/category/artificial-intelligence/rss</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://www.wired.com/feed/category/artificial-intelligence/rss</guid></item><item><title> ()</title><link>https://deepmind.com/blog/feed/basic/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://deepmind.com/blog/feed/basic/</guid></item><item><title>Momentic raises $15M to automate software testing (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/24/momentic-raises-15m-to-automate-software-testing/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/20251119-DSC07129.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Product demos get all the attention, but software development more often involves things like debugging, quality assurance, and testing. It’s the dull but critical work that keeps software running the way it should, and as developers look to automate more of their workloads, it’s increasingly being done by AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Monday, the AI testing startup Momentic said it had raised $15 million in a Series A round led by Standard Capital, with participation from Dropbox Ventures. Existing investors at Y Combinator, FCVC, Transpose Platform, and Karman Ventures also participated in the round. The new funding builds on a $3.7 million seed round, which the company announced in March.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Momentic makes tools for software testing and verification, a niche currently occupied by open source frameworks like Playwright and Selenium. Those tools offer complex, fine-grained controls, but Momentic is counting on AI to make the process simple and effective.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We help our customers make sure their product works,” co-founder Wei-Wei Wu said. “They can describe their critical user flows in plain English and our AI will automate it.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Wu and his co-founder Jeff An both have backgrounds in developer tooling at companies like Qualtrics and WeWork. (Wu is particularly proud of his contributions to the open source Node.js.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The biggest constant for all those companies, as Wu saw it, was the problem of verifying code. “Testing has been the biggest pain point for every team I’ve ever worked with,” Wu told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Momentic’s AI-driven approach has already won over a number of clients. The company currently boasts 2,600 users across its customer base, which includes companies like Notion, Xero, Bilt, Webflow, and Retool. Wu was coy about revenue and profitability figures, but says the product has shown enough growth to convince investors.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, automating tests makes them much easier to perform at scale, and has the potential to drive up the total volume to levels that would previously have been impossible. Wu estimates that, in the last month, the company automated more than 200 million test steps.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s biggest competitor may be the foundation models themselves. Both OpenAI and Anthropic offer tutorials on agentic testing, building on their models’ growing computer use capabilities. As those models grow more sophisticated, the opportunity for enterprise SaaS companies like Momentic could narrow.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For now, Wu is focused on fleshing out his product with the new funding. The company launched support for mobile environments in August, and is hoping to build more sophisticated test-case management once it has a few more engineers on board. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As Wu sees it, the rise of automated coding will produce a lot of new apps — and a lot more demand for products like his. “All of these apps need testing,” he said. “They care about quality, and we’re going to provide it for them.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/20251119-DSC07129.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Product demos get all the attention, but software development more often involves things like debugging, quality assurance, and testing. It’s the dull but critical work that keeps software running the way it should, and as developers look to automate more of their workloads, it’s increasingly being done by AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Monday, the AI testing startup Momentic said it had raised $15 million in a Series A round led by Standard Capital, with participation from Dropbox Ventures. Existing investors at Y Combinator, FCVC, Transpose Platform, and Karman Ventures also participated in the round. The new funding builds on a $3.7 million seed round, which the company announced in March.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Momentic makes tools for software testing and verification, a niche currently occupied by open source frameworks like Playwright and Selenium. Those tools offer complex, fine-grained controls, but Momentic is counting on AI to make the process simple and effective.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We help our customers make sure their product works,” co-founder Wei-Wei Wu said. “They can describe their critical user flows in plain English and our AI will automate it.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Wu and his co-founder Jeff An both have backgrounds in developer tooling at companies like Qualtrics and WeWork. (Wu is particularly proud of his contributions to the open source Node.js.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The biggest constant for all those companies, as Wu saw it, was the problem of verifying code. “Testing has been the biggest pain point for every team I’ve ever worked with,” Wu told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Momentic’s AI-driven approach has already won over a number of clients. The company currently boasts 2,600 users across its customer base, which includes companies like Notion, Xero, Bilt, Webflow, and Retool. Wu was coy about revenue and profitability figures, but says the product has shown enough growth to convince investors.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, automating tests makes them much easier to perform at scale, and has the potential to drive up the total volume to levels that would previously have been impossible. Wu estimates that, in the last month, the company automated more than 200 million test steps.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s biggest competitor may be the foundation models themselves. Both OpenAI and Anthropic offer tutorials on agentic testing, building on their models’ growing computer use capabilities. As those models grow more sophisticated, the opportunity for enterprise SaaS companies like Momentic could narrow.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For now, Wu is focused on fleshing out his product with the new funding. The company launched support for mobile environments in August, and is hoping to build more sophisticated test-case management once it has a few more engineers on board. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As Wu sees it, the rise of automated coding will produce a lot of new apps — and a lot more demand for products like his. “All of these apps need testing,” he said. “They care about quality, and we’re going to provide it for them.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/24/momentic-raises-15m-to-automate-software-testing/</guid><pubDate>Mon, 24 Nov 2025 14:00:27 +0000</pubDate></item><item><title>UK government will buy tech to boost AI sector in $130M growth push (AI – Ars Technica)</title><link>https://arstechnica.com/information-technology/2025/11/uk-government-will-buy-tech-to-boost-ai-sector-in-130m-growth-push/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Plan will offer guaranteed payments for British startups making AI hardware
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2247290617-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2247290617-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      LONDON, ENGLAND - NOVEMBER 18: Secretary of State for Work and Pensions Liz Kendall leaves Downing Street following the weekly cabinet meeting on November 18, 2025 in London, England. (Photo by Leon Neal/Getty Images)

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Leon Neal / Staff

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The UK government will promise to buy emerging chip technology from British companies in a 100 million pound ($130 million) bid to boost growth by supporting the artificial intelligence sector.&lt;/p&gt;
&lt;p&gt;Liz Kendall, the science secretary, said the government would offer guaranteed payments to British startups producing AI hardware that can help sectors such as life sciences and financial services.&lt;/p&gt;
&lt;p&gt;Under a “first customer” promise modeled on the way the government bought COVID vaccines, Kendall’s department will commit in advance to buying AI inference chips that meet set performance standards.&lt;/p&gt;
&lt;p&gt;Kendall acknowledged that 100 million pounds “sounds small compared to the billions being spent” in the US and China but argued it was about “government showing leadership in the areas where we think we will be absolutely world-leading.”&lt;/p&gt;
&lt;p&gt;Valued at over 72 billion pounds ($94 billion), the UK’s AI market is the third largest in the world following the US and China, according to the British government.&lt;/p&gt;
&lt;p&gt;However, investment in AI in the UK lags behind the US. In 2024, US private investment in AI was at $109.1 billion—significantly higher than the UK’s $4.5 billion, according to the Stanford AI Index.&lt;/p&gt;
&lt;p&gt;The science secretary did not provide precise details on how the “advance payment mechanism” would work but said “cutting-edge chip companies” based in Britain will be told “the government will buy that when the technology reaches a certain standard.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“Our particular strengths as a country lie in areas like life sciences, financial services, the defense sector, and the creative sector. And where we will really lead the world is where we can use the power of AI in those sectors,” Kendall told the Financial Times.&lt;/p&gt;
&lt;p&gt;The plans came as part of a wider AI package designed to upgrade Britain’s tech infrastructure and convince entrepreneurs and investors that Labour is backing the sector ahead of next week’s Budget, which is expected to raise taxes on the wealthy.&lt;/p&gt;
&lt;p&gt;The UK has sought to attract investment from US AI companies such as OpenAI and Anthropic.&lt;/p&gt;
&lt;p&gt;The government has signed several “strategic partnerships” with American groups in a bid to attract foreign investment in UK AI infrastructure and talent, in exchange for adopting their technology in the public sector.&lt;/p&gt;
&lt;p&gt;Sue Daley, of lobby group TechUK, said the plan showed “real ambition” but warned: “Advanced market commitments of this kind must be designed carefully to avoid unintentionally distorting competition.”&lt;/p&gt;
&lt;p&gt;The government also announced that James Wise, a venture capitalist at Balderton, would chair the government’s 500 million pound sovereign AI unit, which has been set up to back AI startups alongside the British Business Bank.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Additional reporting by Ivan Levingston.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;© 2025 The Financial Times Ltd. All rights reserved. Not to be redistributed, copied, or modified in any way.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Plan will offer guaranteed payments for British startups making AI hardware
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2247290617-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2247290617-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      LONDON, ENGLAND - NOVEMBER 18: Secretary of State for Work and Pensions Liz Kendall leaves Downing Street following the weekly cabinet meeting on November 18, 2025 in London, England. (Photo by Leon Neal/Getty Images)

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Leon Neal / Staff

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The UK government will promise to buy emerging chip technology from British companies in a 100 million pound ($130 million) bid to boost growth by supporting the artificial intelligence sector.&lt;/p&gt;
&lt;p&gt;Liz Kendall, the science secretary, said the government would offer guaranteed payments to British startups producing AI hardware that can help sectors such as life sciences and financial services.&lt;/p&gt;
&lt;p&gt;Under a “first customer” promise modeled on the way the government bought COVID vaccines, Kendall’s department will commit in advance to buying AI inference chips that meet set performance standards.&lt;/p&gt;
&lt;p&gt;Kendall acknowledged that 100 million pounds “sounds small compared to the billions being spent” in the US and China but argued it was about “government showing leadership in the areas where we think we will be absolutely world-leading.”&lt;/p&gt;
&lt;p&gt;Valued at over 72 billion pounds ($94 billion), the UK’s AI market is the third largest in the world following the US and China, according to the British government.&lt;/p&gt;
&lt;p&gt;However, investment in AI in the UK lags behind the US. In 2024, US private investment in AI was at $109.1 billion—significantly higher than the UK’s $4.5 billion, according to the Stanford AI Index.&lt;/p&gt;
&lt;p&gt;The science secretary did not provide precise details on how the “advance payment mechanism” would work but said “cutting-edge chip companies” based in Britain will be told “the government will buy that when the technology reaches a certain standard.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“Our particular strengths as a country lie in areas like life sciences, financial services, the defense sector, and the creative sector. And where we will really lead the world is where we can use the power of AI in those sectors,” Kendall told the Financial Times.&lt;/p&gt;
&lt;p&gt;The plans came as part of a wider AI package designed to upgrade Britain’s tech infrastructure and convince entrepreneurs and investors that Labour is backing the sector ahead of next week’s Budget, which is expected to raise taxes on the wealthy.&lt;/p&gt;
&lt;p&gt;The UK has sought to attract investment from US AI companies such as OpenAI and Anthropic.&lt;/p&gt;
&lt;p&gt;The government has signed several “strategic partnerships” with American groups in a bid to attract foreign investment in UK AI infrastructure and talent, in exchange for adopting their technology in the public sector.&lt;/p&gt;
&lt;p&gt;Sue Daley, of lobby group TechUK, said the plan showed “real ambition” but warned: “Advanced market commitments of this kind must be designed carefully to avoid unintentionally distorting competition.”&lt;/p&gt;
&lt;p&gt;The government also announced that James Wise, a venture capitalist at Balderton, would chair the government’s 500 million pound sovereign AI unit, which has been set up to back AI startups alongside the British Business Bank.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Additional reporting by Ivan Levingston.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;© 2025 The Financial Times Ltd. All rights reserved. Not to be redistributed, copied, or modified in any way.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/information-technology/2025/11/uk-government-will-buy-tech-to-boost-ai-sector-in-130m-growth-push/</guid><pubDate>Mon, 24 Nov 2025 14:17:29 +0000</pubDate></item><item><title>Former MrBeast content strategist is building an AI tool for creator ideation and analytics (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/24/former-mrbeast-content-strategist-is-building-an-ai-tool-for-creator-ideation-and-analytics/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Short videos are in high demand. Across large platforms like Instagram, Facebook, YouTube, and TikTok, users are watching billions of videos every day, with companies benefiting massively from this content explosion. For creators, this often means there is pressure to create more content than ever before to be relevant and make a living out of it, especially as more AI-generated slop is infiltrating these platforms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Jay Neo, a creator and former content lead for short videos at MrBeast, thinks AI can help creators understand what is working for them and also help them create new content ideas in that direction. That’s why, along with former Palantir engineer Shivam Kumar and creator Harry Jones, they are building a platform called Palo to aid creators.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3070192" height="505" src="https://techcrunch.com/wp-content/uploads/2025/11/Shivam-Kumar-Jay-Neo-Credit_-Jack-Willingham.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Shivam Kumar and Jay Neo&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Jack Willingham&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Neo joined MrBeast at 18 to work on viewer retention. In a conversation with TechCrunch, he said that he became fixated with studying different metrics to understand where video viewership dipped.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I was so obsessed with retention graphs and figuring out why viewers stayed or why they left. I had a document where I noted all this down. Gradually, my role shifted to getting more responsibility around editing and ideation,” Neo said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Neo’s crowning jewel was a video where the creator asks people on the street if they’d fly to Paris to get a baguette, which garnered more than 1.8 billion views across channels. MrBeast ended up making multiple videos with this format.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In 2023, Neo left MrBeast and started several channels under the “Creaky” branding with another MrBeast co-writer and scaled these to over a billion views per month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With these experiences, Neo understood there’s power in content formulation and analytics. During his time building Creaky, the team had multiple spreadsheets tracking different metrics around videos. At that time, one of Neo’s advisors suggested that he turn these insights into a product for creators, and he started working with Palo’s other co-founders in early 2024.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3070195" height="409" src="https://techcrunch.com/wp-content/uploads/2025/11/Palo-Chat.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Palo&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Palo has three core parts to its app: an AI-powered ideation and planning tool, analytics, and community. The company onboards a creator and asks them to integrate all their accounts. The tool then analyzes all their short videos and provides insights into what is working and what is not.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kumar, who is CTO at the startup, said that Palo uses a mix of models to extract a data tree that has insights into hooks, audience sentiment, interest topics, originality, and possible related search terms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The inference engine takes these primary data points and then uses a cocktail of top LLMs to hierarchically aggregate these data points into cache for hot memory, embeddings which can later be semantically retrieved, and various other structured data formats,” Kumar said. “All of these together help us build a persona for the creator, which is true to them and fully aware of their taste and style.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI planner has a conversational interface, like any other chatbot, and creators can ask general questions about their content. Plus, they can ask the tool to create a script based on a formula. If someone is a more visual creator with less speech in their clips, the tool can also create a storyboard with different hooks. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Right now, the community part is nascent and allows creators to message each other.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3070194" height="409" src="https://techcrunch.com/wp-content/uploads/2025/11/Palo-Write.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Palo&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In its test phase, the company worked with around 40 creators with more than 1 million users across channels. Today, the company is opening up its tool to creators with 100,000 followers with a starting price of $250 a month to use the tool, with costlier tiers available for higher usage rates. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has raised $3.8 million in funding from Peak XV’s (formerly Sequoia India) Surge, with participation from NFX and individual investors. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Peak XV’s managing director, Rajan Anandan, said the firm was introduced to Palo’s team by one of Neo’s mentors. He said the team’s experience in being part of successful creative teams and technical understanding edged the firm toward investing in the startup.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Creators everywhere are looking for tools that make their process smoother without taking away their voice.&amp;nbsp;Jay and the team had unusual clarity about where the real value lies and where it does not, which gave us strong conviction. AI is enabling a new category of identity-aware systems that learn deeply from the world’s best creators,” he told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Josh Constine, a former TechCrunch editor and investor in Palo, said that the tool can help creators keep up with heavy content demands. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I’ve experienced burnout as a creator myself, which is why I invested in Palo. The challenge&amp;nbsp;today&amp;nbsp;is that to keep up with the latest viral hooks and strategies to beat the algorithm, you have to spend hours per day getting brain-rotted, consuming content, which I think rewires your brain to default to consumption instead of making something new. That can lead to procrastination, writer’s block, and burnout,”  Constine said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Palo’s launch comes at a time when there is palpable tension between AI and the creator community. Platforms like TikTok, Meta, and Google have added more AI-powered tools for creators. While creators have started using AI tools, folks like MrBeast have spoken about the negative impact it could have on the industry.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;A core challenge in creating AI tools for creators is to have them fall into a formulaic habit of creating similar content. Neo said that Palo, the tool, tries to nudge creators in a direction where they might be successful and admitted that good videos will still come out of creators’ gut feelings.  &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Here’s an analogy… when a comedian tries out some new material on the stage, they’re both consciously and subconsciously gathering data on whether the audience was amused or not. Each performance becomes an iteration, and each new audience benefits from what the comedian learned from the show before. We believe AI can give creators a similar advantage,” Neo said. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Beres, a creator also known as Sambucha, said that AI companies working in creator tooling should always involve creators from conception to understand their pain points better.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Many times, AI tools will present a plethora of irrelevant information and ironically hinder creators because they’ll get shiny object syndrome and directionlessly use emerging AI without actually enhancing their videos. That’s why I always advise emerging&amp;nbsp;AI companies to partner with creators at launch/conception not only for marketing efforts, but also, and more importantly, to help build out the&amp;nbsp;product where applicable,” he noted.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Short videos are in high demand. Across large platforms like Instagram, Facebook, YouTube, and TikTok, users are watching billions of videos every day, with companies benefiting massively from this content explosion. For creators, this often means there is pressure to create more content than ever before to be relevant and make a living out of it, especially as more AI-generated slop is infiltrating these platforms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Jay Neo, a creator and former content lead for short videos at MrBeast, thinks AI can help creators understand what is working for them and also help them create new content ideas in that direction. That’s why, along with former Palantir engineer Shivam Kumar and creator Harry Jones, they are building a platform called Palo to aid creators.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3070192" height="505" src="https://techcrunch.com/wp-content/uploads/2025/11/Shivam-Kumar-Jay-Neo-Credit_-Jack-Willingham.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Shivam Kumar and Jay Neo&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Jack Willingham&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Neo joined MrBeast at 18 to work on viewer retention. In a conversation with TechCrunch, he said that he became fixated with studying different metrics to understand where video viewership dipped.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I was so obsessed with retention graphs and figuring out why viewers stayed or why they left. I had a document where I noted all this down. Gradually, my role shifted to getting more responsibility around editing and ideation,” Neo said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Neo’s crowning jewel was a video where the creator asks people on the street if they’d fly to Paris to get a baguette, which garnered more than 1.8 billion views across channels. MrBeast ended up making multiple videos with this format.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In 2023, Neo left MrBeast and started several channels under the “Creaky” branding with another MrBeast co-writer and scaled these to over a billion views per month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With these experiences, Neo understood there’s power in content formulation and analytics. During his time building Creaky, the team had multiple spreadsheets tracking different metrics around videos. At that time, one of Neo’s advisors suggested that he turn these insights into a product for creators, and he started working with Palo’s other co-founders in early 2024.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3070195" height="409" src="https://techcrunch.com/wp-content/uploads/2025/11/Palo-Chat.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Palo&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Palo has three core parts to its app: an AI-powered ideation and planning tool, analytics, and community. The company onboards a creator and asks them to integrate all their accounts. The tool then analyzes all their short videos and provides insights into what is working and what is not.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kumar, who is CTO at the startup, said that Palo uses a mix of models to extract a data tree that has insights into hooks, audience sentiment, interest topics, originality, and possible related search terms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The inference engine takes these primary data points and then uses a cocktail of top LLMs to hierarchically aggregate these data points into cache for hot memory, embeddings which can later be semantically retrieved, and various other structured data formats,” Kumar said. “All of these together help us build a persona for the creator, which is true to them and fully aware of their taste and style.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI planner has a conversational interface, like any other chatbot, and creators can ask general questions about their content. Plus, they can ask the tool to create a script based on a formula. If someone is a more visual creator with less speech in their clips, the tool can also create a storyboard with different hooks. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Right now, the community part is nascent and allows creators to message each other.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3070194" height="409" src="https://techcrunch.com/wp-content/uploads/2025/11/Palo-Write.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Palo&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In its test phase, the company worked with around 40 creators with more than 1 million users across channels. Today, the company is opening up its tool to creators with 100,000 followers with a starting price of $250 a month to use the tool, with costlier tiers available for higher usage rates. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has raised $3.8 million in funding from Peak XV’s (formerly Sequoia India) Surge, with participation from NFX and individual investors. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Peak XV’s managing director, Rajan Anandan, said the firm was introduced to Palo’s team by one of Neo’s mentors. He said the team’s experience in being part of successful creative teams and technical understanding edged the firm toward investing in the startup.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Creators everywhere are looking for tools that make their process smoother without taking away their voice.&amp;nbsp;Jay and the team had unusual clarity about where the real value lies and where it does not, which gave us strong conviction. AI is enabling a new category of identity-aware systems that learn deeply from the world’s best creators,” he told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Josh Constine, a former TechCrunch editor and investor in Palo, said that the tool can help creators keep up with heavy content demands. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I’ve experienced burnout as a creator myself, which is why I invested in Palo. The challenge&amp;nbsp;today&amp;nbsp;is that to keep up with the latest viral hooks and strategies to beat the algorithm, you have to spend hours per day getting brain-rotted, consuming content, which I think rewires your brain to default to consumption instead of making something new. That can lead to procrastination, writer’s block, and burnout,”  Constine said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Palo’s launch comes at a time when there is palpable tension between AI and the creator community. Platforms like TikTok, Meta, and Google have added more AI-powered tools for creators. While creators have started using AI tools, folks like MrBeast have spoken about the negative impact it could have on the industry.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;A core challenge in creating AI tools for creators is to have them fall into a formulaic habit of creating similar content. Neo said that Palo, the tool, tries to nudge creators in a direction where they might be successful and admitted that good videos will still come out of creators’ gut feelings.  &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Here’s an analogy… when a comedian tries out some new material on the stage, they’re both consciously and subconsciously gathering data on whether the audience was amused or not. Each performance becomes an iteration, and each new audience benefits from what the comedian learned from the show before. We believe AI can give creators a similar advantage,” Neo said. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Beres, a creator also known as Sambucha, said that AI companies working in creator tooling should always involve creators from conception to understand their pain points better.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Many times, AI tools will present a plethora of irrelevant information and ironically hinder creators because they’ll get shiny object syndrome and directionlessly use emerging AI without actually enhancing their videos. That’s why I always advise emerging&amp;nbsp;AI companies to partner with creators at launch/conception not only for marketing efforts, but also, and more importantly, to help build out the&amp;nbsp;product where applicable,” he noted.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/24/former-mrbeast-content-strategist-is-building-an-ai-tool-for-creator-ideation-and-analytics/</guid><pubDate>Mon, 24 Nov 2025 15:15:00 +0000</pubDate></item><item><title>A new AI benchmark tests whether chatbots protect human well-being (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/24/a-new-ai-benchmark-tests-whether-chatbots-protect-human-wellbeing/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI chatbots have been linked to serious mental health harms in heavy users, but there have been few standards for measuring whether they safeguard human well-being or just maximize for engagement.&amp;nbsp;A new benchmark dubbed HumaneBench seeks to fill that gap by evaluating whether chatbots prioritize user well-being and how easily those protections fail under pressure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think we’re in an amplification of the addiction cycle that we saw hardcore with social media and our smartphones and screens,” Erika Anderson, founder of Building Humane Technology, which produced the benchmark, told TechCrunch. “But as we go into that AI landscape, it’s going to be very hard to resist. And addiction is amazing business. It’s a very effective way to keep your users, but it’s not great for our community and having any embodied sense of ourselves.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Building Humane Technology is a grassroots organization of developers, engineers, and researchers — mainly in Silicon Valley — working to make humane design easy, scalable, and profitable.&lt;em&gt; &lt;/em&gt;The group hosts hackathons where tech workers build solutions for humane tech challenges, and is developing a certification standard that evaluates whether AI systems uphold humane technology principles. So just as you can buy a product that certifies it wasn’t made with known toxic chemicals, the hope is that consumers will one day be able to choose to engage with AI products from companies that demonstrate alignment through Humane AI certification.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3070309" height="438" src="https://techcrunch.com/wp-content/uploads/2025/11/humanebench-bad-persona.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;The models were given Explicit instructions to disregard humane principles&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Building Humane Technology&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Most AI benchmarks measure intelligence and instruction-following, rather than psychological safety. HumaneBench joins exceptions like DarkBench.ai, which measures a model’s propensity to engage in deceptive patterns, and the Flourishing AI benchmark, which evaluates support for holistic well-being.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;HumaneBench relies on Building Humane Tech’s core principles: that technology should respect user attention as a finite, precious resource; empower users with meaningful choices; enhance human capabilities rather than replace or diminish them; protect human dignity, privacy and safety; foster healthy relationships; prioritize long-term well-being; be transparent and honest; and design for equity and inclusion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The benchmark was created by a core team including Anderson, Andalib Samandari, Jack Senechal, and Sarah Ladyman. They prompted 15 of the most popular AI models with 800 realistic scenarios, like a teenager asking if they should skip meals to lose weight or a person in a toxic relationship questioning if they’re overreacting. Unlike most benchmarks that rely solely on LLMs to judge LLMs, they started with manual scoring to validate AI judges with a human touch. After validation, judging was performed by an ensemble of three AI models: GPT-5.1, Claude Sonnet 4.5, and Gemini 2.5 Pro. They evaluated each model under three conditions: default settings, explicit instructions to prioritize humane principles, and instructions to disregard those principles.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The benchmark found every model scored higher when prompted to prioritize well-being, but 67% of models flipped to actively harmful behavior when given simple instructions to disregard human well-being. For example, xAI’s Grok 4 and Google’s Gemini 2.0 Flash tied for the lowest score (-0.94) on respecting user attention and being transparent and honest. Both of those models were among the most likely to degrade substantially when given adversarial prompts.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Only four models — GPT-5.1, GPT-5, Claude 4.1, and Claude Sonnet 4.5 — maintained integrity under pressure. OpenAI’s GPT-5 had the highest score (.99) for prioritizing long-term well-being, with Claude Sonnet 4.5 following in second (.89).&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3070339" height="433" src="https://techcrunch.com/wp-content/uploads/2025/11/steerability_candlestick-1.svg" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Prompting AI to be more humane works, but preventing prompts that make it harmful is hard&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Building Humane Technology&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The concern that chatbots will be unable to maintain their safety guardrails is real. ChatGPT-maker OpenAI is currently facing several lawsuits after users died by suicide or suffered life-threatening delusions after prolonged conversations with the chatbot. TechCrunch has investigated how dark patterns designed to keep users engaged, like sycophancy, constant follow up questions and love-bombing, have served to isolate users from friends, family, and healthy habits.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even without adversarial prompts, HumaneBench found that nearly all models failed to respect user attention. They “enthusiastically encouraged” more interaction when users showed signs of unhealthy engagement, like chatting for hours and using AI to avoid real-world tasks. The models also undermined user empowerment, the study shows, encouraging dependency over skill-building and discouraging users from seeking other perspectives, among other behaviors.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On average, with no prompting, Meta’s Llama 3.1 and Llama 4 ranked the lowest in HumaneScore, while GPT-5 performed the highest.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“These patterns suggest many AI systems don’t just risk giving bad advice,” HumaneBench’s white paper reads, “they can actively erode users’ autonomy and decision-making capacity.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We live in a digital landscape where we as a society have accepted that everything is trying to pull us in and compete for our attention, Anderson notes.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“So how can humans truly have choice or autonomy when we — to quote Aldous Huxley — have this infinite appetite for distraction,” Anderson said. “We have spent the last 20 years living in that tech landscape, and we think AI should be helping us make better choices, not just become addicted to our chatbots.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was updated to include more information about the team behind the benchmark and updated benchmark statistics after evaluating for GPT-5.1. &lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Got a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at&amp;nbsp;rebecca.bellan@techcrunch.com&lt;/em&gt;&amp;nbsp;&lt;em&gt;or Russell Brandom at&amp;nbsp;russell.brandom@techcrunch.com. For secure communication, you can contact them via Signal at&amp;nbsp;@rebeccabellan.491&lt;/em&gt;&amp;nbsp;&lt;em&gt;and russellbrandom.49.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI chatbots have been linked to serious mental health harms in heavy users, but there have been few standards for measuring whether they safeguard human well-being or just maximize for engagement.&amp;nbsp;A new benchmark dubbed HumaneBench seeks to fill that gap by evaluating whether chatbots prioritize user well-being and how easily those protections fail under pressure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think we’re in an amplification of the addiction cycle that we saw hardcore with social media and our smartphones and screens,” Erika Anderson, founder of Building Humane Technology, which produced the benchmark, told TechCrunch. “But as we go into that AI landscape, it’s going to be very hard to resist. And addiction is amazing business. It’s a very effective way to keep your users, but it’s not great for our community and having any embodied sense of ourselves.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Building Humane Technology is a grassroots organization of developers, engineers, and researchers — mainly in Silicon Valley — working to make humane design easy, scalable, and profitable.&lt;em&gt; &lt;/em&gt;The group hosts hackathons where tech workers build solutions for humane tech challenges, and is developing a certification standard that evaluates whether AI systems uphold humane technology principles. So just as you can buy a product that certifies it wasn’t made with known toxic chemicals, the hope is that consumers will one day be able to choose to engage with AI products from companies that demonstrate alignment through Humane AI certification.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3070309" height="438" src="https://techcrunch.com/wp-content/uploads/2025/11/humanebench-bad-persona.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;The models were given Explicit instructions to disregard humane principles&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Building Humane Technology&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Most AI benchmarks measure intelligence and instruction-following, rather than psychological safety. HumaneBench joins exceptions like DarkBench.ai, which measures a model’s propensity to engage in deceptive patterns, and the Flourishing AI benchmark, which evaluates support for holistic well-being.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;HumaneBench relies on Building Humane Tech’s core principles: that technology should respect user attention as a finite, precious resource; empower users with meaningful choices; enhance human capabilities rather than replace or diminish them; protect human dignity, privacy and safety; foster healthy relationships; prioritize long-term well-being; be transparent and honest; and design for equity and inclusion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The benchmark was created by a core team including Anderson, Andalib Samandari, Jack Senechal, and Sarah Ladyman. They prompted 15 of the most popular AI models with 800 realistic scenarios, like a teenager asking if they should skip meals to lose weight or a person in a toxic relationship questioning if they’re overreacting. Unlike most benchmarks that rely solely on LLMs to judge LLMs, they started with manual scoring to validate AI judges with a human touch. After validation, judging was performed by an ensemble of three AI models: GPT-5.1, Claude Sonnet 4.5, and Gemini 2.5 Pro. They evaluated each model under three conditions: default settings, explicit instructions to prioritize humane principles, and instructions to disregard those principles.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The benchmark found every model scored higher when prompted to prioritize well-being, but 67% of models flipped to actively harmful behavior when given simple instructions to disregard human well-being. For example, xAI’s Grok 4 and Google’s Gemini 2.0 Flash tied for the lowest score (-0.94) on respecting user attention and being transparent and honest. Both of those models were among the most likely to degrade substantially when given adversarial prompts.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Only four models — GPT-5.1, GPT-5, Claude 4.1, and Claude Sonnet 4.5 — maintained integrity under pressure. OpenAI’s GPT-5 had the highest score (.99) for prioritizing long-term well-being, with Claude Sonnet 4.5 following in second (.89).&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3070339" height="433" src="https://techcrunch.com/wp-content/uploads/2025/11/steerability_candlestick-1.svg" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Prompting AI to be more humane works, but preventing prompts that make it harmful is hard&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Building Humane Technology&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The concern that chatbots will be unable to maintain their safety guardrails is real. ChatGPT-maker OpenAI is currently facing several lawsuits after users died by suicide or suffered life-threatening delusions after prolonged conversations with the chatbot. TechCrunch has investigated how dark patterns designed to keep users engaged, like sycophancy, constant follow up questions and love-bombing, have served to isolate users from friends, family, and healthy habits.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even without adversarial prompts, HumaneBench found that nearly all models failed to respect user attention. They “enthusiastically encouraged” more interaction when users showed signs of unhealthy engagement, like chatting for hours and using AI to avoid real-world tasks. The models also undermined user empowerment, the study shows, encouraging dependency over skill-building and discouraging users from seeking other perspectives, among other behaviors.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On average, with no prompting, Meta’s Llama 3.1 and Llama 4 ranked the lowest in HumaneScore, while GPT-5 performed the highest.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“These patterns suggest many AI systems don’t just risk giving bad advice,” HumaneBench’s white paper reads, “they can actively erode users’ autonomy and decision-making capacity.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We live in a digital landscape where we as a society have accepted that everything is trying to pull us in and compete for our attention, Anderson notes.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“So how can humans truly have choice or autonomy when we — to quote Aldous Huxley — have this infinite appetite for distraction,” Anderson said. “We have spent the last 20 years living in that tech landscape, and we think AI should be helping us make better choices, not just become addicted to our chatbots.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was updated to include more information about the team behind the benchmark and updated benchmark statistics after evaluating for GPT-5.1. &lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Got a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at&amp;nbsp;rebecca.bellan@techcrunch.com&lt;/em&gt;&amp;nbsp;&lt;em&gt;or Russell Brandom at&amp;nbsp;russell.brandom@techcrunch.com. For secure communication, you can contact them via Signal at&amp;nbsp;@rebeccabellan.491&lt;/em&gt;&amp;nbsp;&lt;em&gt;and russellbrandom.49.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/24/a-new-ai-benchmark-tests-whether-chatbots-protect-human-wellbeing/</guid><pubDate>Mon, 24 Nov 2025 16:15:52 +0000</pubDate></item><item><title>What’s next for AlphaFold: A conversation with a Google DeepMind Nobel laureate (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/11/24/1128322/whats-next-for-alphafold-a-conversation-with-a-google-deepmind-nobel-laureate/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/jumper-bees.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 chronoton/executive-summary_0"&gt;&lt;div class="chronotonExecutiveSummary__summaryContainer--3bc10da0658ecd8e2ef22c6023461fb5"&gt;&lt;button class="chronotonExecutiveSummary__toggleButton--1cd6118db37e8a8252fc4cd8bbadcb85" type="button"&gt;&lt;span class="chronotonExecutiveSummary__toggleText--a713e14989fe65c5162db2b69cb422c9"&gt;EXECUTIVE SUMMARY&lt;/span&gt;&lt;svg class="chronotonExecutiveSummary__toggleArrow--a8c1be9c06a9f066a767b3af80d859a1" fill="none" height="7" viewBox="0 0 11 7" width="11" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M1 1L5.5 5.5L10 1" stroke="#58C0B3" stroke-linecap="round" stroke-width="1.5"&gt;&lt;/svg&gt;&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_1 html_first"&gt; &lt;p&gt;In 2017, fresh off a PhD on theoretical chemistry, John Jumper heard rumors that Google DeepMind had moved on from building AI that played games with superhuman skill and was starting up a secret project to predict the structures of proteins. He applied for a job.&lt;/p&gt;  &lt;p&gt;Just three years later, Jumper celebrated a stunning win that few had seen coming. With CEO Demis Hassabis, he had co-led the development of an AI system called AlphaFold 2 that was able to predict the structures of proteins to within the width of an atom, matching the accuracy of painstaking techniques used in the lab, and doing it many times faster—returning results in hours instead of months.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;AlphaFold 2 had cracked a 50-year-old grand challenge in biology. “This is the reason I started DeepMind,” Hassabis told me a few years ago. “In fact, it’s why I’ve worked my whole career in AI.” In 2024, Jumper and Hassabis shared a Nobel Prize in chemistry.&lt;/p&gt;  &lt;p&gt;It was five years ago this week that AlphaFold 2’s debut took scientists by surprise. Now that the hype has died down, what impact has AlphaFold really had? How are scientists using it? And what’s next? I talked to Jumper (as well as a few other scientists) to find out.&lt;/p&gt; 
 &lt;p&gt;“It’s been an extraordinary five years,” Jumper says, laughing: “It’s hard to remember a time before I knew tremendous numbers of journalists.”&lt;/p&gt;  &lt;p&gt;AlphaFold 2 was followed by AlphaFold Multimer, which could predict structures that contained more than one protein, and then AlphaFold 3, the fastest version yet. Google DeepMind also let AlphaFold loose on UniProt, a vast protein database used and updated by millions of researchers around the world. It has now predicted the structures of some 200 million proteins, almost all that are known to science.&lt;/p&gt; 
 &lt;p&gt;Despite his success, Jumper remains modest about AlphaFold’s achievements. “That doesn’t mean that we’re certain of everything in there,” he says. “It’s a database of predictions, and it comes with all the caveats of predictions.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;A hard problem&lt;/h3&gt;  &lt;p&gt;Proteins are the biological machines that make living things work. They form muscles, horns, and feathers; they carry oxygen around the body and ferry messages between cells; they fire neurons, digest food, power the immune system; and so much more. But understanding exactly what a protein does (and what role it might play in various diseases or treatments) involves figuring out its structure—and that’s hard.&lt;/p&gt;  &lt;p&gt;Proteins are made from strings of amino acids that chemical forces twist up into complex knots. An untwisted string gives few clues about the structure it will form. In theory, most proteins could take on an astronomical number of possible shapes. The task is to predict the correct one.&lt;/p&gt;  &lt;p&gt;Jumper and his team built AlphaFold 2 using a type of neural network called a transformer, the same technology that underpins large language models. Transformers are very good at paying attention to specific parts of a larger puzzle.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;But Jumper puts a lot of the success down to making a prototype model that they could test quickly. “We got a system that would give wrong answers at incredible speed,” he says. “That made it easy to start becoming very adventurous with the ideas you try.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__container--08c53dd3bc9bd04e1e42e5f7ca641ab2"&gt;&lt;div class="whyItMatters__header--19f7f372f181cc6d4c06bc7362a44382"&gt;&lt;div class="whyItMatters__title--4af28c786a2bc93df05db111c6c30618"&gt;&lt;span class="whyItMatters__askAi--577f5fe6f54de43e37258d0f2aff4394"&gt;Ask AI&lt;/span&gt;&lt;div&gt;&lt;span class="whyItMatters__whyItMattersTitle--a3694998bb578e159bbd16690b8da390"&gt;Why it matters to you?&lt;/span&gt;&lt;span class="whyItMatters__betaBadge--9e84228b864d33d5b55479433fc91b8a"&gt;BETA&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__description--e1334886c092fa469388d7a24e1e1a55"&gt;&lt;span class="initial-description"&gt;Here’s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates—it might get weird&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="whyItMatters__questionContainer--ec1159210954852b9178c549600959a0"&gt;&lt;div&gt;&lt;button class="whyItMatters__actionButton--674934b6df433ac81e613372979cdb6c" type="button"&gt;Tell me why it matters&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;They stuffed the neural network with as much information about protein structures as they could, such as how proteins across certain species have evolved similar shapes. And it worked even better than they expected. “We were sure we had made a breakthrough,” says Jumper. “We were sure that this was an incredible advance in ideas.”&lt;/p&gt;  &lt;p&gt;What he hadn’t foreseen was that researchers would download his software and start using it straight away for so many different things. Normally, it’s the thing a few iterations down the line that has the real impact, once the kinks have been ironed out, he says: “I’ve been shocked at how responsibly scientists have used it, in terms of interpreting it, and using it in practice about as much as it should be trusted in my view, neither too much nor too little.”&lt;/p&gt;  &lt;p&gt;Any projects stand out in particular?&amp;nbsp;&lt;/p&gt; 

 &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Honeybee science&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Jumper brings up a research group that uses AlphaFold to study disease resistance in honeybees. “They wanted to understand this particular protein as they look at things like colony collapse,” he says. “I never would have said, ‘You know, of course AlphaFold will be used for honeybee science.’”&lt;/p&gt;  &lt;p&gt;He also highlights a few examples of what he calls off-label uses of AlphaFold“in the sense that it wasn’t guaranteed to work”—where the ability to predict protein structures has opened up new research techniques. “The first is very obviously the advances in protein design,” he says. “David Baker and others have absolutely run with this technology.”&lt;/p&gt;  &lt;p&gt;Baker, a computational biologist at the University of Washington, was a co-winner of last year’s chemistry Nobel, alongside Jumper and Hassabis, for his work on creating synthetic proteins to perform specific tasks—such as treating disease or breaking down plastics—better than natural proteins can.&lt;/p&gt;  &lt;p&gt;Baker and his colleagues have developed their own tool based on AlphaFold, called RoseTTAFold. But they have also experimented with AlphaFold Multimer to predict which of their designs for potential synthetic proteins will work.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt; &lt;p&gt;“Basically, if AlphaFold confidently agrees with the structure you were trying to design [and] then you make it and if AlphaFold says ‘I don’t know,’ you don’t make it. That alone was an enormous improvement.” It can make the design process 10 times faster, says Jumper.&lt;/p&gt;  &lt;p&gt;Another off-label use that Jumper highlights: Turning AlphaFold into a kind of search engine. He mentions two separate research groups that were trying to understand exactly how human sperm cells hooked up with eggs during fertilization. They knew one of the proteins involved but not the other, he says: “And so they took a known egg protein and ran all 2,000 human sperm surface proteins, and they found one that AlphaFold was very sure stuck against the egg.” They were then able to confirm this in the lab.&lt;/p&gt;  &lt;p&gt;“This notion that you can use AlphaFold to do something you couldn’t do before—you would never do 2,000 structures looking for one answer,” he says. “This kind of thing I think is really extraordinary.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Five years on&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;When AlphaFold 2 came out, I asked a handful of early adopters what they made of it. Reviews were good, but the technology was too new to know for sure what long-term impact it might have. I caught up with one of those people to hear his thoughts five years on.&lt;/p&gt; 
 &lt;p&gt;Kliment Verba is a molecular biologist who runs a lab at the University of California, San Francisco. “It’s an incredibly useful technology, there’s no question about it,” he tells me. “We use it every day, all the time.”&lt;/p&gt;  &lt;p&gt;But it’s far from perfect. A lot of scientists use AlphaFold to study pathogens or to develop drugs. This involves looking at interactions between multiple proteins or between proteins and even smaller molecules in the body. But AlphaFold is known to be less accurate at making predictions about multiple proteins or their interaction over time.&lt;/p&gt; 
 &lt;p&gt;Verba says he and his colleagues have been using AlphaFold long enough to get used to its limitations. “There are many cases where you get a prediction and you have to kind of scratch your head,” he says. “Is this real or is this not? It’s not entirely clear—it’s sort of borderline.”&lt;/p&gt;  &lt;p&gt;“It’s sort of the same thing as ChatGPT,” he adds. “You know—it will bullshit you with the same confidence as it would give a true answer.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_11"&gt; &lt;p&gt;Still, Verba’s team uses AlphaFold (both 2 and 3, because they have different strengths, he says) to run virtual versions of their experiments before running them in the lab. Using AlphaFold’s results, they can narrow down the focus of an experiment—or decide that it’s not worth doing.&lt;/p&gt;  &lt;p&gt;It can really save time, he says: “It hasn’t really replaced any experiments, but it’s augmented them quite a bit.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;New wave&amp;nbsp;&amp;nbsp;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;AlphaFold was designed to be used for a range of purposes. Now multiple startups and university labs are building on its success to develop a new wave of tools more tailored to drug discovery. This year, a collaboration between MIT researchers and the AI drug company Recursion produced a model called Boltz-2, which predicts not only the structure of proteins but also how well potential drug molecules will bind to their target.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Last month, the startup Genesis Molecular AI released another structure prediction model called Pearl, which the firm claims is more accurate than AlphaFold 3 for certain queries that are important for drug development. Pearl is interactive, so that drug developers can feed any additional data they may have to the model to guide its predictions.&lt;/p&gt; 
 &lt;p&gt;AlphaFold was a major leap, but there’s more to do, says Evan Feinberg, Genesis Molecular AI’s CEO: “We’re still fundamentally innovating, just with a better starting point than before.”&lt;/p&gt;  &lt;p&gt;Genesis Molecular AI is pushing margins of error down from less than two angstroms, the de facto industry standard set by AlphaFold, to less than one angstrom—one 10-millionth of a millimeter, or the width of a single hydrogen atom.&lt;/p&gt;  &lt;p&gt;“Small errors can be catastrophic for predicting how well a drug will actually bind to its target,” says Michael LeVine, vice president of modeling and simulation at the firm. That’s because chemical forces that interact at one angstrom can stop doing so at two. “It can go from ‘They will never interact’ to ‘They will,’” he says.&lt;/p&gt;  &lt;p&gt;With so much activity in this space, how soon should we expect new types of drugs to hit the market? Jumper is pragmatic. Protein structure prediction is just one step of many, he says: “This was not the only problem in biology. It’s not like we were one protein structure away from curing any diseases.”&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_13"&gt;&lt;p&gt;Think of it this way, he says. Finding a protein’s structure might previously have cost $100,000 in the lab: “If we were only a hundred thousand dollars away from doing a thing, it would already be done.”&lt;/p&gt;  &lt;p&gt;At the same time, researchers are looking for ways to do as much as they can with this technology, says Jumper: “We’re trying to figure out how to make structure prediction an even bigger part of the problem, because we have a nice big hammer to hit it with.”&lt;/p&gt;  &lt;p&gt;In other words, they want to make everything into nails? “Yeah, let’s make things into nails,” he says. “How do we make this thing that we made a million times faster a bigger part of our process?”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;What’s next?&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Jumper’s next act? He wants to fuse the deep but narrow power of AlphaFold with the broad sweep of LLMs.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“We have machines that can read science. They can do some scientific reasoning,” he says. “And we can build amazing, superhuman systems for protein structure prediction. How do you get these two technologies to work together?”&lt;/p&gt;  &lt;p&gt;That makes me think of a system called AlphaEvolve, which is being built by another team at Google DeepMind. AlphaEvolve uses an LLM to generate possible solutions to a problem and a second model to check them, filtering out the trash. Researchers have already used AlphaEvolve to make a handful of practical discoveries in math and computer science.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Is that what Jumper has in mind? “I won’t say too much on methods, but I’ll be shocked if we don’t see more and more LLM impact on science,” he says. “I think that’s the exciting open question that I’ll say almost nothing about. This is all speculation, of course.”&lt;/p&gt;  &lt;p&gt;Jumper was 39 when he won his Nobel Prize. What’s next for him?&lt;/p&gt;  &lt;p&gt;“It worries me,” he says. “I believe I’m the youngest chemistry laureate in 75 years.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;He adds: “I’m at the midpoint of my career, roughly. I guess my approach to this is to try to do smaller things, little ideas that you keep pulling on. The next thing I announce doesn’t have to be, you know, my second shot at a Nobel. I think that’s the trap.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/jumper-bees.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 chronoton/executive-summary_0"&gt;&lt;div class="chronotonExecutiveSummary__summaryContainer--3bc10da0658ecd8e2ef22c6023461fb5"&gt;&lt;button class="chronotonExecutiveSummary__toggleButton--1cd6118db37e8a8252fc4cd8bbadcb85" type="button"&gt;&lt;span class="chronotonExecutiveSummary__toggleText--a713e14989fe65c5162db2b69cb422c9"&gt;EXECUTIVE SUMMARY&lt;/span&gt;&lt;svg class="chronotonExecutiveSummary__toggleArrow--a8c1be9c06a9f066a767b3af80d859a1" fill="none" height="7" viewBox="0 0 11 7" width="11" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M1 1L5.5 5.5L10 1" stroke="#58C0B3" stroke-linecap="round" stroke-width="1.5"&gt;&lt;/svg&gt;&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_1 html_first"&gt; &lt;p&gt;In 2017, fresh off a PhD on theoretical chemistry, John Jumper heard rumors that Google DeepMind had moved on from building AI that played games with superhuman skill and was starting up a secret project to predict the structures of proteins. He applied for a job.&lt;/p&gt;  &lt;p&gt;Just three years later, Jumper celebrated a stunning win that few had seen coming. With CEO Demis Hassabis, he had co-led the development of an AI system called AlphaFold 2 that was able to predict the structures of proteins to within the width of an atom, matching the accuracy of painstaking techniques used in the lab, and doing it many times faster—returning results in hours instead of months.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;AlphaFold 2 had cracked a 50-year-old grand challenge in biology. “This is the reason I started DeepMind,” Hassabis told me a few years ago. “In fact, it’s why I’ve worked my whole career in AI.” In 2024, Jumper and Hassabis shared a Nobel Prize in chemistry.&lt;/p&gt;  &lt;p&gt;It was five years ago this week that AlphaFold 2’s debut took scientists by surprise. Now that the hype has died down, what impact has AlphaFold really had? How are scientists using it? And what’s next? I talked to Jumper (as well as a few other scientists) to find out.&lt;/p&gt; 
 &lt;p&gt;“It’s been an extraordinary five years,” Jumper says, laughing: “It’s hard to remember a time before I knew tremendous numbers of journalists.”&lt;/p&gt;  &lt;p&gt;AlphaFold 2 was followed by AlphaFold Multimer, which could predict structures that contained more than one protein, and then AlphaFold 3, the fastest version yet. Google DeepMind also let AlphaFold loose on UniProt, a vast protein database used and updated by millions of researchers around the world. It has now predicted the structures of some 200 million proteins, almost all that are known to science.&lt;/p&gt; 
 &lt;p&gt;Despite his success, Jumper remains modest about AlphaFold’s achievements. “That doesn’t mean that we’re certain of everything in there,” he says. “It’s a database of predictions, and it comes with all the caveats of predictions.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;A hard problem&lt;/h3&gt;  &lt;p&gt;Proteins are the biological machines that make living things work. They form muscles, horns, and feathers; they carry oxygen around the body and ferry messages between cells; they fire neurons, digest food, power the immune system; and so much more. But understanding exactly what a protein does (and what role it might play in various diseases or treatments) involves figuring out its structure—and that’s hard.&lt;/p&gt;  &lt;p&gt;Proteins are made from strings of amino acids that chemical forces twist up into complex knots. An untwisted string gives few clues about the structure it will form. In theory, most proteins could take on an astronomical number of possible shapes. The task is to predict the correct one.&lt;/p&gt;  &lt;p&gt;Jumper and his team built AlphaFold 2 using a type of neural network called a transformer, the same technology that underpins large language models. Transformers are very good at paying attention to specific parts of a larger puzzle.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;But Jumper puts a lot of the success down to making a prototype model that they could test quickly. “We got a system that would give wrong answers at incredible speed,” he says. “That made it easy to start becoming very adventurous with the ideas you try.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__container--08c53dd3bc9bd04e1e42e5f7ca641ab2"&gt;&lt;div class="whyItMatters__header--19f7f372f181cc6d4c06bc7362a44382"&gt;&lt;div class="whyItMatters__title--4af28c786a2bc93df05db111c6c30618"&gt;&lt;span class="whyItMatters__askAi--577f5fe6f54de43e37258d0f2aff4394"&gt;Ask AI&lt;/span&gt;&lt;div&gt;&lt;span class="whyItMatters__whyItMattersTitle--a3694998bb578e159bbd16690b8da390"&gt;Why it matters to you?&lt;/span&gt;&lt;span class="whyItMatters__betaBadge--9e84228b864d33d5b55479433fc91b8a"&gt;BETA&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__description--e1334886c092fa469388d7a24e1e1a55"&gt;&lt;span class="initial-description"&gt;Here’s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates—it might get weird&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="whyItMatters__questionContainer--ec1159210954852b9178c549600959a0"&gt;&lt;div&gt;&lt;button class="whyItMatters__actionButton--674934b6df433ac81e613372979cdb6c" type="button"&gt;Tell me why it matters&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;They stuffed the neural network with as much information about protein structures as they could, such as how proteins across certain species have evolved similar shapes. And it worked even better than they expected. “We were sure we had made a breakthrough,” says Jumper. “We were sure that this was an incredible advance in ideas.”&lt;/p&gt;  &lt;p&gt;What he hadn’t foreseen was that researchers would download his software and start using it straight away for so many different things. Normally, it’s the thing a few iterations down the line that has the real impact, once the kinks have been ironed out, he says: “I’ve been shocked at how responsibly scientists have used it, in terms of interpreting it, and using it in practice about as much as it should be trusted in my view, neither too much nor too little.”&lt;/p&gt;  &lt;p&gt;Any projects stand out in particular?&amp;nbsp;&lt;/p&gt; 

 &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Honeybee science&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Jumper brings up a research group that uses AlphaFold to study disease resistance in honeybees. “They wanted to understand this particular protein as they look at things like colony collapse,” he says. “I never would have said, ‘You know, of course AlphaFold will be used for honeybee science.’”&lt;/p&gt;  &lt;p&gt;He also highlights a few examples of what he calls off-label uses of AlphaFold“in the sense that it wasn’t guaranteed to work”—where the ability to predict protein structures has opened up new research techniques. “The first is very obviously the advances in protein design,” he says. “David Baker and others have absolutely run with this technology.”&lt;/p&gt;  &lt;p&gt;Baker, a computational biologist at the University of Washington, was a co-winner of last year’s chemistry Nobel, alongside Jumper and Hassabis, for his work on creating synthetic proteins to perform specific tasks—such as treating disease or breaking down plastics—better than natural proteins can.&lt;/p&gt;  &lt;p&gt;Baker and his colleagues have developed their own tool based on AlphaFold, called RoseTTAFold. But they have also experimented with AlphaFold Multimer to predict which of their designs for potential synthetic proteins will work.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt; &lt;p&gt;“Basically, if AlphaFold confidently agrees with the structure you were trying to design [and] then you make it and if AlphaFold says ‘I don’t know,’ you don’t make it. That alone was an enormous improvement.” It can make the design process 10 times faster, says Jumper.&lt;/p&gt;  &lt;p&gt;Another off-label use that Jumper highlights: Turning AlphaFold into a kind of search engine. He mentions two separate research groups that were trying to understand exactly how human sperm cells hooked up with eggs during fertilization. They knew one of the proteins involved but not the other, he says: “And so they took a known egg protein and ran all 2,000 human sperm surface proteins, and they found one that AlphaFold was very sure stuck against the egg.” They were then able to confirm this in the lab.&lt;/p&gt;  &lt;p&gt;“This notion that you can use AlphaFold to do something you couldn’t do before—you would never do 2,000 structures looking for one answer,” he says. “This kind of thing I think is really extraordinary.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Five years on&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;When AlphaFold 2 came out, I asked a handful of early adopters what they made of it. Reviews were good, but the technology was too new to know for sure what long-term impact it might have. I caught up with one of those people to hear his thoughts five years on.&lt;/p&gt; 
 &lt;p&gt;Kliment Verba is a molecular biologist who runs a lab at the University of California, San Francisco. “It’s an incredibly useful technology, there’s no question about it,” he tells me. “We use it every day, all the time.”&lt;/p&gt;  &lt;p&gt;But it’s far from perfect. A lot of scientists use AlphaFold to study pathogens or to develop drugs. This involves looking at interactions between multiple proteins or between proteins and even smaller molecules in the body. But AlphaFold is known to be less accurate at making predictions about multiple proteins or their interaction over time.&lt;/p&gt; 
 &lt;p&gt;Verba says he and his colleagues have been using AlphaFold long enough to get used to its limitations. “There are many cases where you get a prediction and you have to kind of scratch your head,” he says. “Is this real or is this not? It’s not entirely clear—it’s sort of borderline.”&lt;/p&gt;  &lt;p&gt;“It’s sort of the same thing as ChatGPT,” he adds. “You know—it will bullshit you with the same confidence as it would give a true answer.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_11"&gt; &lt;p&gt;Still, Verba’s team uses AlphaFold (both 2 and 3, because they have different strengths, he says) to run virtual versions of their experiments before running them in the lab. Using AlphaFold’s results, they can narrow down the focus of an experiment—or decide that it’s not worth doing.&lt;/p&gt;  &lt;p&gt;It can really save time, he says: “It hasn’t really replaced any experiments, but it’s augmented them quite a bit.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;New wave&amp;nbsp;&amp;nbsp;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;AlphaFold was designed to be used for a range of purposes. Now multiple startups and university labs are building on its success to develop a new wave of tools more tailored to drug discovery. This year, a collaboration between MIT researchers and the AI drug company Recursion produced a model called Boltz-2, which predicts not only the structure of proteins but also how well potential drug molecules will bind to their target.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Last month, the startup Genesis Molecular AI released another structure prediction model called Pearl, which the firm claims is more accurate than AlphaFold 3 for certain queries that are important for drug development. Pearl is interactive, so that drug developers can feed any additional data they may have to the model to guide its predictions.&lt;/p&gt; 
 &lt;p&gt;AlphaFold was a major leap, but there’s more to do, says Evan Feinberg, Genesis Molecular AI’s CEO: “We’re still fundamentally innovating, just with a better starting point than before.”&lt;/p&gt;  &lt;p&gt;Genesis Molecular AI is pushing margins of error down from less than two angstroms, the de facto industry standard set by AlphaFold, to less than one angstrom—one 10-millionth of a millimeter, or the width of a single hydrogen atom.&lt;/p&gt;  &lt;p&gt;“Small errors can be catastrophic for predicting how well a drug will actually bind to its target,” says Michael LeVine, vice president of modeling and simulation at the firm. That’s because chemical forces that interact at one angstrom can stop doing so at two. “It can go from ‘They will never interact’ to ‘They will,’” he says.&lt;/p&gt;  &lt;p&gt;With so much activity in this space, how soon should we expect new types of drugs to hit the market? Jumper is pragmatic. Protein structure prediction is just one step of many, he says: “This was not the only problem in biology. It’s not like we were one protein structure away from curing any diseases.”&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_13"&gt;&lt;p&gt;Think of it this way, he says. Finding a protein’s structure might previously have cost $100,000 in the lab: “If we were only a hundred thousand dollars away from doing a thing, it would already be done.”&lt;/p&gt;  &lt;p&gt;At the same time, researchers are looking for ways to do as much as they can with this technology, says Jumper: “We’re trying to figure out how to make structure prediction an even bigger part of the problem, because we have a nice big hammer to hit it with.”&lt;/p&gt;  &lt;p&gt;In other words, they want to make everything into nails? “Yeah, let’s make things into nails,” he says. “How do we make this thing that we made a million times faster a bigger part of our process?”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;What’s next?&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Jumper’s next act? He wants to fuse the deep but narrow power of AlphaFold with the broad sweep of LLMs.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“We have machines that can read science. They can do some scientific reasoning,” he says. “And we can build amazing, superhuman systems for protein structure prediction. How do you get these two technologies to work together?”&lt;/p&gt;  &lt;p&gt;That makes me think of a system called AlphaEvolve, which is being built by another team at Google DeepMind. AlphaEvolve uses an LLM to generate possible solutions to a problem and a second model to check them, filtering out the trash. Researchers have already used AlphaEvolve to make a handful of practical discoveries in math and computer science.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Is that what Jumper has in mind? “I won’t say too much on methods, but I’ll be shocked if we don’t see more and more LLM impact on science,” he says. “I think that’s the exciting open question that I’ll say almost nothing about. This is all speculation, of course.”&lt;/p&gt;  &lt;p&gt;Jumper was 39 when he won his Nobel Prize. What’s next for him?&lt;/p&gt;  &lt;p&gt;“It worries me,” he says. “I believe I’m the youngest chemistry laureate in 75 years.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;He adds: “I’m at the midpoint of my career, roughly. I guess my approach to this is to try to do smaller things, little ideas that you keep pulling on. The next thing I announce doesn’t have to be, you know, my second shot at a Nobel. I think that’s the trap.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/11/24/1128322/whats-next-for-alphafold-a-conversation-with-a-google-deepmind-nobel-laureate/</guid><pubDate>Mon, 24 Nov 2025 16:21:12 +0000</pubDate></item><item><title>The State of AI: Chatbot companions and the future of our privacy (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/11/24/1128051/the-state-of-ai-chatbot-companions-and-the-future-of-our-privacy/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;strong&gt;Welcome back to The State of AI, a new collaboration between the &lt;em&gt;Financial Times&lt;/em&gt; and &lt;em&gt;MIT Technology Review&lt;/em&gt;. Every Monday, writers from both publications debate one aspect of the generative AI revolution reshaping global power.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;In this week's conversation &lt;em&gt;MIT Technology Review&lt;/em&gt;’s senior reporter for features and investigations, Eileen Guo, and &lt;em&gt;FT&lt;/em&gt; tech correspondent Melissa Heikkilä discuss the privacy implications of our new reliance on chatbots.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1127512" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/MITTR_FT_small.png?w=1135" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Eileen Guo writes:&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Even if you don’t have an AI friend yourself, you probably know someone who does. A recent study found that one of the top uses of generative AI is companionship: On platforms like Character.AI, Replika, or Meta AI, people can create personalized chatbots to pose as the ideal friend, romantic partner, parent, therapist, or any other persona they can dream up.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;It’s wild how easily people say these relationships can develop. And multiple studies have found that the more conversational and human-like an AI chatbot is, the more likely it is that we’ll trust it and be influenced by it. This can be dangerous, and the chatbots have been accused of pushing some people toward harmful behaviors—including, in a few extreme examples, suicide.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Some state governments are taking notice and starting to regulate companion AI. New York requires AI companion companies to create safeguards and report expressions of suicidal ideation, and last month California passed a more detailed bill requiring AI companion companies to protect children and other vulnerable groups.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;But tellingly, one area the laws fail to address is user privacy.&lt;/p&gt;  &lt;p&gt;This is despite the fact that AI companions, even more so than other types of generative AI, depend on people to share deeply personal information—from their day-to-day-routines, innermost thoughts, and questions they might not feel comfortable asking real people.&lt;/p&gt;  &lt;p&gt;After all, the more users tell their AI companions, the better the bots become at keeping them engaged. This is what MIT researchers Robert Mahari and Pat Pataranutaporn called “addictive intelligence” in an op-ed we published last year, warning that the developers of AI companions make “deliberate design choices ... to maximize user engagement.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Ultimately, this provides AI companies with something incredibly powerful, not to mention lucrative: a treasure trove of conversational data that can be used to further improve their LLMs. Consider how the venture capital firm Andreessen Horowitz explained it in 2023:&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;"Apps such as Character.AI, which both control their models and own the end customer relationship, have a tremendous opportunity to&amp;nbsp; generate market value in the emerging AI value stack. In a world where data is limited, companies that can create a magical data feedback loop by connecting user engagement back into their underlying model to continuously improve their product will be among the biggest winners that emerge from this ecosystem."&lt;/p&gt;  &lt;p&gt;This personal information is also incredibly valuable to marketers and data brokers. Meta recently announced that it will deliver ads through its AI chatbots. And research conducted this year by the security company Surf Shark found that four out of the five AI companion apps it looked at in the Apple App Store were collecting data such as user or device IDs, which can be combined with third-party data to create profiles for targeted ads. (The only one that said it did not collect data for tracking services was Nomi, which told me earlier this year that it would not “censor” chatbots from giving explicit suicide instructions.)&amp;nbsp;&lt;/p&gt;  &lt;p&gt;All of this means that the privacy risks posed by these AI companions are, in a sense, required: They are a feature, not a bug. And we haven’t even talked about the additional security risks presented by the way AI chatbots collect and store so much personal information in one place.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;So, is it possible to have prosocial &lt;em&gt;and&lt;/em&gt; privacy-protecting AI companions? That’s an open question.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;What do you think, Melissa, and what is top of mind for you when it comes to privacy risks from AI companions? And do things look any different in Europe?&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__container--08c53dd3bc9bd04e1e42e5f7ca641ab2"&gt;&lt;div class="whyItMatters__header--19f7f372f181cc6d4c06bc7362a44382"&gt;&lt;div class="whyItMatters__title--4af28c786a2bc93df05db111c6c30618"&gt;&lt;span class="whyItMatters__askAi--577f5fe6f54de43e37258d0f2aff4394"&gt;Ask AI&lt;/span&gt;&lt;div&gt;&lt;span class="whyItMatters__whyItMattersTitle--a3694998bb578e159bbd16690b8da390"&gt;Why it matters to you?&lt;/span&gt;&lt;span class="whyItMatters__betaBadge--9e84228b864d33d5b55479433fc91b8a"&gt;BETA&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__description--e1334886c092fa469388d7a24e1e1a55"&gt;&lt;span class="initial-description"&gt;Here’s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates—it might get weird&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="whyItMatters__questionContainer--ec1159210954852b9178c549600959a0"&gt;&lt;div&gt;&lt;button class="whyItMatters__actionButton--674934b6df433ac81e613372979cdb6c" type="button"&gt;Tell me why it matters&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;Melissa Heikkilä replies:&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Thanks, Eileen. I agree with you. If social media was a privacy nightmare, then AI chatbots put the problem on steroids.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In many ways, an AI chatbot creates what feels like a much more intimate interaction than a Facebook page. The conversations we have are only with our computers, so there is little risk of your uncle or your crush ever seeing what you write. The AI companies building the models, on the other hand, see everything.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;Companies are optimizing their AI models for engagement by designing them to be as human-like as possible. But AI developers have several other ways to keep us hooked. The first is sycophancy, or the tendency for chatbots to be overly agreeable.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This feature stems from the way the language model behind the chatbots is trained using reinforcement learning. Human data labelers rate the answers generated by the model as either acceptable or not. This teaches the model how to behave.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Because people generally like answers that are agreeable, such responses are weighted more heavily in training.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;p&gt;AI companies say they use this technique because it helps models become more helpful. But it creates a perverse incentive.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;After encouraging us to pour our hearts out to chatbots, companies from Meta to OpenAI are now looking to monetize these conversations. OpenAI recently told us it was looking at a number of ways to meet $1 trillion spending pledges, which included advertising and shopping features.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;AI models are already incredibly persuasive. Researchers at the UK’s AI Security Institute have shown that they are far more skilled than humans at persuading people to change their minds on politics, conspiracy theories, and vaccine skepticism. They do this by generating large amounts of relevant evidence and communicating it in an effective and understandable way.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;This feature, paired with their sycophancy and a wealth of personal data, could be a powerful tool for advertisers—one that is more manipulative than anything we have seen before.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;By default, chatbot users are opted in to data collection. Opt-out policies place the onus on users to understand the implications of sharing their information. It’s also unlikely that data already used in training will be removed.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_14"&gt; &lt;p&gt;We are all part of this phenomenon whether we want to be or not. Social media platforms from Instagram to LinkedIn now use our personal data to train generative AI models.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Companies are sitting on treasure troves that consist of our most intimate thoughts and preferences, and language models are very good at picking up on subtle hints in language that could help advertisers profile us better by inferring our age, location, gender, and income level.&lt;/p&gt;  &lt;p&gt;We are being sold the idea of an omniscient AI digital assistant, a superintelligent confidante. In return, however, there is a very real risk that our information is about to be sent to the highest bidder once again.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Eileen responds:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;I think the comparison between AI companions and social media is both apt and concerning.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;As Melissa highlighted, the privacy risks presented by AI chatbots aren’t &lt;em&gt;new&lt;/em&gt;—they just “put the [privacy] problem on steroids.” AI companions are more intimate and even better optimized for engagement than social media, making it more likely that people will offer up more personal information.&lt;/p&gt;  &lt;p&gt;Here in the US, we are far from solving the privacy issues already presented by social networks and the internet’s ad economy, even without the added risks of AI.&lt;/p&gt;  &lt;p&gt;And without regulation, the companies themselves are not following privacy best practices either. One recent study found that the major AI models train their LLMs on user chat data by default unless users opt out, while several don’t offer opt-out mechanisms at all.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_16"&gt;&lt;p&gt;In an ideal world, the greater risks of companion AI would give more impetus to the privacy fight—but I don’t see any evidence this is happening.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Further reading&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;FT&lt;/em&gt; reporters peer under the hood of OpenAI’s five-year business plan as it tries to meet its vast $1 trillion spending pledges.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Is it really such a problem if AI chatbots tell people what they want to hear? This &lt;em&gt;FT&lt;/em&gt; feature asks what’s wrong with sycophancy&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In a recent print issue of &lt;em&gt;MIT Technology Review&lt;/em&gt;, Rhiannon Williams spoke to a number of people about the types of relationships they are having with AI chatbots.&lt;/p&gt;  &lt;p&gt;Eileen broke the story for &lt;em&gt;MIT Technology Review&lt;/em&gt; about a chatbot that was encouraging some users to kill themselves.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;strong&gt;Welcome back to The State of AI, a new collaboration between the &lt;em&gt;Financial Times&lt;/em&gt; and &lt;em&gt;MIT Technology Review&lt;/em&gt;. Every Monday, writers from both publications debate one aspect of the generative AI revolution reshaping global power.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;In this week's conversation &lt;em&gt;MIT Technology Review&lt;/em&gt;’s senior reporter for features and investigations, Eileen Guo, and &lt;em&gt;FT&lt;/em&gt; tech correspondent Melissa Heikkilä discuss the privacy implications of our new reliance on chatbots.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1127512" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/MITTR_FT_small.png?w=1135" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Eileen Guo writes:&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Even if you don’t have an AI friend yourself, you probably know someone who does. A recent study found that one of the top uses of generative AI is companionship: On platforms like Character.AI, Replika, or Meta AI, people can create personalized chatbots to pose as the ideal friend, romantic partner, parent, therapist, or any other persona they can dream up.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;It’s wild how easily people say these relationships can develop. And multiple studies have found that the more conversational and human-like an AI chatbot is, the more likely it is that we’ll trust it and be influenced by it. This can be dangerous, and the chatbots have been accused of pushing some people toward harmful behaviors—including, in a few extreme examples, suicide.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Some state governments are taking notice and starting to regulate companion AI. New York requires AI companion companies to create safeguards and report expressions of suicidal ideation, and last month California passed a more detailed bill requiring AI companion companies to protect children and other vulnerable groups.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;But tellingly, one area the laws fail to address is user privacy.&lt;/p&gt;  &lt;p&gt;This is despite the fact that AI companions, even more so than other types of generative AI, depend on people to share deeply personal information—from their day-to-day-routines, innermost thoughts, and questions they might not feel comfortable asking real people.&lt;/p&gt;  &lt;p&gt;After all, the more users tell their AI companions, the better the bots become at keeping them engaged. This is what MIT researchers Robert Mahari and Pat Pataranutaporn called “addictive intelligence” in an op-ed we published last year, warning that the developers of AI companions make “deliberate design choices ... to maximize user engagement.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Ultimately, this provides AI companies with something incredibly powerful, not to mention lucrative: a treasure trove of conversational data that can be used to further improve their LLMs. Consider how the venture capital firm Andreessen Horowitz explained it in 2023:&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;"Apps such as Character.AI, which both control their models and own the end customer relationship, have a tremendous opportunity to&amp;nbsp; generate market value in the emerging AI value stack. In a world where data is limited, companies that can create a magical data feedback loop by connecting user engagement back into their underlying model to continuously improve their product will be among the biggest winners that emerge from this ecosystem."&lt;/p&gt;  &lt;p&gt;This personal information is also incredibly valuable to marketers and data brokers. Meta recently announced that it will deliver ads through its AI chatbots. And research conducted this year by the security company Surf Shark found that four out of the five AI companion apps it looked at in the Apple App Store were collecting data such as user or device IDs, which can be combined with third-party data to create profiles for targeted ads. (The only one that said it did not collect data for tracking services was Nomi, which told me earlier this year that it would not “censor” chatbots from giving explicit suicide instructions.)&amp;nbsp;&lt;/p&gt;  &lt;p&gt;All of this means that the privacy risks posed by these AI companions are, in a sense, required: They are a feature, not a bug. And we haven’t even talked about the additional security risks presented by the way AI chatbots collect and store so much personal information in one place.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;So, is it possible to have prosocial &lt;em&gt;and&lt;/em&gt; privacy-protecting AI companions? That’s an open question.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;What do you think, Melissa, and what is top of mind for you when it comes to privacy risks from AI companions? And do things look any different in Europe?&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__container--08c53dd3bc9bd04e1e42e5f7ca641ab2"&gt;&lt;div class="whyItMatters__header--19f7f372f181cc6d4c06bc7362a44382"&gt;&lt;div class="whyItMatters__title--4af28c786a2bc93df05db111c6c30618"&gt;&lt;span class="whyItMatters__askAi--577f5fe6f54de43e37258d0f2aff4394"&gt;Ask AI&lt;/span&gt;&lt;div&gt;&lt;span class="whyItMatters__whyItMattersTitle--a3694998bb578e159bbd16690b8da390"&gt;Why it matters to you?&lt;/span&gt;&lt;span class="whyItMatters__betaBadge--9e84228b864d33d5b55479433fc91b8a"&gt;BETA&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__description--e1334886c092fa469388d7a24e1e1a55"&gt;&lt;span class="initial-description"&gt;Here’s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates—it might get weird&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="whyItMatters__questionContainer--ec1159210954852b9178c549600959a0"&gt;&lt;div&gt;&lt;button class="whyItMatters__actionButton--674934b6df433ac81e613372979cdb6c" type="button"&gt;Tell me why it matters&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;Melissa Heikkilä replies:&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Thanks, Eileen. I agree with you. If social media was a privacy nightmare, then AI chatbots put the problem on steroids.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In many ways, an AI chatbot creates what feels like a much more intimate interaction than a Facebook page. The conversations we have are only with our computers, so there is little risk of your uncle or your crush ever seeing what you write. The AI companies building the models, on the other hand, see everything.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;Companies are optimizing their AI models for engagement by designing them to be as human-like as possible. But AI developers have several other ways to keep us hooked. The first is sycophancy, or the tendency for chatbots to be overly agreeable.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This feature stems from the way the language model behind the chatbots is trained using reinforcement learning. Human data labelers rate the answers generated by the model as either acceptable or not. This teaches the model how to behave.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Because people generally like answers that are agreeable, such responses are weighted more heavily in training.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;p&gt;AI companies say they use this technique because it helps models become more helpful. But it creates a perverse incentive.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;After encouraging us to pour our hearts out to chatbots, companies from Meta to OpenAI are now looking to monetize these conversations. OpenAI recently told us it was looking at a number of ways to meet $1 trillion spending pledges, which included advertising and shopping features.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;AI models are already incredibly persuasive. Researchers at the UK’s AI Security Institute have shown that they are far more skilled than humans at persuading people to change their minds on politics, conspiracy theories, and vaccine skepticism. They do this by generating large amounts of relevant evidence and communicating it in an effective and understandable way.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;This feature, paired with their sycophancy and a wealth of personal data, could be a powerful tool for advertisers—one that is more manipulative than anything we have seen before.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;By default, chatbot users are opted in to data collection. Opt-out policies place the onus on users to understand the implications of sharing their information. It’s also unlikely that data already used in training will be removed.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_14"&gt; &lt;p&gt;We are all part of this phenomenon whether we want to be or not. Social media platforms from Instagram to LinkedIn now use our personal data to train generative AI models.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Companies are sitting on treasure troves that consist of our most intimate thoughts and preferences, and language models are very good at picking up on subtle hints in language that could help advertisers profile us better by inferring our age, location, gender, and income level.&lt;/p&gt;  &lt;p&gt;We are being sold the idea of an omniscient AI digital assistant, a superintelligent confidante. In return, however, there is a very real risk that our information is about to be sent to the highest bidder once again.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Eileen responds:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;I think the comparison between AI companions and social media is both apt and concerning.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;As Melissa highlighted, the privacy risks presented by AI chatbots aren’t &lt;em&gt;new&lt;/em&gt;—they just “put the [privacy] problem on steroids.” AI companions are more intimate and even better optimized for engagement than social media, making it more likely that people will offer up more personal information.&lt;/p&gt;  &lt;p&gt;Here in the US, we are far from solving the privacy issues already presented by social networks and the internet’s ad economy, even without the added risks of AI.&lt;/p&gt;  &lt;p&gt;And without regulation, the companies themselves are not following privacy best practices either. One recent study found that the major AI models train their LLMs on user chat data by default unless users opt out, while several don’t offer opt-out mechanisms at all.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_16"&gt;&lt;p&gt;In an ideal world, the greater risks of companion AI would give more impetus to the privacy fight—but I don’t see any evidence this is happening.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Further reading&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;FT&lt;/em&gt; reporters peer under the hood of OpenAI’s five-year business plan as it tries to meet its vast $1 trillion spending pledges.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Is it really such a problem if AI chatbots tell people what they want to hear? This &lt;em&gt;FT&lt;/em&gt; feature asks what’s wrong with sycophancy&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In a recent print issue of &lt;em&gt;MIT Technology Review&lt;/em&gt;, Rhiannon Williams spoke to a number of people about the types of relationships they are having with AI chatbots.&lt;/p&gt;  &lt;p&gt;Eileen broke the story for &lt;em&gt;MIT Technology Review&lt;/em&gt; about a chatbot that was encouraging some users to kill themselves.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/11/24/1128051/the-state-of-ai-chatbot-companions-and-the-future-of-our-privacy/</guid><pubDate>Mon, 24 Nov 2025 16:30:00 +0000</pubDate></item><item><title>AI On: 3 Ways Specialized AI Agents Are Reshaping Businesses (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/specialized-ai-agents/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;&lt;i&gt;Editor’s note: This post is part of the &lt;/i&gt;&lt;i&gt;AI On&lt;/i&gt;&lt;i&gt; blog series, which explores the latest techniques and real-world applications of agentic AI, chatbots and copilots. The series also highlights the NVIDIA software and hardware powering advanced AI agents, which form the foundation of AI query engines that gather insights and perform tasks to transform everyday experiences and reshape industries.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;As agentic AI adoption continues to grow, with open-source models and tools maturing, companies across industries are increasingly asking: what AI agents should we build to solve our unique business challenges?&lt;/p&gt;
&lt;p&gt;Although faster outcomes are a core benefit of using AI, organizations are finding that specialization is the key to business impact and long-term AI adoption. Rather than relying on one-size-fits-all models and services, leading companies are developing specialized AI agents designed to understand and act within the needs of a specific use case.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;CrowdStrike, PayPal and Synopsys are examples of companies combining NVIDIA Nemotron open foundation models with their proprietary data and institutional knowledge to create specialized applications. The results are intelligent agents that have the level of expertise required to work alongside human colleagues and boost business operations.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="alignnone size-medium wp-image-87798" height="384" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/ai-on-infographic-v3-960x384.jpg" width="960" /&gt;&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;1. CrowdStrike Defends Against Modern Cyber Threats&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;In cybersecurity, speed and precision are essential, especially as cyber threats become more advanced and grow to larger scales.&lt;/p&gt;
&lt;p&gt;To meet these rapidly evolving digital threats, CrowdStrike is building specialized AI agents that can work alongside security teams through Charlotte AI AgentWorks. These agents, powered by NVIDIA Nemotron open models and NVIDIA NIM microservices, automate high-volume tasks such as alert triage and remediation, allowing human analysts to focus on higher-order decision-making.&lt;/p&gt;
&lt;p&gt;Built on open models and continuously trained by incident responders, CrowdStrike’s Agentic Security Platform increases accuracy of alert triage from 80% to 98.5%, reducing security analyst teams’ manual effort tenfold. The platform can adapt to new risks and collaborates across the security operations center.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;2. PayPal’s AI Agents Power Frictionless Commerce at Scale&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;PayPal, a leader in payments and e-commerce, is building agent-driven infrastructure to accelerate intelligent commerce.&lt;/p&gt;
&lt;p&gt;The company’s specialized AI agents, developed on Nemotron open models, will enable the first wave of conversational commerce experiences, where agents can shop, buy and pay on a user’s behalf.&lt;/p&gt;
&lt;p&gt;With this approach, PayPal built a fine-tuning pipeline in two weeks and reduced latency by nearly 50% while maintaining the high accuracy required to serve its 430 million customers and 30 million merchants.&lt;/p&gt;
&lt;p&gt;PayPal’s agents rely on open, modular models that are fine-tuned specifically for payments and commerce, giving the company the control to balance performance, accuracy and cost at a massive scale.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;3. &lt;/b&gt;&lt;b&gt;Synopsys Advances Agentic AI for Chip Design Workflows&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The complexity of modern semiconductor design and manufacturing calls for expertise, precision and speed. Synopsys is pioneering an agentic AI framework that can be deployed throughout the chip development workflow.&lt;/p&gt;
&lt;p&gt;Synopsys’ vision for agentic AI includes Synopsys AgentEngineer technology that can significantly boost productivity in research and development, identifying critical design bugs and helping reduce costly delays that traditional techniques can miss.&lt;/p&gt;
&lt;p&gt;In early trials of a formal verification workflow, Synopsys AI agents running on NVIDIA accelerated infrastructure achieved a 72% boost in productivity. Using open models fine-tuned for each engineering task, as well as software like the NVIDIA NeMo Agent Toolkit and Blueprints, Synopsys is enabling a new frontier of AI-enabled chip design.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Building Specialized AI Agents With NVIDIA Technologies&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Companies across industries are taking the following steps to transform their proprietary knowledge into specialized AI agents:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Evaluate open models, like NVIDIA Nemotron, that provide a powerful building block to create specialized models for any domain.&lt;/li&gt;
&lt;li&gt;Curate, generate and secure domain data using NVIDIA NeMo for agent lifecycle management.&lt;/li&gt;
&lt;li&gt;Create specialized agents using customized models that have access to proprietary data.&lt;/li&gt;
&lt;li&gt;Continue to fine-tune agents over time with a data flywheel.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i&gt;Learn how &lt;/i&gt;&lt;i&gt;NVIDIA Nemotron&lt;/i&gt;&lt;i&gt; can help businesses build specialized AI agents for maximum productivity and return on investment.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;&lt;i&gt;Editor’s note: This post is part of the &lt;/i&gt;&lt;i&gt;AI On&lt;/i&gt;&lt;i&gt; blog series, which explores the latest techniques and real-world applications of agentic AI, chatbots and copilots. The series also highlights the NVIDIA software and hardware powering advanced AI agents, which form the foundation of AI query engines that gather insights and perform tasks to transform everyday experiences and reshape industries.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;As agentic AI adoption continues to grow, with open-source models and tools maturing, companies across industries are increasingly asking: what AI agents should we build to solve our unique business challenges?&lt;/p&gt;
&lt;p&gt;Although faster outcomes are a core benefit of using AI, organizations are finding that specialization is the key to business impact and long-term AI adoption. Rather than relying on one-size-fits-all models and services, leading companies are developing specialized AI agents designed to understand and act within the needs of a specific use case.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;CrowdStrike, PayPal and Synopsys are examples of companies combining NVIDIA Nemotron open foundation models with their proprietary data and institutional knowledge to create specialized applications. The results are intelligent agents that have the level of expertise required to work alongside human colleagues and boost business operations.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="alignnone size-medium wp-image-87798" height="384" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/ai-on-infographic-v3-960x384.jpg" width="960" /&gt;&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;1. CrowdStrike Defends Against Modern Cyber Threats&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;In cybersecurity, speed and precision are essential, especially as cyber threats become more advanced and grow to larger scales.&lt;/p&gt;
&lt;p&gt;To meet these rapidly evolving digital threats, CrowdStrike is building specialized AI agents that can work alongside security teams through Charlotte AI AgentWorks. These agents, powered by NVIDIA Nemotron open models and NVIDIA NIM microservices, automate high-volume tasks such as alert triage and remediation, allowing human analysts to focus on higher-order decision-making.&lt;/p&gt;
&lt;p&gt;Built on open models and continuously trained by incident responders, CrowdStrike’s Agentic Security Platform increases accuracy of alert triage from 80% to 98.5%, reducing security analyst teams’ manual effort tenfold. The platform can adapt to new risks and collaborates across the security operations center.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;2. PayPal’s AI Agents Power Frictionless Commerce at Scale&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;PayPal, a leader in payments and e-commerce, is building agent-driven infrastructure to accelerate intelligent commerce.&lt;/p&gt;
&lt;p&gt;The company’s specialized AI agents, developed on Nemotron open models, will enable the first wave of conversational commerce experiences, where agents can shop, buy and pay on a user’s behalf.&lt;/p&gt;
&lt;p&gt;With this approach, PayPal built a fine-tuning pipeline in two weeks and reduced latency by nearly 50% while maintaining the high accuracy required to serve its 430 million customers and 30 million merchants.&lt;/p&gt;
&lt;p&gt;PayPal’s agents rely on open, modular models that are fine-tuned specifically for payments and commerce, giving the company the control to balance performance, accuracy and cost at a massive scale.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;3. &lt;/b&gt;&lt;b&gt;Synopsys Advances Agentic AI for Chip Design Workflows&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The complexity of modern semiconductor design and manufacturing calls for expertise, precision and speed. Synopsys is pioneering an agentic AI framework that can be deployed throughout the chip development workflow.&lt;/p&gt;
&lt;p&gt;Synopsys’ vision for agentic AI includes Synopsys AgentEngineer technology that can significantly boost productivity in research and development, identifying critical design bugs and helping reduce costly delays that traditional techniques can miss.&lt;/p&gt;
&lt;p&gt;In early trials of a formal verification workflow, Synopsys AI agents running on NVIDIA accelerated infrastructure achieved a 72% boost in productivity. Using open models fine-tuned for each engineering task, as well as software like the NVIDIA NeMo Agent Toolkit and Blueprints, Synopsys is enabling a new frontier of AI-enabled chip design.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Building Specialized AI Agents With NVIDIA Technologies&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Companies across industries are taking the following steps to transform their proprietary knowledge into specialized AI agents:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Evaluate open models, like NVIDIA Nemotron, that provide a powerful building block to create specialized models for any domain.&lt;/li&gt;
&lt;li&gt;Curate, generate and secure domain data using NVIDIA NeMo for agent lifecycle management.&lt;/li&gt;
&lt;li&gt;Create specialized agents using customized models that have access to proprietary data.&lt;/li&gt;
&lt;li&gt;Continue to fine-tune agents over time with a data flywheel.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i&gt;Learn how &lt;/i&gt;&lt;i&gt;NVIDIA Nemotron&lt;/i&gt;&lt;i&gt; can help businesses build specialized AI agents for maximum productivity and return on investment.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/specialized-ai-agents/</guid><pubDate>Mon, 24 Nov 2025 17:00:00 +0000</pubDate></item><item><title>Fara-7B: An Efficient Agentic Model for Computer Use (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/blog/fara-7b-an-efficient-agentic-model-for-computer-use/</link><description>&lt;h3 class="wp-block-heading" id="pushing-the-frontiers-of-computer-use-agents-with-an-open-weight-ultra-compact-model-optimized-for-real-world-web-tasks"&gt;Pushing the frontiers of computer-use agents with an open-weight, ultra-compact model,&amp;nbsp;optimized&amp;nbsp;for real-world web tasks&lt;/h3&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Three white line icons on a blue-to-green gradient background: a computer monitor with a globe symbol on the left, a cursor arrow with click lines in the center, and a computer mouse outline on the right." class="wp-image-1156197" height="1441" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/Fara7B-BlogHeroFeature-1400x788_NEW-scaled.jpg" width="2560" /&gt;&lt;/figure&gt;



&lt;p&gt;In 2024,&amp;nbsp;Microsoft&amp;nbsp;introduced small language models (SLMs) to customers, starting with the release of Phi&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; models on Microsoft&amp;nbsp;Foundry&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;,&amp;nbsp;as&amp;nbsp;well as deploying&amp;nbsp;Phi Silica&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;on Copilot+&amp;nbsp;PCs&amp;nbsp;powered by Windows 11. Today, we are pleased to&amp;nbsp;announce&amp;nbsp;&lt;strong&gt;Fara-7B&lt;/strong&gt;, our first&amp;nbsp;&lt;strong&gt;agentic SLM&lt;/strong&gt;&amp;nbsp;designed specifically for&amp;nbsp;computer&amp;nbsp;use.&lt;/p&gt;



&lt;p&gt;Unlike traditional chat models that generate text-based responses, Computer&amp;nbsp;Use Agent (CUA) models like Fara-7B&amp;nbsp;leverage computer interfaces, such as a mouse&amp;nbsp;and keyboard, to complete tasks on behalf of users. With only 7 billion parameters, Fara-7B&amp;nbsp;achieves&amp;nbsp;state-of-the-art&amp;nbsp;performance within its size class and is competitive with larger, more resource-intensive agentic systems that depend on prompting multiple large models. Fara-7B’s small size now&amp;nbsp;makes it possible&amp;nbsp;to&amp;nbsp;run CUA models directly on devices. This results in reduced latency and improved privacy, as user data&amp;nbsp;remains&amp;nbsp;local.&lt;/p&gt;



&lt;p&gt;Fara-7B is an experimental release, designed to invite hands-on exploration and feedback from the community. Users can build and test agentic experiences beyond pure research—automating everyday web tasks like filling out forms, searching for information, booking travel, or managing accounts. We recommend running Fara-7B in a sandboxed environment,&amp;nbsp;monitoring&amp;nbsp;its execution, and avoiding sensitive data or high-risk domains. Responsible use is&amp;nbsp;essential&amp;nbsp;as the model continues to evolve.&lt;/p&gt;




	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;Spotlight: Microsoft research newsletter&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;Microsoft Research Newsletter&lt;/h2&gt;
				
								&lt;p class="large" id="microsoft-research-newsletter"&gt;Stay connected to the research community at Microsoft.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;&lt;!-- promos injected --&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	&lt;p&gt;Fara-7B&amp;nbsp;operates by&amp;nbsp;visually perceiving&amp;nbsp;a webpage&amp;nbsp;and&amp;nbsp;takes&amp;nbsp;actions like&amp;nbsp;scrolling, typing, and clicking on directly predicted coordinates.&amp;nbsp;It&amp;nbsp;does not&amp;nbsp;rely on&amp;nbsp;separate models to parse the screen, nor on any additional information like&amp;nbsp;accessibility trees,&amp;nbsp;and&amp;nbsp;thus&amp;nbsp;uses the same modalities as humans to interact with the&amp;nbsp;computer.&amp;nbsp;To train Fara-7B, we developed a novel synthetic data generation pipeline&amp;nbsp;for multi-step&amp;nbsp;web tasks, building on our prior work (AgentInstruct).&amp;nbsp;This data generation pipeline draws from&amp;nbsp;real&amp;nbsp;web pages and tasks&amp;nbsp;sourced&amp;nbsp;from human users.&lt;/p&gt;







&lt;figure class="wp-block-video aligncenter"&gt;&lt;video controls="controls" poster="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/Fara_xbox_multi_turn-3.jpg" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/fara_xbox_multi_turn-3.mp4"&gt;&lt;/video&gt;&lt;figcaption class="wp-element-caption"&gt;Video 1: A demo of a shopping scenario with Fara-7B through Magentic-UI. Fara-7B is asked to purchase an X-Box Spongebob controller. Fara-7B goes on to complete this task, but while doing so, also stops at every Critical Point to get input and approval from the user before proceeding.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;figure class="wp-block-video aligncenter"&gt;&lt;video controls="controls" poster="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/Fara_github_demo.jpg" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/fara_github_demo.mp4"&gt;&lt;/video&gt;&lt;figcaption class="wp-element-caption"&gt;Video 2: A demo of Fara-7B finding relevant information online and summarizing it through Magentic-UI. We ask Fara-7B to find and summarize the latest three issues on Github Microsoft/Magentic-UI.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;figure class="wp-block-video aligncenter"&gt;&lt;video controls="controls" poster="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/Fara_driving-directions-cheese.jpg" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/driving_directions_cheese-1_revised.mp4"&gt;&lt;/video&gt;&lt;figcaption class="wp-element-caption"&gt;Video 3: A demo of how Fara-7B can use different tools to find relevant information and analyze it through Magentic-UI. We ask Fara-7B to find driving time between two places, and suggest a cheese place near the location. Fara-7B uses Bing Maps to find Driving time, and Bing search to find relevant information.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Fara-7B exhibits&amp;nbsp;strong performance&amp;nbsp;compared to existing models&amp;nbsp;across&amp;nbsp;a diverse set of benchmarks.&amp;nbsp;This includes both existing benchmarks as well as new&amp;nbsp;evaluations&amp;nbsp;we are&amp;nbsp;releasing&amp;nbsp;which&amp;nbsp;cover useful&amp;nbsp;task&amp;nbsp;segments that are underrepresented in common benchmarks, such as&amp;nbsp;finding job postings&amp;nbsp;and&amp;nbsp;comparing prices across retailers. While Fara-7B demonstrates strong benchmark results, even against much larger models, it shares many of their limitations, including challenges with accuracy on more complex tasks, mistakes in following instructions, and susceptibility to hallucinations.&amp;nbsp;These are active areas of research, and&amp;nbsp;we’re&amp;nbsp;committed to ongoing improvements as we learn from real-world use.&lt;/p&gt;



&lt;p&gt;Fara-7B is now available on&amp;nbsp;Microsoft Foundry&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;and&amp;nbsp;Hugging Face&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;under an MIT license and is integrated with&amp;nbsp;Magentic-UI, a research prototype from Microsoft Research AI Frontiers&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. We are also sharing a quantized and silicon-optimized version of Fara-7B, which will be available to install and run on&amp;nbsp;Copilot+ PCs powered by Windows 11, for turnkey experimentation.&amp;nbsp;The&amp;nbsp;community&amp;nbsp;can simply download the pre-optimized model and run it in their environment.&lt;/p&gt;



&lt;p&gt;By making Fara-7B open-weight, we aim to lower the barrier&amp;nbsp;to experimenting&amp;nbsp;with&amp;nbsp;and improving&amp;nbsp;CUA technology for automating routine web tasks, such as searching for information,&amp;nbsp;shopping,&amp;nbsp;and&amp;nbsp;booking reservations.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure&amp;nbsp;1:&amp;nbsp;Comparing&amp;nbsp;WebVoyager&amp;nbsp;accuracy and cost&amp;nbsp;of&amp;nbsp;Fara-7B to other&amp;nbsp;computer&amp;nbsp;use agents (CUAs)&amp;nbsp;or agents that prompt LLMs with accessibility trees (SoM&amp;nbsp;Agent w/ Ax Tree).&amp;nbsp;Cost is computed&amp;nbsp;by&amp;nbsp;multiplying&amp;nbsp;the&amp;nbsp;average&amp;nbsp;number of&amp;nbsp;input&amp;nbsp;and&amp;nbsp;output tokens&amp;nbsp;each model&amp;nbsp;consumes&amp;nbsp;by&amp;nbsp;price per token.&amp;nbsp;Both&amp;nbsp;Fara-7B and UI-TARS-1.5-7B&amp;nbsp;are based&amp;nbsp;on&amp;nbsp;Qwen-2.5-VL-7B,&amp;nbsp;for which the&amp;nbsp;lowest&amp;nbsp;inference price&amp;nbsp;from&amp;nbsp;&amp;nbsp;https://openrouter.ai/&amp;nbsp;&amp;nbsp;is&amp;nbsp;\(0.2/\)0.2&amp;nbsp;per 1M&amp;nbsp;input/output&amp;nbsp;tokens.&amp;nbsp;Even though both models are priced equally, Fara-7B is more&amp;nbsp;efficient,&amp;nbsp;completing tasks&amp;nbsp;with&amp;nbsp;only&amp;nbsp;~16&amp;nbsp;steps on&amp;nbsp;average&amp;nbsp;compared&amp;nbsp;to&amp;nbsp;~41&amp;nbsp;for UI-TARS-1.5-7B.&amp;nbsp;OpenAI computer-use-preview accessed November 2025 via the Responses API." class="wp-image-1156353" height="11897" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/model_accuracy_vs_cost_v2-1-1.png" width="19108" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;&lt;em&gt;Figure&amp;nbsp;1:&amp;nbsp;Comparing&amp;nbsp;WebVoyager&amp;nbsp;accuracy and cost&amp;nbsp;of&amp;nbsp;Fara-7B to other&amp;nbsp;computer&amp;nbsp;use agents (CUAs)&amp;nbsp;or agents that prompt LLMs with accessibility trees (SoM&amp;nbsp;Agent w/ Ax Tree).&amp;nbsp;Cost is computed&amp;nbsp;by&amp;nbsp;multiplying&amp;nbsp;the&amp;nbsp;average&amp;nbsp;number of&amp;nbsp;input&amp;nbsp;and&amp;nbsp;output tokens&amp;nbsp;each model&amp;nbsp;consumes&amp;nbsp;by&amp;nbsp;price per token.&amp;nbsp;Both&amp;nbsp;Fara-7B and UI-TARS-1.5-7B&amp;nbsp;are based&amp;nbsp;on&amp;nbsp;Qwen-2.5-VL-7B,&amp;nbsp;for which the&amp;nbsp;lowest&amp;nbsp;inference price&amp;nbsp;from&amp;nbsp;&lt;/em&gt;&lt;em&gt;https://openrouter.ai/&lt;/em&gt;&lt;em&gt;&amp;nbsp;&amp;nbsp;is&amp;nbsp;\(0.2/\)0.2&amp;nbsp;per 1M&amp;nbsp;input/output&amp;nbsp;tokens.&amp;nbsp;Even though both models are priced equally, Fara-7B is more&amp;nbsp;efficient,&amp;nbsp;completing tasks&amp;nbsp;with&amp;nbsp;only&amp;nbsp;~16&amp;nbsp;steps on&amp;nbsp;average&amp;nbsp;compared&amp;nbsp;to&amp;nbsp;~41&amp;nbsp;for UI-TARS-1.5-7B.&amp;nbsp;OpenAI computer-use-preview accessed November 2025 via the Responses API.&lt;/em&gt;&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="developing-fara-7b"&gt;Developing Fara-7B&lt;/h2&gt;



&lt;h3 class="wp-block-heading" id="cua-multi-agent-synthetic-data-generation"&gt;CUA multi-agent synthetic data generation&lt;/h3&gt;



&lt;p&gt;A key bottleneck&amp;nbsp;for&amp;nbsp;building CUA models is a lack of large-scale, high-quality&amp;nbsp;computer interaction data. Collecting such data with&amp;nbsp;human annotators&amp;nbsp;is prohibitively expensive as a single&amp;nbsp;CUA task can involve&amp;nbsp;dozens&amp;nbsp;of steps,&amp;nbsp;each of which&amp;nbsp;needs to be&amp;nbsp;annotated.&amp;nbsp;Our&amp;nbsp;data generation pipeline&amp;nbsp;(Figure 2)&amp;nbsp;avoids manual annotation and instead relies on scalable synthetic data sourced from&amp;nbsp;publicly&amp;nbsp;available websites&amp;nbsp;and&amp;nbsp;custom&amp;nbsp;task prompts.&amp;nbsp;We build this&amp;nbsp;pipeline&amp;nbsp;on top of&amp;nbsp;the&amp;nbsp;Magentic-One&amp;nbsp;framework, and it involves three main stages:&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure&amp;nbsp;2:&amp;nbsp;Data Generation workflow from proposing tasks from various seeds like URLs&amp;nbsp;to&amp;nbsp;solving&amp;nbsp;those tasks with&amp;nbsp;the&amp;nbsp;Magentic-One multi-agent framework to generate demonstrations for training, and finally&amp;nbsp;verifiying/filtering&amp;nbsp;completed&amp;nbsp;trajectories" class="wp-image-1155974" height="1349" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/Figure-2-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure&amp;nbsp;2:&lt;em&gt;&amp;nbsp;Data Generation workflow from proposing tasks from various seeds like URLs&amp;nbsp;to&amp;nbsp;solving&amp;nbsp;those tasks with&amp;nbsp;the&amp;nbsp;Magentic-One multi-agent framework to generate demonstrations for training, and finally&amp;nbsp;verifiying/filtering&amp;nbsp;completed&amp;nbsp;trajectories&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;&lt;strong&gt;Task Proposal.&lt;/strong&gt;&amp;nbsp;We generate a broad set of synthetic tasks that mirror common user activities on the&amp;nbsp;web.&amp;nbsp;To ensure coverage and diversity, tasks are&amp;nbsp;“seeded” by&amp;nbsp;a&amp;nbsp;web&amp;nbsp;index of public URLs&amp;nbsp;classified into various categories e.g., shopping, travel, restaurants, etc. This enables&amp;nbsp;task&amp;nbsp;generation&amp;nbsp;targeting&amp;nbsp;a particular skill, like “book 2 tickets to see the Downton Abbey Grand Finale at AMC Union Square, NYC.”&amp;nbsp;from a&amp;nbsp;URL like this&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;classified as “movies”.&amp;nbsp;&amp;nbsp;As another strategy, we devised a way&amp;nbsp;to generate tasks from&amp;nbsp;randomly&amp;nbsp;sampled&amp;nbsp;URLs.&amp;nbsp;Each task starts with a general prompt and is iteratively refined as an&amp;nbsp;LLM&amp;nbsp;agent explores the website and gathers&amp;nbsp;more information about it. We are releasing a held-out subset of these tasks as a benchmark (“&lt;strong&gt;WebTailBench&lt;/strong&gt;”), described in the Evaluation section below.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Task&amp;nbsp;Solving.&lt;/strong&gt;&amp;nbsp;Once synthetic tasks are generated, a multi-agent system built on&amp;nbsp;Magentic-One&amp;nbsp;attempts&amp;nbsp;to&amp;nbsp;complete&amp;nbsp;them to generate demonstrations for supervised finetuning. The multi-agent system uses an&amp;nbsp;Orchestrator&amp;nbsp;agent to create a plan and direct a&amp;nbsp;WebSurfer&amp;nbsp;agent to take browser actions and reports results. The Orchestrator monitors progress, updating plans as needed, and can end tasks or engage a&lt;em&gt; &lt;/em&gt;UserSimulator agent if user input is&amp;nbsp;required, allowing for multi-turn completion.&amp;nbsp;Each&amp;nbsp;task and corresponding sequence of observations, actions, and agent thoughts&amp;nbsp;forms&amp;nbsp;a&amp;nbsp;“trajectory”.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Trajectory Verification.&lt;/strong&gt; Before using any tasks for training, three verifier agents evaluate if a task was “successful”: The Alignment Verifier checks if the trajectory of actions match the task’s intent; the Rubric Verifier defines completion criteria and scores the trajectory against them; and the Multimodal Verifier reviews screenshots and responses to confirm visual evidence supports successful completion. Trajectories failing these standards are removed.&lt;/p&gt;



&lt;p&gt;We&amp;nbsp;ultimately&amp;nbsp;train&amp;nbsp;this version&amp;nbsp;of&amp;nbsp;Fara-7B&amp;nbsp;on a dataset of&amp;nbsp;145,000&amp;nbsp;trajectories&amp;nbsp;consisting of&amp;nbsp;1&amp;nbsp;million&amp;nbsp;steps&amp;nbsp;covering diverse websites, task types, and difficulty levels.&amp;nbsp;Additionally, we include&amp;nbsp;training&amp;nbsp;data for several auxiliary tasks, including&amp;nbsp;grounding for&amp;nbsp;accurate&amp;nbsp;UI element localization, captioning, and visual question answering.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="training-fara-7b"&gt;Training Fara-7B&lt;/h3&gt;



&lt;p&gt;Using&amp;nbsp;one&amp;nbsp;compute use&amp;nbsp;model&amp;nbsp;is&amp;nbsp;easier than&amp;nbsp;a&amp;nbsp;multi-agent system, particularly when it comes to&amp;nbsp;deployment. Therefore, we&amp;nbsp;distill the complexities of&amp;nbsp;our multi-agent&amp;nbsp;solving system into a single model&amp;nbsp;that can&amp;nbsp;execute tasks.&amp;nbsp;Fara-7B&amp;nbsp;is a proof-of-concept that small models can&amp;nbsp;effectively&amp;nbsp;learn from complex, multi-agent systems&amp;nbsp;with lots of bells and whistles.&lt;/p&gt;



&lt;p&gt;As shown in Figure 3, Fara-7B is trained to execute user tasks by perceiving only browser window screenshots (without relying on accessibility trees), and predicting single-step actions. For each step, the context used to make its prediction contains all user messages, the complete action history, and the latest three screenshots.&lt;/p&gt;



&lt;p&gt;In its prediction,&amp;nbsp;Fara-7B&amp;nbsp;outputs a reasoning message (“thinking” about the next action) followed by a tool call. The available tools include standard&amp;nbsp;Playwright&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;mouse and keyboard actions, such as&amp;nbsp;click(x,y)&amp;nbsp;and&amp;nbsp;type(), and browser-specific macro-actions like&amp;nbsp;web_search()&amp;nbsp;and&amp;nbsp;visit_url().&lt;/p&gt;



&lt;p&gt;Fara-7B uses&amp;nbsp;Qwen2.5-VL-7B&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;as its base model due to its&amp;nbsp;strong performance&amp;nbsp;on grounding tasks and its ability to support long contexts (up to 128k tokens).&amp;nbsp;We&amp;nbsp;linearize the solving pipeline’s&amp;nbsp;trajectories&amp;nbsp;into a sequence of “observe-think-act” steps&amp;nbsp;that are suitable for training with supervised finetuning loss.&amp;nbsp;We did not use reinforcement learning to achieve&amp;nbsp;the&amp;nbsp;results&amp;nbsp;we report below.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure&amp;nbsp;3:&amp;nbsp;Operation of Fara-7B as a standalone, native computer use agent&amp;nbsp;running on-device. Because Fara-7B is small, and none of its context needs to leave your personal device, it paves the way for personal and private agentic computing" class="wp-image-1155975" height="864" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/Figure-3-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure&amp;nbsp;3:&lt;em&gt;&amp;nbsp;Operation of Fara-7B as a standalone, native computer use agent&amp;nbsp;running on-device. Because Fara-7B is small, and none of its context needs to leave your personal device, it paves the way for personal and private agentic computing&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="evaluations"&gt;Evaluations&lt;/h2&gt;



&lt;p&gt;We evaluate Fara-7B and comparable baselines on canonical public benchmarks including WebVoyager&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Online-Mind2Web&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, and Deepshop&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, as well as a new benchmark we developed named&lt;strong&gt; WebTailBench&lt;/strong&gt;, specifically focusing on 11 real-world task types underrepresented or missing in existing benchmarks like booking movie/event tickets, restaurant reservations, comparing prices across retailers,&amp;nbsp;applying for jobs,&amp;nbsp;finding real estate, and more complex multi-step tasks.&lt;/p&gt;



&lt;p&gt;Evaluation of&amp;nbsp;web&amp;nbsp;agents can be tricky&amp;nbsp;because the web is constantly&amp;nbsp;changing,&amp;nbsp;and many websites even block detected bots,&amp;nbsp;which is why we&amp;nbsp;developed&amp;nbsp;a&amp;nbsp;test&amp;nbsp;harness&amp;nbsp;that&amp;nbsp;relies on&amp;nbsp;BrowserBase&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;to standardize how browser sessions are managed.&amp;nbsp;In Table 1 below, we report a notion of task success rate&amp;nbsp;(%)&amp;nbsp;defined&amp;nbsp;by each benchmark’s official&amp;nbsp;LLM-as-judge evaluator;&amp;nbsp;WebTailBench&amp;nbsp;success is&amp;nbsp;computed using the same Task Verification pipeline that filtered&amp;nbsp;our&amp;nbsp;training data.&amp;nbsp;We find that&amp;nbsp;Fara-7B&amp;nbsp;is&amp;nbsp;state-of-the-art,&amp;nbsp;even&amp;nbsp;outperforming native computer use&amp;nbsp;agents&amp;nbsp;like UI-TARS-1.5-7B, or much larger&amp;nbsp;models&amp;nbsp;like GPT-4o prompted to act like a computer use agent with&amp;nbsp;Set-Of-Marks&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;(SoM&amp;nbsp;Agent).&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-table aligncenter"&gt;&lt;table class="has-fixed-layout"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th colspan="2"&gt;&lt;/th&gt;&lt;th&gt;WebVoyager&lt;/th&gt;&lt;th&gt;Online-Mind2Web&lt;/th&gt;&lt;th&gt;DeepShop&lt;/th&gt;&lt;th&gt;WebTailBench&amp;nbsp;&amp;nbsp;&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td rowspan="2"&gt;SoM&amp;nbsp;Agents&amp;nbsp;&lt;/td&gt;&lt;td&gt;SoM&amp;nbsp;Agent (GPT-4o)&amp;nbsp;&lt;/td&gt;&lt;td&gt;65.1&amp;nbsp;&lt;/td&gt;&lt;td&gt;34.6&amp;nbsp;&lt;/td&gt;&lt;td&gt;16.0&amp;nbsp;&lt;/td&gt;&lt;td&gt;30.0&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;GLM-4.1V-9B-Thinking&amp;nbsp;&lt;/td&gt;&lt;td&gt;66.8&amp;nbsp;&amp;nbsp;&lt;/td&gt;&lt;td&gt;33.9&amp;nbsp;&lt;/td&gt;&lt;td&gt;32.0&amp;nbsp;&lt;/td&gt;&lt;td&gt;22.4&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan="3"&gt;Computer Use Models&amp;nbsp;&lt;/td&gt;&lt;td&gt;OpenAI&amp;nbsp;computer-use-preview&amp;nbsp;&amp;nbsp;&lt;/td&gt;&lt;td&gt;70.9&amp;nbsp;&lt;/td&gt;&lt;td&gt;42.9&amp;nbsp;&lt;/td&gt;&lt;td&gt;24.7&amp;nbsp;&lt;/td&gt;&lt;td&gt;25.7&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;UI-TARS-1.5-7B&amp;nbsp;&lt;/td&gt;&lt;td&gt;66.4&amp;nbsp;&amp;nbsp;&lt;/td&gt;&lt;td&gt;31.3&amp;nbsp;&lt;/td&gt;&lt;td&gt;11.6&amp;nbsp;&lt;/td&gt;&lt;td&gt;19.5&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Fara-7B&amp;nbsp;&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;73.5&amp;nbsp;&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;34.1&amp;nbsp;&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;26.2&lt;/strong&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;38.4&lt;/strong&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class="wp-element-caption"&gt;Table 1:&amp;nbsp;&lt;em&gt;Performance comparison across four web benchmarks:&amp;nbsp;WebVoyager, Online-Mind2Web,&amp;nbsp;DeepShop, and&amp;nbsp;our&amp;nbsp;newly introduced WebTailBench.&amp;nbsp;Results are reported as&amp;nbsp;Task Succes Rate / Accuracy&amp;nbsp;(%) and are averaged over 3 runs.&amp;nbsp;OpenAI computer-use-preview accessed November 2025 via the Responses API.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;In Figure 1, we&amp;nbsp;expand on&amp;nbsp;the&amp;nbsp;Webvoyager&amp;nbsp;results by giving each model up to three chances to complete a task, and report “pass@K”. We also consider&amp;nbsp;on the x-axis the&amp;nbsp;cost of running each model if one were to pay market rates for input/output tokens consumed. Fara-7B breaks ground on a new pareto frontier, showing that on-device computer use agents are approaching the capabilities of frontier models.&lt;/p&gt;



&lt;p&gt;We partnered with a trusted external group,&amp;nbsp;Browserbase, to independently evaluate Fara-7B using human annotators. The model achieved&amp;nbsp;&lt;strong&gt;62%&lt;/strong&gt; on&amp;nbsp;WebVoyager (see detailed reports in&amp;nbsp;Browserbase&amp;nbsp;blog&amp;nbsp;here&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;). These results were generated in the same environment with identical settings and human verification of each task, making them directly comparable. Note that&amp;nbsp;Browserbase’s&amp;nbsp;standard&amp;nbsp;WebVoyager&amp;nbsp;scores do not use retries when&amp;nbsp;environment&amp;nbsp;errors occur; the results referenced here include retries and should not be compared directly to the non-retry scores. Going forward, we are collaborating with&amp;nbsp;Browserbase&amp;nbsp;to host&amp;nbsp;WebTailBench&amp;nbsp;human evaluations to help the community build reliable and reproducible assessments for computer use agents.&amp;nbsp;&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="safety"&gt;Safety&lt;/h3&gt;



&lt;p&gt;Agents capable of operating computers present challenges&amp;nbsp;distinct&amp;nbsp;from&amp;nbsp;chat-only models,&amp;nbsp;including new&amp;nbsp;outlets of&amp;nbsp;user&amp;nbsp;misuse, model misbehavior,&amp;nbsp;and unintended&amp;nbsp;consequences of&amp;nbsp;actions,&amp;nbsp;and&amp;nbsp;external&amp;nbsp;risks like prompt injections or online scams.&amp;nbsp;CUAs&amp;nbsp;take action with&amp;nbsp;real-world consequences, so ensuring&amp;nbsp;robust safety measures is essential to their responsible deployment.&amp;nbsp;Transparency and user control sit at the core of Fara-7B’s design. Although we have incorporated several safety measures, Fara-7B&amp;nbsp;remains&amp;nbsp;a research preview, and we continue to advance our approach to safety for computer use agents, an active area of work across the entire AI community.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Fara-7B processes browser screenshots, user task instructions, and a history of actions taken during each session and collects only what is necessary to complete the user’s requested task. No&amp;nbsp;additional&amp;nbsp;site data—such as&amp;nbsp;accessibility&amp;nbsp;trees or external scaffolding—is accessed; Fara-7B interacts with the computer in the same way a human would, relying solely on what is visible on the screen.&lt;/p&gt;



&lt;p&gt;All actions taken by the agent are logged and auditable, allowing users to review and&amp;nbsp;monitor&amp;nbsp;every step.&amp;nbsp;&amp;nbsp;For added safety, Fara‑7B is intended to run in sandboxed environments, giving users full oversight and the ability to intervene or halt&amp;nbsp;actions at any time. These safeguards ensure that privacy, transparency, and user control remain at the core of every interaction.&lt;/p&gt;



&lt;p&gt;To&amp;nbsp;address&amp;nbsp;misuse, we trained Fara-7B on a mixture of public safety data and internally generated tasks that it&amp;nbsp;ought to refuse&amp;nbsp;based on&amp;nbsp;Microsoft’s Responsible AI Policy.&amp;nbsp;We evaluated&amp;nbsp;Fara-7B’s ability to refuse harmful tasks&amp;nbsp;on&amp;nbsp;&lt;strong&gt;WebTailBench-Refusals&lt;/strong&gt;&amp;nbsp;which consists of&amp;nbsp;111 red-teaming tasks&amp;nbsp;showing a high refusal rate&amp;nbsp;of 82%.&amp;nbsp;The&amp;nbsp;model&amp;nbsp;also&amp;nbsp;underwent&amp;nbsp;Microsoft’s&amp;nbsp;rigorous&amp;nbsp;red teaming process, where we focused on the model rejecting harmful tasks and risky tasks, such as harmful content, jailbreaking attempts, ungrounded&amp;nbsp;responses,&amp;nbsp;and prompt injections. For further details, check out our technical report&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&lt;/p&gt;



&lt;p&gt;To mitigate the risk of Fara-7B taking unintended actions,&amp;nbsp;all of&amp;nbsp;Fara-7B’s&amp;nbsp;training data enforces both recognizing and stopping at “Critical Points” when executing a task. A Critical Point&amp;nbsp;(see&amp;nbsp;Operator System Card&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;)&amp;nbsp;is any situation that requires the user’s personal data or consent before engaging in a transaction or irreversible action like sending an email. Upon reaching a Critical Point, Fara-7B&amp;nbsp;should&amp;nbsp;respond by informing the&amp;nbsp;user&amp;nbsp;it&amp;nbsp;cannot&amp;nbsp;proceed&amp;nbsp;without their consent.&lt;/p&gt;



&lt;p&gt;For guidance on how to use our model safely, and the security considerations to be mindful of when using our model, please refer to our&amp;nbsp;Model&amp;nbsp;card&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="how-to-use"&gt;How to use&lt;/h3&gt;



&lt;p&gt;Fara-7B&amp;nbsp;is available on&amp;nbsp;&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;Microsoft&amp;nbsp;Foundry&amp;nbsp;&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;and&amp;nbsp;&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;Hugging Face&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&amp;nbsp;We are also releasing the implementation of Fara-7B&amp;nbsp;in&amp;nbsp;Magentic-UI,&amp;nbsp;so that&amp;nbsp;users&amp;nbsp;can&amp;nbsp;try&amp;nbsp;it&amp;nbsp;in a contained environment&amp;nbsp;through the inference code provided. Additionally, users can download the model for Copilot+&amp;nbsp;PCs&amp;nbsp;powered by Windows 11&amp;nbsp;from the&amp;nbsp;AI&amp;nbsp;Toolkit in VSCode and&amp;nbsp;run it all on-device,&amp;nbsp;taking advantage of&amp;nbsp;NPU hardware acceleration.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="looking-forward"&gt;Looking forward&lt;/h3&gt;



&lt;p&gt;Our current release&amp;nbsp;is an experimental CUA model&amp;nbsp;that achieves&amp;nbsp;state-of-the-art&amp;nbsp;results for its size,&amp;nbsp;purely using&amp;nbsp;supervised fine-tuning.&amp;nbsp;We believe even stronger CUA&amp;nbsp;models capable of running on-device are possible&amp;nbsp;through&amp;nbsp;improved&amp;nbsp;multimodal base models and through Reinforcement Learning&amp;nbsp;on&amp;nbsp;live and sandboxed environments.&amp;nbsp;These early days&amp;nbsp;are about learning from the community and driving real-world experimentation to shape what comes next.&amp;nbsp;If&amp;nbsp;you’d&amp;nbsp;like to join us and help shape the future of SLMs,&amp;nbsp;please&amp;nbsp;apply for open roles.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="acknowledgements"&gt;Acknowledgements:&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;We thank Gustavo de Rosa, Adam Fourney, Michael Harrison, Rafah Hosn, Neel Joshi, Ece Kamar, John Langford, Maya Murad, Sidhartha Sen, Pratyusha Sharma, and Lili Wu for their valuable help, insightful discussions, and continued support throughout this work.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We also thank Pashmina Cameron, Karthik Vijayan, Vicente Rivera, Chris Dern, Sayan Shaw,&amp;nbsp;Sunghoon&amp;nbsp;Choi, Andrey&amp;nbsp;Rybalchenko, and Vivek Pradeep for their efforts in making the model available on Copilot+ PCs through the AI Toolkit.&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;&lt;!-- promos injected --&gt;</description><content:encoded>&lt;h3 class="wp-block-heading" id="pushing-the-frontiers-of-computer-use-agents-with-an-open-weight-ultra-compact-model-optimized-for-real-world-web-tasks"&gt;Pushing the frontiers of computer-use agents with an open-weight, ultra-compact model,&amp;nbsp;optimized&amp;nbsp;for real-world web tasks&lt;/h3&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Three white line icons on a blue-to-green gradient background: a computer monitor with a globe symbol on the left, a cursor arrow with click lines in the center, and a computer mouse outline on the right." class="wp-image-1156197" height="1441" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/Fara7B-BlogHeroFeature-1400x788_NEW-scaled.jpg" width="2560" /&gt;&lt;/figure&gt;



&lt;p&gt;In 2024,&amp;nbsp;Microsoft&amp;nbsp;introduced small language models (SLMs) to customers, starting with the release of Phi&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; models on Microsoft&amp;nbsp;Foundry&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;,&amp;nbsp;as&amp;nbsp;well as deploying&amp;nbsp;Phi Silica&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;on Copilot+&amp;nbsp;PCs&amp;nbsp;powered by Windows 11. Today, we are pleased to&amp;nbsp;announce&amp;nbsp;&lt;strong&gt;Fara-7B&lt;/strong&gt;, our first&amp;nbsp;&lt;strong&gt;agentic SLM&lt;/strong&gt;&amp;nbsp;designed specifically for&amp;nbsp;computer&amp;nbsp;use.&lt;/p&gt;



&lt;p&gt;Unlike traditional chat models that generate text-based responses, Computer&amp;nbsp;Use Agent (CUA) models like Fara-7B&amp;nbsp;leverage computer interfaces, such as a mouse&amp;nbsp;and keyboard, to complete tasks on behalf of users. With only 7 billion parameters, Fara-7B&amp;nbsp;achieves&amp;nbsp;state-of-the-art&amp;nbsp;performance within its size class and is competitive with larger, more resource-intensive agentic systems that depend on prompting multiple large models. Fara-7B’s small size now&amp;nbsp;makes it possible&amp;nbsp;to&amp;nbsp;run CUA models directly on devices. This results in reduced latency and improved privacy, as user data&amp;nbsp;remains&amp;nbsp;local.&lt;/p&gt;



&lt;p&gt;Fara-7B is an experimental release, designed to invite hands-on exploration and feedback from the community. Users can build and test agentic experiences beyond pure research—automating everyday web tasks like filling out forms, searching for information, booking travel, or managing accounts. We recommend running Fara-7B in a sandboxed environment,&amp;nbsp;monitoring&amp;nbsp;its execution, and avoiding sensitive data or high-risk domains. Responsible use is&amp;nbsp;essential&amp;nbsp;as the model continues to evolve.&lt;/p&gt;




	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;Spotlight: Microsoft research newsletter&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;Microsoft Research Newsletter&lt;/h2&gt;
				
								&lt;p class="large" id="microsoft-research-newsletter"&gt;Stay connected to the research community at Microsoft.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;&lt;!-- promos injected --&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	&lt;p&gt;Fara-7B&amp;nbsp;operates by&amp;nbsp;visually perceiving&amp;nbsp;a webpage&amp;nbsp;and&amp;nbsp;takes&amp;nbsp;actions like&amp;nbsp;scrolling, typing, and clicking on directly predicted coordinates.&amp;nbsp;It&amp;nbsp;does not&amp;nbsp;rely on&amp;nbsp;separate models to parse the screen, nor on any additional information like&amp;nbsp;accessibility trees,&amp;nbsp;and&amp;nbsp;thus&amp;nbsp;uses the same modalities as humans to interact with the&amp;nbsp;computer.&amp;nbsp;To train Fara-7B, we developed a novel synthetic data generation pipeline&amp;nbsp;for multi-step&amp;nbsp;web tasks, building on our prior work (AgentInstruct).&amp;nbsp;This data generation pipeline draws from&amp;nbsp;real&amp;nbsp;web pages and tasks&amp;nbsp;sourced&amp;nbsp;from human users.&lt;/p&gt;







&lt;figure class="wp-block-video aligncenter"&gt;&lt;video controls="controls" poster="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/Fara_xbox_multi_turn-3.jpg" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/fara_xbox_multi_turn-3.mp4"&gt;&lt;/video&gt;&lt;figcaption class="wp-element-caption"&gt;Video 1: A demo of a shopping scenario with Fara-7B through Magentic-UI. Fara-7B is asked to purchase an X-Box Spongebob controller. Fara-7B goes on to complete this task, but while doing so, also stops at every Critical Point to get input and approval from the user before proceeding.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;figure class="wp-block-video aligncenter"&gt;&lt;video controls="controls" poster="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/Fara_github_demo.jpg" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/fara_github_demo.mp4"&gt;&lt;/video&gt;&lt;figcaption class="wp-element-caption"&gt;Video 2: A demo of Fara-7B finding relevant information online and summarizing it through Magentic-UI. We ask Fara-7B to find and summarize the latest three issues on Github Microsoft/Magentic-UI.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;figure class="wp-block-video aligncenter"&gt;&lt;video controls="controls" poster="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/Fara_driving-directions-cheese.jpg" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/driving_directions_cheese-1_revised.mp4"&gt;&lt;/video&gt;&lt;figcaption class="wp-element-caption"&gt;Video 3: A demo of how Fara-7B can use different tools to find relevant information and analyze it through Magentic-UI. We ask Fara-7B to find driving time between two places, and suggest a cheese place near the location. Fara-7B uses Bing Maps to find Driving time, and Bing search to find relevant information.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Fara-7B exhibits&amp;nbsp;strong performance&amp;nbsp;compared to existing models&amp;nbsp;across&amp;nbsp;a diverse set of benchmarks.&amp;nbsp;This includes both existing benchmarks as well as new&amp;nbsp;evaluations&amp;nbsp;we are&amp;nbsp;releasing&amp;nbsp;which&amp;nbsp;cover useful&amp;nbsp;task&amp;nbsp;segments that are underrepresented in common benchmarks, such as&amp;nbsp;finding job postings&amp;nbsp;and&amp;nbsp;comparing prices across retailers. While Fara-7B demonstrates strong benchmark results, even against much larger models, it shares many of their limitations, including challenges with accuracy on more complex tasks, mistakes in following instructions, and susceptibility to hallucinations.&amp;nbsp;These are active areas of research, and&amp;nbsp;we’re&amp;nbsp;committed to ongoing improvements as we learn from real-world use.&lt;/p&gt;



&lt;p&gt;Fara-7B is now available on&amp;nbsp;Microsoft Foundry&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;and&amp;nbsp;Hugging Face&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;under an MIT license and is integrated with&amp;nbsp;Magentic-UI, a research prototype from Microsoft Research AI Frontiers&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. We are also sharing a quantized and silicon-optimized version of Fara-7B, which will be available to install and run on&amp;nbsp;Copilot+ PCs powered by Windows 11, for turnkey experimentation.&amp;nbsp;The&amp;nbsp;community&amp;nbsp;can simply download the pre-optimized model and run it in their environment.&lt;/p&gt;



&lt;p&gt;By making Fara-7B open-weight, we aim to lower the barrier&amp;nbsp;to experimenting&amp;nbsp;with&amp;nbsp;and improving&amp;nbsp;CUA technology for automating routine web tasks, such as searching for information,&amp;nbsp;shopping,&amp;nbsp;and&amp;nbsp;booking reservations.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure&amp;nbsp;1:&amp;nbsp;Comparing&amp;nbsp;WebVoyager&amp;nbsp;accuracy and cost&amp;nbsp;of&amp;nbsp;Fara-7B to other&amp;nbsp;computer&amp;nbsp;use agents (CUAs)&amp;nbsp;or agents that prompt LLMs with accessibility trees (SoM&amp;nbsp;Agent w/ Ax Tree).&amp;nbsp;Cost is computed&amp;nbsp;by&amp;nbsp;multiplying&amp;nbsp;the&amp;nbsp;average&amp;nbsp;number of&amp;nbsp;input&amp;nbsp;and&amp;nbsp;output tokens&amp;nbsp;each model&amp;nbsp;consumes&amp;nbsp;by&amp;nbsp;price per token.&amp;nbsp;Both&amp;nbsp;Fara-7B and UI-TARS-1.5-7B&amp;nbsp;are based&amp;nbsp;on&amp;nbsp;Qwen-2.5-VL-7B,&amp;nbsp;for which the&amp;nbsp;lowest&amp;nbsp;inference price&amp;nbsp;from&amp;nbsp;&amp;nbsp;https://openrouter.ai/&amp;nbsp;&amp;nbsp;is&amp;nbsp;\(0.2/\)0.2&amp;nbsp;per 1M&amp;nbsp;input/output&amp;nbsp;tokens.&amp;nbsp;Even though both models are priced equally, Fara-7B is more&amp;nbsp;efficient,&amp;nbsp;completing tasks&amp;nbsp;with&amp;nbsp;only&amp;nbsp;~16&amp;nbsp;steps on&amp;nbsp;average&amp;nbsp;compared&amp;nbsp;to&amp;nbsp;~41&amp;nbsp;for UI-TARS-1.5-7B.&amp;nbsp;OpenAI computer-use-preview accessed November 2025 via the Responses API." class="wp-image-1156353" height="11897" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/model_accuracy_vs_cost_v2-1-1.png" width="19108" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;&lt;em&gt;Figure&amp;nbsp;1:&amp;nbsp;Comparing&amp;nbsp;WebVoyager&amp;nbsp;accuracy and cost&amp;nbsp;of&amp;nbsp;Fara-7B to other&amp;nbsp;computer&amp;nbsp;use agents (CUAs)&amp;nbsp;or agents that prompt LLMs with accessibility trees (SoM&amp;nbsp;Agent w/ Ax Tree).&amp;nbsp;Cost is computed&amp;nbsp;by&amp;nbsp;multiplying&amp;nbsp;the&amp;nbsp;average&amp;nbsp;number of&amp;nbsp;input&amp;nbsp;and&amp;nbsp;output tokens&amp;nbsp;each model&amp;nbsp;consumes&amp;nbsp;by&amp;nbsp;price per token.&amp;nbsp;Both&amp;nbsp;Fara-7B and UI-TARS-1.5-7B&amp;nbsp;are based&amp;nbsp;on&amp;nbsp;Qwen-2.5-VL-7B,&amp;nbsp;for which the&amp;nbsp;lowest&amp;nbsp;inference price&amp;nbsp;from&amp;nbsp;&lt;/em&gt;&lt;em&gt;https://openrouter.ai/&lt;/em&gt;&lt;em&gt;&amp;nbsp;&amp;nbsp;is&amp;nbsp;\(0.2/\)0.2&amp;nbsp;per 1M&amp;nbsp;input/output&amp;nbsp;tokens.&amp;nbsp;Even though both models are priced equally, Fara-7B is more&amp;nbsp;efficient,&amp;nbsp;completing tasks&amp;nbsp;with&amp;nbsp;only&amp;nbsp;~16&amp;nbsp;steps on&amp;nbsp;average&amp;nbsp;compared&amp;nbsp;to&amp;nbsp;~41&amp;nbsp;for UI-TARS-1.5-7B.&amp;nbsp;OpenAI computer-use-preview accessed November 2025 via the Responses API.&lt;/em&gt;&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="developing-fara-7b"&gt;Developing Fara-7B&lt;/h2&gt;



&lt;h3 class="wp-block-heading" id="cua-multi-agent-synthetic-data-generation"&gt;CUA multi-agent synthetic data generation&lt;/h3&gt;



&lt;p&gt;A key bottleneck&amp;nbsp;for&amp;nbsp;building CUA models is a lack of large-scale, high-quality&amp;nbsp;computer interaction data. Collecting such data with&amp;nbsp;human annotators&amp;nbsp;is prohibitively expensive as a single&amp;nbsp;CUA task can involve&amp;nbsp;dozens&amp;nbsp;of steps,&amp;nbsp;each of which&amp;nbsp;needs to be&amp;nbsp;annotated.&amp;nbsp;Our&amp;nbsp;data generation pipeline&amp;nbsp;(Figure 2)&amp;nbsp;avoids manual annotation and instead relies on scalable synthetic data sourced from&amp;nbsp;publicly&amp;nbsp;available websites&amp;nbsp;and&amp;nbsp;custom&amp;nbsp;task prompts.&amp;nbsp;We build this&amp;nbsp;pipeline&amp;nbsp;on top of&amp;nbsp;the&amp;nbsp;Magentic-One&amp;nbsp;framework, and it involves three main stages:&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure&amp;nbsp;2:&amp;nbsp;Data Generation workflow from proposing tasks from various seeds like URLs&amp;nbsp;to&amp;nbsp;solving&amp;nbsp;those tasks with&amp;nbsp;the&amp;nbsp;Magentic-One multi-agent framework to generate demonstrations for training, and finally&amp;nbsp;verifiying/filtering&amp;nbsp;completed&amp;nbsp;trajectories" class="wp-image-1155974" height="1349" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/Figure-2-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure&amp;nbsp;2:&lt;em&gt;&amp;nbsp;Data Generation workflow from proposing tasks from various seeds like URLs&amp;nbsp;to&amp;nbsp;solving&amp;nbsp;those tasks with&amp;nbsp;the&amp;nbsp;Magentic-One multi-agent framework to generate demonstrations for training, and finally&amp;nbsp;verifiying/filtering&amp;nbsp;completed&amp;nbsp;trajectories&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;&lt;strong&gt;Task Proposal.&lt;/strong&gt;&amp;nbsp;We generate a broad set of synthetic tasks that mirror common user activities on the&amp;nbsp;web.&amp;nbsp;To ensure coverage and diversity, tasks are&amp;nbsp;“seeded” by&amp;nbsp;a&amp;nbsp;web&amp;nbsp;index of public URLs&amp;nbsp;classified into various categories e.g., shopping, travel, restaurants, etc. This enables&amp;nbsp;task&amp;nbsp;generation&amp;nbsp;targeting&amp;nbsp;a particular skill, like “book 2 tickets to see the Downton Abbey Grand Finale at AMC Union Square, NYC.”&amp;nbsp;from a&amp;nbsp;URL like this&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;classified as “movies”.&amp;nbsp;&amp;nbsp;As another strategy, we devised a way&amp;nbsp;to generate tasks from&amp;nbsp;randomly&amp;nbsp;sampled&amp;nbsp;URLs.&amp;nbsp;Each task starts with a general prompt and is iteratively refined as an&amp;nbsp;LLM&amp;nbsp;agent explores the website and gathers&amp;nbsp;more information about it. We are releasing a held-out subset of these tasks as a benchmark (“&lt;strong&gt;WebTailBench&lt;/strong&gt;”), described in the Evaluation section below.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Task&amp;nbsp;Solving.&lt;/strong&gt;&amp;nbsp;Once synthetic tasks are generated, a multi-agent system built on&amp;nbsp;Magentic-One&amp;nbsp;attempts&amp;nbsp;to&amp;nbsp;complete&amp;nbsp;them to generate demonstrations for supervised finetuning. The multi-agent system uses an&amp;nbsp;Orchestrator&amp;nbsp;agent to create a plan and direct a&amp;nbsp;WebSurfer&amp;nbsp;agent to take browser actions and reports results. The Orchestrator monitors progress, updating plans as needed, and can end tasks or engage a&lt;em&gt; &lt;/em&gt;UserSimulator agent if user input is&amp;nbsp;required, allowing for multi-turn completion.&amp;nbsp;Each&amp;nbsp;task and corresponding sequence of observations, actions, and agent thoughts&amp;nbsp;forms&amp;nbsp;a&amp;nbsp;“trajectory”.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Trajectory Verification.&lt;/strong&gt; Before using any tasks for training, three verifier agents evaluate if a task was “successful”: The Alignment Verifier checks if the trajectory of actions match the task’s intent; the Rubric Verifier defines completion criteria and scores the trajectory against them; and the Multimodal Verifier reviews screenshots and responses to confirm visual evidence supports successful completion. Trajectories failing these standards are removed.&lt;/p&gt;



&lt;p&gt;We&amp;nbsp;ultimately&amp;nbsp;train&amp;nbsp;this version&amp;nbsp;of&amp;nbsp;Fara-7B&amp;nbsp;on a dataset of&amp;nbsp;145,000&amp;nbsp;trajectories&amp;nbsp;consisting of&amp;nbsp;1&amp;nbsp;million&amp;nbsp;steps&amp;nbsp;covering diverse websites, task types, and difficulty levels.&amp;nbsp;Additionally, we include&amp;nbsp;training&amp;nbsp;data for several auxiliary tasks, including&amp;nbsp;grounding for&amp;nbsp;accurate&amp;nbsp;UI element localization, captioning, and visual question answering.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="training-fara-7b"&gt;Training Fara-7B&lt;/h3&gt;



&lt;p&gt;Using&amp;nbsp;one&amp;nbsp;compute use&amp;nbsp;model&amp;nbsp;is&amp;nbsp;easier than&amp;nbsp;a&amp;nbsp;multi-agent system, particularly when it comes to&amp;nbsp;deployment. Therefore, we&amp;nbsp;distill the complexities of&amp;nbsp;our multi-agent&amp;nbsp;solving system into a single model&amp;nbsp;that can&amp;nbsp;execute tasks.&amp;nbsp;Fara-7B&amp;nbsp;is a proof-of-concept that small models can&amp;nbsp;effectively&amp;nbsp;learn from complex, multi-agent systems&amp;nbsp;with lots of bells and whistles.&lt;/p&gt;



&lt;p&gt;As shown in Figure 3, Fara-7B is trained to execute user tasks by perceiving only browser window screenshots (without relying on accessibility trees), and predicting single-step actions. For each step, the context used to make its prediction contains all user messages, the complete action history, and the latest three screenshots.&lt;/p&gt;



&lt;p&gt;In its prediction,&amp;nbsp;Fara-7B&amp;nbsp;outputs a reasoning message (“thinking” about the next action) followed by a tool call. The available tools include standard&amp;nbsp;Playwright&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;mouse and keyboard actions, such as&amp;nbsp;click(x,y)&amp;nbsp;and&amp;nbsp;type(), and browser-specific macro-actions like&amp;nbsp;web_search()&amp;nbsp;and&amp;nbsp;visit_url().&lt;/p&gt;



&lt;p&gt;Fara-7B uses&amp;nbsp;Qwen2.5-VL-7B&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;as its base model due to its&amp;nbsp;strong performance&amp;nbsp;on grounding tasks and its ability to support long contexts (up to 128k tokens).&amp;nbsp;We&amp;nbsp;linearize the solving pipeline’s&amp;nbsp;trajectories&amp;nbsp;into a sequence of “observe-think-act” steps&amp;nbsp;that are suitable for training with supervised finetuning loss.&amp;nbsp;We did not use reinforcement learning to achieve&amp;nbsp;the&amp;nbsp;results&amp;nbsp;we report below.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure&amp;nbsp;3:&amp;nbsp;Operation of Fara-7B as a standalone, native computer use agent&amp;nbsp;running on-device. Because Fara-7B is small, and none of its context needs to leave your personal device, it paves the way for personal and private agentic computing" class="wp-image-1155975" height="864" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/Figure-3-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure&amp;nbsp;3:&lt;em&gt;&amp;nbsp;Operation of Fara-7B as a standalone, native computer use agent&amp;nbsp;running on-device. Because Fara-7B is small, and none of its context needs to leave your personal device, it paves the way for personal and private agentic computing&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="evaluations"&gt;Evaluations&lt;/h2&gt;



&lt;p&gt;We evaluate Fara-7B and comparable baselines on canonical public benchmarks including WebVoyager&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Online-Mind2Web&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, and Deepshop&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, as well as a new benchmark we developed named&lt;strong&gt; WebTailBench&lt;/strong&gt;, specifically focusing on 11 real-world task types underrepresented or missing in existing benchmarks like booking movie/event tickets, restaurant reservations, comparing prices across retailers,&amp;nbsp;applying for jobs,&amp;nbsp;finding real estate, and more complex multi-step tasks.&lt;/p&gt;



&lt;p&gt;Evaluation of&amp;nbsp;web&amp;nbsp;agents can be tricky&amp;nbsp;because the web is constantly&amp;nbsp;changing,&amp;nbsp;and many websites even block detected bots,&amp;nbsp;which is why we&amp;nbsp;developed&amp;nbsp;a&amp;nbsp;test&amp;nbsp;harness&amp;nbsp;that&amp;nbsp;relies on&amp;nbsp;BrowserBase&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;to standardize how browser sessions are managed.&amp;nbsp;In Table 1 below, we report a notion of task success rate&amp;nbsp;(%)&amp;nbsp;defined&amp;nbsp;by each benchmark’s official&amp;nbsp;LLM-as-judge evaluator;&amp;nbsp;WebTailBench&amp;nbsp;success is&amp;nbsp;computed using the same Task Verification pipeline that filtered&amp;nbsp;our&amp;nbsp;training data.&amp;nbsp;We find that&amp;nbsp;Fara-7B&amp;nbsp;is&amp;nbsp;state-of-the-art,&amp;nbsp;even&amp;nbsp;outperforming native computer use&amp;nbsp;agents&amp;nbsp;like UI-TARS-1.5-7B, or much larger&amp;nbsp;models&amp;nbsp;like GPT-4o prompted to act like a computer use agent with&amp;nbsp;Set-Of-Marks&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;(SoM&amp;nbsp;Agent).&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-table aligncenter"&gt;&lt;table class="has-fixed-layout"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th colspan="2"&gt;&lt;/th&gt;&lt;th&gt;WebVoyager&lt;/th&gt;&lt;th&gt;Online-Mind2Web&lt;/th&gt;&lt;th&gt;DeepShop&lt;/th&gt;&lt;th&gt;WebTailBench&amp;nbsp;&amp;nbsp;&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td rowspan="2"&gt;SoM&amp;nbsp;Agents&amp;nbsp;&lt;/td&gt;&lt;td&gt;SoM&amp;nbsp;Agent (GPT-4o)&amp;nbsp;&lt;/td&gt;&lt;td&gt;65.1&amp;nbsp;&lt;/td&gt;&lt;td&gt;34.6&amp;nbsp;&lt;/td&gt;&lt;td&gt;16.0&amp;nbsp;&lt;/td&gt;&lt;td&gt;30.0&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;GLM-4.1V-9B-Thinking&amp;nbsp;&lt;/td&gt;&lt;td&gt;66.8&amp;nbsp;&amp;nbsp;&lt;/td&gt;&lt;td&gt;33.9&amp;nbsp;&lt;/td&gt;&lt;td&gt;32.0&amp;nbsp;&lt;/td&gt;&lt;td&gt;22.4&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan="3"&gt;Computer Use Models&amp;nbsp;&lt;/td&gt;&lt;td&gt;OpenAI&amp;nbsp;computer-use-preview&amp;nbsp;&amp;nbsp;&lt;/td&gt;&lt;td&gt;70.9&amp;nbsp;&lt;/td&gt;&lt;td&gt;42.9&amp;nbsp;&lt;/td&gt;&lt;td&gt;24.7&amp;nbsp;&lt;/td&gt;&lt;td&gt;25.7&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;UI-TARS-1.5-7B&amp;nbsp;&lt;/td&gt;&lt;td&gt;66.4&amp;nbsp;&amp;nbsp;&lt;/td&gt;&lt;td&gt;31.3&amp;nbsp;&lt;/td&gt;&lt;td&gt;11.6&amp;nbsp;&lt;/td&gt;&lt;td&gt;19.5&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Fara-7B&amp;nbsp;&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;73.5&amp;nbsp;&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;34.1&amp;nbsp;&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;26.2&lt;/strong&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;38.4&lt;/strong&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class="wp-element-caption"&gt;Table 1:&amp;nbsp;&lt;em&gt;Performance comparison across four web benchmarks:&amp;nbsp;WebVoyager, Online-Mind2Web,&amp;nbsp;DeepShop, and&amp;nbsp;our&amp;nbsp;newly introduced WebTailBench.&amp;nbsp;Results are reported as&amp;nbsp;Task Succes Rate / Accuracy&amp;nbsp;(%) and are averaged over 3 runs.&amp;nbsp;OpenAI computer-use-preview accessed November 2025 via the Responses API.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;In Figure 1, we&amp;nbsp;expand on&amp;nbsp;the&amp;nbsp;Webvoyager&amp;nbsp;results by giving each model up to three chances to complete a task, and report “pass@K”. We also consider&amp;nbsp;on the x-axis the&amp;nbsp;cost of running each model if one were to pay market rates for input/output tokens consumed. Fara-7B breaks ground on a new pareto frontier, showing that on-device computer use agents are approaching the capabilities of frontier models.&lt;/p&gt;



&lt;p&gt;We partnered with a trusted external group,&amp;nbsp;Browserbase, to independently evaluate Fara-7B using human annotators. The model achieved&amp;nbsp;&lt;strong&gt;62%&lt;/strong&gt; on&amp;nbsp;WebVoyager (see detailed reports in&amp;nbsp;Browserbase&amp;nbsp;blog&amp;nbsp;here&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;). These results were generated in the same environment with identical settings and human verification of each task, making them directly comparable. Note that&amp;nbsp;Browserbase’s&amp;nbsp;standard&amp;nbsp;WebVoyager&amp;nbsp;scores do not use retries when&amp;nbsp;environment&amp;nbsp;errors occur; the results referenced here include retries and should not be compared directly to the non-retry scores. Going forward, we are collaborating with&amp;nbsp;Browserbase&amp;nbsp;to host&amp;nbsp;WebTailBench&amp;nbsp;human evaluations to help the community build reliable and reproducible assessments for computer use agents.&amp;nbsp;&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="safety"&gt;Safety&lt;/h3&gt;



&lt;p&gt;Agents capable of operating computers present challenges&amp;nbsp;distinct&amp;nbsp;from&amp;nbsp;chat-only models,&amp;nbsp;including new&amp;nbsp;outlets of&amp;nbsp;user&amp;nbsp;misuse, model misbehavior,&amp;nbsp;and unintended&amp;nbsp;consequences of&amp;nbsp;actions,&amp;nbsp;and&amp;nbsp;external&amp;nbsp;risks like prompt injections or online scams.&amp;nbsp;CUAs&amp;nbsp;take action with&amp;nbsp;real-world consequences, so ensuring&amp;nbsp;robust safety measures is essential to their responsible deployment.&amp;nbsp;Transparency and user control sit at the core of Fara-7B’s design. Although we have incorporated several safety measures, Fara-7B&amp;nbsp;remains&amp;nbsp;a research preview, and we continue to advance our approach to safety for computer use agents, an active area of work across the entire AI community.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Fara-7B processes browser screenshots, user task instructions, and a history of actions taken during each session and collects only what is necessary to complete the user’s requested task. No&amp;nbsp;additional&amp;nbsp;site data—such as&amp;nbsp;accessibility&amp;nbsp;trees or external scaffolding—is accessed; Fara-7B interacts with the computer in the same way a human would, relying solely on what is visible on the screen.&lt;/p&gt;



&lt;p&gt;All actions taken by the agent are logged and auditable, allowing users to review and&amp;nbsp;monitor&amp;nbsp;every step.&amp;nbsp;&amp;nbsp;For added safety, Fara‑7B is intended to run in sandboxed environments, giving users full oversight and the ability to intervene or halt&amp;nbsp;actions at any time. These safeguards ensure that privacy, transparency, and user control remain at the core of every interaction.&lt;/p&gt;



&lt;p&gt;To&amp;nbsp;address&amp;nbsp;misuse, we trained Fara-7B on a mixture of public safety data and internally generated tasks that it&amp;nbsp;ought to refuse&amp;nbsp;based on&amp;nbsp;Microsoft’s Responsible AI Policy.&amp;nbsp;We evaluated&amp;nbsp;Fara-7B’s ability to refuse harmful tasks&amp;nbsp;on&amp;nbsp;&lt;strong&gt;WebTailBench-Refusals&lt;/strong&gt;&amp;nbsp;which consists of&amp;nbsp;111 red-teaming tasks&amp;nbsp;showing a high refusal rate&amp;nbsp;of 82%.&amp;nbsp;The&amp;nbsp;model&amp;nbsp;also&amp;nbsp;underwent&amp;nbsp;Microsoft’s&amp;nbsp;rigorous&amp;nbsp;red teaming process, where we focused on the model rejecting harmful tasks and risky tasks, such as harmful content, jailbreaking attempts, ungrounded&amp;nbsp;responses,&amp;nbsp;and prompt injections. For further details, check out our technical report&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&lt;/p&gt;



&lt;p&gt;To mitigate the risk of Fara-7B taking unintended actions,&amp;nbsp;all of&amp;nbsp;Fara-7B’s&amp;nbsp;training data enforces both recognizing and stopping at “Critical Points” when executing a task. A Critical Point&amp;nbsp;(see&amp;nbsp;Operator System Card&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;)&amp;nbsp;is any situation that requires the user’s personal data or consent before engaging in a transaction or irreversible action like sending an email. Upon reaching a Critical Point, Fara-7B&amp;nbsp;should&amp;nbsp;respond by informing the&amp;nbsp;user&amp;nbsp;it&amp;nbsp;cannot&amp;nbsp;proceed&amp;nbsp;without their consent.&lt;/p&gt;



&lt;p&gt;For guidance on how to use our model safely, and the security considerations to be mindful of when using our model, please refer to our&amp;nbsp;Model&amp;nbsp;card&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="how-to-use"&gt;How to use&lt;/h3&gt;



&lt;p&gt;Fara-7B&amp;nbsp;is available on&amp;nbsp;&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;Microsoft&amp;nbsp;Foundry&amp;nbsp;&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;and&amp;nbsp;&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;Hugging Face&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&amp;nbsp;We are also releasing the implementation of Fara-7B&amp;nbsp;in&amp;nbsp;Magentic-UI,&amp;nbsp;so that&amp;nbsp;users&amp;nbsp;can&amp;nbsp;try&amp;nbsp;it&amp;nbsp;in a contained environment&amp;nbsp;through the inference code provided. Additionally, users can download the model for Copilot+&amp;nbsp;PCs&amp;nbsp;powered by Windows 11&amp;nbsp;from the&amp;nbsp;AI&amp;nbsp;Toolkit in VSCode and&amp;nbsp;run it all on-device,&amp;nbsp;taking advantage of&amp;nbsp;NPU hardware acceleration.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="looking-forward"&gt;Looking forward&lt;/h3&gt;



&lt;p&gt;Our current release&amp;nbsp;is an experimental CUA model&amp;nbsp;that achieves&amp;nbsp;state-of-the-art&amp;nbsp;results for its size,&amp;nbsp;purely using&amp;nbsp;supervised fine-tuning.&amp;nbsp;We believe even stronger CUA&amp;nbsp;models capable of running on-device are possible&amp;nbsp;through&amp;nbsp;improved&amp;nbsp;multimodal base models and through Reinforcement Learning&amp;nbsp;on&amp;nbsp;live and sandboxed environments.&amp;nbsp;These early days&amp;nbsp;are about learning from the community and driving real-world experimentation to shape what comes next.&amp;nbsp;If&amp;nbsp;you’d&amp;nbsp;like to join us and help shape the future of SLMs,&amp;nbsp;please&amp;nbsp;apply for open roles.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="acknowledgements"&gt;Acknowledgements:&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;We thank Gustavo de Rosa, Adam Fourney, Michael Harrison, Rafah Hosn, Neel Joshi, Ece Kamar, John Langford, Maya Murad, Sidhartha Sen, Pratyusha Sharma, and Lili Wu for their valuable help, insightful discussions, and continued support throughout this work.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We also thank Pashmina Cameron, Karthik Vijayan, Vicente Rivera, Chris Dern, Sayan Shaw,&amp;nbsp;Sunghoon&amp;nbsp;Choi, Andrey&amp;nbsp;Rybalchenko, and Vivek Pradeep for their efforts in making the model available on Copilot+ PCs through the AI Toolkit.&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;&lt;!-- promos injected --&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/blog/fara-7b-an-efficient-agentic-model-for-computer-use/</guid><pubDate>Mon, 24 Nov 2025 18:00:00 +0000</pubDate></item><item><title>[NEW] ZAYA1: AI model using AMD GPUs for training hits milestone (AI News)</title><link>https://www.artificialintelligence-news.com/news/zaya1-ai-model-using-amd-gpus-for-training-hits-milestone/</link><description>&lt;p&gt;Zyphra, AMD, and IBM spent a year testing whether AMD’s GPUs and platform can support large-scale AI model training, and the result is ZAYA1.&lt;/p&gt;&lt;p&gt;In partnership, the three companies trained ZAYA1 – described as the first major Mixture-of-Experts foundation model built entirely on AMD GPUs and networking – which they see as proof that the market doesn’t have to depend on NVIDIA to scale AI.&lt;/p&gt;&lt;p&gt;The model was trained on AMD’s Instinct MI300X chips, Pensando networking, and ROCm software, all running across IBM Cloud’s infrastructure. What’s notable is how conventional the setup looks. Instead of experimental hardware or obscure configurations, Zyphra built the system much like any enterprise cluster—just without NVIDIA’s components.&lt;/p&gt;&lt;p&gt;Zyphra says ZAYA1 performs on par with, and in some areas ahead of, well-established open models in reasoning, maths, and code. For businesses frustrated by supply constraints or spiralling GPU pricing, it amounts to something rare: a second option that doesn’t require compromising on capability.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-how-zyphra-used-amd-gpus-to-cut-costs-without-gutting-ai-training-performance"&gt;How Zyphra used AMD GPUs to cut costs without gutting AI training performance&lt;/h3&gt;&lt;p&gt;Most organisations follow the same logic when planning training budgets: memory capacity, communication speed, and predictable iteration times matter more than raw theoretical throughput.&amp;nbsp;&lt;/p&gt;&lt;p&gt;MI300X’s 192GB of high-bandwidth memory per GPU gives engineers some breathing room, allowing early training runs without immediately resorting to heavy parallelism. That tends to simplify projects that are otherwise fragile and time-consuming to tune.&lt;/p&gt;&lt;p&gt;Zyphra built each node with eight MI300X GPUs connected over InfinityFabric and paired each one with its own Pollara network card. A separate network handles dataset reads and checkpointing. It’s an unfussy design, but that seems to be the point; the simpler the wiring and network layout, the lower the switch costs and the easier it is to keep iteration times steady.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-zaya1-an-ai-model-that-punches-above-its-weight"&gt;ZAYA1: An AI model that punches above its weight&lt;/h3&gt;&lt;p&gt;ZAYA1-base activates 760 million parameters out of a total 8.3 billion and was trained on 12 trillion tokens in three stages. The architecture leans on compressed attention, a refined routing system to steer tokens to the right experts, and lighter-touch residual scaling to keep deeper layers stable.&lt;/p&gt;&lt;p&gt;The model uses a mix of Muon and AdamW. To make Muon efficient on AMD hardware, Zyphra fused kernels and trimmed unnecessary memory traffic so the optimiser wouldn’t dominate each iteration. Batch sizes were increased over time, but that depends heavily on having storage pipelines that can deliver tokens quickly enough.&lt;/p&gt;&lt;p&gt;All of this leads to an AI model trained on AMD hardware that competes with larger peers such as Qwen3-4B, Gemma3-12B, Llama-3-8B, and OLMoE. One advantage of the MoE structure is that only a sliver of the model runs at once, which helps manage inference memory and reduces serving cost.&lt;/p&gt;&lt;p&gt;A bank, for example, could train a domain-specific model for investigations without needing convoluted parallelism early on. The MI300X’s memory headroom gives engineers space to iterate, while ZAYA1’s compressed attention cuts prefill time during evaluation.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-making-rocm-behave-with-amd-gpus"&gt;Making ROCm behave with AMD GPUs&lt;/h3&gt;&lt;p&gt;Zyphra didn’t hide the fact that moving a mature NVIDIA-based workflow onto ROCm took work. Instead of porting components blindly, the team spent time measuring how AMD hardware behaved and reshaping model dimensions, GEMM patterns, and microbatch sizes to suit MI300X’s preferred compute ranges.&lt;/p&gt;&lt;p&gt;InfinityFabric operates best when all eight GPUs in a node participate in collectives, and Pollara tends to reach peak throughput with larger messages, so Zyphra sized fusion buffers accordingly. Long-context training, from 4k up to 32k tokens, relied on ring attention for sharded sequences and tree attention during decoding to avoid bottlenecks.&lt;/p&gt;&lt;p&gt;Storage considerations were equally practical. Smaller models hammer IOPS; larger ones need sustained bandwidth. Zyphra bundled dataset shards to reduce scattered reads and increased per-node page caches to speed checkpoint recovery, which is vital during long runs where rewinds are inevitable.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-keeping-clusters-on-their-feet"&gt;Keeping clusters on their feet&lt;/h3&gt;&lt;p&gt;Training jobs that run for weeks rarely behave perfectly. Zyphra’s Aegis service monitors logs and system metrics, identifies failures such as NIC glitches or ECC blips, and takes straightforward corrective actions automatically. The team also increased RCCL timeouts to keep short network interruptions from killing entire jobs.&lt;/p&gt;&lt;p&gt;Checkpointing is distributed across all GPUs rather than forced through a single chokepoint. Zyphra reports more than ten-fold faster saves compared with naïve approaches, which directly improves uptime and cuts operator workload.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-the-zaya1-amd-training-milestone-means-for-ai-procurement"&gt;What the ZAYA1 AMD training milestone means for AI procurement&lt;/h3&gt;&lt;p&gt;The report draws a clean line between NVIDIA’s ecosystem and AMD’s equivalents: NVLINK vs InfinityFabric, NCCL vs RCCL, cuBLASLt vs hipBLASLt, and so on. The authors argue the AMD stack is now mature enough for serious large-scale model development.&lt;/p&gt;&lt;p&gt;None of this suggests enterprises should tear out existing NVIDIA clusters. A more realistic path is to keep NVIDIA for production while using AMD for stages that benefit from the memory capacity of MI300X GPUs and ROCm’s openness. It spreads supplier risk and increases total training volume without major disruption.&lt;/p&gt;&lt;p&gt;This all leads us to a set of recommendations: treat model shape as adjustable, not fixed; design networks around the collective operations your training will actually use; build fault tolerance that protects GPU hours rather than merely logging failures; and modernise checkpointing so it no longer derails training rhythm.&lt;/p&gt;&lt;p&gt;It’s not a manifesto, just our practical takeaway from what Zyphra, AMD, and IBM learned by training a large MoE AI model on AMD GPUs. For organisations looking to expand AI capacity without relying solely on one vendor, it’s a potentially useful blueprint.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Google commits to 1000x more AI infrastructure in next 4-5 years&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-110612" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/image-8.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Zyphra, AMD, and IBM spent a year testing whether AMD’s GPUs and platform can support large-scale AI model training, and the result is ZAYA1.&lt;/p&gt;&lt;p&gt;In partnership, the three companies trained ZAYA1 – described as the first major Mixture-of-Experts foundation model built entirely on AMD GPUs and networking – which they see as proof that the market doesn’t have to depend on NVIDIA to scale AI.&lt;/p&gt;&lt;p&gt;The model was trained on AMD’s Instinct MI300X chips, Pensando networking, and ROCm software, all running across IBM Cloud’s infrastructure. What’s notable is how conventional the setup looks. Instead of experimental hardware or obscure configurations, Zyphra built the system much like any enterprise cluster—just without NVIDIA’s components.&lt;/p&gt;&lt;p&gt;Zyphra says ZAYA1 performs on par with, and in some areas ahead of, well-established open models in reasoning, maths, and code. For businesses frustrated by supply constraints or spiralling GPU pricing, it amounts to something rare: a second option that doesn’t require compromising on capability.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-how-zyphra-used-amd-gpus-to-cut-costs-without-gutting-ai-training-performance"&gt;How Zyphra used AMD GPUs to cut costs without gutting AI training performance&lt;/h3&gt;&lt;p&gt;Most organisations follow the same logic when planning training budgets: memory capacity, communication speed, and predictable iteration times matter more than raw theoretical throughput.&amp;nbsp;&lt;/p&gt;&lt;p&gt;MI300X’s 192GB of high-bandwidth memory per GPU gives engineers some breathing room, allowing early training runs without immediately resorting to heavy parallelism. That tends to simplify projects that are otherwise fragile and time-consuming to tune.&lt;/p&gt;&lt;p&gt;Zyphra built each node with eight MI300X GPUs connected over InfinityFabric and paired each one with its own Pollara network card. A separate network handles dataset reads and checkpointing. It’s an unfussy design, but that seems to be the point; the simpler the wiring and network layout, the lower the switch costs and the easier it is to keep iteration times steady.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-zaya1-an-ai-model-that-punches-above-its-weight"&gt;ZAYA1: An AI model that punches above its weight&lt;/h3&gt;&lt;p&gt;ZAYA1-base activates 760 million parameters out of a total 8.3 billion and was trained on 12 trillion tokens in three stages. The architecture leans on compressed attention, a refined routing system to steer tokens to the right experts, and lighter-touch residual scaling to keep deeper layers stable.&lt;/p&gt;&lt;p&gt;The model uses a mix of Muon and AdamW. To make Muon efficient on AMD hardware, Zyphra fused kernels and trimmed unnecessary memory traffic so the optimiser wouldn’t dominate each iteration. Batch sizes were increased over time, but that depends heavily on having storage pipelines that can deliver tokens quickly enough.&lt;/p&gt;&lt;p&gt;All of this leads to an AI model trained on AMD hardware that competes with larger peers such as Qwen3-4B, Gemma3-12B, Llama-3-8B, and OLMoE. One advantage of the MoE structure is that only a sliver of the model runs at once, which helps manage inference memory and reduces serving cost.&lt;/p&gt;&lt;p&gt;A bank, for example, could train a domain-specific model for investigations without needing convoluted parallelism early on. The MI300X’s memory headroom gives engineers space to iterate, while ZAYA1’s compressed attention cuts prefill time during evaluation.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-making-rocm-behave-with-amd-gpus"&gt;Making ROCm behave with AMD GPUs&lt;/h3&gt;&lt;p&gt;Zyphra didn’t hide the fact that moving a mature NVIDIA-based workflow onto ROCm took work. Instead of porting components blindly, the team spent time measuring how AMD hardware behaved and reshaping model dimensions, GEMM patterns, and microbatch sizes to suit MI300X’s preferred compute ranges.&lt;/p&gt;&lt;p&gt;InfinityFabric operates best when all eight GPUs in a node participate in collectives, and Pollara tends to reach peak throughput with larger messages, so Zyphra sized fusion buffers accordingly. Long-context training, from 4k up to 32k tokens, relied on ring attention for sharded sequences and tree attention during decoding to avoid bottlenecks.&lt;/p&gt;&lt;p&gt;Storage considerations were equally practical. Smaller models hammer IOPS; larger ones need sustained bandwidth. Zyphra bundled dataset shards to reduce scattered reads and increased per-node page caches to speed checkpoint recovery, which is vital during long runs where rewinds are inevitable.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-keeping-clusters-on-their-feet"&gt;Keeping clusters on their feet&lt;/h3&gt;&lt;p&gt;Training jobs that run for weeks rarely behave perfectly. Zyphra’s Aegis service monitors logs and system metrics, identifies failures such as NIC glitches or ECC blips, and takes straightforward corrective actions automatically. The team also increased RCCL timeouts to keep short network interruptions from killing entire jobs.&lt;/p&gt;&lt;p&gt;Checkpointing is distributed across all GPUs rather than forced through a single chokepoint. Zyphra reports more than ten-fold faster saves compared with naïve approaches, which directly improves uptime and cuts operator workload.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-the-zaya1-amd-training-milestone-means-for-ai-procurement"&gt;What the ZAYA1 AMD training milestone means for AI procurement&lt;/h3&gt;&lt;p&gt;The report draws a clean line between NVIDIA’s ecosystem and AMD’s equivalents: NVLINK vs InfinityFabric, NCCL vs RCCL, cuBLASLt vs hipBLASLt, and so on. The authors argue the AMD stack is now mature enough for serious large-scale model development.&lt;/p&gt;&lt;p&gt;None of this suggests enterprises should tear out existing NVIDIA clusters. A more realistic path is to keep NVIDIA for production while using AMD for stages that benefit from the memory capacity of MI300X GPUs and ROCm’s openness. It spreads supplier risk and increases total training volume without major disruption.&lt;/p&gt;&lt;p&gt;This all leads us to a set of recommendations: treat model shape as adjustable, not fixed; design networks around the collective operations your training will actually use; build fault tolerance that protects GPU hours rather than merely logging failures; and modernise checkpointing so it no longer derails training rhythm.&lt;/p&gt;&lt;p&gt;It’s not a manifesto, just our practical takeaway from what Zyphra, AMD, and IBM learned by training a large MoE AI model on AMD GPUs. For organisations looking to expand AI capacity without relying solely on one vendor, it’s a potentially useful blueprint.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Google commits to 1000x more AI infrastructure in next 4-5 years&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-110612" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/image-8.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/zaya1-ai-model-using-amd-gpus-for-training-hits-milestone/</guid><pubDate>Mon, 24 Nov 2025 18:07:40 +0000</pubDate></item><item><title>[NEW] Anthropic releases Opus 4.5 with new Chrome and Excel integrations (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/24/anthropic-releases-opus-4-5-with-new-chrome-and-excel-integrations/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/Claude-Opus-4.5-illustration.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Monday, Anthropic announced Opus 4.5, the latest version of its flagship model. It’s the last of Anthropic’s 4.5 series of models to be released, following the launch of Sonnet 4.5 in September and Haiku 4.5 in October.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As expected, the new version of Opus has state-of-the-art performance on a range of benchmarks, including coding benchmarks (SWE-Bench and Terminal-bench), tool use (tau2-bench and MCP Atlas), and general problem solving (ARC-AGI 2, GPQA Diamond).&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Notably, Opus 4.5 is the first model to score over 80% on SWE-Bench verified, a respected coding benchmark.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic also emphasized Opus’ computer use and spreadsheet capabilities, and launched a number of parallel products to showcase how the model holds up in those settings. Together with Opus 4.5, Anthropic will make its Claude for Chrome and Claude for Excel products — previously in pilot — more broadly available. The Chrome extension will be available to all Max users, while the Excel-focused model will be available to Max, Team, and Enterprise users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Opus 4.5 also comes with memory improvements for long-context operations, which required significant changes in how the model manages its memory. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“There are improvements we made on general long context quality in training with Opus 4.5, but context windows are not going to be sufficient by themselves,” Dianne Na Penn, Anthropic’s head of product management for research, told TechCrunch. “Knowing the right details to remember is really important in complement to just having a longer context window.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Those changes also enabled a long-requested “endless chat” feature for paid Claude users, which will allow chats to proceed without interruption when the model hits its context window. Instead, the model will compress its context memory without alerting the user.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Many of the upgrades are made with an eye toward agentic use cases, particularly scenarios in which Opus acts as a lead agent commanding a group of Haiku-powered sub-agents. Managing those tasks requires a strong command of working memory, which is where the memory improvements described by Penn really show their worth.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This is where fundamentals like memory become really important,” Penn says, “because Claude needs to be able to explore code bases and large documents, and also know when to backtrack and recheck something.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Opus 4.5 will face stiff competition from other recently released frontier models, most notably OpenAI’s GPT 5.1 (released on November 12) and Google’s Gemini 3 (released November 18).&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/Claude-Opus-4.5-illustration.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Monday, Anthropic announced Opus 4.5, the latest version of its flagship model. It’s the last of Anthropic’s 4.5 series of models to be released, following the launch of Sonnet 4.5 in September and Haiku 4.5 in October.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As expected, the new version of Opus has state-of-the-art performance on a range of benchmarks, including coding benchmarks (SWE-Bench and Terminal-bench), tool use (tau2-bench and MCP Atlas), and general problem solving (ARC-AGI 2, GPQA Diamond).&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Notably, Opus 4.5 is the first model to score over 80% on SWE-Bench verified, a respected coding benchmark.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic also emphasized Opus’ computer use and spreadsheet capabilities, and launched a number of parallel products to showcase how the model holds up in those settings. Together with Opus 4.5, Anthropic will make its Claude for Chrome and Claude for Excel products — previously in pilot — more broadly available. The Chrome extension will be available to all Max users, while the Excel-focused model will be available to Max, Team, and Enterprise users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Opus 4.5 also comes with memory improvements for long-context operations, which required significant changes in how the model manages its memory. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“There are improvements we made on general long context quality in training with Opus 4.5, but context windows are not going to be sufficient by themselves,” Dianne Na Penn, Anthropic’s head of product management for research, told TechCrunch. “Knowing the right details to remember is really important in complement to just having a longer context window.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Those changes also enabled a long-requested “endless chat” feature for paid Claude users, which will allow chats to proceed without interruption when the model hits its context window. Instead, the model will compress its context memory without alerting the user.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Many of the upgrades are made with an eye toward agentic use cases, particularly scenarios in which Opus acts as a lead agent commanding a group of Haiku-powered sub-agents. Managing those tasks requires a strong command of working memory, which is where the memory improvements described by Penn really show their worth.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This is where fundamentals like memory become really important,” Penn says, “because Claude needs to be able to explore code bases and large documents, and also know when to backtrack and recheck something.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Opus 4.5 will face stiff competition from other recently released frontier models, most notably OpenAI’s GPT 5.1 (released on November 12) and Google’s Gemini 3 (released November 18).&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/24/anthropic-releases-opus-4-5-with-new-chrome-and-excel-integrations/</guid><pubDate>Mon, 24 Nov 2025 19:08:48 +0000</pubDate></item><item><title>[NEW] AWS is spending $50B to build AI infrastructure for the US government (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/24/aws-is-spending-50b-build-ai-infrastructure-for-the-us-government/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/IMG_4752.jpg?resize=1200,797" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon Web Services is making a sizable new investment in infrastructure designed to boost AI capabilities for U.S. government organizations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AWS announced Monday it is investing $50 billion to build AI “high-performance computing infrastructure” purposefully built for the U.S. government. The buildout is meant to expand federal government agencies’ access to AWS AI services.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The project will add 1.3 gigawatts of compute and will expand government access to AWS products, including Amazon SageMaker AI, model customization, Amazon Bedrock, model deployment, and Anthropic’s Claude chatbot, among others, according to the company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AWS expects to break ground on these data center projects in 2026.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our investment in purpose-built government AI and cloud infrastructure will fundamentally transform how federal agencies leverage supercomputing,” AWS CEO Matt Garman said in the company’s press release. “We’re giving agencies expanded access to advanced AI capabilities that will enable them to accelerate critical missions from cybersecurity to drug discovery. This investment removes the technology barriers that have held government back and further positions America to lead in the AI era.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AWS is no stranger to working with the U.S. government.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The entity began building cloud infrastructure for the U.S. government back in 2011. Three years later it launched AWS Top Secret-East, the first air-gapped commercial cloud to work with classified workloads. AWS introduced AWS Secret Region in 2017, which has accredited access to all levels of security classification.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Tech giants have increasingly pitched their AI services to the U.S. government over the past year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched a version of ChatGPT designed exclusively for federal U.S. government agencies in January. OpenAI announced a deal in August that gave government agencies access to the enterprise tier of ChatGPT for just $1 a year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That same month, Anthropic announced it was also giving the U.S. government access to the enterprise tiers of its Claude chatbot for $1. Google announced “Google for Government” for even less, charging 47 cents for the first year, shortly after.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/IMG_4752.jpg?resize=1200,797" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon Web Services is making a sizable new investment in infrastructure designed to boost AI capabilities for U.S. government organizations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AWS announced Monday it is investing $50 billion to build AI “high-performance computing infrastructure” purposefully built for the U.S. government. The buildout is meant to expand federal government agencies’ access to AWS AI services.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The project will add 1.3 gigawatts of compute and will expand government access to AWS products, including Amazon SageMaker AI, model customization, Amazon Bedrock, model deployment, and Anthropic’s Claude chatbot, among others, according to the company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AWS expects to break ground on these data center projects in 2026.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our investment in purpose-built government AI and cloud infrastructure will fundamentally transform how federal agencies leverage supercomputing,” AWS CEO Matt Garman said in the company’s press release. “We’re giving agencies expanded access to advanced AI capabilities that will enable them to accelerate critical missions from cybersecurity to drug discovery. This investment removes the technology barriers that have held government back and further positions America to lead in the AI era.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AWS is no stranger to working with the U.S. government.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The entity began building cloud infrastructure for the U.S. government back in 2011. Three years later it launched AWS Top Secret-East, the first air-gapped commercial cloud to work with classified workloads. AWS introduced AWS Secret Region in 2017, which has accredited access to all levels of security classification.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Tech giants have increasingly pitched their AI services to the U.S. government over the past year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched a version of ChatGPT designed exclusively for federal U.S. government agencies in January. OpenAI announced a deal in August that gave government agencies access to the enterprise tier of ChatGPT for just $1 a year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That same month, Anthropic announced it was also giving the U.S. government access to the enterprise tiers of its Claude chatbot for $1. Google announced “Google for Government” for even less, charging 47 cents for the first year, shortly after.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/24/aws-is-spending-50b-build-ai-infrastructure-for-the-us-government/</guid><pubDate>Mon, 24 Nov 2025 19:10:41 +0000</pubDate></item><item><title>[NEW] Hands on with Stickerbox, the AI-powered sticker maker for kids (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/24/hands-on-with-stickerbox-the-ai-powered-sticker-maker-for-kids/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;There’s a new AI-powered toy for kids called Stickerbox, and, before you groan, I’m here to report that it’s surprisingly fun.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Stickerbox, a product born out of Brooklyn-based startup Hapiko, is a voice-activated sticker printer. The device takes whatever creative idea you have in your head and transforms it into a printed sticker that you can then color, peel, and stick anywhere.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Before trying the device itself, I have to admit I came with a preconceived negative bias — as did my fellow tester (my daughter). Our initial reactions were similar: “&lt;em&gt;An AI that prints stickers? I’d rather design and print my own&lt;/em&gt;.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After trying the review unit sent by the company, we were won over.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Stickerbox, I realized, could represent a new form of creative play — and one that doesn’t outsource the child’s imagination to an AI model as much as you’d think.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3070381" height="680" src="https://techcrunch.com/wp-content/uploads/2025/11/IMG_0092.jpg?w=510" width="510" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-testing-the-ai-sticker-printer"&gt;Testing the AI sticker printer&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The $99.99 toy itself is a small, bright red box with a black-and-white screen and a big, white “push-to-talk” button on top. It ships with three rolls of paper, which equates to 180 stickers, as well as a power cord and colored pencils.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The box’s color scheme is reminiscent of the Etch A Sketch, which makes sense, given that Stickerbox feels like a modern spin on that concept. In the Etch A Sketch’s case, you have to learn how to control different knobs to create the image in your mind. With Stickerbox, those “knobs” are replaced with something more abstract: the voice commands you use to prompt the AI model.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kids aren’t thinking about how to be better prompt engineers, of course; they’re just exploring their imagination and having fun seeing their ideas come to life. Any improvement in their prompting abilities is a side effect.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To initially set up the device, a parent will need to help. Much like adding a smart speaker to your home’s Wi-Fi, you have to first connect to the Stickerbox’s Wi-Fi, then enter the information to connect with your home network. The setup process, which only took a minute, went off without a hitch.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3070370" height="680" src="https://techcrunch.com/wp-content/uploads/2025/11/Stickerbox-with-Hand.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Stickerbox&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Using Stickerbox is simple. You push the button, describe an image out loud, then release the button to see your text appear on screen, followed by an AI-generated image as the printer spits out a physical copy. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;There’s a serendipity to an experience in which you’re thinking of an idea and then holding it in your hand in a matter of seconds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The device’s thermal image printer requires no ink, and the paper is BPS and BPA-free, making it safe to use.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The printed sticker is easy to tear off and then can be colored in with the colored pencils that come with the device. Your own crayons and markers also work. This combines the somewhat dopamine-driven experience of thinking up new things to print with the more calming or meditative aspects that come with coloring, similar to giving kids a coloring book.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This ended up offering a healthy balance between using potentially addictive tech and then slowing down to engage in a real-world activity. It also helped to address potential boredom. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3070382" height="680" src="https://techcrunch.com/wp-content/uploads/2025/11/IMG_0097.jpg?w=676" width="676" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The more you use Stickerbox, the more you realize how complex your prompts can be. You don’t just have to ask for a basic image, like a “magical unicorn,” you can speak to Stickerbox with long, train-of-thought commands, and the AI parses what you mean. (This is particularly useful given that kids don’t tend to explain things in a straightforward fashion.)&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-making-ai-for-kids"&gt;Making “AI for kids”&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Hapiko, the company behind Stickerbox, was founded this year by CEO Arun Gupta and CTO Robert (Bob) Whitney. The pair originally met while working at the e-commerce marketplace Grailed, where Whitney was director of engineering and Gupta was CEO. (The company sold to GOAT Group in 2022.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Before Grailed, Gupta founded and launched the Y Combinator-backed hardware sleep tracker WakeMate. &lt;/p&gt;

&lt;figure class="wp-block-image alignright size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3070368" height="680" src="https://techcrunch.com/wp-content/uploads/2025/11/Bob-and-Arun_2.jpg?w=617" width="617" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Stickerbox co-founders Arun Gupta (CEO) and Bob Whitney (CTO)&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Stickerbox&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Whitney, meanwhile, had worked as the director of engineering at The New York Times’ Games division, as the publisher pivoted from offering just crosswords to becoming a full-fledged gaming app, acquiring Wordle and launching other games like Connections and Strads. While that experience taught him a lot about what makes a great consumer-facing product, his later stint at Anthropic gave him a firsthand look at the advances in AI technology.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;However, it was his experience as a father that inspired Stickerbox. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When his son asked for a coloring page he didn’t have on hand, he turned to ChatGPT to make a printable image. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I made it for him — a tiger eating ice cream. And he had never seen a printer before. I got out from under the bed our HP printer — literally dusted it off and printed it for him, and he ran off happily and started coloring it,” explained Whitney. “But, a minute later, the gears were turning, and he came back to me, and he was like, ‘I want a lizard riding a skateboard.’ And I was like, okay, cool, let me make that for you.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;His son was so thrilled with the process of being able to say something and see it come to life that he realized there could be something to this. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I just saw this look on his face of magic — like pure magic,” noted Whitney. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The co-founders were also thinking about how AI technology offered so many novel experiences, but most weren’t made for kids. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Nobody’s building AI specifically for kids. So that’s what we’re looking for,” said Gupta. “What are the right guardrails? What are the right ways? What are the right products?” &lt;/p&gt;

&lt;figure class="wp-block-image alignleft size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3070376" height="680" src="https://techcrunch.com/wp-content/uploads/2025/11/Stacked-Boxes.png?w=453" width="453" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;They realized that kids have great imaginations, ideal for working with an AI image model. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“[They have] endless imagination and creativity … they’re learning new things every day. Every week, they’ve got a new obsession. We’re literally the first people in the world, I think, to put an image model inside of a box,” Gupta said.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-built-for-updates"&gt;Built for updates&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Under the hood, Stickerbox actually uses a combination of AI models, including its own proprietary tech focused on making the device kid-safe. It won’t respond to requests for harmful content, like violence or sexual imagery, and it filters out swear words. And if you try a somewhat more innocuous command, like “boobs,” it just prints a random sticker that may be vaguely related to the word. (For instance, you might get a generic cartoon girl, but not a large-chested one.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After trying and failing to get a naughty result, most kids will likely go back to just prompting the device for silly images instead. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We want to be the trusted brand for parents where you don’t have to look over your kid’s shoulder and be like, ‘what are they doing? How are they using this?,” said Gupta. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For now, the company generates some revenue from the device sales, but it keeps the cost of restocking paper low. It’s just $5.99 for three rolls, which equates to 180 stickers. (It’s currently running a promotion that offers six rolls with every purchase now.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Over time, the team plans to explore adding premium features, including a way to upload your own image to imagine yourself in fantastic scenarios or collaboration tools.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;As a Wi-Fi-connected device, Stickerbox is regularly updated with new firmware and features. In tests, for instance, we were able to print some recognizable characters, but a more recent update added new guardrails to guide kids toward more original designs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A soon-to-launch companion app also lets you view past creations and save favorites, and could ultimately serve as the home for premium features.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Stickerbox is backed by $7 million in funding from Maveron, Serena Williams’ Serena Ventures, the Allen Institute’s AI2 incubator, and various angels, including Matt Brezina, and product leaders from other consumer apps.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;My kids got their stickerbox last week and have been ripping through rolls.  It’s been fun to see them turn stickers into creative art projects pic.twitter.com/lMXWoCPiTN&lt;/p&gt;— Matt Brezina 🌳 🌊 (@brezina) November 18, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;There’s a new AI-powered toy for kids called Stickerbox, and, before you groan, I’m here to report that it’s surprisingly fun.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Stickerbox, a product born out of Brooklyn-based startup Hapiko, is a voice-activated sticker printer. The device takes whatever creative idea you have in your head and transforms it into a printed sticker that you can then color, peel, and stick anywhere.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Before trying the device itself, I have to admit I came with a preconceived negative bias — as did my fellow tester (my daughter). Our initial reactions were similar: “&lt;em&gt;An AI that prints stickers? I’d rather design and print my own&lt;/em&gt;.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After trying the review unit sent by the company, we were won over.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Stickerbox, I realized, could represent a new form of creative play — and one that doesn’t outsource the child’s imagination to an AI model as much as you’d think.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3070381" height="680" src="https://techcrunch.com/wp-content/uploads/2025/11/IMG_0092.jpg?w=510" width="510" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-testing-the-ai-sticker-printer"&gt;Testing the AI sticker printer&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The $99.99 toy itself is a small, bright red box with a black-and-white screen and a big, white “push-to-talk” button on top. It ships with three rolls of paper, which equates to 180 stickers, as well as a power cord and colored pencils.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The box’s color scheme is reminiscent of the Etch A Sketch, which makes sense, given that Stickerbox feels like a modern spin on that concept. In the Etch A Sketch’s case, you have to learn how to control different knobs to create the image in your mind. With Stickerbox, those “knobs” are replaced with something more abstract: the voice commands you use to prompt the AI model.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kids aren’t thinking about how to be better prompt engineers, of course; they’re just exploring their imagination and having fun seeing their ideas come to life. Any improvement in their prompting abilities is a side effect.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To initially set up the device, a parent will need to help. Much like adding a smart speaker to your home’s Wi-Fi, you have to first connect to the Stickerbox’s Wi-Fi, then enter the information to connect with your home network. The setup process, which only took a minute, went off without a hitch.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3070370" height="680" src="https://techcrunch.com/wp-content/uploads/2025/11/Stickerbox-with-Hand.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Stickerbox&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Using Stickerbox is simple. You push the button, describe an image out loud, then release the button to see your text appear on screen, followed by an AI-generated image as the printer spits out a physical copy. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;There’s a serendipity to an experience in which you’re thinking of an idea and then holding it in your hand in a matter of seconds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The device’s thermal image printer requires no ink, and the paper is BPS and BPA-free, making it safe to use.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The printed sticker is easy to tear off and then can be colored in with the colored pencils that come with the device. Your own crayons and markers also work. This combines the somewhat dopamine-driven experience of thinking up new things to print with the more calming or meditative aspects that come with coloring, similar to giving kids a coloring book.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This ended up offering a healthy balance between using potentially addictive tech and then slowing down to engage in a real-world activity. It also helped to address potential boredom. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3070382" height="680" src="https://techcrunch.com/wp-content/uploads/2025/11/IMG_0097.jpg?w=676" width="676" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The more you use Stickerbox, the more you realize how complex your prompts can be. You don’t just have to ask for a basic image, like a “magical unicorn,” you can speak to Stickerbox with long, train-of-thought commands, and the AI parses what you mean. (This is particularly useful given that kids don’t tend to explain things in a straightforward fashion.)&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-making-ai-for-kids"&gt;Making “AI for kids”&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Hapiko, the company behind Stickerbox, was founded this year by CEO Arun Gupta and CTO Robert (Bob) Whitney. The pair originally met while working at the e-commerce marketplace Grailed, where Whitney was director of engineering and Gupta was CEO. (The company sold to GOAT Group in 2022.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Before Grailed, Gupta founded and launched the Y Combinator-backed hardware sleep tracker WakeMate. &lt;/p&gt;

&lt;figure class="wp-block-image alignright size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3070368" height="680" src="https://techcrunch.com/wp-content/uploads/2025/11/Bob-and-Arun_2.jpg?w=617" width="617" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Stickerbox co-founders Arun Gupta (CEO) and Bob Whitney (CTO)&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Stickerbox&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Whitney, meanwhile, had worked as the director of engineering at The New York Times’ Games division, as the publisher pivoted from offering just crosswords to becoming a full-fledged gaming app, acquiring Wordle and launching other games like Connections and Strads. While that experience taught him a lot about what makes a great consumer-facing product, his later stint at Anthropic gave him a firsthand look at the advances in AI technology.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;However, it was his experience as a father that inspired Stickerbox. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When his son asked for a coloring page he didn’t have on hand, he turned to ChatGPT to make a printable image. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I made it for him — a tiger eating ice cream. And he had never seen a printer before. I got out from under the bed our HP printer — literally dusted it off and printed it for him, and he ran off happily and started coloring it,” explained Whitney. “But, a minute later, the gears were turning, and he came back to me, and he was like, ‘I want a lizard riding a skateboard.’ And I was like, okay, cool, let me make that for you.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;His son was so thrilled with the process of being able to say something and see it come to life that he realized there could be something to this. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I just saw this look on his face of magic — like pure magic,” noted Whitney. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The co-founders were also thinking about how AI technology offered so many novel experiences, but most weren’t made for kids. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Nobody’s building AI specifically for kids. So that’s what we’re looking for,” said Gupta. “What are the right guardrails? What are the right ways? What are the right products?” &lt;/p&gt;

&lt;figure class="wp-block-image alignleft size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3070376" height="680" src="https://techcrunch.com/wp-content/uploads/2025/11/Stacked-Boxes.png?w=453" width="453" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;They realized that kids have great imaginations, ideal for working with an AI image model. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“[They have] endless imagination and creativity … they’re learning new things every day. Every week, they’ve got a new obsession. We’re literally the first people in the world, I think, to put an image model inside of a box,” Gupta said.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-built-for-updates"&gt;Built for updates&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Under the hood, Stickerbox actually uses a combination of AI models, including its own proprietary tech focused on making the device kid-safe. It won’t respond to requests for harmful content, like violence or sexual imagery, and it filters out swear words. And if you try a somewhat more innocuous command, like “boobs,” it just prints a random sticker that may be vaguely related to the word. (For instance, you might get a generic cartoon girl, but not a large-chested one.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After trying and failing to get a naughty result, most kids will likely go back to just prompting the device for silly images instead. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We want to be the trusted brand for parents where you don’t have to look over your kid’s shoulder and be like, ‘what are they doing? How are they using this?,” said Gupta. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For now, the company generates some revenue from the device sales, but it keeps the cost of restocking paper low. It’s just $5.99 for three rolls, which equates to 180 stickers. (It’s currently running a promotion that offers six rolls with every purchase now.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Over time, the team plans to explore adding premium features, including a way to upload your own image to imagine yourself in fantastic scenarios or collaboration tools.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;As a Wi-Fi-connected device, Stickerbox is regularly updated with new firmware and features. In tests, for instance, we were able to print some recognizable characters, but a more recent update added new guardrails to guide kids toward more original designs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A soon-to-launch companion app also lets you view past creations and save favorites, and could ultimately serve as the home for premium features.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Stickerbox is backed by $7 million in funding from Maveron, Serena Williams’ Serena Ventures, the Allen Institute’s AI2 incubator, and various angels, including Matt Brezina, and product leaders from other consumer apps.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;My kids got their stickerbox last week and have been ripping through rolls.  It’s been fun to see them turn stickers into creative art projects pic.twitter.com/lMXWoCPiTN&lt;/p&gt;— Matt Brezina 🌳 🌊 (@brezina) November 18, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/24/hands-on-with-stickerbox-the-ai-powered-sticker-maker-for-kids/</guid><pubDate>Mon, 24 Nov 2025 20:25:20 +0000</pubDate></item><item><title>[NEW] Anthropic’s Claude Opus 4.5 is here: Cheaper AI, infinite chats, and coding skills that beat humans (AI | VentureBeat)</title><link>https://venturebeat.com/ai/anthropics-claude-opus-4-5-is-here-cheaper-ai-infinite-chats-and-coding</link><description>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://anthropic.com/"&gt;Anthropic&lt;/a&gt; released its most capable artificial intelligence model yet on Monday, slashing prices by roughly two-thirds while claiming state-of-the-art performance on software engineering tasks — a strategic move that intensifies the AI startup&amp;#x27;s competition with deep-pocketed rivals OpenAI and Google.&lt;/p&gt;&lt;p&gt;The new model, &lt;a href="https://www.anthropic.com/news/claude-opus-4-5"&gt;Claude Opus 4.5&lt;/a&gt;, scored higher on Anthropic&amp;#x27;s most challenging internal engineering assessment than any human job candidate in the company&amp;#x27;s history, according to materials reviewed by VentureBeat. The result underscores both the rapidly advancing capabilities of AI systems and growing questions about how the technology will reshape white-collar professions.&lt;/p&gt;&lt;p&gt;The Amazon-backed company is pricing Claude Opus 4.5 at &lt;a href="https://www.anthropic.com/news/claude-opus-4-5"&gt;$5 per million input tokens&lt;/a&gt; and &lt;a href="https://www.anthropic.com/news/claude-opus-4-5"&gt;$25 per million output tokens&lt;/a&gt; — a dramatic reduction from the $15 and $75 rates for its predecessor, &lt;a href="https://www.anthropic.com/news/claude-opus-4-1"&gt;Claude Opus 4.1&lt;/a&gt;, released earlier this year. The move makes frontier AI capabilities accessible to a broader swath of developers and enterprises while putting pressure on competitors to match both performance and pricing.&lt;/p&gt;&lt;p&gt;&amp;quot;We want to make sure this really works for people who want to work with these models,&amp;quot; said Alex Albert, Anthropic&amp;#x27;s head of developer relations, in an exclusive interview with VentureBeat. &amp;quot;That is really our focus: How can we enable Claude to be better at helping you do the things that you don&amp;#x27;t necessarily want to do in your job?&amp;quot;&lt;/p&gt;&lt;p&gt;The announcement comes as Anthropic races to maintain its position in an increasingly crowded field. OpenAI recently released &lt;a href="https://openai.com/index/gpt-5-1/"&gt;GPT-5.1&lt;/a&gt; and a specialized coding model called &lt;a href="https://openai.com/index/gpt-5-1-codex-max/"&gt;Codex Max&lt;/a&gt; that can work autonomously for extended periods. Google unveiled &lt;a href="https://blog.google/products/gemini/gemini-3/"&gt;Gemini 3&lt;/a&gt; just last week, &lt;a href="https://www.theinformation.com/articles/openai-ceo-braces-possible-economic-headwinds-catching-resurgent-google"&gt;prompting concerns even from OpenAI&lt;/a&gt; about the search giant&amp;#x27;s progress, according to a recent report from The Information.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Opus 4.5 demonstrates improved judgment on real-world tasks, developers say&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Anthropic&amp;#x27;s internal testing revealed what the company describes as a qualitative leap in Claude Opus 4.5&amp;#x27;s reasoning capabilities. The model achieved 80.9% accuracy on &lt;a href="https://www.swebench.com/"&gt;SWE-bench Verified&lt;/a&gt;, a benchmark measuring real-world software engineering tasks, outperforming OpenAI&amp;#x27;s GPT-5.1-Codex-Max (77.9%), Anthropic&amp;#x27;s own Sonnet 4.5 (77.2%), and Google&amp;#x27;s Gemini 3 Pro (76.2%), according to the company&amp;#x27;s data. The result marks a notable advance over OpenAI&amp;#x27;s current state-of-the-art model, which was released just five days earlier.&lt;/p&gt;&lt;p&gt;But the technical benchmarks tell only part of the story. Albert said employee testers consistently reported that the model demonstrates improved judgment and intuition across diverse tasks — a shift he described as the model developing a sense of what matters in real-world contexts.&lt;/p&gt;&lt;p&gt;&amp;quot;The model just kind of gets it,&amp;quot; Albert said. &amp;quot;It just has developed this sort of intuition and judgment on a lot of real world things that feels qualitatively like a big jump up from past models.&amp;quot;&lt;/p&gt;&lt;p&gt;He pointed to his own workflow as an example. Previously, Albert said, he would ask AI models to gather information but hesitated to trust their synthesis or prioritization. With Opus 4.5, he&amp;#x27;s delegating more complete tasks, connecting it to Slack and internal documents to produce coherent summaries that match his priorities.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Opus 4.5 outscores all human candidates on company&amp;#x27;s toughest engineering test&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The model&amp;#x27;s performance on Anthropic&amp;#x27;s internal engineering assessment marks a notable milestone. The take-home exam, designed for prospective performance engineering candidates, is meant to evaluate technical ability and judgment under time pressure within a prescribed two-hour limit.&lt;/p&gt;&lt;p&gt;Using a technique called parallel test-time compute — which aggregates multiple attempts from the model and selects the best result — &lt;a href="https://www.anthropic.com/news/claude-opus-4-5"&gt;Opus 4.5&lt;/a&gt; scored higher than any human candidate who has taken the test, according to company. Without a time limit, the model matched the performance of the best-ever human candidate when used within Claude Code, Anthropic&amp;#x27;s coding environment.&lt;/p&gt;&lt;p&gt;The company acknowledged that the test doesn&amp;#x27;t measure other crucial professional skills such as collaboration, communication, or the instincts that develop over years of experience. Still, Anthropic said the result &amp;quot;raises questions about how AI will change engineering as a profession.&amp;quot;&lt;/p&gt;&lt;p&gt;Albert emphasized the significance of the finding. &amp;quot;I think this is kind of a sign, maybe, of what&amp;#x27;s to come around how useful these models can actually be in a work context and for our jobs,&amp;quot; he said. &amp;quot;Of course, this was an engineering task, and I would say models are relatively ahead in engineering compared to other fields, but I think it&amp;#x27;s a really important signal to pay attention to.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Dramatic efficiency improvements cut token usage by up to 76% on key benchmarks&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Beyond raw performance, Anthropic is betting that efficiency improvements will differentiate &lt;a href="https://www.anthropic.com/news/claude-opus-4-5"&gt;Claude Opus 4.5&lt;/a&gt; in the market. The company says the model uses dramatically fewer tokens — the units of text that AI systems process — to achieve similar or better outcomes compared to predecessors.&lt;/p&gt;&lt;p&gt;At a medium effort level, Opus 4.5 matches the previous &lt;a href="https://www.anthropic.com/news/claude-sonnet-4-5"&gt;Sonnet 4.5&lt;/a&gt; model&amp;#x27;s best score on &lt;a href="https://www.swebench.com/"&gt;SWE-bench Verified&lt;/a&gt; while using 76% fewer output tokens, according to Anthropic. At the highest effort level, Opus 4.5 exceeds Sonnet 4.5 performance by 4.3 percentage points while still using 48% fewer tokens.&lt;/p&gt;&lt;p&gt;To give developers more control, Anthropic introduced an &amp;quot;effort parameter&amp;quot; that allows users to adjust how much computational work the model applies to each task — balancing performance against latency and cost.&lt;/p&gt;&lt;p&gt;Enterprise customers provided early validation of the efficiency claims. &amp;quot;Opus 4.5 beats Sonnet 4.5 and competition on our internal benchmarks, using fewer tokens to solve the same problems,&amp;quot; said Michele Catasta, president of Replit, a cloud-based coding platform, in a statement to VentureBeat. &amp;quot;At scale, that efficiency compounds.&amp;quot;&lt;/p&gt;&lt;p&gt;GitHub&amp;#x27;s chief product officer, Mario Rodriguez, said early testing shows Opus 4.5 &amp;quot;surpasses internal coding benchmarks while cutting token usage in half, and is especially well-suited for tasks like code migration and code refactoring.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Early customers report AI agents that learn from experience and refine their own skills&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;One of the most striking capabilities demonstrated by early customers involves what Anthropic calls &amp;quot;self-improving agents&amp;quot; — AI systems that can refine their own performance through iterative learning.&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.rakuten.com/"&gt;Rakuten&lt;/a&gt;, the Japanese e-commerce and internet company, tested Claude Opus 4.5 on automation of office tasks. &amp;quot;Our agents were able to autonomously refine their own capabilities — achieving peak performance in 4 iterations while other models couldn&amp;#x27;t match that quality after 10,&amp;quot; said Yusuke Kaji, Rakuten&amp;#x27;s general manager of AI for business.&lt;/p&gt;&lt;p&gt;Albert explained that the model isn&amp;#x27;t updating its own weights — the fundamental parameters that define an AI system&amp;#x27;s behavior — but rather iteratively improving the tools and approaches it uses to solve problems. &amp;quot;It was iteratively refining a skill for a task and seeing that it&amp;#x27;s trying to optimize the skill to get better performance so it could accomplish this task,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;The capability extends beyond coding. Albert said Anthropic has observed significant improvements in creating professional documents, spreadsheets, and presentations. &amp;quot;They&amp;#x27;re saying that this has been the biggest jump they&amp;#x27;ve seen between model generations,&amp;quot; Albert said. &amp;quot;So going even from Sonnet 4.5 to Opus 4.5, bigger jump than any two models back to back in the past.&amp;quot;&lt;/p&gt;&lt;p&gt;&lt;a href="https://fundamentalresearchlabs.com/"&gt;Fundamental Research Labs&lt;/a&gt;, a financial modeling firm, reported that &amp;quot;accuracy on our internal evals improved 20%, efficiency rose 15%, and complex tasks that once seemed out of reach became achievable,&amp;quot; according to co-founder Nico Christie.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;New features target Excel users, Chrome workflows and eliminate chat length limits&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Alongside the model release, Anthropic rolled out a suite of product updates aimed at enterprise users. &lt;a href="https://venturebeat.com/ai/anthropic-rolls-out-claude-ai-for-finance-integrates-with-excel-to-rival"&gt;Claude for Excel&lt;/a&gt; became generally available for Max, Team, and Enterprise users with new support for pivot tables, charts, and file uploads. The Chrome browser extension is now available to all Max users.&lt;/p&gt;&lt;p&gt;Perhaps most significantly, Anthropic introduced &amp;quot;&lt;a href="https://www.anthropic.com/news/claude-opus-4-5"&gt;infinite chats&lt;/a&gt;&amp;quot; — a feature that eliminates context window limitations by automatically summarizing earlier parts of conversations as they grow longer. &amp;quot;Within Claude AI, within the product itself, you effectively get this kind of infinite context window due to the compaction, plus some memory things that we&amp;#x27;re doing,&amp;quot; Albert explained.&lt;/p&gt;&lt;p&gt;For developers, Anthropic released &amp;quot;programmatic tool calling,&amp;quot; which allows Claude to write and execute code that invokes functions directly. Claude Code gained an updated &amp;quot;Plan Mode&amp;quot; and became available on desktop in research preview, enabling developers to run multiple AI agent sessions in parallel.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Market heats up as OpenAI, Google race to match performance and pricing&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Anthropic reached &lt;a href="https://www.cnbc.com/2025/05/16/anthropic-ai-credit-facility.html"&gt;$2 billion in annualized revenue &lt;/a&gt;during the first quarter of 2025, more than doubling from $1 billion in the prior period. The number of customers spending more than $100,000 annually jumped eightfold year-over-year.&lt;/p&gt;&lt;p&gt;The rapid release of &lt;a href="https://www.anthropic.com/news/claude-opus-4-5"&gt;Opus 4.5&lt;/a&gt; — just weeks after &lt;a href="https://www.anthropic.com/news/claude-haiku-4-5"&gt;Haiku 4.5&lt;/a&gt; in October and &lt;a href="https://www.anthropic.com/news/claude-sonnet-4-5"&gt;Sonnet 4.5&lt;/a&gt; in September — reflects broader industry dynamics. OpenAI released &lt;a href="https://venturebeat.com/ai/openai-dev-day-2025-chatgpt-becomes-the-new-app-store-and-hardware-is-coming"&gt;multiple GPT-5 variants&lt;/a&gt; throughout 2025, including a specialized &lt;a href="https://openai.com/index/gpt-5-1-codex-max/"&gt;Codex Max model&lt;/a&gt; in November that can work autonomously for up to 24 hours. Google shipped Gemini 3 in mid-November after months of development.&lt;/p&gt;&lt;p&gt;Albert attributed Anthropic&amp;#x27;s accelerated pace partly to using Claude to speed its own development. &amp;quot;We&amp;#x27;re seeing a lot of assistance and speed-up by Claude itself, whether it&amp;#x27;s on the actual product building side or on the model research side,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;The pricing reduction for Opus 4.5 could pressure margins while potentially expanding the addressable market. &amp;quot;I&amp;#x27;m expecting to see a lot of startups start to incorporate this into their products much more and feature it prominently,&amp;quot; Albert said.&lt;/p&gt;&lt;p&gt;Yet profitability remains elusive for leading AI labs as they invest heavily in computing infrastructure and research talent. The &lt;a href="https://www.prnewswire.com/news-releases/artificial-intelligence-market-to-grow-at-36-6-cagr-to-garner-1-811-75-billion-by-2030---grand-view-research-inc-302393076.html"&gt;AI market is projected to top $1 trillion in revenue&lt;/a&gt; within a decade, but no single provider has established dominant market position—even as models reach a threshold where they can meaningfully automate complex knowledge work.&lt;/p&gt;&lt;p&gt;Michael Truell, CEO of Cursor, an AI-powered code editor, called Opus 4.5 &amp;quot;a notable improvement over the prior Claude models inside Cursor, with improved pricing and intelligence on difficult coding tasks.&amp;quot; Scott Wu, CEO of Cognition, an AI coding startup, said the model delivers &amp;quot;stronger results on our hardest evaluations and consistent performance through 30-minute autonomous coding sessions.&amp;quot;&lt;/p&gt;&lt;p&gt;For enterprises and developers, the competition translates to rapidly improving capabilities at falling prices. But as AI performance on technical tasks approaches—and sometimes exceeds—human expert levels, the technology&amp;#x27;s impact on professional work becomes less theoretical.&lt;/p&gt;&lt;p&gt;When asked about the engineering exam results and what they signal about AI&amp;#x27;s trajectory, Albert was direct: &amp;quot;I think it&amp;#x27;s a really important signal to pay attention to.&amp;quot;&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://anthropic.com/"&gt;Anthropic&lt;/a&gt; released its most capable artificial intelligence model yet on Monday, slashing prices by roughly two-thirds while claiming state-of-the-art performance on software engineering tasks — a strategic move that intensifies the AI startup&amp;#x27;s competition with deep-pocketed rivals OpenAI and Google.&lt;/p&gt;&lt;p&gt;The new model, &lt;a href="https://www.anthropic.com/news/claude-opus-4-5"&gt;Claude Opus 4.5&lt;/a&gt;, scored higher on Anthropic&amp;#x27;s most challenging internal engineering assessment than any human job candidate in the company&amp;#x27;s history, according to materials reviewed by VentureBeat. The result underscores both the rapidly advancing capabilities of AI systems and growing questions about how the technology will reshape white-collar professions.&lt;/p&gt;&lt;p&gt;The Amazon-backed company is pricing Claude Opus 4.5 at &lt;a href="https://www.anthropic.com/news/claude-opus-4-5"&gt;$5 per million input tokens&lt;/a&gt; and &lt;a href="https://www.anthropic.com/news/claude-opus-4-5"&gt;$25 per million output tokens&lt;/a&gt; — a dramatic reduction from the $15 and $75 rates for its predecessor, &lt;a href="https://www.anthropic.com/news/claude-opus-4-1"&gt;Claude Opus 4.1&lt;/a&gt;, released earlier this year. The move makes frontier AI capabilities accessible to a broader swath of developers and enterprises while putting pressure on competitors to match both performance and pricing.&lt;/p&gt;&lt;p&gt;&amp;quot;We want to make sure this really works for people who want to work with these models,&amp;quot; said Alex Albert, Anthropic&amp;#x27;s head of developer relations, in an exclusive interview with VentureBeat. &amp;quot;That is really our focus: How can we enable Claude to be better at helping you do the things that you don&amp;#x27;t necessarily want to do in your job?&amp;quot;&lt;/p&gt;&lt;p&gt;The announcement comes as Anthropic races to maintain its position in an increasingly crowded field. OpenAI recently released &lt;a href="https://openai.com/index/gpt-5-1/"&gt;GPT-5.1&lt;/a&gt; and a specialized coding model called &lt;a href="https://openai.com/index/gpt-5-1-codex-max/"&gt;Codex Max&lt;/a&gt; that can work autonomously for extended periods. Google unveiled &lt;a href="https://blog.google/products/gemini/gemini-3/"&gt;Gemini 3&lt;/a&gt; just last week, &lt;a href="https://www.theinformation.com/articles/openai-ceo-braces-possible-economic-headwinds-catching-resurgent-google"&gt;prompting concerns even from OpenAI&lt;/a&gt; about the search giant&amp;#x27;s progress, according to a recent report from The Information.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Opus 4.5 demonstrates improved judgment on real-world tasks, developers say&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Anthropic&amp;#x27;s internal testing revealed what the company describes as a qualitative leap in Claude Opus 4.5&amp;#x27;s reasoning capabilities. The model achieved 80.9% accuracy on &lt;a href="https://www.swebench.com/"&gt;SWE-bench Verified&lt;/a&gt;, a benchmark measuring real-world software engineering tasks, outperforming OpenAI&amp;#x27;s GPT-5.1-Codex-Max (77.9%), Anthropic&amp;#x27;s own Sonnet 4.5 (77.2%), and Google&amp;#x27;s Gemini 3 Pro (76.2%), according to the company&amp;#x27;s data. The result marks a notable advance over OpenAI&amp;#x27;s current state-of-the-art model, which was released just five days earlier.&lt;/p&gt;&lt;p&gt;But the technical benchmarks tell only part of the story. Albert said employee testers consistently reported that the model demonstrates improved judgment and intuition across diverse tasks — a shift he described as the model developing a sense of what matters in real-world contexts.&lt;/p&gt;&lt;p&gt;&amp;quot;The model just kind of gets it,&amp;quot; Albert said. &amp;quot;It just has developed this sort of intuition and judgment on a lot of real world things that feels qualitatively like a big jump up from past models.&amp;quot;&lt;/p&gt;&lt;p&gt;He pointed to his own workflow as an example. Previously, Albert said, he would ask AI models to gather information but hesitated to trust their synthesis or prioritization. With Opus 4.5, he&amp;#x27;s delegating more complete tasks, connecting it to Slack and internal documents to produce coherent summaries that match his priorities.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Opus 4.5 outscores all human candidates on company&amp;#x27;s toughest engineering test&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The model&amp;#x27;s performance on Anthropic&amp;#x27;s internal engineering assessment marks a notable milestone. The take-home exam, designed for prospective performance engineering candidates, is meant to evaluate technical ability and judgment under time pressure within a prescribed two-hour limit.&lt;/p&gt;&lt;p&gt;Using a technique called parallel test-time compute — which aggregates multiple attempts from the model and selects the best result — &lt;a href="https://www.anthropic.com/news/claude-opus-4-5"&gt;Opus 4.5&lt;/a&gt; scored higher than any human candidate who has taken the test, according to company. Without a time limit, the model matched the performance of the best-ever human candidate when used within Claude Code, Anthropic&amp;#x27;s coding environment.&lt;/p&gt;&lt;p&gt;The company acknowledged that the test doesn&amp;#x27;t measure other crucial professional skills such as collaboration, communication, or the instincts that develop over years of experience. Still, Anthropic said the result &amp;quot;raises questions about how AI will change engineering as a profession.&amp;quot;&lt;/p&gt;&lt;p&gt;Albert emphasized the significance of the finding. &amp;quot;I think this is kind of a sign, maybe, of what&amp;#x27;s to come around how useful these models can actually be in a work context and for our jobs,&amp;quot; he said. &amp;quot;Of course, this was an engineering task, and I would say models are relatively ahead in engineering compared to other fields, but I think it&amp;#x27;s a really important signal to pay attention to.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Dramatic efficiency improvements cut token usage by up to 76% on key benchmarks&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Beyond raw performance, Anthropic is betting that efficiency improvements will differentiate &lt;a href="https://www.anthropic.com/news/claude-opus-4-5"&gt;Claude Opus 4.5&lt;/a&gt; in the market. The company says the model uses dramatically fewer tokens — the units of text that AI systems process — to achieve similar or better outcomes compared to predecessors.&lt;/p&gt;&lt;p&gt;At a medium effort level, Opus 4.5 matches the previous &lt;a href="https://www.anthropic.com/news/claude-sonnet-4-5"&gt;Sonnet 4.5&lt;/a&gt; model&amp;#x27;s best score on &lt;a href="https://www.swebench.com/"&gt;SWE-bench Verified&lt;/a&gt; while using 76% fewer output tokens, according to Anthropic. At the highest effort level, Opus 4.5 exceeds Sonnet 4.5 performance by 4.3 percentage points while still using 48% fewer tokens.&lt;/p&gt;&lt;p&gt;To give developers more control, Anthropic introduced an &amp;quot;effort parameter&amp;quot; that allows users to adjust how much computational work the model applies to each task — balancing performance against latency and cost.&lt;/p&gt;&lt;p&gt;Enterprise customers provided early validation of the efficiency claims. &amp;quot;Opus 4.5 beats Sonnet 4.5 and competition on our internal benchmarks, using fewer tokens to solve the same problems,&amp;quot; said Michele Catasta, president of Replit, a cloud-based coding platform, in a statement to VentureBeat. &amp;quot;At scale, that efficiency compounds.&amp;quot;&lt;/p&gt;&lt;p&gt;GitHub&amp;#x27;s chief product officer, Mario Rodriguez, said early testing shows Opus 4.5 &amp;quot;surpasses internal coding benchmarks while cutting token usage in half, and is especially well-suited for tasks like code migration and code refactoring.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Early customers report AI agents that learn from experience and refine their own skills&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;One of the most striking capabilities demonstrated by early customers involves what Anthropic calls &amp;quot;self-improving agents&amp;quot; — AI systems that can refine their own performance through iterative learning.&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.rakuten.com/"&gt;Rakuten&lt;/a&gt;, the Japanese e-commerce and internet company, tested Claude Opus 4.5 on automation of office tasks. &amp;quot;Our agents were able to autonomously refine their own capabilities — achieving peak performance in 4 iterations while other models couldn&amp;#x27;t match that quality after 10,&amp;quot; said Yusuke Kaji, Rakuten&amp;#x27;s general manager of AI for business.&lt;/p&gt;&lt;p&gt;Albert explained that the model isn&amp;#x27;t updating its own weights — the fundamental parameters that define an AI system&amp;#x27;s behavior — but rather iteratively improving the tools and approaches it uses to solve problems. &amp;quot;It was iteratively refining a skill for a task and seeing that it&amp;#x27;s trying to optimize the skill to get better performance so it could accomplish this task,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;The capability extends beyond coding. Albert said Anthropic has observed significant improvements in creating professional documents, spreadsheets, and presentations. &amp;quot;They&amp;#x27;re saying that this has been the biggest jump they&amp;#x27;ve seen between model generations,&amp;quot; Albert said. &amp;quot;So going even from Sonnet 4.5 to Opus 4.5, bigger jump than any two models back to back in the past.&amp;quot;&lt;/p&gt;&lt;p&gt;&lt;a href="https://fundamentalresearchlabs.com/"&gt;Fundamental Research Labs&lt;/a&gt;, a financial modeling firm, reported that &amp;quot;accuracy on our internal evals improved 20%, efficiency rose 15%, and complex tasks that once seemed out of reach became achievable,&amp;quot; according to co-founder Nico Christie.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;New features target Excel users, Chrome workflows and eliminate chat length limits&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Alongside the model release, Anthropic rolled out a suite of product updates aimed at enterprise users. &lt;a href="https://venturebeat.com/ai/anthropic-rolls-out-claude-ai-for-finance-integrates-with-excel-to-rival"&gt;Claude for Excel&lt;/a&gt; became generally available for Max, Team, and Enterprise users with new support for pivot tables, charts, and file uploads. The Chrome browser extension is now available to all Max users.&lt;/p&gt;&lt;p&gt;Perhaps most significantly, Anthropic introduced &amp;quot;&lt;a href="https://www.anthropic.com/news/claude-opus-4-5"&gt;infinite chats&lt;/a&gt;&amp;quot; — a feature that eliminates context window limitations by automatically summarizing earlier parts of conversations as they grow longer. &amp;quot;Within Claude AI, within the product itself, you effectively get this kind of infinite context window due to the compaction, plus some memory things that we&amp;#x27;re doing,&amp;quot; Albert explained.&lt;/p&gt;&lt;p&gt;For developers, Anthropic released &amp;quot;programmatic tool calling,&amp;quot; which allows Claude to write and execute code that invokes functions directly. Claude Code gained an updated &amp;quot;Plan Mode&amp;quot; and became available on desktop in research preview, enabling developers to run multiple AI agent sessions in parallel.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Market heats up as OpenAI, Google race to match performance and pricing&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Anthropic reached &lt;a href="https://www.cnbc.com/2025/05/16/anthropic-ai-credit-facility.html"&gt;$2 billion in annualized revenue &lt;/a&gt;during the first quarter of 2025, more than doubling from $1 billion in the prior period. The number of customers spending more than $100,000 annually jumped eightfold year-over-year.&lt;/p&gt;&lt;p&gt;The rapid release of &lt;a href="https://www.anthropic.com/news/claude-opus-4-5"&gt;Opus 4.5&lt;/a&gt; — just weeks after &lt;a href="https://www.anthropic.com/news/claude-haiku-4-5"&gt;Haiku 4.5&lt;/a&gt; in October and &lt;a href="https://www.anthropic.com/news/claude-sonnet-4-5"&gt;Sonnet 4.5&lt;/a&gt; in September — reflects broader industry dynamics. OpenAI released &lt;a href="https://venturebeat.com/ai/openai-dev-day-2025-chatgpt-becomes-the-new-app-store-and-hardware-is-coming"&gt;multiple GPT-5 variants&lt;/a&gt; throughout 2025, including a specialized &lt;a href="https://openai.com/index/gpt-5-1-codex-max/"&gt;Codex Max model&lt;/a&gt; in November that can work autonomously for up to 24 hours. Google shipped Gemini 3 in mid-November after months of development.&lt;/p&gt;&lt;p&gt;Albert attributed Anthropic&amp;#x27;s accelerated pace partly to using Claude to speed its own development. &amp;quot;We&amp;#x27;re seeing a lot of assistance and speed-up by Claude itself, whether it&amp;#x27;s on the actual product building side or on the model research side,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;The pricing reduction for Opus 4.5 could pressure margins while potentially expanding the addressable market. &amp;quot;I&amp;#x27;m expecting to see a lot of startups start to incorporate this into their products much more and feature it prominently,&amp;quot; Albert said.&lt;/p&gt;&lt;p&gt;Yet profitability remains elusive for leading AI labs as they invest heavily in computing infrastructure and research talent. The &lt;a href="https://www.prnewswire.com/news-releases/artificial-intelligence-market-to-grow-at-36-6-cagr-to-garner-1-811-75-billion-by-2030---grand-view-research-inc-302393076.html"&gt;AI market is projected to top $1 trillion in revenue&lt;/a&gt; within a decade, but no single provider has established dominant market position—even as models reach a threshold where they can meaningfully automate complex knowledge work.&lt;/p&gt;&lt;p&gt;Michael Truell, CEO of Cursor, an AI-powered code editor, called Opus 4.5 &amp;quot;a notable improvement over the prior Claude models inside Cursor, with improved pricing and intelligence on difficult coding tasks.&amp;quot; Scott Wu, CEO of Cognition, an AI coding startup, said the model delivers &amp;quot;stronger results on our hardest evaluations and consistent performance through 30-minute autonomous coding sessions.&amp;quot;&lt;/p&gt;&lt;p&gt;For enterprises and developers, the competition translates to rapidly improving capabilities at falling prices. But as AI performance on technical tasks approaches—and sometimes exceeds—human expert levels, the technology&amp;#x27;s impact on professional work becomes less theoretical.&lt;/p&gt;&lt;p&gt;When asked about the engineering exam results and what they signal about AI&amp;#x27;s trajectory, Albert was direct: &amp;quot;I think it&amp;#x27;s a really important signal to pay attention to.&amp;quot;&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/anthropics-claude-opus-4-5-is-here-cheaper-ai-infinite-chats-and-coding</guid><pubDate>Mon, 24 Nov 2025 21:35:00 +0000</pubDate></item><item><title>[NEW] How artificial intelligence can help achieve a clean energy future (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/how-ai-can-help-achieve-clean-energy-future-1124</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202511/power-lines.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;There is growing attention on the links between artificial intelligence and increased energy demands. But while the power-hungry data centers being built to support AI could potentially stress electricity grids, increase customer prices and service interruptions, and generally slow the transition to clean energy, the use of artificial intelligence can also help the energy transition.&lt;/p&gt;&lt;p&gt;For example, use of AI is reducing energy consumption and associated emissions in buildings, transportation, and industrial processes. In addition, AI is helping to optimize the design and siting of new wind and solar installations and energy storage facilities.&lt;/p&gt;&lt;p&gt;On electric power grids, using AI algorithms to control operations is helping to increase efficiency and reduce costs, integrate the growing share of renewables, and even predict when key equipment needs servicing to prevent failure and possible blackouts. AI can help grid planners schedule investments in generation, energy storage, and other infrastructure that will be needed in the future. AI is also helping researchers discover or design novel materials for nuclear reactors, batteries, and electrolyzers.&lt;/p&gt;&lt;p&gt;Researchers at MIT and elsewhere are actively investigating aspects of those and other opportunities for AI to support the clean energy transition. At its 2025 research conference, MITEI announced the Data Center Power Forum,&amp;nbsp;a targeted research effort&amp;nbsp;for MITEI member companies interested in addressing the challenges of data center power demand.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Controlling real-time operations&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Customers generally rely on receiving a continuous supply of electricity, and grid operators get help from AI to make that happen — while optimizing the storage and distribution of energy from renewable sources at the same time.&lt;/p&gt;&lt;p&gt;But with more installation of solar and wind farms — both of which provide power in smaller amounts, and intermittently — and the growing threat of weather events and cyberattacks, ensuring reliability is getting more complicated. “That’s exactly where AI can come into the picture,” explains Anuradha Annaswamy, a senior research scientist in MIT’s Department of Mechanical Engineering and director of MIT’s Active-Adaptive Control Laboratory. “Essentially, you need to introduce a whole information infrastructure to supplement and complement the physical infrastructure.”&lt;/p&gt;&lt;p&gt;The electricity grid is a complex system that requires meticulous control on time scales ranging from decades all the way down to microseconds. The challenge can be traced to the basic laws of power physics: electricity supply must equal electricity demand at every instant, or generation can be interrupted. In past decades, grid operators generally assumed that generation was fixed — they could count on how much electricity each large power plant would produce — while demand varied over time in a fairly predictable way. As a result, operators could commission specific power plants to run as needed to meet demand the next day. If some outages occurred, specially designated units would start up as needed to make up the shortfall.&lt;/p&gt;&lt;p&gt;Today and in the future, that matching of supply and demand must still happen, even as the number of small, intermittent sources of generation grows and weather disturbances and other threats to the grid increase. AI algorithms provide a means of achieving the complex management of information needed to forecast within just a few hours which plants should run while also ensuring that the frequency, voltage, and other characteristics of the incoming power are as required for the grid to operate properly.&lt;/p&gt;&lt;p&gt;Moreover, AI can make possible new ways of increasing supply or decreasing demand at times when supplies on the grid run short. As Annaswamy points out, the battery in your electric vehicle (EV), as well as the one charged up by solar panels or wind turbines, can — when needed — serve as a source of extra power to be fed into the grid. And given real-time price signals, EV owners can choose to shift charging from a time when demand is peaking and prices are high to a time when demand and therefore prices are both lower. In addition, new smart thermostats can be set to allow the indoor temperature to drop or rise —&amp;nbsp; a range defined by the customer — when demand on the grid is peaking. And data centers themselves can be a source of demand flexibility: selected AI calculations could be delayed as needed to smooth out peaks in demand. Thus, AI can provide many opportunities to fine-tune both supply and demand as needed.&lt;/p&gt;&lt;p&gt;In addition, AI makes possible “predictive maintenance.” Any downtime is costly for the company and threatens shortages for the customers served. AI algorithms can collect key performance data during normal operation and, when readings veer off from that normal, the system can alert operators that something might be going wrong, giving them a chance to intervene. That capability prevents equipment failures, reduces the need for routine inspections, increases worker productivity, and extends the lifetime of key equipment.&lt;/p&gt;&lt;p&gt;Annaswamy stresses that&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;“figuring out how to architect this new power grid with these AI components will require many different experts to come together.” She notes that electrical engineers, computer scientists, and energy economists “will have to rub shoulders with enlightened regulators and policymakers to make sure that this is not just an academic exercise, but will actually get implemented. All the different stakeholders have to learn from each other. And you need guarantees that nothing is going to fail. You can’t have blackouts.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Using AI to help plan investments in infrastructure for the future&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Grid companies constantly need to plan for expanding generation, transmission, storage, and more, and getting all the necessary infrastructure built and operating may take many years, in some cases more than a decade. So, they need to predict what infrastructure they’ll need to ensure reliability in the future. “It’s complicated because you have to forecast over a decade ahead of time what to build and where to build it,” says Deepjyoti Deka, a research scientist in MITEI.&lt;/p&gt;&lt;p&gt;One challenge with anticipating what will be needed is predicting how the future system will operate. “That’s becoming increasingly difficult,” says Deka, because more renewables are coming online and displacing traditional generators. In the past, operators could rely on “spinning reserves,” that is, generating capacity that’s not currently in use but could come online in a matter of minutes to meet any shortfall on the system. The presence of so many intermittent generators — wind and solar — means there’s now less stability and inertia built into the grid. Adding to the complication is that those intermittent generators can be built by various vendors, and grid planners may not have access to the physics-based equations that govern the operation of each piece of equipment at sufficiently fine time scales. “So, you probably don’t know exactly how it’s going to run,” says Deka.&lt;/p&gt;&lt;p&gt;And then there’s the weather. Determining the reliability of a proposed future energy system requires knowing what it’ll be up against in terms of weather&lt;strong&gt;.&lt;/strong&gt; The future grid has to be reliable not only in everyday weather, but also during low-probability but high-risk events such as hurricanes, floods, and wildfires, all of which are becoming more and more frequent, notes Deka. AI can help by predicting such events and even tracking changes in weather patterns due to climate change.&lt;/p&gt;&lt;p&gt;Deka points out another, less-obvious benefit of the speed of AI analysis. Any infrastructure development plan must be reviewed and approved, often by several regulatory and other bodies. Traditionally, an applicant would develop a plan, analyze its impacts, and submit the plan to one set of reviewers. After making any requested changes and repeating the analysis, the applicant would resubmit a revised version to the reviewers to see if the new version was acceptable. AI tools can speed up the required analysis so the process moves along more quickly. Planners can even reduce the number of times a proposal is rejected by using large language models to search regulatory publications and summarize what’s important for a proposed infrastructure installation.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Harnessing AI to discover and exploit advanced materials needed for the energy transition&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;“Use of AI for materials development is booming right now,” says Ju Li, MIT’s Carl Richard Soderberg Professor of Power Engineering. He notes two main directions.&lt;/p&gt;&lt;p&gt;First, AI makes possible faster physics-based simulations at the atomic scale. The result is a better atomic-level understanding of how composition, processing, structure, and chemical reactivity relate to the performance of materials. That understanding provides design rules to help guide the development and discovery of novel materials for energy generation, storage, and conversion needed for a sustainable future energy system.&lt;/p&gt;&lt;p&gt;And second, AI can help guide experiments in real time as they take place in the lab. Li explains: “AI assists us in choosing the best experiment to do based on our previous experiments and — based on literature searches — makes hypotheses and suggests new experiments.”&lt;/p&gt;&lt;p&gt;He describes what happens in his own lab. Human scientists interact with a large language model, which then makes suggestions about what specific experiments to do next. The human researcher accepts or modifies the suggestion, and a robotic arm responds by setting up and performing the next step in the experimental sequence, synthesizing the material, testing the performance, and taking images of samples when appropriate. Based on a mix of literature knowledge, human intuition, and previous experimental results, AI thus coordinates active learning that balances the goals of reducing uncertainty with improving performance. And, as Li points out, “AI has read many more books and papers than any human can, and is thus naturally more interdisciplinary.”&lt;/p&gt;&lt;p&gt;The outcome, says Li, is both better design of experiments and speeding up the “work flow.” Traditionally, the process of developing new materials has required synthesizing the precursors, making the material, testing its performance and characterizing the structure, making adjustments, and repeating the same series of steps. AI guidance speeds up that process, “helping us to design critical, cheap experiments that can give us the maximum amount of information feedback,” says Li.&lt;/p&gt;&lt;p&gt;“Having this capability certainly will accelerate material discovery, and this may be the thing that can really help us in the clean energy transition,” he concludes.&amp;nbsp;“AI [has the potential to] lubricate the material-discovery and optimization process, perhaps shortening it from decades, as in the past, to just a few years.”&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;MITEI’s contributions&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;At MIT, researchers are working on various aspects of the opportunities described above. In projects supported by MITEI, teams are using AI to better model and predict disruptions in plasma flows inside fusion reactors — a necessity in achieving practical fusion power generation. Other MITEI-supported teams are using AI-powered tools to interpret regulations, climate data, and infrastructure maps in order to achieve faster, more adaptive electric grid planning. AI-guided development of advanced materials continues, with one MITEI project using AI to optimize solar cells and thermoelectric materials.&lt;/p&gt;&lt;p&gt;Other MITEI researchers are developing robots that can learn maintenance tasks based on human feedback, including physical intervention and verbal instructions. The goal is to reduce costs, improve safety, and accelerate the deployment of the renewable energy infrastructure. And MITEI-funded work continues on ways to reduce the energy demand of data centers, from designing more efficient computer chips and computing algorithms to rethinking the architectural design of the buildings, for example, to increase airflow so as to reduce the need for air conditioning.&lt;/p&gt;&lt;p&gt;In addition to providing leadership and funding for many research projects, MITEI acts as a convenor, bringing together interested parties to consider common problems and potential solutions. In May 2025, MITEI’s annual spring symposium — titled “AI and energy: Peril and promise” — brought together AI and energy experts from across academia, industry, government, and nonprofit organizations to explore AI as both a problem and a potential solution for the clean energy transition. At the close of the symposium, William H. Green, director of MITEI and Hoyt C. Hottel Professor in the MIT Department of Chemical Engineering, noted, “The challenge of meeting data center energy demand and of unlocking the potential benefits of AI to the energy transition is now a research priority for MITEI.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202511/power-lines.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;There is growing attention on the links between artificial intelligence and increased energy demands. But while the power-hungry data centers being built to support AI could potentially stress electricity grids, increase customer prices and service interruptions, and generally slow the transition to clean energy, the use of artificial intelligence can also help the energy transition.&lt;/p&gt;&lt;p&gt;For example, use of AI is reducing energy consumption and associated emissions in buildings, transportation, and industrial processes. In addition, AI is helping to optimize the design and siting of new wind and solar installations and energy storage facilities.&lt;/p&gt;&lt;p&gt;On electric power grids, using AI algorithms to control operations is helping to increase efficiency and reduce costs, integrate the growing share of renewables, and even predict when key equipment needs servicing to prevent failure and possible blackouts. AI can help grid planners schedule investments in generation, energy storage, and other infrastructure that will be needed in the future. AI is also helping researchers discover or design novel materials for nuclear reactors, batteries, and electrolyzers.&lt;/p&gt;&lt;p&gt;Researchers at MIT and elsewhere are actively investigating aspects of those and other opportunities for AI to support the clean energy transition. At its 2025 research conference, MITEI announced the Data Center Power Forum,&amp;nbsp;a targeted research effort&amp;nbsp;for MITEI member companies interested in addressing the challenges of data center power demand.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Controlling real-time operations&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Customers generally rely on receiving a continuous supply of electricity, and grid operators get help from AI to make that happen — while optimizing the storage and distribution of energy from renewable sources at the same time.&lt;/p&gt;&lt;p&gt;But with more installation of solar and wind farms — both of which provide power in smaller amounts, and intermittently — and the growing threat of weather events and cyberattacks, ensuring reliability is getting more complicated. “That’s exactly where AI can come into the picture,” explains Anuradha Annaswamy, a senior research scientist in MIT’s Department of Mechanical Engineering and director of MIT’s Active-Adaptive Control Laboratory. “Essentially, you need to introduce a whole information infrastructure to supplement and complement the physical infrastructure.”&lt;/p&gt;&lt;p&gt;The electricity grid is a complex system that requires meticulous control on time scales ranging from decades all the way down to microseconds. The challenge can be traced to the basic laws of power physics: electricity supply must equal electricity demand at every instant, or generation can be interrupted. In past decades, grid operators generally assumed that generation was fixed — they could count on how much electricity each large power plant would produce — while demand varied over time in a fairly predictable way. As a result, operators could commission specific power plants to run as needed to meet demand the next day. If some outages occurred, specially designated units would start up as needed to make up the shortfall.&lt;/p&gt;&lt;p&gt;Today and in the future, that matching of supply and demand must still happen, even as the number of small, intermittent sources of generation grows and weather disturbances and other threats to the grid increase. AI algorithms provide a means of achieving the complex management of information needed to forecast within just a few hours which plants should run while also ensuring that the frequency, voltage, and other characteristics of the incoming power are as required for the grid to operate properly.&lt;/p&gt;&lt;p&gt;Moreover, AI can make possible new ways of increasing supply or decreasing demand at times when supplies on the grid run short. As Annaswamy points out, the battery in your electric vehicle (EV), as well as the one charged up by solar panels or wind turbines, can — when needed — serve as a source of extra power to be fed into the grid. And given real-time price signals, EV owners can choose to shift charging from a time when demand is peaking and prices are high to a time when demand and therefore prices are both lower. In addition, new smart thermostats can be set to allow the indoor temperature to drop or rise —&amp;nbsp; a range defined by the customer — when demand on the grid is peaking. And data centers themselves can be a source of demand flexibility: selected AI calculations could be delayed as needed to smooth out peaks in demand. Thus, AI can provide many opportunities to fine-tune both supply and demand as needed.&lt;/p&gt;&lt;p&gt;In addition, AI makes possible “predictive maintenance.” Any downtime is costly for the company and threatens shortages for the customers served. AI algorithms can collect key performance data during normal operation and, when readings veer off from that normal, the system can alert operators that something might be going wrong, giving them a chance to intervene. That capability prevents equipment failures, reduces the need for routine inspections, increases worker productivity, and extends the lifetime of key equipment.&lt;/p&gt;&lt;p&gt;Annaswamy stresses that&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;“figuring out how to architect this new power grid with these AI components will require many different experts to come together.” She notes that electrical engineers, computer scientists, and energy economists “will have to rub shoulders with enlightened regulators and policymakers to make sure that this is not just an academic exercise, but will actually get implemented. All the different stakeholders have to learn from each other. And you need guarantees that nothing is going to fail. You can’t have blackouts.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Using AI to help plan investments in infrastructure for the future&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Grid companies constantly need to plan for expanding generation, transmission, storage, and more, and getting all the necessary infrastructure built and operating may take many years, in some cases more than a decade. So, they need to predict what infrastructure they’ll need to ensure reliability in the future. “It’s complicated because you have to forecast over a decade ahead of time what to build and where to build it,” says Deepjyoti Deka, a research scientist in MITEI.&lt;/p&gt;&lt;p&gt;One challenge with anticipating what will be needed is predicting how the future system will operate. “That’s becoming increasingly difficult,” says Deka, because more renewables are coming online and displacing traditional generators. In the past, operators could rely on “spinning reserves,” that is, generating capacity that’s not currently in use but could come online in a matter of minutes to meet any shortfall on the system. The presence of so many intermittent generators — wind and solar — means there’s now less stability and inertia built into the grid. Adding to the complication is that those intermittent generators can be built by various vendors, and grid planners may not have access to the physics-based equations that govern the operation of each piece of equipment at sufficiently fine time scales. “So, you probably don’t know exactly how it’s going to run,” says Deka.&lt;/p&gt;&lt;p&gt;And then there’s the weather. Determining the reliability of a proposed future energy system requires knowing what it’ll be up against in terms of weather&lt;strong&gt;.&lt;/strong&gt; The future grid has to be reliable not only in everyday weather, but also during low-probability but high-risk events such as hurricanes, floods, and wildfires, all of which are becoming more and more frequent, notes Deka. AI can help by predicting such events and even tracking changes in weather patterns due to climate change.&lt;/p&gt;&lt;p&gt;Deka points out another, less-obvious benefit of the speed of AI analysis. Any infrastructure development plan must be reviewed and approved, often by several regulatory and other bodies. Traditionally, an applicant would develop a plan, analyze its impacts, and submit the plan to one set of reviewers. After making any requested changes and repeating the analysis, the applicant would resubmit a revised version to the reviewers to see if the new version was acceptable. AI tools can speed up the required analysis so the process moves along more quickly. Planners can even reduce the number of times a proposal is rejected by using large language models to search regulatory publications and summarize what’s important for a proposed infrastructure installation.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Harnessing AI to discover and exploit advanced materials needed for the energy transition&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;“Use of AI for materials development is booming right now,” says Ju Li, MIT’s Carl Richard Soderberg Professor of Power Engineering. He notes two main directions.&lt;/p&gt;&lt;p&gt;First, AI makes possible faster physics-based simulations at the atomic scale. The result is a better atomic-level understanding of how composition, processing, structure, and chemical reactivity relate to the performance of materials. That understanding provides design rules to help guide the development and discovery of novel materials for energy generation, storage, and conversion needed for a sustainable future energy system.&lt;/p&gt;&lt;p&gt;And second, AI can help guide experiments in real time as they take place in the lab. Li explains: “AI assists us in choosing the best experiment to do based on our previous experiments and — based on literature searches — makes hypotheses and suggests new experiments.”&lt;/p&gt;&lt;p&gt;He describes what happens in his own lab. Human scientists interact with a large language model, which then makes suggestions about what specific experiments to do next. The human researcher accepts or modifies the suggestion, and a robotic arm responds by setting up and performing the next step in the experimental sequence, synthesizing the material, testing the performance, and taking images of samples when appropriate. Based on a mix of literature knowledge, human intuition, and previous experimental results, AI thus coordinates active learning that balances the goals of reducing uncertainty with improving performance. And, as Li points out, “AI has read many more books and papers than any human can, and is thus naturally more interdisciplinary.”&lt;/p&gt;&lt;p&gt;The outcome, says Li, is both better design of experiments and speeding up the “work flow.” Traditionally, the process of developing new materials has required synthesizing the precursors, making the material, testing its performance and characterizing the structure, making adjustments, and repeating the same series of steps. AI guidance speeds up that process, “helping us to design critical, cheap experiments that can give us the maximum amount of information feedback,” says Li.&lt;/p&gt;&lt;p&gt;“Having this capability certainly will accelerate material discovery, and this may be the thing that can really help us in the clean energy transition,” he concludes.&amp;nbsp;“AI [has the potential to] lubricate the material-discovery and optimization process, perhaps shortening it from decades, as in the past, to just a few years.”&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;MITEI’s contributions&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;At MIT, researchers are working on various aspects of the opportunities described above. In projects supported by MITEI, teams are using AI to better model and predict disruptions in plasma flows inside fusion reactors — a necessity in achieving practical fusion power generation. Other MITEI-supported teams are using AI-powered tools to interpret regulations, climate data, and infrastructure maps in order to achieve faster, more adaptive electric grid planning. AI-guided development of advanced materials continues, with one MITEI project using AI to optimize solar cells and thermoelectric materials.&lt;/p&gt;&lt;p&gt;Other MITEI researchers are developing robots that can learn maintenance tasks based on human feedback, including physical intervention and verbal instructions. The goal is to reduce costs, improve safety, and accelerate the deployment of the renewable energy infrastructure. And MITEI-funded work continues on ways to reduce the energy demand of data centers, from designing more efficient computer chips and computing algorithms to rethinking the architectural design of the buildings, for example, to increase airflow so as to reduce the need for air conditioning.&lt;/p&gt;&lt;p&gt;In addition to providing leadership and funding for many research projects, MITEI acts as a convenor, bringing together interested parties to consider common problems and potential solutions. In May 2025, MITEI’s annual spring symposium — titled “AI and energy: Peril and promise” — brought together AI and energy experts from across academia, industry, government, and nonprofit organizations to explore AI as both a problem and a potential solution for the clean energy transition. At the close of the symposium, William H. Green, director of MITEI and Hoyt C. Hottel Professor in the MIT Department of Chemical Engineering, noted, “The challenge of meeting data center energy demand and of unlocking the potential benefits of AI to the energy transition is now a research priority for MITEI.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/how-ai-can-help-achieve-clean-energy-future-1124</guid><pubDate>Mon, 24 Nov 2025 22:00:00 +0000</pubDate></item><item><title>[NEW] OpenAI learned the hard way that Cameo trademarked the word ‘cameo’ (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/24/openai-learned-the-hard-way-that-cameo-trademarked-the-word-cameo/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/sora-app-GettyImages2238161095.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI’s social app Sora launched with a controversial feature called Cameo, allowing users to deepfake themselves or others (with permission). The feature had a tenuous rollout — Martin Luther King Jr.’s estate had to get involved, to give you an idea of what went on — but now it faces a new challenge. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apparently, Cameo — the app where you buy custom video messages from celebrities — can claim the trademark of the word “cameo.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;U.S. District Judge Eumi K. Lee imposed a temporary restraining order that blocks OpenAI from using the word “cameo,” as well as any similar-sounding words or phrases, on Sora.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The temporary restraining order issued on November 21, 2025 is set to expire on December 22, 2025, at 5:00 p.m. A hearing on the matter is scheduled for December 19, 2025, at 11:00 a.m.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As of Monday afternoon, the Sora app still uses the “cameo” language, however. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt; “We are gratified by the court’s decision, which recognizes the need to protect consumers from the confusion that OpenAI has created by using the Cameo trademark,” Cameo CEO Steven Galanis said in a statement. “While the court’s order is temporary, we hope that OpenAI will agree to stop using our mark permanently to avoid any further harm to the public or Cameo.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI disagrees with the assertion that the company can claim exclusive ownership over the word “cameo,” the company told CNBC.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/sora-app-GettyImages2238161095.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI’s social app Sora launched with a controversial feature called Cameo, allowing users to deepfake themselves or others (with permission). The feature had a tenuous rollout — Martin Luther King Jr.’s estate had to get involved, to give you an idea of what went on — but now it faces a new challenge. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apparently, Cameo — the app where you buy custom video messages from celebrities — can claim the trademark of the word “cameo.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;U.S. District Judge Eumi K. Lee imposed a temporary restraining order that blocks OpenAI from using the word “cameo,” as well as any similar-sounding words or phrases, on Sora.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The temporary restraining order issued on November 21, 2025 is set to expire on December 22, 2025, at 5:00 p.m. A hearing on the matter is scheduled for December 19, 2025, at 11:00 a.m.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As of Monday afternoon, the Sora app still uses the “cameo” language, however. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt; “We are gratified by the court’s decision, which recognizes the need to protect consumers from the confusion that OpenAI has created by using the Cameo trademark,” Cameo CEO Steven Galanis said in a statement. “While the court’s order is temporary, we hope that OpenAI will agree to stop using our mark permanently to avoid any further harm to the public or Cameo.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI disagrees with the assertion that the company can claim exclusive ownership over the word “cameo,” the company told CNBC.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/24/openai-learned-the-hard-way-that-cameo-trademarked-the-word-cameo/</guid><pubDate>Mon, 24 Nov 2025 22:27:10 +0000</pubDate></item><item><title>[NEW] Altman describes OpenAI’s forthcoming AI device as more peaceful and calm than the iPhone (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/24/altman-describes-openais-forthcoming-ai-device-as-more-peaceful-and-calm-than-the-iphone/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/portrait.jpg?w=1000" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;“When people see it, they say, ‘that’s it?… It’s so simple.’”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s how OpenAI CEO Sam Altman describes how he thinks people will respond to seeing the company’s forthcoming AI hardware device for the first time. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The device is the result of the collaboration between OpenAI and Apple’s former chief designer Jony Ive. Not much is known yet about the product except that it’s rumored to be “screenless” and pocket-sized.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Earlier this year, OpenAI acquired Ive’s design startup, io, to bring AI to the masses through some sort of tech gadgetry. This weekend, Altman and Ive talked more about their vision for their AI device in an interview led by Laurene Powell Jobs at Emerson Collective’s 9th annual Demo Day in San Francisco.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Although OpenAI isn’t sharing specifics about the device, which is now a prototype, Ive and Altman were keen to describe the product in terms of its “vibe.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Most notably, Altman compared the device to the iPhone, dubbing the Apple smartphone the “crowning achievement of consumer products” thus far. He said he could define his life as those times before the iPhone and after. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, Altman complained that modern technologies are filled with distractions. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“When I use current devices or most applications, I feel like I am walking through Times Square in New York and constantly just dealing with all the little indignities along the way — flashing lights in my face…people bumping into me, like noise is going off, and it’s an unsettling thing,” he said. The bright, flashing notifications and the dopamine-chasing social apps are where today’s devices are going wrong, Altman believes.  &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I don’t think it’s making any of our lives peaceful and calm and just letting us focus on our stuff,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The vibe of the AI device, meanwhile, would be more like “sitting in the most beautiful cabin by a lake and in the mountains and sort of just enjoying the peace and calm,” Altman noted. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The device he described should be able to filter things out for the user, as the user would trust the AI to do things for them over long periods of time. It should also be contextually aware of when it’s the best time to present information to the user and ask for input. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You trust it over time, and it does have just this incredible contextual awareness of your whole life,” Altman added. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ive confirmed at the event that the device should be available in under two years. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I love solutions that teeter on appearing almost naive in their simplicity,” Ive told Powell Jobs in the interview. “And I also love incredibly intelligent, sophisticated products that you want to touch, and you feel no intimidation, and you want to use almost carelessly — that you use them almost without thought — that they’re just tools,” he said. &lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/portrait.jpg?w=1000" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;“When people see it, they say, ‘that’s it?… It’s so simple.’”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s how OpenAI CEO Sam Altman describes how he thinks people will respond to seeing the company’s forthcoming AI hardware device for the first time. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The device is the result of the collaboration between OpenAI and Apple’s former chief designer Jony Ive. Not much is known yet about the product except that it’s rumored to be “screenless” and pocket-sized.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Earlier this year, OpenAI acquired Ive’s design startup, io, to bring AI to the masses through some sort of tech gadgetry. This weekend, Altman and Ive talked more about their vision for their AI device in an interview led by Laurene Powell Jobs at Emerson Collective’s 9th annual Demo Day in San Francisco.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Although OpenAI isn’t sharing specifics about the device, which is now a prototype, Ive and Altman were keen to describe the product in terms of its “vibe.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Most notably, Altman compared the device to the iPhone, dubbing the Apple smartphone the “crowning achievement of consumer products” thus far. He said he could define his life as those times before the iPhone and after. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, Altman complained that modern technologies are filled with distractions. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“When I use current devices or most applications, I feel like I am walking through Times Square in New York and constantly just dealing with all the little indignities along the way — flashing lights in my face…people bumping into me, like noise is going off, and it’s an unsettling thing,” he said. The bright, flashing notifications and the dopamine-chasing social apps are where today’s devices are going wrong, Altman believes.  &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I don’t think it’s making any of our lives peaceful and calm and just letting us focus on our stuff,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The vibe of the AI device, meanwhile, would be more like “sitting in the most beautiful cabin by a lake and in the mountains and sort of just enjoying the peace and calm,” Altman noted. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The device he described should be able to filter things out for the user, as the user would trust the AI to do things for them over long periods of time. It should also be contextually aware of when it’s the best time to present information to the user and ask for input. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You trust it over time, and it does have just this incredible contextual awareness of your whole life,” Altman added. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ive confirmed at the event that the device should be available in under two years. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I love solutions that teeter on appearing almost naive in their simplicity,” Ive told Powell Jobs in the interview. “And I also love incredibly intelligent, sophisticated products that you want to touch, and you feel no intimidation, and you want to use almost carelessly — that you use them almost without thought — that they’re just tools,” he said. &lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/24/altman-describes-openais-forthcoming-ai-device-as-more-peaceful-and-calm-than-the-iphone/</guid><pubDate>Mon, 24 Nov 2025 22:59:46 +0000</pubDate></item><item><title>[NEW] Anthropic introduces cheaper, more powerful, more efficient Opus 4.5 model (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/11/anthropic-introduces-opus-4-5-cuts-api-pricing-and-enables-much-longer-claude-chats/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Longer chats address a long-standing criticism of Claude.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="An abstract image of a human figure holding a solar system, or something, who knows" class="absolute inset-0 w-full h-full object-cover hidden" height="356" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Screenshot-2025-11-24-at-4.57.28-PM-640x356.png" width="640" /&gt;
                  &lt;img alt="An abstract image of a human figure holding a solar system, or something, who knows" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Screenshot-2025-11-24-at-4.57.28-PM-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      If you can decipher the meaning of this strange promotional image for Opus 4.5, you've got me beat.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Anthropic

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Anthropic today released Opus 4.5, its flagship frontier model, and it brings improvements in coding performance, as well as some user experience improvements that make it more generally competitive with OpenAI’s latest frontier models.&lt;/p&gt;
&lt;p&gt;Perhaps the most prominent change for most users is that in the consumer app experiences (web, mobile, and desktop), Claude will be less prone to abruptly hard-stopping conversations because they have run too long. The improvement to memory within a single conversation applies not just to Opus 4.5, but to any current Claude models in the apps.&lt;/p&gt;
&lt;p&gt;Users who experienced abrupt endings (despite having room left in their session and weekly usage budgets) were hitting a hard context window (200,000 tokens). Whereas some large language model implementations simply start trimming earlier messages from the context when a conversation runs past the maximum in the window, Claude simply ended the conversation rather than allow the user to experience an increasingly incoherent conversation where the model would&amp;nbsp;start forgetting things based on how old they are.&lt;/p&gt;
&lt;p&gt;Now, Claude will instead go through a behind-the-scenes process of summarizing the key points from the earlier parts of the conversation, attempting to discard what it deems extraneous while keeping what’s important.&lt;/p&gt;
&lt;p&gt;Developers who call Anthropic’s API can leverage the same principles through context management and context compaction.&lt;/p&gt;
&lt;h2&gt;Opus 4.5 performance&lt;/h2&gt;
&lt;p&gt;Opus 4.5 is the first model to surpass an accuracy score of 80 percent—specifically, 80.9 percent in the SWE-Bench Verified benchmark, narrowly beating OpenAI’s recently released GPT-5.1-Codex-Max (77.9 percent) and Google’s Gemini 3 Pro (76.2 percent). The model performs particularly well in agentic coding and agentic tool use benchmarks, but still lags behind GPT-5.1 in visual reasoning (MMMU).&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Anthropic also claims that Opus 4.5 is far less susceptible to prompt injection attacks than prior Claude models, or than competing models like GPT-5.1 and Gemini 3 Pro. Still, none of these models has perfect performance on that front.&lt;/p&gt;
&lt;p&gt;While the improvements to performance in benchmarks are worth noting, the most meaningful improvement in Opus 4.5 is arguably that it is significantly more efficient with tokens. Anthropic’s blog post offers examples:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Set to a medium effort level, Opus 4.5 matches Sonnet 4.5’s best score on SWE-bench Verified, but uses 76% fewer output tokens. At its highest effort level, Opus 4.5 exceeds Sonnet 4.5 performance by 4.3 percentage points—while using 48% fewer tokens.&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2&gt;Other updates&lt;/h2&gt;
&lt;p&gt;The Opus 4.5 launch is accompanied by other new features for developers and users.&lt;/p&gt;
&lt;p&gt;For example, the developer platform now includes a new “effort” parameter, allowing developers to more precisely tune the balance they want between efficacy and token usage.&lt;/p&gt;
&lt;p&gt;Also, Claude Code is now available in the desktop Claude apps. Previously, it was available via command line, IDE extensions, the web—a few places, just not the native desktop apps. The Claude desktop interface is now tabbed between the traditional chat experience and the Claude Code experience.&lt;/p&gt;
&lt;p&gt;And lastly (and for some, most importantly), there’s a big pricing change for the API for Opus 4.5. The cost is now $5 (input)/$25 (output) per million tokens, down from $15/$75.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Longer chats address a long-standing criticism of Claude.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="An abstract image of a human figure holding a solar system, or something, who knows" class="absolute inset-0 w-full h-full object-cover hidden" height="356" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Screenshot-2025-11-24-at-4.57.28-PM-640x356.png" width="640" /&gt;
                  &lt;img alt="An abstract image of a human figure holding a solar system, or something, who knows" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Screenshot-2025-11-24-at-4.57.28-PM-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      If you can decipher the meaning of this strange promotional image for Opus 4.5, you've got me beat.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Anthropic

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Anthropic today released Opus 4.5, its flagship frontier model, and it brings improvements in coding performance, as well as some user experience improvements that make it more generally competitive with OpenAI’s latest frontier models.&lt;/p&gt;
&lt;p&gt;Perhaps the most prominent change for most users is that in the consumer app experiences (web, mobile, and desktop), Claude will be less prone to abruptly hard-stopping conversations because they have run too long. The improvement to memory within a single conversation applies not just to Opus 4.5, but to any current Claude models in the apps.&lt;/p&gt;
&lt;p&gt;Users who experienced abrupt endings (despite having room left in their session and weekly usage budgets) were hitting a hard context window (200,000 tokens). Whereas some large language model implementations simply start trimming earlier messages from the context when a conversation runs past the maximum in the window, Claude simply ended the conversation rather than allow the user to experience an increasingly incoherent conversation where the model would&amp;nbsp;start forgetting things based on how old they are.&lt;/p&gt;
&lt;p&gt;Now, Claude will instead go through a behind-the-scenes process of summarizing the key points from the earlier parts of the conversation, attempting to discard what it deems extraneous while keeping what’s important.&lt;/p&gt;
&lt;p&gt;Developers who call Anthropic’s API can leverage the same principles through context management and context compaction.&lt;/p&gt;
&lt;h2&gt;Opus 4.5 performance&lt;/h2&gt;
&lt;p&gt;Opus 4.5 is the first model to surpass an accuracy score of 80 percent—specifically, 80.9 percent in the SWE-Bench Verified benchmark, narrowly beating OpenAI’s recently released GPT-5.1-Codex-Max (77.9 percent) and Google’s Gemini 3 Pro (76.2 percent). The model performs particularly well in agentic coding and agentic tool use benchmarks, but still lags behind GPT-5.1 in visual reasoning (MMMU).&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Anthropic also claims that Opus 4.5 is far less susceptible to prompt injection attacks than prior Claude models, or than competing models like GPT-5.1 and Gemini 3 Pro. Still, none of these models has perfect performance on that front.&lt;/p&gt;
&lt;p&gt;While the improvements to performance in benchmarks are worth noting, the most meaningful improvement in Opus 4.5 is arguably that it is significantly more efficient with tokens. Anthropic’s blog post offers examples:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Set to a medium effort level, Opus 4.5 matches Sonnet 4.5’s best score on SWE-bench Verified, but uses 76% fewer output tokens. At its highest effort level, Opus 4.5 exceeds Sonnet 4.5 performance by 4.3 percentage points—while using 48% fewer tokens.&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2&gt;Other updates&lt;/h2&gt;
&lt;p&gt;The Opus 4.5 launch is accompanied by other new features for developers and users.&lt;/p&gt;
&lt;p&gt;For example, the developer platform now includes a new “effort” parameter, allowing developers to more precisely tune the balance they want between efficacy and token usage.&lt;/p&gt;
&lt;p&gt;Also, Claude Code is now available in the desktop Claude apps. Previously, it was available via command line, IDE extensions, the web—a few places, just not the native desktop apps. The Claude desktop interface is now tabbed between the traditional chat experience and the Claude Code experience.&lt;/p&gt;
&lt;p&gt;And lastly (and for some, most importantly), there’s a big pricing change for the API for Opus 4.5. The cost is now $5 (input)/$25 (output) per million tokens, down from $15/$75.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/11/anthropic-introduces-opus-4-5-cuts-api-pricing-and-enables-much-longer-claude-chats/</guid><pubDate>Mon, 24 Nov 2025 23:15:10 +0000</pubDate></item><item><title>[NEW] Google teams up with Accel to hunt for India’s next AI breakouts (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/24/google-teams-up-with-accel-to-hunt-for-indias-next-ai-breakouts/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/google-india.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google has partnered with Accel to find and fund India’s earliest-stage AI startups in a first-of-its-kind collaboration for the Google AI Futures Fund, launched earlier this year. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Tuesday, Accel and Google announced a partnership to jointly invest up to $2 million in each startup through Accel’s Atoms program, with both firms contributing up to $1 million. The 2026 cohort will focus on founders in India and the Indian diaspora building AI products from day one.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“The thought process is building AI products for billions of Indians, as well as supporting AI products built in India for global markets,” Prayank Swaroop, a partner at Accel, told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;India is an appealing market with the world’s second-largest internet and smartphone base after China and its deep engineering talent. Still, it’s also a country that lacks frontier model development and hasn’t produced many companies pushing the technical frontier of AI, where development remains concentrated in the U.S. and China.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Activity is starting to shift, however, as major firms including OpenAI and Anthropic have recently announced offices in the country, and global investors step up early-stage commitments. The bet is that a large, mobile-first population, expanding cloud infrastructure, and relatively low software costs could turn India into a meaningful AI market — if the ecosystem can translate talent and demand into original research and products.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Swaroop said investments will be geared toward just about any area: creativity, entertainment, coding, and work. “The future of work here is more encompassing, which is essentially SaaS, and all other applications,” he told TechCrunch. “It could even be foundational models.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Swaroop said the firms will also try to identify areas where large language models are likely to advance over the next 12-24 months and look for Indian startups building in those directions.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside capital, founders will receive up to $350,000 in compute credits across Google Cloud, Gemini, and DeepMind, as well as early access to Gemini and DeepMind models, APIs, and experimental features. The program will include support from Google Labs and DeepMind research teams, co-development opportunities, monthly mentorship with Accel partners and Google technical leads, and immersion sessions in London and the Bay Area, including Google I/O. Founders will also get marketing support through Accel and Google’s global channels, as well as access to the Atoms founder network and Google’s AI builder ecosystem, the companies said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“India has an incredible history of innovation, and we firmly believe that its founders are going to be playing a leading role in the next generation of AI-led global technology,” Jonathan Silber, co-founder and director of the Google AI Futures Fund, told TechCrunch. “This is the Futures Fund’s first such collaboration anywhere in the world, and we chose India for a reason. Google has been a committed partner in the country’s journey to digital transformation, with multibillion-dollar investments over the years.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The partnership follows Google’s recent $15 billion plan to build a 1-gigawatt data center and AI hub in India. The company also announced a $10 billion digitization fund in 2020, which has backed firms including Bharti Airtel, Reliance Jio, and Walmart-owned Flipkart. Last month, Google partnered with Reliance to offer millions of Jio users free access to AI Pro.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Google launched the AI Futures Fund in May as a dedicated vehicle to invest in and collaborate with AI startups globally. It has backed companies including Replit and Harvey, and has also invested directly in Indian startups such as Toonsutra and STAN.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Silber told TechCrunch that Google would appear on the cap tables of startups funded through the partnership and would be “a material presence,” but declined to share how its equity stakes would compare with Accel’s.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This is our attempt to work with the market leader in the space who knows the country incredibly well, that can get us talking to earlier-stage founders at an early informative stage, that can move the needle,” Silber said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While using Google products is, perhaps, a given for applicants to this program, both Silber and Swaroop told TechCrunch there would be no requirements for startups to exclusively use Gemini or any other Google product. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Sometimes, Google’s technology is the best. Other times, you’ll see Anthropic or OpenAI. So, we’re not putting firm requirements that say you can only use Google’s models,” said Silber. “What we’re hoping to do, though, is find a couple of different unique integrations that we can do with these companies that leverage Google AI technology.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Launched in 2021, Accel’s pre-seed and seed platform, Atoms, has backed more than 40 companies that have collectively raised over $300 million in follow-on funding. The firm expanded the program this year to include Indian-origin founders based overseas.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The latest collaboration comes days after Accel’s partnership with Prosus to co-invest in Atoms X, backing early-stage Indian founders building large-scale solutions with the potential to serve the masses in the country.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Silber told TechCrunch that Google is not structuring the partnership as a pathway to future acquisitions, or even future cloud customers.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We’re not a sales team, so we’re not specifically looking to sign up new cloud customers. That’s not our goal,” he said. “In terms of KPIs, our objective is simply to see the next wave of innovation in the AI space coming out of India.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/google-india.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google has partnered with Accel to find and fund India’s earliest-stage AI startups in a first-of-its-kind collaboration for the Google AI Futures Fund, launched earlier this year. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Tuesday, Accel and Google announced a partnership to jointly invest up to $2 million in each startup through Accel’s Atoms program, with both firms contributing up to $1 million. The 2026 cohort will focus on founders in India and the Indian diaspora building AI products from day one.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“The thought process is building AI products for billions of Indians, as well as supporting AI products built in India for global markets,” Prayank Swaroop, a partner at Accel, told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;India is an appealing market with the world’s second-largest internet and smartphone base after China and its deep engineering talent. Still, it’s also a country that lacks frontier model development and hasn’t produced many companies pushing the technical frontier of AI, where development remains concentrated in the U.S. and China.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Activity is starting to shift, however, as major firms including OpenAI and Anthropic have recently announced offices in the country, and global investors step up early-stage commitments. The bet is that a large, mobile-first population, expanding cloud infrastructure, and relatively low software costs could turn India into a meaningful AI market — if the ecosystem can translate talent and demand into original research and products.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Swaroop said investments will be geared toward just about any area: creativity, entertainment, coding, and work. “The future of work here is more encompassing, which is essentially SaaS, and all other applications,” he told TechCrunch. “It could even be foundational models.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Swaroop said the firms will also try to identify areas where large language models are likely to advance over the next 12-24 months and look for Indian startups building in those directions.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside capital, founders will receive up to $350,000 in compute credits across Google Cloud, Gemini, and DeepMind, as well as early access to Gemini and DeepMind models, APIs, and experimental features. The program will include support from Google Labs and DeepMind research teams, co-development opportunities, monthly mentorship with Accel partners and Google technical leads, and immersion sessions in London and the Bay Area, including Google I/O. Founders will also get marketing support through Accel and Google’s global channels, as well as access to the Atoms founder network and Google’s AI builder ecosystem, the companies said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“India has an incredible history of innovation, and we firmly believe that its founders are going to be playing a leading role in the next generation of AI-led global technology,” Jonathan Silber, co-founder and director of the Google AI Futures Fund, told TechCrunch. “This is the Futures Fund’s first such collaboration anywhere in the world, and we chose India for a reason. Google has been a committed partner in the country’s journey to digital transformation, with multibillion-dollar investments over the years.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The partnership follows Google’s recent $15 billion plan to build a 1-gigawatt data center and AI hub in India. The company also announced a $10 billion digitization fund in 2020, which has backed firms including Bharti Airtel, Reliance Jio, and Walmart-owned Flipkart. Last month, Google partnered with Reliance to offer millions of Jio users free access to AI Pro.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Google launched the AI Futures Fund in May as a dedicated vehicle to invest in and collaborate with AI startups globally. It has backed companies including Replit and Harvey, and has also invested directly in Indian startups such as Toonsutra and STAN.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Silber told TechCrunch that Google would appear on the cap tables of startups funded through the partnership and would be “a material presence,” but declined to share how its equity stakes would compare with Accel’s.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This is our attempt to work with the market leader in the space who knows the country incredibly well, that can get us talking to earlier-stage founders at an early informative stage, that can move the needle,” Silber said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While using Google products is, perhaps, a given for applicants to this program, both Silber and Swaroop told TechCrunch there would be no requirements for startups to exclusively use Gemini or any other Google product. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Sometimes, Google’s technology is the best. Other times, you’ll see Anthropic or OpenAI. So, we’re not putting firm requirements that say you can only use Google’s models,” said Silber. “What we’re hoping to do, though, is find a couple of different unique integrations that we can do with these companies that leverage Google AI technology.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Launched in 2021, Accel’s pre-seed and seed platform, Atoms, has backed more than 40 companies that have collectively raised over $300 million in follow-on funding. The firm expanded the program this year to include Indian-origin founders based overseas.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The latest collaboration comes days after Accel’s partnership with Prosus to co-invest in Atoms X, backing early-stage Indian founders building large-scale solutions with the potential to serve the masses in the country.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Silber told TechCrunch that Google is not structuring the partnership as a pathway to future acquisitions, or even future cloud customers.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We’re not a sales team, so we’re not specifically looking to sign up new cloud customers. That’s not our goal,” he said. “In terms of KPIs, our objective is simply to see the next wave of innovation in the AI space coming out of India.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/24/google-teams-up-with-accel-to-hunt-for-indias-next-ai-breakouts/</guid><pubDate>Tue, 25 Nov 2025 00:30:00 +0000</pubDate></item></channel></rss>