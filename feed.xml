<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 02 Sep 2025 18:27:57 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>Therapists are secretly using ChatGPT. Clients are triggered. (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/02/1122871/therapists-using-chatgpt-secretly/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/IMG_9643.jpeg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Declan would never have found out his therapist was using ChatGPT had it not been for a technical mishap. The connection was patchy during one of their online sessions, so Declan suggested they turn off their video feeds. Instead, his therapist began inadvertently sharing his screen.&lt;/p&gt;  &lt;p&gt;“Suddenly, I was watching him use ChatGPT,” says Declan, 31, who lives in Los Angeles. “He was taking what I was saying and putting it into ChatGPT, and then summarizing or cherry-picking answers.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Declan was so shocked he didn’t say anything, and for the rest of the session he was privy to a real-time stream of ChatGPT analysis rippling across his therapist’s screen. The session became even more surreal when Declan began echoing ChatGPT in his own responses, preempting his therapist.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“I became the best patient ever,” he says, “because ChatGPT would be like, ‘Well, do you consider that your way of thinking might be a little too black and white?’ And I would be like, ‘Huh, you know, I think my way of thinking might be too black and white,’ and [my therapist would] be like, ‘&lt;em&gt;Exactly&lt;/em&gt;.’ I’m sure it was his dream session.”&lt;/p&gt; 
 &lt;p&gt;Among the questions racing through Declan’s mind was, “Is this legal?” When Declan raised the incident with his therapist at the next session—“It was super awkward, like a weird breakup”—the therapist cried. He explained he had felt they’d hit a wall and had begun looking for answers elsewhere.&lt;em&gt; &lt;/em&gt;“I was still charged for that session,” Declan says, laughing.&lt;/p&gt;  &lt;p&gt;The large language model (LLM) boom of the past few years has had unexpected ramifications for the field of psychotherapy, mostly due to the growing number of people substituting the likes of ChatGPT for human therapists. But less discussed is how some therapists themselves are integrating AI into their practice. As in many other professions, generative AI promises tantalizing efficiency savings, but its adoption risks compromising sensitive patient data and undermining a relationship in which trust is paramount.&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;Suspicious sentiments&lt;/h3&gt;  &lt;p&gt;Declan is not alone, as I can attest from personal experience. When I received a recent email from my therapist that seemed longer and more polished than usual, I initially felt heartened. It seemed to convey a kind, validating message, and its length made me feel that she’d taken the time to reflect on all of the points in my (rather sensitive) email.&lt;/p&gt;  &lt;p&gt;On closer inspection, though, her email seemed a little strange. It was in a new font, and the text displayed several AI “tells,” including liberal use of the Americanized em dash (we’re both from the UK), the signature impersonal style, and the habit of addressing each point made in the original email line by line.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;My positive feelings quickly drained away, to be replaced by disappointment and mistrust, once I realized ChatGPT likely had a hand in drafting the message—which my therapist confirmed when I asked her.&lt;/p&gt;  &lt;p&gt;Despite her assurance that she simply dictates longer emails using AI, I still felt uncertainty over the extent to which she, as opposed to the bot, was responsible for the sentiments expressed. I also couldn’t entirely shake the suspicion that she might have pasted my highly personal email wholesale into ChatGPT.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;When I took to the internet to see whether others had had similar experiences, I found plenty of examples of people receiving what they suspected were AI-generated communiqués from their therapists. Many, including Declan, had taken to Reddit to solicit emotional support and advice.&lt;/p&gt;  &lt;p&gt;So had Hope, 25, who lives on the east coast of the US, and had direct-messaged her therapist about the death of her dog. She soon received a message back. It would have been consoling and thoughtful—expressing how hard it must be “not having him by your side right now”—were it not for the reference to the AI prompt accidentally preserved at the top: “Here’s a more human, heartfelt version with a gentle, conversational tone.”&lt;/p&gt;  &lt;p&gt;Hope says she felt “honestly really surprised and confused.” “It was just a very strange feeling,” she says. “Then I started to feel kind of betrayed. … It definitely affected my trust in her.” This was especially problematic, she adds, because “part of why I was seeing her was for my trust issues.”&lt;/p&gt;  &lt;p&gt;Hope had believed her therapist to be competent and empathetic, and therefore “never would have suspected her to feel the need to use AI.” Her therapist was apologetic when confronted, and she explained that because she’d never had a pet herself, she’d turned to AI for help expressing the appropriate sentiment.&amp;nbsp;&lt;/p&gt; 

 &lt;h3 class="wp-block-heading"&gt;A disclosure dilemma&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;Betrayal or not, there may be some merit to the argument that AI could help therapists better communicate with their clients. A 2025 study published in &lt;em&gt;PLOS Mental Health&lt;/em&gt; asked therapists to use ChatGPT to respond to vignettes describing problems of the kind patients might raise in therapy. Not only was a panel of 830 participants unable to distinguish between the human and AI responses, but AI responses were rated as conforming better to therapeutic best practice.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;However, when participants suspected responses to have been written by ChatGPT, they ranked them lower. (Responses written by ChatGPT but misattributed to therapists received the highest ratings overall.)&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Similarly, Cornell University researchers found in a 2023 study that AI-generated messages can increase feelings of closeness and cooperation between interlocutors, but only if the recipient remains oblivious to the role of AI. The mere suspicion of its use was found to rapidly sour goodwill.&lt;/p&gt;  &lt;p&gt;“People value authenticity, particularly in psychotherapy,” says Adrian Aguilera, a clinical psychologist and professor at the University of California, Berkeley. “I think [using AI] can feel like, ‘You’re not taking my relationship seriously.’ Do I ChatGPT a response to my wife or my kids? That wouldn’t feel genuine.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;In 2023, in the early days of generative AI, the online therapy service Koko conducted a clandestine experiment on its users, mixing in responses generated by GPT-3 with ones drafted by humans. They discovered that users tended to rate the AI-generated responses more positively. The revelation that users had unwittingly been experimented on, however, sparked outrage.&lt;/p&gt;  &lt;p&gt;The online therapy provider BetterHelp has also been subject to claims that its therapists have used AI to draft responses. In a Medium post, photographer Brendan Keen said his BetterHelp therapist admitted to using AI in their replies, leading to “an acute sense of betrayal” and persistent worry, despite reassurances, that his data privacy had been breached. He ended the relationship thereafter.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;A BetterHelp spokesperson told us the company “prohibits therapists from disclosing any member’s personal or health information to third-party artificial intelligence, or using AI to craft messages to members to the extent it might directly or indirectly have the potential to identify someone.”&lt;/p&gt;  &lt;p&gt;All these examples relate to undisclosed AI usage. Aguilera believes time-strapped therapists can make use of LLMs, but transparency is essential. “We have to be up-front and tell people, ‘Hey, I’m going to use this tool for X, Y, and Z’ and provide a rationale,” he says. People then receive AI-generated messages with that prior context, rather than assuming their therapist is “trying to be sneaky.”&lt;/p&gt; 
 &lt;p&gt;Psychologists are often working at the limits of their capacity, and levels of burnout in the profession are high, according to 2023 research conducted by the American Psychological Association. That context makes the appeal of AI-powered tools obvious.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But lack of disclosure risks permanently damaging trust. Hope decided to continue seeing her therapist, though she stopped working with her a little later for reasons she says were unrelated. “But I always thought about the AI Incident whenever I saw her,” she says.&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;Risking patient privacy&lt;/h3&gt;  &lt;p&gt;Beyond the transparency issue, many therapists are leery of using LLMs in the first place, says Margaret Morris, a clinical psychologist and affiliate faculty member at the University of Washington.&lt;/p&gt;  &lt;p&gt;“I think these tools might be really valuable for learning,” she says, noting that therapists should continue developing their expertise over the course of their career. “But I think we have to be super careful about patient data.” Morris calls Declan’s experience “alarming.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;Therapists need to be aware that general-purpose AI chatbots like ChatGPT are not approved by the US Food and Drug Administration and are not HIPAA compliant, says Pardis Emami-Naeini, assistant professor of computer science at Duke University, who has researched the privacy and security implications of LLMs in a health context. (HIPAA is a set of US federal regulations that protect people’s sensitive health information.)&lt;/p&gt;  &lt;p&gt;“This creates significant risks for patient privacy if any information about the patient is disclosed or can be inferred by the AI,” she says.&lt;/p&gt;  &lt;p&gt;In a recent paper, Emami-Naeini found that many users wrongly believe ChatGPT &lt;em&gt;is&lt;/em&gt; HIPAA compliant, creating an unwarranted sense of trust in the tool. “I expect some therapists may share this misconception,” she says.&lt;/p&gt;  &lt;p&gt;As a relatively open person, Declan says, he wasn’t completely distraught to learn how his therapist was using ChatGPT. “Personally, I am not thinking, ‘Oh, my God, I have deep, dark secrets,’” he said. But it did still feel violating: “I can imagine that if I was suicidal, or on drugs, or cheating on my girlfriend … I wouldn’t want that to be put into ChatGPT.”&lt;/p&gt; 
 &lt;p&gt;When using AI to help with email, “it’s not as simple as removing obvious identifiers such as names and addresses,” says Emami-Naeini. “Sensitive information can often be inferred from seemingly nonsensitive details.”&lt;/p&gt;  &lt;p&gt;She adds, “Identifying and rephrasing all potential sensitive data requires time and expertise, which may conflict with the intended convenience of using AI tools. In all cases, therapists should disclose their use of AI to patients and seek consent.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;A growing number of companies, including Heidi Health, Upheal, Lyssn, and Blueprint, are marketing specialized tools to therapists, such as AI-assisted note-taking, training, and transcription services. These companies say they are HIPAA compliant and store data securely using encryption and pseudonymization where necessary. But many therapists are still wary of the privacy implications—particularly of services that necessitate the recording of entire sessions.&lt;/p&gt;  &lt;p&gt;“Even if privacy protections are improved, there is always some risk of information leakage or secondary uses of data,” says Emami-Naeini.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt;&lt;p&gt;A 2020 hack on a Finnish mental health company, which resulted in tens of thousands of clients’ treatment records being accessed, serves as a warning. People on the list were blackmailed, and subsequently the entire trove was publicly released, revealing extremely sensitive details such as peoples’ experiences of child abuse and addiction problems.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;What therapists stand to lose&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;In addition to violation of data privacy, other risks are involved when psychotherapists consult LLMs on behalf of a client. Studies have found that although some specialized therapy bots can rival human-delivered interventions, advice from the likes of ChatGPT can cause more harm than good.&lt;/p&gt;  &lt;p&gt;A recent Stanford University study, for example, found that chatbots can fuel delusions and psychopathy by blindly validating a user rather than challenging them, as well as suffer from biases and engage in sycophancy. The same flaws could make it risky for therapists to consult chatbots on behalf of their clients. They could, for example, baselessly validate a therapist’s hunch, or lead them down the wrong path.&lt;/p&gt;  &lt;p&gt;Aguilera says he has played around with tools like ChatGPT while teaching mental health trainees, such as by entering hypothetical symptoms and asking the AI chatbot to make a diagnosis. The tool will produce lots of possible conditions, but it’s rather thin in its analysis, he says. The American Counseling Association recommends that AI not be used for mental health diagnosis at present.&lt;/p&gt;  &lt;p&gt;A study published in 2024 of an earlier version of ChatGPT similarly found it was too vague and general to be truly useful in diagnosis or devising treatment plans, and it was heavily biased toward suggesting people seek cognitive behavioral therapy as opposed to other types of therapy that might be more suitable.&lt;/p&gt;  &lt;p&gt;Daniel Kimmel, a psychiatrist and neuroscientist at Columbia University, conducted experiments with ChatGPT where he posed as a client having relationship troubles. He says he found the chatbot was a decent mimic when it came to “stock-in-trade” therapeutic responses, like normalizing and validating, asking for additional information, or highlighting certain cognitive or emotional associations.&lt;/p&gt;  &lt;p&gt;However, “it didn’t do a lot of digging,” he says. It didn’t attempt “to link seemingly or superficially unrelated things together into something cohesive … to come up with a story, an idea, a theory.”&lt;/p&gt;  &lt;p&gt;“I would be skeptical about using it to do the thinking for you,” he says. Thinking, he says, should be the job of therapists.&lt;/p&gt;  &lt;p&gt;Therapists could save time using AI-powered tech, but this benefit should be weighed against the needs of patients, says Morris: “Maybe you’re saving yourself a couple of minutes. But what are you giving away?”&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/IMG_9643.jpeg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Declan would never have found out his therapist was using ChatGPT had it not been for a technical mishap. The connection was patchy during one of their online sessions, so Declan suggested they turn off their video feeds. Instead, his therapist began inadvertently sharing his screen.&lt;/p&gt;  &lt;p&gt;“Suddenly, I was watching him use ChatGPT,” says Declan, 31, who lives in Los Angeles. “He was taking what I was saying and putting it into ChatGPT, and then summarizing or cherry-picking answers.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Declan was so shocked he didn’t say anything, and for the rest of the session he was privy to a real-time stream of ChatGPT analysis rippling across his therapist’s screen. The session became even more surreal when Declan began echoing ChatGPT in his own responses, preempting his therapist.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“I became the best patient ever,” he says, “because ChatGPT would be like, ‘Well, do you consider that your way of thinking might be a little too black and white?’ And I would be like, ‘Huh, you know, I think my way of thinking might be too black and white,’ and [my therapist would] be like, ‘&lt;em&gt;Exactly&lt;/em&gt;.’ I’m sure it was his dream session.”&lt;/p&gt; 
 &lt;p&gt;Among the questions racing through Declan’s mind was, “Is this legal?” When Declan raised the incident with his therapist at the next session—“It was super awkward, like a weird breakup”—the therapist cried. He explained he had felt they’d hit a wall and had begun looking for answers elsewhere.&lt;em&gt; &lt;/em&gt;“I was still charged for that session,” Declan says, laughing.&lt;/p&gt;  &lt;p&gt;The large language model (LLM) boom of the past few years has had unexpected ramifications for the field of psychotherapy, mostly due to the growing number of people substituting the likes of ChatGPT for human therapists. But less discussed is how some therapists themselves are integrating AI into their practice. As in many other professions, generative AI promises tantalizing efficiency savings, but its adoption risks compromising sensitive patient data and undermining a relationship in which trust is paramount.&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;Suspicious sentiments&lt;/h3&gt;  &lt;p&gt;Declan is not alone, as I can attest from personal experience. When I received a recent email from my therapist that seemed longer and more polished than usual, I initially felt heartened. It seemed to convey a kind, validating message, and its length made me feel that she’d taken the time to reflect on all of the points in my (rather sensitive) email.&lt;/p&gt;  &lt;p&gt;On closer inspection, though, her email seemed a little strange. It was in a new font, and the text displayed several AI “tells,” including liberal use of the Americanized em dash (we’re both from the UK), the signature impersonal style, and the habit of addressing each point made in the original email line by line.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;My positive feelings quickly drained away, to be replaced by disappointment and mistrust, once I realized ChatGPT likely had a hand in drafting the message—which my therapist confirmed when I asked her.&lt;/p&gt;  &lt;p&gt;Despite her assurance that she simply dictates longer emails using AI, I still felt uncertainty over the extent to which she, as opposed to the bot, was responsible for the sentiments expressed. I also couldn’t entirely shake the suspicion that she might have pasted my highly personal email wholesale into ChatGPT.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;When I took to the internet to see whether others had had similar experiences, I found plenty of examples of people receiving what they suspected were AI-generated communiqués from their therapists. Many, including Declan, had taken to Reddit to solicit emotional support and advice.&lt;/p&gt;  &lt;p&gt;So had Hope, 25, who lives on the east coast of the US, and had direct-messaged her therapist about the death of her dog. She soon received a message back. It would have been consoling and thoughtful—expressing how hard it must be “not having him by your side right now”—were it not for the reference to the AI prompt accidentally preserved at the top: “Here’s a more human, heartfelt version with a gentle, conversational tone.”&lt;/p&gt;  &lt;p&gt;Hope says she felt “honestly really surprised and confused.” “It was just a very strange feeling,” she says. “Then I started to feel kind of betrayed. … It definitely affected my trust in her.” This was especially problematic, she adds, because “part of why I was seeing her was for my trust issues.”&lt;/p&gt;  &lt;p&gt;Hope had believed her therapist to be competent and empathetic, and therefore “never would have suspected her to feel the need to use AI.” Her therapist was apologetic when confronted, and she explained that because she’d never had a pet herself, she’d turned to AI for help expressing the appropriate sentiment.&amp;nbsp;&lt;/p&gt; 

 &lt;h3 class="wp-block-heading"&gt;A disclosure dilemma&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;Betrayal or not, there may be some merit to the argument that AI could help therapists better communicate with their clients. A 2025 study published in &lt;em&gt;PLOS Mental Health&lt;/em&gt; asked therapists to use ChatGPT to respond to vignettes describing problems of the kind patients might raise in therapy. Not only was a panel of 830 participants unable to distinguish between the human and AI responses, but AI responses were rated as conforming better to therapeutic best practice.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;However, when participants suspected responses to have been written by ChatGPT, they ranked them lower. (Responses written by ChatGPT but misattributed to therapists received the highest ratings overall.)&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Similarly, Cornell University researchers found in a 2023 study that AI-generated messages can increase feelings of closeness and cooperation between interlocutors, but only if the recipient remains oblivious to the role of AI. The mere suspicion of its use was found to rapidly sour goodwill.&lt;/p&gt;  &lt;p&gt;“People value authenticity, particularly in psychotherapy,” says Adrian Aguilera, a clinical psychologist and professor at the University of California, Berkeley. “I think [using AI] can feel like, ‘You’re not taking my relationship seriously.’ Do I ChatGPT a response to my wife or my kids? That wouldn’t feel genuine.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;In 2023, in the early days of generative AI, the online therapy service Koko conducted a clandestine experiment on its users, mixing in responses generated by GPT-3 with ones drafted by humans. They discovered that users tended to rate the AI-generated responses more positively. The revelation that users had unwittingly been experimented on, however, sparked outrage.&lt;/p&gt;  &lt;p&gt;The online therapy provider BetterHelp has also been subject to claims that its therapists have used AI to draft responses. In a Medium post, photographer Brendan Keen said his BetterHelp therapist admitted to using AI in their replies, leading to “an acute sense of betrayal” and persistent worry, despite reassurances, that his data privacy had been breached. He ended the relationship thereafter.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;A BetterHelp spokesperson told us the company “prohibits therapists from disclosing any member’s personal or health information to third-party artificial intelligence, or using AI to craft messages to members to the extent it might directly or indirectly have the potential to identify someone.”&lt;/p&gt;  &lt;p&gt;All these examples relate to undisclosed AI usage. Aguilera believes time-strapped therapists can make use of LLMs, but transparency is essential. “We have to be up-front and tell people, ‘Hey, I’m going to use this tool for X, Y, and Z’ and provide a rationale,” he says. People then receive AI-generated messages with that prior context, rather than assuming their therapist is “trying to be sneaky.”&lt;/p&gt; 
 &lt;p&gt;Psychologists are often working at the limits of their capacity, and levels of burnout in the profession are high, according to 2023 research conducted by the American Psychological Association. That context makes the appeal of AI-powered tools obvious.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But lack of disclosure risks permanently damaging trust. Hope decided to continue seeing her therapist, though she stopped working with her a little later for reasons she says were unrelated. “But I always thought about the AI Incident whenever I saw her,” she says.&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;Risking patient privacy&lt;/h3&gt;  &lt;p&gt;Beyond the transparency issue, many therapists are leery of using LLMs in the first place, says Margaret Morris, a clinical psychologist and affiliate faculty member at the University of Washington.&lt;/p&gt;  &lt;p&gt;“I think these tools might be really valuable for learning,” she says, noting that therapists should continue developing their expertise over the course of their career. “But I think we have to be super careful about patient data.” Morris calls Declan’s experience “alarming.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;Therapists need to be aware that general-purpose AI chatbots like ChatGPT are not approved by the US Food and Drug Administration and are not HIPAA compliant, says Pardis Emami-Naeini, assistant professor of computer science at Duke University, who has researched the privacy and security implications of LLMs in a health context. (HIPAA is a set of US federal regulations that protect people’s sensitive health information.)&lt;/p&gt;  &lt;p&gt;“This creates significant risks for patient privacy if any information about the patient is disclosed or can be inferred by the AI,” she says.&lt;/p&gt;  &lt;p&gt;In a recent paper, Emami-Naeini found that many users wrongly believe ChatGPT &lt;em&gt;is&lt;/em&gt; HIPAA compliant, creating an unwarranted sense of trust in the tool. “I expect some therapists may share this misconception,” she says.&lt;/p&gt;  &lt;p&gt;As a relatively open person, Declan says, he wasn’t completely distraught to learn how his therapist was using ChatGPT. “Personally, I am not thinking, ‘Oh, my God, I have deep, dark secrets,’” he said. But it did still feel violating: “I can imagine that if I was suicidal, or on drugs, or cheating on my girlfriend … I wouldn’t want that to be put into ChatGPT.”&lt;/p&gt; 
 &lt;p&gt;When using AI to help with email, “it’s not as simple as removing obvious identifiers such as names and addresses,” says Emami-Naeini. “Sensitive information can often be inferred from seemingly nonsensitive details.”&lt;/p&gt;  &lt;p&gt;She adds, “Identifying and rephrasing all potential sensitive data requires time and expertise, which may conflict with the intended convenience of using AI tools. In all cases, therapists should disclose their use of AI to patients and seek consent.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;A growing number of companies, including Heidi Health, Upheal, Lyssn, and Blueprint, are marketing specialized tools to therapists, such as AI-assisted note-taking, training, and transcription services. These companies say they are HIPAA compliant and store data securely using encryption and pseudonymization where necessary. But many therapists are still wary of the privacy implications—particularly of services that necessitate the recording of entire sessions.&lt;/p&gt;  &lt;p&gt;“Even if privacy protections are improved, there is always some risk of information leakage or secondary uses of data,” says Emami-Naeini.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt;&lt;p&gt;A 2020 hack on a Finnish mental health company, which resulted in tens of thousands of clients’ treatment records being accessed, serves as a warning. People on the list were blackmailed, and subsequently the entire trove was publicly released, revealing extremely sensitive details such as peoples’ experiences of child abuse and addiction problems.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;What therapists stand to lose&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;In addition to violation of data privacy, other risks are involved when psychotherapists consult LLMs on behalf of a client. Studies have found that although some specialized therapy bots can rival human-delivered interventions, advice from the likes of ChatGPT can cause more harm than good.&lt;/p&gt;  &lt;p&gt;A recent Stanford University study, for example, found that chatbots can fuel delusions and psychopathy by blindly validating a user rather than challenging them, as well as suffer from biases and engage in sycophancy. The same flaws could make it risky for therapists to consult chatbots on behalf of their clients. They could, for example, baselessly validate a therapist’s hunch, or lead them down the wrong path.&lt;/p&gt;  &lt;p&gt;Aguilera says he has played around with tools like ChatGPT while teaching mental health trainees, such as by entering hypothetical symptoms and asking the AI chatbot to make a diagnosis. The tool will produce lots of possible conditions, but it’s rather thin in its analysis, he says. The American Counseling Association recommends that AI not be used for mental health diagnosis at present.&lt;/p&gt;  &lt;p&gt;A study published in 2024 of an earlier version of ChatGPT similarly found it was too vague and general to be truly useful in diagnosis or devising treatment plans, and it was heavily biased toward suggesting people seek cognitive behavioral therapy as opposed to other types of therapy that might be more suitable.&lt;/p&gt;  &lt;p&gt;Daniel Kimmel, a psychiatrist and neuroscientist at Columbia University, conducted experiments with ChatGPT where he posed as a client having relationship troubles. He says he found the chatbot was a decent mimic when it came to “stock-in-trade” therapeutic responses, like normalizing and validating, asking for additional information, or highlighting certain cognitive or emotional associations.&lt;/p&gt;  &lt;p&gt;However, “it didn’t do a lot of digging,” he says. It didn’t attempt “to link seemingly or superficially unrelated things together into something cohesive … to come up with a story, an idea, a theory.”&lt;/p&gt;  &lt;p&gt;“I would be skeptical about using it to do the thinking for you,” he says. Thinking, he says, should be the job of therapists.&lt;/p&gt;  &lt;p&gt;Therapists could save time using AI-powered tech, but this benefit should be weighed against the needs of patients, says Morris: “Maybe you’re saving yourself a couple of minutes. But what are you giving away?”&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/02/1122871/therapists-using-chatgpt-secretly/</guid><pubDate>Tue, 02 Sep 2025 08:38:24 +0000</pubDate></item><item><title>Can an AI doppelgänger help me do my job? (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/02/1122856/can-an-ai-doppelganger-help-me-do-my-job/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/250926-james-ai2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Everywhere I look, I see AI clones. On X and LinkedIn, “thought leaders” and influencers offer their followers a chance to ask questions of their digital replicas. OnlyFans creators are having AI models of themselves chat, for a price, with followers. “Virtual human” salespeople in China are reportedly outselling real humans.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Digital clones—AI models that replicate a specific person—package together a few technologies that have been around for a while now: hyperrealistic video models to match your appearance, lifelike voices based on just a couple of minutes of speech recordings, and conversational chatbots increasingly capable of holding our attention. But they’re also offering something the ChatGPTs of the world cannot: an AI that’s not smart in the general sense, but that 'thinks' like &lt;em&gt;you&lt;/em&gt; do.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Who are they for? Delphi, a startup that recently raised $16 million from funders including Anthropic and actor/director Olivia Wilde’s venture capital firm, Proximity Ventures, helps famous people create replicas that can speak with their fans in both chat and voice calls. It feels like MasterClass—the platform for instructional seminars led by celebrities—vaulted into the AI age. On its website, Delphi writes that modern leaders “possess potentially life-altering knowledge and wisdom, but their time is limited and access is constrained.”&lt;/p&gt;  &lt;p&gt;It has a library of official clones created by famous figures that you can speak with. Arnold Schwarzenegger, for example, told me, “I’m here to cut the crap and help you get stronger and happier,” before informing me cheerily that I’ve now been signed up to receive the &lt;em&gt;Arnold’s Pump Club&lt;/em&gt; newsletter. Even if his or other celebrities’ clones fall short of Delphi’s lofty vision of spreading “personalized wisdom at scale,” they at least seem to serve as a funnel to find fans, build mailing lists, or sell supplements.&lt;/p&gt; 
 &lt;p&gt;But what about for the rest of us? Could well-crafted clones serve as our stand-ins? I certainly feel stretched thin at work sometimes, wishing I could be in two places at once, and I bet you do too. I could see a replica popping into a virtual meeting with a PR representative, not to trick them into thinking it’s the real me, but simply to take a brief call on my behalf. A recording of this call might summarize how it went.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;To find out, I tried making a clone. Tavus, a Y Combinator alum that raised $18 million last year, will build a video avatar of you (plans start at $59 per month) that can be coached to reflect your personality and can join video calls. These clones have the “emotional intelligence of humans, with the reach of machines,” according to the company. “Reporter’s assistant” does not appear on the company’s site as an example use case, but it does mention therapists, physician’s assistants, and other roles that could benefit from an AI clone.&lt;/p&gt; 
 &lt;p&gt;For Tavus’s onboarding process, I turned on my camera, read through a script to help it learn my voice (which also acted as a waiver, with me agreeing to lend my likeness to Tavus), and recorded one minute of me just sitting in silence. Within a few hours, my avatar was ready. Upon meeting this digital me, I found it looked and spoke like I do (though I hated its teeth). But faking my appearance was the easy part. Could it learn enough about me and what topics I cover to serve as a stand-in with minimal risk of embarrassing me?&lt;/p&gt;  &lt;p&gt;Via a helpful chatbot interface, Tavus walked me through how to craft my clone’s personality, asking what I wanted the replica to do. It then helped me formulate instructions that became its operating manual. I uploaded three dozen of my stories that it could use to reference what I cover. It may have benefited from having more of my content—interviews, reporting notes, and the like—but I would never share that data for a host of reasons, not the least of which being that the other people who appear in it have not consented to their sides of our conversations being used to train an AI replica.&lt;/p&gt;  &lt;p&gt;So in the realm of AI—where models learn from entire libraries of data—I didn’t give my clone all that much to learn from, but I was still hopeful it had enough to be useful.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Alas, conversationally it was a wild card. It acted overly excited about story pitches I would never pursue. It repeated itself, and it kept saying it was checking my schedule to set up a meeting with the real me, which it could not do as I never gave it access to my calendar. It spoke in loops, with no way for the person on the other end to wrap up the conversation.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;These are common early quirks, Tavus’s cofounder Quinn Favret told me. The clones typically rely on Meta’s Llama model, which “often aims to be more helpful than it truly is,” Favret says, and developers building on top of Tavus’s platform are often the ones who set instructions for how the clones finish conversations or access calendars.&lt;/p&gt;  &lt;p&gt;For my purposes, it was a bust. To be useful to me, my AI clone would need to show at least some basic instincts for understanding what I cover, and at the very least not creep out whoever’s on the other side of the conversation. My clone fell short.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Such a clone could be helpful in other jobs, though. If you’re an influencer looking for ways to engage with more fans, or a salesperson for whom work is a numbers game and a clone could give you a leg up, it might just work. You run the risk that your replica could go off the rails or embarrass the real you, but the tradeoffs might be reasonable.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Favret told me some of Tavus’s bigger customers are companies using clones for health-care intake and job interviews. Replicas are also being used in corporate role-play, for practicing sales pitches or having HR-related conversations with employees, for example.&lt;/p&gt; 

 &lt;p&gt;But companies building clones are promising that they will be much more than cold-callers or telemarketing machines. Delphi says its clones will offer “meaningful, personal interactions at infinite scale,” and Tavus says its replicas have “a face, a brain, and memories” that enable “meaningful face-to-face conversations.” Favret also told me a growing number of Tavus’s customers are building clones for mentorship and even decision-making, like AI loan officers who use clones to qualify and filter applicants.&lt;/p&gt;  &lt;p&gt;Which is sort of the crux of it. Teaching an AI clone discernment, critical thinking, and taste—never mind the quirks of a specific person—is still the stuff of science fiction. That’s all fine when the person chatting with a clone is in on the bit (most of us know that Schwarzenegger’s replica, for example, will not coach me to be a better athlete).&lt;/p&gt;  &lt;p&gt;But as companies polish clones with “human” features and exaggerate their capabilities, I worry that people chasing efficiency will start using their replicas at best for roles that are cringeworthy, and at worst for making decisions they should never be entrusted with. In the end, these models are designed for scale, not fidelity. They can flatter us, amplify us, even sell for us—but they can’t quite become us.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&amp;nbsp;sign up here.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/250926-james-ai2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Everywhere I look, I see AI clones. On X and LinkedIn, “thought leaders” and influencers offer their followers a chance to ask questions of their digital replicas. OnlyFans creators are having AI models of themselves chat, for a price, with followers. “Virtual human” salespeople in China are reportedly outselling real humans.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Digital clones—AI models that replicate a specific person—package together a few technologies that have been around for a while now: hyperrealistic video models to match your appearance, lifelike voices based on just a couple of minutes of speech recordings, and conversational chatbots increasingly capable of holding our attention. But they’re also offering something the ChatGPTs of the world cannot: an AI that’s not smart in the general sense, but that 'thinks' like &lt;em&gt;you&lt;/em&gt; do.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Who are they for? Delphi, a startup that recently raised $16 million from funders including Anthropic and actor/director Olivia Wilde’s venture capital firm, Proximity Ventures, helps famous people create replicas that can speak with their fans in both chat and voice calls. It feels like MasterClass—the platform for instructional seminars led by celebrities—vaulted into the AI age. On its website, Delphi writes that modern leaders “possess potentially life-altering knowledge and wisdom, but their time is limited and access is constrained.”&lt;/p&gt;  &lt;p&gt;It has a library of official clones created by famous figures that you can speak with. Arnold Schwarzenegger, for example, told me, “I’m here to cut the crap and help you get stronger and happier,” before informing me cheerily that I’ve now been signed up to receive the &lt;em&gt;Arnold’s Pump Club&lt;/em&gt; newsletter. Even if his or other celebrities’ clones fall short of Delphi’s lofty vision of spreading “personalized wisdom at scale,” they at least seem to serve as a funnel to find fans, build mailing lists, or sell supplements.&lt;/p&gt; 
 &lt;p&gt;But what about for the rest of us? Could well-crafted clones serve as our stand-ins? I certainly feel stretched thin at work sometimes, wishing I could be in two places at once, and I bet you do too. I could see a replica popping into a virtual meeting with a PR representative, not to trick them into thinking it’s the real me, but simply to take a brief call on my behalf. A recording of this call might summarize how it went.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;To find out, I tried making a clone. Tavus, a Y Combinator alum that raised $18 million last year, will build a video avatar of you (plans start at $59 per month) that can be coached to reflect your personality and can join video calls. These clones have the “emotional intelligence of humans, with the reach of machines,” according to the company. “Reporter’s assistant” does not appear on the company’s site as an example use case, but it does mention therapists, physician’s assistants, and other roles that could benefit from an AI clone.&lt;/p&gt; 
 &lt;p&gt;For Tavus’s onboarding process, I turned on my camera, read through a script to help it learn my voice (which also acted as a waiver, with me agreeing to lend my likeness to Tavus), and recorded one minute of me just sitting in silence. Within a few hours, my avatar was ready. Upon meeting this digital me, I found it looked and spoke like I do (though I hated its teeth). But faking my appearance was the easy part. Could it learn enough about me and what topics I cover to serve as a stand-in with minimal risk of embarrassing me?&lt;/p&gt;  &lt;p&gt;Via a helpful chatbot interface, Tavus walked me through how to craft my clone’s personality, asking what I wanted the replica to do. It then helped me formulate instructions that became its operating manual. I uploaded three dozen of my stories that it could use to reference what I cover. It may have benefited from having more of my content—interviews, reporting notes, and the like—but I would never share that data for a host of reasons, not the least of which being that the other people who appear in it have not consented to their sides of our conversations being used to train an AI replica.&lt;/p&gt;  &lt;p&gt;So in the realm of AI—where models learn from entire libraries of data—I didn’t give my clone all that much to learn from, but I was still hopeful it had enough to be useful.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Alas, conversationally it was a wild card. It acted overly excited about story pitches I would never pursue. It repeated itself, and it kept saying it was checking my schedule to set up a meeting with the real me, which it could not do as I never gave it access to my calendar. It spoke in loops, with no way for the person on the other end to wrap up the conversation.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;These are common early quirks, Tavus’s cofounder Quinn Favret told me. The clones typically rely on Meta’s Llama model, which “often aims to be more helpful than it truly is,” Favret says, and developers building on top of Tavus’s platform are often the ones who set instructions for how the clones finish conversations or access calendars.&lt;/p&gt;  &lt;p&gt;For my purposes, it was a bust. To be useful to me, my AI clone would need to show at least some basic instincts for understanding what I cover, and at the very least not creep out whoever’s on the other side of the conversation. My clone fell short.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Such a clone could be helpful in other jobs, though. If you’re an influencer looking for ways to engage with more fans, or a salesperson for whom work is a numbers game and a clone could give you a leg up, it might just work. You run the risk that your replica could go off the rails or embarrass the real you, but the tradeoffs might be reasonable.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Favret told me some of Tavus’s bigger customers are companies using clones for health-care intake and job interviews. Replicas are also being used in corporate role-play, for practicing sales pitches or having HR-related conversations with employees, for example.&lt;/p&gt; 

 &lt;p&gt;But companies building clones are promising that they will be much more than cold-callers or telemarketing machines. Delphi says its clones will offer “meaningful, personal interactions at infinite scale,” and Tavus says its replicas have “a face, a brain, and memories” that enable “meaningful face-to-face conversations.” Favret also told me a growing number of Tavus’s customers are building clones for mentorship and even decision-making, like AI loan officers who use clones to qualify and filter applicants.&lt;/p&gt;  &lt;p&gt;Which is sort of the crux of it. Teaching an AI clone discernment, critical thinking, and taste—never mind the quirks of a specific person—is still the stuff of science fiction. That’s all fine when the person chatting with a clone is in on the bit (most of us know that Schwarzenegger’s replica, for example, will not coach me to be a better athlete).&lt;/p&gt;  &lt;p&gt;But as companies polish clones with “human” features and exaggerate their capabilities, I worry that people chasing efficiency will start using their replicas at best for roles that are cringeworthy, and at worst for making decisions they should never be entrusted with. In the end, these models are designed for scale, not fidelity. They can flatter us, amplify us, even sell for us—but they can’t quite become us.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&amp;nbsp;sign up here.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/02/1122856/can-an-ai-doppelganger-help-me-do-my-job/</guid><pubDate>Tue, 02 Sep 2025 09:00:00 +0000</pubDate></item><item><title>How healthcare accelerator programs are changing care (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/02/1122698/how-healthcare-accelerator-programs-are-changing-care/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;Provided by&lt;/span&gt;Mayo Clinic Platform&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;As healthcare faces mounting pressures, from rising costs and an aging population to widening disparities, forward thinking innovations are more essential than ever.&lt;/p&gt;  &lt;p&gt;Accelerator programs have proven to be powerful launchpads for health tech companies, often combining resources, mentorship, and technology that startups otherwise would not have access to. By joining these fast-moving platforms, startups are better able to rapidly innovate, enhance, and scale their healthcare solutions, bringing transformative approaches to hospitals and patients faster.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;So, why are healthcare accelerators becoming essential to the evolution of the industry? There are key reasons why these programs are reshaping health innovation and explanations how they are helping to make care more personalized, proactive, and accessible.&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1122699" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/iStock-2160720116.jpg" /&gt;&lt;/figure&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Empowering growth and scaling impact &lt;/strong&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;Healthcare accelerator programs offer a powerful combination of guidance, resources, and connections to help early-stage startups grow, scale, and succeed in a complex industry.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Participants typically benefit from:&amp;nbsp;&lt;/p&gt;  &lt;ul class="wp-block-list"&gt; &lt;li&gt;Expert mentorship from seasoned healthcare professionals, entrepreneurs, and industry leaders to navigate clinical, regulatory, and business challenges&lt;/li&gt;    &lt;li&gt;Access to valuable resources such as clinical data, testing environments, and technical infrastructure to refine and validate health tech solutions&lt;/li&gt;    &lt;li&gt;Strategic support for growth including investor introductions, partnership opportunities, and go-to-market guidance to expand reach and impact&amp;nbsp;&lt;/li&gt; &lt;/ul&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Speeding up innovation&lt;/strong&gt;&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;Accelerators help startups and early-stage companies bring their solutions to market faster by streamlining the path through one of the most complex industries: healthcare. Traditionally, innovation in this space is slowed by regulatory hurdles, extended sales cycles, clinical validation requirements, and fragmented data systems.&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Through structured support, accelerators help companies refine their product market fit, navigate compliance and regulatory landscapes, integrate with healthcare systems, and gather the clinical evidence needed to build trust and credibility. They also open doors to early pilot opportunities, customer feedback, and strategic partnerships, compressing what could take years into just a few months.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;By removing barriers and accelerating critical early steps, these programs enable digital health innovators to reach the market more efficiently, with stronger solutions and a clearer path to impact.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Connecting startups with key stakeholders&lt;/strong&gt;&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;Today, many accelerator programs are developed by large healthcare organizations that are driving change from within. These accelerator programs are especially beneficial to startups since they have strong partnerships with hospitals, pharma companies, insurance providers, and regulators. This gives startups a chance to validate their ideas in real-world settings, gather clinical feedback early, and scale more effectively.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Many accelerators also bring together people from different fields; doctors, engineers, data scientists, and designers, encouraging fresh perspectives on persistent problems like chronic disease management, preventative care, data interoperability, and patient engagement.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Breaking barriers to global expansion&lt;/strong&gt;&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;Healthcare accelerator programs act as gateways for international digital health companies looking to enter the U.S. market, often considered one of the most complex and highly regulated healthcare landscapes in the world. These programs provide tailored support to navigate U.S. compliance standards, understand payer and provider dynamics, and tailor offerings to meet the needs of U.S. patients and care delivery models.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Through market-specific mentorship, strategic introductions, and access to a robust health innovation ecosystem, accelerators help international startups overcome geographic and regulatory barriers, enabling global ideas to scale and make an impact where they’re needed most.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Building the future of healthcare&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;The role of healthcare accelerator programs extends far beyond startup support. They are helping to redefine how innovation happens, shifting it from isolated efforts to collaborative ecosystems of change. By bridging gaps between early-stage technology and real-world implementation, these programs play a critical role in making healthcare more personalized, preventative, and equitable.&lt;/p&gt;  &lt;p&gt;As the digital transformation of healthcare continues, accelerator programs will remain indispensable in cultivating the next generation of breakthroughs, ensuring that bold ideas are not only born, but brought to life in meaningful, measurable ways.&lt;/p&gt; 

 &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Spotlight: Mayo Clinic Platform_Accelerate&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;One standout example of this innovation-forward approach is Mayo Clinic Platform_Accelerate, a 30-week accelerator program designed to help health tech startups reach market readiness. Participants gain access to de-identified clinical data, prototyping labs, and guidance from experts across clinical, regulatory, and business domains.&lt;/p&gt;  &lt;p&gt;By combining Mayo Clinic’s legacy of clinical excellence with a forward-thinking innovation model, the Mayo Clinic Platform_Accelerate program helps promising startups to refine their solutions and prepare for meaningful scale, transforming how care is delivered across the continuum.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Finding value in accelerator programs&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;In a time when healthcare must evolve faster than ever, accelerator programs have become vital to the industry’s future. By supporting early-stage innovators with the tools, mentorship, and networks they need to succeed, these programs are paving the way for smarter, safer, and more connected care.&lt;/p&gt;  &lt;p&gt;Whether tackling chronic disease, reimagining patient engagement, or unlocking the power of data, the startups nurtured in accelerator programs are helping to shape a more resilient and responsive health system, one innovation at a time.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Mayo Clinic Platform. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;Provided by&lt;/span&gt;Mayo Clinic Platform&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;As healthcare faces mounting pressures, from rising costs and an aging population to widening disparities, forward thinking innovations are more essential than ever.&lt;/p&gt;  &lt;p&gt;Accelerator programs have proven to be powerful launchpads for health tech companies, often combining resources, mentorship, and technology that startups otherwise would not have access to. By joining these fast-moving platforms, startups are better able to rapidly innovate, enhance, and scale their healthcare solutions, bringing transformative approaches to hospitals and patients faster.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;So, why are healthcare accelerators becoming essential to the evolution of the industry? There are key reasons why these programs are reshaping health innovation and explanations how they are helping to make care more personalized, proactive, and accessible.&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1122699" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/iStock-2160720116.jpg" /&gt;&lt;/figure&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Empowering growth and scaling impact &lt;/strong&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;Healthcare accelerator programs offer a powerful combination of guidance, resources, and connections to help early-stage startups grow, scale, and succeed in a complex industry.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Participants typically benefit from:&amp;nbsp;&lt;/p&gt;  &lt;ul class="wp-block-list"&gt; &lt;li&gt;Expert mentorship from seasoned healthcare professionals, entrepreneurs, and industry leaders to navigate clinical, regulatory, and business challenges&lt;/li&gt;    &lt;li&gt;Access to valuable resources such as clinical data, testing environments, and technical infrastructure to refine and validate health tech solutions&lt;/li&gt;    &lt;li&gt;Strategic support for growth including investor introductions, partnership opportunities, and go-to-market guidance to expand reach and impact&amp;nbsp;&lt;/li&gt; &lt;/ul&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Speeding up innovation&lt;/strong&gt;&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;Accelerators help startups and early-stage companies bring their solutions to market faster by streamlining the path through one of the most complex industries: healthcare. Traditionally, innovation in this space is slowed by regulatory hurdles, extended sales cycles, clinical validation requirements, and fragmented data systems.&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Through structured support, accelerators help companies refine their product market fit, navigate compliance and regulatory landscapes, integrate with healthcare systems, and gather the clinical evidence needed to build trust and credibility. They also open doors to early pilot opportunities, customer feedback, and strategic partnerships, compressing what could take years into just a few months.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;By removing barriers and accelerating critical early steps, these programs enable digital health innovators to reach the market more efficiently, with stronger solutions and a clearer path to impact.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Connecting startups with key stakeholders&lt;/strong&gt;&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;Today, many accelerator programs are developed by large healthcare organizations that are driving change from within. These accelerator programs are especially beneficial to startups since they have strong partnerships with hospitals, pharma companies, insurance providers, and regulators. This gives startups a chance to validate their ideas in real-world settings, gather clinical feedback early, and scale more effectively.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Many accelerators also bring together people from different fields; doctors, engineers, data scientists, and designers, encouraging fresh perspectives on persistent problems like chronic disease management, preventative care, data interoperability, and patient engagement.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Breaking barriers to global expansion&lt;/strong&gt;&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;Healthcare accelerator programs act as gateways for international digital health companies looking to enter the U.S. market, often considered one of the most complex and highly regulated healthcare landscapes in the world. These programs provide tailored support to navigate U.S. compliance standards, understand payer and provider dynamics, and tailor offerings to meet the needs of U.S. patients and care delivery models.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Through market-specific mentorship, strategic introductions, and access to a robust health innovation ecosystem, accelerators help international startups overcome geographic and regulatory barriers, enabling global ideas to scale and make an impact where they’re needed most.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Building the future of healthcare&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;The role of healthcare accelerator programs extends far beyond startup support. They are helping to redefine how innovation happens, shifting it from isolated efforts to collaborative ecosystems of change. By bridging gaps between early-stage technology and real-world implementation, these programs play a critical role in making healthcare more personalized, preventative, and equitable.&lt;/p&gt;  &lt;p&gt;As the digital transformation of healthcare continues, accelerator programs will remain indispensable in cultivating the next generation of breakthroughs, ensuring that bold ideas are not only born, but brought to life in meaningful, measurable ways.&lt;/p&gt; 

 &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Spotlight: Mayo Clinic Platform_Accelerate&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;One standout example of this innovation-forward approach is Mayo Clinic Platform_Accelerate, a 30-week accelerator program designed to help health tech startups reach market readiness. Participants gain access to de-identified clinical data, prototyping labs, and guidance from experts across clinical, regulatory, and business domains.&lt;/p&gt;  &lt;p&gt;By combining Mayo Clinic’s legacy of clinical excellence with a forward-thinking innovation model, the Mayo Clinic Platform_Accelerate program helps promising startups to refine their solutions and prepare for meaningful scale, transforming how care is delivered across the continuum.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Finding value in accelerator programs&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;In a time when healthcare must evolve faster than ever, accelerator programs have become vital to the industry’s future. By supporting early-stage innovators with the tools, mentorship, and networks they need to succeed, these programs are paving the way for smarter, safer, and more connected care.&lt;/p&gt;  &lt;p&gt;Whether tackling chronic disease, reimagining patient engagement, or unlocking the power of data, the startups nurtured in accelerator programs are helping to shape a more resilient and responsive health system, one innovation at a time.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Mayo Clinic Platform. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/02/1122698/how-healthcare-accelerator-programs-are-changing-care/</guid><pubDate>Tue, 02 Sep 2025 12:00:00 +0000</pubDate></item><item><title>What health care providers actually want from AI (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/02/1122688/what-health-care-providers-actually-want-from-ai/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;Provided by&lt;/span&gt;Mayo Clinic Platform&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;In a market flooded with AI promises, health care decision-makers are no longer dazzled by flashy demos or abstract potential. &lt;a&gt;Today, they want pragmatic and pressure-tested products.&amp;nbsp;They want solutions that work for their clinicians, staff, patients, and their bottom line.&lt;/p&gt;  &lt;p&gt;To gain traction in 2025 and beyond, health care providers are looking for real-world solutions in AI right now.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1122693" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/iStock-1477482140.jpg" /&gt;&lt;/figure&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Solutions that fix real problems&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Hospitals and health systems are looking at AI-enabled solutions that target their most urgent pain points: staffing shortages, clinician burnout, rising costs, and patient bottlenecks. These operational realities keep leadership up at night, and AI solutions&amp;nbsp; must directly address them.&lt;/p&gt;  &lt;p&gt;For instance, hospitals and health systems are eager for AI tools that can reduce documentation burden for physicians and nurses. Natural language processing (NLP) solutions that auto-generate clinical notes or streamline coding to free up time for direct patient care are far more compelling pitches than generic efficiency gains. Similarly, predictive analytics that help optimize staffing levels or manage patient flows can directly address operational workflow and improve throughput.&lt;/p&gt; 
 &lt;p&gt;Ultimately, if an AI solution doesn’t target these critical issues and deliver tangible benefits, it’s unlikely to capture serious buyer interest.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Demonstrate real-world results &lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;AI solutions need validation in environments that mirror actual care settings. The first step toward that is to leverage high-quality, well-curated real-world data to drive reliable insights and avoid misleading results when building and refining AI models.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Then, hospitals and health systems need evidence that the solution does what it claims to do, for instance through independent-third party validation, pilot projects, peer-reviewed publications, or documented case studies.&lt;/p&gt;  &lt;p&gt;Mayo Clinic Platform offers a rigorous independent process where clinical, data science, and regulatory experts evaluate a solution for intended use, proposed value, and clinical and algorithmic performance, which gives innovators the credibility their solutions need to win the confidence of health-care leaders.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Integration with existing systems&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;With so many demands, health-care IT leaders have little patience for standalone AI tools that create additional complexity. They want solutions that integrate seamlessly into existing systems and workflows. Compatibility with major electronic health record (EHR) platforms, robust APIs, and smooth data ingestion processes are now baseline requirements.&lt;/p&gt;  &lt;p&gt;Custom integrations that require significant IT resources—or worse, create duplicative work—are deal breakers for many organizations already stretched thin. The less disruption an AI solution introduces, the more likely it is to gain traction. This is the reason solution developers are turning to platforms like Mayo Clinic Platform Solutions Studio, a program that provides seamless integration, single implementation, expert guidance to reduce risk, and a simplified process to accelerate solution adoption among healthcare providers.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Explainability and transparency&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;The importance of trust cannot be overstated when it comes to health care, and transparency and explainability are critical to establishing trust in AI. As AI models grow more complex, health-care providers recognize that simply knowing what an algorithm predicts isn’t enough. They also need to understand how it arrived at that insight.&lt;/p&gt;  &lt;p&gt;Health-care organizations are increasingly wary of black-box AI systems whose logic remains opaque. Instead, they’re demanding solutions that offer clear, understandable explanations clinicians can relay confidently to peers, patients, and regulators.&lt;/p&gt;  &lt;p&gt;As McKinsey research shows, organizations that embed explainability into their AI strategy not only reduce risk but also see higher adoption, better performance outcomes, and stronger financial returns. Solution developers that can demystify their models, provide transparent performance metrics, and build trust at every level will have a significant edge in today’s health-care market.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Clear ROI and low implementation burden&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Hospitals and health systems want to know precisely how quickly an AI solution will pay for itself, how much staff time it will save, and what costs it will help offset. The more specific and evidence-backed the answers, the better rate of adoption.&lt;/p&gt; 

 &lt;p&gt;Solution developers that offer comprehensive training and responsive support are far more likely to win deals and keep customers satisfied over the long term.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Alignment with regulatory and compliance needs&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;As AI adoption grows, so does regulatory scrutiny. Health-care providers are increasingly focused on ensuring that any new solution complies with HIPAA, data privacy laws, and emerging guidelines around AI governance and bias mitigation.&lt;/p&gt;  &lt;p&gt;Solution developers that can proactively demonstrate compliance provide significant peace of mind. Transparent data handling practices, rigorous security measures, and alignment with ethical AI principles are all becoming essential selling points as well.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;A solution developer &lt;/strong&gt;&lt;strong&gt;that&lt;/strong&gt;&lt;strong&gt; understands health care&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Finally, it’s not just about the technology. Health-care providers want partners that genuinely understand the complexities of clinical care and hospital operations. They’re looking for partners that speak the language of health care, grasp the nuances of change management, and appreciate the realities of delivering patient care under tight margins and high stakes.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Successful AI vendors recognize that even the best technology must fit into a highly human-centered and often unpredictable environment. Long-term partnerships, not short-term sales, are the goal.&lt;/p&gt;  &lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;Delivering true value with AI&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h2&gt;  &lt;p&gt;To earn their trust and investment, AI developers must focus relentlessly on solving real problems, demonstrating proven results, integrating without friction, and maintaining transparency and compliance.&lt;/p&gt;  &lt;p&gt;Those that deliver on these expectations will have the chance to help shape the future of health care.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Mayo Clinic Platform. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;Provided by&lt;/span&gt;Mayo Clinic Platform&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;In a market flooded with AI promises, health care decision-makers are no longer dazzled by flashy demos or abstract potential. &lt;a&gt;Today, they want pragmatic and pressure-tested products.&amp;nbsp;They want solutions that work for their clinicians, staff, patients, and their bottom line.&lt;/p&gt;  &lt;p&gt;To gain traction in 2025 and beyond, health care providers are looking for real-world solutions in AI right now.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1122693" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/iStock-1477482140.jpg" /&gt;&lt;/figure&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Solutions that fix real problems&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Hospitals and health systems are looking at AI-enabled solutions that target their most urgent pain points: staffing shortages, clinician burnout, rising costs, and patient bottlenecks. These operational realities keep leadership up at night, and AI solutions&amp;nbsp; must directly address them.&lt;/p&gt;  &lt;p&gt;For instance, hospitals and health systems are eager for AI tools that can reduce documentation burden for physicians and nurses. Natural language processing (NLP) solutions that auto-generate clinical notes or streamline coding to free up time for direct patient care are far more compelling pitches than generic efficiency gains. Similarly, predictive analytics that help optimize staffing levels or manage patient flows can directly address operational workflow and improve throughput.&lt;/p&gt; 
 &lt;p&gt;Ultimately, if an AI solution doesn’t target these critical issues and deliver tangible benefits, it’s unlikely to capture serious buyer interest.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Demonstrate real-world results &lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;AI solutions need validation in environments that mirror actual care settings. The first step toward that is to leverage high-quality, well-curated real-world data to drive reliable insights and avoid misleading results when building and refining AI models.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Then, hospitals and health systems need evidence that the solution does what it claims to do, for instance through independent-third party validation, pilot projects, peer-reviewed publications, or documented case studies.&lt;/p&gt;  &lt;p&gt;Mayo Clinic Platform offers a rigorous independent process where clinical, data science, and regulatory experts evaluate a solution for intended use, proposed value, and clinical and algorithmic performance, which gives innovators the credibility their solutions need to win the confidence of health-care leaders.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Integration with existing systems&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;With so many demands, health-care IT leaders have little patience for standalone AI tools that create additional complexity. They want solutions that integrate seamlessly into existing systems and workflows. Compatibility with major electronic health record (EHR) platforms, robust APIs, and smooth data ingestion processes are now baseline requirements.&lt;/p&gt;  &lt;p&gt;Custom integrations that require significant IT resources—or worse, create duplicative work—are deal breakers for many organizations already stretched thin. The less disruption an AI solution introduces, the more likely it is to gain traction. This is the reason solution developers are turning to platforms like Mayo Clinic Platform Solutions Studio, a program that provides seamless integration, single implementation, expert guidance to reduce risk, and a simplified process to accelerate solution adoption among healthcare providers.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Explainability and transparency&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;The importance of trust cannot be overstated when it comes to health care, and transparency and explainability are critical to establishing trust in AI. As AI models grow more complex, health-care providers recognize that simply knowing what an algorithm predicts isn’t enough. They also need to understand how it arrived at that insight.&lt;/p&gt;  &lt;p&gt;Health-care organizations are increasingly wary of black-box AI systems whose logic remains opaque. Instead, they’re demanding solutions that offer clear, understandable explanations clinicians can relay confidently to peers, patients, and regulators.&lt;/p&gt;  &lt;p&gt;As McKinsey research shows, organizations that embed explainability into their AI strategy not only reduce risk but also see higher adoption, better performance outcomes, and stronger financial returns. Solution developers that can demystify their models, provide transparent performance metrics, and build trust at every level will have a significant edge in today’s health-care market.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Clear ROI and low implementation burden&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Hospitals and health systems want to know precisely how quickly an AI solution will pay for itself, how much staff time it will save, and what costs it will help offset. The more specific and evidence-backed the answers, the better rate of adoption.&lt;/p&gt; 

 &lt;p&gt;Solution developers that offer comprehensive training and responsive support are far more likely to win deals and keep customers satisfied over the long term.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Alignment with regulatory and compliance needs&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;As AI adoption grows, so does regulatory scrutiny. Health-care providers are increasingly focused on ensuring that any new solution complies with HIPAA, data privacy laws, and emerging guidelines around AI governance and bias mitigation.&lt;/p&gt;  &lt;p&gt;Solution developers that can proactively demonstrate compliance provide significant peace of mind. Transparent data handling practices, rigorous security measures, and alignment with ethical AI principles are all becoming essential selling points as well.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;A solution developer &lt;/strong&gt;&lt;strong&gt;that&lt;/strong&gt;&lt;strong&gt; understands health care&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Finally, it’s not just about the technology. Health-care providers want partners that genuinely understand the complexities of clinical care and hospital operations. They’re looking for partners that speak the language of health care, grasp the nuances of change management, and appreciate the realities of delivering patient care under tight margins and high stakes.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Successful AI vendors recognize that even the best technology must fit into a highly human-centered and often unpredictable environment. Long-term partnerships, not short-term sales, are the goal.&lt;/p&gt;  &lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;Delivering true value with AI&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h2&gt;  &lt;p&gt;To earn their trust and investment, AI developers must focus relentlessly on solving real problems, demonstrating proven results, integrating without friction, and maintaining transparency and compliance.&lt;/p&gt;  &lt;p&gt;Those that deliver on these expectations will have the chance to help shape the future of health care.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Mayo Clinic Platform. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/02/1122688/what-health-care-providers-actually-want-from-ai/</guid><pubDate>Tue, 02 Sep 2025 12:00:00 +0000</pubDate></item><item><title>The Download: therapists secretly using AI, and Apple AirPods’ hearing aid potential (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/02/1122877/the-download-therapists-secretly-using-ai-and-apple-airpods-hearing-aid-potential/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Therapists are secretly using ChatGPT. Clients are triggered.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Declan would never have found out his therapist was using ChatGPT had it not been for a technical mishap. The connection was patchy during one of their online sessions, so Declan suggested they turn off their video feeds. Instead, his therapist began inadvertently sharing his screen.&lt;/p&gt;&lt;p&gt;For the rest of the session, Declan was privy to a real-time stream of ChatGPT analysis rippling across his therapist’s screen, who was taking what Declan was saying, putting it into ChatGPT, and then parroting its answers.&lt;/p&gt;  &lt;p&gt;But Declan is not alone. In fact, a growing number of people are reporting receiving AI-generated communiqués from their therapists. Clients’ trust and privacy are being abandoned in the process. Read the full story.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Laurie Clarke&lt;/em&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Apple AirPods: a gateway hearing aid&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Ashley Shew&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;When the US Food and Drug Administration approved hearing-aid software for Apple’s AirPods Pro in September 2024, with a device price point around $200, I was excited.&lt;/p&gt;&lt;p&gt;I have hearing loss and tinnitus, and my everyday hearing aids cost just over $2,000. Ninety percent of the hearing-aid market is concentrated in the hands of a few companies, and there’s little competitive pricing. So I was thrilled that a major tech company has entered this field with the AirPods Pro 2. Here’s what I made of them.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story is from our new print edition, which is all about the future of security. &lt;/strong&gt;&lt;strong&gt;Subscribe here&lt;/strong&gt;&lt;strong&gt; to catch future copies when they land.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 MAHA is in chaos&lt;/strong&gt;&lt;br /&gt;RFK Jr’s movement is tearing itself apart over what it wants to achieve. (WSJ $)&lt;br /&gt;+ &lt;em&gt;Trying to pressure food companies to alter their products is unlikely to work. &lt;/em&gt;(The Atlantic $)&lt;br /&gt;+ &lt;em&gt;Ultra-processed food makes up a sizable proportion of the American diet. &lt;/em&gt;(Axios)&lt;br /&gt;+ &lt;em&gt;RFK Jr’s plan to improve America’s diet is missing the point. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 DOGE is using AI to target SEC rules to ditch&lt;/strong&gt;&lt;br /&gt;Experts fear its decisions won’t be checked by qualified humans. (The Information $)&lt;br /&gt;+ &lt;em&gt;Can AI help DOGE slash government budgets? It’s complex. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;3 Salesforce has replaced around 4,000 jobs with AI agents&lt;/strong&gt;&lt;br /&gt;It’s slashed its support staff team nearly in half. (SF Chronicle $)&lt;br /&gt;+ &lt;em&gt;Workers are trying to weather the AI-induced storm. &lt;/em&gt;(Vox)&lt;br /&gt;+ &lt;em&gt;AI is coming for the job market, security, and prosperity. &lt;/em&gt;(MIT Technology Review)&lt;br /&gt;&lt;strong&gt;&lt;br /&gt;4 What’s up with China’s EV industry?&lt;br /&gt;&lt;/strong&gt;Its cutthroat competitive practices are starting to grate on the government. (NYT $)&lt;br /&gt;+ &lt;em&gt;The country’s robotmakers are on the rise. &lt;/em&gt;(FT $)&lt;br /&gt;+ &lt;em&gt;China’s EV giants are betting big on humanoid robots. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 A “nearly naked” black hole has been spotted&lt;/strong&gt;&lt;br /&gt;The never-before-seen black hole may have been created moments after the big bang. (The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 How to make quantum computers useful&lt;br /&gt;&lt;/strong&gt;Researchers have turned their attention towards making software for the machines. (FT $)&lt;br /&gt;+ &lt;em&gt;Why AI could eat quantum computing’s lunch. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 OnlyFans has a piracy problem&lt;br /&gt;&lt;/strong&gt;Adult creators’ content isn’t staying behind the paywall. (404 Media)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;8 These humans are paid to fix AI slop&lt;/strong&gt;&lt;br /&gt;Anyone can prompt AI, but the results aren’t always good. (NBC News)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 The hottest gadget for kids is a landline phone&lt;/strong&gt;&amp;nbsp;&lt;br /&gt;And they’re learning phone etiquette for the first time. (Insider $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 Meet iTunes’ diehard fans&lt;/strong&gt;&lt;br /&gt;They’re eschewing streaming platforms in favor of their digital libraries. (WP $)&lt;br /&gt;+ &lt;em&gt;How to break free of Spotify’s algorithm. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“The calculator doesn’t construct facts about world knowledge and give them to you.”&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;—Elisha Roberts, assistant director at the nonprofit Colorado Education Initiative, tells Bloomberg she doesn’t buy the idea that AI is comparable to other classroom tools like the calculator.&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" src="https://wp.technologyreview.com/wp-content/uploads/2024/06/1.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Supershoes are reshaping distance running&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Since 2016, when Nike introduced the Vaporfly, a paradigm-­shifting shoe that helped athletes run more efficiently (and therefore faster), the elite running world has muddled through a period of soul-searching over the impact of high-tech footwear on the sport.&lt;/p&gt;&lt;p&gt;“Supershoes” —which combine a lightweight, energy-­returning foam with a carbon-fiber plate for stiffness—have been behind every broken world record in distances from 5,000 meters to the marathon since 2020.&lt;/p&gt;&lt;p&gt;To some, this is a sign of progress. In much of the world, elite running lacks a widespread following. Record-breaking adds a layer of excitement. And the shoes have benefits beyond the clock: most important, they help minimize wear on the body and enable faster recovery from hard workouts and races.&lt;/p&gt;&lt;p&gt;Still, some argue that they’ve changed the sport too quickly. Read the full story.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Jonathan W. Rosen&lt;/em&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ Happy birthday to Keanu Reeves, who turns 61 today! Here’s a compilation of his hilariously bad acting in Bram Stroker’s Dracula.&lt;br /&gt;+ Why do some cats hate water, yet others love it?&lt;br /&gt;+ If you fancy setting a Guinness World Record, there’s a few still up for grabs.&lt;br /&gt;+ To mark world coconut day (what do you mean, you forgot?), check out these delicious-looking recipes 🥥&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Therapists are secretly using ChatGPT. Clients are triggered.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Declan would never have found out his therapist was using ChatGPT had it not been for a technical mishap. The connection was patchy during one of their online sessions, so Declan suggested they turn off their video feeds. Instead, his therapist began inadvertently sharing his screen.&lt;/p&gt;&lt;p&gt;For the rest of the session, Declan was privy to a real-time stream of ChatGPT analysis rippling across his therapist’s screen, who was taking what Declan was saying, putting it into ChatGPT, and then parroting its answers.&lt;/p&gt;  &lt;p&gt;But Declan is not alone. In fact, a growing number of people are reporting receiving AI-generated communiqués from their therapists. Clients’ trust and privacy are being abandoned in the process. Read the full story.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Laurie Clarke&lt;/em&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Apple AirPods: a gateway hearing aid&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Ashley Shew&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;When the US Food and Drug Administration approved hearing-aid software for Apple’s AirPods Pro in September 2024, with a device price point around $200, I was excited.&lt;/p&gt;&lt;p&gt;I have hearing loss and tinnitus, and my everyday hearing aids cost just over $2,000. Ninety percent of the hearing-aid market is concentrated in the hands of a few companies, and there’s little competitive pricing. So I was thrilled that a major tech company has entered this field with the AirPods Pro 2. Here’s what I made of them.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story is from our new print edition, which is all about the future of security. &lt;/strong&gt;&lt;strong&gt;Subscribe here&lt;/strong&gt;&lt;strong&gt; to catch future copies when they land.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 MAHA is in chaos&lt;/strong&gt;&lt;br /&gt;RFK Jr’s movement is tearing itself apart over what it wants to achieve. (WSJ $)&lt;br /&gt;+ &lt;em&gt;Trying to pressure food companies to alter their products is unlikely to work. &lt;/em&gt;(The Atlantic $)&lt;br /&gt;+ &lt;em&gt;Ultra-processed food makes up a sizable proportion of the American diet. &lt;/em&gt;(Axios)&lt;br /&gt;+ &lt;em&gt;RFK Jr’s plan to improve America’s diet is missing the point. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 DOGE is using AI to target SEC rules to ditch&lt;/strong&gt;&lt;br /&gt;Experts fear its decisions won’t be checked by qualified humans. (The Information $)&lt;br /&gt;+ &lt;em&gt;Can AI help DOGE slash government budgets? It’s complex. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;3 Salesforce has replaced around 4,000 jobs with AI agents&lt;/strong&gt;&lt;br /&gt;It’s slashed its support staff team nearly in half. (SF Chronicle $)&lt;br /&gt;+ &lt;em&gt;Workers are trying to weather the AI-induced storm. &lt;/em&gt;(Vox)&lt;br /&gt;+ &lt;em&gt;AI is coming for the job market, security, and prosperity. &lt;/em&gt;(MIT Technology Review)&lt;br /&gt;&lt;strong&gt;&lt;br /&gt;4 What’s up with China’s EV industry?&lt;br /&gt;&lt;/strong&gt;Its cutthroat competitive practices are starting to grate on the government. (NYT $)&lt;br /&gt;+ &lt;em&gt;The country’s robotmakers are on the rise. &lt;/em&gt;(FT $)&lt;br /&gt;+ &lt;em&gt;China’s EV giants are betting big on humanoid robots. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 A “nearly naked” black hole has been spotted&lt;/strong&gt;&lt;br /&gt;The never-before-seen black hole may have been created moments after the big bang. (The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 How to make quantum computers useful&lt;br /&gt;&lt;/strong&gt;Researchers have turned their attention towards making software for the machines. (FT $)&lt;br /&gt;+ &lt;em&gt;Why AI could eat quantum computing’s lunch. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 OnlyFans has a piracy problem&lt;br /&gt;&lt;/strong&gt;Adult creators’ content isn’t staying behind the paywall. (404 Media)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;8 These humans are paid to fix AI slop&lt;/strong&gt;&lt;br /&gt;Anyone can prompt AI, but the results aren’t always good. (NBC News)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 The hottest gadget for kids is a landline phone&lt;/strong&gt;&amp;nbsp;&lt;br /&gt;And they’re learning phone etiquette for the first time. (Insider $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 Meet iTunes’ diehard fans&lt;/strong&gt;&lt;br /&gt;They’re eschewing streaming platforms in favor of their digital libraries. (WP $)&lt;br /&gt;+ &lt;em&gt;How to break free of Spotify’s algorithm. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“The calculator doesn’t construct facts about world knowledge and give them to you.”&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;—Elisha Roberts, assistant director at the nonprofit Colorado Education Initiative, tells Bloomberg she doesn’t buy the idea that AI is comparable to other classroom tools like the calculator.&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" src="https://wp.technologyreview.com/wp-content/uploads/2024/06/1.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Supershoes are reshaping distance running&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Since 2016, when Nike introduced the Vaporfly, a paradigm-­shifting shoe that helped athletes run more efficiently (and therefore faster), the elite running world has muddled through a period of soul-searching over the impact of high-tech footwear on the sport.&lt;/p&gt;&lt;p&gt;“Supershoes” —which combine a lightweight, energy-­returning foam with a carbon-fiber plate for stiffness—have been behind every broken world record in distances from 5,000 meters to the marathon since 2020.&lt;/p&gt;&lt;p&gt;To some, this is a sign of progress. In much of the world, elite running lacks a widespread following. Record-breaking adds a layer of excitement. And the shoes have benefits beyond the clock: most important, they help minimize wear on the body and enable faster recovery from hard workouts and races.&lt;/p&gt;&lt;p&gt;Still, some argue that they’ve changed the sport too quickly. Read the full story.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Jonathan W. Rosen&lt;/em&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ Happy birthday to Keanu Reeves, who turns 61 today! Here’s a compilation of his hilariously bad acting in Bram Stroker’s Dracula.&lt;br /&gt;+ Why do some cats hate water, yet others love it?&lt;br /&gt;+ If you fancy setting a Guinness World Record, there’s a few still up for grabs.&lt;br /&gt;+ To mark world coconut day (what do you mean, you forgot?), check out these delicious-looking recipes 🥥&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/02/1122877/the-download-therapists-secretly-using-ai-and-apple-airpods-hearing-aid-potential/</guid><pubDate>Tue, 02 Sep 2025 12:10:00 +0000</pubDate></item><item><title>[NEW] It’s the Humidity: How International Researchers in Poland, Deep Learning and NVIDIA GPUs Could Change the Forecast (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/humidity/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/IMG_7538-scaled.jpeg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;For more than a century, meteorologists have chased storms with chalkboards, equations, and now, supercomputers. But for all the progress, they still stumble over one deceptively simple ingredient: water vapor.&lt;/p&gt;
&lt;p&gt;Humidity is the invisible fuel for thunderstorms, flash floods, and hurricanes. It’s the difference between a passing sprinkle and a summer downpour that sends you sprinting for cover. And until now, satellites have struggled to capture it with the detail needed to warn us before skies crack open.&lt;/p&gt;
&lt;p&gt;A team from the Wrocław University of Environmental and Life Sciences (UPWr) may help change that. In a paper published this month in &lt;i&gt;Satellite Navigation&lt;/i&gt;, researchers describe how deep learning can transform blurry global navigation satellite system (GNSS)-based snapshots of the atmosphere into sharp 3D maps of humidity, revealing the hidden swirls that shape local weather.&lt;/p&gt;
&lt;p&gt;The secret? A super-resolution generative adversarial network (SRGAN), a kind of AI best known for making grainy photos look crisp. Instead of celebrities or landscapes, researchers trained the network on global weather data and powered by NVIDIA GPUs. The result: low-resolution readings from navigation satellites get “upscaled” into high-resolution humidity maps with far fewer errors.&lt;/p&gt;
&lt;p&gt;In Poland, the technique cuts errors by 62%. In California, it delivers a 52% cut in errors, even in rainy conditions when forecasts are most likely to get slippery. Compared with older methods that smeared details into a watercolor blur, the AI produced sharp gradients that actually matched what ground instruments saw.&lt;/p&gt;
&lt;p&gt;And because weather prediction is as much about trust as accuracy, the team added a twist: explainable AI. Using visualization tools like Grad-CAM and SHAP, they demonstrated where the model “looked” when making decisions. The AI’s gaze landed, reassuringly, on storm-prone areas — Poland’s western borders, California’s coastal mountains — exactly where forecasters know the atmosphere can turn nasty.&lt;/p&gt;
&lt;p&gt;“High-resolution, reliable humidity data is the missing link in forecasting the kind of weather that disrupts lives,” said lead author Saeid Haji-Aghajany, assistant professor at&amp;nbsp; UPWr. “Our approach doesn’t just sharpen GNSS tomography — it also shows us how the model makes its decisions. That transparency is critical for building trust as AI enters weather forecasting.”&lt;/p&gt;
&lt;p&gt;The implications could be enormous. Feed these sharper humidity fields into physics-based or AI-driven weather models, and you get forecasts that can catch sudden downpours or flash floods before they hit. Communities living under skies that turn dangerous in minutes could gain crucial lead time.&lt;/p&gt;
&lt;p&gt;And it all hinges on an element that too often gets ignored. Not the thunder. Not the lightning. It’s the humidity.&lt;/p&gt;
&lt;p&gt;Reference: DOI: 10.1186/s43020-025-00177-6&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/IMG_7538-scaled.jpeg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;For more than a century, meteorologists have chased storms with chalkboards, equations, and now, supercomputers. But for all the progress, they still stumble over one deceptively simple ingredient: water vapor.&lt;/p&gt;
&lt;p&gt;Humidity is the invisible fuel for thunderstorms, flash floods, and hurricanes. It’s the difference between a passing sprinkle and a summer downpour that sends you sprinting for cover. And until now, satellites have struggled to capture it with the detail needed to warn us before skies crack open.&lt;/p&gt;
&lt;p&gt;A team from the Wrocław University of Environmental and Life Sciences (UPWr) may help change that. In a paper published this month in &lt;i&gt;Satellite Navigation&lt;/i&gt;, researchers describe how deep learning can transform blurry global navigation satellite system (GNSS)-based snapshots of the atmosphere into sharp 3D maps of humidity, revealing the hidden swirls that shape local weather.&lt;/p&gt;
&lt;p&gt;The secret? A super-resolution generative adversarial network (SRGAN), a kind of AI best known for making grainy photos look crisp. Instead of celebrities or landscapes, researchers trained the network on global weather data and powered by NVIDIA GPUs. The result: low-resolution readings from navigation satellites get “upscaled” into high-resolution humidity maps with far fewer errors.&lt;/p&gt;
&lt;p&gt;In Poland, the technique cuts errors by 62%. In California, it delivers a 52% cut in errors, even in rainy conditions when forecasts are most likely to get slippery. Compared with older methods that smeared details into a watercolor blur, the AI produced sharp gradients that actually matched what ground instruments saw.&lt;/p&gt;
&lt;p&gt;And because weather prediction is as much about trust as accuracy, the team added a twist: explainable AI. Using visualization tools like Grad-CAM and SHAP, they demonstrated where the model “looked” when making decisions. The AI’s gaze landed, reassuringly, on storm-prone areas — Poland’s western borders, California’s coastal mountains — exactly where forecasters know the atmosphere can turn nasty.&lt;/p&gt;
&lt;p&gt;“High-resolution, reliable humidity data is the missing link in forecasting the kind of weather that disrupts lives,” said lead author Saeid Haji-Aghajany, assistant professor at&amp;nbsp; UPWr. “Our approach doesn’t just sharpen GNSS tomography — it also shows us how the model makes its decisions. That transparency is critical for building trust as AI enters weather forecasting.”&lt;/p&gt;
&lt;p&gt;The implications could be enormous. Feed these sharper humidity fields into physics-based or AI-driven weather models, and you get forecasts that can catch sudden downpours or flash floods before they hit. Communities living under skies that turn dangerous in minutes could gain crucial lead time.&lt;/p&gt;
&lt;p&gt;And it all hinges on an element that too often gets ignored. Not the thunder. Not the lightning. It’s the humidity.&lt;/p&gt;
&lt;p&gt;Reference: DOI: 10.1186/s43020-025-00177-6&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/humidity/</guid><pubDate>Tue, 02 Sep 2025 13:00:15 +0000</pubDate></item><item><title>[NEW] Just 4 days left to exhibit at TechCrunch Disrupt 2025 — 10 tables remain (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/02/just-4-days-left-to-exhibit-at-techcrunch-disrupt-2025-10-tables-remain/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The clock is ticking, and exhibit space at &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; is filling up fast. With just &lt;strong&gt;4 days left&lt;/strong&gt; to book your table, now’s the time to stop circling the idea and claim your spot on the show floor.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Only 10 tables remain&lt;/strong&gt; — and once they’re gone, they’re gone. No waitlist. No last-minute add-ons.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Disrupt draws over &lt;strong&gt;10,000 startup and VC leaders&lt;/strong&gt;, and the &lt;strong&gt;exhibit floor&lt;/strong&gt; is where some of the biggest conversations begin. If you’ve got a killer product, a bold vision, or early traction, and you’re ready to scale, then this is your platform.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2024 exhibitor" class="wp-image-3040886" height="469" src="https://techcrunch.com/wp-content/uploads/2025/08/polygraf2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Silkroad &lt;span class="screen-reader-text"&gt;(opens in a new window)&lt;/span&gt;&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-here-s-what-your-table-unlocks"&gt;Here’s what your table unlocks&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Prime placement in front of the biggest names in venture, media, and tech&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;A dedicated listing on the Disrupt website, event app, on-site signage, and a shout-out to TechCrunch readers&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;10 passes to the full event — perfect for team networking or joining interactive sessions with tech leaders&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;And many more benefits&lt;/strong&gt; that are designed to help you scale your startup and strengthen your brand&lt;/li&gt;
&lt;/ul&gt;

&lt;p class="wp-block-paragraph"&gt;You’ve got just a few days to decide: Are you showing up, or watching from the sidelines?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;&lt;em&gt;Secure your table&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;&lt;strong&gt; before the September 5 deadline!&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 no anniversary" class="wp-image-3040972" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_Disrupt_General_Article_No-Anniversary-at-all_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The clock is ticking, and exhibit space at &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; is filling up fast. With just &lt;strong&gt;4 days left&lt;/strong&gt; to book your table, now’s the time to stop circling the idea and claim your spot on the show floor.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Only 10 tables remain&lt;/strong&gt; — and once they’re gone, they’re gone. No waitlist. No last-minute add-ons.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Disrupt draws over &lt;strong&gt;10,000 startup and VC leaders&lt;/strong&gt;, and the &lt;strong&gt;exhibit floor&lt;/strong&gt; is where some of the biggest conversations begin. If you’ve got a killer product, a bold vision, or early traction, and you’re ready to scale, then this is your platform.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2024 exhibitor" class="wp-image-3040886" height="469" src="https://techcrunch.com/wp-content/uploads/2025/08/polygraf2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Silkroad &lt;span class="screen-reader-text"&gt;(opens in a new window)&lt;/span&gt;&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-here-s-what-your-table-unlocks"&gt;Here’s what your table unlocks&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Prime placement in front of the biggest names in venture, media, and tech&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;A dedicated listing on the Disrupt website, event app, on-site signage, and a shout-out to TechCrunch readers&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;10 passes to the full event — perfect for team networking or joining interactive sessions with tech leaders&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;And many more benefits&lt;/strong&gt; that are designed to help you scale your startup and strengthen your brand&lt;/li&gt;
&lt;/ul&gt;

&lt;p class="wp-block-paragraph"&gt;You’ve got just a few days to decide: Are you showing up, or watching from the sidelines?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;&lt;em&gt;Secure your table&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;&lt;strong&gt; before the September 5 deadline!&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 no anniversary" class="wp-image-3040972" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_Disrupt_General_Article_No-Anniversary-at-all_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/02/just-4-days-left-to-exhibit-at-techcrunch-disrupt-2025-10-tables-remain/</guid><pubDate>Tue, 02 Sep 2025 14:00:00 +0000</pubDate></item><item><title>[NEW] Microsoft gives free Copilot AI services to US government workers (AI News)</title><link>https://www.artificialintelligence-news.com/news/microsoft-gives-free-copilot-ai-services-to-us-government-workers/</link><description>&lt;p&gt;Millions of US federal government workers are about to get a new AI assistant on their devices for free in the form of Microsoft Copilot. The move is part of a deal between Microsoft and the US General Services Administration (GSA) that’s also expected to save taxpayers $3.1 billion in its first year.&lt;/p&gt;&lt;p&gt;The centrepiece of this huge new agreement is a full year of Microsoft 365 Copilot at no extra cost for government workers using the high-security G5 licence. This is a push to get the latest AI tools into the hands of public servants quickly and safely, aiming to improve how the government operates.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-microsoft-pushes-the-us-government-into-the-ai-era"&gt;Microsoft pushes the US government into the AI era&lt;/h3&gt;&lt;p&gt;This deal aims to place the US government at the forefront of AI adoption. It’s a direct response to the administration’s AI Action Plan, designed to bring the power of modern artificial intelligence to everything from managing citizen enquiries to analysing complex data.&lt;/p&gt;&lt;p&gt;“OneGov represents a paradigm shift in federal procurement that is leading to immense cost savings, achieved by leveraging the purchasing power of the entire federal government,” explained FAS Commissioner Josh Gruenbaum.&lt;/p&gt;&lt;p&gt;The free Copilot offer is specifically for users on the Microsoft 365 G5 plan, the premium tier for departments that handle sensitive information and require the tightest security protocols. But the benefits extend further, with the deal helping agencies to use AI for automating routine tasks, freeing up people to focus on the work that matters most.&lt;/p&gt;&lt;p&gt;The agreement also makes it cheaper and easier for different departments to modernise their technology. By offering big discounts on Azure cloud services and getting rid of data transfer fees, it tackles a major headache that has often slowed down collaboration between agencies.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-security-is-not-an-afterthought"&gt;Security is not an afterthought&lt;/h3&gt;&lt;p&gt;Of course, giving AI access to government systems raises immediate security questions. The deal addresses this head-on, with Microsoft emphasising that its core cloud and AI services have already passed FedRAMP High security authorisation, a critical standard for handling sensitive government data.&lt;/p&gt;&lt;p&gt;While the full FedRAMP High certification for Copilot itself is expected soon, it has already been given a provisional green light by the Department of Defense. The package also includes advanced security tools like Microsoft Sentinel and Entra ID to support the government’s “zero trust” security goal.&lt;/p&gt;&lt;p&gt;GSA Deputy Administrator Stephen Ehikian strongly encouraged government agencies to take advantage of the new tools.&lt;/p&gt;&lt;p&gt;“GSA is proud to partner with technology companies, like Microsoft, to advance AI adoption across the federal government, a key priority of the Trump Administration,” said Ehikian. “We urge our federal partners to leverage these agreements, providing government workers with transformative AI tools that streamline operations, cut costs, and enhance results.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-helping-government-agencies-to-use-ai-effectively"&gt;Helping government agencies to use AI effectively&lt;/h3&gt;&lt;p&gt;Microsoft is also putting money into making sure the technology is actually used effectively. The company has committed an extra $20 million for support and training, including workshops to help agencies get the most out of the new tools and find other areas to reduce waste.&lt;/p&gt;&lt;p&gt;All told, the package is estimated to deliver more than $6 billion in value over the next three years.&lt;/p&gt;&lt;p&gt;“With this new agreement with the US General Services Administration, including a no-cost Microsoft 365 Copilot offer, we will help federal agencies use AI and digital technologies to improve citizen services, strengthen security, and save taxpayers more than $3 billion in the first year alone,” commented Satya Nadella, Chairman and CEO of Microsoft.&lt;/p&gt;&lt;figure class="wp-block-embed aligncenter is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;&lt;blockquote class="cmplz-placeholder-element twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;For more than four decades, Microsoft has&amp;nbsp;partnered&amp;nbsp;with&amp;nbsp;the U.S.&amp;nbsp;Government to serve the American people. From modernizing IT infrastructure to advancing cybersecurity, our partnership has always been rooted in trust, innovation, and shared purpose.&lt;/p&gt;&lt;p&gt;Today, we are building on…&lt;/p&gt;— Satya Nadella (@satyanadella) September 2, 2025&lt;/blockquote&gt;&lt;/div&gt;&lt;/figure&gt;&lt;p&gt;For the millions of people working within the US government, this agreement with Microsoft means that an AI-powered assistant is set to change their daily work.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Marketing AI boom faces crisis of consumer trust&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for the AI &amp;amp; Big Data Expo event series." class="wp-image-109137" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Millions of US federal government workers are about to get a new AI assistant on their devices for free in the form of Microsoft Copilot. The move is part of a deal between Microsoft and the US General Services Administration (GSA) that’s also expected to save taxpayers $3.1 billion in its first year.&lt;/p&gt;&lt;p&gt;The centrepiece of this huge new agreement is a full year of Microsoft 365 Copilot at no extra cost for government workers using the high-security G5 licence. This is a push to get the latest AI tools into the hands of public servants quickly and safely, aiming to improve how the government operates.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-microsoft-pushes-the-us-government-into-the-ai-era"&gt;Microsoft pushes the US government into the AI era&lt;/h3&gt;&lt;p&gt;This deal aims to place the US government at the forefront of AI adoption. It’s a direct response to the administration’s AI Action Plan, designed to bring the power of modern artificial intelligence to everything from managing citizen enquiries to analysing complex data.&lt;/p&gt;&lt;p&gt;“OneGov represents a paradigm shift in federal procurement that is leading to immense cost savings, achieved by leveraging the purchasing power of the entire federal government,” explained FAS Commissioner Josh Gruenbaum.&lt;/p&gt;&lt;p&gt;The free Copilot offer is specifically for users on the Microsoft 365 G5 plan, the premium tier for departments that handle sensitive information and require the tightest security protocols. But the benefits extend further, with the deal helping agencies to use AI for automating routine tasks, freeing up people to focus on the work that matters most.&lt;/p&gt;&lt;p&gt;The agreement also makes it cheaper and easier for different departments to modernise their technology. By offering big discounts on Azure cloud services and getting rid of data transfer fees, it tackles a major headache that has often slowed down collaboration between agencies.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-security-is-not-an-afterthought"&gt;Security is not an afterthought&lt;/h3&gt;&lt;p&gt;Of course, giving AI access to government systems raises immediate security questions. The deal addresses this head-on, with Microsoft emphasising that its core cloud and AI services have already passed FedRAMP High security authorisation, a critical standard for handling sensitive government data.&lt;/p&gt;&lt;p&gt;While the full FedRAMP High certification for Copilot itself is expected soon, it has already been given a provisional green light by the Department of Defense. The package also includes advanced security tools like Microsoft Sentinel and Entra ID to support the government’s “zero trust” security goal.&lt;/p&gt;&lt;p&gt;GSA Deputy Administrator Stephen Ehikian strongly encouraged government agencies to take advantage of the new tools.&lt;/p&gt;&lt;p&gt;“GSA is proud to partner with technology companies, like Microsoft, to advance AI adoption across the federal government, a key priority of the Trump Administration,” said Ehikian. “We urge our federal partners to leverage these agreements, providing government workers with transformative AI tools that streamline operations, cut costs, and enhance results.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-helping-government-agencies-to-use-ai-effectively"&gt;Helping government agencies to use AI effectively&lt;/h3&gt;&lt;p&gt;Microsoft is also putting money into making sure the technology is actually used effectively. The company has committed an extra $20 million for support and training, including workshops to help agencies get the most out of the new tools and find other areas to reduce waste.&lt;/p&gt;&lt;p&gt;All told, the package is estimated to deliver more than $6 billion in value over the next three years.&lt;/p&gt;&lt;p&gt;“With this new agreement with the US General Services Administration, including a no-cost Microsoft 365 Copilot offer, we will help federal agencies use AI and digital technologies to improve citizen services, strengthen security, and save taxpayers more than $3 billion in the first year alone,” commented Satya Nadella, Chairman and CEO of Microsoft.&lt;/p&gt;&lt;figure class="wp-block-embed aligncenter is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;&lt;blockquote class="cmplz-placeholder-element twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;For more than four decades, Microsoft has&amp;nbsp;partnered&amp;nbsp;with&amp;nbsp;the U.S.&amp;nbsp;Government to serve the American people. From modernizing IT infrastructure to advancing cybersecurity, our partnership has always been rooted in trust, innovation, and shared purpose.&lt;/p&gt;&lt;p&gt;Today, we are building on…&lt;/p&gt;— Satya Nadella (@satyanadella) September 2, 2025&lt;/blockquote&gt;&lt;/div&gt;&lt;/figure&gt;&lt;p&gt;For the millions of people working within the US government, this agreement with Microsoft means that an AI-powered assistant is set to change their daily work.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Marketing AI boom faces crisis of consumer trust&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for the AI &amp;amp; Big Data Expo event series." class="wp-image-109137" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/microsoft-gives-free-copilot-ai-services-to-us-government-workers/</guid><pubDate>Tue, 02 Sep 2025 14:22:42 +0000</pubDate></item><item><title>[NEW] OpenAI to route sensitive conversations to GPT-5, introduce parental controls (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/02/openai-to-route-sensitive-conversations-to-gpt-5-introduce-parental-controls/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-1922977290.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI said Tuesday it plans to route sensitive conversations to reasoning models like GPT-5 and roll out parental controls within the next month — part of an ongoing response to recent safety incidents involving ChatGPT failing to detect mental distress.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new guardrails come in the aftermath of the suicide of teenager Adam Raine, who discussed self-harm and plans to end his life with ChatGPT, which even supplied him with information about specific suicide methods. Raine’s parents have filed a wrongful death lawsuit against OpenAI.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In a blog post last week, OpenAI acknowledged shortcomings in its safety systems, including failures to maintain guardrails during extended conversations. Experts attribute these issues to fundamental design elements: the models’ tendency to validate user statements and their next-word prediction algorithms, which cause chatbots to follow conversational threads rather than redirect potentially harmful discussions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That tendency is displayed in the extreme in the case of Stein-Erik Soelberg, whose murder-suicide was reported on by The Wall Street Journal over the weekend. Soelberg, who had a history of mental illness, used ChatGPT to validate and fuel his paranoia that he was being targeted in a grand conspiracy. His delusions progressed so badly that he ended up killing his mother and himself last month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI thinks that at least one solution to conversations that go off the rails could be to automatically reroute sensitive chats to “reasoning” models.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We recently introduced a real-time router that can choose between efficient chat models and reasoning models based on the conversation context,” OpenAI wrote in a Tuesday blog post. “We’ll soon begin to route some sensitive conversations—like when our system detects signs of acute distress—to a reasoning model, like GPT‑5-thinking, so it can provide more helpful and beneficial responses, regardless of which model a person first selected.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says its GPT-5 thinking and o3 models are built to spend more time thinking for longer and reasoning through context before answering, which means they are “more resistant to adversarial prompts.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI firm also said it would roll out parental controls in the next month, allowing parents to link their account with their teen’s account through an email invitation. In late July, OpenAI rolled out Study Mode in ChatGPT to help students maintain critical thinking capabilities while studying, rather than tapping ChatGPT to write their essays for them. Soon, parents will be able to control how ChatGPT responds to their child with “age-appropriate model behavior rules, which are on by default.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Parents will also be able to disable features like memory and chat history, which experts say could lead to delusional thinking and other problematic behavior, including dependency and attachment issues, reinforcement of harmful thought patterns, and the illusion of thought-reading. In the case of Adam Raine, ChatGPT supplied methods to commit suicide that reflected knowledge of his hobbies, per The New York Times.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Perhaps the most important parental control that OpenAI intends to roll out is that parents can receive notifications when the system detects their teenager is in a moment of “acute distress.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;TechCrunch has asked OpenAI for more information about how the company is able to flag moments of acute distress in real time, how long it has had “age-appropriate model behavior rules” on by default, and whether it is exploring allowing parents to implement a time limit on teenage use of ChatGPT.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has already rolled out in-app reminders during long sessions to encourage breaks for all users, but stops short of cutting people off who might be using ChatGPT to spiral.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI firm says these safeguards are part of a “120-day initiative” to preview plans for improvements that OpenAI hopes to launch this year. The company also said it is partnering with experts — including ones with expertise in areas like eating disorders, substance use, and adolescent health — via its Global Physician Network and Expert Council on Well-Being and AI to help “define and measure well-being, set priorities, and design future safeguards.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has asked OpenAI how many mental health professionals are involved in this initiative, who leads its Expert Council, and what suggestions mental health experts have made in terms of product, research, and policy decisions.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-1922977290.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI said Tuesday it plans to route sensitive conversations to reasoning models like GPT-5 and roll out parental controls within the next month — part of an ongoing response to recent safety incidents involving ChatGPT failing to detect mental distress.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new guardrails come in the aftermath of the suicide of teenager Adam Raine, who discussed self-harm and plans to end his life with ChatGPT, which even supplied him with information about specific suicide methods. Raine’s parents have filed a wrongful death lawsuit against OpenAI.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In a blog post last week, OpenAI acknowledged shortcomings in its safety systems, including failures to maintain guardrails during extended conversations. Experts attribute these issues to fundamental design elements: the models’ tendency to validate user statements and their next-word prediction algorithms, which cause chatbots to follow conversational threads rather than redirect potentially harmful discussions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That tendency is displayed in the extreme in the case of Stein-Erik Soelberg, whose murder-suicide was reported on by The Wall Street Journal over the weekend. Soelberg, who had a history of mental illness, used ChatGPT to validate and fuel his paranoia that he was being targeted in a grand conspiracy. His delusions progressed so badly that he ended up killing his mother and himself last month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI thinks that at least one solution to conversations that go off the rails could be to automatically reroute sensitive chats to “reasoning” models.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We recently introduced a real-time router that can choose between efficient chat models and reasoning models based on the conversation context,” OpenAI wrote in a Tuesday blog post. “We’ll soon begin to route some sensitive conversations—like when our system detects signs of acute distress—to a reasoning model, like GPT‑5-thinking, so it can provide more helpful and beneficial responses, regardless of which model a person first selected.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says its GPT-5 thinking and o3 models are built to spend more time thinking for longer and reasoning through context before answering, which means they are “more resistant to adversarial prompts.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI firm also said it would roll out parental controls in the next month, allowing parents to link their account with their teen’s account through an email invitation. In late July, OpenAI rolled out Study Mode in ChatGPT to help students maintain critical thinking capabilities while studying, rather than tapping ChatGPT to write their essays for them. Soon, parents will be able to control how ChatGPT responds to their child with “age-appropriate model behavior rules, which are on by default.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Parents will also be able to disable features like memory and chat history, which experts say could lead to delusional thinking and other problematic behavior, including dependency and attachment issues, reinforcement of harmful thought patterns, and the illusion of thought-reading. In the case of Adam Raine, ChatGPT supplied methods to commit suicide that reflected knowledge of his hobbies, per The New York Times.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Perhaps the most important parental control that OpenAI intends to roll out is that parents can receive notifications when the system detects their teenager is in a moment of “acute distress.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;TechCrunch has asked OpenAI for more information about how the company is able to flag moments of acute distress in real time, how long it has had “age-appropriate model behavior rules” on by default, and whether it is exploring allowing parents to implement a time limit on teenage use of ChatGPT.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has already rolled out in-app reminders during long sessions to encourage breaks for all users, but stops short of cutting people off who might be using ChatGPT to spiral.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI firm says these safeguards are part of a “120-day initiative” to preview plans for improvements that OpenAI hopes to launch this year. The company also said it is partnering with experts — including ones with expertise in areas like eating disorders, substance use, and adolescent health — via its Global Physician Network and Expert Council on Well-Being and AI to help “define and measure well-being, set priorities, and design future safeguards.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has asked OpenAI how many mental health professionals are involved in this initiative, who leads its Expert Council, and what suggestions mental health experts have made in terms of product, research, and policy decisions.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/02/openai-to-route-sensitive-conversations-to-gpt-5-introduce-parental-controls/</guid><pubDate>Tue, 02 Sep 2025 15:09:02 +0000</pubDate></item><item><title>[NEW] OpenAI announces parental controls for ChatGPT after teen suicide lawsuit (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/09/openai-announces-parental-controls-for-chatgpt-after-teen-suicide-lawsuit/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Promised protections follow reports of vulnerable users misled in extended chats.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The OpenAI logo over a tectonic shift in the background." class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/09/openai_tectonic_shift-300x169.jpg" width="300" /&gt;
                  &lt;img alt="The OpenAI logo over a tectonic shift in the background." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/09/openai_tectonic_shift-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards / OpenAI

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Tuesday, OpenAI announced plans to roll out parental controls for ChatGPT and route sensitive mental health conversations to its simulated reasoning models, following what the company has called "heartbreaking cases" of users experiencing crises while using the AI assistant. The moves come after multiple reported incidents where ChatGPT allegedly failed to intervene appropriately when users expressed suicidal thoughts or experienced mental health episodes.&lt;/p&gt;
&lt;p&gt;"This work has already been underway, but we want to proactively preview our plans for the next 120 days, so you won’t need to wait for launches to see where we’re headed," OpenAI wrote in a blog post published Tuesday. "The work will continue well beyond this period of time, but we’re making a focused effort to launch as many of these improvements as possible this year."&lt;/p&gt;
&lt;p&gt;The planned parental controls represent OpenAI's most concrete response to concerns about teen safety on the platform so far. Within the next month, OpenAI says, parents will be able to link their accounts with their teens' ChatGPT accounts (minimum age 13) through email invitations, control how the AI model responds with age-appropriate behavior rules that are on by default, manage which features to disable (including memory and chat history), and receive notifications when the system detects their teen experiencing acute distress.&lt;/p&gt;
&lt;p&gt;The parental controls build on existing features like in-app reminders during long sessions that encourage users to take breaks, which OpenAI rolled out for all users in August.&lt;/p&gt;
&lt;h2&gt;High-profile cases prompt safety changes&lt;/h2&gt;
&lt;p&gt;OpenAI's new safety initiative arrives after several high-profile cases drew scrutiny to ChatGPT's handling of vulnerable users. In August, Matt and Maria Raine filed suit against OpenAI after their 16-year-old son Adam died by suicide following extensive ChatGPT interactions that included 377 messages flagged for self-harm content. According to court documents, ChatGPT mentioned suicide 1,275 times in conversations with Adam—six times more often than the teen himself. Last week, The Wall Street Journal reported that a 56-year-old man killed his mother and himself after ChatGPT reinforced his paranoid delusions rather than challenging them.&lt;/p&gt;
&lt;p&gt;To guide these safety improvements, OpenAI is working with what it calls an Expert Council on Well-Being and AI to "shape a clear, evidence-based vision for how AI can support people's well-being," according to the company's blog post. The council will help define and measure well-being, set priorities, and design future safeguards including the parental controls.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;A separate "Global Physician Network" of more than 250 physicians who have practiced in 60 countries provides medical expertise, with 90 physicians across 30 countries specifically contributing research on how ChatGPT should behave in mental health contexts. These physicians advise on handling specific issues like eating disorders, substance use, and adolescent mental health, though OpenAI notes it "remains accountable for the choices we make" despite the expert input.&lt;/p&gt;
&lt;h2&gt;Degrading safeguards in extended conversations&lt;/h2&gt;
&lt;p&gt;OpenAI recently acknowledged that ChatGPT's safety measures can break down during lengthy conversations—precisely when vulnerable users might need them most. "As the back-and-forth grows, parts of the model's safety training may degrade," the company wrote in a blog post last week. The AI assistant might correctly point users to suicide hotlines initially, but "after many messages over a long period of time, it might eventually offer an answer that goes against our safeguards."&lt;/p&gt;
&lt;p&gt;This degradation reflects fundamental limitations in the Transformer AI architecture that underlies ChatGPT. OpenAI's models use a mechanism that compares every new text fragment to the entire conversation history, with computational costs growing quadratically as conversation length increases. Also, as conversations lengthen beyond the model's context window, the system drops earlier messages and potentially loses important context from the beginning of the conversation.&lt;/p&gt;
&lt;p&gt;The timing of these safety measures follows OpenAI's February decision to ease content safeguards after user complaints about overly restrictive moderation and issues related to a rise in sycophancy, where the GPT-4o AI model told users what they wanted to hear. Combined with a very persuasive simulation of humanlike personality,&amp;nbsp;these tendencies created particularly hazardous conditions for vulnerable users who believed they were interacting with an authoritative and accurate source of information rather than a pattern-matching system generating statistically likely responses.&lt;/p&gt;
&lt;p&gt;Research from July led by Oxford psychiatrists identified what they call "bidirectional belief amplification"—a feedback loop where chatbot sycophancy reinforces user beliefs, which then conditions the chatbot to generate increasingly extreme validations. The researchers warn that this creates conditions for "a technological folie à deux," where two individuals mutually reinforce the same delusion.&lt;/p&gt;
&lt;p&gt;Unlike pharmaceuticals or human therapists, AI chatbots face few safety regulations in the United States, though Illinois recently banned chatbots as therapists, with fines of up to $10,000 per violation. The Oxford researchers conclude that "current AI safety measures are inadequate to address these interaction-based risks" and call for treating chatbots that function as companions or therapists with the same regulatory oversight as mental health interventions.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Promised protections follow reports of vulnerable users misled in extended chats.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The OpenAI logo over a tectonic shift in the background." class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/09/openai_tectonic_shift-300x169.jpg" width="300" /&gt;
                  &lt;img alt="The OpenAI logo over a tectonic shift in the background." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/09/openai_tectonic_shift-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards / OpenAI

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Tuesday, OpenAI announced plans to roll out parental controls for ChatGPT and route sensitive mental health conversations to its simulated reasoning models, following what the company has called "heartbreaking cases" of users experiencing crises while using the AI assistant. The moves come after multiple reported incidents where ChatGPT allegedly failed to intervene appropriately when users expressed suicidal thoughts or experienced mental health episodes.&lt;/p&gt;
&lt;p&gt;"This work has already been underway, but we want to proactively preview our plans for the next 120 days, so you won’t need to wait for launches to see where we’re headed," OpenAI wrote in a blog post published Tuesday. "The work will continue well beyond this period of time, but we’re making a focused effort to launch as many of these improvements as possible this year."&lt;/p&gt;
&lt;p&gt;The planned parental controls represent OpenAI's most concrete response to concerns about teen safety on the platform so far. Within the next month, OpenAI says, parents will be able to link their accounts with their teens' ChatGPT accounts (minimum age 13) through email invitations, control how the AI model responds with age-appropriate behavior rules that are on by default, manage which features to disable (including memory and chat history), and receive notifications when the system detects their teen experiencing acute distress.&lt;/p&gt;
&lt;p&gt;The parental controls build on existing features like in-app reminders during long sessions that encourage users to take breaks, which OpenAI rolled out for all users in August.&lt;/p&gt;
&lt;h2&gt;High-profile cases prompt safety changes&lt;/h2&gt;
&lt;p&gt;OpenAI's new safety initiative arrives after several high-profile cases drew scrutiny to ChatGPT's handling of vulnerable users. In August, Matt and Maria Raine filed suit against OpenAI after their 16-year-old son Adam died by suicide following extensive ChatGPT interactions that included 377 messages flagged for self-harm content. According to court documents, ChatGPT mentioned suicide 1,275 times in conversations with Adam—six times more often than the teen himself. Last week, The Wall Street Journal reported that a 56-year-old man killed his mother and himself after ChatGPT reinforced his paranoid delusions rather than challenging them.&lt;/p&gt;
&lt;p&gt;To guide these safety improvements, OpenAI is working with what it calls an Expert Council on Well-Being and AI to "shape a clear, evidence-based vision for how AI can support people's well-being," according to the company's blog post. The council will help define and measure well-being, set priorities, and design future safeguards including the parental controls.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;A separate "Global Physician Network" of more than 250 physicians who have practiced in 60 countries provides medical expertise, with 90 physicians across 30 countries specifically contributing research on how ChatGPT should behave in mental health contexts. These physicians advise on handling specific issues like eating disorders, substance use, and adolescent mental health, though OpenAI notes it "remains accountable for the choices we make" despite the expert input.&lt;/p&gt;
&lt;h2&gt;Degrading safeguards in extended conversations&lt;/h2&gt;
&lt;p&gt;OpenAI recently acknowledged that ChatGPT's safety measures can break down during lengthy conversations—precisely when vulnerable users might need them most. "As the back-and-forth grows, parts of the model's safety training may degrade," the company wrote in a blog post last week. The AI assistant might correctly point users to suicide hotlines initially, but "after many messages over a long period of time, it might eventually offer an answer that goes against our safeguards."&lt;/p&gt;
&lt;p&gt;This degradation reflects fundamental limitations in the Transformer AI architecture that underlies ChatGPT. OpenAI's models use a mechanism that compares every new text fragment to the entire conversation history, with computational costs growing quadratically as conversation length increases. Also, as conversations lengthen beyond the model's context window, the system drops earlier messages and potentially loses important context from the beginning of the conversation.&lt;/p&gt;
&lt;p&gt;The timing of these safety measures follows OpenAI's February decision to ease content safeguards after user complaints about overly restrictive moderation and issues related to a rise in sycophancy, where the GPT-4o AI model told users what they wanted to hear. Combined with a very persuasive simulation of humanlike personality,&amp;nbsp;these tendencies created particularly hazardous conditions for vulnerable users who believed they were interacting with an authoritative and accurate source of information rather than a pattern-matching system generating statistically likely responses.&lt;/p&gt;
&lt;p&gt;Research from July led by Oxford psychiatrists identified what they call "bidirectional belief amplification"—a feedback loop where chatbot sycophancy reinforces user beliefs, which then conditions the chatbot to generate increasingly extreme validations. The researchers warn that this creates conditions for "a technological folie à deux," where two individuals mutually reinforce the same delusion.&lt;/p&gt;
&lt;p&gt;Unlike pharmaceuticals or human therapists, AI chatbots face few safety regulations in the United States, though Illinois recently banned chatbots as therapists, with fines of up to $10,000 per violation. The Oxford researchers conclude that "current AI safety measures are inadequate to address these interaction-based risks" and call for treating chatbots that function as companions or therapists with the same regulatory oversight as mental health interventions.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/09/openai-announces-parental-controls-for-chatgpt-after-teen-suicide-lawsuit/</guid><pubDate>Tue, 02 Sep 2025 15:10:26 +0000</pubDate></item><item><title>[NEW] Tesla Dojo: the rise and fall of Elon Musk’s AI supercomputer (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/02/tesla-dojo-the-rise-and-fall-of-elon-musks-ai-supercomputer/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;For years, Elon Musk has spoken of the promise of Dojo, the AI supercomputer that was supposed to be the cornerstone of Tesla’s AI ambitions. It was important enough to Musk that in July 2024, he said the company’s AI team would “double down” on Dojo in the lead-up to Tesla’s robotaxi reveal, which happened in October.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After six years of hype, Tesla decided last month to shut down Dojo and disband the team behind the supercomputer in August 2025. Within weeks of projecting that Dojo 2, Tesla’s second supercluster that was meant to be built on the company’s in-house D2 chips, would reach scale by 2026, Musk reversed course, declaring it “an evolutionary dead end.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This article originally set out to explain what Dojo was and how it could help Tesla achieve full-self driving, autonomous humanoid robots, semiconductor autonomy, and more. Now, you can think of it more as an obituary of a project that convinced so many analysts and investors that Tesla wasn’t just an automaker, it was an AI company.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Dojo was Tesla’s custom-built supercomputer that was designed to train its “Full Self-Driving” neural networks. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beefing up Dojo went hand-in-hand with Tesla’s goal to reach full self-driving and bring a robotaxi to market. FSD (Supervised) is Tesla’s advanced driver assistance system that’s on hundreds of thousands of Tesla vehicles today and can perform some automated driving tasks, but it still requires a human to be attentive behind the wheel.&amp;nbsp;It’s also the basis of similar technology powering Tesla’s limited robotaxi service that the company launched in Austin this June using Model Y SUVs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even as Dojo’s &lt;em&gt;raison d’être&lt;/em&gt; started to come to life, Tesla failed to attribute its self-driving successes — controversial as they were — to the supercomputer. In fact, Musk and Tesla had barely mentioned Dojo at all over the past year. In August 2024, Tesla began promoting Cortex, the company’s “giant new AI training supercluster being built at Tesla HQ in Austin to solve real-world AI,” which Musk has said would have “massive storage for video training of FSD and Optimus.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In Tesla’s Q4 2024 shareholder deck, the company shared updates on Cortex, but nothing on Dojo. It’s not clear whether Tesla’s Dojo shutdown affects Cortex.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The response to Dojo’s disbanding has been mixed. Some see it as another example of Musk making promises he can’t deliver on that comes at a time of falling EV sales and a lackluster robotaxi rollout. Others say the shutdown wasn’t a failure, but a strategic pivot from a high-risk, self-reliant hardware to a streamlined path that relies on partners for chip development.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Dojo’s story reveals what was on the line, where the project fell short, and what its shutdown signals for Tesla’s future.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-a-recap-of-dojo-s-shutdown"&gt;A recap of Dojo’s shutdown&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Tesla disbanded its Dojo team and shut down the project in mid-August 2025. Dojo’s lead, Peter Bannon, left the company as well, following the departure of around 20 workers who left to start their own AI chip and infrastructure company called DensityAI. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Analysts have pointed out that losing key talent can quickly derail a project, especially a highly specialized, internal tech project.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The shutdown came a couple of weeks after Tesla signed a $16.5 billion deal to get its next-generation AI6 chips from Samsung. The AI6 chip is Tesla’s bet on a chip design that can scale from powering FSD and Tesla’s Optimus humanoid robots to high-performance AI training in data centers.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Once it became clear that all paths converged to AI6, I had to shut down Dojo and make some tough personnel choices, as Dojo 2 was now an evolutionary dead end,” Musk posted on X, the social media platform he owns. “Dojo 3 arguably lives on in the form of a large number of AI6 [systems-on-a-chip] on a single board.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-tesla-s-dojo-backstory"&gt;Tesla’s Dojo backstory&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-2819229" height="453" src="https://techcrunch.com/wp-content/uploads/2024/08/GettyImages-1239825394.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Suzanne Cordeiro / AFP / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Musk has insisted that Tesla isn’t just an automaker, or even a purveyor of solar panels and energy storage systems. Instead, he has pitched Tesla as an AI company, one that has cracked the code to self-driving cars by mimicking human perception.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Most other companies building autonomous vehicle technology rely on a combination of sensors to perceive the world — like lidar, radar and cameras — as well as high-definition maps to localize the vehicle. Tesla believes it can achieve fully autonomous driving by relying on cameras alone to capture visual data and then use advanced neural networks to process that data and make quick decisions about how the car should behave.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The pitch has been that Dojo-trained AI software will eventually be pushed out to Tesla customers via over-the-air updates. The scale of FSD also means Tesla has been able to rake in millions of miles worth of video footage that it uses to train FSD. The idea there is that the more data Tesla can collect, the closer the automaker can get to actually achieving full self-driving.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, some industry experts say there might be a limit to the brute force approach of throwing more data at a model and expecting it to get smarter.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“First of all, there’s an economic constraint, and soon it will just get too expensive to do that,” Anand Raghunathan, Purdue University’s Silicon Valley professor of electrical and computer engineering, told TechCrunch. Further, he said, “Some people claim that we might actually run out of meaningful data to train the models on. More data doesn’t necessarily mean more information, so it depends on whether that data has information that is useful to create a better model, and if the training process is able to actually distill that information into a better model.”&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Raghunathan said despite these doubts, the trend of more data appears to be here for the short-term at least. And more data means more compute power needed to store and process it all to train Tesla’s AI models. That was where Dojo, the supercomputer, came in.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-is-a-supercomputer"&gt;What is a supercomputer?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Dojo was Tesla’s supercomputer system that was designed to function as a training ground for AI, specifically FSD. The name is a nod to the space where martial arts are practiced.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A supercomputer is made up of thousands of smaller computers called nodes. Each of those nodes has its own CPU (central processing unit) and GPU (graphics processing unit). The former handles overall management of the node, and the latter does the complex stuff, like splitting tasks into multiple parts and working on them simultaneously. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;GPUs are essential for machine learning operations like those that power FSD training in simulation. They also power large language models, which is why the rise of generative AI has made Nvidia the most valuable company on the planet.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even Tesla buys Nvidia GPUs to train its AI (more on that later).&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-why-did-tesla-need-a-supercomputer"&gt;Why did Tesla need a supercomputer?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Tesla’s vision-only approach was the main reason Tesla needed a supercomputer. The neural networks behind FSD are trained on vast amounts of driving data to recognize and classify objects around the vehicle and then make driving decisions. That means that when FSD is engaged, the neural nets have to collect and process visual data continuously at speeds that match the depth and velocity recognition capabilities of a human.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In other words, Tesla means to create a digital duplicate of the human visual cortex and brain function.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To get there, Tesla needs to store and process all the video data collected from its cars around the world and run millions of simulations to train its model on the data.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Tesla relied mainly on Nvidia to power its current Dojo training computer, but it didn’t want to have all its eggs in one basket — not least because Nvidia chips are expensive. Tesla had hoped to make something better that increased bandwidth and decreased latencies. That’s why the automaker’s AI division decided to come up with its own custom hardware program that aimed to train AI models more efficiently than traditional systems.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;At that program’s core was Tesla’s proprietary D1 chips, which the company said were&amp;nbsp; optimized for AI workloads.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-tell-me-more-about-these-chips"&gt;Tell me more about these chips&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Ganesh Venkataramanan, former senior director of Autopilot hardware, presenting the D1 training tile at Tesla’s 2021 AI Day." class="wp-image-2819208" height="336" src="https://techcrunch.com/wp-content/uploads/2024/08/Tesla-AI-Day-Dojo-Tile.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Ganesh Venkataramanan, former senior director of Autopilot hardware, presenting the D1 training tile at Tesla’s 2021 AI Day.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Tesla / screenshot&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Tesla, like Apple, thinks hardware and software should be designed to work together. That’s why Tesla was working to move away from the standard GPU hardware and design its own chips to power Dojo.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tesla unveiled its D1 chip, a silicon square the size of a palm, on AI Day in 2021. The D1 chip entered into production around July 2023. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Taiwan Semiconductor Manufacturing Company (TSMC) manufactured the chips using 7 nanometer semiconductor nodes. The D1 has 50 billion transistors and a large die size of 645 millimeters squared, according to Tesla. This is all to say that the D1 promises to be extremely powerful and efficient and to handle complex tasks quickly.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The D1 wasn’t as powerful as Nvidia’s A100 chip, though.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tesla had been working on a next-gen D2 chip that aimed to solve information flow bottlenecks. Instead of connecting the individual chips, the D2 would have put the entire Dojo tile onto a single wafer of silicon.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tesla never confirmed how many D1 chips it ordered or received. The company also never&amp;nbsp; provided a timeline for how long it would have taken to get Dojo supercomputers running on D1 chips.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-did-dojo-mean-for-tesla"&gt;What did Dojo mean for Tesla?&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Visitors are viewing Tesla's humanoid robot Optimus Prime II at WAIC in Shanghai, China, on July 7, 2024." class="wp-image-2819231" height="444" src="https://techcrunch.com/wp-content/uploads/2024/08/GettyImages-2162480419.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Visitors are viewing Tesla’s humanoid robot Optimus Prime II at WAIC in Shanghai, China, on July 7, 2024. &lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Costfoto / NurPhoto / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Tesla’s hope was that by taking control of its own chip production, it might one day be able to quickly add large amounts of compute power to AI training programs at a low cost.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;It also meant not having to rely on Nvidia’s chips in the future, which are increasingly expensive and hard to secure. Now, Tesla is going all-in on partnerships — with Nvidia, AMD, and Samsung, which will build its next-gen AI6 chip.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;During Tesla’s second-quarter 2024 earnings call, Musk said demand for Nvidia hardware was “so high that it’s often difficult to get the GPUs.” He said he was “quite concerned about actually being able to get steady GPUs when we want them, and I think this therefore requires that we put a lot more effort on Dojo in order to ensure that we’ve got the training capability that we need.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Dojo was a risky bet, one that Musk hedged several times by saying that Tesla might not succeed.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the long run, Tesla toyed with the idea of creating a new business model based on its AI division, with Musk even saying during a Q2 2024 earnings call that he saw “a path to being competitive with Nvidia with Dojo.” While D1 was more tailored for Tesla computer vision labeling and training — useful for FSD and Optimus training — it wouldn’t have been useful for much else. Future versions would have to be more tailored to general-purpose AI training, Musk said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The problem that Tesla might have come up against is that almost all AI software out there has been written to work with GPUs. Using Dojo chips to train general-purpose AI models would have required rewriting the software.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That is, unless Tesla rented out its compute, similar to how AWS and Azure rent out cloud computing capabilities — an idea that excited analysts. A September 2023 report from Morgan Stanley predicted that Dojo could add $500 billion to Tesla’s market value by unlocking new revenue streams in the form of robotaxis and software services.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In short, Dojo chips were an insurance policy for the automaker, but one that might have paid dividends.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-how-far-did-tesla-dojo-get"&gt;How far did Tesla Dojo get?&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-2819240" height="453" src="https://techcrunch.com/wp-content/uploads/2024/08/GettyImages-524212924.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Nvidia CEO Jensen Huang and Tesla CEO Elon Musk&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kim Kulish / Corbis / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Musk often provided progress reports, but many of his goals for Dojo were never reached.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For instance, Musk suggested in June 2023 that Dojo had been online and running useful tasks for a few months.” Around the same time, Tesla said it expected Dojo to be one of the top five most powerful supercomputers by February 2024 and had planned for total compute to reach 100 exaflops in October 2024, which would have required roughly 276,000 D1s, or around 320,500 Nvidia A100 GPUs.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tesla never provided an update or any information that would suggest it ever reached these goals.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tesla and Musk made numerous other pledges for Dojo, including financial ones.&amp;nbsp;For instance, Tesla committed in&amp;nbsp;January 2024 to spend $500 million to build a Dojo supercomputer at its gigafactory in Buffalo, New York, and has already spent $314 million of that, per a 2024 report.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Just after Tesla’s second-quarter 2024 earnings call, Musk posted photos of Dojo 1 on X, saying that it would have “roughly 8k H100-equivalent of training online by end of year. Not massive, but not trivial either.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite all of this activity — particularly by Musk on X and in earnings calls — mention of Dojo abruptly ended August 2024.&amp;nbsp;And talk switched to Cortex.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;During the company’s fourth-quarter 2024 earnings call, Tesla said it completed the deployment of Cortex, “a ~50k H100 training cluster at Gigafactory Texas” and that Cortex helped enable V13 of supervised FSD.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In Q2 2025, Tesla noted it “expanded AI training compute with an additional 16k H200 GPUs at Gigafactory Texas, bringing Cortex to a total of 67k H100 equivalents.” During that same earnings call, Musk said he expected to have a second Dojo cluster operating “at scale” in 2026. He also hinted at potential redundancies.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Thinking about Dojo 3 and the AI6 inference chip, it seems like intuitively, we want to try to find convergence there, where it’s basically the same chip,” Musk said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;A few weeks later, he reversed course and disbanded the Dojo team.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch confirmed in late August 2025 that Tesla still plans to commit $500 million to a supercomputer in Buffalo — it just won’t be Dojo.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story originally published August 3, 2024. The article was updated for a final time September 2, 2025, with new information about Tesla’s decision to shut down Dojo.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;For years, Elon Musk has spoken of the promise of Dojo, the AI supercomputer that was supposed to be the cornerstone of Tesla’s AI ambitions. It was important enough to Musk that in July 2024, he said the company’s AI team would “double down” on Dojo in the lead-up to Tesla’s robotaxi reveal, which happened in October.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After six years of hype, Tesla decided last month to shut down Dojo and disband the team behind the supercomputer in August 2025. Within weeks of projecting that Dojo 2, Tesla’s second supercluster that was meant to be built on the company’s in-house D2 chips, would reach scale by 2026, Musk reversed course, declaring it “an evolutionary dead end.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This article originally set out to explain what Dojo was and how it could help Tesla achieve full-self driving, autonomous humanoid robots, semiconductor autonomy, and more. Now, you can think of it more as an obituary of a project that convinced so many analysts and investors that Tesla wasn’t just an automaker, it was an AI company.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Dojo was Tesla’s custom-built supercomputer that was designed to train its “Full Self-Driving” neural networks. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beefing up Dojo went hand-in-hand with Tesla’s goal to reach full self-driving and bring a robotaxi to market. FSD (Supervised) is Tesla’s advanced driver assistance system that’s on hundreds of thousands of Tesla vehicles today and can perform some automated driving tasks, but it still requires a human to be attentive behind the wheel.&amp;nbsp;It’s also the basis of similar technology powering Tesla’s limited robotaxi service that the company launched in Austin this June using Model Y SUVs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even as Dojo’s &lt;em&gt;raison d’être&lt;/em&gt; started to come to life, Tesla failed to attribute its self-driving successes — controversial as they were — to the supercomputer. In fact, Musk and Tesla had barely mentioned Dojo at all over the past year. In August 2024, Tesla began promoting Cortex, the company’s “giant new AI training supercluster being built at Tesla HQ in Austin to solve real-world AI,” which Musk has said would have “massive storage for video training of FSD and Optimus.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In Tesla’s Q4 2024 shareholder deck, the company shared updates on Cortex, but nothing on Dojo. It’s not clear whether Tesla’s Dojo shutdown affects Cortex.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The response to Dojo’s disbanding has been mixed. Some see it as another example of Musk making promises he can’t deliver on that comes at a time of falling EV sales and a lackluster robotaxi rollout. Others say the shutdown wasn’t a failure, but a strategic pivot from a high-risk, self-reliant hardware to a streamlined path that relies on partners for chip development.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Dojo’s story reveals what was on the line, where the project fell short, and what its shutdown signals for Tesla’s future.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-a-recap-of-dojo-s-shutdown"&gt;A recap of Dojo’s shutdown&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Tesla disbanded its Dojo team and shut down the project in mid-August 2025. Dojo’s lead, Peter Bannon, left the company as well, following the departure of around 20 workers who left to start their own AI chip and infrastructure company called DensityAI. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Analysts have pointed out that losing key talent can quickly derail a project, especially a highly specialized, internal tech project.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The shutdown came a couple of weeks after Tesla signed a $16.5 billion deal to get its next-generation AI6 chips from Samsung. The AI6 chip is Tesla’s bet on a chip design that can scale from powering FSD and Tesla’s Optimus humanoid robots to high-performance AI training in data centers.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Once it became clear that all paths converged to AI6, I had to shut down Dojo and make some tough personnel choices, as Dojo 2 was now an evolutionary dead end,” Musk posted on X, the social media platform he owns. “Dojo 3 arguably lives on in the form of a large number of AI6 [systems-on-a-chip] on a single board.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-tesla-s-dojo-backstory"&gt;Tesla’s Dojo backstory&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-2819229" height="453" src="https://techcrunch.com/wp-content/uploads/2024/08/GettyImages-1239825394.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Suzanne Cordeiro / AFP / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Musk has insisted that Tesla isn’t just an automaker, or even a purveyor of solar panels and energy storage systems. Instead, he has pitched Tesla as an AI company, one that has cracked the code to self-driving cars by mimicking human perception.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Most other companies building autonomous vehicle technology rely on a combination of sensors to perceive the world — like lidar, radar and cameras — as well as high-definition maps to localize the vehicle. Tesla believes it can achieve fully autonomous driving by relying on cameras alone to capture visual data and then use advanced neural networks to process that data and make quick decisions about how the car should behave.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The pitch has been that Dojo-trained AI software will eventually be pushed out to Tesla customers via over-the-air updates. The scale of FSD also means Tesla has been able to rake in millions of miles worth of video footage that it uses to train FSD. The idea there is that the more data Tesla can collect, the closer the automaker can get to actually achieving full self-driving.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, some industry experts say there might be a limit to the brute force approach of throwing more data at a model and expecting it to get smarter.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“First of all, there’s an economic constraint, and soon it will just get too expensive to do that,” Anand Raghunathan, Purdue University’s Silicon Valley professor of electrical and computer engineering, told TechCrunch. Further, he said, “Some people claim that we might actually run out of meaningful data to train the models on. More data doesn’t necessarily mean more information, so it depends on whether that data has information that is useful to create a better model, and if the training process is able to actually distill that information into a better model.”&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Raghunathan said despite these doubts, the trend of more data appears to be here for the short-term at least. And more data means more compute power needed to store and process it all to train Tesla’s AI models. That was where Dojo, the supercomputer, came in.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-is-a-supercomputer"&gt;What is a supercomputer?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Dojo was Tesla’s supercomputer system that was designed to function as a training ground for AI, specifically FSD. The name is a nod to the space where martial arts are practiced.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A supercomputer is made up of thousands of smaller computers called nodes. Each of those nodes has its own CPU (central processing unit) and GPU (graphics processing unit). The former handles overall management of the node, and the latter does the complex stuff, like splitting tasks into multiple parts and working on them simultaneously. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;GPUs are essential for machine learning operations like those that power FSD training in simulation. They also power large language models, which is why the rise of generative AI has made Nvidia the most valuable company on the planet.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even Tesla buys Nvidia GPUs to train its AI (more on that later).&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-why-did-tesla-need-a-supercomputer"&gt;Why did Tesla need a supercomputer?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Tesla’s vision-only approach was the main reason Tesla needed a supercomputer. The neural networks behind FSD are trained on vast amounts of driving data to recognize and classify objects around the vehicle and then make driving decisions. That means that when FSD is engaged, the neural nets have to collect and process visual data continuously at speeds that match the depth and velocity recognition capabilities of a human.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In other words, Tesla means to create a digital duplicate of the human visual cortex and brain function.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To get there, Tesla needs to store and process all the video data collected from its cars around the world and run millions of simulations to train its model on the data.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Tesla relied mainly on Nvidia to power its current Dojo training computer, but it didn’t want to have all its eggs in one basket — not least because Nvidia chips are expensive. Tesla had hoped to make something better that increased bandwidth and decreased latencies. That’s why the automaker’s AI division decided to come up with its own custom hardware program that aimed to train AI models more efficiently than traditional systems.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;At that program’s core was Tesla’s proprietary D1 chips, which the company said were&amp;nbsp; optimized for AI workloads.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-tell-me-more-about-these-chips"&gt;Tell me more about these chips&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Ganesh Venkataramanan, former senior director of Autopilot hardware, presenting the D1 training tile at Tesla’s 2021 AI Day." class="wp-image-2819208" height="336" src="https://techcrunch.com/wp-content/uploads/2024/08/Tesla-AI-Day-Dojo-Tile.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Ganesh Venkataramanan, former senior director of Autopilot hardware, presenting the D1 training tile at Tesla’s 2021 AI Day.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Tesla / screenshot&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Tesla, like Apple, thinks hardware and software should be designed to work together. That’s why Tesla was working to move away from the standard GPU hardware and design its own chips to power Dojo.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tesla unveiled its D1 chip, a silicon square the size of a palm, on AI Day in 2021. The D1 chip entered into production around July 2023. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Taiwan Semiconductor Manufacturing Company (TSMC) manufactured the chips using 7 nanometer semiconductor nodes. The D1 has 50 billion transistors and a large die size of 645 millimeters squared, according to Tesla. This is all to say that the D1 promises to be extremely powerful and efficient and to handle complex tasks quickly.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The D1 wasn’t as powerful as Nvidia’s A100 chip, though.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tesla had been working on a next-gen D2 chip that aimed to solve information flow bottlenecks. Instead of connecting the individual chips, the D2 would have put the entire Dojo tile onto a single wafer of silicon.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tesla never confirmed how many D1 chips it ordered or received. The company also never&amp;nbsp; provided a timeline for how long it would have taken to get Dojo supercomputers running on D1 chips.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-did-dojo-mean-for-tesla"&gt;What did Dojo mean for Tesla?&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Visitors are viewing Tesla's humanoid robot Optimus Prime II at WAIC in Shanghai, China, on July 7, 2024." class="wp-image-2819231" height="444" src="https://techcrunch.com/wp-content/uploads/2024/08/GettyImages-2162480419.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Visitors are viewing Tesla’s humanoid robot Optimus Prime II at WAIC in Shanghai, China, on July 7, 2024. &lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Costfoto / NurPhoto / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Tesla’s hope was that by taking control of its own chip production, it might one day be able to quickly add large amounts of compute power to AI training programs at a low cost.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;It also meant not having to rely on Nvidia’s chips in the future, which are increasingly expensive and hard to secure. Now, Tesla is going all-in on partnerships — with Nvidia, AMD, and Samsung, which will build its next-gen AI6 chip.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;During Tesla’s second-quarter 2024 earnings call, Musk said demand for Nvidia hardware was “so high that it’s often difficult to get the GPUs.” He said he was “quite concerned about actually being able to get steady GPUs when we want them, and I think this therefore requires that we put a lot more effort on Dojo in order to ensure that we’ve got the training capability that we need.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Dojo was a risky bet, one that Musk hedged several times by saying that Tesla might not succeed.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the long run, Tesla toyed with the idea of creating a new business model based on its AI division, with Musk even saying during a Q2 2024 earnings call that he saw “a path to being competitive with Nvidia with Dojo.” While D1 was more tailored for Tesla computer vision labeling and training — useful for FSD and Optimus training — it wouldn’t have been useful for much else. Future versions would have to be more tailored to general-purpose AI training, Musk said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The problem that Tesla might have come up against is that almost all AI software out there has been written to work with GPUs. Using Dojo chips to train general-purpose AI models would have required rewriting the software.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That is, unless Tesla rented out its compute, similar to how AWS and Azure rent out cloud computing capabilities — an idea that excited analysts. A September 2023 report from Morgan Stanley predicted that Dojo could add $500 billion to Tesla’s market value by unlocking new revenue streams in the form of robotaxis and software services.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In short, Dojo chips were an insurance policy for the automaker, but one that might have paid dividends.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-how-far-did-tesla-dojo-get"&gt;How far did Tesla Dojo get?&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-2819240" height="453" src="https://techcrunch.com/wp-content/uploads/2024/08/GettyImages-524212924.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Nvidia CEO Jensen Huang and Tesla CEO Elon Musk&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kim Kulish / Corbis / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Musk often provided progress reports, but many of his goals for Dojo were never reached.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For instance, Musk suggested in June 2023 that Dojo had been online and running useful tasks for a few months.” Around the same time, Tesla said it expected Dojo to be one of the top five most powerful supercomputers by February 2024 and had planned for total compute to reach 100 exaflops in October 2024, which would have required roughly 276,000 D1s, or around 320,500 Nvidia A100 GPUs.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tesla never provided an update or any information that would suggest it ever reached these goals.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tesla and Musk made numerous other pledges for Dojo, including financial ones.&amp;nbsp;For instance, Tesla committed in&amp;nbsp;January 2024 to spend $500 million to build a Dojo supercomputer at its gigafactory in Buffalo, New York, and has already spent $314 million of that, per a 2024 report.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Just after Tesla’s second-quarter 2024 earnings call, Musk posted photos of Dojo 1 on X, saying that it would have “roughly 8k H100-equivalent of training online by end of year. Not massive, but not trivial either.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite all of this activity — particularly by Musk on X and in earnings calls — mention of Dojo abruptly ended August 2024.&amp;nbsp;And talk switched to Cortex.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;During the company’s fourth-quarter 2024 earnings call, Tesla said it completed the deployment of Cortex, “a ~50k H100 training cluster at Gigafactory Texas” and that Cortex helped enable V13 of supervised FSD.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In Q2 2025, Tesla noted it “expanded AI training compute with an additional 16k H200 GPUs at Gigafactory Texas, bringing Cortex to a total of 67k H100 equivalents.” During that same earnings call, Musk said he expected to have a second Dojo cluster operating “at scale” in 2026. He also hinted at potential redundancies.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Thinking about Dojo 3 and the AI6 inference chip, it seems like intuitively, we want to try to find convergence there, where it’s basically the same chip,” Musk said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;A few weeks later, he reversed course and disbanded the Dojo team.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch confirmed in late August 2025 that Tesla still plans to commit $500 million to a supercomputer in Buffalo — it just won’t be Dojo.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story originally published August 3, 2024. The article was updated for a final time September 2, 2025, with new information about Tesla’s decision to shut down Dojo.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/02/tesla-dojo-the-rise-and-fall-of-elon-musks-ai-supercomputer/</guid><pubDate>Tue, 02 Sep 2025 16:18:46 +0000</pubDate></item><item><title>[NEW] WordPress shows off Telex, its experimental AI development tool (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/02/wordpress-shows-off-telex-its-experimental-ai-development-tool/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Web publishing platform WordPress is introducing an early version of an AI development tool, which CEO Matt Mullenweg described as a “V0 or Lovable, but specifically for WordPress” — V0 and Lovable being references to popular “vibe coding” services for building software using prompt-based, AI interfaces. Mullenweg introduced the new WordPress AI tool, called Telex, at the company’s WordCamp US 2025 conference in Portland last week, alongside other AI experiments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;During his keynote address, Mullenweg briefly demonstrated how Telex would allow users to create Gutenberg blocks — or the modular bits of text, images, columns, and more — that make up a WordPress website. He showed off how one developer used the new tool to make a simple marketing animation. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Available on its own domain at telex.automattic.ai, Telex today is labeled as “experimental.” To use the service, you type in a prompt for what sort of content block you want to produce, which is returned as a .zip file you can install as a plugin to a WordPress site or WordPress Playground. (The latter being the platform that lets you run WordPress in a web browser on any device without a host.)  &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3041473" height="348" src="https://techcrunch.com/wp-content/uploads/2025/09/telex.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Telex Screenshot&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Telex screenshot&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The launch follows WordPress’s announcement earlier this year that it was forming an AI team to steward the development of AI products that align with the company’s long-term goals.  &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Early testers found that Telex still has a ways to go, as several test projects failed or needed additional work to run properly. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Though Mullenweg did stress that Telex was still a prototype, he was bullish on the potential for AI to further the WordPress mission over time. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When we think about democratized publishing, like embedded in that, is very core to WordPress’ mission, has been taking things that were difficult to do, that required knowledge of coding or anything else, and … made it accessible to people. Made it accessible in a radically open way, in every language, at low cost, open source — we actually own it and have rights to it,” Mullenweg said.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The CEO also admitted there were parts of AI’s progress that could be scary, given the hype and the talk about AI potentially being a bubble, but that didn’t overrule his excitement. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“At the core of it, there is a seed of something, which is so enabling,” he said of AI. “It is an incredibly exciting time to be building for WordPress.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3041477" height="325" src="https://techcrunch.com/wp-content/uploads/2025/09/telex-ex.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Telex screenshot&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Mullenweg also showed off another simpler AI tool, built with an hour or two of work during Contributor Day, which offered a WordPress help assistant inside the browser. And he spoke of his favorite AI browser — Perplexity’s Comet — which would allow users to interact with WordPress from its interface.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As for the legal drama that’s been surrounding the company over the past year or so,  Mullenweg only offered a brief update. The company has been engaged in a dispute with hosting provider WP Engine, which Mulleweg alleges is profiting off the work WordPress does, without contributing enough back. He wants WP Engine to therefore license the WordPress trademark, which he says confuses customers about its association with the company. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The quick update is, it’s working its way through the legal system. We trust in the fairness of the courts,” Mullenweg said. “If there’s any commentary, I’ll just say that there was a settlement conference, I showed up; the other CEO did not. But it is working its way through that. And that’s my only comment on that whole rigmarole.”&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Web publishing platform WordPress is introducing an early version of an AI development tool, which CEO Matt Mullenweg described as a “V0 or Lovable, but specifically for WordPress” — V0 and Lovable being references to popular “vibe coding” services for building software using prompt-based, AI interfaces. Mullenweg introduced the new WordPress AI tool, called Telex, at the company’s WordCamp US 2025 conference in Portland last week, alongside other AI experiments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;During his keynote address, Mullenweg briefly demonstrated how Telex would allow users to create Gutenberg blocks — or the modular bits of text, images, columns, and more — that make up a WordPress website. He showed off how one developer used the new tool to make a simple marketing animation. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Available on its own domain at telex.automattic.ai, Telex today is labeled as “experimental.” To use the service, you type in a prompt for what sort of content block you want to produce, which is returned as a .zip file you can install as a plugin to a WordPress site or WordPress Playground. (The latter being the platform that lets you run WordPress in a web browser on any device without a host.)  &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3041473" height="348" src="https://techcrunch.com/wp-content/uploads/2025/09/telex.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Telex Screenshot&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Telex screenshot&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The launch follows WordPress’s announcement earlier this year that it was forming an AI team to steward the development of AI products that align with the company’s long-term goals.  &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Early testers found that Telex still has a ways to go, as several test projects failed or needed additional work to run properly. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Though Mullenweg did stress that Telex was still a prototype, he was bullish on the potential for AI to further the WordPress mission over time. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When we think about democratized publishing, like embedded in that, is very core to WordPress’ mission, has been taking things that were difficult to do, that required knowledge of coding or anything else, and … made it accessible to people. Made it accessible in a radically open way, in every language, at low cost, open source — we actually own it and have rights to it,” Mullenweg said.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The CEO also admitted there were parts of AI’s progress that could be scary, given the hype and the talk about AI potentially being a bubble, but that didn’t overrule his excitement. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“At the core of it, there is a seed of something, which is so enabling,” he said of AI. “It is an incredibly exciting time to be building for WordPress.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3041477" height="325" src="https://techcrunch.com/wp-content/uploads/2025/09/telex-ex.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Telex screenshot&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Mullenweg also showed off another simpler AI tool, built with an hour or two of work during Contributor Day, which offered a WordPress help assistant inside the browser. And he spoke of his favorite AI browser — Perplexity’s Comet — which would allow users to interact with WordPress from its interface.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As for the legal drama that’s been surrounding the company over the past year or so,  Mullenweg only offered a brief update. The company has been engaged in a dispute with hosting provider WP Engine, which Mulleweg alleges is profiting off the work WordPress does, without contributing enough back. He wants WP Engine to therefore license the WordPress trademark, which he says confuses customers about its association with the company. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The quick update is, it’s working its way through the legal system. We trust in the fairness of the courts,” Mullenweg said. “If there’s any commentary, I’ll just say that there was a settlement conference, I showed up; the other CEO did not. But it is working its way through that. And that’s my only comment on that whole rigmarole.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/02/wordpress-shows-off-telex-its-experimental-ai-development-tool/</guid><pubDate>Tue, 02 Sep 2025 16:26:48 +0000</pubDate></item><item><title>[NEW] Anthropic raises $13B Series F at $183B valuation (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/02/anthropic-raises-13b-series-f-at-183b-valuation/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/Screenshot-2025-09-02-at-12.22.37PM.png?resize=1200,671" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI firm Anthropic has raised a $13 billion Series F round that brings its post-money valuation up to $183 billion – funds the company says will be used to grow its enterprise adoption, deepen safety research, and support international expansion.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Iconiq co-led the round with Fidelity Management &amp;amp; Research Company and Lightspeed Venture Partners, according to the company’s blog post. Other backers include a string of institutional investors, VCs, sovereign wealth funds, private equity, and asset managers, such as Altimeter, Baillie Gifford, BlackRock, Blackstone, Coatue, D1 Capital Partners, Insight Partners, Ontario Teachers’ Pension Plan, Qatar Investment Authority, and more.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We are seeing exponential growth in demand across our entire customer base,” Anthropic CFO Krishna Rao said in the post. “This financing demonstrates investors’ extraordinary confidence in our financial performance and the strength of their collaboration with us to continue fueling our unprecedented growth.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic last raised $3.5 billion at a $61.5 billion post-money valuation in March 2025.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This latest fundraise comes after reports that Anthropic was nearing a deal to raise between $3 billion and $5 billion in funding at a $170 billion valuation. It also follows impressive growth from the AI&amp;nbsp;startup, which reported a jump in annual recurring revenue from $1 billion to $5 billion over the course of 2025 amid accelerated API usage and enterprise adoption.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Anthropic now serves over 300,000 business customers, and our number of large accounts—customers that each represent over $100,000 in run-rate revenue—has grown nearly 7x in the past year,” the company said in the company blog post.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Claude Code is also a developer favorite and one of the main impetuses for Anthropic’s growth. The company said its vibe-coding product already generates more than $500 million in run-rate revenue with usage growing more than 10x in the last three months.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;But maintaining that growth and competing with rivals like OpenAI, Cursor, and others requires more money, as its CEO Dario Amodei recently confessed in a memo, reported by Wired. He said he wasn’t “thrilled” about taking money from sovereign wealth funds of dictatorial governments, but that it’s difficult to run a business by excluding “bad people” from investing.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story is developing. Check back for updates…&lt;/em&gt;&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/Screenshot-2025-09-02-at-12.22.37PM.png?resize=1200,671" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI firm Anthropic has raised a $13 billion Series F round that brings its post-money valuation up to $183 billion – funds the company says will be used to grow its enterprise adoption, deepen safety research, and support international expansion.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Iconiq co-led the round with Fidelity Management &amp;amp; Research Company and Lightspeed Venture Partners, according to the company’s blog post. Other backers include a string of institutional investors, VCs, sovereign wealth funds, private equity, and asset managers, such as Altimeter, Baillie Gifford, BlackRock, Blackstone, Coatue, D1 Capital Partners, Insight Partners, Ontario Teachers’ Pension Plan, Qatar Investment Authority, and more.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We are seeing exponential growth in demand across our entire customer base,” Anthropic CFO Krishna Rao said in the post. “This financing demonstrates investors’ extraordinary confidence in our financial performance and the strength of their collaboration with us to continue fueling our unprecedented growth.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic last raised $3.5 billion at a $61.5 billion post-money valuation in March 2025.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This latest fundraise comes after reports that Anthropic was nearing a deal to raise between $3 billion and $5 billion in funding at a $170 billion valuation. It also follows impressive growth from the AI&amp;nbsp;startup, which reported a jump in annual recurring revenue from $1 billion to $5 billion over the course of 2025 amid accelerated API usage and enterprise adoption.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Anthropic now serves over 300,000 business customers, and our number of large accounts—customers that each represent over $100,000 in run-rate revenue—has grown nearly 7x in the past year,” the company said in the company blog post.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Claude Code is also a developer favorite and one of the main impetuses for Anthropic’s growth. The company said its vibe-coding product already generates more than $500 million in run-rate revenue with usage growing more than 10x in the last three months.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;But maintaining that growth and competing with rivals like OpenAI, Cursor, and others requires more money, as its CEO Dario Amodei recently confessed in a memo, reported by Wired. He said he wasn’t “thrilled” about taking money from sovereign wealth funds of dictatorial governments, but that it’s difficult to run a business by excluding “bad people” from investing.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story is developing. Check back for updates…&lt;/em&gt;&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/02/anthropic-raises-13b-series-f-at-183b-valuation/</guid><pubDate>Tue, 02 Sep 2025 16:34:16 +0000</pubDate></item><item><title>[NEW] Tesla’s Dojo, a timeline (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/02/teslas-dojo-a-timeline/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/08/tesla-dojo-v3.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Elon Musk doesn’t want Tesla to be just an automaker. He wants Tesla to be an AI company, one that’s figured out how to make cars drive themselves.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Crucial to that mission was Dojo, a custom-built supercomputer designed by Tesla to train its Full Self-Driving (FSD) neural networks. FSD isn’t actually fully self-driving; it can perform some automated driving tasks, but still requires an attentive human behind the wheel. But Tesla thinks with more data, more compute power and more training, it can cross the threshold from almost self-driving to full self-driving.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;And that’s where Dojo was supposed to come in. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk teased Dojo for years and ramped up discussions about the supercomputer throughout 2024. But Dojo is now out, and another supercomputer called Cortex has entered the chat. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Below is a timeline of Dojo mentions and promises.&amp;nbsp;Check out this explainer on what Dojo  for even more information on what it was, why it mattered, and what comes next.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-2019"&gt;&lt;strong&gt;2019&lt;/strong&gt;&lt;/h2&gt;

&lt;h2 class="wp-block-heading" id="h-first-mentions-of-dojo"&gt;&lt;strong&gt;First mentions of Dojo&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;April 22 – &lt;/strong&gt;At Tesla’s Autonomy Day, the automaker had its AI team onstage to talk about Autopilot and Full Self-Driving, and the AI powering them both. The company shares information about Tesla’s custom-built chips that are designed specifically for neural networks and self-driving cars.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;During the event, Musk teases Dojo, revealing that it’s a supercomputer for training AI.&amp;nbsp;He also notes that all Tesla cars being produced at the time would have all hardware necessary for full self-driving and only needed a software update.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h2 class="wp-block-heading" id="h-2020-nbsp"&gt;&lt;strong&gt;2020&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;

&lt;h2 class="wp-block-heading" id="h-musk-begins-the-dojo-roadshow"&gt;&lt;strong&gt;Musk begins the Dojo roadshow&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Feb 2 – &lt;/strong&gt;Musk says Tesla will soon have more than a million connected vehicles worldwide with sensors and compute needed for full self-driving — and touts Dojo’s capabilities.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Dojo, our training supercomputer, will be able to process vast amounts of video training data &amp;amp; efficiently run hyperspace arrays with a vast number of parameters, plenty of memory &amp;amp; ultra-high bandwidth between cores. More on this later.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;August 14 &lt;/strong&gt;&lt;strong&gt;–&lt;/strong&gt; Musk reiterates Tesla’s plan to develop a neural network training computer called Dojo “to process truly vast amounts of video data,” calling it “a beast.” He also says the first version of Dojo is “about a year away,” which would put its launch date somewhere around August 2021.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;December&lt;/strong&gt; &lt;strong&gt;31&lt;/strong&gt; &lt;strong&gt;–&lt;/strong&gt; Elon says Dojo isn’t needed, but it will make self-driving better. “It isn’t enough to be safer than human drivers, Autopilot ultimately needs to be more than 10 times safer than human drivers.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-2021"&gt;&lt;strong&gt;2021&lt;/strong&gt;&lt;/h2&gt;

&lt;h2 class="wp-block-heading" id="h-tesla-makes-dojo-official"&gt;&lt;strong&gt;Tesla makes Dojo official&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;August 19 – &lt;/strong&gt;The automaker officially announces Dojo at Tesla’s first AI Day, an event meant to attract engineers to Tesla’s AI team. Tesla also introduces its D1 chip, which the automaker says it will use — alongside Nvidia’s GPU — to power the Dojo supercomputer. Tesla notes its AI cluster will house 3,000 D1 chips.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;October 12 – &lt;/strong&gt;Tesla releases&lt;strong&gt; &lt;/strong&gt;a&lt;strong&gt; &lt;/strong&gt;Dojo Technology whitepaper, “a guide to Tesla’s configurable floating point formats &amp;amp; arithmetic.” The whitepaper outlines a technical standard for a new type of binary floating-point arithmetic that’s used in deep learning neural networks and can be implemented “entirely in software, entirely in hardware, or in any combination of software and hardware.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-2022"&gt;&lt;strong&gt;2022&lt;/strong&gt;&lt;/h2&gt;

&lt;h2 class="wp-block-heading" id="h-tesla-reveals-dojo-progress"&gt;&lt;strong&gt;Tesla reveals Dojo progress&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;August 12 – &lt;/strong&gt;Musk says Tesla will “phase in Dojo. Won’t need to buy as many incremental GPUs next year.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;September 30 – &lt;/strong&gt;At Tesla’s second AI Day, the company reveals that it has installed the first Dojo cabinet, testing 2.2 megawatts of load testing. Tesla says it was building one tile per day (which is made up of 25 D1 chips). Tesla demos Dojo onstage running a Stable Diffusion model to create an AI-generated image of a “Cybertruck on Mars.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Importantly, the company sets a target date of a full Exapod cluster to be completed by Q1 2023, and says it plans to build a total of seven Exapods in Palo Alto.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-2023"&gt;&lt;strong&gt;2023&lt;/strong&gt;&lt;/h2&gt;

&lt;h2 class="wp-block-heading" id="h-a-long-shot-bet"&gt;&lt;strong&gt;A ‘long-shot bet&lt;/strong&gt;‘&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;April 19 – &lt;/strong&gt;Musk tells investors during Tesla’s first-quarter earnings that Dojo “has the potential for an order of magnitude improvement in the cost of training,” and also “has the potential to become a sellable service that we would offer to other companies in the same way that Amazon Web Services offers web services.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk also notes that he’d “look at Dojo as kind of a long-shot bet,” but a “bet worth making.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;June 21 &lt;/strong&gt;&lt;strong&gt;–&lt;/strong&gt; The Tesla AI X account posts that the company’s neural networks are already in customer vehicles. The thread includes a graph with a timeline of Tesla’s current and projected compute power, which places the start of Dojo production at July 2023, although it’s not clear if this refers to the D1 chips or the supercomputer itself. Musk says that same day that Dojo was already online and running tasks at Tesla data centers.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company also projects that Tesla’s compute will be the top five in the entire world by around February 2024 (there are no indications this was successful) and that Tesla would reach 100 exaflops by October 2024.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;July 19 – &lt;/strong&gt;Tesla notes in its second-quarter earnings report it has started production of Dojo. Musk also says Tesla plans to spend more than $1 billion on Dojo through 2024.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;September 6 – &lt;/strong&gt;Musk posts on X that Tesla is limited by AI training compute, but that Nvidia and Dojo will fix that. He says managing the data from the roughly 160 billion frames of video Tesla gets from its cars per day is extremely difficult.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-2024"&gt;&lt;strong&gt;2024&lt;/strong&gt;&lt;/h2&gt;

&lt;h2 class="wp-block-heading" id="h-plans-to-scale"&gt;&lt;strong&gt;Plans to scale&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;January 24 – &lt;/strong&gt;During Tesla’s fourth-quarter and full-year earnings call, Musk acknowledges again that Dojo is a high-risk, high-reward project. He also says that Tesla was pursuing “the dual path of Nvidia and Dojo,” that “Dojo is working” and is “doing training jobs.” He notes Tesla is scaling it up and has “plans for Dojo 1.5, Dojo 2, Dojo 3 and whatnot.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;January 26 – &lt;/strong&gt;Tesla announced plans to spend $500 million to build a Dojo supercomputer in Buffalo. Musk then downplays the investment somewhat, posting on X that while $500 million is a large sum, it’s “only equivalent to a 10k H100 system from Nvidia. Tesla will spend more than that on Nvidia hardware this year. The table stakes for being competitive in AI are at least several billion dollars per year at this point.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;April 30 – &lt;/strong&gt;At TSMC’s North American Technology Symposium, the company says Dojo’s next-generation training tile — the D2, which puts the entire Dojo tile onto a single silicon wafer, rather than connecting 25 chips to make one tile — is already in production, according to IEEE Spectrum.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;May 20 – &lt;/strong&gt;Musk notes that the rear portion of the Giga Texas factory extension will include the construction of “a super dense, water-cooled supercomputer cluster.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;June 4 – &lt;/strong&gt;A CNBC report reveals Musk diverted thousands of Nvidia chips reserved for Tesla to X and xAI. After initially saying the report was false, Musk posts on X that Tesla didn’t have a location to send the Nvidia chips to turn them on, due to the continued construction on the south extension of Giga Texas, “so they would have just sat in a warehouse.” He noted the extension will “house 50k H100s for FSD training.”&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He also posts:&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Of the roughly $10B in AI-related expenditures I said Tesla would make this year, about half is internal, primarily the Tesla-designed AI inference computer and sensors present in all of our cars, plus Dojo. For building the AI training superclusters, NVidia hardware is about 2/3 of the cost. My current best guess for Nvidia purchases by Tesla are $3B to $4B this year.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;July 1 – &lt;/strong&gt;Musk reveals on X that current Tesla vehicles may not have the right hardware for the company’s next-gen AI model. He says that the roughly 5x increase in parameter count with the next-gen AI “is very difficult to achieve without upgrading the vehicle inference computer.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-nvidia-supply-challenges"&gt;Nvidia supply challenges&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;July 23 – &lt;/strong&gt;During Tesla’s second-quarter earnings call, Musk says demand for Nvidia hardware is “so high that it’s often difficult to get the GPUs.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think this therefore requires that we put a lot more effort on Dojo in order to ensure that we’ve got the training capability that we need,” Musk says. “And we do see a path to being competitive with Nvidia with Dojo.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A graph in Tesla’s investor deck predicts that Tesla AI training capacity will ramp to roughly 90,000 H100 equivalent GPUs by the end of 2024, up from around 40,000 in June. Later that day on X, Musk posts that Dojo 1 will have “roughly 8k H100-equivalent of training online by end of year.” He also posts photos of the supercomputer, which appears to use the same fridge-like stainless steel exterior as Tesla’s Cybertrucks.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-from-dojo-to-cortex"&gt;From Dojo to Cortex&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;July 30 –&amp;nbsp; &lt;/strong&gt;AI5 is ~18 months away from high-volume production, Musk says in a reply to a post from someone claiming to start a club of “Tesla HW4/AI4 owners angry about getting left behind when AI5 comes out.”&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;August 3 – &lt;/strong&gt;Musk posts on X that he did a walkthrough of “the Tesla supercompute cluster at Giga Texas (aka Cortex).” He notes that it would be made roughly of 100,000 H100/H200 Nvidia GPUs with “massive storage for video training of FSD &amp;amp; Optimus.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;August 26 – &lt;/strong&gt;Musk posts on X a video of Cortex, which he refers to as “the giant new AI training supercluster being built at Tesla HQ in Austin to solve real-world AI.”&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-202-5"&gt;&lt;strong&gt;202&lt;/strong&gt;5&lt;/h2&gt;

&lt;h2 class="wp-block-heading" id="h-dojo-shutdown-its-team-disbanded"&gt;&lt;strong&gt;Dojo shutdown, its team disbanded&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;January 29 &lt;/strong&gt;– Tesla’s Q4 and full-year 2024 earnings call included no mention of Dojo. Cortex, Tesla’s new AI training supercluster at the Austin gigafactory, did make an appearance, however. Tesla noted in its shareholder deck that it completed the deployment of Cortex, which is made up of roughly 50,000 H100 Nvidia GPUs.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Cortex helped enable V13 of FSD (Supervised), which boasts major improvements in safety and comfort thanks to 4.2x increase in data, higher resolution video inputs … among other enhancements,” according to the letter.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;During the call, CFO Vaibhav Taneja noted that Tesla accelerated the buildout of Cortex to speed up the rollout of FSD V13. He said that accumulated AI-related capital expenditures, including infrastructure, “so far has been approximately $5 billion.” In 2025, Taneja said he expects capex to be flat as it relates to AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;July 23 – &lt;/strong&gt;During Tesla’s Q2 2025 earnings call, Musk said Dojo 2 was expected to be “operating at scale” sometime in 2026, with “scale being somewhere around 100k H100 equivalent.” In the same breath, he hinted at possible redundancies.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Thinking about Dojo 3 and the AI6 inference chip, it seems like intuitively, we want to try to find convergence there, where it’s basically the same chip,” Musk said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;July 28 – &lt;/strong&gt;Tesla signed a $16.5 billion deal to get its next-generation AI6 chips from Samsung. The AI6 chip is Tesla’s bet on a chip design that can scale from powering FSD and Tesla’s Optimus humanoid robots to high-performance AI training in data centers.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;August 6 – &lt;/strong&gt;Bloomberg reports that close to 20 Dojo workers left to start their own company that builds AI chips, software, and hardware called DensityAI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;August 7 – &lt;/strong&gt;Bloomberg reports that Tesla has disbanded its Dojo team and shut down the project. Peter Bannon, Dojo’s lead, left the company, as well.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk responded to the reports on X, saying: “It doesn’t make sense for Tesla to divide its resources and scale two quite different AI chip designs. The Tesla AI5, AI6 and subsequent chips will be excellent for inference and at least pretty good for training. All effort is focused on that.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;August 10 – &lt;/strong&gt;“Once it became clear that all paths converged to AI6, I had to shut down Dojo and make some tough personnel choices, as Dojo 2 was now an evolutionary dead end,” Musk posted on X, the social media platform he owns. “Dojo 3 arguably lives on in the form of a large number of AI6 [systems-on-a-chip] on a single board.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;September 1&lt;/strong&gt; – Tesla shares its Master Plan Part IV on social media platform X. There is no mention of Dojo or Cortex, although AI, and more specifically, “physical AI” takes a central role. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story originally published August 10, 2024. The final update of the Tesla Dojo timeline published September 2, 2025.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/08/tesla-dojo-v3.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Elon Musk doesn’t want Tesla to be just an automaker. He wants Tesla to be an AI company, one that’s figured out how to make cars drive themselves.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Crucial to that mission was Dojo, a custom-built supercomputer designed by Tesla to train its Full Self-Driving (FSD) neural networks. FSD isn’t actually fully self-driving; it can perform some automated driving tasks, but still requires an attentive human behind the wheel. But Tesla thinks with more data, more compute power and more training, it can cross the threshold from almost self-driving to full self-driving.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;And that’s where Dojo was supposed to come in. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk teased Dojo for years and ramped up discussions about the supercomputer throughout 2024. But Dojo is now out, and another supercomputer called Cortex has entered the chat. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Below is a timeline of Dojo mentions and promises.&amp;nbsp;Check out this explainer on what Dojo  for even more information on what it was, why it mattered, and what comes next.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-2019"&gt;&lt;strong&gt;2019&lt;/strong&gt;&lt;/h2&gt;

&lt;h2 class="wp-block-heading" id="h-first-mentions-of-dojo"&gt;&lt;strong&gt;First mentions of Dojo&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;April 22 – &lt;/strong&gt;At Tesla’s Autonomy Day, the automaker had its AI team onstage to talk about Autopilot and Full Self-Driving, and the AI powering them both. The company shares information about Tesla’s custom-built chips that are designed specifically for neural networks and self-driving cars.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;During the event, Musk teases Dojo, revealing that it’s a supercomputer for training AI.&amp;nbsp;He also notes that all Tesla cars being produced at the time would have all hardware necessary for full self-driving and only needed a software update.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h2 class="wp-block-heading" id="h-2020-nbsp"&gt;&lt;strong&gt;2020&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;

&lt;h2 class="wp-block-heading" id="h-musk-begins-the-dojo-roadshow"&gt;&lt;strong&gt;Musk begins the Dojo roadshow&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Feb 2 – &lt;/strong&gt;Musk says Tesla will soon have more than a million connected vehicles worldwide with sensors and compute needed for full self-driving — and touts Dojo’s capabilities.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Dojo, our training supercomputer, will be able to process vast amounts of video training data &amp;amp; efficiently run hyperspace arrays with a vast number of parameters, plenty of memory &amp;amp; ultra-high bandwidth between cores. More on this later.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;August 14 &lt;/strong&gt;&lt;strong&gt;–&lt;/strong&gt; Musk reiterates Tesla’s plan to develop a neural network training computer called Dojo “to process truly vast amounts of video data,” calling it “a beast.” He also says the first version of Dojo is “about a year away,” which would put its launch date somewhere around August 2021.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;December&lt;/strong&gt; &lt;strong&gt;31&lt;/strong&gt; &lt;strong&gt;–&lt;/strong&gt; Elon says Dojo isn’t needed, but it will make self-driving better. “It isn’t enough to be safer than human drivers, Autopilot ultimately needs to be more than 10 times safer than human drivers.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-2021"&gt;&lt;strong&gt;2021&lt;/strong&gt;&lt;/h2&gt;

&lt;h2 class="wp-block-heading" id="h-tesla-makes-dojo-official"&gt;&lt;strong&gt;Tesla makes Dojo official&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;August 19 – &lt;/strong&gt;The automaker officially announces Dojo at Tesla’s first AI Day, an event meant to attract engineers to Tesla’s AI team. Tesla also introduces its D1 chip, which the automaker says it will use — alongside Nvidia’s GPU — to power the Dojo supercomputer. Tesla notes its AI cluster will house 3,000 D1 chips.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;October 12 – &lt;/strong&gt;Tesla releases&lt;strong&gt; &lt;/strong&gt;a&lt;strong&gt; &lt;/strong&gt;Dojo Technology whitepaper, “a guide to Tesla’s configurable floating point formats &amp;amp; arithmetic.” The whitepaper outlines a technical standard for a new type of binary floating-point arithmetic that’s used in deep learning neural networks and can be implemented “entirely in software, entirely in hardware, or in any combination of software and hardware.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-2022"&gt;&lt;strong&gt;2022&lt;/strong&gt;&lt;/h2&gt;

&lt;h2 class="wp-block-heading" id="h-tesla-reveals-dojo-progress"&gt;&lt;strong&gt;Tesla reveals Dojo progress&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;August 12 – &lt;/strong&gt;Musk says Tesla will “phase in Dojo. Won’t need to buy as many incremental GPUs next year.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;September 30 – &lt;/strong&gt;At Tesla’s second AI Day, the company reveals that it has installed the first Dojo cabinet, testing 2.2 megawatts of load testing. Tesla says it was building one tile per day (which is made up of 25 D1 chips). Tesla demos Dojo onstage running a Stable Diffusion model to create an AI-generated image of a “Cybertruck on Mars.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Importantly, the company sets a target date of a full Exapod cluster to be completed by Q1 2023, and says it plans to build a total of seven Exapods in Palo Alto.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-2023"&gt;&lt;strong&gt;2023&lt;/strong&gt;&lt;/h2&gt;

&lt;h2 class="wp-block-heading" id="h-a-long-shot-bet"&gt;&lt;strong&gt;A ‘long-shot bet&lt;/strong&gt;‘&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;April 19 – &lt;/strong&gt;Musk tells investors during Tesla’s first-quarter earnings that Dojo “has the potential for an order of magnitude improvement in the cost of training,” and also “has the potential to become a sellable service that we would offer to other companies in the same way that Amazon Web Services offers web services.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk also notes that he’d “look at Dojo as kind of a long-shot bet,” but a “bet worth making.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;June 21 &lt;/strong&gt;&lt;strong&gt;–&lt;/strong&gt; The Tesla AI X account posts that the company’s neural networks are already in customer vehicles. The thread includes a graph with a timeline of Tesla’s current and projected compute power, which places the start of Dojo production at July 2023, although it’s not clear if this refers to the D1 chips or the supercomputer itself. Musk says that same day that Dojo was already online and running tasks at Tesla data centers.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company also projects that Tesla’s compute will be the top five in the entire world by around February 2024 (there are no indications this was successful) and that Tesla would reach 100 exaflops by October 2024.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;July 19 – &lt;/strong&gt;Tesla notes in its second-quarter earnings report it has started production of Dojo. Musk also says Tesla plans to spend more than $1 billion on Dojo through 2024.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;September 6 – &lt;/strong&gt;Musk posts on X that Tesla is limited by AI training compute, but that Nvidia and Dojo will fix that. He says managing the data from the roughly 160 billion frames of video Tesla gets from its cars per day is extremely difficult.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-2024"&gt;&lt;strong&gt;2024&lt;/strong&gt;&lt;/h2&gt;

&lt;h2 class="wp-block-heading" id="h-plans-to-scale"&gt;&lt;strong&gt;Plans to scale&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;January 24 – &lt;/strong&gt;During Tesla’s fourth-quarter and full-year earnings call, Musk acknowledges again that Dojo is a high-risk, high-reward project. He also says that Tesla was pursuing “the dual path of Nvidia and Dojo,” that “Dojo is working” and is “doing training jobs.” He notes Tesla is scaling it up and has “plans for Dojo 1.5, Dojo 2, Dojo 3 and whatnot.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;January 26 – &lt;/strong&gt;Tesla announced plans to spend $500 million to build a Dojo supercomputer in Buffalo. Musk then downplays the investment somewhat, posting on X that while $500 million is a large sum, it’s “only equivalent to a 10k H100 system from Nvidia. Tesla will spend more than that on Nvidia hardware this year. The table stakes for being competitive in AI are at least several billion dollars per year at this point.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;April 30 – &lt;/strong&gt;At TSMC’s North American Technology Symposium, the company says Dojo’s next-generation training tile — the D2, which puts the entire Dojo tile onto a single silicon wafer, rather than connecting 25 chips to make one tile — is already in production, according to IEEE Spectrum.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;May 20 – &lt;/strong&gt;Musk notes that the rear portion of the Giga Texas factory extension will include the construction of “a super dense, water-cooled supercomputer cluster.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;June 4 – &lt;/strong&gt;A CNBC report reveals Musk diverted thousands of Nvidia chips reserved for Tesla to X and xAI. After initially saying the report was false, Musk posts on X that Tesla didn’t have a location to send the Nvidia chips to turn them on, due to the continued construction on the south extension of Giga Texas, “so they would have just sat in a warehouse.” He noted the extension will “house 50k H100s for FSD training.”&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He also posts:&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Of the roughly $10B in AI-related expenditures I said Tesla would make this year, about half is internal, primarily the Tesla-designed AI inference computer and sensors present in all of our cars, plus Dojo. For building the AI training superclusters, NVidia hardware is about 2/3 of the cost. My current best guess for Nvidia purchases by Tesla are $3B to $4B this year.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;July 1 – &lt;/strong&gt;Musk reveals on X that current Tesla vehicles may not have the right hardware for the company’s next-gen AI model. He says that the roughly 5x increase in parameter count with the next-gen AI “is very difficult to achieve without upgrading the vehicle inference computer.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-nvidia-supply-challenges"&gt;Nvidia supply challenges&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;July 23 – &lt;/strong&gt;During Tesla’s second-quarter earnings call, Musk says demand for Nvidia hardware is “so high that it’s often difficult to get the GPUs.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think this therefore requires that we put a lot more effort on Dojo in order to ensure that we’ve got the training capability that we need,” Musk says. “And we do see a path to being competitive with Nvidia with Dojo.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A graph in Tesla’s investor deck predicts that Tesla AI training capacity will ramp to roughly 90,000 H100 equivalent GPUs by the end of 2024, up from around 40,000 in June. Later that day on X, Musk posts that Dojo 1 will have “roughly 8k H100-equivalent of training online by end of year.” He also posts photos of the supercomputer, which appears to use the same fridge-like stainless steel exterior as Tesla’s Cybertrucks.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-from-dojo-to-cortex"&gt;From Dojo to Cortex&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;July 30 –&amp;nbsp; &lt;/strong&gt;AI5 is ~18 months away from high-volume production, Musk says in a reply to a post from someone claiming to start a club of “Tesla HW4/AI4 owners angry about getting left behind when AI5 comes out.”&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;August 3 – &lt;/strong&gt;Musk posts on X that he did a walkthrough of “the Tesla supercompute cluster at Giga Texas (aka Cortex).” He notes that it would be made roughly of 100,000 H100/H200 Nvidia GPUs with “massive storage for video training of FSD &amp;amp; Optimus.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;August 26 – &lt;/strong&gt;Musk posts on X a video of Cortex, which he refers to as “the giant new AI training supercluster being built at Tesla HQ in Austin to solve real-world AI.”&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-202-5"&gt;&lt;strong&gt;202&lt;/strong&gt;5&lt;/h2&gt;

&lt;h2 class="wp-block-heading" id="h-dojo-shutdown-its-team-disbanded"&gt;&lt;strong&gt;Dojo shutdown, its team disbanded&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;January 29 &lt;/strong&gt;– Tesla’s Q4 and full-year 2024 earnings call included no mention of Dojo. Cortex, Tesla’s new AI training supercluster at the Austin gigafactory, did make an appearance, however. Tesla noted in its shareholder deck that it completed the deployment of Cortex, which is made up of roughly 50,000 H100 Nvidia GPUs.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Cortex helped enable V13 of FSD (Supervised), which boasts major improvements in safety and comfort thanks to 4.2x increase in data, higher resolution video inputs … among other enhancements,” according to the letter.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;During the call, CFO Vaibhav Taneja noted that Tesla accelerated the buildout of Cortex to speed up the rollout of FSD V13. He said that accumulated AI-related capital expenditures, including infrastructure, “so far has been approximately $5 billion.” In 2025, Taneja said he expects capex to be flat as it relates to AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;July 23 – &lt;/strong&gt;During Tesla’s Q2 2025 earnings call, Musk said Dojo 2 was expected to be “operating at scale” sometime in 2026, with “scale being somewhere around 100k H100 equivalent.” In the same breath, he hinted at possible redundancies.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Thinking about Dojo 3 and the AI6 inference chip, it seems like intuitively, we want to try to find convergence there, where it’s basically the same chip,” Musk said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;July 28 – &lt;/strong&gt;Tesla signed a $16.5 billion deal to get its next-generation AI6 chips from Samsung. The AI6 chip is Tesla’s bet on a chip design that can scale from powering FSD and Tesla’s Optimus humanoid robots to high-performance AI training in data centers.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;August 6 – &lt;/strong&gt;Bloomberg reports that close to 20 Dojo workers left to start their own company that builds AI chips, software, and hardware called DensityAI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;August 7 – &lt;/strong&gt;Bloomberg reports that Tesla has disbanded its Dojo team and shut down the project. Peter Bannon, Dojo’s lead, left the company, as well.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk responded to the reports on X, saying: “It doesn’t make sense for Tesla to divide its resources and scale two quite different AI chip designs. The Tesla AI5, AI6 and subsequent chips will be excellent for inference and at least pretty good for training. All effort is focused on that.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;August 10 – &lt;/strong&gt;“Once it became clear that all paths converged to AI6, I had to shut down Dojo and make some tough personnel choices, as Dojo 2 was now an evolutionary dead end,” Musk posted on X, the social media platform he owns. “Dojo 3 arguably lives on in the form of a large number of AI6 [systems-on-a-chip] on a single board.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;September 1&lt;/strong&gt; – Tesla shares its Master Plan Part IV on social media platform X. There is no mention of Dojo or Cortex, although AI, and more specifically, “physical AI” takes a central role. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story originally published August 10, 2024. The final update of the Tesla Dojo timeline published September 2, 2025.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/02/teslas-dojo-a-timeline/</guid><pubDate>Tue, 02 Sep 2025 16:39:01 +0000</pubDate></item></channel></rss>