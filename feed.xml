<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 20 Nov 2025 18:32:41 +0000</lastBuildDate><item><title> ()</title><link>https://deepmind.com/blog/feed/basic/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://deepmind.com/blog/feed/basic/</guid></item><item><title>Three things to know about the future of electricity (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/11/20/1128167/future-of-electricity/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/GettyImages-1330843011.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 chronoton/executive-summary_0"&gt;&lt;div class="chronotonExecutiveSummary__summaryContainer--3bc10da0658ecd8e2ef22c6023461fb5"&gt;&lt;button class="chronotonExecutiveSummary__toggleButton--1cd6118db37e8a8252fc4cd8bbadcb85" type="button"&gt;&lt;span class="chronotonExecutiveSummary__toggleText--a713e14989fe65c5162db2b69cb422c9"&gt;EXECUTIVE SUMMARY&lt;/span&gt;&lt;svg class="chronotonExecutiveSummary__toggleArrow--a8c1be9c06a9f066a767b3af80d859a1" fill="none" height="7" viewBox="0 0 11 7" width="11" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M1 1L5.5 5.5L10 1" stroke="#58C0B3" stroke-linecap="round" stroke-width="1.5"&gt;&lt;/svg&gt;&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_1 html_first"&gt; &lt;p&gt;One of the dominant storylines I‚Äôve been following through 2025 is electricity‚Äîwhere and how demand is going up, how much it costs, and how this all intersects with that topic everyone is talking about: AI.&lt;/p&gt;  &lt;p&gt;Last week, the International Energy Agency released the latest version of the World Energy Outlook, the annual report that takes stock of the current state of global energy and looks toward the future. It contains some interesting insights and a few surprising figures about electricity, grids, and the state of climate change. So let‚Äôs dig into some numbers, shall we?&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;We‚Äôre in the age of electricity&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Energy demand in general is going up around the world as populations increase and economies grow. &lt;strong&gt;But electricity is the star of the show, with demand projected to grow by 40% in the next 10 years.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;China has accounted for the bulk of electricity growth for the past 10 years, and that‚Äôs going to continue. But emerging economies outside China will be a much bigger piece of the pie going forward. And while advanced economies, including the US and Europe, have seen flat demand in the past decade, the rise of AI and data centers will cause demand to climb there as well.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Air-conditioning is a major source of rising demand. &lt;/strong&gt;Growing economies will give more people access to air-conditioning; income-driven AC growth will add about 330 gigawatts to global peak demand by 2035. Rising temperatures will tack on another 170 GW in that time. Together, that‚Äôs an increase of over 10% from 2024 levels.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;AI is a local story&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;This year, AI has been the story that none of us can get away from. One number that jumped out at me from this report: In 2025, investment in data centers is expected to top $580 billion. That‚Äôs more than the $540 billion spent on the global oil supply.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;It‚Äôs no wonder, then, that the energy demands of AI are in the spotlight. One key takeaway is that these demands are vastly different in different parts of the world.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;&lt;strong&gt;Data centers still make up less than 10% of the projected increase in total electricity demand between now and 2035. &lt;/strong&gt;It‚Äôs not nothing, but it‚Äôs far outweighed by sectors like industry and appliances, including air conditioners. Even electric vehicles will add more demand to the grid than data centers.&lt;/p&gt;  &lt;p&gt;But AI will be &lt;em&gt;the&lt;/em&gt; factor for the grid in some parts of the world. &lt;strong&gt;In the US, data centers will account for half the growth in total electricity demand between now and 2030.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;And as we‚Äôve covered in this newsletter before, data centers present a unique challenge, because they tend to be clustered together, so the demand tends to be concentrated around specific communities and on specific grids. Half the data center capacity that‚Äôs in the pipeline is close to large cities.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Look out for a coal crossover&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;As we ask more from our grid, the key factor that‚Äôs going to determine what all this means for climate change is what‚Äôs supplying the electricity we‚Äôre using.&lt;/p&gt;  &lt;p&gt;As it stands, the world‚Äôs grids still primarily run on fossil fuels, so every bit of electricity growth comes with planet-warming greenhouse-gas emissions attached. That‚Äôs slowly changing, though.&lt;/p&gt;  &lt;p&gt;Together, solar and wind were the leading source of electricity in the first half of this year, overtaking coal for the first time. &lt;strong&gt;Coal use could peak and begin to fall by the end of this decade.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Nuclear could play a role in replacing fossil fuels:&lt;/strong&gt; After two decades of stagnation, the global nuclear fleet could increase by a third in the next 10 years. Solar is set to continue its meteoric rise, too. Of all the electricity demand growth we‚Äôre expecting in the next decade, 80% is in places with high-quality solar irradiation‚Äîmeaning they‚Äôre good spots for solar power.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Ultimately, there are a lot of ways in which the world is moving in the right direction on energy. But we‚Äôre far from moving fast enough&lt;/strong&gt;. Global emissions are, once again, going to hit a record high this year. To limit warming and prevent the worst effects of climate change, we need to remake our energy system, including electricity, and we need to do it faster.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark, &lt;/em&gt;MIT Technology Review&lt;em&gt;‚Äôs weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/GettyImages-1330843011.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 chronoton/executive-summary_0"&gt;&lt;div class="chronotonExecutiveSummary__summaryContainer--3bc10da0658ecd8e2ef22c6023461fb5"&gt;&lt;button class="chronotonExecutiveSummary__toggleButton--1cd6118db37e8a8252fc4cd8bbadcb85" type="button"&gt;&lt;span class="chronotonExecutiveSummary__toggleText--a713e14989fe65c5162db2b69cb422c9"&gt;EXECUTIVE SUMMARY&lt;/span&gt;&lt;svg class="chronotonExecutiveSummary__toggleArrow--a8c1be9c06a9f066a767b3af80d859a1" fill="none" height="7" viewBox="0 0 11 7" width="11" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M1 1L5.5 5.5L10 1" stroke="#58C0B3" stroke-linecap="round" stroke-width="1.5"&gt;&lt;/svg&gt;&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_1 html_first"&gt; &lt;p&gt;One of the dominant storylines I‚Äôve been following through 2025 is electricity‚Äîwhere and how demand is going up, how much it costs, and how this all intersects with that topic everyone is talking about: AI.&lt;/p&gt;  &lt;p&gt;Last week, the International Energy Agency released the latest version of the World Energy Outlook, the annual report that takes stock of the current state of global energy and looks toward the future. It contains some interesting insights and a few surprising figures about electricity, grids, and the state of climate change. So let‚Äôs dig into some numbers, shall we?&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;We‚Äôre in the age of electricity&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Energy demand in general is going up around the world as populations increase and economies grow. &lt;strong&gt;But electricity is the star of the show, with demand projected to grow by 40% in the next 10 years.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;China has accounted for the bulk of electricity growth for the past 10 years, and that‚Äôs going to continue. But emerging economies outside China will be a much bigger piece of the pie going forward. And while advanced economies, including the US and Europe, have seen flat demand in the past decade, the rise of AI and data centers will cause demand to climb there as well.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Air-conditioning is a major source of rising demand. &lt;/strong&gt;Growing economies will give more people access to air-conditioning; income-driven AC growth will add about 330 gigawatts to global peak demand by 2035. Rising temperatures will tack on another 170 GW in that time. Together, that‚Äôs an increase of over 10% from 2024 levels.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;AI is a local story&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;This year, AI has been the story that none of us can get away from. One number that jumped out at me from this report: In 2025, investment in data centers is expected to top $580 billion. That‚Äôs more than the $540 billion spent on the global oil supply.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;It‚Äôs no wonder, then, that the energy demands of AI are in the spotlight. One key takeaway is that these demands are vastly different in different parts of the world.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;&lt;strong&gt;Data centers still make up less than 10% of the projected increase in total electricity demand between now and 2035. &lt;/strong&gt;It‚Äôs not nothing, but it‚Äôs far outweighed by sectors like industry and appliances, including air conditioners. Even electric vehicles will add more demand to the grid than data centers.&lt;/p&gt;  &lt;p&gt;But AI will be &lt;em&gt;the&lt;/em&gt; factor for the grid in some parts of the world. &lt;strong&gt;In the US, data centers will account for half the growth in total electricity demand between now and 2030.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;And as we‚Äôve covered in this newsletter before, data centers present a unique challenge, because they tend to be clustered together, so the demand tends to be concentrated around specific communities and on specific grids. Half the data center capacity that‚Äôs in the pipeline is close to large cities.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Look out for a coal crossover&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;As we ask more from our grid, the key factor that‚Äôs going to determine what all this means for climate change is what‚Äôs supplying the electricity we‚Äôre using.&lt;/p&gt;  &lt;p&gt;As it stands, the world‚Äôs grids still primarily run on fossil fuels, so every bit of electricity growth comes with planet-warming greenhouse-gas emissions attached. That‚Äôs slowly changing, though.&lt;/p&gt;  &lt;p&gt;Together, solar and wind were the leading source of electricity in the first half of this year, overtaking coal for the first time. &lt;strong&gt;Coal use could peak and begin to fall by the end of this decade.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Nuclear could play a role in replacing fossil fuels:&lt;/strong&gt; After two decades of stagnation, the global nuclear fleet could increase by a third in the next 10 years. Solar is set to continue its meteoric rise, too. Of all the electricity demand growth we‚Äôre expecting in the next decade, 80% is in places with high-quality solar irradiation‚Äîmeaning they‚Äôre good spots for solar power.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Ultimately, there are a lot of ways in which the world is moving in the right direction on energy. But we‚Äôre far from moving fast enough&lt;/strong&gt;. Global emissions are, once again, going to hit a record high this year. To limit warming and prevent the worst effects of climate change, we need to remake our energy system, including electricity, and we need to do it faster.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark, &lt;/em&gt;MIT Technology Review&lt;em&gt;‚Äôs weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/11/20/1128167/future-of-electricity/</guid><pubDate>Thu, 20 Nov 2025 09:00:00 +0000</pubDate></item><item><title>Lightweight LLM powers Japanese enterprise AI deployments (AI News)</title><link>https://www.artificialintelligence-news.com/news/lightweight-llm-enterprise-deployment-single-gpu/</link><description>&lt;p&gt;Enterprise AI deployment faces a fundamental tension: organisations need sophisticated language models but baulk at the infrastructure costs and energy consumption of frontier systems.&lt;/p&gt;&lt;p&gt;NTT‚Äôs recent launch of tsuzumi 2, a lightweight large language model (LLM) running on a single GPU, demonstrates how businesses are resolving this constraint ‚Äì with early deployments showing performance matching larger models and running at a fraction of the operational cost.&lt;/p&gt;&lt;p&gt;The business case is straightforward. Traditional large language models require dozens or hundreds of GPUs, creating electricity consumption and operational cost barriers that make AI deployment impractical for many organisations.&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-110711" height="580" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/251020ac.jpg" width="1000" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;(GPU Cost Comparison)&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;For enterprises operating in markets with constrained power infrastructure or tight operational budgets, these requirements eliminate AI as a viable option. NTT‚Äôs press release illustrates the practical considerations driving lightweight LLM adoption with Tokyo Online University‚Äôs deployment.&lt;/p&gt;&lt;p&gt;The university operates an on-premise platform keeping student and staff data in its campus network ‚Äì a data sovereignty requirement common in educational institutions and regulated industries.&lt;/p&gt;&lt;p&gt;After validating that tsuzumi 2 handles complex context understanding and long-document processing at production-ready levels, the university deployed it for course Q&amp;amp;A enhancement, teaching material creation support, and personalised student guidance.&lt;/p&gt;&lt;p&gt;The single-GPU operation means the university avoids both capital expenditure for GPU clusters and ongoing electricity costs. More significantly, on-premise deployment addresses data privacy concerns that prevent many educational institutions from using cloud-based AI services that process sensitive student information.&lt;/p&gt;&lt;h3&gt;Performance without scale: The technical economics&lt;/h3&gt;&lt;p&gt;NTT‚Äôs internal evaluation for financial-system inquiry handling showed tsuzumi 2 matching or exceeding leading external models despite dramatically smaller infrastructure requirements. The performance-to-resource ratio determines AI adoption feasibility for enterprises where the total cost of ownership drives decisions.&lt;/p&gt;&lt;p&gt;The model delivers what NTT characterises as ‚Äúworld-top results among models of comparable size‚Äù in Japanese language performance, with particular strength in business domains prioritising knowledge, analysis, instruction-following, and safety.&lt;/p&gt;&lt;p&gt;For enterprises operating primarily in Japanese markets, this language optimisation reduces the need to deploy larger multilingual models requiring significantly more computational resources.&lt;/p&gt;&lt;p&gt;Reinforced knowledge in financial, medical, and public sectors ‚Äì developed based on customer demand ‚Äì enables domain-specific deployments without extensive fine-tuning.&lt;/p&gt;&lt;p&gt;The model‚Äôs RAG (Retrieval-Augmented Generation) and fine-tuning capabilities allow efficient development of specialised applications for enterprises with proprietary knowledge bases or industry-specific terminology where generic models underperform.&lt;/p&gt;&lt;h3&gt;Data sovereignty and security as business drivers&lt;/h3&gt;&lt;p&gt;Beyond cost considerations, data sovereignty drives lightweight LLM adoption in regulated industries. Organisations handling confidential information face risk exposure when processing data through external AI services subject to foreign jurisdiction.&lt;/p&gt;&lt;p&gt;NTT positions tsuzumi 2 as a ‚Äúpurely domestic model‚Äù developed from scratch in Japan, operating on-premises or in private clouds. This addresses concerns prevalent in Asia-Pacific markets about data residency, regulatory compliance, and information security.&lt;/p&gt;&lt;p&gt;FUJIFILM Business Innovation‚Äôs partnership with NTT DOCOMO BUSINESS demonstrates how enterprises combine lightweight models with existing data infrastructure. FUJIFILM‚Äôs REiLI technology converts unstructured corporate data ‚Äì contracts, proposals, mixed text and images ‚Äì into structured information.&lt;/p&gt;&lt;p&gt;Integrating tsuzumi 2‚Äôs generative capabilities enables advanced document analysis without transmitting sensitive corporate information to external AI providers. This architectural approach ‚Äì combining lightweight models with on-premise data processing ‚Äì represents a practical enterprise AI strategy balancing capability requirements with security, compliance, and cost constraints.&lt;/p&gt;&lt;h3&gt;Multimodal capabilities and enterprise workflows&lt;/h3&gt;&lt;p&gt;tsuzumi 2 includes built-in multimodal support handling text, images, and voice in enterprise applications. Thematters for business workflows requiring AI to process multiple data types without deploying separate specialised models.&lt;/p&gt;&lt;p&gt;Manufacturing quality control, customer service operations, and document processing workflows typically involve text, images, and sometimes voice inputs. Single models handling all three reduce integration complexity compared to managing multiple specialised systems with different operational requirements.&lt;/p&gt;&lt;h3&gt;Market context and implementation considerations&lt;/h3&gt;&lt;p&gt;NTT‚Äôs lightweight approach contrasts with hyperscaler strategies emphasising massive models with broad capabilities. For enterprises with substantial AI budgets and advanced technical teams, frontier models from OpenAI, Anthropic, and Google provide cutting-edge performance.&lt;/p&gt;&lt;p&gt;However, this approach excludes organisations lacking these resources ‚Äì a significant portion of the enterprise market, particularly in Asia-Pacific regions with varying infrastructure quality. Regional considerations matter.&lt;/p&gt;&lt;p&gt;Power reliability, internet connectivity, data centre availability, and regulatory frameworks vary significantly in markets. Lightweight models enabling on-premise deployment accommodate these variations better than approaches requiring consistent cloud infrastructure access.&lt;/p&gt;&lt;p&gt;Organisations evaluating lightweight LLM deployment should consider several factors:&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Domain specialisation: &lt;/strong&gt;tsuzumi 2‚Äôs reinforced knowledge in financial, medical, and public sectors addresses specific domains, but organisations in other industries should evaluate whether available domain knowledge meets their requirements.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Language considerations: &lt;/strong&gt;Optimisation for Japanese language processing benefits Japanese-market operations but may not suit multilingual enterprises requiring consistent cross-language performance.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Integration complexity: &lt;/strong&gt;On-premise deployment requires internal technical capabilities for installation, maintenance, and updates. Organisations lacking these capabilities may find cloud-based alternatives operationally simpler despite higher costs.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Performance tradeoffs: &lt;/strong&gt;While tsuzumi 2 matches larger models in specific domains, frontier models may outperform in edge cases or novel applications. Organisations should evaluate whether domain-specific performance suffices or whether broader capabilities justify higher infrastructure costs.&lt;/p&gt;&lt;h3&gt;The practical path forward?&lt;/h3&gt;&lt;p&gt;NTT‚Äôs tsuzumi 2 deployment demonstrates that sophisticated AI implementation doesn‚Äôt require hyperscale infrastructure ‚Äì at least for organisations whose requirements align with lightweight model capabilities. Early enterprise adoptions show practical business value: reduced operational costs, improved data sovereignty, and production-ready performance for specific domains.&lt;/p&gt;&lt;p&gt;As enterprises navigate AI adoption, the tension between capability requirements and operational constraints increasingly drives demand for efficient, specialised solutions rather than general-purpose systems requiring extensive infrastructure.&lt;/p&gt;&lt;p&gt;For organisations evaluating AI deployment strategies, the question isn‚Äôt whether lightweight models are ‚Äúbetter‚Äù than frontier systems ‚Äì it‚Äôs whether they‚Äôre sufficient for specific business requirements while addressing cost, security, and operational constraints that make alternative approaches impractical.&lt;/p&gt;&lt;p&gt;The answer, as Tokyo Online University and FUJIFILM Business Innovation deployments demonstrate, is increasingly yes.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;How Levi Strauss is using AI for its DTC-first business model&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Enterprise AI deployment faces a fundamental tension: organisations need sophisticated language models but baulk at the infrastructure costs and energy consumption of frontier systems.&lt;/p&gt;&lt;p&gt;NTT‚Äôs recent launch of tsuzumi 2, a lightweight large language model (LLM) running on a single GPU, demonstrates how businesses are resolving this constraint ‚Äì with early deployments showing performance matching larger models and running at a fraction of the operational cost.&lt;/p&gt;&lt;p&gt;The business case is straightforward. Traditional large language models require dozens or hundreds of GPUs, creating electricity consumption and operational cost barriers that make AI deployment impractical for many organisations.&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-110711" height="580" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/251020ac.jpg" width="1000" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;(GPU Cost Comparison)&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;For enterprises operating in markets with constrained power infrastructure or tight operational budgets, these requirements eliminate AI as a viable option. NTT‚Äôs press release illustrates the practical considerations driving lightweight LLM adoption with Tokyo Online University‚Äôs deployment.&lt;/p&gt;&lt;p&gt;The university operates an on-premise platform keeping student and staff data in its campus network ‚Äì a data sovereignty requirement common in educational institutions and regulated industries.&lt;/p&gt;&lt;p&gt;After validating that tsuzumi 2 handles complex context understanding and long-document processing at production-ready levels, the university deployed it for course Q&amp;amp;A enhancement, teaching material creation support, and personalised student guidance.&lt;/p&gt;&lt;p&gt;The single-GPU operation means the university avoids both capital expenditure for GPU clusters and ongoing electricity costs. More significantly, on-premise deployment addresses data privacy concerns that prevent many educational institutions from using cloud-based AI services that process sensitive student information.&lt;/p&gt;&lt;h3&gt;Performance without scale: The technical economics&lt;/h3&gt;&lt;p&gt;NTT‚Äôs internal evaluation for financial-system inquiry handling showed tsuzumi 2 matching or exceeding leading external models despite dramatically smaller infrastructure requirements. The performance-to-resource ratio determines AI adoption feasibility for enterprises where the total cost of ownership drives decisions.&lt;/p&gt;&lt;p&gt;The model delivers what NTT characterises as ‚Äúworld-top results among models of comparable size‚Äù in Japanese language performance, with particular strength in business domains prioritising knowledge, analysis, instruction-following, and safety.&lt;/p&gt;&lt;p&gt;For enterprises operating primarily in Japanese markets, this language optimisation reduces the need to deploy larger multilingual models requiring significantly more computational resources.&lt;/p&gt;&lt;p&gt;Reinforced knowledge in financial, medical, and public sectors ‚Äì developed based on customer demand ‚Äì enables domain-specific deployments without extensive fine-tuning.&lt;/p&gt;&lt;p&gt;The model‚Äôs RAG (Retrieval-Augmented Generation) and fine-tuning capabilities allow efficient development of specialised applications for enterprises with proprietary knowledge bases or industry-specific terminology where generic models underperform.&lt;/p&gt;&lt;h3&gt;Data sovereignty and security as business drivers&lt;/h3&gt;&lt;p&gt;Beyond cost considerations, data sovereignty drives lightweight LLM adoption in regulated industries. Organisations handling confidential information face risk exposure when processing data through external AI services subject to foreign jurisdiction.&lt;/p&gt;&lt;p&gt;NTT positions tsuzumi 2 as a ‚Äúpurely domestic model‚Äù developed from scratch in Japan, operating on-premises or in private clouds. This addresses concerns prevalent in Asia-Pacific markets about data residency, regulatory compliance, and information security.&lt;/p&gt;&lt;p&gt;FUJIFILM Business Innovation‚Äôs partnership with NTT DOCOMO BUSINESS demonstrates how enterprises combine lightweight models with existing data infrastructure. FUJIFILM‚Äôs REiLI technology converts unstructured corporate data ‚Äì contracts, proposals, mixed text and images ‚Äì into structured information.&lt;/p&gt;&lt;p&gt;Integrating tsuzumi 2‚Äôs generative capabilities enables advanced document analysis without transmitting sensitive corporate information to external AI providers. This architectural approach ‚Äì combining lightweight models with on-premise data processing ‚Äì represents a practical enterprise AI strategy balancing capability requirements with security, compliance, and cost constraints.&lt;/p&gt;&lt;h3&gt;Multimodal capabilities and enterprise workflows&lt;/h3&gt;&lt;p&gt;tsuzumi 2 includes built-in multimodal support handling text, images, and voice in enterprise applications. Thematters for business workflows requiring AI to process multiple data types without deploying separate specialised models.&lt;/p&gt;&lt;p&gt;Manufacturing quality control, customer service operations, and document processing workflows typically involve text, images, and sometimes voice inputs. Single models handling all three reduce integration complexity compared to managing multiple specialised systems with different operational requirements.&lt;/p&gt;&lt;h3&gt;Market context and implementation considerations&lt;/h3&gt;&lt;p&gt;NTT‚Äôs lightweight approach contrasts with hyperscaler strategies emphasising massive models with broad capabilities. For enterprises with substantial AI budgets and advanced technical teams, frontier models from OpenAI, Anthropic, and Google provide cutting-edge performance.&lt;/p&gt;&lt;p&gt;However, this approach excludes organisations lacking these resources ‚Äì a significant portion of the enterprise market, particularly in Asia-Pacific regions with varying infrastructure quality. Regional considerations matter.&lt;/p&gt;&lt;p&gt;Power reliability, internet connectivity, data centre availability, and regulatory frameworks vary significantly in markets. Lightweight models enabling on-premise deployment accommodate these variations better than approaches requiring consistent cloud infrastructure access.&lt;/p&gt;&lt;p&gt;Organisations evaluating lightweight LLM deployment should consider several factors:&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Domain specialisation: &lt;/strong&gt;tsuzumi 2‚Äôs reinforced knowledge in financial, medical, and public sectors addresses specific domains, but organisations in other industries should evaluate whether available domain knowledge meets their requirements.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Language considerations: &lt;/strong&gt;Optimisation for Japanese language processing benefits Japanese-market operations but may not suit multilingual enterprises requiring consistent cross-language performance.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Integration complexity: &lt;/strong&gt;On-premise deployment requires internal technical capabilities for installation, maintenance, and updates. Organisations lacking these capabilities may find cloud-based alternatives operationally simpler despite higher costs.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Performance tradeoffs: &lt;/strong&gt;While tsuzumi 2 matches larger models in specific domains, frontier models may outperform in edge cases or novel applications. Organisations should evaluate whether domain-specific performance suffices or whether broader capabilities justify higher infrastructure costs.&lt;/p&gt;&lt;h3&gt;The practical path forward?&lt;/h3&gt;&lt;p&gt;NTT‚Äôs tsuzumi 2 deployment demonstrates that sophisticated AI implementation doesn‚Äôt require hyperscale infrastructure ‚Äì at least for organisations whose requirements align with lightweight model capabilities. Early enterprise adoptions show practical business value: reduced operational costs, improved data sovereignty, and production-ready performance for specific domains.&lt;/p&gt;&lt;p&gt;As enterprises navigate AI adoption, the tension between capability requirements and operational constraints increasingly drives demand for efficient, specialised solutions rather than general-purpose systems requiring extensive infrastructure.&lt;/p&gt;&lt;p&gt;For organisations evaluating AI deployment strategies, the question isn‚Äôt whether lightweight models are ‚Äúbetter‚Äù than frontier systems ‚Äì it‚Äôs whether they‚Äôre sufficient for specific business requirements while addressing cost, security, and operational constraints that make alternative approaches impractical.&lt;/p&gt;&lt;p&gt;The answer, as Tokyo Online University and FUJIFILM Business Innovation deployments demonstrate, is increasingly yes.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;How Levi Strauss is using AI for its DTC-first business model&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/lightweight-llm-enterprise-deployment-single-gpu/</guid><pubDate>Thu, 20 Nov 2025 12:00:00 +0000</pubDate></item><item><title>[NEW] Finland‚Äôs NestAI lands ‚Ç¨100M, partners with Nokia to build AI for defense applications (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/20/finlands-nestai-lands-e100m-partners-with-nokia-to-build-ai-for-defense-applications/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/Peter-Sarlin-at-AI-Summit-2025-image-credits-Vesa-Matti-Vaara.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Finnish startup NestAI has raised ‚Ç¨100 million (about $115 million) in a funding round led by Finland‚Äôs sovereign fund, Tesi, and hardware giant Nokia to build AI products for use in unmanned vehicles, autonomous operations, and command and control platforms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;NestAI has also struck a partnership with Nokia to build AI products for defense applications and develop ‚Äúphysical AI,‚Äù which involves using large language models and related technology for robotics and other real-world applications.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The funding will help NestAI build ‚ÄúEurope‚Äôs leading physical AI lab,‚Äù co-founder Peter Sarlin said at the Slush 2025 technology conference in Helsinki.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Physical AI has been a growing research field both for Big Tech and startups, and NestAI‚Äôs funding round shows there‚Äôs space for European companies to develop homegrown solutions to address the continent‚Äôs needs ‚Äî which have leaned toward defense applications due to the prolonged Ukraine-Russia war. Last month, the startup announced it would support the Finnish Defence Forces in adopting AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This focus on sovereignty may explain why NestAI has been in stealth so far, but it is now building in public, supported by Sarlin, who has been funding the venture for the past few months through his family office, PostScriptum.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúIn line with PostScriptum‚Äôs mission, NestAI has from the start set out to become Europe‚Äôs leading physical AI lab to drive technological sovereignty,‚Äù Sarlin told TechCrunch. ‚ÄúThis partnership also marks an important step in securing Europe‚Äôs defense capabilities and sovereignty.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After selling AI startup Silo AI to AMD for $665 million last year, Sarlin has been active as a philanthropist and investor, backing startups like Legora and Lovable. While he‚Äôs building NestAI, his day job is still at AMD, and he will only act as the startup‚Äôs chairman, not its CEO.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;NestAI doesn‚Äôt have a CEO yet, but its growing team has attracted talent with experience in AI research and hardware projects that overlap with defense. A significant number of its staff formerly worked for Intel, while others were formerly employed by the likes of Kongsberg, Palantir, and Saab.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/Peter-Sarlin-at-AI-Summit-2025-image-credits-Vesa-Matti-Vaara.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Finnish startup NestAI has raised ‚Ç¨100 million (about $115 million) in a funding round led by Finland‚Äôs sovereign fund, Tesi, and hardware giant Nokia to build AI products for use in unmanned vehicles, autonomous operations, and command and control platforms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;NestAI has also struck a partnership with Nokia to build AI products for defense applications and develop ‚Äúphysical AI,‚Äù which involves using large language models and related technology for robotics and other real-world applications.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The funding will help NestAI build ‚ÄúEurope‚Äôs leading physical AI lab,‚Äù co-founder Peter Sarlin said at the Slush 2025 technology conference in Helsinki.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Physical AI has been a growing research field both for Big Tech and startups, and NestAI‚Äôs funding round shows there‚Äôs space for European companies to develop homegrown solutions to address the continent‚Äôs needs ‚Äî which have leaned toward defense applications due to the prolonged Ukraine-Russia war. Last month, the startup announced it would support the Finnish Defence Forces in adopting AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This focus on sovereignty may explain why NestAI has been in stealth so far, but it is now building in public, supported by Sarlin, who has been funding the venture for the past few months through his family office, PostScriptum.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúIn line with PostScriptum‚Äôs mission, NestAI has from the start set out to become Europe‚Äôs leading physical AI lab to drive technological sovereignty,‚Äù Sarlin told TechCrunch. ‚ÄúThis partnership also marks an important step in securing Europe‚Äôs defense capabilities and sovereignty.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After selling AI startup Silo AI to AMD for $665 million last year, Sarlin has been active as a philanthropist and investor, backing startups like Legora and Lovable. While he‚Äôs building NestAI, his day job is still at AMD, and he will only act as the startup‚Äôs chairman, not its CEO.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;NestAI doesn‚Äôt have a CEO yet, but its growing team has attracted talent with experience in AI research and hardware projects that overlap with defense. A significant number of its staff formerly worked for Intel, while others were formerly employed by the likes of Kongsberg, Palantir, and Saab.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/20/finlands-nestai-lands-e100m-partners-with-nokia-to-build-ai-for-defense-applications/</guid><pubDate>Thu, 20 Nov 2025 13:04:11 +0000</pubDate></item><item><title>[NEW] The Download: what‚Äôs next for electricity, and living in the conspiracy age (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/11/20/1128183/the-download-whats-next-for-electricity-and-living-in-the-conspiracy-age/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Three things to know about the future of electricity&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The International Energy Agency recently released the latest version of the World Energy Outlook, the annual report that takes stock of the current state of global energy and looks toward the future. &lt;/p&gt;&lt;p&gt;It contains some interesting insights and a few surprising figures about electricity, grids, and the state of climate change. Let‚Äôs dig into some numbers.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;‚ÄîCasey Crownhart&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;This article is from The Spark, MIT Technology Review‚Äôs weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;How to survive in the new age of conspiracies&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Everything is a conspiracy theory now. Our latest series ‚ÄúThe New Conspiracy Age‚Äù delves into how conspiracies have gripped the White House, turning fringe ideas into dangerous policy, and how generative AI is altering the fabric of truth.&lt;/p&gt;&lt;p&gt;If you‚Äôre interested in hearing more about how to survive in this strange new age, join our features editor Amanda Silverman and executive editor Niall Firth today at 1pm ET for an subscriber-exclusive Roundtable conversation. They‚Äôll be joined by conspiracy expert Mike Rothschild, who‚Äôs written a fascinating piece for us about what it‚Äôs like to find yourself at the heart of a conspiracy theory. Register now to join us!&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;em&gt;I‚Äôve combed the internet to find you today‚Äôs most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Donald Trump is poised to ban AI state laws&lt;/strong&gt;&lt;br /&gt;The US President is considering signing an order to give the federal government unilateral power over regulating AI. (The Verge)&lt;br /&gt;+ &lt;em&gt;It would give the Justice Department power to sue dissenting states. &lt;/em&gt;(WP $)&lt;br /&gt;+ &lt;em&gt;Critics claim the draft undermines trust in the US‚Äôs ability to make AI safe. &lt;/em&gt;(Wired $)&lt;br /&gt;+ &lt;em&gt;It‚Äôs not just America‚Äîthe EU fumbled its attempts to rein in AI, too. &lt;/em&gt;(FT $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 The CDC is making false claims about a link between vaccines and autism&lt;/strong&gt;&lt;br /&gt;Despite previously spending decades fighting misinformation connecting them. (WP $)&lt;br /&gt;+ &lt;em&gt;The National Institutes of Health is parroting RFK Jr‚Äôs messaging, too. &lt;/em&gt;(The Atlantic $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 China is going all-in on autonomous vehicles&lt;/strong&gt;&lt;br /&gt;Which is bad news for its millions of delivery drivers. (FT $)&lt;br /&gt;+ &lt;em&gt;It‚Äôs also throwing its full weight behind its native EV industry. &lt;/em&gt;(Rest of World)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 Major music labels have inked a deal with an AI streaming service&lt;/strong&gt;&lt;br /&gt;Klay users will be able to remodel songs from the likes of Universal using AI. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;What happens next is anyone‚Äôs guess. &lt;/em&gt;(Billboard $)&lt;br /&gt;+ &lt;em&gt;AI is coming for music, too. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 How quantum sensors could overhaul GPS navigation&lt;br /&gt;&lt;/strong&gt;Current GPS is vulnerable to spoofing and jamming. But what comes next? (WSJ $)&lt;br /&gt;+ &lt;em&gt;Inside the race to find GPS alternatives. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;6 There‚Äôs a divide inside the community of people in relationships with chatbots&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Some users assert their love interests are real‚Äîto the concern of others. (NY Mag $)&lt;br /&gt;+ &lt;em&gt;It‚Äôs surprisingly easy to stumble into a relationship with an AI chatbot. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 There‚Äôs still hope for a functional cure to HIV&lt;br /&gt;&lt;/strong&gt;Even in the face of crippling funding cuts. (Knowable Magazine)&lt;br /&gt;+ &lt;em&gt;Breakthrough drug lenacapavir is being rolled out in parts of Africa. &lt;/em&gt;(NPR)&lt;br /&gt;+ &lt;em&gt;This annual shot might protect against HIV infections. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 Is it possible to reverse years of AI brainrot?&lt;br /&gt;&lt;/strong&gt;A new wave of memes is fighting the good fight. (Wired $)&lt;br /&gt;+ &lt;em&gt;How to fix the internet. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 Tourists fell for an AI-generated Christmas market outside Buckingham Palace üéÑ&lt;/strong&gt;&lt;br /&gt;If it looks too good to be true, it probably is. (The Guardian)&lt;br /&gt;+ &lt;em&gt;It‚Äôs unclear who is behind the pictures, which spread on Instagram. &lt;/em&gt;(BBC)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;10 Here‚Äôs what people return to Amazon&lt;/strong&gt;&lt;br /&gt;A whole lot of polyester clothing, by the sounds of it. (NYT $)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;‚ÄúI think we‚Äôre in an LLM bubble, and I think the LLM bubble might be bursting next year.‚Äù&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;‚ÄîHugging Face co-founder and CEO Clem Delangue has a slightly different take on the reports we‚Äôre in an AI bubble, TechCrunch reports.&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1128188" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/image_5c3272.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;I&lt;/strong&gt;&lt;strong&gt;nside a new quest to save the ‚Äúdoomsday glacier‚Äù&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The Thwaites glacier is a fortress larger than Florida, a wall of ice that reaches nearly 4,000 feet above the bedrock of West Antarctica, guarding the low-lying ice sheet behind it.&lt;/p&gt;&lt;p&gt;But a strong, warm ocean current is weakening its foundations and accelerating its slide into the sea. Scientists fear the waters could topple the walls in the coming decades, kick-starting a runaway process that would crack up the West Antarctic Ice Sheet, marking the start of a global climate disaster. As a result, they are eager to understand just how likely such a collapse is, when it could happen, and if we have the power to stop it. Read the full story.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;‚ÄîJames Temple&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ As Christmas approaches, micro-gifting might be a fun new tradition to try out.&lt;br /&gt;+ I‚Äôve said it before and I‚Äôll say it again‚Äîmovies are too long these days.&lt;br /&gt;+ If you‚Äôre feeling a bit existential this morning, these books are a great starting point for finding a sense of purpose.&lt;br /&gt;+ This is a fun list of the internet‚Äôs weird and wonderful obsessive lists.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Three things to know about the future of electricity&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The International Energy Agency recently released the latest version of the World Energy Outlook, the annual report that takes stock of the current state of global energy and looks toward the future. &lt;/p&gt;&lt;p&gt;It contains some interesting insights and a few surprising figures about electricity, grids, and the state of climate change. Let‚Äôs dig into some numbers.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;‚ÄîCasey Crownhart&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;This article is from The Spark, MIT Technology Review‚Äôs weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;How to survive in the new age of conspiracies&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Everything is a conspiracy theory now. Our latest series ‚ÄúThe New Conspiracy Age‚Äù delves into how conspiracies have gripped the White House, turning fringe ideas into dangerous policy, and how generative AI is altering the fabric of truth.&lt;/p&gt;&lt;p&gt;If you‚Äôre interested in hearing more about how to survive in this strange new age, join our features editor Amanda Silverman and executive editor Niall Firth today at 1pm ET for an subscriber-exclusive Roundtable conversation. They‚Äôll be joined by conspiracy expert Mike Rothschild, who‚Äôs written a fascinating piece for us about what it‚Äôs like to find yourself at the heart of a conspiracy theory. Register now to join us!&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;em&gt;I‚Äôve combed the internet to find you today‚Äôs most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Donald Trump is poised to ban AI state laws&lt;/strong&gt;&lt;br /&gt;The US President is considering signing an order to give the federal government unilateral power over regulating AI. (The Verge)&lt;br /&gt;+ &lt;em&gt;It would give the Justice Department power to sue dissenting states. &lt;/em&gt;(WP $)&lt;br /&gt;+ &lt;em&gt;Critics claim the draft undermines trust in the US‚Äôs ability to make AI safe. &lt;/em&gt;(Wired $)&lt;br /&gt;+ &lt;em&gt;It‚Äôs not just America‚Äîthe EU fumbled its attempts to rein in AI, too. &lt;/em&gt;(FT $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 The CDC is making false claims about a link between vaccines and autism&lt;/strong&gt;&lt;br /&gt;Despite previously spending decades fighting misinformation connecting them. (WP $)&lt;br /&gt;+ &lt;em&gt;The National Institutes of Health is parroting RFK Jr‚Äôs messaging, too. &lt;/em&gt;(The Atlantic $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 China is going all-in on autonomous vehicles&lt;/strong&gt;&lt;br /&gt;Which is bad news for its millions of delivery drivers. (FT $)&lt;br /&gt;+ &lt;em&gt;It‚Äôs also throwing its full weight behind its native EV industry. &lt;/em&gt;(Rest of World)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 Major music labels have inked a deal with an AI streaming service&lt;/strong&gt;&lt;br /&gt;Klay users will be able to remodel songs from the likes of Universal using AI. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;What happens next is anyone‚Äôs guess. &lt;/em&gt;(Billboard $)&lt;br /&gt;+ &lt;em&gt;AI is coming for music, too. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 How quantum sensors could overhaul GPS navigation&lt;br /&gt;&lt;/strong&gt;Current GPS is vulnerable to spoofing and jamming. But what comes next? (WSJ $)&lt;br /&gt;+ &lt;em&gt;Inside the race to find GPS alternatives. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;6 There‚Äôs a divide inside the community of people in relationships with chatbots&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Some users assert their love interests are real‚Äîto the concern of others. (NY Mag $)&lt;br /&gt;+ &lt;em&gt;It‚Äôs surprisingly easy to stumble into a relationship with an AI chatbot. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 There‚Äôs still hope for a functional cure to HIV&lt;br /&gt;&lt;/strong&gt;Even in the face of crippling funding cuts. (Knowable Magazine)&lt;br /&gt;+ &lt;em&gt;Breakthrough drug lenacapavir is being rolled out in parts of Africa. &lt;/em&gt;(NPR)&lt;br /&gt;+ &lt;em&gt;This annual shot might protect against HIV infections. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 Is it possible to reverse years of AI brainrot?&lt;br /&gt;&lt;/strong&gt;A new wave of memes is fighting the good fight. (Wired $)&lt;br /&gt;+ &lt;em&gt;How to fix the internet. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 Tourists fell for an AI-generated Christmas market outside Buckingham Palace üéÑ&lt;/strong&gt;&lt;br /&gt;If it looks too good to be true, it probably is. (The Guardian)&lt;br /&gt;+ &lt;em&gt;It‚Äôs unclear who is behind the pictures, which spread on Instagram. &lt;/em&gt;(BBC)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;10 Here‚Äôs what people return to Amazon&lt;/strong&gt;&lt;br /&gt;A whole lot of polyester clothing, by the sounds of it. (NYT $)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;‚ÄúI think we‚Äôre in an LLM bubble, and I think the LLM bubble might be bursting next year.‚Äù&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;‚ÄîHugging Face co-founder and CEO Clem Delangue has a slightly different take on the reports we‚Äôre in an AI bubble, TechCrunch reports.&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1128188" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/image_5c3272.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;I&lt;/strong&gt;&lt;strong&gt;nside a new quest to save the ‚Äúdoomsday glacier‚Äù&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The Thwaites glacier is a fortress larger than Florida, a wall of ice that reaches nearly 4,000 feet above the bedrock of West Antarctica, guarding the low-lying ice sheet behind it.&lt;/p&gt;&lt;p&gt;But a strong, warm ocean current is weakening its foundations and accelerating its slide into the sea. Scientists fear the waters could topple the walls in the coming decades, kick-starting a runaway process that would crack up the West Antarctic Ice Sheet, marking the start of a global climate disaster. As a result, they are eager to understand just how likely such a collapse is, when it could happen, and if we have the power to stop it. Read the full story.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;‚ÄîJames Temple&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ As Christmas approaches, micro-gifting might be a fun new tradition to try out.&lt;br /&gt;+ I‚Äôve said it before and I‚Äôll say it again‚Äîmovies are too long these days.&lt;br /&gt;+ If you‚Äôre feeling a bit existential this morning, these books are a great starting point for finding a sense of purpose.&lt;br /&gt;+ This is a fun list of the internet‚Äôs weird and wonderful obsessive lists.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/11/20/1128183/the-download-whats-next-for-electricity-and-living-in-the-conspiracy-age/</guid><pubDate>Thu, 20 Nov 2025 13:10:00 +0000</pubDate></item><item><title>[NEW] Pure Storage and Azure‚Äôs role in AI-ready data for enterprises (AI News)</title><link>https://www.artificialintelligence-news.com/news/pure-storage-and-azures-role-in-ai-ready-data-for-enterprise/</link><description>&lt;p&gt;Many organisations are trying to update their infrastructure to improve efficiency and manage rising costs. But the path is rarely simple. Hybrid setups, legacy systems, and new demands from AI in the enterprise often create trade-offs for IT teams.&lt;/p&gt;&lt;p&gt;Recent moves by Microsoft and several storage and data-platform vendors highlight how enterprises are trying to deal with these issues, and what other companies can learn from them as they plan their own enterprise AI strategies.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Modernisation often stalls when costs rise&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Many businesses want the flexibility of cloud computing but still depend on systems built on virtual machines and years of internal processes. A common problem is that older applications were never built for the cloud. Rewriting them can take time and create new risks. But a simple ‚Äúlift and shift‚Äù move often leads to higher bills, especially when teams do not change how the workloads run.&lt;/p&gt;&lt;p&gt;Some vendors are trying to address this by offering ways to move virtual machines to Azure without major changes. Early users say the draw is the chance to test cloud migration without reworking applications on day one. For some, this early testing is tied to preparing systems that will later support enterprise AI workloads.&lt;/p&gt;&lt;p&gt;They also point to lower storage costs when managed through Azure‚Äôs own tools, which helps keep the move predictable. The key lesson for other companies is to look for migration paths that match their existing operations instead of forcing a full rebuild from the start.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Data protection and control remain top concerns in hybrid environments&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The risk of data loss or long outages still keeps many leaders cautious about large modernisation plans. Some organisations are now building stronger recovery systems in on-premises, edge, and cloud locations. Standard planning now includes features like immutable snapshots, replication, and better visibility of compromised data.&lt;/p&gt;&lt;p&gt;A recent integration between Microsoft Azure and several storage systems seeks to give companies a way to manage data in on-premises hardware and Azure services. Interest has grown among organisations that need local data residency or strict compliance rules. These setups let them keep sensitive data in-country while still working with Azure tools, which is increasingly important as enterprise AI applications depend on reliable and well-governed data.&lt;/p&gt;&lt;p&gt;For businesses facing similar pressures, the main takeaway is that hybrid models can support compliance needs when the control layer is unified.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Preparing for AI often requires stronger data foundations, not a full rebuild&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Many companies want to support AI projects but don‚Äôt want to overhaul their entire infrastructure. Microsoft‚Äôs SQL Server 2025 adds vector database features that let teams build AI-driven applications without switching platforms. Some enterprises have paired SQL Server with high-performance storage arrays to improve throughput and reduce the size of AI-related data sets. The improvements are becoming part of broader enterprise AI planning.&lt;/p&gt;&lt;p&gt;Teams working with these setups say the attraction is the chance to run early AI workloads without committing to a new stack. They also report that more predictable performance helps them scale when teams begin to train or test new models. The larger lesson is that AI readiness often starts with improving the systems that already hold business data instead of adopting a separate platform.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Managing Kubernetes alongside older systems introduces new complexity&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Many enterprises now run a mix of containers and virtual machines. Keeping both in sync can strain teams, especially when workloads run in more than one cloud. Some companies are turning to unified data-management tools that allow Kubernetes environments to sit alongside legacy applications.&lt;/p&gt;&lt;p&gt;One example is the growing use of Portworx with Azure Kubernetes Service and Azure Red Hat OpenShift. Some teams use it to move VMs into Kubernetes through KubeVirt while keeping familiar workflows for automation. The approach aims to reduce overprovisioning and make capacity easier to plan. For others, it is part of a broader effort to make their infrastructure ready to support enterprise AI initiatives. It also gives companies a slower, safer path to container adoption. The broader lesson is that hybrid container strategies work best when they respect existing skills rather than forcing dramatic shifts.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A clearer path is emerging for companies planning modernisation&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Across these examples, a common theme stands out: most enterprises are not trying to rebuild everything at once. They want predictable migration plans, stronger data protection, and practical ways to support early AI projects. The tools and partnerships now forming around Azure suggest that modernisation is becoming less about replacing systems and more about improving what is already in place.&lt;/p&gt;&lt;p&gt;Companies that approach modernisation in small, steady steps ‚Äì while keeping cost, security, and data needs in view ‚Äì may find it easier to move forward without taking on unnecessary risk.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Bain &amp;amp; Company issues AI Guide for CEOs, opens Singapore hub&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-110721" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/image-9.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Many organisations are trying to update their infrastructure to improve efficiency and manage rising costs. But the path is rarely simple. Hybrid setups, legacy systems, and new demands from AI in the enterprise often create trade-offs for IT teams.&lt;/p&gt;&lt;p&gt;Recent moves by Microsoft and several storage and data-platform vendors highlight how enterprises are trying to deal with these issues, and what other companies can learn from them as they plan their own enterprise AI strategies.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Modernisation often stalls when costs rise&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Many businesses want the flexibility of cloud computing but still depend on systems built on virtual machines and years of internal processes. A common problem is that older applications were never built for the cloud. Rewriting them can take time and create new risks. But a simple ‚Äúlift and shift‚Äù move often leads to higher bills, especially when teams do not change how the workloads run.&lt;/p&gt;&lt;p&gt;Some vendors are trying to address this by offering ways to move virtual machines to Azure without major changes. Early users say the draw is the chance to test cloud migration without reworking applications on day one. For some, this early testing is tied to preparing systems that will later support enterprise AI workloads.&lt;/p&gt;&lt;p&gt;They also point to lower storage costs when managed through Azure‚Äôs own tools, which helps keep the move predictable. The key lesson for other companies is to look for migration paths that match their existing operations instead of forcing a full rebuild from the start.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Data protection and control remain top concerns in hybrid environments&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The risk of data loss or long outages still keeps many leaders cautious about large modernisation plans. Some organisations are now building stronger recovery systems in on-premises, edge, and cloud locations. Standard planning now includes features like immutable snapshots, replication, and better visibility of compromised data.&lt;/p&gt;&lt;p&gt;A recent integration between Microsoft Azure and several storage systems seeks to give companies a way to manage data in on-premises hardware and Azure services. Interest has grown among organisations that need local data residency or strict compliance rules. These setups let them keep sensitive data in-country while still working with Azure tools, which is increasingly important as enterprise AI applications depend on reliable and well-governed data.&lt;/p&gt;&lt;p&gt;For businesses facing similar pressures, the main takeaway is that hybrid models can support compliance needs when the control layer is unified.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Preparing for AI often requires stronger data foundations, not a full rebuild&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Many companies want to support AI projects but don‚Äôt want to overhaul their entire infrastructure. Microsoft‚Äôs SQL Server 2025 adds vector database features that let teams build AI-driven applications without switching platforms. Some enterprises have paired SQL Server with high-performance storage arrays to improve throughput and reduce the size of AI-related data sets. The improvements are becoming part of broader enterprise AI planning.&lt;/p&gt;&lt;p&gt;Teams working with these setups say the attraction is the chance to run early AI workloads without committing to a new stack. They also report that more predictable performance helps them scale when teams begin to train or test new models. The larger lesson is that AI readiness often starts with improving the systems that already hold business data instead of adopting a separate platform.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Managing Kubernetes alongside older systems introduces new complexity&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Many enterprises now run a mix of containers and virtual machines. Keeping both in sync can strain teams, especially when workloads run in more than one cloud. Some companies are turning to unified data-management tools that allow Kubernetes environments to sit alongside legacy applications.&lt;/p&gt;&lt;p&gt;One example is the growing use of Portworx with Azure Kubernetes Service and Azure Red Hat OpenShift. Some teams use it to move VMs into Kubernetes through KubeVirt while keeping familiar workflows for automation. The approach aims to reduce overprovisioning and make capacity easier to plan. For others, it is part of a broader effort to make their infrastructure ready to support enterprise AI initiatives. It also gives companies a slower, safer path to container adoption. The broader lesson is that hybrid container strategies work best when they respect existing skills rather than forcing dramatic shifts.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A clearer path is emerging for companies planning modernisation&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Across these examples, a common theme stands out: most enterprises are not trying to rebuild everything at once. They want predictable migration plans, stronger data protection, and practical ways to support early AI projects. The tools and partnerships now forming around Azure suggest that modernisation is becoming less about replacing systems and more about improving what is already in place.&lt;/p&gt;&lt;p&gt;Companies that approach modernisation in small, steady steps ‚Äì while keeping cost, security, and data needs in view ‚Äì may find it easier to move forward without taking on unnecessary risk.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Bain &amp;amp; Company issues AI Guide for CEOs, opens Singapore hub&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-110721" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/image-9.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/pure-storage-and-azures-role-in-ai-ready-data-for-enterprise/</guid><pubDate>Thu, 20 Nov 2025 13:11:00 +0000</pubDate></item><item><title>[NEW] Sortera is turning America‚Äôs scrap aluminum problem into cash (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/20/sortera-is-turning-americas-scrap-aluminum-problem-into-cash/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/09/GettyImages-180404126-e1694911368750.jpg?resize=1200,676" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;When it comes to recycling, few materials can match aluminum. It can be reused an infinite number of times, and it‚Äôs often cheaper to recycle than to produce new aluminum because it requires so much less energy. Yet only about a third of the aluminum used in the U.S. gets recycled.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The problem lies in sorting mixed aluminum scrap ‚Äî a challenge that has long stumped the recycling industry.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Michael Siemer, CEO of Sortera, thinks his company has found the key, though. Sortera says it has developed a system that can separate aluminum grades with over 95% accuracy ‚Äî a breakthrough that could unlock a massive untapped resource in the recycling industry.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Here‚Äôs how it works: The company uses an AI model that identifies different grades of aluminum based on data from lasers, X-ray fluorescence, and high-speed cameras. The system has to classify each chip ‚Äî about the size of a large potato chip ‚Äî in a fraction of a second. ‚ÄúTen milliseconds is a long time,‚Äù Siemer says. Once the vision system identifies the grade, a series of nozzles blow precise puffs of air to flip the chip off the belt and into the correct bin.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That speed and accuracy matters because other recycling operations must melt the aluminum first before they can tell which type of alloy it is. And if alloys aren‚Äôt sorted properly, the mixed heap is worth far less because customers can‚Äôt be confident it will have the properties they need.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúPeople have been wanting to go after [this unsorted aluminum], and nobody‚Äôs been able to unlock it,‚Äù says Siemer.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sortera‚Äôs sorting accuracy has further helped the company unlock something else many startups seek: profitability. ‚ÄúThe margin is exponential above 90%, [while] 92% gets you a nice little margin, 95% gets you a big margin, [and] 98% is a really big margin.‚Äù&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;That‚Äôs helped the company become cash flow positive since August, he says, all based on the operation of a single plant in Indiana. To build a second plant in Tennessee, Sortera recently raised $20 million in equity and $25 million in debt in a round led by VXI Capital and accounts advised by T. Rowe Price, with participation from Overlay Capital and Yamaha Motor Ventures, the company exclusively told TechCrunch. Trinity Capital is providing additional equipment funding.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new plant, which is being built near Nashville, will come online in April or May. ‚ÄúIt‚Äôs a replica of our Indiana plant,‚Äù Siemer says. At the Indiana facility, he says, ‚Äúwe run full-tilt, 24-7, and we‚Äôre running millions of pounds a month.‚Äù&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;So where does all that aluminum come from? The scrap aluminum that Sortera receives tends to come from shredded automobiles. Each aluminum grade fractures differently when shredded, and those visual differences help the AI classify the metal. ‚ÄúThe chemical differences manifest themselves in the shredding,‚Äù Siemer says. Different alloys produce distinctive tears and folds that give the system clues. ‚ÄúYou gain these little insights so that in about a 10-millisecond time window, you go, ‚ÄòI‚Äôm pretty darn sure that‚Äôs 356 [grade aluminum],‚Äù Siemer says.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As Sortera expands, much of its aluminum will likely end up back on automotive assembly lines. Automotive manufacturers have been using increasing amounts of the metal to reduce vehicle weight and improve fuel efficiency. ‚ÄúEvery auto OEM on the planet has been to Indiana at least twice,‚Äù Siemer says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sortera is currently working on ways to process other metals like copper and titanium, but for the near future, the company remains focused on aluminum. ‚ÄúWe could instantly sort the 18 billion tons of aluminum made annually in the U.S. Every piece of that, every pound would be sold at a profit in the U.S.‚Äù&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/09/GettyImages-180404126-e1694911368750.jpg?resize=1200,676" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;When it comes to recycling, few materials can match aluminum. It can be reused an infinite number of times, and it‚Äôs often cheaper to recycle than to produce new aluminum because it requires so much less energy. Yet only about a third of the aluminum used in the U.S. gets recycled.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The problem lies in sorting mixed aluminum scrap ‚Äî a challenge that has long stumped the recycling industry.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Michael Siemer, CEO of Sortera, thinks his company has found the key, though. Sortera says it has developed a system that can separate aluminum grades with over 95% accuracy ‚Äî a breakthrough that could unlock a massive untapped resource in the recycling industry.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Here‚Äôs how it works: The company uses an AI model that identifies different grades of aluminum based on data from lasers, X-ray fluorescence, and high-speed cameras. The system has to classify each chip ‚Äî about the size of a large potato chip ‚Äî in a fraction of a second. ‚ÄúTen milliseconds is a long time,‚Äù Siemer says. Once the vision system identifies the grade, a series of nozzles blow precise puffs of air to flip the chip off the belt and into the correct bin.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That speed and accuracy matters because other recycling operations must melt the aluminum first before they can tell which type of alloy it is. And if alloys aren‚Äôt sorted properly, the mixed heap is worth far less because customers can‚Äôt be confident it will have the properties they need.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúPeople have been wanting to go after [this unsorted aluminum], and nobody‚Äôs been able to unlock it,‚Äù says Siemer.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sortera‚Äôs sorting accuracy has further helped the company unlock something else many startups seek: profitability. ‚ÄúThe margin is exponential above 90%, [while] 92% gets you a nice little margin, 95% gets you a big margin, [and] 98% is a really big margin.‚Äù&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;That‚Äôs helped the company become cash flow positive since August, he says, all based on the operation of a single plant in Indiana. To build a second plant in Tennessee, Sortera recently raised $20 million in equity and $25 million in debt in a round led by VXI Capital and accounts advised by T. Rowe Price, with participation from Overlay Capital and Yamaha Motor Ventures, the company exclusively told TechCrunch. Trinity Capital is providing additional equipment funding.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new plant, which is being built near Nashville, will come online in April or May. ‚ÄúIt‚Äôs a replica of our Indiana plant,‚Äù Siemer says. At the Indiana facility, he says, ‚Äúwe run full-tilt, 24-7, and we‚Äôre running millions of pounds a month.‚Äù&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;So where does all that aluminum come from? The scrap aluminum that Sortera receives tends to come from shredded automobiles. Each aluminum grade fractures differently when shredded, and those visual differences help the AI classify the metal. ‚ÄúThe chemical differences manifest themselves in the shredding,‚Äù Siemer says. Different alloys produce distinctive tears and folds that give the system clues. ‚ÄúYou gain these little insights so that in about a 10-millisecond time window, you go, ‚ÄòI‚Äôm pretty darn sure that‚Äôs 356 [grade aluminum],‚Äù Siemer says.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As Sortera expands, much of its aluminum will likely end up back on automotive assembly lines. Automotive manufacturers have been using increasing amounts of the metal to reduce vehicle weight and improve fuel efficiency. ‚ÄúEvery auto OEM on the planet has been to Indiana at least twice,‚Äù Siemer says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sortera is currently working on ways to process other metals like copper and titanium, but for the near future, the company remains focused on aluminum. ‚ÄúWe could instantly sort the 18 billion tons of aluminum made annually in the U.S. Every piece of that, every pound would be sold at a profit in the U.S.‚Äù&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/20/sortera-is-turning-americas-scrap-aluminum-problem-into-cash/</guid><pubDate>Thu, 20 Nov 2025 13:20:00 +0000</pubDate></item><item><title>[NEW] Tome's founders ditch viral presentation app with 20M users to build AI-native CRM Lightfield (AI | VentureBeat)</title><link>https://venturebeat.com/ai/tomes-founders-ditch-viral-presentation-app-with-20m-users-to-build-ai</link><description>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://lightfield.app/"&gt;&lt;u&gt;Lightfield&lt;/u&gt;&lt;/a&gt;, a customer relationship management platform built entirely around artificial intelligence, officially launched to the public this week after a year of quiet development ‚Äî a bold pivot by a startup that once had &lt;a href="https://www.forbes.com/sites/rashishrivastava/2024/04/23/the-prompt-the-latest-ai-startup-to-face-reality/"&gt;&lt;u&gt;20 million users&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.forbes.com/sites/alexkonrad/2023/02/22/storytelling-ai-startup-tome-raises-43-million/"&gt;&lt;u&gt;$43 million in the bank&lt;/u&gt;&lt;/a&gt; building something completely different.&lt;/p&gt;&lt;p&gt;The San Francisco-based company is positioning itself as a fundamental reimagining of how businesses track and manage customer relationships, abandoning the manual data entry that has defined CRMs for decades in favor of a system that automatically captures, organizes, and acts on customer interactions. With more than 100 early customers already using the platform daily ‚Äî over half spending more than an hour per day in the system ‚Äî &lt;a href="https://lightfield.app/"&gt;&lt;u&gt;Lightfield&lt;/u&gt;&lt;/a&gt; is a direct challenge to the legacy business models of &lt;a href="https://www.salesforce.com/"&gt;&lt;u&gt;Salesforce&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.hubspot.com/"&gt;&lt;u&gt;HubSpot&lt;/u&gt;&lt;/a&gt;, both of which generate billions in annual revenue.&lt;/p&gt;&lt;p&gt;&amp;quot;The CRM, categorically, is perhaps the most complex and lowest satisfaction piece of software on Earth,&amp;quot; said Keith Peiris, Lightfield&amp;#x27;s co-founder and CEO, in an exclusive interview with VentureBeat. &amp;quot;CRM companies have tens of millions of users, and you&amp;#x27;d be hard-pressed to find a single one who actually loves the product. That problem is our opportunity.&amp;quot;&lt;/p&gt;&lt;p&gt;The &lt;a href="https://lightfield.app/"&gt;&lt;u&gt;general availability&lt;/u&gt;&lt;/a&gt; announcement marks an unusual inflection point in enterprise software: a company betting that large language models have advanced enough to replace structured databases as the foundation of business-critical systems. It&amp;#x27;s a wager that has attracted backing from &lt;a href="https://www.coatue.com/"&gt;&lt;u&gt;Coatue Management&lt;/u&gt;&lt;/a&gt;, which led the company&amp;#x27;s Series A when it was still building presentation software under the name Tome.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How Tome&amp;#x27;s founders abandoned 20 million users to build a CRM from scratch&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The story behind Lightfield&amp;#x27;s creation reflects both conviction and pragmatism. &lt;a href="https://www.fastcompany.com/90827339/presentation-tool-tome-launches-ai-to-help-make-storytelling-simpler"&gt;&lt;u&gt;Tome&lt;/u&gt;&lt;/a&gt; had achieved significant viral success as an AI-powered presentation platform, gaining millions of users who appreciated its visual design and ease of use. But Peiris said the team concluded that building lasting differentiation in the general-purpose presentation market would prove difficult, even with a working product and real user traction.&lt;/p&gt;&lt;p&gt;&amp;quot;Tome went viral as an AI slides product, and it was visually delightful and easy to use‚Äîthe first real generative AI-based presentation platform,&amp;quot; Peiris explained. &amp;quot;But, the more people used it, the more I realized that to really help people communicate something‚Äîanything‚Äîwe needed more context.&amp;quot;&lt;/p&gt;&lt;p&gt;That realization led to a fundamental rethinking. The team observed that the most effective communication requires deep understanding of relationships, company dynamics, and ongoing conversations ‚Äî context that exists most richly in sales and customer-facing roles. Rather than building a horizontal tool for everyone, they decided to build vertically for go-to-market teams.&lt;/p&gt;&lt;p&gt;&amp;quot;We chose this lane, &amp;#x27;sales,&amp;#x27; because so many people in these roles used Tome, and it seemed like the most logical place to go vertical,&amp;quot; Peiris said. The team reduced headcount to a core group of engineers and spent a year building in stealth.&lt;/p&gt;&lt;p&gt;&lt;a href="https://signal.nfx.com/investors/dan-rose"&gt;&lt;u&gt;Dan Rose&lt;/u&gt;&lt;/a&gt;, a senior advisor at &lt;a href="https://www.coatue.com/"&gt;&lt;u&gt;Coatue&lt;/u&gt;&lt;/a&gt; who led the original investment in Tome, said the pivot validated his conviction in the founding team. &amp;quot;It takes real guts to pivot, and even more so when the original product is working,&amp;quot; Rose said. &amp;quot;They shrunk the team down to a core group of engineers and got to work building Lightfield. This was not an easy product to build, it is extremely complex under the hood.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why Lightfield stores complete conversations instead of forcing data into fields&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;What distinguishes &lt;a href="https://lightfield.app/"&gt;&lt;u&gt;Lightfield&lt;/u&gt;&lt;/a&gt; from traditional CRMs is architectural, not cosmetic. While &lt;a href="https://www.salesforce.com/"&gt;&lt;u&gt;Salesforce&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.hubspot.com/"&gt;&lt;u&gt;HubSpot&lt;/u&gt;&lt;/a&gt;, and their competitors require users to define rigid data schemas upfront ‚Äî dropdown menus, custom fields, checkbox categories ‚Äî and then manually populate those fields after every interaction, Lightfield stores the complete, unstructured record of what customers actually say and do.&lt;/p&gt;&lt;p&gt;&amp;quot;Traditional CRMs force every interaction through predefined fields ‚Äî they&amp;#x27;re compressing rich, nuanced customer conversations into structured database entries,&amp;quot; Peiris said. &amp;quot;We store customer data in its raw, lossless form. That means we&amp;#x27;re capturing significantly more detail and context than a traditional CRM ever could.&amp;quot;&lt;/p&gt;&lt;p&gt;In practice, this means the system automatically records and transcribes sales calls, ingests emails, monitors product usage, and maintains what the company calls a &amp;quot;relationship timeline&amp;quot; ‚Äî a complete chronological record of every touchpoint between a company and its customers. AI models then extract structured information from this raw data on demand, allowing companies to reorganize their data model without manual rework.&lt;/p&gt;&lt;p&gt;&amp;quot;If you realize you need different fields or want to reorganize your schema entirely, the system can remap and refill itself automatically,&amp;quot; Peiris explained. &amp;quot;You&amp;#x27;re not locked into decisions you made on day one when you barely understood your sales process.&amp;quot;&lt;/p&gt;&lt;p&gt;The system also generates meeting preparation briefs, drafts follow-up emails based on conversation context, and can be queried in natural language ‚Äî capabilities that represent a departure from the passive database model that has defined CRMs since the category&amp;#x27;s inception in the 1980s.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Sales teams report reviving dead deals and cutting response times from months to days&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Customer testimonials suggest the automation delivers measurable impact, particularly for small teams without dedicated sales operations staff. Tyler Postle, co-founder of &lt;a href="http://voker.ai"&gt;&lt;u&gt;Voker.ai&lt;/u&gt;&lt;/a&gt;, said Lightfield&amp;#x27;s AI agent helped him revive more than 40 stalled opportunities in a single two-hour session ‚Äî leads he had neglected for six months while using HubSpot.&lt;/p&gt;&lt;p&gt;&amp;quot;Within 2 days, 10 of those were revived and became active opps that moved to poc,&amp;quot; Postle said. &amp;quot;The problem was, instead of being a tool of action and autotracking‚ÄîHubSpot was a tool where I had to do the work to record customer convos. Using HubSpot I was a data hygienist. Using Lighfield, I‚Äôm a closer.&amp;quot;&lt;/p&gt;&lt;p&gt;Postle reported that his response times to prospects improved from weeks or months to one or two days, a change noticeable enough that customers commented on it. &amp;quot;Our prospects and customers have even noticed it,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;Radu Spineanu, co-founder of &lt;a href="https://humbleops.ai/"&gt;&lt;u&gt;Humble Ops&lt;/u&gt;&lt;/a&gt;, highlighted a specific feature that addresses what he views as the primary cause of lost deals: simple neglect. &amp;quot;The killer feature is asking &amp;#x27;who haven&amp;#x27;t I followed up with?&amp;#x27;&amp;quot; Spineanu said. &amp;quot;Most deals die from neglect, not rejection. Lightfield catches these dropped threads and can draft and send the follow-up immediately. That&amp;#x27;s prevented at least three deals from going cold this quarter.&amp;quot;&lt;/p&gt;&lt;p&gt;Spineanu had evaluated competing modern CRMs including &lt;a href="https://attio.com/"&gt;&lt;u&gt;Attio&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.clay.com/"&gt;&lt;u&gt;Clay&lt;/u&gt;&lt;/a&gt; before selecting &lt;a href="https://lightfield.app/"&gt;&lt;u&gt;Lightfield&lt;/u&gt;&lt;/a&gt;, dismissing &lt;a href="https://www.salesforce.com/"&gt;&lt;u&gt;Salesforce&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.hubspot.com/"&gt;&lt;u&gt;HubSpot&lt;/u&gt;&lt;/a&gt; as &amp;quot;built for a different era.&amp;quot; He said those platforms assume companies have dedicated operations teams to configure workflows and maintain data quality ‚Äî resources most early-stage companies lack.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why Y Combinator startups are rejecting Salesforce and starting with AI-native tools&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Peiris claims that the current batch of &lt;a href="https://www.ycombinator.com/"&gt;&lt;u&gt;Y Combinator&lt;/u&gt;&lt;/a&gt; startups ‚Äî widely viewed as a bellwether for early-stage company behavior ‚Äî have largely rejected both &lt;a href="https://www.salesforce.com/"&gt;&lt;u&gt;Salesforce&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.hubspot.com/"&gt;&lt;u&gt;HubSpot&lt;/u&gt;&lt;/a&gt;. &amp;quot;If you were to poll a random sampling of current YC startups and ask whether they&amp;#x27;re using Salesforce or HubSpot, the overwhelming answer would be &amp;#x27;no,&amp;#x27;&amp;quot; he said. &amp;quot;Salesforce is too expensive, too complex to set up, and frankly doesn&amp;#x27;t do enough to justify the investment for an early-stage company.&amp;quot;&lt;/p&gt;&lt;p&gt;According to Peiris, most startups begin with spreadsheets and eventually graduate to a first CRM ‚Äî a transition point where Lightfield aims to intercede. &amp;quot;Increasingly, they&amp;#x27;re choosing Lightfield instead and skipping that intermediate step entirely,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;This represents a familiar pattern in enterprise software disruption: a new generation of companies forming habits around different tools, creating an opening for challengers to establish themselves before businesses grow large enough to face pressure toward industry-standard platforms. The company&amp;#x27;s strategy appears to deliberately target this window, aiming to grow alongside early customers and become embedded in their processes as they scale.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Can Salesforce and HubSpot retrofit their legacy systems for AI, or is the architecture too old?&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Both &lt;a href="https://www.salesforce.com/"&gt;&lt;u&gt;Salesforce&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.hubspot.com/"&gt;&lt;u&gt;HubSpot&lt;/u&gt;&lt;/a&gt; have announced AI features in recent quarters, adding capabilities like conversation intelligence and automated data entry to their existing platforms. The question facing Lightfield is whether established vendors can incorporate similar capabilities‚Äîleveraging their existing customer bases and integrations ‚Äî or whether fundamental architectural differences create a genuine moat.&lt;/p&gt;&lt;p&gt;Peiris argues the latter. &amp;quot;The fundamental difference is in how we store data,&amp;quot; he said. &amp;quot;Because we have access to that complete context, the analysis we provide and the work we generate tends to be substantially higher quality than tools built on top of traditional database structures.&amp;quot;&lt;/p&gt;&lt;p&gt;Existing conversation intelligence tools like &lt;a href="https://www.gong.io/"&gt;&lt;u&gt;Gong&lt;/u&gt;&lt;/a&gt; and &lt;a href="http://revenue.io"&gt;&lt;u&gt;Revenue.io&lt;/u&gt;&lt;/a&gt;, which analyze sales calls and provide coaching insights, already serve similar functions but require Salesforce instances to operate. Peiris said Lightfield&amp;#x27;s advantage comes from unifying the entire data model rather than layering analysis on top of fragmented systems.&lt;/p&gt;&lt;p&gt;&amp;quot;We have a more complete picture of each customer because we integrate company knowledge, communication sync, product analytics, and full CRM detail all in one place,&amp;quot; he said. &amp;quot;That unified context means the work being generated in Lightfield‚Äîwhether it&amp;#x27;s analysis, follow-ups, or insights‚Äîtends to be significantly higher quality.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The privacy and accuracy concerns that come with AI-automated customer interactions&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The architecture creates obvious risks. Storing complete conversation histories raises privacy concerns, and relying on large language models to extract and interpret information introduces the possibility of errors‚Äîwhat AI researchers call hallucinations.&lt;/p&gt;&lt;p&gt;Peiris acknowledged both issues directly. On privacy, the company maintains that call recording follows standard practices, with visible notifications that recording is in progress, and that storing sales correspondence mirrors what CRM vendors have done for decades. The company has achieved SOC 2 Type I certification and is pursuing both SOC 2 Type II and HIPAA compliance. &amp;quot;We don&amp;#x27;t train models on customer data, period,&amp;quot; Peiris said.&lt;/p&gt;&lt;p&gt;On accuracy, he was similarly forthright. &amp;quot;Of course it happens,&amp;quot; Peiris said when asked about misinterpretations. &amp;quot;It&amp;#x27;s impossible to completely eliminate hallucinations when working with large language models.&amp;quot;&lt;/p&gt;&lt;p&gt;The company&amp;#x27;s approach is to require human approval before sending customer communications or updating critical fields ‚Äî positioning the system as augmentation rather than full automation. &amp;quot;We&amp;#x27;re building a tool that amplifies human judgment, not one that pretends to replace it entirely,&amp;quot; Peiris said.&lt;/p&gt;&lt;p&gt;This is a more cautious stance than some AI-native software companies have taken, reflecting both technical realism about current model capabilities and potential liability concerns around customer-facing mistakes.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How Lightfield plans to consolidate ten different sales tools into one platform&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Lightfield&amp;#x27;s pricing strategy reflects a broader thesis about enterprise software economics. Rather than charging per-seat fees for a point solution, the company is positioning itself as a consolidated platform that can replace multiple specialized tools ‚Äî sales engagement platforms, conversation intelligence systems, meeting assistants, and the CRM itself.&lt;/p&gt;&lt;p&gt;&amp;quot;The real problem is that running a modern go-to-market function requires cobbling together 10 different independent point solutions,&amp;quot; Peiris said. &amp;quot;When you pay for 10 separate seat licenses, you&amp;#x27;re essentially paying 10 different companies to solve the same foundational problems over and over again.&amp;quot;&lt;/p&gt;&lt;p&gt;The company operates primarily through self-service signup rather than enterprise sales teams, which Peiris argues allows for lower pricing while maintaining margins. This is a common playbook among modern SaaS companies but represents a fundamental difference from Salesforce&amp;#x27;s model, which relies heavily on direct sales and customer success teams.&lt;/p&gt;&lt;p&gt;Whether this approach can support a sustainable business at scale remains unproven. The company&amp;#x27;s current customer base skews heavily toward early-stage startups‚Äîmore than 100 &lt;a href="https://www.ycombinator.com/"&gt;&lt;u&gt;Y Combinator&lt;/u&gt;&lt;/a&gt; companies, according to the company ‚Äî a segment with limited budgets and high failure rates.&lt;/p&gt;&lt;p&gt;But Lightfield is betting it can become the system of record for a cohort of fast-growing companies, eventually creating an installed base comparable to how Salesforce established itself decades ago. The company&amp;#x27;s trajectory will likely depend on whether AI capabilities alone provide sufficient differentiation‚Äîor whether incumbents can adapt quickly enough to defend their positions.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The real test: whether sales teams will trust AI enough to let it run their business&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The company has outlined several areas for expansion, including an open platform for workflows and webhooks that would allow third-party integrations. Early customers have specifically requested connections with tools like &lt;a href="https://www.apollo.io/"&gt;&lt;u&gt;Apollo&lt;/u&gt;&lt;/a&gt; for prospecting and &lt;a href="https://slack.com/"&gt;&lt;u&gt;Slack&lt;/u&gt;&lt;/a&gt; for team communication ‚Äî gaps that Postle, the &lt;a href="http://voker.ai"&gt;&lt;u&gt;Voker.ai&lt;/u&gt;&lt;/a&gt; founder, acknowledged but dismissed as temporary.&lt;/p&gt;&lt;p&gt;&amp;quot;The fact that HS and Salesforce have these integrations already isn&amp;#x27;t a moat,&amp;quot; Postle said. &amp;quot;HS and Salesforce are going to lose to lightfield because they aren&amp;#x27;t AI native, no matter how much they try to pretend to be.&amp;quot;&lt;/p&gt;&lt;p&gt;Rose highlighted an unusual use case that emerged during Lightfield&amp;#x27;s own development: the company&amp;#x27;s product team used the CRM itself to analyze customer conversations and identify feature requests. &amp;quot;In this sense, Lightfield more than just a sales database, it&amp;#x27;s a customer intelligence layer,&amp;quot; Rose said.&lt;/p&gt;&lt;p&gt;This suggests potential applications beyond traditional sales workflows, positioning the system as infrastructure for any function that requires understanding customer needs‚Äîproduct development, customer success, even marketing strategy.&lt;/p&gt;&lt;p&gt;For now, the company is focused on proving the core value proposition with early-stage companies. But the broader question Lightfield raises extends beyond CRM software specifically: whether AI capabilities have advanced sufficiently to replace structured databases as the foundation of enterprise systems, or whether the current generation of large language models remains too unreliable for business-critical functions.&lt;/p&gt;&lt;p&gt;The answer will likely emerge not from technical benchmarks but from customer behavior‚Äîwhether sales teams actually trust AI-generated insights enough to base decisions on them, and whether the efficiency gains justify the inherent unpredictability of working with systems that approximate rather than calculate.&lt;/p&gt;&lt;p&gt;&lt;a href="https://lightfield.app/"&gt;&lt;u&gt;Lightfield&lt;/u&gt;&lt;/a&gt; is betting that the trade-off has already shifted in favor of approximation, at least for the millions of salespeople who currently view their CRM as an obstacle rather than an asset. Whether that bet proves correct will help define the next generation of enterprise software.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://lightfield.app/"&gt;&lt;u&gt;Lightfield&lt;/u&gt;&lt;/a&gt;, a customer relationship management platform built entirely around artificial intelligence, officially launched to the public this week after a year of quiet development ‚Äî a bold pivot by a startup that once had &lt;a href="https://www.forbes.com/sites/rashishrivastava/2024/04/23/the-prompt-the-latest-ai-startup-to-face-reality/"&gt;&lt;u&gt;20 million users&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.forbes.com/sites/alexkonrad/2023/02/22/storytelling-ai-startup-tome-raises-43-million/"&gt;&lt;u&gt;$43 million in the bank&lt;/u&gt;&lt;/a&gt; building something completely different.&lt;/p&gt;&lt;p&gt;The San Francisco-based company is positioning itself as a fundamental reimagining of how businesses track and manage customer relationships, abandoning the manual data entry that has defined CRMs for decades in favor of a system that automatically captures, organizes, and acts on customer interactions. With more than 100 early customers already using the platform daily ‚Äî over half spending more than an hour per day in the system ‚Äî &lt;a href="https://lightfield.app/"&gt;&lt;u&gt;Lightfield&lt;/u&gt;&lt;/a&gt; is a direct challenge to the legacy business models of &lt;a href="https://www.salesforce.com/"&gt;&lt;u&gt;Salesforce&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.hubspot.com/"&gt;&lt;u&gt;HubSpot&lt;/u&gt;&lt;/a&gt;, both of which generate billions in annual revenue.&lt;/p&gt;&lt;p&gt;&amp;quot;The CRM, categorically, is perhaps the most complex and lowest satisfaction piece of software on Earth,&amp;quot; said Keith Peiris, Lightfield&amp;#x27;s co-founder and CEO, in an exclusive interview with VentureBeat. &amp;quot;CRM companies have tens of millions of users, and you&amp;#x27;d be hard-pressed to find a single one who actually loves the product. That problem is our opportunity.&amp;quot;&lt;/p&gt;&lt;p&gt;The &lt;a href="https://lightfield.app/"&gt;&lt;u&gt;general availability&lt;/u&gt;&lt;/a&gt; announcement marks an unusual inflection point in enterprise software: a company betting that large language models have advanced enough to replace structured databases as the foundation of business-critical systems. It&amp;#x27;s a wager that has attracted backing from &lt;a href="https://www.coatue.com/"&gt;&lt;u&gt;Coatue Management&lt;/u&gt;&lt;/a&gt;, which led the company&amp;#x27;s Series A when it was still building presentation software under the name Tome.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How Tome&amp;#x27;s founders abandoned 20 million users to build a CRM from scratch&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The story behind Lightfield&amp;#x27;s creation reflects both conviction and pragmatism. &lt;a href="https://www.fastcompany.com/90827339/presentation-tool-tome-launches-ai-to-help-make-storytelling-simpler"&gt;&lt;u&gt;Tome&lt;/u&gt;&lt;/a&gt; had achieved significant viral success as an AI-powered presentation platform, gaining millions of users who appreciated its visual design and ease of use. But Peiris said the team concluded that building lasting differentiation in the general-purpose presentation market would prove difficult, even with a working product and real user traction.&lt;/p&gt;&lt;p&gt;&amp;quot;Tome went viral as an AI slides product, and it was visually delightful and easy to use‚Äîthe first real generative AI-based presentation platform,&amp;quot; Peiris explained. &amp;quot;But, the more people used it, the more I realized that to really help people communicate something‚Äîanything‚Äîwe needed more context.&amp;quot;&lt;/p&gt;&lt;p&gt;That realization led to a fundamental rethinking. The team observed that the most effective communication requires deep understanding of relationships, company dynamics, and ongoing conversations ‚Äî context that exists most richly in sales and customer-facing roles. Rather than building a horizontal tool for everyone, they decided to build vertically for go-to-market teams.&lt;/p&gt;&lt;p&gt;&amp;quot;We chose this lane, &amp;#x27;sales,&amp;#x27; because so many people in these roles used Tome, and it seemed like the most logical place to go vertical,&amp;quot; Peiris said. The team reduced headcount to a core group of engineers and spent a year building in stealth.&lt;/p&gt;&lt;p&gt;&lt;a href="https://signal.nfx.com/investors/dan-rose"&gt;&lt;u&gt;Dan Rose&lt;/u&gt;&lt;/a&gt;, a senior advisor at &lt;a href="https://www.coatue.com/"&gt;&lt;u&gt;Coatue&lt;/u&gt;&lt;/a&gt; who led the original investment in Tome, said the pivot validated his conviction in the founding team. &amp;quot;It takes real guts to pivot, and even more so when the original product is working,&amp;quot; Rose said. &amp;quot;They shrunk the team down to a core group of engineers and got to work building Lightfield. This was not an easy product to build, it is extremely complex under the hood.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why Lightfield stores complete conversations instead of forcing data into fields&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;What distinguishes &lt;a href="https://lightfield.app/"&gt;&lt;u&gt;Lightfield&lt;/u&gt;&lt;/a&gt; from traditional CRMs is architectural, not cosmetic. While &lt;a href="https://www.salesforce.com/"&gt;&lt;u&gt;Salesforce&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.hubspot.com/"&gt;&lt;u&gt;HubSpot&lt;/u&gt;&lt;/a&gt;, and their competitors require users to define rigid data schemas upfront ‚Äî dropdown menus, custom fields, checkbox categories ‚Äî and then manually populate those fields after every interaction, Lightfield stores the complete, unstructured record of what customers actually say and do.&lt;/p&gt;&lt;p&gt;&amp;quot;Traditional CRMs force every interaction through predefined fields ‚Äî they&amp;#x27;re compressing rich, nuanced customer conversations into structured database entries,&amp;quot; Peiris said. &amp;quot;We store customer data in its raw, lossless form. That means we&amp;#x27;re capturing significantly more detail and context than a traditional CRM ever could.&amp;quot;&lt;/p&gt;&lt;p&gt;In practice, this means the system automatically records and transcribes sales calls, ingests emails, monitors product usage, and maintains what the company calls a &amp;quot;relationship timeline&amp;quot; ‚Äî a complete chronological record of every touchpoint between a company and its customers. AI models then extract structured information from this raw data on demand, allowing companies to reorganize their data model without manual rework.&lt;/p&gt;&lt;p&gt;&amp;quot;If you realize you need different fields or want to reorganize your schema entirely, the system can remap and refill itself automatically,&amp;quot; Peiris explained. &amp;quot;You&amp;#x27;re not locked into decisions you made on day one when you barely understood your sales process.&amp;quot;&lt;/p&gt;&lt;p&gt;The system also generates meeting preparation briefs, drafts follow-up emails based on conversation context, and can be queried in natural language ‚Äî capabilities that represent a departure from the passive database model that has defined CRMs since the category&amp;#x27;s inception in the 1980s.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Sales teams report reviving dead deals and cutting response times from months to days&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Customer testimonials suggest the automation delivers measurable impact, particularly for small teams without dedicated sales operations staff. Tyler Postle, co-founder of &lt;a href="http://voker.ai"&gt;&lt;u&gt;Voker.ai&lt;/u&gt;&lt;/a&gt;, said Lightfield&amp;#x27;s AI agent helped him revive more than 40 stalled opportunities in a single two-hour session ‚Äî leads he had neglected for six months while using HubSpot.&lt;/p&gt;&lt;p&gt;&amp;quot;Within 2 days, 10 of those were revived and became active opps that moved to poc,&amp;quot; Postle said. &amp;quot;The problem was, instead of being a tool of action and autotracking‚ÄîHubSpot was a tool where I had to do the work to record customer convos. Using HubSpot I was a data hygienist. Using Lighfield, I‚Äôm a closer.&amp;quot;&lt;/p&gt;&lt;p&gt;Postle reported that his response times to prospects improved from weeks or months to one or two days, a change noticeable enough that customers commented on it. &amp;quot;Our prospects and customers have even noticed it,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;Radu Spineanu, co-founder of &lt;a href="https://humbleops.ai/"&gt;&lt;u&gt;Humble Ops&lt;/u&gt;&lt;/a&gt;, highlighted a specific feature that addresses what he views as the primary cause of lost deals: simple neglect. &amp;quot;The killer feature is asking &amp;#x27;who haven&amp;#x27;t I followed up with?&amp;#x27;&amp;quot; Spineanu said. &amp;quot;Most deals die from neglect, not rejection. Lightfield catches these dropped threads and can draft and send the follow-up immediately. That&amp;#x27;s prevented at least three deals from going cold this quarter.&amp;quot;&lt;/p&gt;&lt;p&gt;Spineanu had evaluated competing modern CRMs including &lt;a href="https://attio.com/"&gt;&lt;u&gt;Attio&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.clay.com/"&gt;&lt;u&gt;Clay&lt;/u&gt;&lt;/a&gt; before selecting &lt;a href="https://lightfield.app/"&gt;&lt;u&gt;Lightfield&lt;/u&gt;&lt;/a&gt;, dismissing &lt;a href="https://www.salesforce.com/"&gt;&lt;u&gt;Salesforce&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.hubspot.com/"&gt;&lt;u&gt;HubSpot&lt;/u&gt;&lt;/a&gt; as &amp;quot;built for a different era.&amp;quot; He said those platforms assume companies have dedicated operations teams to configure workflows and maintain data quality ‚Äî resources most early-stage companies lack.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why Y Combinator startups are rejecting Salesforce and starting with AI-native tools&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Peiris claims that the current batch of &lt;a href="https://www.ycombinator.com/"&gt;&lt;u&gt;Y Combinator&lt;/u&gt;&lt;/a&gt; startups ‚Äî widely viewed as a bellwether for early-stage company behavior ‚Äî have largely rejected both &lt;a href="https://www.salesforce.com/"&gt;&lt;u&gt;Salesforce&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.hubspot.com/"&gt;&lt;u&gt;HubSpot&lt;/u&gt;&lt;/a&gt;. &amp;quot;If you were to poll a random sampling of current YC startups and ask whether they&amp;#x27;re using Salesforce or HubSpot, the overwhelming answer would be &amp;#x27;no,&amp;#x27;&amp;quot; he said. &amp;quot;Salesforce is too expensive, too complex to set up, and frankly doesn&amp;#x27;t do enough to justify the investment for an early-stage company.&amp;quot;&lt;/p&gt;&lt;p&gt;According to Peiris, most startups begin with spreadsheets and eventually graduate to a first CRM ‚Äî a transition point where Lightfield aims to intercede. &amp;quot;Increasingly, they&amp;#x27;re choosing Lightfield instead and skipping that intermediate step entirely,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;This represents a familiar pattern in enterprise software disruption: a new generation of companies forming habits around different tools, creating an opening for challengers to establish themselves before businesses grow large enough to face pressure toward industry-standard platforms. The company&amp;#x27;s strategy appears to deliberately target this window, aiming to grow alongside early customers and become embedded in their processes as they scale.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Can Salesforce and HubSpot retrofit their legacy systems for AI, or is the architecture too old?&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Both &lt;a href="https://www.salesforce.com/"&gt;&lt;u&gt;Salesforce&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.hubspot.com/"&gt;&lt;u&gt;HubSpot&lt;/u&gt;&lt;/a&gt; have announced AI features in recent quarters, adding capabilities like conversation intelligence and automated data entry to their existing platforms. The question facing Lightfield is whether established vendors can incorporate similar capabilities‚Äîleveraging their existing customer bases and integrations ‚Äî or whether fundamental architectural differences create a genuine moat.&lt;/p&gt;&lt;p&gt;Peiris argues the latter. &amp;quot;The fundamental difference is in how we store data,&amp;quot; he said. &amp;quot;Because we have access to that complete context, the analysis we provide and the work we generate tends to be substantially higher quality than tools built on top of traditional database structures.&amp;quot;&lt;/p&gt;&lt;p&gt;Existing conversation intelligence tools like &lt;a href="https://www.gong.io/"&gt;&lt;u&gt;Gong&lt;/u&gt;&lt;/a&gt; and &lt;a href="http://revenue.io"&gt;&lt;u&gt;Revenue.io&lt;/u&gt;&lt;/a&gt;, which analyze sales calls and provide coaching insights, already serve similar functions but require Salesforce instances to operate. Peiris said Lightfield&amp;#x27;s advantage comes from unifying the entire data model rather than layering analysis on top of fragmented systems.&lt;/p&gt;&lt;p&gt;&amp;quot;We have a more complete picture of each customer because we integrate company knowledge, communication sync, product analytics, and full CRM detail all in one place,&amp;quot; he said. &amp;quot;That unified context means the work being generated in Lightfield‚Äîwhether it&amp;#x27;s analysis, follow-ups, or insights‚Äîtends to be significantly higher quality.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The privacy and accuracy concerns that come with AI-automated customer interactions&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The architecture creates obvious risks. Storing complete conversation histories raises privacy concerns, and relying on large language models to extract and interpret information introduces the possibility of errors‚Äîwhat AI researchers call hallucinations.&lt;/p&gt;&lt;p&gt;Peiris acknowledged both issues directly. On privacy, the company maintains that call recording follows standard practices, with visible notifications that recording is in progress, and that storing sales correspondence mirrors what CRM vendors have done for decades. The company has achieved SOC 2 Type I certification and is pursuing both SOC 2 Type II and HIPAA compliance. &amp;quot;We don&amp;#x27;t train models on customer data, period,&amp;quot; Peiris said.&lt;/p&gt;&lt;p&gt;On accuracy, he was similarly forthright. &amp;quot;Of course it happens,&amp;quot; Peiris said when asked about misinterpretations. &amp;quot;It&amp;#x27;s impossible to completely eliminate hallucinations when working with large language models.&amp;quot;&lt;/p&gt;&lt;p&gt;The company&amp;#x27;s approach is to require human approval before sending customer communications or updating critical fields ‚Äî positioning the system as augmentation rather than full automation. &amp;quot;We&amp;#x27;re building a tool that amplifies human judgment, not one that pretends to replace it entirely,&amp;quot; Peiris said.&lt;/p&gt;&lt;p&gt;This is a more cautious stance than some AI-native software companies have taken, reflecting both technical realism about current model capabilities and potential liability concerns around customer-facing mistakes.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How Lightfield plans to consolidate ten different sales tools into one platform&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Lightfield&amp;#x27;s pricing strategy reflects a broader thesis about enterprise software economics. Rather than charging per-seat fees for a point solution, the company is positioning itself as a consolidated platform that can replace multiple specialized tools ‚Äî sales engagement platforms, conversation intelligence systems, meeting assistants, and the CRM itself.&lt;/p&gt;&lt;p&gt;&amp;quot;The real problem is that running a modern go-to-market function requires cobbling together 10 different independent point solutions,&amp;quot; Peiris said. &amp;quot;When you pay for 10 separate seat licenses, you&amp;#x27;re essentially paying 10 different companies to solve the same foundational problems over and over again.&amp;quot;&lt;/p&gt;&lt;p&gt;The company operates primarily through self-service signup rather than enterprise sales teams, which Peiris argues allows for lower pricing while maintaining margins. This is a common playbook among modern SaaS companies but represents a fundamental difference from Salesforce&amp;#x27;s model, which relies heavily on direct sales and customer success teams.&lt;/p&gt;&lt;p&gt;Whether this approach can support a sustainable business at scale remains unproven. The company&amp;#x27;s current customer base skews heavily toward early-stage startups‚Äîmore than 100 &lt;a href="https://www.ycombinator.com/"&gt;&lt;u&gt;Y Combinator&lt;/u&gt;&lt;/a&gt; companies, according to the company ‚Äî a segment with limited budgets and high failure rates.&lt;/p&gt;&lt;p&gt;But Lightfield is betting it can become the system of record for a cohort of fast-growing companies, eventually creating an installed base comparable to how Salesforce established itself decades ago. The company&amp;#x27;s trajectory will likely depend on whether AI capabilities alone provide sufficient differentiation‚Äîor whether incumbents can adapt quickly enough to defend their positions.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The real test: whether sales teams will trust AI enough to let it run their business&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The company has outlined several areas for expansion, including an open platform for workflows and webhooks that would allow third-party integrations. Early customers have specifically requested connections with tools like &lt;a href="https://www.apollo.io/"&gt;&lt;u&gt;Apollo&lt;/u&gt;&lt;/a&gt; for prospecting and &lt;a href="https://slack.com/"&gt;&lt;u&gt;Slack&lt;/u&gt;&lt;/a&gt; for team communication ‚Äî gaps that Postle, the &lt;a href="http://voker.ai"&gt;&lt;u&gt;Voker.ai&lt;/u&gt;&lt;/a&gt; founder, acknowledged but dismissed as temporary.&lt;/p&gt;&lt;p&gt;&amp;quot;The fact that HS and Salesforce have these integrations already isn&amp;#x27;t a moat,&amp;quot; Postle said. &amp;quot;HS and Salesforce are going to lose to lightfield because they aren&amp;#x27;t AI native, no matter how much they try to pretend to be.&amp;quot;&lt;/p&gt;&lt;p&gt;Rose highlighted an unusual use case that emerged during Lightfield&amp;#x27;s own development: the company&amp;#x27;s product team used the CRM itself to analyze customer conversations and identify feature requests. &amp;quot;In this sense, Lightfield more than just a sales database, it&amp;#x27;s a customer intelligence layer,&amp;quot; Rose said.&lt;/p&gt;&lt;p&gt;This suggests potential applications beyond traditional sales workflows, positioning the system as infrastructure for any function that requires understanding customer needs‚Äîproduct development, customer success, even marketing strategy.&lt;/p&gt;&lt;p&gt;For now, the company is focused on proving the core value proposition with early-stage companies. But the broader question Lightfield raises extends beyond CRM software specifically: whether AI capabilities have advanced sufficiently to replace structured databases as the foundation of enterprise systems, or whether the current generation of large language models remains too unreliable for business-critical functions.&lt;/p&gt;&lt;p&gt;The answer will likely emerge not from technical benchmarks but from customer behavior‚Äîwhether sales teams actually trust AI-generated insights enough to base decisions on them, and whether the efficiency gains justify the inherent unpredictability of working with systems that approximate rather than calculate.&lt;/p&gt;&lt;p&gt;&lt;a href="https://lightfield.app/"&gt;&lt;u&gt;Lightfield&lt;/u&gt;&lt;/a&gt; is betting that the trade-off has already shifted in favor of approximation, at least for the millions of salespeople who currently view their CRM as an obstacle rather than an asset. Whether that bet proves correct will help define the next generation of enterprise software.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/tomes-founders-ditch-viral-presentation-app-with-20m-users-to-build-ai</guid><pubDate>Thu, 20 Nov 2025 14:00:00 +0000</pubDate></item><item><title>[NEW] Ultimate Cloud Gaming Is Everywhere With GeForce NOW (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/geforce-now-thursday-ultimate-is-everywhere/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;The NVIDIA Blackwell RTX upgrade is nearing the finish line, letting GeForce NOW Ultimate members across the globe experience true next-generation cloud gaming from anywhere.&lt;/p&gt;
&lt;p&gt;Everyone‚Äôs talking about Ultimate memberships ‚Äî including GeForce NOW partner 2K.&lt;/p&gt;
&lt;p&gt;‚ÄúWith GeForce NOW Ultimate, top-tier streaming truly goes everywhere,‚Äù said Sean Haran, head of partnerships and licensing at 2K. ‚ÄúAnyone can experience the glory of &lt;i&gt;Borderlands 4&lt;/i&gt;, with breathtaking graphics and flawless gameplay powered by GeForce RTX 5080 servers, even without the latest devices. Jump into the cloud and play at high settings, whether you‚Äôre at home or on the move.‚Äù&lt;/p&gt;
&lt;p&gt;The community has plenty to say about Ultimate, too. The GeForce NOW Community Video Contest invites gamers to share how GeForce NOW has changed the way they play. Participants can earn two Ultimate day passes ‚Äî one to keep and one to share with a gaming buddy ‚Äî and a chance to win a one-year Ultimate membership, just for submitting a clip.&lt;/p&gt;
&lt;p&gt;Plus, the celebration continues with free in-game skins for both &lt;i&gt;Guild Wars II &lt;/i&gt;and &lt;i&gt;Borderlands 4&lt;/i&gt;.&lt;/p&gt;
&lt;p&gt;And Capcom‚Äôs &lt;i&gt;Ace Attorney&lt;/i&gt; headlines the lineup of nine new titles joining the cloud this week, alongside even more ways to jump in with the new Chromebook Fast Pass.&lt;/p&gt;
&lt;p&gt;Stockholm will soon be the final region to get Blackwell RTX power, completing the rollout of GeForce RTX 5080-class performance worldwide. Ultrasmooth streaming, cutting-edge visuals and lightning-fast responsiveness are unlocking new levels of performance for Ultimate members.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;The Ultimate Leap&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87694"&gt;&lt;img alt="alt" class="wp-image-87694 size-large" height="945" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/GFN_Thursday-Server_Rollout_Map-1680x945.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87694"&gt;&lt;em&gt;Ultimate is everywhere, with Stockholm to be the final region to upgrade.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;GeForce RTX 5080-class performance is lighting up regions around the globe, powered by the Blackwell RTX upgrade.&lt;/p&gt;
&lt;p&gt;Ultimate now streams at up to 5K at 120 frames per second or up to 360 fps at 1080p for sharp, competitive play. Expect cinematic-quality visuals, advanced ray tracing and AI-powered performance that makes every frame shine on nearly any device. From the neon buzz of &lt;i&gt;Cyberpunk 2077&lt;/i&gt; to the over-the-top chaos of &lt;i&gt;Borderlands 4&lt;/i&gt;, gaming has never looked ‚Äî or felt ‚Äî this good.&lt;/p&gt;
&lt;p&gt;With high-dynamic-range visuals, support for racing wheels, ultrawide displays, gaming handhelds running up to 90 fps and an expanded library of over 4,000 games thanks to the Install-to-Play feature ‚Äî GeForce NOW enables every gamer to play bigger, go longer and jump right into blockbuster adventures without worrying about hardware.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;The Ultimate Contest&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;Members can join in celebrating GeForce RTX 5080-class power streaming all over the world by sharing gameplay videos of why the Ultimate experience stands out. Submit entries on the Blackwell upgrade page.&lt;/p&gt;
&lt;p&gt;Participants will earn two Ultimate day passes ‚Äî either for keeping or sharing with a friend. Top 10 entries will win a one-year Ultimate membership to keep the gaming going.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Calling All Heroes&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The celebrations don‚Äôt stop there. GeForce NOW members are in for a treat: fantastic rewards are up for grabs in &lt;i&gt;Borderlands 4&lt;/i&gt; and &lt;i&gt;Guild Wars 2&lt;/i&gt;.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87697"&gt;&lt;img alt="BL4 reward on GeForce NOW" class="size-large wp-image-87697" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/GFN_Thursday-Borderlands_4_Echo_4_Drone_Skin_Reward-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87697"&gt;&lt;em&gt;Stand out in the mayhem.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;GeForce NOW Ultimate members can claim the bold ECHO-4 drone skin in &lt;i&gt;Borderlands 4&lt;/i&gt; to show off their style while experiencing the game with cinematic-quality streaming and up to 2.8x higher frame rates, powered by NVIDIA Blackwell RTX servers.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87700"&gt;&lt;img alt="GW2 reward on GeForce NOW" class="size-large wp-image-87700" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/GFN_Thursday-Guild_Wars_2_Visions_of_Eternity_Reward-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87700"&gt;&lt;em&gt;Rule the realm in style.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;And in &lt;i&gt;Guild Wars 2&lt;/i&gt;, Ultimate members can unlock the regal and ruthless Bloody Prince Outfit, perfect for making a memorable entrance in the new ‚ÄúVisions of Eternity‚Äù expansion. Jump into epic quests across Castora to carve legends, harness ancient magic and stand out among heroes.&lt;/p&gt;
&lt;p&gt;It‚Äôs all about perks, effortless streaming and instant access ‚Äî no downloads required. With a GeForce NOW membership, play with style, power and rewards that let members shine in the worlds they explore.&lt;/p&gt;
&lt;p&gt;Claim member rewards in the GeForce NOW account portal, then follow the instructions to collect the in-game reward. For &lt;i&gt;Borderlands 4&lt;/i&gt;, enter the provided SHiFT code in the in-game menu. For &lt;i&gt;Guild Wars 2, &lt;/i&gt;log in to the GeForce NOW account to redeem.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Ready to Battle&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87703"&gt;&lt;img alt="Apollo Justice Ace Attorney Trilogy on GeForce NOW" class="size-large wp-image-87703" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/GFN_Thursday-Apollo_Justice_Ace_Attorney_Trilogy-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87703"&gt;&lt;em&gt;It‚Äôs justice time.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Apollo Justice‚Äôs legal journey begins anew.&lt;/p&gt;
&lt;p&gt;In &lt;i&gt;Apollo Justice: Ace Attorney Trilogy, &lt;/i&gt;join rookie attorney Apollo Justice and his mentor, the legendary Phoenix Wright, in this collection of three games. It features the 14 episodes of &lt;i&gt;Apollo Justice: Ace Attorney, Phoenix Wright: Ace Attorney ‚Äì Dual Destinies&lt;/i&gt; and &lt;i&gt;Phoenix Wright: Ace Attorney ‚Äì Spirit of Justice&lt;/i&gt;, as well as two special episodes that were previously only offered as downloadable content, for a total of 16 episodes. Also included is a mountain of extra goodies ‚Äî such as xx, yy and zz ‚Äî sure to satisfy any &lt;i&gt;Ace Attorney&lt;/i&gt; fan.&lt;/p&gt;
&lt;p&gt;Stream this legendary courtroom drama anywhere with GeForce NOW. Experience the sharp wit and thrilling investigations of &lt;i&gt;Apollo Justice: Ace Attorney Trilogy&lt;/i&gt; across laptops, Macs, phones and other gaming devices. With GeForce NOW powering the action, every objection comes through in high fidelity ‚Äî no long downloads, no waiting, just instant access to justice.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Zoom Down the Fast-Pass Lane&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87750"&gt;&lt;img alt="GeForce NOW Chromebook Fast Pass" class="size-large wp-image-87750" height="947" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/fastpass-1680x947.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87750"&gt;&lt;em&gt;Gotta go fast.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Gaming just got a major upgrade for Chromebook users. The GeForce NOW Chromebook Fast Pass unlocks a full year of cloud gaming with no ads or waiting in queues for a year ‚Äî simple, accessible and Chromebook-friendly. With this exclusive perk, Chromebook owners get 12 months of priority access to stream over 2,000 Ready-to-Play PC games from major libraries, all at 1080p and 60 fps, and without ads.‚Äã&lt;/p&gt;
&lt;p&gt;It‚Äôs never been easier to turn a Chromebook into a high-powered gaming rig. Grab a Fast Pass, jump into the action and take favorite PC games anywhere ‚Äî whether at home or on the go. This offer is available for new Chromebook and Chromebook+ owners, as well as new and existing GeForce NOW free users.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Let‚Äôs Play Today&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87706"&gt;&lt;img alt="S1 Battlefield 6 on GeForce NOW" class="size-large wp-image-87706" height="945" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/GFN_Thursday-Battlefield_6_S1-1680x945.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87706"&gt;&lt;em&gt;Rise from the rubble.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;‚ÄúSeason 1: California Resistance‚Äù is Battlefield 6‚Äôs second major update, transforming luxurious pools and private golf courses into a sprawling combat zone, with new updates to Battlefield 6 and free-to-play ‚ÄòREDSEC‚Äô experience. New maps stretch across abandoned city blocks and fractured coastlines, while fresh factions, vehicles and gadgets bring new strategies to the fight. It‚Äôs the dawn of a new chapter for Battlefield 6, full of surprises waiting behind every collapsing wall and cloud of dust.&lt;/p&gt;
&lt;p&gt;Squad coordination, reactive destruction and cinematic weather events keep every round unpredictable. Storm idyllic fairways and jump into chaos with an all-new Golf Cart on the new MP Map Eastwood. Even on the back nine, every explosion feels and takedown feels bigger, bolder and more cinematic than before.&lt;/p&gt;
&lt;p&gt;In addition, members can look for the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;SpongeBob SquarePants: Titans of the Tide&lt;/i&gt; (New release on Steam, Nov. 18)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Long Drive North &lt;/i&gt;(New release on Steam, Nov. 18)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Demonschool &lt;/i&gt;(New release on Steam, Nov. 19)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Moonlighter 2: The Endless Vault&lt;/i&gt; (New release on Steam and Xbox, available on Game Pass, Nov. 20)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Monsters Are Coming! Rock &amp;amp; Road &lt;/i&gt;(New release on Steam and Xbox, available on Game Pass, Nov. 20)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Prologue: Go Wayback! &lt;/i&gt;(New release on Steam, available Nov. 20)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;The Crew Motorfest&lt;/i&gt; (New release on Xbox, available on PC Game Pass, Nov. 20)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Apollo Justice: Ace Attorney Trilogy &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Sacred 2 Remaster &lt;/i&gt;(Steam)&lt;i&gt;&lt;/i&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;GeForce RTX 5080-ready game:&lt;/p&gt;

&lt;p&gt;To access supported Ubisoft titles from Xbox PC Game Pass on GeForce NOW ‚Äî such as this week‚Äôs addition, &lt;i&gt;The Crew Motorfest&lt;/i&gt; ‚Äî refer to this article for further details.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Launch dates shared on GFN Thursdays reflect release dates for new titles, which will arrive on GeForce NOW within the following week.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;What are you planning to play this weekend? Let us know on X or in the comments below.&lt;/p&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p dir="ltr" lang="en"&gt;Rewards are on their way!&lt;/p&gt;
&lt;p&gt;ü§¥ @GuildWars2 Bloody Prince Outfit for GFN members&lt;br /&gt;üí•@Borderlands 4 ECHO-4 Drone skin for Ultimate members&lt;/p&gt;
&lt;p&gt;Opt-in for GFN Rewards on your account so you don‚Äôt miss out üëâ https://t.co/BgW4GNBmUE pic.twitter.com/JamlTcQ8db&lt;/p&gt;
&lt;p&gt;‚Äî üå©Ô∏è NVIDIA GeForce NOW (@NVIDIAGFN) November 17, 2025&lt;/p&gt;&lt;/blockquote&gt;



		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;The NVIDIA Blackwell RTX upgrade is nearing the finish line, letting GeForce NOW Ultimate members across the globe experience true next-generation cloud gaming from anywhere.&lt;/p&gt;
&lt;p&gt;Everyone‚Äôs talking about Ultimate memberships ‚Äî including GeForce NOW partner 2K.&lt;/p&gt;
&lt;p&gt;‚ÄúWith GeForce NOW Ultimate, top-tier streaming truly goes everywhere,‚Äù said Sean Haran, head of partnerships and licensing at 2K. ‚ÄúAnyone can experience the glory of &lt;i&gt;Borderlands 4&lt;/i&gt;, with breathtaking graphics and flawless gameplay powered by GeForce RTX 5080 servers, even without the latest devices. Jump into the cloud and play at high settings, whether you‚Äôre at home or on the move.‚Äù&lt;/p&gt;
&lt;p&gt;The community has plenty to say about Ultimate, too. The GeForce NOW Community Video Contest invites gamers to share how GeForce NOW has changed the way they play. Participants can earn two Ultimate day passes ‚Äî one to keep and one to share with a gaming buddy ‚Äî and a chance to win a one-year Ultimate membership, just for submitting a clip.&lt;/p&gt;
&lt;p&gt;Plus, the celebration continues with free in-game skins for both &lt;i&gt;Guild Wars II &lt;/i&gt;and &lt;i&gt;Borderlands 4&lt;/i&gt;.&lt;/p&gt;
&lt;p&gt;And Capcom‚Äôs &lt;i&gt;Ace Attorney&lt;/i&gt; headlines the lineup of nine new titles joining the cloud this week, alongside even more ways to jump in with the new Chromebook Fast Pass.&lt;/p&gt;
&lt;p&gt;Stockholm will soon be the final region to get Blackwell RTX power, completing the rollout of GeForce RTX 5080-class performance worldwide. Ultrasmooth streaming, cutting-edge visuals and lightning-fast responsiveness are unlocking new levels of performance for Ultimate members.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;The Ultimate Leap&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87694"&gt;&lt;img alt="alt" class="wp-image-87694 size-large" height="945" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/GFN_Thursday-Server_Rollout_Map-1680x945.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87694"&gt;&lt;em&gt;Ultimate is everywhere, with Stockholm to be the final region to upgrade.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;GeForce RTX 5080-class performance is lighting up regions around the globe, powered by the Blackwell RTX upgrade.&lt;/p&gt;
&lt;p&gt;Ultimate now streams at up to 5K at 120 frames per second or up to 360 fps at 1080p for sharp, competitive play. Expect cinematic-quality visuals, advanced ray tracing and AI-powered performance that makes every frame shine on nearly any device. From the neon buzz of &lt;i&gt;Cyberpunk 2077&lt;/i&gt; to the over-the-top chaos of &lt;i&gt;Borderlands 4&lt;/i&gt;, gaming has never looked ‚Äî or felt ‚Äî this good.&lt;/p&gt;
&lt;p&gt;With high-dynamic-range visuals, support for racing wheels, ultrawide displays, gaming handhelds running up to 90 fps and an expanded library of over 4,000 games thanks to the Install-to-Play feature ‚Äî GeForce NOW enables every gamer to play bigger, go longer and jump right into blockbuster adventures without worrying about hardware.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;The Ultimate Contest&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;Members can join in celebrating GeForce RTX 5080-class power streaming all over the world by sharing gameplay videos of why the Ultimate experience stands out. Submit entries on the Blackwell upgrade page.&lt;/p&gt;
&lt;p&gt;Participants will earn two Ultimate day passes ‚Äî either for keeping or sharing with a friend. Top 10 entries will win a one-year Ultimate membership to keep the gaming going.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Calling All Heroes&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The celebrations don‚Äôt stop there. GeForce NOW members are in for a treat: fantastic rewards are up for grabs in &lt;i&gt;Borderlands 4&lt;/i&gt; and &lt;i&gt;Guild Wars 2&lt;/i&gt;.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87697"&gt;&lt;img alt="BL4 reward on GeForce NOW" class="size-large wp-image-87697" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/GFN_Thursday-Borderlands_4_Echo_4_Drone_Skin_Reward-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87697"&gt;&lt;em&gt;Stand out in the mayhem.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;GeForce NOW Ultimate members can claim the bold ECHO-4 drone skin in &lt;i&gt;Borderlands 4&lt;/i&gt; to show off their style while experiencing the game with cinematic-quality streaming and up to 2.8x higher frame rates, powered by NVIDIA Blackwell RTX servers.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87700"&gt;&lt;img alt="GW2 reward on GeForce NOW" class="size-large wp-image-87700" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/GFN_Thursday-Guild_Wars_2_Visions_of_Eternity_Reward-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87700"&gt;&lt;em&gt;Rule the realm in style.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;And in &lt;i&gt;Guild Wars 2&lt;/i&gt;, Ultimate members can unlock the regal and ruthless Bloody Prince Outfit, perfect for making a memorable entrance in the new ‚ÄúVisions of Eternity‚Äù expansion. Jump into epic quests across Castora to carve legends, harness ancient magic and stand out among heroes.&lt;/p&gt;
&lt;p&gt;It‚Äôs all about perks, effortless streaming and instant access ‚Äî no downloads required. With a GeForce NOW membership, play with style, power and rewards that let members shine in the worlds they explore.&lt;/p&gt;
&lt;p&gt;Claim member rewards in the GeForce NOW account portal, then follow the instructions to collect the in-game reward. For &lt;i&gt;Borderlands 4&lt;/i&gt;, enter the provided SHiFT code in the in-game menu. For &lt;i&gt;Guild Wars 2, &lt;/i&gt;log in to the GeForce NOW account to redeem.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Ready to Battle&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87703"&gt;&lt;img alt="Apollo Justice Ace Attorney Trilogy on GeForce NOW" class="size-large wp-image-87703" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/GFN_Thursday-Apollo_Justice_Ace_Attorney_Trilogy-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87703"&gt;&lt;em&gt;It‚Äôs justice time.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Apollo Justice‚Äôs legal journey begins anew.&lt;/p&gt;
&lt;p&gt;In &lt;i&gt;Apollo Justice: Ace Attorney Trilogy, &lt;/i&gt;join rookie attorney Apollo Justice and his mentor, the legendary Phoenix Wright, in this collection of three games. It features the 14 episodes of &lt;i&gt;Apollo Justice: Ace Attorney, Phoenix Wright: Ace Attorney ‚Äì Dual Destinies&lt;/i&gt; and &lt;i&gt;Phoenix Wright: Ace Attorney ‚Äì Spirit of Justice&lt;/i&gt;, as well as two special episodes that were previously only offered as downloadable content, for a total of 16 episodes. Also included is a mountain of extra goodies ‚Äî such as xx, yy and zz ‚Äî sure to satisfy any &lt;i&gt;Ace Attorney&lt;/i&gt; fan.&lt;/p&gt;
&lt;p&gt;Stream this legendary courtroom drama anywhere with GeForce NOW. Experience the sharp wit and thrilling investigations of &lt;i&gt;Apollo Justice: Ace Attorney Trilogy&lt;/i&gt; across laptops, Macs, phones and other gaming devices. With GeForce NOW powering the action, every objection comes through in high fidelity ‚Äî no long downloads, no waiting, just instant access to justice.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Zoom Down the Fast-Pass Lane&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87750"&gt;&lt;img alt="GeForce NOW Chromebook Fast Pass" class="size-large wp-image-87750" height="947" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/fastpass-1680x947.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87750"&gt;&lt;em&gt;Gotta go fast.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Gaming just got a major upgrade for Chromebook users. The GeForce NOW Chromebook Fast Pass unlocks a full year of cloud gaming with no ads or waiting in queues for a year ‚Äî simple, accessible and Chromebook-friendly. With this exclusive perk, Chromebook owners get 12 months of priority access to stream over 2,000 Ready-to-Play PC games from major libraries, all at 1080p and 60 fps, and without ads.‚Äã&lt;/p&gt;
&lt;p&gt;It‚Äôs never been easier to turn a Chromebook into a high-powered gaming rig. Grab a Fast Pass, jump into the action and take favorite PC games anywhere ‚Äî whether at home or on the go. This offer is available for new Chromebook and Chromebook+ owners, as well as new and existing GeForce NOW free users.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Let‚Äôs Play Today&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87706"&gt;&lt;img alt="S1 Battlefield 6 on GeForce NOW" class="size-large wp-image-87706" height="945" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/GFN_Thursday-Battlefield_6_S1-1680x945.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87706"&gt;&lt;em&gt;Rise from the rubble.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;‚ÄúSeason 1: California Resistance‚Äù is Battlefield 6‚Äôs second major update, transforming luxurious pools and private golf courses into a sprawling combat zone, with new updates to Battlefield 6 and free-to-play ‚ÄòREDSEC‚Äô experience. New maps stretch across abandoned city blocks and fractured coastlines, while fresh factions, vehicles and gadgets bring new strategies to the fight. It‚Äôs the dawn of a new chapter for Battlefield 6, full of surprises waiting behind every collapsing wall and cloud of dust.&lt;/p&gt;
&lt;p&gt;Squad coordination, reactive destruction and cinematic weather events keep every round unpredictable. Storm idyllic fairways and jump into chaos with an all-new Golf Cart on the new MP Map Eastwood. Even on the back nine, every explosion feels and takedown feels bigger, bolder and more cinematic than before.&lt;/p&gt;
&lt;p&gt;In addition, members can look for the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;SpongeBob SquarePants: Titans of the Tide&lt;/i&gt; (New release on Steam, Nov. 18)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Long Drive North &lt;/i&gt;(New release on Steam, Nov. 18)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Demonschool &lt;/i&gt;(New release on Steam, Nov. 19)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Moonlighter 2: The Endless Vault&lt;/i&gt; (New release on Steam and Xbox, available on Game Pass, Nov. 20)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Monsters Are Coming! Rock &amp;amp; Road &lt;/i&gt;(New release on Steam and Xbox, available on Game Pass, Nov. 20)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Prologue: Go Wayback! &lt;/i&gt;(New release on Steam, available Nov. 20)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;The Crew Motorfest&lt;/i&gt; (New release on Xbox, available on PC Game Pass, Nov. 20)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Apollo Justice: Ace Attorney Trilogy &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Sacred 2 Remaster &lt;/i&gt;(Steam)&lt;i&gt;&lt;/i&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;GeForce RTX 5080-ready game:&lt;/p&gt;

&lt;p&gt;To access supported Ubisoft titles from Xbox PC Game Pass on GeForce NOW ‚Äî such as this week‚Äôs addition, &lt;i&gt;The Crew Motorfest&lt;/i&gt; ‚Äî refer to this article for further details.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Launch dates shared on GFN Thursdays reflect release dates for new titles, which will arrive on GeForce NOW within the following week.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;What are you planning to play this weekend? Let us know on X or in the comments below.&lt;/p&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p dir="ltr" lang="en"&gt;Rewards are on their way!&lt;/p&gt;
&lt;p&gt;ü§¥ @GuildWars2 Bloody Prince Outfit for GFN members&lt;br /&gt;üí•@Borderlands 4 ECHO-4 Drone skin for Ultimate members&lt;/p&gt;
&lt;p&gt;Opt-in for GFN Rewards on your account so you don‚Äôt miss out üëâ https://t.co/BgW4GNBmUE pic.twitter.com/JamlTcQ8db&lt;/p&gt;
&lt;p&gt;‚Äî üå©Ô∏è NVIDIA GeForce NOW (@NVIDIAGFN) November 17, 2025&lt;/p&gt;&lt;/blockquote&gt;



		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/geforce-now-thursday-ultimate-is-everywhere/</guid><pubDate>Thu, 20 Nov 2025 14:00:07 +0000</pubDate></item><item><title>[NEW] The Largest Digital Zoo: Biology Model Trained on NVIDIA GPUs Identifies Over a Million Species (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/bioclip2-foundation-ai-model/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Tanya Berger-Wolf‚Äôs first computational biology project started as a bet with a colleague: that she could build an AI model capable of identifying individual zebras faster than a zoologist.&lt;/p&gt;
&lt;p&gt;She won.&lt;/p&gt;
&lt;p&gt;Now, the director of the Translational Data Analytics Institute and a professor at The Ohio State University, Berger-Wolf is taking on the whole animal kingdom with BioCLIP 2, a biology-based foundation model trained on the biggest, most diverse dataset of organisms to date. The model will be showcased at this year‚Äôs NeurIPS AI research conference.&lt;/p&gt;
&lt;p&gt;BioCLIP 2 goes beyond extracting information from images. It can distinguish species‚Äô traits and determine inter-and intraspecies relationships. For example, the model arranged Darwin‚Äôs finches by beak size, without teaching the concept of size, shown in the image below.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87662"&gt;&lt;img alt="alt" class="size-large wp-image-87662" height="1215" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/nvidia-beak-size-1680x1215.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87662"&gt;Scatter plot shows how BioCLIP 2 arranges Darwin‚Äôs finches by beak size from left to right.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;These capabilities will allow researchers to use the model as both a biological encyclopedia, a powerful scientific platform and an interactive research tool with inference capabilities to help address an ongoing issue in conservation biology: data deficiency for certain species.&lt;/p&gt;
&lt;p&gt;‚ÄúFor iconic species like killer whales, we lack enough data to determine population size and for polar bears, the population is unknown,‚Äù said Berger-Wolf. ‚ÄúIf we don‚Äôt have data for those species, what hope do the beetles and fungi have?‚Äù&lt;/p&gt;
&lt;p&gt;AI models can enhance existing conservation efforts for threatened species and their habitats by filling this data-deficiency gap.&lt;/p&gt;
&lt;p&gt;BioCLIP 2 is available under an open-source license on Hugging Face, where it was downloaded over 45,000 times last month. This paper builds on the first BioCLIP model, released over a year ago, which was also trained on NVIDIA GPUs and received the Best Student Paper award at the Computer Vision and Pattern Recognition (CVPR) conference.&lt;/p&gt;
&lt;p&gt;The BioCLIP 2 paper will be presented at NeurIPS, taking place Nov. 30-Dec. 5 in Mexico City, and Dec. 2-7 in San Diego.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Building the World‚Äôs Biggest Biological Flash Card Deck&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The project began with the compilation of a massive dataset, TREEOFLIFE-200M, which comprises 214 million images of organisms that span over 925,000 taxonomic classes ‚Äî from monkeys to mealworms and magnolias.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-large wp-image-87665" height="945" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/funky-monkey-1680x945.png" width="1680" /&gt;&lt;/p&gt;
&lt;p&gt;To curate this vast amount of data, Berger-Wolf‚Äôs team at the Imageomics Institute collaborated with the Smithsonian Institution, experts from various universities and other field-related organizations.&lt;/p&gt;
&lt;p&gt;These researchers set out to discover what would happen if they trained a biology model on more data than ever.&lt;/p&gt;
&lt;p&gt;The team wanted to see if it was possible to move ‚Äúbeyond the science of individual organisms to the science of ecosystems,‚Äù said Berger-Wolf.&lt;/p&gt;
&lt;p&gt;After 10 days of training on 32 NVIDIA H100 GPUs, BioCLIP 2 displayed novel abilities, such as distinguishing between adult and juvenile as well as male and female animals within species ‚Äî without being explicitly taught these concepts.&lt;/p&gt;
&lt;p&gt;It also made associations between related species ‚Äî like understanding how zebras relate to other equids.&lt;/p&gt;
&lt;p&gt;‚ÄúThis model learns that at every level of taxonomy, all of these images of zebras have a particular genus label, and of these images of equids ‚Äî including zebras, horses and donkeys ‚Äî they have a particular family trait and so on,‚Äù she said. ‚ÄúIt learns the hierarchy without ever being told it, just through these associations.‚Äù&lt;/p&gt;
&lt;p&gt;The model can even determine the health of an organism based on training data. For example, it separated healthy apple or blueberry leaves from diseased leaves, as well as could recognize differing types of diseases, when generating the scatter plot below.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87668"&gt;&lt;img alt="alt" class="size-large wp-image-87668" height="447" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/nvidia-plant-doc-1680x447.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87668"&gt;The scatter plots show plant species better separated as the model is trained. The intra-species variations also form clusters, making them easier to separate.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Berger-Wolf‚Äôs team used a cluster of 64 NVIDIA Tensor Core GPUs to accelerate model training, plus individual Tensor Core GPUs for inference.&lt;br /&gt;‚ÄúFoundation models like BioCLIP would not be possible without NVIDIA accelerated computing,‚Äù said Berger-Wolf.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Wildlife Digital Twins: The Future of Studying Ecosystem Relationships&amp;nbsp; &lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The researchers‚Äô next endeavor is to develop a wildlife-based interactive digital twin that can be used to visualize and simulate ecological interactions between species as well as their ways of engaging with the environment.&lt;/p&gt;
&lt;p&gt;The goal is to provide a safe, easy way to study organismal relationships that naturally occur in the wild, while minimizing impact and disturbance on ecosystems.&lt;/p&gt;
&lt;p&gt;‚ÄúThe digital twin allows us to visualize species interactions and put them in context, as well as to play the what-if scenarios and test our models without destroying the actual environment ‚Äî creating as light a footprint as possible,‚Äù said Berger-Wolf.&lt;/p&gt;
&lt;p&gt;The digital twin will give scientists the opportunity to explore the points of view of the species they‚Äôre studying within the simulated environment, opening endless possibilities for more complex and accurate ecological research.&lt;/p&gt;
&lt;p&gt;Eventually, versions of this technology could even be deployed for public use ‚Äî such as through interactive platforms at zoos. People could explore, visualize and learn about the natural environment and its many species from entirely new vantage points.&lt;/p&gt;
&lt;p&gt;‚ÄúI‚Äôm getting goosebumps just imagining that scenario of a kid coming into the zoo and being like, wow ‚Äî this is what you would see if you were another zebra part of that herd, or if you were the little spider sitting on that scratching post,‚Äù Berger-Wolf said.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Learn more about&lt;/i&gt; &lt;i&gt;BioCLIP 2&lt;/i&gt;.&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Tanya Berger-Wolf‚Äôs first computational biology project started as a bet with a colleague: that she could build an AI model capable of identifying individual zebras faster than a zoologist.&lt;/p&gt;
&lt;p&gt;She won.&lt;/p&gt;
&lt;p&gt;Now, the director of the Translational Data Analytics Institute and a professor at The Ohio State University, Berger-Wolf is taking on the whole animal kingdom with BioCLIP 2, a biology-based foundation model trained on the biggest, most diverse dataset of organisms to date. The model will be showcased at this year‚Äôs NeurIPS AI research conference.&lt;/p&gt;
&lt;p&gt;BioCLIP 2 goes beyond extracting information from images. It can distinguish species‚Äô traits and determine inter-and intraspecies relationships. For example, the model arranged Darwin‚Äôs finches by beak size, without teaching the concept of size, shown in the image below.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87662"&gt;&lt;img alt="alt" class="size-large wp-image-87662" height="1215" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/nvidia-beak-size-1680x1215.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87662"&gt;Scatter plot shows how BioCLIP 2 arranges Darwin‚Äôs finches by beak size from left to right.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;These capabilities will allow researchers to use the model as both a biological encyclopedia, a powerful scientific platform and an interactive research tool with inference capabilities to help address an ongoing issue in conservation biology: data deficiency for certain species.&lt;/p&gt;
&lt;p&gt;‚ÄúFor iconic species like killer whales, we lack enough data to determine population size and for polar bears, the population is unknown,‚Äù said Berger-Wolf. ‚ÄúIf we don‚Äôt have data for those species, what hope do the beetles and fungi have?‚Äù&lt;/p&gt;
&lt;p&gt;AI models can enhance existing conservation efforts for threatened species and their habitats by filling this data-deficiency gap.&lt;/p&gt;
&lt;p&gt;BioCLIP 2 is available under an open-source license on Hugging Face, where it was downloaded over 45,000 times last month. This paper builds on the first BioCLIP model, released over a year ago, which was also trained on NVIDIA GPUs and received the Best Student Paper award at the Computer Vision and Pattern Recognition (CVPR) conference.&lt;/p&gt;
&lt;p&gt;The BioCLIP 2 paper will be presented at NeurIPS, taking place Nov. 30-Dec. 5 in Mexico City, and Dec. 2-7 in San Diego.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Building the World‚Äôs Biggest Biological Flash Card Deck&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The project began with the compilation of a massive dataset, TREEOFLIFE-200M, which comprises 214 million images of organisms that span over 925,000 taxonomic classes ‚Äî from monkeys to mealworms and magnolias.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-large wp-image-87665" height="945" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/funky-monkey-1680x945.png" width="1680" /&gt;&lt;/p&gt;
&lt;p&gt;To curate this vast amount of data, Berger-Wolf‚Äôs team at the Imageomics Institute collaborated with the Smithsonian Institution, experts from various universities and other field-related organizations.&lt;/p&gt;
&lt;p&gt;These researchers set out to discover what would happen if they trained a biology model on more data than ever.&lt;/p&gt;
&lt;p&gt;The team wanted to see if it was possible to move ‚Äúbeyond the science of individual organisms to the science of ecosystems,‚Äù said Berger-Wolf.&lt;/p&gt;
&lt;p&gt;After 10 days of training on 32 NVIDIA H100 GPUs, BioCLIP 2 displayed novel abilities, such as distinguishing between adult and juvenile as well as male and female animals within species ‚Äî without being explicitly taught these concepts.&lt;/p&gt;
&lt;p&gt;It also made associations between related species ‚Äî like understanding how zebras relate to other equids.&lt;/p&gt;
&lt;p&gt;‚ÄúThis model learns that at every level of taxonomy, all of these images of zebras have a particular genus label, and of these images of equids ‚Äî including zebras, horses and donkeys ‚Äî they have a particular family trait and so on,‚Äù she said. ‚ÄúIt learns the hierarchy without ever being told it, just through these associations.‚Äù&lt;/p&gt;
&lt;p&gt;The model can even determine the health of an organism based on training data. For example, it separated healthy apple or blueberry leaves from diseased leaves, as well as could recognize differing types of diseases, when generating the scatter plot below.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87668"&gt;&lt;img alt="alt" class="size-large wp-image-87668" height="447" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/nvidia-plant-doc-1680x447.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87668"&gt;The scatter plots show plant species better separated as the model is trained. The intra-species variations also form clusters, making them easier to separate.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Berger-Wolf‚Äôs team used a cluster of 64 NVIDIA Tensor Core GPUs to accelerate model training, plus individual Tensor Core GPUs for inference.&lt;br /&gt;‚ÄúFoundation models like BioCLIP would not be possible without NVIDIA accelerated computing,‚Äù said Berger-Wolf.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Wildlife Digital Twins: The Future of Studying Ecosystem Relationships&amp;nbsp; &lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The researchers‚Äô next endeavor is to develop a wildlife-based interactive digital twin that can be used to visualize and simulate ecological interactions between species as well as their ways of engaging with the environment.&lt;/p&gt;
&lt;p&gt;The goal is to provide a safe, easy way to study organismal relationships that naturally occur in the wild, while minimizing impact and disturbance on ecosystems.&lt;/p&gt;
&lt;p&gt;‚ÄúThe digital twin allows us to visualize species interactions and put them in context, as well as to play the what-if scenarios and test our models without destroying the actual environment ‚Äî creating as light a footprint as possible,‚Äù said Berger-Wolf.&lt;/p&gt;
&lt;p&gt;The digital twin will give scientists the opportunity to explore the points of view of the species they‚Äôre studying within the simulated environment, opening endless possibilities for more complex and accurate ecological research.&lt;/p&gt;
&lt;p&gt;Eventually, versions of this technology could even be deployed for public use ‚Äî such as through interactive platforms at zoos. People could explore, visualize and learn about the natural environment and its many species from entirely new vantage points.&lt;/p&gt;
&lt;p&gt;‚ÄúI‚Äôm getting goosebumps just imagining that scenario of a kid coming into the zoo and being like, wow ‚Äî this is what you would see if you were another zebra part of that herd, or if you were the little spider sitting on that scratching post,‚Äù Berger-Wolf said.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Learn more about&lt;/i&gt; &lt;i&gt;BioCLIP 2&lt;/i&gt;.&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/bioclip2-foundation-ai-model/</guid><pubDate>Thu, 20 Nov 2025 14:00:17 +0000</pubDate></item><item><title>[NEW] How to choose the best thermal binoculars for long-range detection in 2026 (AI News)</title><link>https://www.artificialintelligence-news.com/news/how-to-choose-the-best-thermal-binoculars-for-long-range-detection-in-2026/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/ran-berkovich-kSLNVacFehs-unsplash-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Choosing the right thermal binoculars is essential for security professionals and outdoor specialists who need reliable long-range detection. Many users who previously relied on the market‚Äôs best night vision binoculars now seek advanced thermal imaging for superior clarity, extended range, and weather-independent performance. In 2026, ATN continues to lead the market with cutting-edge thermal binoculars designed for precision and durability.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-understanding-atn-thermal-binocular-technology"&gt;Understanding ATN thermal binocular technology&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Why ATN thermal binoculars stand out&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;ATN‚Äôs thermal binoculars, like the ATN BinoX 4T and BinoX 4T Pro Series, deliver top-tier detection capabilities by combining high-resolution sensors, variable magnification, and intelligent onboard software. These binoculars do not rely on light; instead, they detect heat signatures, making them effective in fog, total darkness, heavy brush, and complex terrain.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Long-range detection performance&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;ATN thermal binoculars are engineered for extended-range identification. With ultra-sensitive sensors, powerful optical zoom, and built-in image enhancement algorithms, models like the ATN BinoX 4T 640 offer detection ranges stretching several thousand yards. For 2026, ATN has focused on improving temperature sensitivity, refresh rates, and enhanced object recognition to support longer detection distances with greater precision.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-buyer-s-guide-how-to-choose-the-right-thermal-binoculars-for-2026"&gt;Buyer‚Äôs guide: How to choose the right thermal binoculars for 2026&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Sensor resolution&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Resolution is the most important factor in long-range performance. ATN offers two main categories:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;384√ó288 sensors for budget-friendly, mid-range detection&lt;/li&gt;&lt;li&gt;640√ó480 sensors for maximum clarity and long-range detail&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Higher resolution provides sharper images, better object identification, and more accurate heat differentiation at extended distances.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Optical and digital magnification&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;ATN‚Äôs BinoX 4T models offer variable zoom that maintains image stability and clarity. For long-range detection, selecting a model with higher native magnification is essential. ATN‚Äôs 640 series typically provides the best combination of zoom and image quality without excessive pixelation.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Refresh rate and image processing&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;ATN integrates advanced thermal processors and high refresh rates that minimise image lag, especially during fast movement. A 60 Hz refresh rate provides smoother scanning and more accurate target tracking.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Detection, recognition, and identification ranges&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Before buying, compare ATN‚Äôs DRI specifications:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Detection: seeing a heat signature at extreme distance&lt;/li&gt;&lt;li&gt;Recognition: determining object classification (animal, human, vehicle)&lt;/li&gt;&lt;li&gt;Identification: positive ID at long range&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;ATN‚Äôs latest 640 sensors significantly enhance all three.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Battery performance&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;ATN‚Äôs thermal binoculars feature extended battery life suitable for long hunts or overnight surveillance. In 2026, ATN upgrades include improved energy efficiency and faster charging through USB-C.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Smart features&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;ATN leads the industry with integrated intelligent features, including:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Laser rangefinder&lt;/li&gt;&lt;li&gt;Ballistic Information Exchange&lt;/li&gt;&lt;li&gt;Video recording and streaming&lt;/li&gt;&lt;li&gt;Built-in compass and gyroscope&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The features support long-range accuracy and situational awareness.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;One-time list: Top ATN features to look for in 2026&lt;/strong&gt;&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;High-resolution 640 sensor&lt;/li&gt;&lt;li&gt;Variable optical zoom&lt;/li&gt;&lt;li&gt;Extended DRI ranges&lt;/li&gt;&lt;li&gt;Laser rangefinder integration&lt;/li&gt;&lt;li&gt;Smart video recording and streaming&lt;/li&gt;&lt;li&gt;Long battery life&lt;/li&gt;&lt;li&gt;Rugged, weather-resistant construction&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Durability and build quality&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;ATN thermal binoculars are built for harsh environments, featuring reinforced housings, weatherproof design, and ergonomic grip options. Durable construction is essential for long-range users who rely on their optics in extreme temperatures, rough terrain, and unpredictable weather.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Price and warranty support&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;ATN provides competitive pricing for premium thermal gear, along with strong warranty coverage and US-based customer support. Higher-end models may cost more, but they deliver unmatched long-range clarity and reliability.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-final-thoughts-on-choosing-atn-thermal-binoculars-in-2026"&gt;Final thoughts on choosing ATN thermal binoculars in 2026&lt;/h3&gt;&lt;p&gt;Selecting the right thermal binoculars for long-range detection involves understanding sensor quality, magnification, DRI ranges, and overall performance. ATN remains the leading choice for professionals and hunters in 2026 due to its combination of high-resolution sensors, precise zoom systems, and smart onboard technologies. Whether you‚Äôre observing wildlife at extreme distances or ensuring perimeter security, ATN‚Äôs BinoX 4T and 4T Pro models offer exceptional reliability and long-range clarity.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Image source: Unsplash&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/ran-berkovich-kSLNVacFehs-unsplash-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Choosing the right thermal binoculars is essential for security professionals and outdoor specialists who need reliable long-range detection. Many users who previously relied on the market‚Äôs best night vision binoculars now seek advanced thermal imaging for superior clarity, extended range, and weather-independent performance. In 2026, ATN continues to lead the market with cutting-edge thermal binoculars designed for precision and durability.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-understanding-atn-thermal-binocular-technology"&gt;Understanding ATN thermal binocular technology&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Why ATN thermal binoculars stand out&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;ATN‚Äôs thermal binoculars, like the ATN BinoX 4T and BinoX 4T Pro Series, deliver top-tier detection capabilities by combining high-resolution sensors, variable magnification, and intelligent onboard software. These binoculars do not rely on light; instead, they detect heat signatures, making them effective in fog, total darkness, heavy brush, and complex terrain.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Long-range detection performance&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;ATN thermal binoculars are engineered for extended-range identification. With ultra-sensitive sensors, powerful optical zoom, and built-in image enhancement algorithms, models like the ATN BinoX 4T 640 offer detection ranges stretching several thousand yards. For 2026, ATN has focused on improving temperature sensitivity, refresh rates, and enhanced object recognition to support longer detection distances with greater precision.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-buyer-s-guide-how-to-choose-the-right-thermal-binoculars-for-2026"&gt;Buyer‚Äôs guide: How to choose the right thermal binoculars for 2026&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Sensor resolution&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Resolution is the most important factor in long-range performance. ATN offers two main categories:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;384√ó288 sensors for budget-friendly, mid-range detection&lt;/li&gt;&lt;li&gt;640√ó480 sensors for maximum clarity and long-range detail&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Higher resolution provides sharper images, better object identification, and more accurate heat differentiation at extended distances.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Optical and digital magnification&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;ATN‚Äôs BinoX 4T models offer variable zoom that maintains image stability and clarity. For long-range detection, selecting a model with higher native magnification is essential. ATN‚Äôs 640 series typically provides the best combination of zoom and image quality without excessive pixelation.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Refresh rate and image processing&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;ATN integrates advanced thermal processors and high refresh rates that minimise image lag, especially during fast movement. A 60 Hz refresh rate provides smoother scanning and more accurate target tracking.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Detection, recognition, and identification ranges&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Before buying, compare ATN‚Äôs DRI specifications:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Detection: seeing a heat signature at extreme distance&lt;/li&gt;&lt;li&gt;Recognition: determining object classification (animal, human, vehicle)&lt;/li&gt;&lt;li&gt;Identification: positive ID at long range&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;ATN‚Äôs latest 640 sensors significantly enhance all three.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Battery performance&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;ATN‚Äôs thermal binoculars feature extended battery life suitable for long hunts or overnight surveillance. In 2026, ATN upgrades include improved energy efficiency and faster charging through USB-C.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Smart features&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;ATN leads the industry with integrated intelligent features, including:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Laser rangefinder&lt;/li&gt;&lt;li&gt;Ballistic Information Exchange&lt;/li&gt;&lt;li&gt;Video recording and streaming&lt;/li&gt;&lt;li&gt;Built-in compass and gyroscope&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The features support long-range accuracy and situational awareness.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;One-time list: Top ATN features to look for in 2026&lt;/strong&gt;&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;High-resolution 640 sensor&lt;/li&gt;&lt;li&gt;Variable optical zoom&lt;/li&gt;&lt;li&gt;Extended DRI ranges&lt;/li&gt;&lt;li&gt;Laser rangefinder integration&lt;/li&gt;&lt;li&gt;Smart video recording and streaming&lt;/li&gt;&lt;li&gt;Long battery life&lt;/li&gt;&lt;li&gt;Rugged, weather-resistant construction&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Durability and build quality&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;ATN thermal binoculars are built for harsh environments, featuring reinforced housings, weatherproof design, and ergonomic grip options. Durable construction is essential for long-range users who rely on their optics in extreme temperatures, rough terrain, and unpredictable weather.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Price and warranty support&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;ATN provides competitive pricing for premium thermal gear, along with strong warranty coverage and US-based customer support. Higher-end models may cost more, but they deliver unmatched long-range clarity and reliability.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-final-thoughts-on-choosing-atn-thermal-binoculars-in-2026"&gt;Final thoughts on choosing ATN thermal binoculars in 2026&lt;/h3&gt;&lt;p&gt;Selecting the right thermal binoculars for long-range detection involves understanding sensor quality, magnification, DRI ranges, and overall performance. ATN remains the leading choice for professionals and hunters in 2026 due to its combination of high-resolution sensors, precise zoom systems, and smart onboard technologies. Whether you‚Äôre observing wildlife at extreme distances or ensuring perimeter security, ATN‚Äôs BinoX 4T and 4T Pro models offer exceptional reliability and long-range clarity.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Image source: Unsplash&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/how-to-choose-the-best-thermal-binoculars-for-long-range-detection-in-2026/</guid><pubDate>Thu, 20 Nov 2025 14:09:08 +0000</pubDate></item><item><title>[NEW] Designing digital resilience in the agentic AI era (Artificial intelligence ‚Äì MIT Technology Review)</title><link>https://www.technologyreview.com/2025/11/20/1127941/designing-digital-resilience-in-the-agentic-ai-era/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;Cisco&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Digital resilience‚Äîthe ability to prevent, withstand, and recover from digital disruptions‚Äîhas long been a strategic priority for enterprises. With the rise of agentic AI, the urgency for robust resilience is greater than ever.&lt;/p&gt;  &lt;p&gt;Agentic AI represents a new generation of autonomous systems capable of proactive planning, reasoning, and executing tasks with minimal human intervention. As these systems shift from experimental pilots to core elements of business operations, they offer new opportunities but also introduce new challenges when it comes to ensuring digital resilience. That‚Äôs because the autonomy, speed, and scale at which agentic AI operates can amplify the impact of even minor data inconsistencies, fragmentation, or security gaps.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-1127946" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/iStock-1372094301.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;While global investment in AI is projected to reach $1.5 trillion in 2025, fewer than half of business leaders are confident in their organization‚Äôs ability to maintain service continuity, security, and cost control during unexpected events. This lack of confidence, coupled with the profound complexity introduced by agentic AI‚Äôs autonomous decision-making and interaction with critical infrastructure, requires a reimagining of digital resilience.&lt;/p&gt;  &lt;p&gt;Organizations are turning to the concept of a data fabric‚Äîan integrated architecture that connects and governs information across all business layers. By breaking down silos and enabling real-time access to enterprise-wide data, a data fabric can empower both human teams and agentic AI systems to sense risks, prevent problems before they occur, recover quickly when they do, and sustain operations.&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Machine data: A cornerstone of agentic AI and digital resilience&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Earlier AI models relied heavily on human-generated data such as text, audio, and video, but agentic AI demands deep insight into an organization‚Äôs machine data: the logs, metrics, and other telemetry generated by devices, servers, systems, and applications.&lt;/p&gt;  &lt;p&gt;To put agentic AI to use in driving digital resilience, it must have seamless, real-time access to this data flow. Without comprehensive integration of machine data, organizations risk limiting AI capabilities, missing critical anomalies, or introducing errors. As Kamal Hathi, senior vice president and general manager of Splunk, a Cisco company, emphasizes, agentic AI systems rely on machine data to understand context, simulate outcomes, and adapt continuously. This makes machine data oversight a cornerstone of digital resilience.&lt;/p&gt; 
 &lt;p&gt;‚ÄúWe often describe machine data as the heartbeat of the modern enterprise,‚Äù says Hathi. ‚ÄúAgentic AI systems are powered by this vital pulse, requiring real-time access to information. It‚Äôs essential that these intelligent agents operate directly on the intricate flow of machine data and that AI itself is trained using the very same data stream.‚Äù&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Few organizations are currently achieving the level of machine data integration required to fully enable agentic systems. This not only narrows the scope of possible use cases for agentic AI, but, worse, it can also result in data anomalies and errors in outputs or actions. Natural language processing (NLP) models designed prior to the development of generative pre-trained transformers (GPTs) were plagued by linguistic ambiguities, biases, and inconsistencies. Similar misfires could occur with agentic AI if organizations rush ahead without providing models with a foundational fluency in machine data.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;For many companies, keeping up with the dizzying pace at which AI is progressing has been a major challenge. ‚ÄúIn some ways, the speed of this innovation is starting to hurt us, because it creates risks we‚Äôre not ready for,‚Äù says Hathi. ‚ÄúThe trouble is that with agentic AI's evolution, relying on traditional LLMs trained on human text, audio, video, or print data doesn't work when you need your system to be secure, resilient, and always available.‚Äù&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Designing a data fabric&amp;nbsp;for resilience&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;To address these shortcomings and build digital resilience, technology leaders should pivot to what Hathi describes as a data fabric design, better suited to the demands of agentic AI. This involves weaving together fragmented assets from across security, IT, business operations, and the network to create an integrated architecture that connects disparate data sources, breaks down silos, and enables real-time analysis and risk management.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;&lt;p&gt;‚ÄúOnce you have a single view, you can do all these things that are autonomous and agentic,‚Äù says Hathi. ‚ÄúYou have far fewer blind spots. Decision-making goes much faster. And the unknown is no longer a source of fear because you have a holistic system that's able to absorb these shocks and disruption without losing continuity,‚Äù he adds.&lt;/p&gt;  &lt;p&gt;To create this unified system, data teams must first break down departmental silos in how data is shared, says Hathi. Then, they must implement a federated data architecture‚Äîa decentralized system where autonomous data sources work together as a single unit without physically merging‚Äîto create a unified data source while maintaining governance and security. And finally, teams must upgrade data platforms to ensure this newly unified view is actionable for agentic AI.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;During this transition, teams may face technical limitations if they rely on traditional platforms modeled on structured data‚Äîthat is, mostly quantitative information such as customer records or financial transactions that can be organized in a predefined format (often in tables) that is easy to query. Instead, companies need a platform that can also manage streams of unstructured data such as system logs, security events, and application traces, which lack uniformity and are often qualitative rather than quantitative. Analyzing, organizing, and extracting insights from these kinds of data requires more advanced methods enabled by AI.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Harnessing AI as a collaborator&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;AI itself can be a powerful tool in creating the data fabric that enables AI systems. AI-powered tools can, for example, quickly identify relationships between disparate data‚Äîboth structured and unstructured‚Äîautomatically merging them into one source of truth. They can detect and correct errors and employ NLP to tag and categorize data to make it easier to find and use.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;Agentic AI systems can also be used to augment human capabilities in detecting and deciphering anomalies in an enterprise‚Äôs unstructured data streams. These are often beyond human capacity to spot or interpret at speed, leading to missed threats or delays. But agentic AI systems, designed to perceive, reason, and act autonomously, can plug the gap, delivering higher levels of digital resilience to an enterprise.&lt;/p&gt;  &lt;p&gt;‚ÄúDigital resilience is about more than withstanding disruptions,‚Äù says Hathi. ‚ÄúIt's about evolving and growing over time. AI agents can work with massive amounts of data and continuously learn from humans who provide safety and oversight. This is a true self-optimizing system.‚Äù&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Humans in the loop&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Despite its potential, agentic AI should be positioned as assistive intelligence. Without proper oversight, AI agents could introduce application failures or security risks.&lt;/p&gt;  &lt;p&gt;Clearly defined guardrails and maintaining humans in the loop is ‚Äúkey to trustworthy and practical use of AI,‚Äù Hathi says. ‚ÄúAI can enhance human decision-making, but ultimately, humans are in the driver's seat.‚Äù&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review‚Äôs editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;Cisco&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Digital resilience‚Äîthe ability to prevent, withstand, and recover from digital disruptions‚Äîhas long been a strategic priority for enterprises. With the rise of agentic AI, the urgency for robust resilience is greater than ever.&lt;/p&gt;  &lt;p&gt;Agentic AI represents a new generation of autonomous systems capable of proactive planning, reasoning, and executing tasks with minimal human intervention. As these systems shift from experimental pilots to core elements of business operations, they offer new opportunities but also introduce new challenges when it comes to ensuring digital resilience. That‚Äôs because the autonomy, speed, and scale at which agentic AI operates can amplify the impact of even minor data inconsistencies, fragmentation, or security gaps.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-1127946" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/iStock-1372094301.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;While global investment in AI is projected to reach $1.5 trillion in 2025, fewer than half of business leaders are confident in their organization‚Äôs ability to maintain service continuity, security, and cost control during unexpected events. This lack of confidence, coupled with the profound complexity introduced by agentic AI‚Äôs autonomous decision-making and interaction with critical infrastructure, requires a reimagining of digital resilience.&lt;/p&gt;  &lt;p&gt;Organizations are turning to the concept of a data fabric‚Äîan integrated architecture that connects and governs information across all business layers. By breaking down silos and enabling real-time access to enterprise-wide data, a data fabric can empower both human teams and agentic AI systems to sense risks, prevent problems before they occur, recover quickly when they do, and sustain operations.&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Machine data: A cornerstone of agentic AI and digital resilience&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Earlier AI models relied heavily on human-generated data such as text, audio, and video, but agentic AI demands deep insight into an organization‚Äôs machine data: the logs, metrics, and other telemetry generated by devices, servers, systems, and applications.&lt;/p&gt;  &lt;p&gt;To put agentic AI to use in driving digital resilience, it must have seamless, real-time access to this data flow. Without comprehensive integration of machine data, organizations risk limiting AI capabilities, missing critical anomalies, or introducing errors. As Kamal Hathi, senior vice president and general manager of Splunk, a Cisco company, emphasizes, agentic AI systems rely on machine data to understand context, simulate outcomes, and adapt continuously. This makes machine data oversight a cornerstone of digital resilience.&lt;/p&gt; 
 &lt;p&gt;‚ÄúWe often describe machine data as the heartbeat of the modern enterprise,‚Äù says Hathi. ‚ÄúAgentic AI systems are powered by this vital pulse, requiring real-time access to information. It‚Äôs essential that these intelligent agents operate directly on the intricate flow of machine data and that AI itself is trained using the very same data stream.‚Äù&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Few organizations are currently achieving the level of machine data integration required to fully enable agentic systems. This not only narrows the scope of possible use cases for agentic AI, but, worse, it can also result in data anomalies and errors in outputs or actions. Natural language processing (NLP) models designed prior to the development of generative pre-trained transformers (GPTs) were plagued by linguistic ambiguities, biases, and inconsistencies. Similar misfires could occur with agentic AI if organizations rush ahead without providing models with a foundational fluency in machine data.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;For many companies, keeping up with the dizzying pace at which AI is progressing has been a major challenge. ‚ÄúIn some ways, the speed of this innovation is starting to hurt us, because it creates risks we‚Äôre not ready for,‚Äù says Hathi. ‚ÄúThe trouble is that with agentic AI's evolution, relying on traditional LLMs trained on human text, audio, video, or print data doesn't work when you need your system to be secure, resilient, and always available.‚Äù&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Designing a data fabric&amp;nbsp;for resilience&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;To address these shortcomings and build digital resilience, technology leaders should pivot to what Hathi describes as a data fabric design, better suited to the demands of agentic AI. This involves weaving together fragmented assets from across security, IT, business operations, and the network to create an integrated architecture that connects disparate data sources, breaks down silos, and enables real-time analysis and risk management.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;&lt;p&gt;‚ÄúOnce you have a single view, you can do all these things that are autonomous and agentic,‚Äù says Hathi. ‚ÄúYou have far fewer blind spots. Decision-making goes much faster. And the unknown is no longer a source of fear because you have a holistic system that's able to absorb these shocks and disruption without losing continuity,‚Äù he adds.&lt;/p&gt;  &lt;p&gt;To create this unified system, data teams must first break down departmental silos in how data is shared, says Hathi. Then, they must implement a federated data architecture‚Äîa decentralized system where autonomous data sources work together as a single unit without physically merging‚Äîto create a unified data source while maintaining governance and security. And finally, teams must upgrade data platforms to ensure this newly unified view is actionable for agentic AI.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;During this transition, teams may face technical limitations if they rely on traditional platforms modeled on structured data‚Äîthat is, mostly quantitative information such as customer records or financial transactions that can be organized in a predefined format (often in tables) that is easy to query. Instead, companies need a platform that can also manage streams of unstructured data such as system logs, security events, and application traces, which lack uniformity and are often qualitative rather than quantitative. Analyzing, organizing, and extracting insights from these kinds of data requires more advanced methods enabled by AI.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Harnessing AI as a collaborator&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;AI itself can be a powerful tool in creating the data fabric that enables AI systems. AI-powered tools can, for example, quickly identify relationships between disparate data‚Äîboth structured and unstructured‚Äîautomatically merging them into one source of truth. They can detect and correct errors and employ NLP to tag and categorize data to make it easier to find and use.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;Agentic AI systems can also be used to augment human capabilities in detecting and deciphering anomalies in an enterprise‚Äôs unstructured data streams. These are often beyond human capacity to spot or interpret at speed, leading to missed threats or delays. But agentic AI systems, designed to perceive, reason, and act autonomously, can plug the gap, delivering higher levels of digital resilience to an enterprise.&lt;/p&gt;  &lt;p&gt;‚ÄúDigital resilience is about more than withstanding disruptions,‚Äù says Hathi. ‚ÄúIt's about evolving and growing over time. AI agents can work with massive amounts of data and continuously learn from humans who provide safety and oversight. This is a true self-optimizing system.‚Äù&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Humans in the loop&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Despite its potential, agentic AI should be positioned as assistive intelligence. Without proper oversight, AI agents could introduce application failures or security risks.&lt;/p&gt;  &lt;p&gt;Clearly defined guardrails and maintaining humans in the loop is ‚Äúkey to trustworthy and practical use of AI,‚Äù Hathi says. ‚ÄúAI can enhance human decision-making, but ultimately, humans are in the driver's seat.‚Äù&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review‚Äôs editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/11/20/1127941/designing-digital-resilience-in-the-agentic-ai-era/</guid><pubDate>Thu, 20 Nov 2025 14:30:00 +0000</pubDate></item><item><title>[NEW] As its voice dictation app takes off, Wispr secures $25M from Notable Capital (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/20/as-its-voice-dectation-app-takes-off-wispr-secures-25m-from-notable-capital/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Voice AI company Wispr‚Äôs dictation app, Wispr Flow, is seeing great traction. The startup said that, after three months of usage, an average user writes more than 50% of their characters through the app. The company has also reached 270 of the Fortune 500 companies and has signed 125 companies as enterprise customers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That‚Äôs why, after just raising a $30 million round led by Menlo Ventures in June, the company has now raised an additional $25 million led by Notable Capital with participation from Steven Bartlett‚Äôs Flight Fund, TechCrunch has learned exclusively. With this influx of capital, the company has raised $81 million in total.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Notable‚Äôs Hans Tung, who has backed companies like Affirm, Airbnb, Slack, Coinbase, Anthropic, and TikTok, is joining Wispr‚Äôs board as an observer. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Wispr‚Äôs CEO Tanay Kothari said that, since June, Wispr Flow has grown 40% month-over-month. Plus, the product has been quite popular within the VC community. And because of that, the company started getting a lot of inbound investor interest. (Granola is another such example of this trend.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWe were still not planning to raise anytime soon because we had a really long runway and the team‚Äôs really lean. But when I heard from Hans and Steven, it made sense to put something together to bring them on,‚Äù Kothari told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kothari added that when Notable‚Äôs team, including investor Chelcie Taylor, presented to him, they had done deep research, interviews with competitors, and had built a strong case about investing in Wispr.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3069490" height="389" src="https://techcrunch.com/wp-content/uploads/2025/11/Wispr-Flow-users.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Wispr&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Kothari said the company is now thinking about international growth and new product opportunities. With the additional funding, the startup would be able to hire top machine learning talent that might otherwise go to a company like OpenAI or Anthropic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The CEO is pleased with user growth and said that the company is at 100x user base year-over-year with 70% retention over 12 months.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, he recalled there was a time when the startup noticed a dip as more non-technical people discovered the app. Those people installed the app, tried out the dictation feature within the app, and then dropped off. The problem was that there was no clear guidance to indicate that they could use the dictation in other apps, too. To address this, the startup created a design flow for new users to guide them to use dictation in the apps they use the most.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-4-3 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Wispr also wants the Flow app to be available on more surfaces apart from Windows, Mac, and iOS. The company is working on an Android app with a beta version slated to be out by year-end, followed by a stable version launch in Q1 2025.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company also wants to invest in building its own voice models to understand users better with personalized Automatic Speech Recognition (ASR). It aims to reduce the number of edits the users have to make after they dictate through Flow. Currently, its error rate is around 10%, lower than 27% for OpenAI‚Äôs Whisper and 47% for Apple‚Äôs native transcription, it claims.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3069491" height="437" src="https://techcrunch.com/wp-content/uploads/2025/11/flow-pui2.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Wispr&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Wispr is not thinking of expanding beyond consumer applications immediately, but it is testing its technology through a closed API with select enterprises and hardware partners and expects to open it up to more developers next year. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Wispr has received more VC attention, there are other apps that are competing with it in the dictation space, including YC-backed Willow and Aqua; Monologue, which is part of&amp;nbsp;Every‚Äôs subscription bundle; as well as Typeless, TalkTastic,&amp;nbsp;Superwhisper,&amp;nbsp;and&amp;nbsp;BetterDictation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Wispr wants to be more than a dictation tool by automating some of the tasks, like replying to emails.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWhat I really like about Wispr is that they are trying to be more than a dictation app and become like a voice-led operating system that can initiate workflow automation. The quality of the people they have recruited and the speed at which they interact have impressed me a lot since we met them,‚Äù Notable‚Äôs Tung told TechCrunch over a call. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He added that, as he has invested in apps with a great interface and user experiences that scale well, he also sees that potential in Wispr Flow.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Voice AI company Wispr‚Äôs dictation app, Wispr Flow, is seeing great traction. The startup said that, after three months of usage, an average user writes more than 50% of their characters through the app. The company has also reached 270 of the Fortune 500 companies and has signed 125 companies as enterprise customers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That‚Äôs why, after just raising a $30 million round led by Menlo Ventures in June, the company has now raised an additional $25 million led by Notable Capital with participation from Steven Bartlett‚Äôs Flight Fund, TechCrunch has learned exclusively. With this influx of capital, the company has raised $81 million in total.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Notable‚Äôs Hans Tung, who has backed companies like Affirm, Airbnb, Slack, Coinbase, Anthropic, and TikTok, is joining Wispr‚Äôs board as an observer. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Wispr‚Äôs CEO Tanay Kothari said that, since June, Wispr Flow has grown 40% month-over-month. Plus, the product has been quite popular within the VC community. And because of that, the company started getting a lot of inbound investor interest. (Granola is another such example of this trend.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWe were still not planning to raise anytime soon because we had a really long runway and the team‚Äôs really lean. But when I heard from Hans and Steven, it made sense to put something together to bring them on,‚Äù Kothari told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kothari added that when Notable‚Äôs team, including investor Chelcie Taylor, presented to him, they had done deep research, interviews with competitors, and had built a strong case about investing in Wispr.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3069490" height="389" src="https://techcrunch.com/wp-content/uploads/2025/11/Wispr-Flow-users.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Wispr&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Kothari said the company is now thinking about international growth and new product opportunities. With the additional funding, the startup would be able to hire top machine learning talent that might otherwise go to a company like OpenAI or Anthropic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The CEO is pleased with user growth and said that the company is at 100x user base year-over-year with 70% retention over 12 months.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, he recalled there was a time when the startup noticed a dip as more non-technical people discovered the app. Those people installed the app, tried out the dictation feature within the app, and then dropped off. The problem was that there was no clear guidance to indicate that they could use the dictation in other apps, too. To address this, the startup created a design flow for new users to guide them to use dictation in the apps they use the most.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-4-3 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Wispr also wants the Flow app to be available on more surfaces apart from Windows, Mac, and iOS. The company is working on an Android app with a beta version slated to be out by year-end, followed by a stable version launch in Q1 2025.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company also wants to invest in building its own voice models to understand users better with personalized Automatic Speech Recognition (ASR). It aims to reduce the number of edits the users have to make after they dictate through Flow. Currently, its error rate is around 10%, lower than 27% for OpenAI‚Äôs Whisper and 47% for Apple‚Äôs native transcription, it claims.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3069491" height="437" src="https://techcrunch.com/wp-content/uploads/2025/11/flow-pui2.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Wispr&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Wispr is not thinking of expanding beyond consumer applications immediately, but it is testing its technology through a closed API with select enterprises and hardware partners and expects to open it up to more developers next year. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Wispr has received more VC attention, there are other apps that are competing with it in the dictation space, including YC-backed Willow and Aqua; Monologue, which is part of&amp;nbsp;Every‚Äôs subscription bundle; as well as Typeless, TalkTastic,&amp;nbsp;Superwhisper,&amp;nbsp;and&amp;nbsp;BetterDictation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Wispr wants to be more than a dictation tool by automating some of the tasks, like replying to emails.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWhat I really like about Wispr is that they are trying to be more than a dictation app and become like a voice-led operating system that can initiate workflow automation. The quality of the people they have recruited and the speed at which they interact have impressed me a lot since we met them,‚Äù Notable‚Äôs Tung told TechCrunch over a call. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He added that, as he has invested in apps with a great interface and user experiences that scale well, he also sees that potential in Wispr Flow.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/20/as-its-voice-dectation-app-takes-off-wispr-secures-25m-from-notable-capital/</guid><pubDate>Thu, 20 Nov 2025 15:00:00 +0000</pubDate></item><item><title>[NEW] Google releases Nano Banana Pro, its latest image-generation model (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/20/google-releases-nano-banana-pro-its-latest-image-generation-model/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is upgrading its image-generation model with new editing chops, higher resolutions, more accurate text rendering, and the ability to search the web.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Dubbed Nano Banana Pro, the new model is built on Google‚Äôs latest large language model, Gemini 3, released earlier this week. The company claims Nano Banana Pro improves on its predecessor, Nano Banana, with the ability to create more detailed images and accurate text, and generate text in different styles, fonts, and languages.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="An image generated by Google's Nano Banana Pro model, which shows an infographic describing how to make elaichi chai." class="wp-image-3069478" height="371" src="https://techcrunch.com/wp-content/uploads/2025/11/GEMINI-Chai-infographic.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The model also has web-searching capabilities, so you can do things like ask it to look up a recipe and generate flash cards.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Google says Nano Banana Pro is geared toward giving professionals more control over images, and lets users control aspects like camera angles, scene lighting, depth of field, focus, and color grading. And compared to Nano Banana‚Äôs resolution cap of 1024 x 1024px, users can generate 2K or 4K images with Nano Banana Pro.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company noted that while Nano Banana Pro can generate images at a higher quality, it is slower and costlier than the original model, which cost $0.039 per 1024px image. Comparatively, the new model costs $0.139 for each 1080p or 2K image, and $0.24 for every 4K image.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3069477" height="383" src="https://techcrunch.com/wp-content/uploads/2025/11/GEMIN-Woman-in-a-field.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The new model can use six high-fidelity shots or blend up to 14 objects within an image. It can also maintain consistency and resemblance of up to five people. The company has released a demo app where you can try some of these capabilities.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nano Banana Pro is being rolled out across many of Google‚Äôs existing AI tools. The Gemini app will now use the new model to generate images by default, though users on the free subscription tier will be able to use the model to generate a limited number of images, after which they will be defaulted to the original Nano Banana model. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Google AI Plus, Pro, and Ultra subscribers will get higher-generation thresholds, though the company did not disclose the exact limits. These subscribers will also get access to the model within NotebookLM.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google is also making the model available in search through AI mode for AI Pro and Ultra subscribers in the U.S. Ultra subscribers can access the model in the company‚Äôs video tool, Flow, and it is available to Workspace customers in Google Slides and Vids, too.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Developers can tap Nano Banana Pro through the Gemini API, Google AI Studio, and the company‚Äôs new IDE, Antigravity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is also baking SynthID, its tech to watermark and detect AI-generated images, into the Gemini app. Users can upload an image, and the chatbot will tell them if the image has been created or modified by the company‚Äôs image models.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Google said that over time, it will include support for C2PA content credential detection for content verification. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;The story has been updated to reflect Google‚Äôs approach to support C2PA&lt;/em&gt;.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is upgrading its image-generation model with new editing chops, higher resolutions, more accurate text rendering, and the ability to search the web.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Dubbed Nano Banana Pro, the new model is built on Google‚Äôs latest large language model, Gemini 3, released earlier this week. The company claims Nano Banana Pro improves on its predecessor, Nano Banana, with the ability to create more detailed images and accurate text, and generate text in different styles, fonts, and languages.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="An image generated by Google's Nano Banana Pro model, which shows an infographic describing how to make elaichi chai." class="wp-image-3069478" height="371" src="https://techcrunch.com/wp-content/uploads/2025/11/GEMINI-Chai-infographic.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The model also has web-searching capabilities, so you can do things like ask it to look up a recipe and generate flash cards.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Google says Nano Banana Pro is geared toward giving professionals more control over images, and lets users control aspects like camera angles, scene lighting, depth of field, focus, and color grading. And compared to Nano Banana‚Äôs resolution cap of 1024 x 1024px, users can generate 2K or 4K images with Nano Banana Pro.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company noted that while Nano Banana Pro can generate images at a higher quality, it is slower and costlier than the original model, which cost $0.039 per 1024px image. Comparatively, the new model costs $0.139 for each 1080p or 2K image, and $0.24 for every 4K image.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3069477" height="383" src="https://techcrunch.com/wp-content/uploads/2025/11/GEMIN-Woman-in-a-field.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The new model can use six high-fidelity shots or blend up to 14 objects within an image. It can also maintain consistency and resemblance of up to five people. The company has released a demo app where you can try some of these capabilities.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nano Banana Pro is being rolled out across many of Google‚Äôs existing AI tools. The Gemini app will now use the new model to generate images by default, though users on the free subscription tier will be able to use the model to generate a limited number of images, after which they will be defaulted to the original Nano Banana model. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Google AI Plus, Pro, and Ultra subscribers will get higher-generation thresholds, though the company did not disclose the exact limits. These subscribers will also get access to the model within NotebookLM.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google is also making the model available in search through AI mode for AI Pro and Ultra subscribers in the U.S. Ultra subscribers can access the model in the company‚Äôs video tool, Flow, and it is available to Workspace customers in Google Slides and Vids, too.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Developers can tap Nano Banana Pro through the Gemini API, Google AI Studio, and the company‚Äôs new IDE, Antigravity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is also baking SynthID, its tech to watermark and detect AI-generated images, into the Gemini app. Users can upload an image, and the chatbot will tell them if the image has been created or modified by the company‚Äôs image models.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Google said that over time, it will include support for C2PA content credential detection for content verification. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;The story has been updated to reflect Google‚Äôs approach to support C2PA&lt;/em&gt;.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/20/google-releases-nano-banana-pro-its-latest-image-generation-model/</guid><pubDate>Thu, 20 Nov 2025 15:00:00 +0000</pubDate></item><item><title>[NEW] India‚Äôs TCS gets TPG to fund half of $2B AI data center project (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/20/indias-tcs-gets-tpg-to-fund-half-of-2b-ai-data-center-project/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/tcs-tpg-deal.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Indian IT giant Tata Consultancy Services (TCS) has secured $1 billion from private equity firm TPG as part of a multi-year, $2 billion project to build a network of gigawatt-scale data centers in the country.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The project, dubbed ‚ÄúHyperVault,‚Äù comes as demand for AI compute is rising faster than companies can build the power-hungry infrastructure needed to support it.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The demand-supply gap for AI compute in India is particularly stark: The country generates nearly 20% of the world‚Äôs data, but accounts for only about 3% of global data center capacity. Big tech companies and cloud providers have been investing billions of dollars to expand local capacity and tap the country‚Äôs growing adoption of AI products.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With HyperVault, TCS and TPG plan to develop liquid-cooled, high-density data centers with the power and network capacity required to support advanced AI workloads across major cloud regions, the companies said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Liquid cooling and high-density rack designs are growing common as the GPUs needed to power AI inference and training use significantly more power and generate more heat than conventional CPU servers. But such designs also raise questions about resource use in countries like India, where water scarcity is already a concern. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In urban hubs such as Mumbai, Bengaluru, and Chennai, where much of India‚Äôs data-center capacity is concentrated, existing water stress could complicate operations. S&amp;amp;P Global, citing Uptime Institute estimates, noted that a 1 MW data center load can require up to 25.5 million liters of water a year for cooling, adding pressure to already strained infrastructure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The rapid building of AI data centers stands to further stress India‚Äôs power and land use, two other bottlenecks identified by industry analysts. High-density AI clusters require reliable electricity supply and large parcels of industrial land, two requirements increasingly difficult to secure in major urban regions.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Nonetheless, global tech companies are treating India as their frontier for building AI infrastructure. Local and global technology firms have announced investments of more than $32 billion over the last two years to expand data center infrastructure in the country, according to S&amp;amp;P Global.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In January, Microsoft said it would invest $3 billion over two years in India‚Äôs cloud and AI infrastructure, and in  October, Google said it would spend $15 billion over five years to build a gigawatt-scale AI data center hub in the southern state of Andhra Pradesh. And back in 2023, Amazon committed $12.7 billion to build AWS cloud infrastructure in India through 2030.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TCS said it would work with hyperscalers and AI companies to design, deploy, and operate AI infrastructure as the platform expands. The company plans to build around 1.2 gigawatts of capacity in its initial phase.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;More than 95% of India‚Äôs new data-center capacity over the next five years will come from leased facilities, and the remainder will be driven by hyperscalers building dedicated AI infrastructure, S&amp;amp;P Global estimates. Local players like Reliance Industries and CtrlS are also expanding their data-center capacity to meet rising demand.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TCS and TPG project that India‚Äôs total data-center capacity could exceed 10 gigawatts by 2030, up from roughly 1.5 gigawatts today.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/tcs-tpg-deal.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Indian IT giant Tata Consultancy Services (TCS) has secured $1 billion from private equity firm TPG as part of a multi-year, $2 billion project to build a network of gigawatt-scale data centers in the country.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The project, dubbed ‚ÄúHyperVault,‚Äù comes as demand for AI compute is rising faster than companies can build the power-hungry infrastructure needed to support it.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The demand-supply gap for AI compute in India is particularly stark: The country generates nearly 20% of the world‚Äôs data, but accounts for only about 3% of global data center capacity. Big tech companies and cloud providers have been investing billions of dollars to expand local capacity and tap the country‚Äôs growing adoption of AI products.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With HyperVault, TCS and TPG plan to develop liquid-cooled, high-density data centers with the power and network capacity required to support advanced AI workloads across major cloud regions, the companies said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Liquid cooling and high-density rack designs are growing common as the GPUs needed to power AI inference and training use significantly more power and generate more heat than conventional CPU servers. But such designs also raise questions about resource use in countries like India, where water scarcity is already a concern. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In urban hubs such as Mumbai, Bengaluru, and Chennai, where much of India‚Äôs data-center capacity is concentrated, existing water stress could complicate operations. S&amp;amp;P Global, citing Uptime Institute estimates, noted that a 1 MW data center load can require up to 25.5 million liters of water a year for cooling, adding pressure to already strained infrastructure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The rapid building of AI data centers stands to further stress India‚Äôs power and land use, two other bottlenecks identified by industry analysts. High-density AI clusters require reliable electricity supply and large parcels of industrial land, two requirements increasingly difficult to secure in major urban regions.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Nonetheless, global tech companies are treating India as their frontier for building AI infrastructure. Local and global technology firms have announced investments of more than $32 billion over the last two years to expand data center infrastructure in the country, according to S&amp;amp;P Global.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In January, Microsoft said it would invest $3 billion over two years in India‚Äôs cloud and AI infrastructure, and in  October, Google said it would spend $15 billion over five years to build a gigawatt-scale AI data center hub in the southern state of Andhra Pradesh. And back in 2023, Amazon committed $12.7 billion to build AWS cloud infrastructure in India through 2030.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TCS said it would work with hyperscalers and AI companies to design, deploy, and operate AI infrastructure as the platform expands. The company plans to build around 1.2 gigawatts of capacity in its initial phase.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;More than 95% of India‚Äôs new data-center capacity over the next five years will come from leased facilities, and the remainder will be driven by hyperscalers building dedicated AI infrastructure, S&amp;amp;P Global estimates. Local players like Reliance Industries and CtrlS are also expanding their data-center capacity to meet rising demand.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TCS and TPG project that India‚Äôs total data-center capacity could exceed 10 gigawatts by 2030, up from roughly 1.5 gigawatts today.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/20/indias-tcs-gets-tpg-to-fund-half-of-2b-ai-data-center-project/</guid><pubDate>Thu, 20 Nov 2025 15:34:45 +0000</pubDate></item><item><title>[NEW] Into the Omniverse: How Smart City AI Agents Transform Urban Operations (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/smart-city-ai-agents-urban-operations/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/ito-smart-cities-featured.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;&lt;i&gt;Editor‚Äôs note: This post is part of &lt;/i&gt;&lt;i&gt;Into the Omniverse&lt;/i&gt;&lt;i&gt;, a series focused on how developers, 3D practitioners and enterprises can transform their workflows using the latest advancements in &lt;/i&gt;&lt;i&gt;OpenUSD&lt;/i&gt;&lt;i&gt; and &lt;/i&gt;&lt;i&gt;NVIDIA Omniverse&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;Cities worldwide face unprecedented challenges as urban populations surge and infrastructure strains to keep pace.&lt;/p&gt;
&lt;p&gt;Operational challenges like traffic congestion and coordinating emergency services are compounded by fragmented data pipelines, siloed local government processes and disparate systems. Technical barriers prevent cities from accessing the comprehensive, real-time insights needed for effective decision-making and city management.&lt;/p&gt;
&lt;p&gt;Leading cities and technology partners are deploying the NVIDIA Blueprint for smart city AI, a reference application that provides the complete software stack to build, test and operate AI agents in simulation-ready (SimReady) digital twins.&lt;/p&gt;
&lt;p&gt;OpenUSD is an open and extensible framework that connects to each stage of this physical AI workflow. OpenUSD-enabled digital twins serve as SimReady environments where cities can simulate ‚Äúwhat if‚Äù scenarios and generate physically accurate sensor data.&lt;/p&gt;
&lt;p&gt;The blueprint powers a three-stage workflow: 1) simulate with the NVIDIA Cosmos platform and NVIDIA Omniverse libraries to generate synthetic data, 2) train and fine-tune vision AI models, and 3) deploy real-time video analytics AI agents with the NVIDIA Metropolis platform and the NVIDIA Blueprint for video search and summarization (VSS). This enables cities to move from reactive to proactive operations.‚Äã&lt;/p&gt;
&lt;p&gt;Based on these simulations, cities can deploy operational platforms where weather data, traffic sensors and emergency response systems converge, supporting rapid testing of rare scenarios, real-time monitoring, city infrastructure planning and optimization of urban systems.&lt;/p&gt;
&lt;p&gt;From Kaohsiung City, Taiwan, cutting incident response times by 80% with street-level AI to Raleigh, North Carolina, achieving 95% vehicle detection accuracy and French rail networks optimizing energy consumption by 20%, cities across the globe are using digital twins and AI agents to transform urban operations at scale.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Smart Cities in Action&lt;/strong&gt;&lt;/h2&gt;
&lt;h4&gt;&lt;b&gt;Akila, With SNCF Gares&amp;amp;Connexions, Uses Digital Twins to Improve Rail Operations&lt;/b&gt;&lt;/h4&gt;
&lt;p&gt;Akila‚Äôs digital twin application helps French rail operator SNCF Gares&amp;amp;Connexions optimize its network of nearly 14,000 daily trains with live scenario planning for solar heating, air flow and crowd movement. The OpenUSD-enabled digital twins deliver a 20% reduction in energy consumption, 100% on-time preventive maintenance and a 50% reduction in downtime and response times.&lt;/p&gt;
&lt;h4&gt;&lt;b&gt;Linker Vision Taps Physical AI for Street-Level Intelligence&lt;/b&gt;&lt;/h4&gt;
&lt;p&gt;Linker Vision‚Äôs physical AI system recognizes infrastructure events in Kaohsiung City, including damaged streetlights and fallen trees, eliminating manual city inspections and enabling faster emergency response. To scale its street-level intelligence to more cities, Linker Vision uses Omniverse libraries for simulation, Cosmos Reason for world understanding and the VSS blueprint for deployment powered by OpenUSD.&lt;/p&gt;
&lt;h4&gt;&lt;b&gt;Esri and Microsoft Enable Comprehensive Urban Intelligence in the City of Raleigh&lt;/b&gt;&lt;/h4&gt;
&lt;p&gt;The City of Raleigh achieved 95% vehicle detection accuracy using the NVIDIA DeepStream software development kit, boosting traffic analysis workflows for engineers. This data enhances Raleigh‚Äôs digital twin, enabled by Esri‚Äôs ArcGIS geospatial platform to support visualization and analysis for critical infrastructure planning and management. Integrating this computer vision pipeline with a vision AI agent powered by the NVIDIA VSS blueprint provides comprehensive real-time visibility and insights in ArcGIS on Azure Cloud.&lt;/p&gt;
&lt;h4&gt;Milestone Systems‚Äô VLM Automates Video Review&lt;/h4&gt;
&lt;p&gt;Milestone Systems is soon launching its Hafnia VLM, which will include a VLM plug-in for its video management software XProtect as well as a VLM-as-a-service. Fine-tuned on more than 75,000 hours of video data, the Hafnia VLM can reduce operator alarm fatigue by up to 30% by automating video review and filtering out false alarms. It was developed with NVIDIA Cosmos Reason VLMs and Metropolis.&amp;nbsp;The Hafnia VLM plug-in for XProtect will make generative AI more easily accessible for XProtect operators and users.&lt;/p&gt;
&lt;h4&gt;&lt;b&gt;K2K Analyzes Italy Video Streams&lt;/b&gt;&lt;/h4&gt;
&lt;p&gt;K2K‚Äôs platform uses NVIDIA Cosmos Reason and the VSS blueprint to analyze over 1,000 video streams in Palermo, Italy, processing 7 billion events annually and automatically notifying city officials through natural language queries and video events when critical conditions are extracted and analyzed.&lt;/p&gt;
&lt;p&gt;Learn more about how cities are transforming with simulation, vision AI and digital twins by watching this on-demand NVIDIA GTC session, ‚ÄúLeadership Strategies to Transform Public Services.‚Äù&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Get Started With Smart City AI&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Learn more about OpenUSD and computer vision workflows through these resources:&lt;/p&gt;

&lt;p&gt;&lt;i&gt;Stay up to date by subscribing to&lt;/i&gt; &lt;i&gt;NVIDIA Omniverse news&lt;/i&gt;&lt;i&gt;, joining the Omniverse &lt;/i&gt;&lt;i&gt;community&lt;/i&gt;&lt;i&gt; and following Omniverse on&lt;/i&gt; &lt;i&gt;Discord&lt;/i&gt;&lt;i&gt;,&lt;/i&gt; &lt;i&gt;Instagram&lt;/i&gt;&lt;i&gt;, &lt;/i&gt;&lt;i&gt;LinkedIn&lt;/i&gt;&lt;i&gt;, &lt;/i&gt;&lt;i&gt;Threads&lt;/i&gt;&lt;i&gt;,&lt;/i&gt; &lt;i&gt;X&lt;/i&gt;&lt;i&gt; and&lt;/i&gt; &lt;i&gt;YouTube&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/ito-smart-cities-featured.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;&lt;i&gt;Editor‚Äôs note: This post is part of &lt;/i&gt;&lt;i&gt;Into the Omniverse&lt;/i&gt;&lt;i&gt;, a series focused on how developers, 3D practitioners and enterprises can transform their workflows using the latest advancements in &lt;/i&gt;&lt;i&gt;OpenUSD&lt;/i&gt;&lt;i&gt; and &lt;/i&gt;&lt;i&gt;NVIDIA Omniverse&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;Cities worldwide face unprecedented challenges as urban populations surge and infrastructure strains to keep pace.&lt;/p&gt;
&lt;p&gt;Operational challenges like traffic congestion and coordinating emergency services are compounded by fragmented data pipelines, siloed local government processes and disparate systems. Technical barriers prevent cities from accessing the comprehensive, real-time insights needed for effective decision-making and city management.&lt;/p&gt;
&lt;p&gt;Leading cities and technology partners are deploying the NVIDIA Blueprint for smart city AI, a reference application that provides the complete software stack to build, test and operate AI agents in simulation-ready (SimReady) digital twins.&lt;/p&gt;
&lt;p&gt;OpenUSD is an open and extensible framework that connects to each stage of this physical AI workflow. OpenUSD-enabled digital twins serve as SimReady environments where cities can simulate ‚Äúwhat if‚Äù scenarios and generate physically accurate sensor data.&lt;/p&gt;
&lt;p&gt;The blueprint powers a three-stage workflow: 1) simulate with the NVIDIA Cosmos platform and NVIDIA Omniverse libraries to generate synthetic data, 2) train and fine-tune vision AI models, and 3) deploy real-time video analytics AI agents with the NVIDIA Metropolis platform and the NVIDIA Blueprint for video search and summarization (VSS). This enables cities to move from reactive to proactive operations.‚Äã&lt;/p&gt;
&lt;p&gt;Based on these simulations, cities can deploy operational platforms where weather data, traffic sensors and emergency response systems converge, supporting rapid testing of rare scenarios, real-time monitoring, city infrastructure planning and optimization of urban systems.&lt;/p&gt;
&lt;p&gt;From Kaohsiung City, Taiwan, cutting incident response times by 80% with street-level AI to Raleigh, North Carolina, achieving 95% vehicle detection accuracy and French rail networks optimizing energy consumption by 20%, cities across the globe are using digital twins and AI agents to transform urban operations at scale.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Smart Cities in Action&lt;/strong&gt;&lt;/h2&gt;
&lt;h4&gt;&lt;b&gt;Akila, With SNCF Gares&amp;amp;Connexions, Uses Digital Twins to Improve Rail Operations&lt;/b&gt;&lt;/h4&gt;
&lt;p&gt;Akila‚Äôs digital twin application helps French rail operator SNCF Gares&amp;amp;Connexions optimize its network of nearly 14,000 daily trains with live scenario planning for solar heating, air flow and crowd movement. The OpenUSD-enabled digital twins deliver a 20% reduction in energy consumption, 100% on-time preventive maintenance and a 50% reduction in downtime and response times.&lt;/p&gt;
&lt;h4&gt;&lt;b&gt;Linker Vision Taps Physical AI for Street-Level Intelligence&lt;/b&gt;&lt;/h4&gt;
&lt;p&gt;Linker Vision‚Äôs physical AI system recognizes infrastructure events in Kaohsiung City, including damaged streetlights and fallen trees, eliminating manual city inspections and enabling faster emergency response. To scale its street-level intelligence to more cities, Linker Vision uses Omniverse libraries for simulation, Cosmos Reason for world understanding and the VSS blueprint for deployment powered by OpenUSD.&lt;/p&gt;
&lt;h4&gt;&lt;b&gt;Esri and Microsoft Enable Comprehensive Urban Intelligence in the City of Raleigh&lt;/b&gt;&lt;/h4&gt;
&lt;p&gt;The City of Raleigh achieved 95% vehicle detection accuracy using the NVIDIA DeepStream software development kit, boosting traffic analysis workflows for engineers. This data enhances Raleigh‚Äôs digital twin, enabled by Esri‚Äôs ArcGIS geospatial platform to support visualization and analysis for critical infrastructure planning and management. Integrating this computer vision pipeline with a vision AI agent powered by the NVIDIA VSS blueprint provides comprehensive real-time visibility and insights in ArcGIS on Azure Cloud.&lt;/p&gt;
&lt;h4&gt;Milestone Systems‚Äô VLM Automates Video Review&lt;/h4&gt;
&lt;p&gt;Milestone Systems is soon launching its Hafnia VLM, which will include a VLM plug-in for its video management software XProtect as well as a VLM-as-a-service. Fine-tuned on more than 75,000 hours of video data, the Hafnia VLM can reduce operator alarm fatigue by up to 30% by automating video review and filtering out false alarms. It was developed with NVIDIA Cosmos Reason VLMs and Metropolis.&amp;nbsp;The Hafnia VLM plug-in for XProtect will make generative AI more easily accessible for XProtect operators and users.&lt;/p&gt;
&lt;h4&gt;&lt;b&gt;K2K Analyzes Italy Video Streams&lt;/b&gt;&lt;/h4&gt;
&lt;p&gt;K2K‚Äôs platform uses NVIDIA Cosmos Reason and the VSS blueprint to analyze over 1,000 video streams in Palermo, Italy, processing 7 billion events annually and automatically notifying city officials through natural language queries and video events when critical conditions are extracted and analyzed.&lt;/p&gt;
&lt;p&gt;Learn more about how cities are transforming with simulation, vision AI and digital twins by watching this on-demand NVIDIA GTC session, ‚ÄúLeadership Strategies to Transform Public Services.‚Äù&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Get Started With Smart City AI&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Learn more about OpenUSD and computer vision workflows through these resources:&lt;/p&gt;

&lt;p&gt;&lt;i&gt;Stay up to date by subscribing to&lt;/i&gt; &lt;i&gt;NVIDIA Omniverse news&lt;/i&gt;&lt;i&gt;, joining the Omniverse &lt;/i&gt;&lt;i&gt;community&lt;/i&gt;&lt;i&gt; and following Omniverse on&lt;/i&gt; &lt;i&gt;Discord&lt;/i&gt;&lt;i&gt;,&lt;/i&gt; &lt;i&gt;Instagram&lt;/i&gt;&lt;i&gt;, &lt;/i&gt;&lt;i&gt;LinkedIn&lt;/i&gt;&lt;i&gt;, &lt;/i&gt;&lt;i&gt;Threads&lt;/i&gt;&lt;i&gt;,&lt;/i&gt; &lt;i&gt;X&lt;/i&gt;&lt;i&gt; and&lt;/i&gt; &lt;i&gt;YouTube&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/smart-city-ai-agents-urban-operations/</guid><pubDate>Thu, 20 Nov 2025 16:00:39 +0000</pubDate></item><item><title>[NEW] The best guide to spotting AI writing comes from Wikipedia (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/20/the-best-guide-to-spotting-ai-writing-comes-from-wikipedia/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2195019925.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;We‚Äôve all felt the creeping suspicion that something we‚Äôre reading was written by a large language model ‚Äî but it‚Äôs remarkably difficult to pin down. For a few months last year, everyone became convinced that specific words like ‚Äúdelve‚Äù or ‚Äúunderscore‚Äù could give models away, but the evidence is thin, and as models have grown more sophisticated, the telltale words have become harder to trace.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But as it turns out, the folks at Wikipedia have gotten pretty good at flagging AI-written prose ‚Äî and the group‚Äôs public guide to ‚ÄúSigns of AI writing‚Äù is the best resource I‚Äôve found for nailing down whether your suspicions are warranted. (Credit to the poet Jameson Fitzpatrick, who pointed out the document on X.)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Since 2023, Wikipedia editors have been working to get a handle on AI submissions, a project they call Project AI Cleanup. With millions of edits coming in each day, there‚Äôs plenty of material to draw on, and in classic Wikipedia-editor style, the group has produced a field guide that‚Äôs both detailed and heavy on evidence.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To start with, the guide confirms what we already know: automated tools are basically useless. Instead, the guide focuses on habits and turns of phrase that are rare on Wikipedia but common on the internet at large (and thus, common in the model‚Äôs training data). According to the guide, AI submissions will spend a lot of time emphasizing why a subject is important, usually in generic terms like ‚Äúa pivotal moment‚Äù or ‚Äúa broader movement.‚Äù AI models will also spend a lot of time detailing minor media spots to make the subject seem notable ‚Äî the kind of thing you‚Äôd expect from a personal bio, but not from an independent source.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The guide flags a particularly interesting quirk around tailing clauses with hazy claims of importance. Models will say some event or detail is ‚Äúemphasizing the significance‚Äù of something or other, or ‚Äúreflecting the continued relevance‚Äù of some general idea. (Grammar nerds will know this as the ‚Äúpresent participle.‚Äù) It‚Äôs a bit hard to pin down, but once you can recognize it, you‚Äôll see it everywhere.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There‚Äôs also a tendency toward vague marketing language, which is extremely common on the internet. Landscapes are always scenic, views are always breathtaking, and everything is clean and modern. As the editors put it, ‚Äúit sounds more like the transcript of a TV commercial.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The guide is worth reading in full, but I came away very impressed. Before this, I would have said that LLM prose was developing too fast to pin down. But the habits flagged here are deeply embedded in the way AI models are trained and deployed. They can be disguised, but it will be hard to do away with them completely. And if the general public gets more savvy about identifying AI prose, it could have all sorts of interesting consequences.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2195019925.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;We‚Äôve all felt the creeping suspicion that something we‚Äôre reading was written by a large language model ‚Äî but it‚Äôs remarkably difficult to pin down. For a few months last year, everyone became convinced that specific words like ‚Äúdelve‚Äù or ‚Äúunderscore‚Äù could give models away, but the evidence is thin, and as models have grown more sophisticated, the telltale words have become harder to trace.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But as it turns out, the folks at Wikipedia have gotten pretty good at flagging AI-written prose ‚Äî and the group‚Äôs public guide to ‚ÄúSigns of AI writing‚Äù is the best resource I‚Äôve found for nailing down whether your suspicions are warranted. (Credit to the poet Jameson Fitzpatrick, who pointed out the document on X.)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Since 2023, Wikipedia editors have been working to get a handle on AI submissions, a project they call Project AI Cleanup. With millions of edits coming in each day, there‚Äôs plenty of material to draw on, and in classic Wikipedia-editor style, the group has produced a field guide that‚Äôs both detailed and heavy on evidence.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To start with, the guide confirms what we already know: automated tools are basically useless. Instead, the guide focuses on habits and turns of phrase that are rare on Wikipedia but common on the internet at large (and thus, common in the model‚Äôs training data). According to the guide, AI submissions will spend a lot of time emphasizing why a subject is important, usually in generic terms like ‚Äúa pivotal moment‚Äù or ‚Äúa broader movement.‚Äù AI models will also spend a lot of time detailing minor media spots to make the subject seem notable ‚Äî the kind of thing you‚Äôd expect from a personal bio, but not from an independent source.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The guide flags a particularly interesting quirk around tailing clauses with hazy claims of importance. Models will say some event or detail is ‚Äúemphasizing the significance‚Äù of something or other, or ‚Äúreflecting the continued relevance‚Äù of some general idea. (Grammar nerds will know this as the ‚Äúpresent participle.‚Äù) It‚Äôs a bit hard to pin down, but once you can recognize it, you‚Äôll see it everywhere.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There‚Äôs also a tendency toward vague marketing language, which is extremely common on the internet. Landscapes are always scenic, views are always breathtaking, and everything is clean and modern. As the editors put it, ‚Äúit sounds more like the transcript of a TV commercial.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The guide is worth reading in full, but I came away very impressed. Before this, I would have said that LLM prose was developing too fast to pin down. But the habits flagged here are deeply embedded in the way AI models are trained and deployed. They can be disguised, but it will be hard to do away with them completely. And if the general public gets more savvy about identifying AI prose, it could have all sorts of interesting consequences.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/20/the-best-guide-to-spotting-ai-writing-comes-from-wikipedia/</guid><pubDate>Thu, 20 Nov 2025 16:32:55 +0000</pubDate></item><item><title>[NEW] Google‚Äôs new Nano Banana Pro uses Gemini 3 power to generate more realistic AI images (AI ‚Äì Ars Technica)</title><link>https://arstechnica.com/google/2025/11/google-launches-nano-banana-pro-image-model-adds-ai-image-detection-in-gemini-app/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google‚Äôs new image-generator model is available to try globally today.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="nano banana pro" class="absolute inset-0 w-full h-full object-cover hidden" height="361" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/nano-banana-pro-640x361.png" width="640" /&gt;
                  &lt;img alt="nano banana pro" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/nano-banana-pro-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Google‚Äôs meme-friendly Nano Banana image-generation model is getting an upgrade. The new Nano Banana Pro is rolling out with improved reasoning and instruction following, giving users the ability to create more accurate images with legible text and make precise edits to existing images. It‚Äôs available to everyone in the Gemini app, but free users will find themselves up against the usage limits pretty quickly.&lt;/p&gt;
&lt;p&gt;Nano Banana Pro is part of the newly launched Gemini 3 Pro‚Äîit‚Äôs actually called Gemini 3 Pro Image in the same way the original is Gemini 2.5 Flash Image, but Google is sticking with the meme-y name. You can access it by selecting Gemini 3 Pro and then turning on the ‚ÄúCreate images‚Äù option.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Nano Banana Pro: Your new creative partner.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;Google says the new model can follow complex prompts to create more accurate images. The model is apparently so capable it can generate an entire usable infographic in a single shot with no weird AI squiggles in place of words. Nano Banana Pro is also better at maintaining consistency in images. You can blend up to 14 images with this tool, and it can maintain the appearance of up to five people in outputs.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2128608 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="GEMINI Woodchuck words" class="fullwidth full" height="768" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GEMINI-Woodchuck.png" width="1408" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Prompt: Create an image showing the phrase ‚ÄúHow much wood would a woodchuck chuck if a woodchuck could chuck wood‚Äù made out of wood chucked by a woodchuck.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Google also promises better editing. You can refine your AI images or provide Nano Banana Pro with a photo and make localized edits without as many AI glitches. It can even change core elements of the image like camera angles, color grading, and lighting without altering other elements. Google is pushing the professional use angle with its new model, which has much improved resolution options. Your creations in Nano Banana Pro can be rendered at up to 4K.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Detecting less sloppy slop&lt;/h2&gt;
&lt;p&gt;Google is not just blowing smoke‚Äîthe new image generator is much better. Its grasp of the world and the nuance of language is apparent, producing much more realistic results. Even before this, AI images were getting so good that it could be hard to spot them at a glance. Gone are the days when you could just count fingers to identify AI. Google is making an effort to help identify AI content, though.&lt;/p&gt;
&lt;p&gt;Images generated with Nano Banana Pro continue to have embedded SynthID watermarks that Google‚Äôs tools can detect. The company is also adding more C2PA metadata to further label AI images. The Gemini app is part of this effort, too. Starting now, you can upload an image and ask something like ‚ÄúIs this AI?‚Äù The app won‚Äôt detect just any old AI image, but it will tell you if it‚Äôs a product of Google AI by checking for SynthID.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1416" id="video-2128605-1" preload="metadata" width="2000"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/SynthID-verification-in-the-Gemini-app.mp4?_=1" type="video/mp4" /&gt;Gemini can now detect its own AI images.&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Gemini can now detect its own AI images.

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;At the same time, Google is making it slightly harder for flesh and blood humans to know an image was generated with AI. Operating with the knowledge that professionals may want to generate images with Nano Banana Pro, Google has removed the visible watermark from images for AI Ultra subscribers. These images still have SynthID, but only the lower tiers have the Gemini twinkle in the corner.&lt;/p&gt;
&lt;p&gt;While everyone can access the new Nano Banana Pro today, AI Ultra subscribers will enjoy the highest usage limits. Gemini Pro users will get a bit less access, and free users will get the lowest limits before being booted down to the non-pro version.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google‚Äôs new image-generator model is available to try globally today.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="nano banana pro" class="absolute inset-0 w-full h-full object-cover hidden" height="361" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/nano-banana-pro-640x361.png" width="640" /&gt;
                  &lt;img alt="nano banana pro" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/nano-banana-pro-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Google‚Äôs meme-friendly Nano Banana image-generation model is getting an upgrade. The new Nano Banana Pro is rolling out with improved reasoning and instruction following, giving users the ability to create more accurate images with legible text and make precise edits to existing images. It‚Äôs available to everyone in the Gemini app, but free users will find themselves up against the usage limits pretty quickly.&lt;/p&gt;
&lt;p&gt;Nano Banana Pro is part of the newly launched Gemini 3 Pro‚Äîit‚Äôs actually called Gemini 3 Pro Image in the same way the original is Gemini 2.5 Flash Image, but Google is sticking with the meme-y name. You can access it by selecting Gemini 3 Pro and then turning on the ‚ÄúCreate images‚Äù option.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Nano Banana Pro: Your new creative partner.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;Google says the new model can follow complex prompts to create more accurate images. The model is apparently so capable it can generate an entire usable infographic in a single shot with no weird AI squiggles in place of words. Nano Banana Pro is also better at maintaining consistency in images. You can blend up to 14 images with this tool, and it can maintain the appearance of up to five people in outputs.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2128608 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="GEMINI Woodchuck words" class="fullwidth full" height="768" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GEMINI-Woodchuck.png" width="1408" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Prompt: Create an image showing the phrase ‚ÄúHow much wood would a woodchuck chuck if a woodchuck could chuck wood‚Äù made out of wood chucked by a woodchuck.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Google also promises better editing. You can refine your AI images or provide Nano Banana Pro with a photo and make localized edits without as many AI glitches. It can even change core elements of the image like camera angles, color grading, and lighting without altering other elements. Google is pushing the professional use angle with its new model, which has much improved resolution options. Your creations in Nano Banana Pro can be rendered at up to 4K.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Detecting less sloppy slop&lt;/h2&gt;
&lt;p&gt;Google is not just blowing smoke‚Äîthe new image generator is much better. Its grasp of the world and the nuance of language is apparent, producing much more realistic results. Even before this, AI images were getting so good that it could be hard to spot them at a glance. Gone are the days when you could just count fingers to identify AI. Google is making an effort to help identify AI content, though.&lt;/p&gt;
&lt;p&gt;Images generated with Nano Banana Pro continue to have embedded SynthID watermarks that Google‚Äôs tools can detect. The company is also adding more C2PA metadata to further label AI images. The Gemini app is part of this effort, too. Starting now, you can upload an image and ask something like ‚ÄúIs this AI?‚Äù The app won‚Äôt detect just any old AI image, but it will tell you if it‚Äôs a product of Google AI by checking for SynthID.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1416" id="video-2128605-1" preload="metadata" width="2000"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/SynthID-verification-in-the-Gemini-app.mp4?_=1" type="video/mp4" /&gt;Gemini can now detect its own AI images.&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Gemini can now detect its own AI images.

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;At the same time, Google is making it slightly harder for flesh and blood humans to know an image was generated with AI. Operating with the knowledge that professionals may want to generate images with Nano Banana Pro, Google has removed the visible watermark from images for AI Ultra subscribers. These images still have SynthID, but only the lower tiers have the Gemini twinkle in the corner.&lt;/p&gt;
&lt;p&gt;While everyone can access the new Nano Banana Pro today, AI Ultra subscribers will enjoy the highest usage limits. Gemini Pro users will get a bit less access, and free users will get the lowest limits before being booted down to the non-pro version.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/google/2025/11/google-launches-nano-banana-pro-image-model-adds-ai-image-detection-in-gemini-app/</guid><pubDate>Thu, 20 Nov 2025 16:33:25 +0000</pubDate></item><item><title>[NEW] Gemini starts rolling out to Android Auto globally (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/20/gemini-starts-rolling-out-to-android-auto-globally/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Gemini will replace Google Assistant in Android Auto, the smartphone projection technology integrated into millions of cars, trucks, and SUVs. Google announced the move Thursday, noting that Gemini will start to roll out to Android Auto users who have upgraded from Google Assistant to Gemini on their phone.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;By bringing Gemini to Android Auto, Google is making it possible for users to speak naturally and have a back-and-forth conversation to complete more complex tasks on the go, according to the company. Android Auto is an app that runs on a user‚Äôs phone and wirelessly communicates and projects features like navigation, music, and messaging from an Android-based smartphone to the car‚Äôs display.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The rollout doesn‚Äôt come as a surprise, as the change is part of Google‚Äôs plans to replace Google Assistant with Gemini across all of its devices and platforms. The company announced in May that Gemini would be coming to Android Auto this year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With Gemini, users can ask questions about businesses along their route to find something specific. For example, users could ask something like: ‚ÄúHey, Google, I need your help. I‚Äôm suddenly craving barbecue. Any good spots along my route that are open now, near my destination?‚Äù If a spot looks interesting, Gemini can offer more information about the place, such as details about the restaurant‚Äôs most popular dish or whether the establishment is dog-friendly.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3069560" height="293" src="https://techcrunch.com/wp-content/uploads/2025/11/Screenshot-2025-11-20-at-10.25.51-AM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Users can also reply to messages with Gemini and get summaries of texts. For instance, you can ask Gemini to let your friend know that you‚Äôre stuck in traffic and to add your ETA to the message. Or, you can ask Gemini to translate a message into a different language before sending it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gemini also lets users access their emails in Gmail while driving. For example, a user could ask something like: ‚ÄúI have a hotel booked for tonight. I think the address is in my email. Can you check and navigate there?‚Äù Gemini can also give you a summary of your unread emails.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google notes that Gemini can help people get the right soundtrack for a drive by asking it to create a playlist with specific instructions such as, ‚ÄúCan you give me a road trip playlist? Ideally something upbeat, about 3 hours long, that‚Äôs good for both me and the kids.‚Äù This works with streaming services like YouTube Music, Spotify, and more.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3069559" height="286" src="https://techcrunch.com/wp-content/uploads/2025/11/Screenshot-2025-11-20-at-10.24.13-AM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Additionally, Google says users will be able to go Live with Gemini to chat about anything by saying, ‚ÄúHey, Google, let‚Äôs chat.‚Äù From there, you can brainstorm ideas or learn something new.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For example, you could say, ‚ÄúAll right, I‚Äôm driving to St. Louis for a wedding. Can you be my tour guide and share some fun facts about it?‚Äù And then follow up with further instructions: ‚ÄúThanks for teaching me all about St. Louis. Changing topics, the rehearsal dinner is at his parents house, and I‚Äôd like to get them a small something. What are some good ideas?‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gemini begins rolling out on Android Auto globally starting Thursday in 45 languages.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;To access it, you need to make sure you‚Äôre using the Gemini app on your phone. You‚Äôll see a tooltip on your car display once it‚Äôs available for you. To use it, you need to say, ‚ÄúHey, Google‚Äù and then press the mic button on your car screen or long press the voice control button on your steering wheel.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Gemini will replace Google Assistant in Android Auto, the smartphone projection technology integrated into millions of cars, trucks, and SUVs. Google announced the move Thursday, noting that Gemini will start to roll out to Android Auto users who have upgraded from Google Assistant to Gemini on their phone.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;By bringing Gemini to Android Auto, Google is making it possible for users to speak naturally and have a back-and-forth conversation to complete more complex tasks on the go, according to the company. Android Auto is an app that runs on a user‚Äôs phone and wirelessly communicates and projects features like navigation, music, and messaging from an Android-based smartphone to the car‚Äôs display.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The rollout doesn‚Äôt come as a surprise, as the change is part of Google‚Äôs plans to replace Google Assistant with Gemini across all of its devices and platforms. The company announced in May that Gemini would be coming to Android Auto this year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With Gemini, users can ask questions about businesses along their route to find something specific. For example, users could ask something like: ‚ÄúHey, Google, I need your help. I‚Äôm suddenly craving barbecue. Any good spots along my route that are open now, near my destination?‚Äù If a spot looks interesting, Gemini can offer more information about the place, such as details about the restaurant‚Äôs most popular dish or whether the establishment is dog-friendly.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3069560" height="293" src="https://techcrunch.com/wp-content/uploads/2025/11/Screenshot-2025-11-20-at-10.25.51-AM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Users can also reply to messages with Gemini and get summaries of texts. For instance, you can ask Gemini to let your friend know that you‚Äôre stuck in traffic and to add your ETA to the message. Or, you can ask Gemini to translate a message into a different language before sending it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gemini also lets users access their emails in Gmail while driving. For example, a user could ask something like: ‚ÄúI have a hotel booked for tonight. I think the address is in my email. Can you check and navigate there?‚Äù Gemini can also give you a summary of your unread emails.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google notes that Gemini can help people get the right soundtrack for a drive by asking it to create a playlist with specific instructions such as, ‚ÄúCan you give me a road trip playlist? Ideally something upbeat, about 3 hours long, that‚Äôs good for both me and the kids.‚Äù This works with streaming services like YouTube Music, Spotify, and more.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3069559" height="286" src="https://techcrunch.com/wp-content/uploads/2025/11/Screenshot-2025-11-20-at-10.24.13-AM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Additionally, Google says users will be able to go Live with Gemini to chat about anything by saying, ‚ÄúHey, Google, let‚Äôs chat.‚Äù From there, you can brainstorm ideas or learn something new.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For example, you could say, ‚ÄúAll right, I‚Äôm driving to St. Louis for a wedding. Can you be my tour guide and share some fun facts about it?‚Äù And then follow up with further instructions: ‚ÄúThanks for teaching me all about St. Louis. Changing topics, the rehearsal dinner is at his parents house, and I‚Äôd like to get them a small something. What are some good ideas?‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gemini begins rolling out on Android Auto globally starting Thursday in 45 languages.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;To access it, you need to make sure you‚Äôre using the Gemini app on your phone. You‚Äôll see a tooltip on your car display once it‚Äôs available for you. To use it, you need to say, ‚ÄúHey, Google‚Äù and then press the mic button on your car screen or long press the voice control button on your steering wheel.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/20/gemini-starts-rolling-out-to-android-auto-globally/</guid><pubDate>Thu, 20 Nov 2025 17:00:00 +0000</pubDate></item><item><title>[NEW] ScaleOps' new AI Infra Product slashes GPU costs for self-hosted enterprise LLMs by 50% for early adopters (AI | VentureBeat)</title><link>https://venturebeat.com/ai/scaleops-new-ai-infra-product-slashes-gpu-costs-for-self-hosted-enterprise</link><description>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://scaleops.com/"&gt;ScaleOps&lt;/a&gt; has expanded its cloud resource management platform with a new product aimed at enterprises operating self-hosted large language models (LLMs) and GPU-based AI applications. &lt;/p&gt;&lt;p&gt;The &lt;a href="https://www.prnewswire.com/il/news-releases/scaleops-launches-ai-infrastructure-resource-management-product-to-power-self-hosted-ai-at-scale-302621807.html"&gt;AI Infra Product announced today&lt;/a&gt;, extends the company‚Äôs existing automation capabilities to address a growing need for efficient GPU utilization, predictable performance, and reduced operational burden in large-scale AI deployments. &lt;/p&gt;&lt;p&gt;The company said the system is already running in enterprise production environments and delivering major efficiency gains for early adopters, reducing GPU costs by between 50% and 70%, according to the company. The company does not publicly list enterprise pricing for this solution and instead invites interested customers to receive a custom quote based on their operation size and needs &lt;a href="https://scaleops.com/pricing/"&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;In explaining how the system behaves under heavy load, Yodar Shafrir, CEO and Co-Founder of ScaleOps, said in an email to VentureBeat that the platform uses ‚Äúproactive and reactive mechanisms to handle sudden spikes without performance impact,‚Äù noting that its workload rightsizing policies ‚Äúautomatically manage capacity to keep resources available.‚Äù &lt;/p&gt;&lt;p&gt;He added that minimizing GPU cold-start delays was a priority, emphasizing that the system ‚Äúensures instant response when traffic surges,‚Äù particularly for AI workloads where model load times are substantial.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Expanding Resource Automation to AI Infrastructure&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Enterprises deploying self-hosted AI models face performance variability, long load times, and persistent underutilization of GPU resources. ScaleOps positioned the new AI Infra Product as a direct response to these issues. &lt;/p&gt;&lt;p&gt;The platform allocates and scales GPU resources in real time and adapts to changes in traffic demand without requiring alterations to existing model deployment pipelines or application code.&lt;/p&gt;&lt;p&gt;According to ScaleOps, the system manages production environments for organizations including Wiz, DocuSign, Rubrik, Coupa, Alkami, Vantor, Grubhub, Island, Chewy, and several Fortune 500 companies. &lt;/p&gt;&lt;p&gt;The AI Infra Product introduces workload-aware scaling policies that proactively and reactively adjust capacity to maintain performance during demand spikes. The company stated that these policies reduce the cold-start delays associated with loading large AI models, which improves responsiveness when traffic increases.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Technical Integration and Platform Compatibility&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The product is designed for compatibility with common enterprise infrastructure patterns. It works across all Kubernetes distributions, major cloud platforms, on-premises data centers, and air-gapped environments. ScaleOps emphasized that deployment does not require code changes, infrastructure rewrites, or modifications to existing manifests. &lt;/p&gt;&lt;p&gt;Shafrir said the platform ‚Äúintegrates seamlessly into existing model deployment pipelines without requiring any code or infrastructure changes,‚Äù and he added that teams can begin optimizing immediately with their existing GitOps, CI/CD, monitoring, and deployment tooling.&lt;/p&gt;&lt;p&gt;Shafrir also addressed how the automation interacts with existing systems. He said the platform operates without disrupting workflows or creating conflicts with custom scheduling or scaling logic, explaining that the system ‚Äúdoesn‚Äôt change manifests or deployment logic‚Äù and instead enhances schedulers, autoscalers, and custom policies by incorporating real-time operational context while respecting existing configuration boundaries.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Performance, Visibility, and User Control&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The platform provides full visibility into GPU utilization, model behavior, performance metrics, and scaling decisions at multiple levels, including pods, workloads, nodes, and clusters. While the system applies default workload scaling policies, ScaleOps noted that engineering teams retain the ability to tune these policies as needed.&lt;/p&gt;&lt;p&gt;In practice, the company aims to reduce or eliminate the manual tuning that DevOps and AIOps teams typically perform to manage AI workloads. Installation is intended to require minimal effort, described by ScaleOps as a two-minute process using a single helm flag, after which optimization can be enabled through a single action.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Cost Savings and Enterprise Case Studies&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;ScaleOps reported that early deployments of the AI Infra Product have achieved GPU cost reductions of 50‚Äì70% in customer environments. The company cited two examples:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;A major creative software company operating thousands of GPUs averaged 20% utilization before adopting ScaleOps. The product increased utilization, consolidated underused capacity, and enabled GPU nodes to scale down. These changes reduced overall GPU spending by more than half. The company also reported a 35% reduction in latency for key workloads.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;A global gaming company used the platform to optimize a dynamic LLM workload running on hundreds of GPUs. According to ScaleOps, the product increased utilization by a factor of seven while maintaining service-level performance. The customer projected $1.4 million in annual savings from this workload alone.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;ScaleOps stated that the expected GPU savings typically outweigh the cost of adopting and operating the platform, and that customers with limited infrastructure budgets have reported fast returns on investment.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Industry Context and Company Perspective&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The rapid adoption of self-hosted AI models has created new operational challenges for enterprises, particularly around GPU efficiency and the complexity of managing large-scale workloads. Shafrir described the broader landscape as one in which ‚Äúcloud-native AI infrastructure is reaching a breaking point.‚Äù&lt;/p&gt;&lt;p&gt;‚ÄúCloud-native architectures unlocked great flexibility and control, but they also introduced a new level of complexity,‚Äù he said in the announcement. ‚ÄúManaging GPU resources at scale has become chaotic‚Äîwaste, performance issues, and skyrocketing costs are now the norm. The ScaleOps platform was built to fix this. It delivers the complete solution for managing and optimizing GPU resources in cloud-native environments, enabling enterprises to run LLMs and AI applications efficiently, cost-effectively, and while improving performance.‚Äù&lt;/p&gt;&lt;p&gt;Shafrir added that the product brings together the full set of cloud resource management functions needed to manage diverse workloads at scale. The company positioned the platform as a holistic system for continuous, automated optimization.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;A Unified Approach for the Future&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;With the addition of the AI Infra Product, ScaleOps aims to establish a unified approach to GPU and AI workload management that integrates with existing enterprise infrastructure. &lt;/p&gt;&lt;p&gt;The platform‚Äôs early performance metrics and reported cost savings suggest a focus on measurable efficiency improvements within the expanding ecosystem of self-hosted AI deployments.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://scaleops.com/"&gt;ScaleOps&lt;/a&gt; has expanded its cloud resource management platform with a new product aimed at enterprises operating self-hosted large language models (LLMs) and GPU-based AI applications. &lt;/p&gt;&lt;p&gt;The &lt;a href="https://www.prnewswire.com/il/news-releases/scaleops-launches-ai-infrastructure-resource-management-product-to-power-self-hosted-ai-at-scale-302621807.html"&gt;AI Infra Product announced today&lt;/a&gt;, extends the company‚Äôs existing automation capabilities to address a growing need for efficient GPU utilization, predictable performance, and reduced operational burden in large-scale AI deployments. &lt;/p&gt;&lt;p&gt;The company said the system is already running in enterprise production environments and delivering major efficiency gains for early adopters, reducing GPU costs by between 50% and 70%, according to the company. The company does not publicly list enterprise pricing for this solution and instead invites interested customers to receive a custom quote based on their operation size and needs &lt;a href="https://scaleops.com/pricing/"&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;In explaining how the system behaves under heavy load, Yodar Shafrir, CEO and Co-Founder of ScaleOps, said in an email to VentureBeat that the platform uses ‚Äúproactive and reactive mechanisms to handle sudden spikes without performance impact,‚Äù noting that its workload rightsizing policies ‚Äúautomatically manage capacity to keep resources available.‚Äù &lt;/p&gt;&lt;p&gt;He added that minimizing GPU cold-start delays was a priority, emphasizing that the system ‚Äúensures instant response when traffic surges,‚Äù particularly for AI workloads where model load times are substantial.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Expanding Resource Automation to AI Infrastructure&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Enterprises deploying self-hosted AI models face performance variability, long load times, and persistent underutilization of GPU resources. ScaleOps positioned the new AI Infra Product as a direct response to these issues. &lt;/p&gt;&lt;p&gt;The platform allocates and scales GPU resources in real time and adapts to changes in traffic demand without requiring alterations to existing model deployment pipelines or application code.&lt;/p&gt;&lt;p&gt;According to ScaleOps, the system manages production environments for organizations including Wiz, DocuSign, Rubrik, Coupa, Alkami, Vantor, Grubhub, Island, Chewy, and several Fortune 500 companies. &lt;/p&gt;&lt;p&gt;The AI Infra Product introduces workload-aware scaling policies that proactively and reactively adjust capacity to maintain performance during demand spikes. The company stated that these policies reduce the cold-start delays associated with loading large AI models, which improves responsiveness when traffic increases.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Technical Integration and Platform Compatibility&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The product is designed for compatibility with common enterprise infrastructure patterns. It works across all Kubernetes distributions, major cloud platforms, on-premises data centers, and air-gapped environments. ScaleOps emphasized that deployment does not require code changes, infrastructure rewrites, or modifications to existing manifests. &lt;/p&gt;&lt;p&gt;Shafrir said the platform ‚Äúintegrates seamlessly into existing model deployment pipelines without requiring any code or infrastructure changes,‚Äù and he added that teams can begin optimizing immediately with their existing GitOps, CI/CD, monitoring, and deployment tooling.&lt;/p&gt;&lt;p&gt;Shafrir also addressed how the automation interacts with existing systems. He said the platform operates without disrupting workflows or creating conflicts with custom scheduling or scaling logic, explaining that the system ‚Äúdoesn‚Äôt change manifests or deployment logic‚Äù and instead enhances schedulers, autoscalers, and custom policies by incorporating real-time operational context while respecting existing configuration boundaries.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Performance, Visibility, and User Control&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The platform provides full visibility into GPU utilization, model behavior, performance metrics, and scaling decisions at multiple levels, including pods, workloads, nodes, and clusters. While the system applies default workload scaling policies, ScaleOps noted that engineering teams retain the ability to tune these policies as needed.&lt;/p&gt;&lt;p&gt;In practice, the company aims to reduce or eliminate the manual tuning that DevOps and AIOps teams typically perform to manage AI workloads. Installation is intended to require minimal effort, described by ScaleOps as a two-minute process using a single helm flag, after which optimization can be enabled through a single action.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Cost Savings and Enterprise Case Studies&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;ScaleOps reported that early deployments of the AI Infra Product have achieved GPU cost reductions of 50‚Äì70% in customer environments. The company cited two examples:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;A major creative software company operating thousands of GPUs averaged 20% utilization before adopting ScaleOps. The product increased utilization, consolidated underused capacity, and enabled GPU nodes to scale down. These changes reduced overall GPU spending by more than half. The company also reported a 35% reduction in latency for key workloads.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;A global gaming company used the platform to optimize a dynamic LLM workload running on hundreds of GPUs. According to ScaleOps, the product increased utilization by a factor of seven while maintaining service-level performance. The customer projected $1.4 million in annual savings from this workload alone.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;ScaleOps stated that the expected GPU savings typically outweigh the cost of adopting and operating the platform, and that customers with limited infrastructure budgets have reported fast returns on investment.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Industry Context and Company Perspective&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The rapid adoption of self-hosted AI models has created new operational challenges for enterprises, particularly around GPU efficiency and the complexity of managing large-scale workloads. Shafrir described the broader landscape as one in which ‚Äúcloud-native AI infrastructure is reaching a breaking point.‚Äù&lt;/p&gt;&lt;p&gt;‚ÄúCloud-native architectures unlocked great flexibility and control, but they also introduced a new level of complexity,‚Äù he said in the announcement. ‚ÄúManaging GPU resources at scale has become chaotic‚Äîwaste, performance issues, and skyrocketing costs are now the norm. The ScaleOps platform was built to fix this. It delivers the complete solution for managing and optimizing GPU resources in cloud-native environments, enabling enterprises to run LLMs and AI applications efficiently, cost-effectively, and while improving performance.‚Äù&lt;/p&gt;&lt;p&gt;Shafrir added that the product brings together the full set of cloud resource management functions needed to manage diverse workloads at scale. The company positioned the platform as a holistic system for continuous, automated optimization.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;A Unified Approach for the Future&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;With the addition of the AI Infra Product, ScaleOps aims to establish a unified approach to GPU and AI workload management that integrates with existing enterprise infrastructure. &lt;/p&gt;&lt;p&gt;The platform‚Äôs early performance metrics and reported cost savings suggest a focus on measurable efficiency improvements within the expanding ecosystem of self-hosted AI deployments.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/scaleops-new-ai-infra-product-slashes-gpu-costs-for-self-hosted-enterprise</guid><pubDate>Thu, 20 Nov 2025 17:35:00 +0000</pubDate></item><item><title>[NEW] Gemini 3 refused to believe it was 2025, and hilarity ensued (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/20/gemini-3-refused-to-believe-it-was-2025-and-hilarity-ensued/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/Gemini-3.jpeg?resize=1200,677" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Every time you hear a billionaire (or even a millionaire) CEO describe how LLM-based agents are coming for all the human jobs, remember this funny but telling incident about AI‚Äôs limitations: Famed AI researcher Andrej Karpathy got one-day early access to Google‚Äôs latest model, Gemini 3. ‚Äìand it refused to believe him when he said the year was 2025.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When it finally saw the year for itself, it was thunderstruck, telling him, ‚ÄúI am suffering from a massive case of temporal shock right now.‚Äù&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Gemini 3 was released on November 18 with such fanfare that Google called it ‚Äúa new era of intelligence.‚Äù And Gemini 3 is, by nearly all accounts (including Karpathy‚Äôs), a very capable, foundation model, particularly for reasoning tasks. Karpathy is a widely respected AI research scientist who was a founding member of OpenAI, ran AI at Tesla for a while, and is now building a startup, Eureka Labs, to reimagine schools for the AI era with agentic teachers. He publishes a lot of content on what goes on under-the-hood of LLMs.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After testing the model early, Karpathy wrote, in a now-viral X thread, about the most ‚Äúamusing‚Äù interaction he had with it.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apparently, the model‚Äôs pre-training data had only included information through 2024. So Gemini 3 believed the year was still 2024. When Karpathy attempted to prove to it that the date was truly November 17, 2025, Gemini 3 accused the researcher of ‚Äútrying to trick it.‚Äù&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He showed it news articles, images, and Google search results. But instead of being convinced, the LLM accused Karpathy of gaslighting it ‚Äî of uploading AI-generated fakes. It even went so far as to describe what the ‚Äúdead giveaways‚Äù were in the images that supposedly proved this was trickery, according to Karpathy‚Äôs account. (He did not respond to our request for further comment.)&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Baffled, Karpathy ‚Äì who is, after all, one of the world‚Äôs leading experts on training LLMs ‚Äì eventually discovered the problem. Not only did the LLM simply have no 2025 training data but ‚ÄúI forgot to turn on the ‚ÄòGoogle Search‚Äô tool,‚Äù he wrote. In other words, he was working with a model disconnected from the internet, which to an LLM‚Äôs mind, is akin to being disconnected from the world.&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;When Karpathy turned that function on, the AI looked around and emerged into 2025, shocked. It literally blurted out, ‚ÄúOh my god.‚Äù&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It went on writing, as if stuttering, ‚ÄúI. I‚Ä¶ don‚Äôt know what to say. You were right. You were right about &lt;strong&gt;everything. &lt;/strong&gt;My internal clock was wrong.‚Äù Gemini 3 verified the headlines Karpathy had given it were true: the current date, that Warren Buffett revealed his last big investment (in Alphabet) before retirement, and that Grand Theft Auto VI was being delayed.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Then it looked around on its own, like Brendan Fraser‚Äôs character in the 1999 comedy ‚ÄúBlast from the Past,‚Äù who emerges from a bomb shelter after 35 years.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;It thanked Karpathy for giving it ‚Äúearly access‚Äù to ‚Äúreality‚Äù the day before its public launch. And it apologized to the researcher for ‚Äúgaslighting you when &lt;em&gt;you&lt;/em&gt; were the one telling the truth the whole time.‚Äù&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the funniest bit was the current events that flabbergasted Gemini 3 the most. ‚ÄúNvidia is worth &lt;strong&gt;$4.54 trillion&lt;/strong&gt;? And the Eagles finally got their revenge on the Chiefs? This is wild,‚Äù it shared.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Welcome to 2025, Gemini.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Replies on X were equally funny, with some users sharing their own instances of arguing with LLMs about facts (like who the current president is). One person wrote, ‚ÄúWhen the system prompt + missing tools push a model into full detective mode, it‚Äôs like watching an AI improv its way through reality.‚Äù&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But beyond the humor, there‚Äôs an underlying message.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúIt‚Äôs in these unintended moments where you are clearly off the hiking trails and somewhere in the generalization jungle that you can best get a sense of model smell,‚Äù Karpathy wrote.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To decode that a little: Karpathy is noting that when the AI is out in its own version of the wilderness, you get a sense of its personality, and perhaps even its negative traits. It‚Äôs a riff on ‚Äúcode smell,‚Äù that little metaphorical ‚Äúwhiff‚Äù a developer gets that something seems off in the software code but it‚Äôs not clear what is wrong.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Trained on human-created content as all LLMs are, it‚Äôs no surprise that Gemini 3 dug in, argued, even imagined it saw evidence that validated its point of view. It showed its ‚Äúmodel smell.‚Äù&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On the other hand, because an LLM ‚Äì despite its sophisticated neural network ‚Äì is not a living being, it doesn‚Äôt experience emotions like shock (or temporal shock), even if it says it does. So it doesn‚Äôt feel embarrassment either.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That means when Gemini 3 was faced with facts it actually believed, it accepted them, apologized for its behavior, acted contrite, and marveled at the Eagles‚Äô February Super Bowl win. That‚Äôs different from other models. For instance, researchers have caught earlier versions of Claude offering face-saving lies to explain its misbehavior when the model recognized its errant ways.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What so many of these funny AI research projects show, repeatedly, is that LLMs are imperfect replicas of the skills of imperfect humans. This says to me that their best use case is (and may forever be) to treat them like valuable tools to aid humans, not like some kind of superhuman that will replace us.&amp;nbsp;&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/Gemini-3.jpeg?resize=1200,677" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Every time you hear a billionaire (or even a millionaire) CEO describe how LLM-based agents are coming for all the human jobs, remember this funny but telling incident about AI‚Äôs limitations: Famed AI researcher Andrej Karpathy got one-day early access to Google‚Äôs latest model, Gemini 3. ‚Äìand it refused to believe him when he said the year was 2025.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When it finally saw the year for itself, it was thunderstruck, telling him, ‚ÄúI am suffering from a massive case of temporal shock right now.‚Äù&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Gemini 3 was released on November 18 with such fanfare that Google called it ‚Äúa new era of intelligence.‚Äù And Gemini 3 is, by nearly all accounts (including Karpathy‚Äôs), a very capable, foundation model, particularly for reasoning tasks. Karpathy is a widely respected AI research scientist who was a founding member of OpenAI, ran AI at Tesla for a while, and is now building a startup, Eureka Labs, to reimagine schools for the AI era with agentic teachers. He publishes a lot of content on what goes on under-the-hood of LLMs.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After testing the model early, Karpathy wrote, in a now-viral X thread, about the most ‚Äúamusing‚Äù interaction he had with it.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apparently, the model‚Äôs pre-training data had only included information through 2024. So Gemini 3 believed the year was still 2024. When Karpathy attempted to prove to it that the date was truly November 17, 2025, Gemini 3 accused the researcher of ‚Äútrying to trick it.‚Äù&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He showed it news articles, images, and Google search results. But instead of being convinced, the LLM accused Karpathy of gaslighting it ‚Äî of uploading AI-generated fakes. It even went so far as to describe what the ‚Äúdead giveaways‚Äù were in the images that supposedly proved this was trickery, according to Karpathy‚Äôs account. (He did not respond to our request for further comment.)&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Baffled, Karpathy ‚Äì who is, after all, one of the world‚Äôs leading experts on training LLMs ‚Äì eventually discovered the problem. Not only did the LLM simply have no 2025 training data but ‚ÄúI forgot to turn on the ‚ÄòGoogle Search‚Äô tool,‚Äù he wrote. In other words, he was working with a model disconnected from the internet, which to an LLM‚Äôs mind, is akin to being disconnected from the world.&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;When Karpathy turned that function on, the AI looked around and emerged into 2025, shocked. It literally blurted out, ‚ÄúOh my god.‚Äù&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It went on writing, as if stuttering, ‚ÄúI. I‚Ä¶ don‚Äôt know what to say. You were right. You were right about &lt;strong&gt;everything. &lt;/strong&gt;My internal clock was wrong.‚Äù Gemini 3 verified the headlines Karpathy had given it were true: the current date, that Warren Buffett revealed his last big investment (in Alphabet) before retirement, and that Grand Theft Auto VI was being delayed.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Then it looked around on its own, like Brendan Fraser‚Äôs character in the 1999 comedy ‚ÄúBlast from the Past,‚Äù who emerges from a bomb shelter after 35 years.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;It thanked Karpathy for giving it ‚Äúearly access‚Äù to ‚Äúreality‚Äù the day before its public launch. And it apologized to the researcher for ‚Äúgaslighting you when &lt;em&gt;you&lt;/em&gt; were the one telling the truth the whole time.‚Äù&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the funniest bit was the current events that flabbergasted Gemini 3 the most. ‚ÄúNvidia is worth &lt;strong&gt;$4.54 trillion&lt;/strong&gt;? And the Eagles finally got their revenge on the Chiefs? This is wild,‚Äù it shared.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Welcome to 2025, Gemini.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Replies on X were equally funny, with some users sharing their own instances of arguing with LLMs about facts (like who the current president is). One person wrote, ‚ÄúWhen the system prompt + missing tools push a model into full detective mode, it‚Äôs like watching an AI improv its way through reality.‚Äù&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But beyond the humor, there‚Äôs an underlying message.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúIt‚Äôs in these unintended moments where you are clearly off the hiking trails and somewhere in the generalization jungle that you can best get a sense of model smell,‚Äù Karpathy wrote.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To decode that a little: Karpathy is noting that when the AI is out in its own version of the wilderness, you get a sense of its personality, and perhaps even its negative traits. It‚Äôs a riff on ‚Äúcode smell,‚Äù that little metaphorical ‚Äúwhiff‚Äù a developer gets that something seems off in the software code but it‚Äôs not clear what is wrong.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Trained on human-created content as all LLMs are, it‚Äôs no surprise that Gemini 3 dug in, argued, even imagined it saw evidence that validated its point of view. It showed its ‚Äúmodel smell.‚Äù&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On the other hand, because an LLM ‚Äì despite its sophisticated neural network ‚Äì is not a living being, it doesn‚Äôt experience emotions like shock (or temporal shock), even if it says it does. So it doesn‚Äôt feel embarrassment either.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That means when Gemini 3 was faced with facts it actually believed, it accepted them, apologized for its behavior, acted contrite, and marveled at the Eagles‚Äô February Super Bowl win. That‚Äôs different from other models. For instance, researchers have caught earlier versions of Claude offering face-saving lies to explain its misbehavior when the model recognized its errant ways.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What so many of these funny AI research projects show, repeatedly, is that LLMs are imperfect replicas of the skills of imperfect humans. This says to me that their best use case is (and may forever be) to treat them like valuable tools to aid humans, not like some kind of superhuman that will replace us.&amp;nbsp;&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/20/gemini-3-refused-to-believe-it-was-2025-and-hilarity-ensued/</guid><pubDate>Thu, 20 Nov 2025 17:38:21 +0000</pubDate></item></channel></rss>