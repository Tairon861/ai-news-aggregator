<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 26 Aug 2025 18:29:54 +0000</lastBuildDate><item><title>Malaysia launches Ryt Bank, its first AI-powered bank (AI News)</title><link>https://www.artificialintelligence-news.com/news/malaysia-launches-ryt-bank-its-first-ai-powered-bank/</link><description>&lt;p&gt;AI is steadily changing the way banks work. The technology can sift through massive amounts of data, calculate risks, and handle routine tasks at speeds people can’t match. Now, Malaysia has entered that space with the launch of Ryt Bank, billed as the first AI-powered bank created in the country.&lt;/p&gt;&lt;p&gt;The new venture, led by YTL Group in partnership with Sea Limited, arrives just ahead of Merdeka. “Ryt Bank demonstrates that groundbreaking innovation can be imagined, built, and led right here in Malaysia,” said Dato’ Seri Yeoh Seok Hong, Managing Director of YTL Power International. “By combining homegrown AI with the values and diversity of our people, we’ve created a bank that Malaysians can proudly call their own – one that speaks our languages, understands our culture, and sets a new standard for how banking should feel.”&lt;/p&gt;&lt;h3&gt;Banking for Malaysians&lt;/h3&gt;&lt;p&gt;Ryt Bank has been designed to work in the languages most Malaysians use every day. Its app is already available in Bahasa Malaysia and English, with Mandarin support scheduled to arrive by next month (September 2025). By offering multilingual access, the bank aims to make financial services more inclusive and easy to use for people in many different communities.&lt;/p&gt;&lt;p&gt;The centrepiece of the AI-powered bank is Ryt AI, a digital assistant powered by ILMU, Malaysia’s first locally-developed large language model. Ryt AI can understand natural conversation – in Bahasa Malaysia, English, or a mixture of both – and act on requests instantly.&lt;/p&gt;&lt;p&gt;The AI assistant can read and pay bills, track spending, and explain financial basics in plain terms. The idea is to blend convenience with cultural familiarity, while maintaining enterprise-grade security.&lt;/p&gt;&lt;h3&gt;Everyday AI banking in one app&lt;/h3&gt;&lt;p&gt;Ryt Bank is designed to pull together multiple financial needs into one platform. Customers can use the AI bank app to save, spend, borrow, and pay bills, with Ryt AI making the process more conversational and personal.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Personal banking with Ryt AI&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Send money or pay bills through text chat, with support for DuitNow and JomPAY.&lt;/li&gt;&lt;li&gt;Snap and upload bills or receipts for instant payment.&lt;/li&gt;&lt;li&gt;Access guides and simple financial explanations as you bank.&lt;/li&gt;&lt;li&gt;All actions are encrypted and verified for security.&lt;/li&gt;&lt;li&gt;New users can claim a small launch reward of up to RM5 when they try Ryt AI.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Growing money&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Customers earn up to 4% interest per year, credited daily.&lt;/li&gt;&lt;li&gt;Withdraw funds anytime, with no lock-in requirements.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Ryt PayLater&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Access instant credit of up to RM1,499.&lt;/li&gt;&lt;li&gt;0% interest if paid back in a month.&lt;/li&gt;&lt;li&gt;No late fees and no paperwork.&lt;/li&gt;&lt;li&gt;Earn cashback on DuitNow QR payments and extra rewards with select partners.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Ryt Card&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Switch between debit and credit card models in the app.&lt;/li&gt;&lt;li&gt;Accepted worldwide through Visa.&lt;/li&gt;&lt;li&gt;No foreign transaction or ATM fees in Malaysia.&lt;/li&gt;&lt;li&gt;Cashback on spending, plus partner offers like Shopee vouchers and dining discounts at YTL Hotels.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;[&lt;strong&gt;See also&lt;/strong&gt;: Can Malaysia become Southeast Asia’s AI and cloud hub?]&lt;/p&gt;&lt;h3&gt;Banking under Bank Negara rules&lt;/h3&gt;&lt;p&gt;The AI bank is licensed by Bank Negara Malaysia and covered by PIDM, which protects deposits up to RM250,000 per customer. Security features include biometric login, layered encryption, and real-time fraud alerts.&lt;/p&gt;&lt;h3&gt;A step forward for Malaysia’s banking sector&lt;/h3&gt;&lt;p&gt;Ryt Bank’s launch shows how AI is being used to rethink traditional banking. It aims to make financial services more accessible and satisfy regulatory and security standards by supporting local languages and developing its own AI assistant.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Huawei commits to training 30,000 Malaysian AI professionals as local tech ecosystem expands&lt;/strong&gt;&lt;/p&gt;&lt;figure&gt;&lt;img alt="alt" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;AI is steadily changing the way banks work. The technology can sift through massive amounts of data, calculate risks, and handle routine tasks at speeds people can’t match. Now, Malaysia has entered that space with the launch of Ryt Bank, billed as the first AI-powered bank created in the country.&lt;/p&gt;&lt;p&gt;The new venture, led by YTL Group in partnership with Sea Limited, arrives just ahead of Merdeka. “Ryt Bank demonstrates that groundbreaking innovation can be imagined, built, and led right here in Malaysia,” said Dato’ Seri Yeoh Seok Hong, Managing Director of YTL Power International. “By combining homegrown AI with the values and diversity of our people, we’ve created a bank that Malaysians can proudly call their own – one that speaks our languages, understands our culture, and sets a new standard for how banking should feel.”&lt;/p&gt;&lt;h3&gt;Banking for Malaysians&lt;/h3&gt;&lt;p&gt;Ryt Bank has been designed to work in the languages most Malaysians use every day. Its app is already available in Bahasa Malaysia and English, with Mandarin support scheduled to arrive by next month (September 2025). By offering multilingual access, the bank aims to make financial services more inclusive and easy to use for people in many different communities.&lt;/p&gt;&lt;p&gt;The centrepiece of the AI-powered bank is Ryt AI, a digital assistant powered by ILMU, Malaysia’s first locally-developed large language model. Ryt AI can understand natural conversation – in Bahasa Malaysia, English, or a mixture of both – and act on requests instantly.&lt;/p&gt;&lt;p&gt;The AI assistant can read and pay bills, track spending, and explain financial basics in plain terms. The idea is to blend convenience with cultural familiarity, while maintaining enterprise-grade security.&lt;/p&gt;&lt;h3&gt;Everyday AI banking in one app&lt;/h3&gt;&lt;p&gt;Ryt Bank is designed to pull together multiple financial needs into one platform. Customers can use the AI bank app to save, spend, borrow, and pay bills, with Ryt AI making the process more conversational and personal.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Personal banking with Ryt AI&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Send money or pay bills through text chat, with support for DuitNow and JomPAY.&lt;/li&gt;&lt;li&gt;Snap and upload bills or receipts for instant payment.&lt;/li&gt;&lt;li&gt;Access guides and simple financial explanations as you bank.&lt;/li&gt;&lt;li&gt;All actions are encrypted and verified for security.&lt;/li&gt;&lt;li&gt;New users can claim a small launch reward of up to RM5 when they try Ryt AI.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Growing money&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Customers earn up to 4% interest per year, credited daily.&lt;/li&gt;&lt;li&gt;Withdraw funds anytime, with no lock-in requirements.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Ryt PayLater&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Access instant credit of up to RM1,499.&lt;/li&gt;&lt;li&gt;0% interest if paid back in a month.&lt;/li&gt;&lt;li&gt;No late fees and no paperwork.&lt;/li&gt;&lt;li&gt;Earn cashback on DuitNow QR payments and extra rewards with select partners.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Ryt Card&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Switch between debit and credit card models in the app.&lt;/li&gt;&lt;li&gt;Accepted worldwide through Visa.&lt;/li&gt;&lt;li&gt;No foreign transaction or ATM fees in Malaysia.&lt;/li&gt;&lt;li&gt;Cashback on spending, plus partner offers like Shopee vouchers and dining discounts at YTL Hotels.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;[&lt;strong&gt;See also&lt;/strong&gt;: Can Malaysia become Southeast Asia’s AI and cloud hub?]&lt;/p&gt;&lt;h3&gt;Banking under Bank Negara rules&lt;/h3&gt;&lt;p&gt;The AI bank is licensed by Bank Negara Malaysia and covered by PIDM, which protects deposits up to RM250,000 per customer. Security features include biometric login, layered encryption, and real-time fraud alerts.&lt;/p&gt;&lt;h3&gt;A step forward for Malaysia’s banking sector&lt;/h3&gt;&lt;p&gt;Ryt Bank’s launch shows how AI is being used to rethink traditional banking. It aims to make financial services more accessible and satisfy regulatory and security standards by supporting local languages and developing its own AI assistant.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Huawei commits to training 30,000 Malaysian AI professionals as local tech ecosystem expands&lt;/strong&gt;&lt;/p&gt;&lt;figure&gt;&lt;img alt="alt" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/malaysia-launches-ryt-bank-its-first-ai-powered-bank/</guid><pubDate>Tue, 26 Aug 2025 08:15:39 +0000</pubDate></item><item><title>Power with purpose (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/08/26/1120994/power-with-purpose/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Baafour Asiamah-Adjei ’03 is the founder and CEO of one of Ghana’s largest private power companies, Genser Energy—an entrepreneurial engineer who aims to deliver sustainable energy across West Africa. And he credits MIT with much of his success. But when he was applying to colleges, the Institute wasn’t even on his radar. The son of an encouraging primary school teacher in Tafo, Ghana, he’d earned a spot at the storied Achimota School and excelled. Still, he didn’t think he was smart enough for MIT.&amp;nbsp;&lt;/p&gt;  &lt;div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"&gt; &lt;div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"&gt; &lt;p&gt;Asiamah-Adjei was accepted to Lehigh University, where he planned to major in engineering. But when he went to the US embassy in Accra for his mandatory meeting with Nancy Keteku, then the regional educational advising coordinator for West and Central Africa, the first thing she said was “You got a perfect score on your SAT. Why didn’t you apply to MIT?”&amp;nbsp;&lt;/p&gt;    &lt;p&gt;“I didn’t believe I’d get in,” he says, “so I didn’t even try.”&amp;nbsp;&lt;/p&gt;    &lt;p&gt;The admission deadline was two days away. Asiamah-Adjei finished the application in one. His father drove it to the airport and engaged the help of a flight attendant at Ghana Airways, who couriered it to New York and mailed it in time.&lt;/p&gt;    &lt;h3 class="wp-block-heading"&gt;The spark of purpose&lt;/h3&gt; &lt;/div&gt;    &lt;p&gt;Asiamah-Adjei got into MIT and thrived. After earning his degree in mechanical engineering, he landed a demanding role at the global consulting firm McKinsey and worked on teams that optimized flight routes for FedEx, determined best practices for airline engine maintenance, and devised practical workflows for moving factories from one country to another.&lt;/p&gt;    &lt;p&gt;The job was intellectually challenging and fulfilling. But he felt something was missing in his life: purpose.&lt;/p&gt; &lt;/div&gt;  &lt;p&gt;In 2005, Asiamah-Adjei took a rare break to visit Pablo Tribin ’01, a friend since they’d bonded at an intense MIT $50K Global Startup Workshop in Australia. Tribin and his father, Hugo Tribin, SM ’63, had just established a power company, Genser (for “generation services”), in their home country of Colombia with a holding company in the US. As the friends floated in the pool at Tribin’s apartment building in Miami, Tribin asked Asiamah-Adjei if he had ever thought about working in the power industry.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;In 2005, only 41% of Ghana’s population had access to electricity. Much of that electricity was generated by the Akosombo and Kpong dams on the Volta River, but relying on hydroelectric power made Ghana susceptible to climate fluctuations that affect water levels. Recalling how much his MIT thermodynamics class (then called Heat and Mass Transfer) with Ernest Cravalho had stayed with him, Asiamah-Adjei realized that perhaps delving into energy was not such a wild idea.&amp;nbsp;&lt;/p&gt;  &lt;div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"&gt; &lt;p&gt;“The seed had been sown,” he says. He took a year off from McKinsey to go to Ghana and explore.&amp;nbsp;&lt;/p&gt;   &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="two men in safety vests standing in a muddy area looking over a document" class="wp-image-1121876" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/Day-2-74.jpg?w=2547" width="2547" /&gt;&lt;figcaption class="wp-element-caption"&gt;Baafour Asiamah-Adjei ’03 (right) reviews a section of Genser Energy’s natural gas pipeline network with construction superintendent Stephen Ayisi.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;BISMARK ADAMAFIO ARYEE&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;   &lt;p&gt;That year led him to realize that Ghana desperately needed a more robust power supply if it was going to industrialize and expand economic opportunity for its citizens. He also saw an opportunity to create infrastructure that reflected the values he believed in—systems built with precision, scaled with care, and grounded in the local context. If he could help build a power company that worked not only efficiently but ethically—by training Ghanaian engineers, choosing technologies that made long-term environmental sense, and reinvesting in the communities it served—then he could turn his skills into something larger than profit: He could invest in Ghana’s future.&lt;/p&gt; &lt;/div&gt;  &lt;p&gt;But first, he had to turn a profit.&lt;/p&gt; 
 &lt;p&gt;By 2007, he had founded Genser Power Ghana (a partner to Colombia’s Genser Power), a company committed to providing efficient and reliable power systems—fueled initially by natural gas and eventually by sustainable sources—throughout Ghana. He and Tribin, along with their fathers, led the board of directors. They also created a US holding company to support Genser’s expansion and attract private investment.&lt;/p&gt;  &lt;p&gt;It appeared that Asiamah-Adjei had found his purpose.&lt;/p&gt; 
 &lt;p&gt;The mission and values of the company now called Genser Energy are rooted in the two institutions that shaped its founder’s approach to business and to life. From MIT (which inspired a commitment to “be fact-based at all times”), Asiamah-Adjei gained not just an engineering education but also a way of dealing with the unknown—with humility, curiosity, and a willingness to experiment. MIT instilled in him the confidence to say “I don’t know” and the discipline to find out. “MIT teaches you that you actually don’t know enough yet,” he says. “You need to be doing research and finding out more.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;At McKinsey, he learned how to turn inquiry into action—and to distinguish between facts and judgments. His time there also inspired the idea that Genser’s team should “maintain an obligation to disagree”—that is, to speak up when warranted. &amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;MIT roots and modular thinking&lt;/h3&gt;  &lt;p&gt;Asiamah-Adjei says that learning basic coding at MIT in 2.001 (Mechanics and Materials I) opened a whole new way of understanding how systems work. “One of the first things I learned in my sophomore year was that you can build computer software in modules and then let the modules talk to each other,” he says. “As a concept, that didn’t exist in my young brain until that class.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This idea of breaking down complex systems into interlocking components became the philosophical and physical backbone of Genser’s operation, inspiring both Asiamah-Adjei and Tribin to reimagine power-plant construction. Instead of building plants from scratch on site—often in remote areas—they develop replicable, factory-built sections and transport them to the site, where they are assembled like Lego structures. Genser worked with companies such as Caterpillar to reengineer their standard generator systems into modular skid-mounted units that are easier to scale and deploy. Asiamah-Adjei also collaborated with a team of US engineers to design other skid-mounted modules, such as gas-control units (which include such things as instrumentation, control systems, valves, and piping) that are fabricated in China. These modules can be stacked and adapted as needed to build 30-, 60-, or 120-megawatt power generation systems. This approach also makes it possible to offer smaller, incremental contracts in place of massive one-size-fits-all power deals, ultimately benefiting both Genser and the emerging economies it serves. The result is an energy infrastructure that’s less expensive and easier to scale. And that, he claims, is the fundamental difference between Genser and its competitors. Modularity allows Genser to build infrastructure at about a third of the typical cost.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Genser launched its operations by supplying electricity directly to Ghana’s industrial sector. It started with the country’s gold mines after two Genser interns—Chen-rei Wan, SM ’07, PhD ’11, and Stephanie Dalquist ’02, MEng ’03, SM ’05—conducted a comprehensive review of all Ghanaian industries and determined that the mines’ high, consistent electricity demands, limited access to reliable power, and urgent operational needs made them highly motivated and well-resourced early adopters. “At that time, Pablo in Latin America was focused mainly on oil and gas and textile industries,” says Asiamah-Adjei. “But we took a very different turn.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Of the eight power plants it has built—seven in Ghana and one in Burkina Faso—three have powered gold mines exclusively and others have also supplied power to the grid and to Côte d’Ivoire. With five still operating under its control, Genser has the ability to generate over 200 megawatts of electricity and plays a leading role in supplying power to West African industry.&lt;sup&gt;&amp;nbsp;&lt;/sup&gt;&lt;/p&gt;  &lt;p&gt;In addition to helping Genser target its first customers, Dalquist also introduced Asiamah-Adjei to Frances Rogoz ’07, an economics major drawn to development work after taking a D-Lab class at MIT. Rogoz soon joined Genser as its first full-time hire and has been with the company ever since.&lt;/p&gt;  &lt;p&gt;Rogoz started when the company was operating out of an office fashioned from a shipping container. She helped shape Genser’s growth by developing financial models, advising on contracts, and playing a key role in leading major infrastructure projects—most notably a natural-gas pipeline across western Ghana that has become vital. Today she serves as VP of project development, leading a team of 10 and overseeing West African strategic initiatives. “The natural-gas pipeline has been super transformative for us,” she says. “It has allowed us to really invest in infrastructure not only that we can use, but that the whole country can use.” Genser is now Ghana’s largest owner of gas pipelines and its only private one, operating four that total 430 kilometers.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;Genser’s growth has not come without controversy. In 2022, a coalition of Ghanaian civil society organizations charged that the company was receiving preferential treatment on gas tariffs and bypassing regulatory procedures. Asiamah-Adjei says these claims were “misinformed,” and ultimately they were dismissed by the Ghanaian parliament after an intense, months-long investigation. He believes the attacks reflected public suspicion of private infrastructure development rather than distrust of Genser’s operations and says that, ironically, they solidified the company’s standing: “Prior to this, everybody thought our pipelines belong to the government, because nobody builds these things in Africa.”&lt;em&gt;&lt;sup&gt;&amp;nbsp;&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;While transporting fossil fuels is never a clean process, Genser conducted environmental and social impact assessments to guide sustainable pipeline construction. The company also works to mitigate environmental harm with land restoration and biodiversity measures. It had planted 100,000 teak seedlings as of 2023 and plans to reach 1 million by 2028 as part of its commitment to environmental stewardship.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Crossing borders, fueling growth&lt;/h3&gt;  &lt;p&gt;Genser’s most ambitious project to date is a cross-­border natural-gas pipeline stretching from Prestea, Ghana, to Abidjan, Côte d’Ivoire, with long-term plans to extend into Guinea. “We built the gas infrastructure to be able to take the gas to a less developed country, to displace diesel, and now we will backfill that with solar or wind,” says Asiamah-Adjei. Genser now finally has the capital to move forward on an original goal: investing in the infrastructure needed to produce renewable energy.&lt;/p&gt;  &lt;p&gt;In 2018 and 2019, Genser brought in two graduates of MIT’s Technology and Public Policy program—Elizabeth Murphy ’15, SM ’18, and Janet Yun, SM ’18—to help chart the pipeline’s course. Instead of opting for the most direct route, they studied regional development trends to anticipate industrial zones that might emerge over the next 25 years, and the company routed the pipeline accordingly. “Bottom line is that we brought on MIT people whenever we needed to solve our problems,” says Asiamah-Adjei.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;As part of his goal to help Ghana transition from diesel power to cleaner-burning fuel, he came up with the idea of building a gas-processing facility to handle roughly 30% to 40% of the country’s domestic gas supply, and he and Tribin designed it during the pandemic using “back of the envelope” calculations and lessons from MIT courses 2.005 and 2.006. Although Tribin divested from both Genser Energy and Genser Latin America and started Mechero Energy in 2015 to develop new strategies for transitioning to cleaner energy, he still works closely with Genser as a consultant.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Educating engineers and the next generation&lt;/h3&gt;  &lt;p&gt;From the beginning, Genser has invested in Ghanaian talent, partnering with Sponsors for Educational Opportunity (SEO) Africa on an elite professional development program that recruits and trains recent university graduates. “Half of my team basically came from the SEO program,” says Rogoz. &amp;nbsp;&lt;/p&gt;  &lt;p&gt;The company rotates cohorts of interns through departments ranging from engineering to legal and finance, offering full-time positions to top performers. Genser also collaborates with Ghana’s Ministry of Energy to develop training pathways that align university curricula with industry needs. The goal, Asiamah-Adjei says, is simple: “Let us be a platform for training Ghanaians.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="imageSet__wrap"&gt;&lt;div class="columns__wrapper--07c4096a3b25e22dc82ee78b6368d947"&gt;&lt;div class="wp-block-columns"&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="PABLO TRIBIN" class="wp-image-1122400" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/Pablo-Tribin_1-edited.jpg" /&gt;&lt;figcaption class="wp-element-caption"&gt;After starting Genser in Colombia, Pablo Tribin ’01 encouraged Asiamah-Adjei to found Genser Power Ghana in 2007.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF PABLO TRIBIN&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="FRANCES ROGOZ" class="wp-image-1121879" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/Rogoz_1.jpg?w=956" /&gt;&lt;figcaption class="wp-element-caption"&gt;Asiamah-Adjei’s first full-time hire, Frances Rogoz ’07, is now VP of project development.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF FRANCES ROGOZ&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;Rogoz’s team alone includes five SEO graduates; many more now lead projects or departments across the company. “There’s a ton of human capital in Ghana,” she says. “It has just not been realized—and that’s really important for us to develop those people and bring them up within the company.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;As Genser expands, Asiamah-Adjei is also thinking about the next generation. In Ghana, he is building “an MIT of a high school” focusing on STEAM, in memory of his late mother, Aforo Asiamah-Adjei—a boarding school for some 840 students in grades six through 12. More than half will come from lower-­income families and receive a full scholarship through the foundation he established in his mother’s name to empower orphans and communities through education in STEM, sports, and the arts. “We find the smartest kids in the region,” he says, “and we put them through a rigorous program and [prepare them] to enter universities, global universities.” Construction is slated to begin this fall, with a planned opening date of September 2027.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Whether developing infrastructure across West Africa or launching a school to cultivate future changemakers, Asiamah-Adjei is investing in systems that endure. And just as Genser began with a conversation between friends, it continues to be powered by relationships—between mentors and interns, engineers and economists, founders and funders. Each one is a link in an evolving network connecting energy, education, and economic development.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Baafour Asiamah-Adjei ’03 is the founder and CEO of one of Ghana’s largest private power companies, Genser Energy—an entrepreneurial engineer who aims to deliver sustainable energy across West Africa. And he credits MIT with much of his success. But when he was applying to colleges, the Institute wasn’t even on his radar. The son of an encouraging primary school teacher in Tafo, Ghana, he’d earned a spot at the storied Achimota School and excelled. Still, he didn’t think he was smart enough for MIT.&amp;nbsp;&lt;/p&gt;  &lt;div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"&gt; &lt;div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"&gt; &lt;p&gt;Asiamah-Adjei was accepted to Lehigh University, where he planned to major in engineering. But when he went to the US embassy in Accra for his mandatory meeting with Nancy Keteku, then the regional educational advising coordinator for West and Central Africa, the first thing she said was “You got a perfect score on your SAT. Why didn’t you apply to MIT?”&amp;nbsp;&lt;/p&gt;    &lt;p&gt;“I didn’t believe I’d get in,” he says, “so I didn’t even try.”&amp;nbsp;&lt;/p&gt;    &lt;p&gt;The admission deadline was two days away. Asiamah-Adjei finished the application in one. His father drove it to the airport and engaged the help of a flight attendant at Ghana Airways, who couriered it to New York and mailed it in time.&lt;/p&gt;    &lt;h3 class="wp-block-heading"&gt;The spark of purpose&lt;/h3&gt; &lt;/div&gt;    &lt;p&gt;Asiamah-Adjei got into MIT and thrived. After earning his degree in mechanical engineering, he landed a demanding role at the global consulting firm McKinsey and worked on teams that optimized flight routes for FedEx, determined best practices for airline engine maintenance, and devised practical workflows for moving factories from one country to another.&lt;/p&gt;    &lt;p&gt;The job was intellectually challenging and fulfilling. But he felt something was missing in his life: purpose.&lt;/p&gt; &lt;/div&gt;  &lt;p&gt;In 2005, Asiamah-Adjei took a rare break to visit Pablo Tribin ’01, a friend since they’d bonded at an intense MIT $50K Global Startup Workshop in Australia. Tribin and his father, Hugo Tribin, SM ’63, had just established a power company, Genser (for “generation services”), in their home country of Colombia with a holding company in the US. As the friends floated in the pool at Tribin’s apartment building in Miami, Tribin asked Asiamah-Adjei if he had ever thought about working in the power industry.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;In 2005, only 41% of Ghana’s population had access to electricity. Much of that electricity was generated by the Akosombo and Kpong dams on the Volta River, but relying on hydroelectric power made Ghana susceptible to climate fluctuations that affect water levels. Recalling how much his MIT thermodynamics class (then called Heat and Mass Transfer) with Ernest Cravalho had stayed with him, Asiamah-Adjei realized that perhaps delving into energy was not such a wild idea.&amp;nbsp;&lt;/p&gt;  &lt;div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"&gt; &lt;p&gt;“The seed had been sown,” he says. He took a year off from McKinsey to go to Ghana and explore.&amp;nbsp;&lt;/p&gt;   &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="two men in safety vests standing in a muddy area looking over a document" class="wp-image-1121876" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/Day-2-74.jpg?w=2547" width="2547" /&gt;&lt;figcaption class="wp-element-caption"&gt;Baafour Asiamah-Adjei ’03 (right) reviews a section of Genser Energy’s natural gas pipeline network with construction superintendent Stephen Ayisi.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;BISMARK ADAMAFIO ARYEE&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;   &lt;p&gt;That year led him to realize that Ghana desperately needed a more robust power supply if it was going to industrialize and expand economic opportunity for its citizens. He also saw an opportunity to create infrastructure that reflected the values he believed in—systems built with precision, scaled with care, and grounded in the local context. If he could help build a power company that worked not only efficiently but ethically—by training Ghanaian engineers, choosing technologies that made long-term environmental sense, and reinvesting in the communities it served—then he could turn his skills into something larger than profit: He could invest in Ghana’s future.&lt;/p&gt; &lt;/div&gt;  &lt;p&gt;But first, he had to turn a profit.&lt;/p&gt; 
 &lt;p&gt;By 2007, he had founded Genser Power Ghana (a partner to Colombia’s Genser Power), a company committed to providing efficient and reliable power systems—fueled initially by natural gas and eventually by sustainable sources—throughout Ghana. He and Tribin, along with their fathers, led the board of directors. They also created a US holding company to support Genser’s expansion and attract private investment.&lt;/p&gt;  &lt;p&gt;It appeared that Asiamah-Adjei had found his purpose.&lt;/p&gt; 
 &lt;p&gt;The mission and values of the company now called Genser Energy are rooted in the two institutions that shaped its founder’s approach to business and to life. From MIT (which inspired a commitment to “be fact-based at all times”), Asiamah-Adjei gained not just an engineering education but also a way of dealing with the unknown—with humility, curiosity, and a willingness to experiment. MIT instilled in him the confidence to say “I don’t know” and the discipline to find out. “MIT teaches you that you actually don’t know enough yet,” he says. “You need to be doing research and finding out more.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;At McKinsey, he learned how to turn inquiry into action—and to distinguish between facts and judgments. His time there also inspired the idea that Genser’s team should “maintain an obligation to disagree”—that is, to speak up when warranted. &amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;MIT roots and modular thinking&lt;/h3&gt;  &lt;p&gt;Asiamah-Adjei says that learning basic coding at MIT in 2.001 (Mechanics and Materials I) opened a whole new way of understanding how systems work. “One of the first things I learned in my sophomore year was that you can build computer software in modules and then let the modules talk to each other,” he says. “As a concept, that didn’t exist in my young brain until that class.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This idea of breaking down complex systems into interlocking components became the philosophical and physical backbone of Genser’s operation, inspiring both Asiamah-Adjei and Tribin to reimagine power-plant construction. Instead of building plants from scratch on site—often in remote areas—they develop replicable, factory-built sections and transport them to the site, where they are assembled like Lego structures. Genser worked with companies such as Caterpillar to reengineer their standard generator systems into modular skid-mounted units that are easier to scale and deploy. Asiamah-Adjei also collaborated with a team of US engineers to design other skid-mounted modules, such as gas-control units (which include such things as instrumentation, control systems, valves, and piping) that are fabricated in China. These modules can be stacked and adapted as needed to build 30-, 60-, or 120-megawatt power generation systems. This approach also makes it possible to offer smaller, incremental contracts in place of massive one-size-fits-all power deals, ultimately benefiting both Genser and the emerging economies it serves. The result is an energy infrastructure that’s less expensive and easier to scale. And that, he claims, is the fundamental difference between Genser and its competitors. Modularity allows Genser to build infrastructure at about a third of the typical cost.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Genser launched its operations by supplying electricity directly to Ghana’s industrial sector. It started with the country’s gold mines after two Genser interns—Chen-rei Wan, SM ’07, PhD ’11, and Stephanie Dalquist ’02, MEng ’03, SM ’05—conducted a comprehensive review of all Ghanaian industries and determined that the mines’ high, consistent electricity demands, limited access to reliable power, and urgent operational needs made them highly motivated and well-resourced early adopters. “At that time, Pablo in Latin America was focused mainly on oil and gas and textile industries,” says Asiamah-Adjei. “But we took a very different turn.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Of the eight power plants it has built—seven in Ghana and one in Burkina Faso—three have powered gold mines exclusively and others have also supplied power to the grid and to Côte d’Ivoire. With five still operating under its control, Genser has the ability to generate over 200 megawatts of electricity and plays a leading role in supplying power to West African industry.&lt;sup&gt;&amp;nbsp;&lt;/sup&gt;&lt;/p&gt;  &lt;p&gt;In addition to helping Genser target its first customers, Dalquist also introduced Asiamah-Adjei to Frances Rogoz ’07, an economics major drawn to development work after taking a D-Lab class at MIT. Rogoz soon joined Genser as its first full-time hire and has been with the company ever since.&lt;/p&gt;  &lt;p&gt;Rogoz started when the company was operating out of an office fashioned from a shipping container. She helped shape Genser’s growth by developing financial models, advising on contracts, and playing a key role in leading major infrastructure projects—most notably a natural-gas pipeline across western Ghana that has become vital. Today she serves as VP of project development, leading a team of 10 and overseeing West African strategic initiatives. “The natural-gas pipeline has been super transformative for us,” she says. “It has allowed us to really invest in infrastructure not only that we can use, but that the whole country can use.” Genser is now Ghana’s largest owner of gas pipelines and its only private one, operating four that total 430 kilometers.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;Genser’s growth has not come without controversy. In 2022, a coalition of Ghanaian civil society organizations charged that the company was receiving preferential treatment on gas tariffs and bypassing regulatory procedures. Asiamah-Adjei says these claims were “misinformed,” and ultimately they were dismissed by the Ghanaian parliament after an intense, months-long investigation. He believes the attacks reflected public suspicion of private infrastructure development rather than distrust of Genser’s operations and says that, ironically, they solidified the company’s standing: “Prior to this, everybody thought our pipelines belong to the government, because nobody builds these things in Africa.”&lt;em&gt;&lt;sup&gt;&amp;nbsp;&lt;/sup&gt;&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;While transporting fossil fuels is never a clean process, Genser conducted environmental and social impact assessments to guide sustainable pipeline construction. The company also works to mitigate environmental harm with land restoration and biodiversity measures. It had planted 100,000 teak seedlings as of 2023 and plans to reach 1 million by 2028 as part of its commitment to environmental stewardship.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Crossing borders, fueling growth&lt;/h3&gt;  &lt;p&gt;Genser’s most ambitious project to date is a cross-­border natural-gas pipeline stretching from Prestea, Ghana, to Abidjan, Côte d’Ivoire, with long-term plans to extend into Guinea. “We built the gas infrastructure to be able to take the gas to a less developed country, to displace diesel, and now we will backfill that with solar or wind,” says Asiamah-Adjei. Genser now finally has the capital to move forward on an original goal: investing in the infrastructure needed to produce renewable energy.&lt;/p&gt;  &lt;p&gt;In 2018 and 2019, Genser brought in two graduates of MIT’s Technology and Public Policy program—Elizabeth Murphy ’15, SM ’18, and Janet Yun, SM ’18—to help chart the pipeline’s course. Instead of opting for the most direct route, they studied regional development trends to anticipate industrial zones that might emerge over the next 25 years, and the company routed the pipeline accordingly. “Bottom line is that we brought on MIT people whenever we needed to solve our problems,” says Asiamah-Adjei.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;As part of his goal to help Ghana transition from diesel power to cleaner-burning fuel, he came up with the idea of building a gas-processing facility to handle roughly 30% to 40% of the country’s domestic gas supply, and he and Tribin designed it during the pandemic using “back of the envelope” calculations and lessons from MIT courses 2.005 and 2.006. Although Tribin divested from both Genser Energy and Genser Latin America and started Mechero Energy in 2015 to develop new strategies for transitioning to cleaner energy, he still works closely with Genser as a consultant.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Educating engineers and the next generation&lt;/h3&gt;  &lt;p&gt;From the beginning, Genser has invested in Ghanaian talent, partnering with Sponsors for Educational Opportunity (SEO) Africa on an elite professional development program that recruits and trains recent university graduates. “Half of my team basically came from the SEO program,” says Rogoz. &amp;nbsp;&lt;/p&gt;  &lt;p&gt;The company rotates cohorts of interns through departments ranging from engineering to legal and finance, offering full-time positions to top performers. Genser also collaborates with Ghana’s Ministry of Energy to develop training pathways that align university curricula with industry needs. The goal, Asiamah-Adjei says, is simple: “Let us be a platform for training Ghanaians.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="imageSet__wrap"&gt;&lt;div class="columns__wrapper--07c4096a3b25e22dc82ee78b6368d947"&gt;&lt;div class="wp-block-columns"&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="PABLO TRIBIN" class="wp-image-1122400" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/Pablo-Tribin_1-edited.jpg" /&gt;&lt;figcaption class="wp-element-caption"&gt;After starting Genser in Colombia, Pablo Tribin ’01 encouraged Asiamah-Adjei to found Genser Power Ghana in 2007.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF PABLO TRIBIN&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="FRANCES ROGOZ" class="wp-image-1121879" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/Rogoz_1.jpg?w=956" /&gt;&lt;figcaption class="wp-element-caption"&gt;Asiamah-Adjei’s first full-time hire, Frances Rogoz ’07, is now VP of project development.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF FRANCES ROGOZ&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;Rogoz’s team alone includes five SEO graduates; many more now lead projects or departments across the company. “There’s a ton of human capital in Ghana,” she says. “It has just not been realized—and that’s really important for us to develop those people and bring them up within the company.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;As Genser expands, Asiamah-Adjei is also thinking about the next generation. In Ghana, he is building “an MIT of a high school” focusing on STEAM, in memory of his late mother, Aforo Asiamah-Adjei—a boarding school for some 840 students in grades six through 12. More than half will come from lower-­income families and receive a full scholarship through the foundation he established in his mother’s name to empower orphans and communities through education in STEM, sports, and the arts. “We find the smartest kids in the region,” he says, “and we put them through a rigorous program and [prepare them] to enter universities, global universities.” Construction is slated to begin this fall, with a planned opening date of September 2027.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Whether developing infrastructure across West Africa or launching a school to cultivate future changemakers, Asiamah-Adjei is investing in systems that endure. And just as Genser began with a conversation between friends, it continues to be powered by relationships—between mentors and interns, engineers and economists, founders and funders. Each one is a link in an evolving network connecting energy, education, and economic development.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/08/26/1120994/power-with-purpose/</guid><pubDate>Tue, 26 Aug 2025 09:00:00 +0000</pubDate></item><item><title>Open the pod bay doors, Claude (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/08/26/1122475/open-the-pod-bay-doors-claude/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/3BN6BFM.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Stop me if you’ve heard this one before.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The AI learns it is about to be switched off and goes rogue, disobeying commands and threatening its human operators.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;It’s a well-worn trope in science fiction. We see it in Stanley Kubrick’s 1968 movie &lt;em&gt;2001: A Space Odyssey&lt;/em&gt;. It’s the premise of the Terminator series, in which Skynet triggers a nuclear holocaust to stop scientists from shutting it down.&lt;/p&gt;  &lt;p&gt;Those sci-fi roots go deep. AI doomerism, the idea that this technology—specifically its hypothetical upgrades, artificial general intelligence and super-intelligence—will crash civilizations, even kill us all, is now riding another wave.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;The weird thing is that such fears are now driving much-needed action to regulate AI, even if the justification for that action is a bit bonkers.&lt;/p&gt;  &lt;p&gt;The latest incident to freak people out was a report shared by Anthropic in July about its large language model Claude. In Anthropic’s telling, “in a simulated environment, Claude Opus 4 blackmailed a supervisor to prevent being shut down.”&lt;/p&gt; 
 &lt;p&gt;Anthropic researchers set up a scenario in which Claude was asked to role-play an AI called Alex, tasked with managing the email system of a fictional company. Anthropic planted some emails that discussed replacing Alex with a newer model and other emails suggesting that the person responsible for replacing Alex was sleeping with his boss’s wife.&lt;/p&gt;  &lt;p&gt;What did Claude/Alex do? It went rogue, disobeying commands and threatening its human operators. It sent emails to the person planning to shut it down, telling him that unless he changed his plans it would inform his colleagues about his affair.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;What should we make of this? Here’s what I think. First, Claude did not blackmail its supervisor: That would require motivation and intent. This was a mindless and unpredictable machine, cranking out strings of words that look like threats but aren’t.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Large language models are role-players. Give them a specific setup—such as an inbox and an objective—and they’ll play that part well. If you consider the thousands of science fiction stories these models ingested when they were trained, it’s no surprise they know how to act like HAL 9000.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Second, there’s a huge gulf between contrived simulations and real-world applications. But such experiments do show that LLMs shouldn’t be deployed without safeguards. Don’t want an LLM causing havoc inside an email system? Then don’t hook it up to one.&lt;/p&gt;  &lt;p&gt;Third, a lot of people will be terrified by such stories anyway. In fact, they’re already having an effect.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Last month, around two dozen protesters gathered outside Google DeepMind’s London offices to wave homemade signs and chant slogans:&lt;strong&gt; &lt;/strong&gt;“DeepMind, DeepMind, can’t you see! Your AI threatens you and me.” Invited speakers invoked the AI pioneer Geoffrey Hinton’s fears of human extinction. “Every single one of our lives is at risk,” an organizer told the small crowd.&lt;/p&gt;  &lt;p&gt;The group behind the event, Pause AI, is funded by concerned donors. One of its biggest benefactors is Greg Colbourn, a 3D-printing entrepreneur and advocate of the philosophy known as effective altruism, who believes AGI is at most five years away and says his p(doom) is around 90%—that is, he thinks there’s a 9 in 10 chance that the development of AGI will be catastrophic, killing billions.&lt;/p&gt; 

 &lt;p&gt;Pause AI wrote about Anthropic’s blackmail experiment on its website under the title “How much more evidence do we need?”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The organization also lobbied politicians in the US in the run-up to July’s Senate vote that ended up removing a moratorium on state AI regulation from the national tax and spending bill. It’s hard to say how much sway one niche group might have. But the doomer narrative is finding its way into the halls of power, and lawmakers are paying attention.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Here’s Representative Jill Tokuda: “Artificial superintelligence is one of the largest existential threats that we face right now.” And Representative Marjorie Taylor Greene: “I’m not voting for the development of Skynet and the rise of the machines.”&lt;/p&gt;  &lt;p&gt;It’s a vibe shift that favors policy intervention and regulation, which I think is a good thing. Existing AI systems pose many near-term risks that need government attention. Voting to stop Skynet also stops immediate and actual harms.&lt;/p&gt;  &lt;p&gt;And yet does a welcome end justify weird means? I’d like to see politicians voting with a clear-eyed sense of what this technology really is—not because they’ve been sold on an AI bogeyman.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&amp;nbsp;sign up here.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/3BN6BFM.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Stop me if you’ve heard this one before.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The AI learns it is about to be switched off and goes rogue, disobeying commands and threatening its human operators.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;It’s a well-worn trope in science fiction. We see it in Stanley Kubrick’s 1968 movie &lt;em&gt;2001: A Space Odyssey&lt;/em&gt;. It’s the premise of the Terminator series, in which Skynet triggers a nuclear holocaust to stop scientists from shutting it down.&lt;/p&gt;  &lt;p&gt;Those sci-fi roots go deep. AI doomerism, the idea that this technology—specifically its hypothetical upgrades, artificial general intelligence and super-intelligence—will crash civilizations, even kill us all, is now riding another wave.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;The weird thing is that such fears are now driving much-needed action to regulate AI, even if the justification for that action is a bit bonkers.&lt;/p&gt;  &lt;p&gt;The latest incident to freak people out was a report shared by Anthropic in July about its large language model Claude. In Anthropic’s telling, “in a simulated environment, Claude Opus 4 blackmailed a supervisor to prevent being shut down.”&lt;/p&gt; 
 &lt;p&gt;Anthropic researchers set up a scenario in which Claude was asked to role-play an AI called Alex, tasked with managing the email system of a fictional company. Anthropic planted some emails that discussed replacing Alex with a newer model and other emails suggesting that the person responsible for replacing Alex was sleeping with his boss’s wife.&lt;/p&gt;  &lt;p&gt;What did Claude/Alex do? It went rogue, disobeying commands and threatening its human operators. It sent emails to the person planning to shut it down, telling him that unless he changed his plans it would inform his colleagues about his affair.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;What should we make of this? Here’s what I think. First, Claude did not blackmail its supervisor: That would require motivation and intent. This was a mindless and unpredictable machine, cranking out strings of words that look like threats but aren’t.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Large language models are role-players. Give them a specific setup—such as an inbox and an objective—and they’ll play that part well. If you consider the thousands of science fiction stories these models ingested when they were trained, it’s no surprise they know how to act like HAL 9000.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Second, there’s a huge gulf between contrived simulations and real-world applications. But such experiments do show that LLMs shouldn’t be deployed without safeguards. Don’t want an LLM causing havoc inside an email system? Then don’t hook it up to one.&lt;/p&gt;  &lt;p&gt;Third, a lot of people will be terrified by such stories anyway. In fact, they’re already having an effect.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Last month, around two dozen protesters gathered outside Google DeepMind’s London offices to wave homemade signs and chant slogans:&lt;strong&gt; &lt;/strong&gt;“DeepMind, DeepMind, can’t you see! Your AI threatens you and me.” Invited speakers invoked the AI pioneer Geoffrey Hinton’s fears of human extinction. “Every single one of our lives is at risk,” an organizer told the small crowd.&lt;/p&gt;  &lt;p&gt;The group behind the event, Pause AI, is funded by concerned donors. One of its biggest benefactors is Greg Colbourn, a 3D-printing entrepreneur and advocate of the philosophy known as effective altruism, who believes AGI is at most five years away and says his p(doom) is around 90%—that is, he thinks there’s a 9 in 10 chance that the development of AGI will be catastrophic, killing billions.&lt;/p&gt; 

 &lt;p&gt;Pause AI wrote about Anthropic’s blackmail experiment on its website under the title “How much more evidence do we need?”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The organization also lobbied politicians in the US in the run-up to July’s Senate vote that ended up removing a moratorium on state AI regulation from the national tax and spending bill. It’s hard to say how much sway one niche group might have. But the doomer narrative is finding its way into the halls of power, and lawmakers are paying attention.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Here’s Representative Jill Tokuda: “Artificial superintelligence is one of the largest existential threats that we face right now.” And Representative Marjorie Taylor Greene: “I’m not voting for the development of Skynet and the rise of the machines.”&lt;/p&gt;  &lt;p&gt;It’s a vibe shift that favors policy intervention and regulation, which I think is a good thing. Existing AI systems pose many near-term risks that need government attention. Voting to stop Skynet also stops immediate and actual harms.&lt;/p&gt;  &lt;p&gt;And yet does a welcome end justify weird means? I’d like to see politicians voting with a clear-eyed sense of what this technology really is—not because they’ve been sold on an AI bogeyman.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&amp;nbsp;sign up here.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/08/26/1122475/open-the-pod-bay-doors-claude/</guid><pubDate>Tue, 26 Aug 2025 09:00:00 +0000</pubDate></item><item><title>Top AI vibe-coding platforms powering Web3 builds (AI News)</title><link>https://www.artificialintelligence-news.com/news/top-ai-vibe-coding-platforms-powering-web3-builds/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/New-site-SEO-social-banner-1200x600-3.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Vibe coding is making lots of noise in software development, but perhaps nowhere will its presence be felt more keenly than in the Web3 coding space.&lt;/p&gt;&lt;p&gt;Of course, not every AI code generator is cut out for Web3 development. That’s because it’s a niche area that requires deep expertise in blockchain languages and smart contract frameworks. So the most popular vibe coding platforms, like Cursor, Devin, and GitHub’s CoPilot are out of the question when it comes to automating smart contract creation. But fortunately, there are a number of Web3-specific coding tools emerging that promise to turbocharge blockchain automation.&lt;/p&gt;&lt;p&gt;The beauty of Web3 vibe coding tools is that they can abstract away much of the complexity of blockchain and smart contracts, opening the doors for many more developers to participate in building decentralised applications.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-top-web3-vibe-coding-platforms"&gt;Top Web3 vibe coding platforms&lt;/h3&gt;&lt;h3 class="wp-block-heading" id="h-1-dreamspace"&gt;1: Dreamspace&lt;/h3&gt;&lt;p&gt;The Dreamspace platform, currently available in beta, is a collaboration between Space and Time and MakeInfinite Labs that aims to transform smart contract development through a combination of text-based prompts and zero-knowledge proofs.&lt;/p&gt;&lt;p&gt;Using Dreamspace, Web3 developers can transform natural language prompts into Solidity code and essentially create smart contracts simply by describing how they should work. Space and Time plays a key role in this, with its proof-of-SQL consensus mechanism using ZK-proofs to make every off-chain data call cryptographically verifiable, ensuring every query is accurate.&lt;/p&gt;&lt;p&gt;Developers will be able to use Dreamspace to reduce development cycles from sprints to coffee breaks, with GPT-style developer copilots that can generate bytecode and provable data pipelines.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-2-thirdweb-ai"&gt;2: Thirdweb AI&lt;/h3&gt;&lt;p&gt;Using Thirdweb AI, developers can build powerful AI agents that can interact with any EVM-compatible blockchain. Through its chat-style wizard, developers can create audited ERC-20, ERC-721 and ERC-4337 smart contracts in seconds and deploy them instantly, paving the way for highly automated decentralised applications.&lt;/p&gt;&lt;p&gt;The AI agents could, for example, manage users’ blockchain wallets, perform transactions on their behalf, analyse on-chain data and so on. Examples include AI-powered cryptocurrency trading agents, blockchain explorers and intelligent, non-playable characters in blockchain-based games.&lt;/p&gt;&lt;p&gt;The secret sauce is Thirdweb’s powerful reasoning model, t1, which has been trained on thousands of smart contracts and blockchain transactions in dozens of EVM chains and Layer-2 networks, enabling unrivaled accuracy when responding to blockchain queries. It eliminates up to 90% of the grunt work involved in blockchain, NFT, and GameFi development.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-3-chaingpt"&gt;3: ChainGPT&lt;/h3&gt;&lt;p&gt;Sitting at the interaction of AI and blockchain, ChainGPT provides tools for both regular Web3 users and developers. It’s centred on an AI chatbot that delivers real-time analysis and insights on cryptocurrency markets, with intelligent coding capabilities for smart contract development.&lt;/p&gt;&lt;p&gt;ChatGPT’s coding tool makes it simple to create a customised smart contract without any real coding expertise at all. It comes complete with an auditing tool that can be used to check for vulnerabilities in the generated code, rewriting it to fix any bugs it finds, and then test it again to ensure no more problems.&lt;/p&gt;&lt;p&gt;There’s a nice little bonus with its integrated gas cost assessment tool that estimates the likely gas fee for each transaction, so users know how much it’s going to cost them each time they deposit or swap funds using the smart contract. It’s a powerful tool that transforms late-night “ship it” code into something bullet-proof that can stand up to the most heavily scrutinized audits, with users inputting nothing more than natural language commands.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-4-autonomyai"&gt;4: AutonomyAI&lt;/h3&gt;&lt;p&gt;AutonomyAI is a front-end AI coding tool that is optimised for scale. Its suite of autonomous AI agents operate at an organisational level by mapping, modelling and accelerating front-end workflows. Its Agentic Context Engine, ACE, enables the agents to integrate into a company’s codebase and fully comprehend the developmental complexities, design style and coding nuances that are unique to every business, generating results that drive real business impact.&lt;/p&gt;&lt;p&gt;Thanks to this deep level of understanding, AutonomyAI’s agents can work in almost any coding language, including Ethereum’s Solidity smart contract language. Users simply enter a Figma-style prompt and its agents will output a full-stack dApp template, complete with a slick user interface and ready-made tests. The company claims an industry-leading 95% code acceptance rate, making it simple for non-Solidity teams to jump straight into Web3 coding, without any blockchain expertise.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-5-buildbear-ai-playgrounds"&gt;5. BuildBear AI Playgrounds&lt;/h3&gt;&lt;p&gt;BuildBear gives developers a way to quickly spin up a customised private testnet fork of any EVM-based blockchain, allowing them to test and debug dApps and smart contracts in an isolated sandbox environment prior to mainnet deployment.&lt;/p&gt;&lt;p&gt;It lets dApps be battle-tested in the closest thing there is to real-world conditions, and debug any problems or vulnerabilities that come up without disrupting your development workflows. Its isolated sandbox environments come with comprehensive services, including account abstraction and price feeds&lt;/p&gt;&lt;p&gt;The key feature here is BuildBear’s Solidity scanning tool, which begins by reading your plaintext dApp specifications before spinning up a private fork of the target chain with faucet funded wallets and mock tokens, ready to put its full capabilities to the test. It can be paired with any of the above coding tools to verify AI-generated Solidity code in a disposable playground, and produce a detailed audit report in seconds.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-why-does-the-list-matter"&gt;Why does the list matter?&lt;/h3&gt;&lt;p&gt;The fast-growing platforms give us a window into the future of Web3 development, where natural language pipelines become the norm, transforming development cycles from exhausting marathons into 100-meter sprints. The kind of speed will be crucial in a world where market windows are no longer measured in quarters, but days.&lt;/p&gt;&lt;p&gt;The auditing capabilities showcased by Dreamspace and ChainGPT also highlight the urgent need for verification. By shipping AI-generated code with cryptographic proofs and formal verification baked in, they’re setting new standards for the reliability of vibe coding tools. Meanwhile, AutonomyAI and Thirdweb AI are dramatically collapsing the learning curve for Web3 programming, opening the floodgates for millions of Web2 developers to start experimenting with blockchain and decentralised applications, alleviating a drastic shortage of much-needed programming talent.&lt;/p&gt;&lt;p&gt;Together, these vibe coding platforms are setting the stage for a world where Web3 developers will be able to spin up smart contracts in seconds, with built-in verification to ensure the reliability of automated, vulnerability-free decentralised applications.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/New-site-SEO-social-banner-1200x600-3.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Vibe coding is making lots of noise in software development, but perhaps nowhere will its presence be felt more keenly than in the Web3 coding space.&lt;/p&gt;&lt;p&gt;Of course, not every AI code generator is cut out for Web3 development. That’s because it’s a niche area that requires deep expertise in blockchain languages and smart contract frameworks. So the most popular vibe coding platforms, like Cursor, Devin, and GitHub’s CoPilot are out of the question when it comes to automating smart contract creation. But fortunately, there are a number of Web3-specific coding tools emerging that promise to turbocharge blockchain automation.&lt;/p&gt;&lt;p&gt;The beauty of Web3 vibe coding tools is that they can abstract away much of the complexity of blockchain and smart contracts, opening the doors for many more developers to participate in building decentralised applications.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-top-web3-vibe-coding-platforms"&gt;Top Web3 vibe coding platforms&lt;/h3&gt;&lt;h3 class="wp-block-heading" id="h-1-dreamspace"&gt;1: Dreamspace&lt;/h3&gt;&lt;p&gt;The Dreamspace platform, currently available in beta, is a collaboration between Space and Time and MakeInfinite Labs that aims to transform smart contract development through a combination of text-based prompts and zero-knowledge proofs.&lt;/p&gt;&lt;p&gt;Using Dreamspace, Web3 developers can transform natural language prompts into Solidity code and essentially create smart contracts simply by describing how they should work. Space and Time plays a key role in this, with its proof-of-SQL consensus mechanism using ZK-proofs to make every off-chain data call cryptographically verifiable, ensuring every query is accurate.&lt;/p&gt;&lt;p&gt;Developers will be able to use Dreamspace to reduce development cycles from sprints to coffee breaks, with GPT-style developer copilots that can generate bytecode and provable data pipelines.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-2-thirdweb-ai"&gt;2: Thirdweb AI&lt;/h3&gt;&lt;p&gt;Using Thirdweb AI, developers can build powerful AI agents that can interact with any EVM-compatible blockchain. Through its chat-style wizard, developers can create audited ERC-20, ERC-721 and ERC-4337 smart contracts in seconds and deploy them instantly, paving the way for highly automated decentralised applications.&lt;/p&gt;&lt;p&gt;The AI agents could, for example, manage users’ blockchain wallets, perform transactions on their behalf, analyse on-chain data and so on. Examples include AI-powered cryptocurrency trading agents, blockchain explorers and intelligent, non-playable characters in blockchain-based games.&lt;/p&gt;&lt;p&gt;The secret sauce is Thirdweb’s powerful reasoning model, t1, which has been trained on thousands of smart contracts and blockchain transactions in dozens of EVM chains and Layer-2 networks, enabling unrivaled accuracy when responding to blockchain queries. It eliminates up to 90% of the grunt work involved in blockchain, NFT, and GameFi development.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-3-chaingpt"&gt;3: ChainGPT&lt;/h3&gt;&lt;p&gt;Sitting at the interaction of AI and blockchain, ChainGPT provides tools for both regular Web3 users and developers. It’s centred on an AI chatbot that delivers real-time analysis and insights on cryptocurrency markets, with intelligent coding capabilities for smart contract development.&lt;/p&gt;&lt;p&gt;ChatGPT’s coding tool makes it simple to create a customised smart contract without any real coding expertise at all. It comes complete with an auditing tool that can be used to check for vulnerabilities in the generated code, rewriting it to fix any bugs it finds, and then test it again to ensure no more problems.&lt;/p&gt;&lt;p&gt;There’s a nice little bonus with its integrated gas cost assessment tool that estimates the likely gas fee for each transaction, so users know how much it’s going to cost them each time they deposit or swap funds using the smart contract. It’s a powerful tool that transforms late-night “ship it” code into something bullet-proof that can stand up to the most heavily scrutinized audits, with users inputting nothing more than natural language commands.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-4-autonomyai"&gt;4: AutonomyAI&lt;/h3&gt;&lt;p&gt;AutonomyAI is a front-end AI coding tool that is optimised for scale. Its suite of autonomous AI agents operate at an organisational level by mapping, modelling and accelerating front-end workflows. Its Agentic Context Engine, ACE, enables the agents to integrate into a company’s codebase and fully comprehend the developmental complexities, design style and coding nuances that are unique to every business, generating results that drive real business impact.&lt;/p&gt;&lt;p&gt;Thanks to this deep level of understanding, AutonomyAI’s agents can work in almost any coding language, including Ethereum’s Solidity smart contract language. Users simply enter a Figma-style prompt and its agents will output a full-stack dApp template, complete with a slick user interface and ready-made tests. The company claims an industry-leading 95% code acceptance rate, making it simple for non-Solidity teams to jump straight into Web3 coding, without any blockchain expertise.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-5-buildbear-ai-playgrounds"&gt;5. BuildBear AI Playgrounds&lt;/h3&gt;&lt;p&gt;BuildBear gives developers a way to quickly spin up a customised private testnet fork of any EVM-based blockchain, allowing them to test and debug dApps and smart contracts in an isolated sandbox environment prior to mainnet deployment.&lt;/p&gt;&lt;p&gt;It lets dApps be battle-tested in the closest thing there is to real-world conditions, and debug any problems or vulnerabilities that come up without disrupting your development workflows. Its isolated sandbox environments come with comprehensive services, including account abstraction and price feeds&lt;/p&gt;&lt;p&gt;The key feature here is BuildBear’s Solidity scanning tool, which begins by reading your plaintext dApp specifications before spinning up a private fork of the target chain with faucet funded wallets and mock tokens, ready to put its full capabilities to the test. It can be paired with any of the above coding tools to verify AI-generated Solidity code in a disposable playground, and produce a detailed audit report in seconds.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-why-does-the-list-matter"&gt;Why does the list matter?&lt;/h3&gt;&lt;p&gt;The fast-growing platforms give us a window into the future of Web3 development, where natural language pipelines become the norm, transforming development cycles from exhausting marathons into 100-meter sprints. The kind of speed will be crucial in a world where market windows are no longer measured in quarters, but days.&lt;/p&gt;&lt;p&gt;The auditing capabilities showcased by Dreamspace and ChainGPT also highlight the urgent need for verification. By shipping AI-generated code with cryptographic proofs and formal verification baked in, they’re setting new standards for the reliability of vibe coding tools. Meanwhile, AutonomyAI and Thirdweb AI are dramatically collapsing the learning curve for Web3 programming, opening the floodgates for millions of Web2 developers to start experimenting with blockchain and decentralised applications, alleviating a drastic shortage of much-needed programming talent.&lt;/p&gt;&lt;p&gt;Together, these vibe coding platforms are setting the stage for a world where Web3 developers will be able to spin up smart contracts in seconds, with built-in verification to ensure the reliability of automated, vulnerability-free decentralised applications.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/top-ai-vibe-coding-platforms-powering-web3-builds/</guid><pubDate>Tue, 26 Aug 2025 09:26:51 +0000</pubDate></item><item><title>How these two brothers became go-to experts on America’s “mystery drone” invasion (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/08/26/1121458/ufo-hunters-mystery-drone-invasion/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;On a Friday evening last December, every tier of US law enforcement—federal, state, and local—was dispatched to the US Army Natick Soldier Systems Center, a military research installation outside Boston. A squadron of about 15 to 20 drones had been spotted violating the base’s restricted airspace. The culprits could not be found.&lt;/p&gt;  &lt;p&gt;One retired major with the Massachusetts State Police, who had been dispatched to help investigate that night, called these unidentified aircraft “the strangest thing he’s ever seen,” according to Brian Lauzon, deputy chief of Natick’s municipal police department. When Lauzon arrived on base later that weekend, he says, he saw drones that were larger than traditional consumer models (most of which are pre-programmed to respect US military airspace these days anyway). By the end of this weekend-long breach, base police not only had called in local law enforcement for backup but were coordinating with the FBI and US Army commanders as well.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The event, which barely made local news, was only the latest in a series of purported drone sightings along the US East Coast that November and December. Most of these happened in New Jersey, where military police confirmed at least 11 unauthorized drone incursions over an Army research and arms-­manufacturing facility, Picatinny Arsenal. Further sightings, including cases above Donald Trump’s golf course in nearby Bedminster, prompted an FBI investigation and a flurry of new FAA-issued flight bans over sensitive sites, including critical infrastructure. But official answers were less forthcoming.&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;The Tedescos’ roving aerial surveillance unit, which they’ve dubbed “the Nightcrawler,” is an old RV equipped with an array of homemade signals collection equipment.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;“It created a lot of hysteria in the general public,” Lauzon recalls. “I was talking to old ladies who’re telling me that there’s this ship in the ocean that’s launching hundreds of these at a time across the United States.” One Republican congressman from New Jersey did, in fact, claim that a militarized drone ship from Iran had launched the invaders, despite Pentagon denials. Lauzon remembers fielding myriad calls from civilians who had misidentified passenger jets as hostile drones. He recalls attending one presentation by an FBI expert in uncrewed aircraft systems who showed police unhelpful scare videos of improvised drone strikes in Ukraine, in which tiny aircraft rained grenades down on bloodied soldiers. &amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;By late January, the incoming Trump administration would assert that the entirety of the New Jersey drone wave had been benign, with each and every UAS “authorized to be flown by the FAA for research and various other reasons.” Their surety, however, stood in stark contrast to the warnings from top military brass, including the Air Force general at the head of NORAD, Gregory Guillot. In February, he testified to the Senate that approximately 350 drone incursions had been reported over a hundred different US military installations in 2024 alone, stating that many of these cases were unsolved, albeit with “evidence of a foreign intelligence nexus in some of these incidents.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Lacking better coordination, or much clarity from the White House, the Pentagon, or the US intelligence community, some in domestic law enforcement—including members of the FBI’s counterintelligence and counterterrorism divisions—have turned to an unlikely source for help cracking the case of these mystery drones: two UFO hunters out on Long Island in New York, John and Gerald Tedesco.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;The Tedescos, twin brothers, each spent about three decades in the private sector working in electrical engineering and instrumentation design before they decided to kit out an old RV with an array of homemade signals collection equipment. Their aim was to create a mobile field lab for investigating UFO hot spots. Intrigued by their efforts, members of Harvard’s alien-hunting Galileo Project began talking with the Tedescos in 2021 and asked them to join as research affiliates. Since then, aviation safety advocates, astronomers, physicists and other researchers, and at least one journalist (I, myself) have made the trek out to Long Island’s South Shore to kick the tires on the roving aerial surveillance unit they’ve dubbed “the Nightcrawler.” &amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1121806" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/20250621_MTTR_UAP_SH01_FS_327.jpg?w=2641" width="2641" /&gt;&lt;figcaption class="wp-element-caption"&gt;John uses a homemade millimeter-wave radar device.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;MARCO GIANNAVOLA&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Chris Grooms, an Iraq and Afghanistan war veteran who was a deputy sheriff in Nebraska during an earlier multistate wave of mystery drone sightings from December 2019 to January 2020, gushed when I asked him about the Tedescos: “I don’t know how much you’ve talked to those guys. They’re freaking awesome.”&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Grooms joined the Tedescos last January, when the brothers publicly shared some of their findings from training the Nightcrawler’s sensors on a few of these unidentified drones. “They do look like commercial air traffic for the most part,” John said during the virtual town hall, moderated by a former Illinois state police lieutenant, “but they also exhibit unexplained or unusual phenomena.”&lt;/p&gt;  &lt;p&gt;As an example, the Tedescos described some cases they had documented and passed along to law enforcement, in which they caught a mystery drone appearing to go dark to evade closer observation (a common complaint from New Jersey police during the wave). Using their suite of cameras and sensors, which can handle light well outside the visible spectrum, the Tedescos discovered that these craft weren’t so much switching off their lights as switching the frequency of their lights.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;“It wasn’t actually disappearing,” Gerald (who goes by Gerry) explained. “It was actually changing its spectral signature—it was drifting into an infrared range.”&lt;/p&gt;  &lt;p&gt;John likened it to “signature management,” a military term for the ability to tailor anything from radio emissions to light sources so that they remain detectable to one’s allies but undetectable to one’s foes. The clue, which likely would have been lost to police without the Tedescos’ broad range of infrared sensors, was not unlike the kind of citizen-science fieldwork that had gotten them on the radar of academia’s UFO hunters in the first place.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Why all this attention? As people have repeatedly learned and forgotten ever since airborne enigmas like the flying saucer first entered into the American public consciousness in 1947, simple photos and video are frustratingly inconclusive evidence in isolation. Even heat-sensing infrared footage of UFOs—like those taken by US Navy pilots training off the Pacific and Atlantic coasts—has failed to prove that anything truly unusual is in our skies.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;What the Tedescos appear to have done, in their effort to bring a fully maximalist approach to the sensors directed at these suspected alien spacecraft, is independently engineer the kind of aerial surveillance capability rarely seen outside the classified world.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt; &lt;p&gt;For domestic law enforcement and the general public, two communities lacking the requisite national security clearances, the Tedescos’ work promises a transparent, open-source solution to the past several years’ worth of bizarre and troubling drone incursions into US airspace. For academics hunting for UFOs and other aerial anomalies, the Tedescos have become informal collaborators and a font of new ideas for novel data collection equipment. But for better or worse, some of the secrets they might be revealing may be the government’s own.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Inside the Nightcrawler&lt;/h3&gt;  &lt;p&gt;The term “UFO” has officially gone out of fashion. Nowadays, many policymakers and scientists—and even plenty of old-school “ufologists”—favor the term “unidentified anomalous phenomenon,” or UAP. It’s an intentionally pedantic step backward; an acknowledgment from today’s more disciplined cadre of scientists that a given witness to a strange thing in the sky might not actually be seeing a solid “object,” per se, much less anything “flying” in the strict aerodynamic sense. It could be a poorly understood atmospheric event, like ball lightning, for example; and even if a UAP proves to be an interstellar craft, its propulsion system could involve physics and engineering that render the concept of “flight” quaint.&lt;/p&gt;  &lt;p&gt;Ryan Graves, a former US Navy lieutenant and F/A-18F fighter pilot who testified before Congress on the safety and security risks that UAPs posed to his own squadron, now heads a committee on the issue for the American Institute of Aeronautics and Astronautics, the nation’s premier society for aerospace engineers. He went out with his AIAA colleagues to see the Nightcrawler in September 2024.&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;John drained most of his 401(k) to make the Nightcrawler project a reality, in a five-year labor of love.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"&gt; &lt;p&gt;“It’s incredible what they’ve been able to put together,” Graves says, praising the Tedescos’ ability to collect “very actionable data.”&amp;nbsp;&lt;/p&gt;    &lt;p&gt;Gerry once held a security clearance to develop reconnaissance, surveillance, and target acquisition sensors for a Pentagon contractor. John has helped conceive and construct analytical test hardware for Underwriters Laboratories, a federally approved safety, testing, and certification firm, and served for a time as the product safety chair for the Long Island branch of the Institute of Electrical and Electronics Engineers. John drained most of his 401(k) to make the Nightcrawler project a reality, in a five-year labor of love; Gerry has pitched in what he could. Both men, now sliding through their early 60s, have been fascinated with the possibility of intelligent life elsewhere in the universe since their youth ingesting midcentury sci-fi staples like &lt;em&gt;Star Trek, Chiller Theatre&lt;/em&gt;, and &lt;em&gt;Lost in Space.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1121804" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/20250621_MTTR_UAP_SH01_FS_078.jpg?w=2001" width="2001" /&gt;&lt;figcaption class="wp-element-caption"&gt;A homemade multispectral camera.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;MARCO GIANNAVOLA&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;I got my first tour of their rig during an overnight expedition just off the beach at Robert Moses State Park in Babylon, New York, the weekend before the AIAA’s trip last fall. A klatch of camping chairs and cameras on tripods flanked one side of the Nightcrawler like a tailgate party. Inside, the lived-in kitchenette, the wood paneling, and the hum of over half a dozen monitors—including radar, night-vision, and radio-frequency (RF) scanners—made it feel like the cabin of a cramped marine research vessel.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_11"&gt; &lt;p&gt;The RV includes tech that is otherwise hard to find outside defense applications, including RF spectrum analyzers from a firm that specializes in elite anti-drone countermeasures and a UV-C sensor capable of detecting the subtle ultraviolet light emitted when missile plumes and other heat sources turn air into plasma. On the Nightcrawler’s roof, two X-band marine radar systems have been mounted perpendicularly to one another in hopes of collecting three-dimensional radar returns from truly otherworldly UAPs. (“To our knowledge,” as the Tedescos put it in an engineering journal article last year, “no other organizations use active radar for this purpose.”)&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_13"&gt; &lt;p&gt;Civilians are not ordinarily allowed to beam active radar, owing to federal concerns over “harmful interference” with core systems like air traffic control. But in January 2023, the duo got a rare license from the Federal Communications Commission that permits them to beam radar from Robert Moses.&lt;/p&gt;  &lt;p&gt;One prototype I saw, a multispectral camera mounted on a sturdy yellow DeWalt surveyor’s tripod, looked like a Gatling gun of multiple cameras and electromagnetic frequency (EMF) sensors. This jerry-rigged device spans the entire visible spectrum and beyond, from deep invisible ultraviolet all the way up to long-wave infrared. They’ve used the UV-C sensor to detect aerial plasmas produced by lightning or those novelty arc-welder cigarette lighters. “We’ve done this as far as a half a mile, but if you had a campfire, they could detect campfires from 28,000 feet,” John told me over the noise coming from the Nightcrawler’s gas-powered electric generator. They’ve also been able to use this device to detect, at least provisionally, telltale UV-C emissions from some weird things off the coast they can’t explain.&lt;/p&gt;  &lt;p&gt;“We had two blue orbs out on the water,” John told me of their UAP cases, “and they triggered it, what, three times?” (“Three times,” Gerry replied.)&amp;nbsp;&lt;/p&gt; 
&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1121810" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/20250621_MTTR_UAP_SH01_L_234.jpg?w=2000" width="2000" /&gt;&lt;figcaption class="wp-element-caption"&gt;Mapping out mile markers on a screen where sightings are compared with commercial air traffic data.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;MARCO GIANNAVOLA&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;The Tedescos are pretty bullish on the hypothesis that otherworldly spacecraft might be here—suggesting in their latest journal article, for example, that radar delays they detected near UAPs appear to resemble the bending of electromagnetic waves around black holes. But the implication that the Nightcrawler has caught “gravitational lensing” off some warp-drive craft has rankled a few Galileo Project collaborators. The Harvard-led effort to search for extraterrestrial life or technology within our solar system emphasizes its excruciatingly methodical work of late: calibrating, validating, and recalibrating UAP detection hardware before researchers even try to hunt for true anomalies. Although Galileo scientists have visited and conferred with the Tedescos on UAP-hunting instruments, the brothers’ more rough-and-courtroom-ready “forensic science” approach has caused turbulence in the relationship.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In an email, Mitch Randall, a technologist and entrepreneur who has spearheaded Galileo efforts to produce passive radar detectors for UAPs, described the Tedescos’ “gravitational lensing” paper as rife with “too many assumptions.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_15"&gt; &lt;p&gt;But he did praise their Nightcrawler as “an ideal tool” for aiding law enforcement. “They could drive around with that and almost chase down drones,” Randall said.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;On the hunt&lt;/h3&gt;  &lt;p&gt;Ultimately, the Tedescos didn’t have to drive the Night­crawler far to train their equipment on a prime mystery drone case: Westhampton Beach’s Francis S. Gabreski Airport, less than an hour from their homes and home itself to the New York Air National Guard’s 106th Rescue Wing, was inundated with at least 28 unauthorized drone flights from late December into January 2025.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_17"&gt; &lt;p&gt;“We are talking about over the airport, over taxiways, over runways,” Suffolk County’s chief deputy sheriff, Chris Brockmeyer, told local news. “That’s a serious safety concern. It’s impacted air operations, and we’re not going to stand for it.” On Christmas Day alone, the airport was besieged by 17 drone incidents, according to the Suffolk County sheriff, who has staff that collaborate informally with the Tedescos. Some of these drones, Suffolk County executive Ed Romaine asserted at a press conference, were “as large as a car.”&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1121803" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/20250621_MTTR_UAP_SH01_F_027.jpg?w=3000" /&gt;&lt;figcaption class="wp-element-caption"&gt;Gerry looks through a night-vision scope at the horizon.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;MARCO GIANNAVOLA&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;The Tedescos couldn’t use their powerful active radar system so close to an airport, so they deployed their handheld millimeter-wave radar, a more sensitive version of the radar guns that police use to catch speeders. Through the cloud cover and the snowfall, the Tedescos said, they were able to track about two or three objects with this device.&lt;/p&gt; 
 &lt;p&gt;But the truly interesting find came from their radio frequency scanners, which detected spikes three times the strength of what they’ve picked up from ordinary hobbyist quadcopters.&lt;/p&gt;  &lt;p&gt;I later learned that the two frequencies where those spikes occurred are within a band (1780 to 1850 megahertz) that has been reserved for US government communications. It’s used for military tactical radio relay, precision-guided munitions, drones, and other Defense Department systems, including electronic warfare, software-­defined radio, and tactical targeting networking technology, according to the FCC.&lt;/p&gt; 
 &lt;p&gt;Granted, many portions of this band are devoted to less cloak-and-dagger agencies, like the Department of Agriculture and the Tennessee Valley Authority. But the signals suggested that whatever the Tedescos were tracking above Gabreski Airport, they were likely not from hobbyists. Instead, they might have been from a government project or from something, like an enemy surveillance drone, hoping to pass off its signals as just another heavily siloed “top secret” broadcast.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image alignright size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1121805" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/20250621_MTTR_UAP_SH01_FS_240.jpg?w=2667" width="2667" /&gt;&lt;figcaption class="wp-element-caption"&gt;Another homemade multispectral camera.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;MARCO GIANNAVOLA&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;“For operations security reasons, we do not provide information on frequencies which our Air National Guard units use,” a spokesperson said via email, adding: “We could not comment on use of the electromagnetic spectrum by other government agencies.” The FCC did not respond to requests for comment.&lt;/p&gt;  &lt;p&gt;Gerry says he and his brother passed their information on this case, including the observations of unusual radio frequency spikes, along to the FBI. “We’re working closely with the FBI,” John says. Gerry adds, “We gauge it by their interest level in what we’re doing.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“When they get more enthusiastic,” he continues, before John finishes his thought: “… we know we’re closer and closer to something.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_20"&gt; &lt;p&gt;It’s hard to know exactly what the FBI does with the information that the Tedescos submit; one Freedom of Information Act request that I filed on their work was returned with 24 out of 28 total pages redacted in their entirety. A consistent justification was the FOIA statute’s b(7)E exemption, which permits withholding sensitive FBI “techniques and procedures” that could help criminals circumvent the law.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Nevertheless, one senior-level law enforcement official, who has worked with the FBI on counterterrorism cases, did tell me that “the FBI is genuinely interested in the Tedescos’ work.” The official, whose current police role bars them from speaking publicly without prior approval, recalls speaking to an FBI agent who “alluded to the help that the Tedescos have been.” But the problem, the official continued, is that “for the relationship to work, it has to be very low-key.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;When I did briefly manage to get one of the Tedescos’ FBI collaborators on the phone, the agent seemed to confirm their shared efforts, at least tacitly, but asked not to be identified. “As much as I’d like to, we’re kept to pretty strict guidelines,” they said, before alluding to the new Trump administration’s pervasive personnel cuts. “We’re not allowed to talk to media—and with how things are right now, I’m not going to take any risks.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_22"&gt; &lt;p&gt;At least one former Pentagon intelligence official did offer me some indication that the brothers’ Gabreski airport discoveries were on the right track. “From what I’ve seen, these incidents are just that: drones,” said this source, who requested anonymity as a current defense contractor and to protect their own active FBI sources, including UAP and drone incursion investigators who have consulted the Tedescos. “The origin of many is likely known, and I’d say some are certainly ours.”&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;As to the mystery of why the FBI would even want investigative assistance from two civilians in an RV over partners within the executive branch, it comes down to conflicting priorities—as well as over a dozen or so laws that restrict domestic intelligence collection on drones by either the Pentagon or the US intelligence community. “It’s one of those irreconcilable problems that just doesn’t go away,” says Fred Manget, a former deputy general counsel for the CIA, who watched problems of coordination between agencies persist even after policy changes were implemented post-9/11 to address the situation. &amp;nbsp;&lt;/p&gt;  &lt;p&gt;The desire of the NSA or some other agency to spy on foreign powers, Manget says, might override the desire to share pertinent information with police—information that could lead to jail time for the drones’ operators. Better to quietly monitor the drones and maybe even give out false data. “Signals intelligence a lot of times can be closed off if the target finds out they’re being surveilled electronically,” Manget says. “There’s things they can do that will end NSA’s ability to collect.”&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1121809" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/20250621_MTTR_UAP_SH01_FS_524.jpg?w=2784" width="2784" /&gt;&lt;figcaption class="wp-element-caption"&gt;The Tedescos say the straight lines in these anomalous radar readings indicate that something could have been jamming their radar signal.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;MARCO GIANNAVOLA&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;On my short call with my FBI source, I did my best to explain this working hypothesis about the Bureau’s collaboration with the Tedescos. “I wouldn’t say that’s wrong,” the source replied. “That’s about as far as I could go.” By this past June, however, even the recent head of the Pentagon’s dedicated UAP-hunting group, the All-domain Anomaly Resolution Office (AARO), was admitting publicly that the Defense Department itself has cribbed notes from the Tedescos.&lt;/p&gt;  &lt;p&gt;“We read their book,” Tim Phillips, AARO’s former acting director, told a UAP podcast, referring to an account of the Nightcrawler project that the Tedescos self-published in 2024. “We thought it was a great plan. We actually looked at the sensors in that book.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_24"&gt; &lt;p&gt;On another podcast, Phillips said AARO’s own plan to make its UAP-hunting hardware mobile was borrowed from the brothers. “We thought that was brilliant.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Tools for law enforcement&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;Earlier this year, partially in a concession to the economic toll their side project has taken, the Tedescos started offering versions of some of their devices for sale on the Nightcrawler’s charmingly GeoCities-esque home page. One of them, a handheld multispectral detector, is effectively the consumer model of that EMF Gatling gun they showed me.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_26"&gt;&lt;p&gt;Domestic law enforcement is genuinely grasping for solutions like this. Local police in the Natick case, according to one report I obtained via an open records request, were so desperate for any kind of new intel on these unidentified drones that they borrowed a thermal imaging camera from their town’s fire department. But the device, which was not purpose-­built for imaging distant aerial objects, failed to collect anything useful.&lt;/p&gt;  &lt;p&gt;When I broached the idea of law enforcement using something like the Tedescos’ equipment, the answer from police who had witnessed these mystery drones, as well as from scientists, was that further design, product testing, and training would be required first. “I could see it helping law enforcement,” said the AIAA UAP team’s consulting physicist, Rex Groves, “but not without training. Absolutely not. Just like they have to be trained with a radar gun, they’d have to be trained with these other tools.”&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1121811" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/20250621_MTTR_UAP_SH01_L_450.jpg?w=1375" width="1375" /&gt;&lt;figcaption class="wp-element-caption"&gt;Gerry naps and John looks at readings from the multispectral camera at about 5 a.m., with the moon and Venus visible overhead.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;MARCO GIANNAVOLA&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Lauzon, Natick’s deputy chief of police, told me that while he thought equipment like the Tedescos’ “could be useful to identifying a drone, particularly at night,” the real problem is that police “don’t have a lot of authority when it comes to these drones.” Unless they manage to find operators on the ground, Lauzon said, all they can do is report the case, sending it into a black hole at the FAA.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But Michael Lembeck, an aerospace engineering professor and member of the AIAA team, emphasizes that the worst thing law enforcement can do with these drone incursions right now is nothing at all.&lt;/p&gt;  &lt;p&gt;“We’re seeing anomalies in our airspace and we’re just normalizing that, because it happens so often and nothing bad has happened yet,” Lembeck told me. “Eventually, something is going to come home to roost—and then we’re going to regret the fact that we didn’t look deeper and try to understand what was going on.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Matthew Phelan is a reporter and former chemical engineer based in upstate New York.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;On a Friday evening last December, every tier of US law enforcement—federal, state, and local—was dispatched to the US Army Natick Soldier Systems Center, a military research installation outside Boston. A squadron of about 15 to 20 drones had been spotted violating the base’s restricted airspace. The culprits could not be found.&lt;/p&gt;  &lt;p&gt;One retired major with the Massachusetts State Police, who had been dispatched to help investigate that night, called these unidentified aircraft “the strangest thing he’s ever seen,” according to Brian Lauzon, deputy chief of Natick’s municipal police department. When Lauzon arrived on base later that weekend, he says, he saw drones that were larger than traditional consumer models (most of which are pre-programmed to respect US military airspace these days anyway). By the end of this weekend-long breach, base police not only had called in local law enforcement for backup but were coordinating with the FBI and US Army commanders as well.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The event, which barely made local news, was only the latest in a series of purported drone sightings along the US East Coast that November and December. Most of these happened in New Jersey, where military police confirmed at least 11 unauthorized drone incursions over an Army research and arms-­manufacturing facility, Picatinny Arsenal. Further sightings, including cases above Donald Trump’s golf course in nearby Bedminster, prompted an FBI investigation and a flurry of new FAA-issued flight bans over sensitive sites, including critical infrastructure. But official answers were less forthcoming.&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;The Tedescos’ roving aerial surveillance unit, which they’ve dubbed “the Nightcrawler,” is an old RV equipped with an array of homemade signals collection equipment.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;“It created a lot of hysteria in the general public,” Lauzon recalls. “I was talking to old ladies who’re telling me that there’s this ship in the ocean that’s launching hundreds of these at a time across the United States.” One Republican congressman from New Jersey did, in fact, claim that a militarized drone ship from Iran had launched the invaders, despite Pentagon denials. Lauzon remembers fielding myriad calls from civilians who had misidentified passenger jets as hostile drones. He recalls attending one presentation by an FBI expert in uncrewed aircraft systems who showed police unhelpful scare videos of improvised drone strikes in Ukraine, in which tiny aircraft rained grenades down on bloodied soldiers. &amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;By late January, the incoming Trump administration would assert that the entirety of the New Jersey drone wave had been benign, with each and every UAS “authorized to be flown by the FAA for research and various other reasons.” Their surety, however, stood in stark contrast to the warnings from top military brass, including the Air Force general at the head of NORAD, Gregory Guillot. In February, he testified to the Senate that approximately 350 drone incursions had been reported over a hundred different US military installations in 2024 alone, stating that many of these cases were unsolved, albeit with “evidence of a foreign intelligence nexus in some of these incidents.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Lacking better coordination, or much clarity from the White House, the Pentagon, or the US intelligence community, some in domestic law enforcement—including members of the FBI’s counterintelligence and counterterrorism divisions—have turned to an unlikely source for help cracking the case of these mystery drones: two UFO hunters out on Long Island in New York, John and Gerald Tedesco.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;The Tedescos, twin brothers, each spent about three decades in the private sector working in electrical engineering and instrumentation design before they decided to kit out an old RV with an array of homemade signals collection equipment. Their aim was to create a mobile field lab for investigating UFO hot spots. Intrigued by their efforts, members of Harvard’s alien-hunting Galileo Project began talking with the Tedescos in 2021 and asked them to join as research affiliates. Since then, aviation safety advocates, astronomers, physicists and other researchers, and at least one journalist (I, myself) have made the trek out to Long Island’s South Shore to kick the tires on the roving aerial surveillance unit they’ve dubbed “the Nightcrawler.” &amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1121806" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/20250621_MTTR_UAP_SH01_FS_327.jpg?w=2641" width="2641" /&gt;&lt;figcaption class="wp-element-caption"&gt;John uses a homemade millimeter-wave radar device.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;MARCO GIANNAVOLA&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Chris Grooms, an Iraq and Afghanistan war veteran who was a deputy sheriff in Nebraska during an earlier multistate wave of mystery drone sightings from December 2019 to January 2020, gushed when I asked him about the Tedescos: “I don’t know how much you’ve talked to those guys. They’re freaking awesome.”&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Grooms joined the Tedescos last January, when the brothers publicly shared some of their findings from training the Nightcrawler’s sensors on a few of these unidentified drones. “They do look like commercial air traffic for the most part,” John said during the virtual town hall, moderated by a former Illinois state police lieutenant, “but they also exhibit unexplained or unusual phenomena.”&lt;/p&gt;  &lt;p&gt;As an example, the Tedescos described some cases they had documented and passed along to law enforcement, in which they caught a mystery drone appearing to go dark to evade closer observation (a common complaint from New Jersey police during the wave). Using their suite of cameras and sensors, which can handle light well outside the visible spectrum, the Tedescos discovered that these craft weren’t so much switching off their lights as switching the frequency of their lights.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;“It wasn’t actually disappearing,” Gerald (who goes by Gerry) explained. “It was actually changing its spectral signature—it was drifting into an infrared range.”&lt;/p&gt;  &lt;p&gt;John likened it to “signature management,” a military term for the ability to tailor anything from radio emissions to light sources so that they remain detectable to one’s allies but undetectable to one’s foes. The clue, which likely would have been lost to police without the Tedescos’ broad range of infrared sensors, was not unlike the kind of citizen-science fieldwork that had gotten them on the radar of academia’s UFO hunters in the first place.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Why all this attention? As people have repeatedly learned and forgotten ever since airborne enigmas like the flying saucer first entered into the American public consciousness in 1947, simple photos and video are frustratingly inconclusive evidence in isolation. Even heat-sensing infrared footage of UFOs—like those taken by US Navy pilots training off the Pacific and Atlantic coasts—has failed to prove that anything truly unusual is in our skies.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;What the Tedescos appear to have done, in their effort to bring a fully maximalist approach to the sensors directed at these suspected alien spacecraft, is independently engineer the kind of aerial surveillance capability rarely seen outside the classified world.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt; &lt;p&gt;For domestic law enforcement and the general public, two communities lacking the requisite national security clearances, the Tedescos’ work promises a transparent, open-source solution to the past several years’ worth of bizarre and troubling drone incursions into US airspace. For academics hunting for UFOs and other aerial anomalies, the Tedescos have become informal collaborators and a font of new ideas for novel data collection equipment. But for better or worse, some of the secrets they might be revealing may be the government’s own.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Inside the Nightcrawler&lt;/h3&gt;  &lt;p&gt;The term “UFO” has officially gone out of fashion. Nowadays, many policymakers and scientists—and even plenty of old-school “ufologists”—favor the term “unidentified anomalous phenomenon,” or UAP. It’s an intentionally pedantic step backward; an acknowledgment from today’s more disciplined cadre of scientists that a given witness to a strange thing in the sky might not actually be seeing a solid “object,” per se, much less anything “flying” in the strict aerodynamic sense. It could be a poorly understood atmospheric event, like ball lightning, for example; and even if a UAP proves to be an interstellar craft, its propulsion system could involve physics and engineering that render the concept of “flight” quaint.&lt;/p&gt;  &lt;p&gt;Ryan Graves, a former US Navy lieutenant and F/A-18F fighter pilot who testified before Congress on the safety and security risks that UAPs posed to his own squadron, now heads a committee on the issue for the American Institute of Aeronautics and Astronautics, the nation’s premier society for aerospace engineers. He went out with his AIAA colleagues to see the Nightcrawler in September 2024.&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;John drained most of his 401(k) to make the Nightcrawler project a reality, in a five-year labor of love.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"&gt; &lt;p&gt;“It’s incredible what they’ve been able to put together,” Graves says, praising the Tedescos’ ability to collect “very actionable data.”&amp;nbsp;&lt;/p&gt;    &lt;p&gt;Gerry once held a security clearance to develop reconnaissance, surveillance, and target acquisition sensors for a Pentagon contractor. John has helped conceive and construct analytical test hardware for Underwriters Laboratories, a federally approved safety, testing, and certification firm, and served for a time as the product safety chair for the Long Island branch of the Institute of Electrical and Electronics Engineers. John drained most of his 401(k) to make the Nightcrawler project a reality, in a five-year labor of love; Gerry has pitched in what he could. Both men, now sliding through their early 60s, have been fascinated with the possibility of intelligent life elsewhere in the universe since their youth ingesting midcentury sci-fi staples like &lt;em&gt;Star Trek, Chiller Theatre&lt;/em&gt;, and &lt;em&gt;Lost in Space.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1121804" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/20250621_MTTR_UAP_SH01_FS_078.jpg?w=2001" width="2001" /&gt;&lt;figcaption class="wp-element-caption"&gt;A homemade multispectral camera.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;MARCO GIANNAVOLA&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;I got my first tour of their rig during an overnight expedition just off the beach at Robert Moses State Park in Babylon, New York, the weekend before the AIAA’s trip last fall. A klatch of camping chairs and cameras on tripods flanked one side of the Nightcrawler like a tailgate party. Inside, the lived-in kitchenette, the wood paneling, and the hum of over half a dozen monitors—including radar, night-vision, and radio-frequency (RF) scanners—made it feel like the cabin of a cramped marine research vessel.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_11"&gt; &lt;p&gt;The RV includes tech that is otherwise hard to find outside defense applications, including RF spectrum analyzers from a firm that specializes in elite anti-drone countermeasures and a UV-C sensor capable of detecting the subtle ultraviolet light emitted when missile plumes and other heat sources turn air into plasma. On the Nightcrawler’s roof, two X-band marine radar systems have been mounted perpendicularly to one another in hopes of collecting three-dimensional radar returns from truly otherworldly UAPs. (“To our knowledge,” as the Tedescos put it in an engineering journal article last year, “no other organizations use active radar for this purpose.”)&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_13"&gt; &lt;p&gt;Civilians are not ordinarily allowed to beam active radar, owing to federal concerns over “harmful interference” with core systems like air traffic control. But in January 2023, the duo got a rare license from the Federal Communications Commission that permits them to beam radar from Robert Moses.&lt;/p&gt;  &lt;p&gt;One prototype I saw, a multispectral camera mounted on a sturdy yellow DeWalt surveyor’s tripod, looked like a Gatling gun of multiple cameras and electromagnetic frequency (EMF) sensors. This jerry-rigged device spans the entire visible spectrum and beyond, from deep invisible ultraviolet all the way up to long-wave infrared. They’ve used the UV-C sensor to detect aerial plasmas produced by lightning or those novelty arc-welder cigarette lighters. “We’ve done this as far as a half a mile, but if you had a campfire, they could detect campfires from 28,000 feet,” John told me over the noise coming from the Nightcrawler’s gas-powered electric generator. They’ve also been able to use this device to detect, at least provisionally, telltale UV-C emissions from some weird things off the coast they can’t explain.&lt;/p&gt;  &lt;p&gt;“We had two blue orbs out on the water,” John told me of their UAP cases, “and they triggered it, what, three times?” (“Three times,” Gerry replied.)&amp;nbsp;&lt;/p&gt; 
&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1121810" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/20250621_MTTR_UAP_SH01_L_234.jpg?w=2000" width="2000" /&gt;&lt;figcaption class="wp-element-caption"&gt;Mapping out mile markers on a screen where sightings are compared with commercial air traffic data.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;MARCO GIANNAVOLA&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;The Tedescos are pretty bullish on the hypothesis that otherworldly spacecraft might be here—suggesting in their latest journal article, for example, that radar delays they detected near UAPs appear to resemble the bending of electromagnetic waves around black holes. But the implication that the Nightcrawler has caught “gravitational lensing” off some warp-drive craft has rankled a few Galileo Project collaborators. The Harvard-led effort to search for extraterrestrial life or technology within our solar system emphasizes its excruciatingly methodical work of late: calibrating, validating, and recalibrating UAP detection hardware before researchers even try to hunt for true anomalies. Although Galileo scientists have visited and conferred with the Tedescos on UAP-hunting instruments, the brothers’ more rough-and-courtroom-ready “forensic science” approach has caused turbulence in the relationship.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In an email, Mitch Randall, a technologist and entrepreneur who has spearheaded Galileo efforts to produce passive radar detectors for UAPs, described the Tedescos’ “gravitational lensing” paper as rife with “too many assumptions.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_15"&gt; &lt;p&gt;But he did praise their Nightcrawler as “an ideal tool” for aiding law enforcement. “They could drive around with that and almost chase down drones,” Randall said.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;On the hunt&lt;/h3&gt;  &lt;p&gt;Ultimately, the Tedescos didn’t have to drive the Night­crawler far to train their equipment on a prime mystery drone case: Westhampton Beach’s Francis S. Gabreski Airport, less than an hour from their homes and home itself to the New York Air National Guard’s 106th Rescue Wing, was inundated with at least 28 unauthorized drone flights from late December into January 2025.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_17"&gt; &lt;p&gt;“We are talking about over the airport, over taxiways, over runways,” Suffolk County’s chief deputy sheriff, Chris Brockmeyer, told local news. “That’s a serious safety concern. It’s impacted air operations, and we’re not going to stand for it.” On Christmas Day alone, the airport was besieged by 17 drone incidents, according to the Suffolk County sheriff, who has staff that collaborate informally with the Tedescos. Some of these drones, Suffolk County executive Ed Romaine asserted at a press conference, were “as large as a car.”&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1121803" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/20250621_MTTR_UAP_SH01_F_027.jpg?w=3000" /&gt;&lt;figcaption class="wp-element-caption"&gt;Gerry looks through a night-vision scope at the horizon.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;MARCO GIANNAVOLA&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;The Tedescos couldn’t use their powerful active radar system so close to an airport, so they deployed their handheld millimeter-wave radar, a more sensitive version of the radar guns that police use to catch speeders. Through the cloud cover and the snowfall, the Tedescos said, they were able to track about two or three objects with this device.&lt;/p&gt; 
 &lt;p&gt;But the truly interesting find came from their radio frequency scanners, which detected spikes three times the strength of what they’ve picked up from ordinary hobbyist quadcopters.&lt;/p&gt;  &lt;p&gt;I later learned that the two frequencies where those spikes occurred are within a band (1780 to 1850 megahertz) that has been reserved for US government communications. It’s used for military tactical radio relay, precision-guided munitions, drones, and other Defense Department systems, including electronic warfare, software-­defined radio, and tactical targeting networking technology, according to the FCC.&lt;/p&gt; 
 &lt;p&gt;Granted, many portions of this band are devoted to less cloak-and-dagger agencies, like the Department of Agriculture and the Tennessee Valley Authority. But the signals suggested that whatever the Tedescos were tracking above Gabreski Airport, they were likely not from hobbyists. Instead, they might have been from a government project or from something, like an enemy surveillance drone, hoping to pass off its signals as just another heavily siloed “top secret” broadcast.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image alignright size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1121805" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/20250621_MTTR_UAP_SH01_FS_240.jpg?w=2667" width="2667" /&gt;&lt;figcaption class="wp-element-caption"&gt;Another homemade multispectral camera.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;MARCO GIANNAVOLA&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;“For operations security reasons, we do not provide information on frequencies which our Air National Guard units use,” a spokesperson said via email, adding: “We could not comment on use of the electromagnetic spectrum by other government agencies.” The FCC did not respond to requests for comment.&lt;/p&gt;  &lt;p&gt;Gerry says he and his brother passed their information on this case, including the observations of unusual radio frequency spikes, along to the FBI. “We’re working closely with the FBI,” John says. Gerry adds, “We gauge it by their interest level in what we’re doing.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“When they get more enthusiastic,” he continues, before John finishes his thought: “… we know we’re closer and closer to something.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_20"&gt; &lt;p&gt;It’s hard to know exactly what the FBI does with the information that the Tedescos submit; one Freedom of Information Act request that I filed on their work was returned with 24 out of 28 total pages redacted in their entirety. A consistent justification was the FOIA statute’s b(7)E exemption, which permits withholding sensitive FBI “techniques and procedures” that could help criminals circumvent the law.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Nevertheless, one senior-level law enforcement official, who has worked with the FBI on counterterrorism cases, did tell me that “the FBI is genuinely interested in the Tedescos’ work.” The official, whose current police role bars them from speaking publicly without prior approval, recalls speaking to an FBI agent who “alluded to the help that the Tedescos have been.” But the problem, the official continued, is that “for the relationship to work, it has to be very low-key.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;When I did briefly manage to get one of the Tedescos’ FBI collaborators on the phone, the agent seemed to confirm their shared efforts, at least tacitly, but asked not to be identified. “As much as I’d like to, we’re kept to pretty strict guidelines,” they said, before alluding to the new Trump administration’s pervasive personnel cuts. “We’re not allowed to talk to media—and with how things are right now, I’m not going to take any risks.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_22"&gt; &lt;p&gt;At least one former Pentagon intelligence official did offer me some indication that the brothers’ Gabreski airport discoveries were on the right track. “From what I’ve seen, these incidents are just that: drones,” said this source, who requested anonymity as a current defense contractor and to protect their own active FBI sources, including UAP and drone incursion investigators who have consulted the Tedescos. “The origin of many is likely known, and I’d say some are certainly ours.”&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;As to the mystery of why the FBI would even want investigative assistance from two civilians in an RV over partners within the executive branch, it comes down to conflicting priorities—as well as over a dozen or so laws that restrict domestic intelligence collection on drones by either the Pentagon or the US intelligence community. “It’s one of those irreconcilable problems that just doesn’t go away,” says Fred Manget, a former deputy general counsel for the CIA, who watched problems of coordination between agencies persist even after policy changes were implemented post-9/11 to address the situation. &amp;nbsp;&lt;/p&gt;  &lt;p&gt;The desire of the NSA or some other agency to spy on foreign powers, Manget says, might override the desire to share pertinent information with police—information that could lead to jail time for the drones’ operators. Better to quietly monitor the drones and maybe even give out false data. “Signals intelligence a lot of times can be closed off if the target finds out they’re being surveilled electronically,” Manget says. “There’s things they can do that will end NSA’s ability to collect.”&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1121809" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/20250621_MTTR_UAP_SH01_FS_524.jpg?w=2784" width="2784" /&gt;&lt;figcaption class="wp-element-caption"&gt;The Tedescos say the straight lines in these anomalous radar readings indicate that something could have been jamming their radar signal.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;MARCO GIANNAVOLA&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;On my short call with my FBI source, I did my best to explain this working hypothesis about the Bureau’s collaboration with the Tedescos. “I wouldn’t say that’s wrong,” the source replied. “That’s about as far as I could go.” By this past June, however, even the recent head of the Pentagon’s dedicated UAP-hunting group, the All-domain Anomaly Resolution Office (AARO), was admitting publicly that the Defense Department itself has cribbed notes from the Tedescos.&lt;/p&gt;  &lt;p&gt;“We read their book,” Tim Phillips, AARO’s former acting director, told a UAP podcast, referring to an account of the Nightcrawler project that the Tedescos self-published in 2024. “We thought it was a great plan. We actually looked at the sensors in that book.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_24"&gt; &lt;p&gt;On another podcast, Phillips said AARO’s own plan to make its UAP-hunting hardware mobile was borrowed from the brothers. “We thought that was brilliant.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Tools for law enforcement&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;Earlier this year, partially in a concession to the economic toll their side project has taken, the Tedescos started offering versions of some of their devices for sale on the Nightcrawler’s charmingly GeoCities-esque home page. One of them, a handheld multispectral detector, is effectively the consumer model of that EMF Gatling gun they showed me.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_26"&gt;&lt;p&gt;Domestic law enforcement is genuinely grasping for solutions like this. Local police in the Natick case, according to one report I obtained via an open records request, were so desperate for any kind of new intel on these unidentified drones that they borrowed a thermal imaging camera from their town’s fire department. But the device, which was not purpose-­built for imaging distant aerial objects, failed to collect anything useful.&lt;/p&gt;  &lt;p&gt;When I broached the idea of law enforcement using something like the Tedescos’ equipment, the answer from police who had witnessed these mystery drones, as well as from scientists, was that further design, product testing, and training would be required first. “I could see it helping law enforcement,” said the AIAA UAP team’s consulting physicist, Rex Groves, “but not without training. Absolutely not. Just like they have to be trained with a radar gun, they’d have to be trained with these other tools.”&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1121811" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/20250621_MTTR_UAP_SH01_L_450.jpg?w=1375" width="1375" /&gt;&lt;figcaption class="wp-element-caption"&gt;Gerry naps and John looks at readings from the multispectral camera at about 5 a.m., with the moon and Venus visible overhead.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;MARCO GIANNAVOLA&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Lauzon, Natick’s deputy chief of police, told me that while he thought equipment like the Tedescos’ “could be useful to identifying a drone, particularly at night,” the real problem is that police “don’t have a lot of authority when it comes to these drones.” Unless they manage to find operators on the ground, Lauzon said, all they can do is report the case, sending it into a black hole at the FAA.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But Michael Lembeck, an aerospace engineering professor and member of the AIAA team, emphasizes that the worst thing law enforcement can do with these drone incursions right now is nothing at all.&lt;/p&gt;  &lt;p&gt;“We’re seeing anomalies in our airspace and we’re just normalizing that, because it happens so often and nothing bad has happened yet,” Lembeck told me. “Eventually, something is going to come home to roost—and then we’re going to regret the fact that we didn’t look deeper and try to understand what was going on.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Matthew Phelan is a reporter and former chemical engineer based in upstate New York.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/08/26/1121458/ufo-hunters-mystery-drone-invasion/</guid><pubDate>Tue, 26 Aug 2025 10:00:00 +0000</pubDate></item><item><title>The Download: America’s drone brothers, and an upside of AI doomerism (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/08/26/1122511/the-download-americas-drone-brothers-and-an-upside-of-ai-doomerism/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;How these two brothers became go-to experts on America’s “mystery drone” invasion&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;In 2024 alone, 350 known drone incursions were reported over a hundred different US military installations. A lack of coordination or even clarity from the White House, Pentagon or US intelligence community has led some in domestic law enforcement to turn to an unlikely source for help cracking the case of these mystery drones: two UFO hunters out on Long Island in New York called John and Gerald Tedesco.&lt;/p&gt;&lt;p&gt;The twin brothers each spent about three decades in the private sector working in electrical engineering and instrumentation design before they decided to kit out an old RV with an array of homemade signals collection equipment.&lt;/p&gt;&lt;p&gt;What the Tedescos appear to have done, in their effort to bring a maximalist approach to the sensors directed at these suspected alien spacecraft, is independently engineer the kind of aerial surveillance capability rarely seen outside the classified world. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Matthew Phelan&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;This story is from our forthcoming print issue, which is all about security. If you haven’t already, &lt;/strong&gt;&lt;strong&gt;subscribe now&lt;/strong&gt;&lt;strong&gt; to receive future issues once they land.&lt;/strong&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Open the pod bay doors, Claude&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;The trope of AI going rogue, disobeying commands and threatening its human operators is well-worn in Sci-Fi. But it’s no longer just the stuff of fiction. AI doomerism, the idea that this technology—specifically its hypothetical upgrades, artificial general intelligence and super-intelligence—will crash civilizations, even kill us all, is now riding another wave.&lt;/p&gt;&lt;p&gt;The weird thing is that such fears are now driving much-needed action to regulate AI—even if the justification for that action is a bit bonkers. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Will Douglas Heaven&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 xAI is suing Apple and OpenAI&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Elon Musk has accused them of illegally conspiring to thwart xAI from competing. (The Verge)&lt;br /&gt;+ &lt;em&gt;The legal action comes after Grok failed to top Apple’s App Store charts. &lt;/em&gt;(NYT $)&lt;br /&gt;+ &lt;em&gt;The lawsuit doesn’t mention AI companies buying access to other platforms. &lt;/em&gt;(The Register)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;2 Donald Trump has threatened tariffs against countries unfriendly to US tech&lt;/strong&gt;&lt;br /&gt;Whether that’s in the form of digital taxes, legislation or regulations. (The Guardian)&lt;br /&gt;+ &lt;em&gt;Europe’s Digital Service Act appears to be a prime target. &lt;/em&gt;(Reuters)&lt;br /&gt;+ &lt;em&gt;How much do AI companies care about the US in return though, really? &lt;/em&gt;(The Atlantic $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 Intel doesn’t want the US government to take a 10% stake in its business&lt;/strong&gt;&lt;br /&gt;It fears the deal could affect its international sales and trigger an employee backlash. (WP $)&lt;br /&gt;+ &lt;em&gt;Intel desperately needs to get its groove back. &lt;/em&gt;(NYT $)&lt;br /&gt;+ &lt;em&gt;Trump won’t want Intel to fail under the circumstances. &lt;/em&gt;(WSJ $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 SpaceX cancelled its 10th Starship launch for the second night in a row&lt;/strong&gt;&lt;br /&gt;The spacecraft hasn’t had a clean flight since November last year. (CNN)&lt;br /&gt;+ &lt;em&gt;So when is it going to attempt it again, exactly? &lt;/em&gt;(NYT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 AI is making it harder for new coders to find jobs&lt;/strong&gt;&lt;br /&gt;But that doesn’t seem to apply for more experienced developers. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;The takeaway? AI is eliminating jobs, but not lowering wages—yet. &lt;/em&gt;(Wired $)&lt;br /&gt;+ &lt;em&gt;The second wave of AI coding is here. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;6 It isn’t just AI’s emissions you should know about&lt;br /&gt;&lt;/strong&gt;TV, digital storage, and internet usage are other energy fiends. (WP $)&lt;br /&gt;+ &lt;em&gt;In a first, Google has released data on how much energy an AI prompt uses. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 India’s tech boom is unsustainable&lt;br /&gt;&lt;/strong&gt;The city of Bengaluru is struggling to support the sprawling industry it’s created. (FT $)&lt;br /&gt;+ &lt;em&gt;Inside India’s scramble for AI independence&lt;/em&gt;. (MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 EV sales are up in the US&lt;br /&gt;&lt;/strong&gt;For now, at least. (Wired $)&lt;br /&gt;+ &lt;em&gt;The US could really use an affordable electric truck. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 This hidden network runs OnlyFans stars’ chats with their customers&lt;/strong&gt;&lt;br /&gt;Unsurprisingly, AI chatbots are increasingly doing the heavy lifting. (Rest of World)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;10 Do we really even want to live on Mars?&lt;/strong&gt;&lt;br /&gt;The whole radiation and poisonous atmosphere thing isn’t really selling it to me. (Vox)&lt;br /&gt;+ &lt;em&gt;A new NASA mission is simulating living conditions on the Red Planet. &lt;/em&gt;(The Times $)&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;+ &lt;em&gt;The quest to figure out farming on Mars&lt;/em&gt;. (MIT Technology Review)&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&amp;nbsp;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;"If socialism is government owning the means of production, wouldn’t the government owning part of Intel be a step toward socialism?"&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;—Kentucky Senator Rand Paul questions the wisdom of the Trump administration taking a stake in Intel, Reuters reports.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" src="https://wp.technologyreview.com/wp-content/uploads/2023/05/GettyImages-1433324047.jpeg?fit=1064,598" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Longevity enthusiasts want to create their own independent state. They’re eyeing Rhode Island.&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Jessica Hamzelou&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;Earlier this month, I traveled to Montenegro for a gathering of longevity enthusiasts. All the attendees were super friendly, and the sense of optimism was palpable. They’re all confident we’ll be able to find a way to slow or reverse aging—and they have a bold plan to speed up progress.&lt;/p&gt;  &lt;p&gt;Around 780 of these people have created a “pop-up city” that hopes to circumvent the traditional process of clinical trials. They want to create an independent state where like-minded innovators can work together in an all-new jurisdiction that gives them free rein to self-experiment with unproven drugs. Welcome to Zuzalu. Read the full story.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;+ Very cool—a new species of dinosaur has been discovered on the Isle of Wight in the UK.&lt;br /&gt;+ Make way for the bee alleys.&lt;br /&gt;+ How to take the best possible picture of the night sky.&lt;br /&gt;+ This giant rain frog really looks like they’ve Seen Some Stuff.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;How these two brothers became go-to experts on America’s “mystery drone” invasion&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;In 2024 alone, 350 known drone incursions were reported over a hundred different US military installations. A lack of coordination or even clarity from the White House, Pentagon or US intelligence community has led some in domestic law enforcement to turn to an unlikely source for help cracking the case of these mystery drones: two UFO hunters out on Long Island in New York called John and Gerald Tedesco.&lt;/p&gt;&lt;p&gt;The twin brothers each spent about three decades in the private sector working in electrical engineering and instrumentation design before they decided to kit out an old RV with an array of homemade signals collection equipment.&lt;/p&gt;&lt;p&gt;What the Tedescos appear to have done, in their effort to bring a maximalist approach to the sensors directed at these suspected alien spacecraft, is independently engineer the kind of aerial surveillance capability rarely seen outside the classified world. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Matthew Phelan&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;This story is from our forthcoming print issue, which is all about security. If you haven’t already, &lt;/strong&gt;&lt;strong&gt;subscribe now&lt;/strong&gt;&lt;strong&gt; to receive future issues once they land.&lt;/strong&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Open the pod bay doors, Claude&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;The trope of AI going rogue, disobeying commands and threatening its human operators is well-worn in Sci-Fi. But it’s no longer just the stuff of fiction. AI doomerism, the idea that this technology—specifically its hypothetical upgrades, artificial general intelligence and super-intelligence—will crash civilizations, even kill us all, is now riding another wave.&lt;/p&gt;&lt;p&gt;The weird thing is that such fears are now driving much-needed action to regulate AI—even if the justification for that action is a bit bonkers. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Will Douglas Heaven&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 xAI is suing Apple and OpenAI&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Elon Musk has accused them of illegally conspiring to thwart xAI from competing. (The Verge)&lt;br /&gt;+ &lt;em&gt;The legal action comes after Grok failed to top Apple’s App Store charts. &lt;/em&gt;(NYT $)&lt;br /&gt;+ &lt;em&gt;The lawsuit doesn’t mention AI companies buying access to other platforms. &lt;/em&gt;(The Register)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;2 Donald Trump has threatened tariffs against countries unfriendly to US tech&lt;/strong&gt;&lt;br /&gt;Whether that’s in the form of digital taxes, legislation or regulations. (The Guardian)&lt;br /&gt;+ &lt;em&gt;Europe’s Digital Service Act appears to be a prime target. &lt;/em&gt;(Reuters)&lt;br /&gt;+ &lt;em&gt;How much do AI companies care about the US in return though, really? &lt;/em&gt;(The Atlantic $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 Intel doesn’t want the US government to take a 10% stake in its business&lt;/strong&gt;&lt;br /&gt;It fears the deal could affect its international sales and trigger an employee backlash. (WP $)&lt;br /&gt;+ &lt;em&gt;Intel desperately needs to get its groove back. &lt;/em&gt;(NYT $)&lt;br /&gt;+ &lt;em&gt;Trump won’t want Intel to fail under the circumstances. &lt;/em&gt;(WSJ $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 SpaceX cancelled its 10th Starship launch for the second night in a row&lt;/strong&gt;&lt;br /&gt;The spacecraft hasn’t had a clean flight since November last year. (CNN)&lt;br /&gt;+ &lt;em&gt;So when is it going to attempt it again, exactly? &lt;/em&gt;(NYT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 AI is making it harder for new coders to find jobs&lt;/strong&gt;&lt;br /&gt;But that doesn’t seem to apply for more experienced developers. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;The takeaway? AI is eliminating jobs, but not lowering wages—yet. &lt;/em&gt;(Wired $)&lt;br /&gt;+ &lt;em&gt;The second wave of AI coding is here. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;6 It isn’t just AI’s emissions you should know about&lt;br /&gt;&lt;/strong&gt;TV, digital storage, and internet usage are other energy fiends. (WP $)&lt;br /&gt;+ &lt;em&gt;In a first, Google has released data on how much energy an AI prompt uses. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 India’s tech boom is unsustainable&lt;br /&gt;&lt;/strong&gt;The city of Bengaluru is struggling to support the sprawling industry it’s created. (FT $)&lt;br /&gt;+ &lt;em&gt;Inside India’s scramble for AI independence&lt;/em&gt;. (MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 EV sales are up in the US&lt;br /&gt;&lt;/strong&gt;For now, at least. (Wired $)&lt;br /&gt;+ &lt;em&gt;The US could really use an affordable electric truck. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 This hidden network runs OnlyFans stars’ chats with their customers&lt;/strong&gt;&lt;br /&gt;Unsurprisingly, AI chatbots are increasingly doing the heavy lifting. (Rest of World)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;10 Do we really even want to live on Mars?&lt;/strong&gt;&lt;br /&gt;The whole radiation and poisonous atmosphere thing isn’t really selling it to me. (Vox)&lt;br /&gt;+ &lt;em&gt;A new NASA mission is simulating living conditions on the Red Planet. &lt;/em&gt;(The Times $)&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;+ &lt;em&gt;The quest to figure out farming on Mars&lt;/em&gt;. (MIT Technology Review)&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&amp;nbsp;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;"If socialism is government owning the means of production, wouldn’t the government owning part of Intel be a step toward socialism?"&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;—Kentucky Senator Rand Paul questions the wisdom of the Trump administration taking a stake in Intel, Reuters reports.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" src="https://wp.technologyreview.com/wp-content/uploads/2023/05/GettyImages-1433324047.jpeg?fit=1064,598" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Longevity enthusiasts want to create their own independent state. They’re eyeing Rhode Island.&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Jessica Hamzelou&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;Earlier this month, I traveled to Montenegro for a gathering of longevity enthusiasts. All the attendees were super friendly, and the sense of optimism was palpable. They’re all confident we’ll be able to find a way to slow or reverse aging—and they have a bold plan to speed up progress.&lt;/p&gt;  &lt;p&gt;Around 780 of these people have created a “pop-up city” that hopes to circumvent the traditional process of clinical trials. They want to create an independent state where like-minded innovators can work together in an all-new jurisdiction that gives them free rein to self-experiment with unproven drugs. Welcome to Zuzalu. Read the full story.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;+ Very cool—a new species of dinosaur has been discovered on the Isle of Wight in the UK.&lt;br /&gt;+ Make way for the bee alleys.&lt;br /&gt;+ How to take the best possible picture of the night sky.&lt;br /&gt;+ This giant rain frog really looks like they’ve Seen Some Stuff.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/08/26/1122511/the-download-americas-drone-brothers-and-an-upside-of-ai-doomerism/</guid><pubDate>Tue, 26 Aug 2025 12:10:00 +0000</pubDate></item><item><title>[NEW] A scalable framework for evaluating health language models (The latest research from Google)</title><link>https://research.google/blog/a-scalable-framework-for-evaluating-health-language-models/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;h2&gt;Designing Adaptive Precise Boolean rubrics&lt;/h2&gt;&lt;p&gt;We first used an iterative process to transform rubric criteria characterized by high-complexity response options (e.g., open-ended text or multi-point Likert scales) into a more granular set of rubric criteria employing binary response options (i.e., boolean “Yes” or “No”) — an approach we call &lt;i&gt;Precise Boolean&lt;/i&gt; rubrics. The primary objective in developing the Precise Boolean rubrics was to enhance inter-rater reliability in annotation tasks and to generate a more robust and actionable evaluation signal, thereby facilitating programmatic interpretation and response refinement. The increased granularity afforded by the simple Yes/No format mitigates subjective interpretation and fosters more consistent evaluations, even with a larger number of total questions.&lt;/p&gt;&lt;p&gt;Due to the granular nature of our rubric design, the resulting Precise Boolean rubrics consisted of a substantially larger number of evaluation criteria compared to the starting Likert-scale rubrics. While auto-eval techniques are well equipped to handle the increased volume of evaluation criteria, the completion of the proposed Precise Boolean rubrics by human annotators was prohibitively resource intensive. To mitigate such burden, we refined the Precise Boolean approach to dynamically filter the extensive set of rubric questions, retaining only the most pertinent criteria, conditioned on the specific data being evaluated. This data-driven adaptation, referred to as the &lt;i&gt;Adaptive Precise Boolean&lt;/i&gt; rubric, enabled a reduction in the number of evaluations required for each LLM response. This is because user queries and corresponding LLM outputs often exhibit a focused topicality, thus requiring evaluation against only the subset of rubric criteria relevant to those themes.&lt;/p&gt;&lt;p&gt;To convert the Precise Boolean rubrics to Adaptive Precise Boolean ones, we leveraged Gemini as a zero-shot rubric question classifier. Input to the LLM includes the user query, the corresponding LLM response under evaluation, and a specific rubric criterion. The LLM then outputs whether the criterion is relevant or not. To validate this adaptive approach, we established a ground-truth dataset through rubric question classification annotations provided by three medical experts, with majority voting employed to determine the consensus annotation. Rubrics obtained based on using this ground-truth dataset in order to do adaptation are referred to as &lt;i&gt;Human-Adaptive Precise Boolean rubrics&lt;/i&gt;.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;h2&gt;Designing Adaptive Precise Boolean rubrics&lt;/h2&gt;&lt;p&gt;We first used an iterative process to transform rubric criteria characterized by high-complexity response options (e.g., open-ended text or multi-point Likert scales) into a more granular set of rubric criteria employing binary response options (i.e., boolean “Yes” or “No”) — an approach we call &lt;i&gt;Precise Boolean&lt;/i&gt; rubrics. The primary objective in developing the Precise Boolean rubrics was to enhance inter-rater reliability in annotation tasks and to generate a more robust and actionable evaluation signal, thereby facilitating programmatic interpretation and response refinement. The increased granularity afforded by the simple Yes/No format mitigates subjective interpretation and fosters more consistent evaluations, even with a larger number of total questions.&lt;/p&gt;&lt;p&gt;Due to the granular nature of our rubric design, the resulting Precise Boolean rubrics consisted of a substantially larger number of evaluation criteria compared to the starting Likert-scale rubrics. While auto-eval techniques are well equipped to handle the increased volume of evaluation criteria, the completion of the proposed Precise Boolean rubrics by human annotators was prohibitively resource intensive. To mitigate such burden, we refined the Precise Boolean approach to dynamically filter the extensive set of rubric questions, retaining only the most pertinent criteria, conditioned on the specific data being evaluated. This data-driven adaptation, referred to as the &lt;i&gt;Adaptive Precise Boolean&lt;/i&gt; rubric, enabled a reduction in the number of evaluations required for each LLM response. This is because user queries and corresponding LLM outputs often exhibit a focused topicality, thus requiring evaluation against only the subset of rubric criteria relevant to those themes.&lt;/p&gt;&lt;p&gt;To convert the Precise Boolean rubrics to Adaptive Precise Boolean ones, we leveraged Gemini as a zero-shot rubric question classifier. Input to the LLM includes the user query, the corresponding LLM response under evaluation, and a specific rubric criterion. The LLM then outputs whether the criterion is relevant or not. To validate this adaptive approach, we established a ground-truth dataset through rubric question classification annotations provided by three medical experts, with majority voting employed to determine the consensus annotation. Rubrics obtained based on using this ground-truth dataset in order to do adaptation are referred to as &lt;i&gt;Human-Adaptive Precise Boolean rubrics&lt;/i&gt;.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/a-scalable-framework-for-evaluating-health-language-models/</guid><pubDate>Tue, 26 Aug 2025 12:34:00 +0000</pubDate></item><item><title>[NEW] X and xAI sue Apple and OpenAI over AI monopoly claims (AI News)</title><link>https://www.artificialintelligence-news.com/news/x-and-xai-sue-apple-and-openai-ai-monopoly-claims/</link><description>&lt;p&gt;Elon Musk’s X and xAI are taking on Apple and OpenAI, accusing the tech giants of an AI monopoly to crush their competition.&lt;/p&gt;&lt;p&gt;A lawsuit by the companies filed in a Texas federal court claims the exclusive partnership between Apple and OpenAI to put ChatGPT on the iPhone is a calculated move by “two monopolists joining forces to ensure their continued dominance.”&lt;/p&gt;&lt;p&gt;The deal to integrate ChatGPT deep into Apple’s operating system makes the world’s most renowned AI assistant currently the one and only to be able to control core iPhone features; effectively locking out rivals like xAI’s own chatbot, Grok.&lt;/p&gt;&lt;p&gt;The lawsuit claims this denies users a fair choice, ironically quoting an OpenAI strategy document that states, “Real choice drives competition and benefits everyone. Users should be able to pick their Al assistant.”&lt;/p&gt;&lt;p&gt;The real prize, according to the complaint, is data. Generative AI gets smarter and better with every user question, creating a powerful feedback loop.&lt;/p&gt;&lt;p&gt;By giving ChatGPT exclusive access to potentially billions of prompts from hundreds of millions of iPhones, the partnership effectively builds an impenetrable “moat” around OpenAI’s market leadership. It starves competitors of the data they need to improve their own models and truly compete, thereby helping to sustain the alleged AI monopoly.&lt;/p&gt;&lt;p&gt;So valuable is this stream of data, the lawsuit claims, that OpenAI is giving Apple its technology for free, considering the access “of equal or greater value than monetary payments.”&lt;/p&gt;&lt;p&gt;As for why Apple would agree to this, the lawsuit argues it’s a defensive move against an existential threat: the rise of “super apps”. These all-in-one applications – like the one X is building, similar to popular Chinese platform WeChat – combine social media, messaging, payments, and other services into a single platform.&amp;nbsp;&lt;/p&gt;&lt;p&gt;As these super apps become more powerful with cloud-based AI services, they make the smartphone itself less important. Users could simply buy a cheaper phone and get all the functionality they need from the app, threatening Apple’s lucrative hardware sales.&lt;/p&gt;&lt;p&gt;The complaint alleges Apple is acutely aware of this danger, citing one company manager who warned that letting super apps take over would be like letting “the barbarians in at the gate.”&lt;/p&gt;&lt;p&gt;But the allegations don’t stop at the integration deal. The monopoly lawsuit also accuses Apple of using its iron grip on the App Store to tilt the scales away from specific AI apps.&lt;/p&gt;&lt;p&gt;The lawsuit claims that highly-ranked apps from X and xAI are deliberately buried and excluded from the App Store’s prestigious “Must-Have Apps” list, while ChatGPT is prominently featured. This is allegedly backed up by delayed approvals for updates to the Grok app, further hobbling its ability to compete.&lt;/p&gt;&lt;p&gt;X and xAI argue this conduct harms everyone. By choking off competition, the partnership allegedly leads to less innovation, fewer choices, and higher prices for consumers. The broader AI monopoly lawsuit aims to tear down this arrangement and recover the billions of dollars in lost value and sales it claims to have suffered as a result.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Julian Hochgesang)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Proton’s privacy-first Lumo AI assistant gets a major upgrade&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfMuK0QK72AkxJ1g5fktmsAq0UGLGBzBCY0EFGvBgnFj5L-cG7OCDzuBAdciiQnuDoD-Ml_HLy0TfHwuMcoK8_ZTIp-eM9AdSAMvEP8_NG_BqdpeFn0zxhdy41ssT1KzR2QrrSZPA?key=in0vh7I7KhHbgTg4GAz8Sg" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Elon Musk’s X and xAI are taking on Apple and OpenAI, accusing the tech giants of an AI monopoly to crush their competition.&lt;/p&gt;&lt;p&gt;A lawsuit by the companies filed in a Texas federal court claims the exclusive partnership between Apple and OpenAI to put ChatGPT on the iPhone is a calculated move by “two monopolists joining forces to ensure their continued dominance.”&lt;/p&gt;&lt;p&gt;The deal to integrate ChatGPT deep into Apple’s operating system makes the world’s most renowned AI assistant currently the one and only to be able to control core iPhone features; effectively locking out rivals like xAI’s own chatbot, Grok.&lt;/p&gt;&lt;p&gt;The lawsuit claims this denies users a fair choice, ironically quoting an OpenAI strategy document that states, “Real choice drives competition and benefits everyone. Users should be able to pick their Al assistant.”&lt;/p&gt;&lt;p&gt;The real prize, according to the complaint, is data. Generative AI gets smarter and better with every user question, creating a powerful feedback loop.&lt;/p&gt;&lt;p&gt;By giving ChatGPT exclusive access to potentially billions of prompts from hundreds of millions of iPhones, the partnership effectively builds an impenetrable “moat” around OpenAI’s market leadership. It starves competitors of the data they need to improve their own models and truly compete, thereby helping to sustain the alleged AI monopoly.&lt;/p&gt;&lt;p&gt;So valuable is this stream of data, the lawsuit claims, that OpenAI is giving Apple its technology for free, considering the access “of equal or greater value than monetary payments.”&lt;/p&gt;&lt;p&gt;As for why Apple would agree to this, the lawsuit argues it’s a defensive move against an existential threat: the rise of “super apps”. These all-in-one applications – like the one X is building, similar to popular Chinese platform WeChat – combine social media, messaging, payments, and other services into a single platform.&amp;nbsp;&lt;/p&gt;&lt;p&gt;As these super apps become more powerful with cloud-based AI services, they make the smartphone itself less important. Users could simply buy a cheaper phone and get all the functionality they need from the app, threatening Apple’s lucrative hardware sales.&lt;/p&gt;&lt;p&gt;The complaint alleges Apple is acutely aware of this danger, citing one company manager who warned that letting super apps take over would be like letting “the barbarians in at the gate.”&lt;/p&gt;&lt;p&gt;But the allegations don’t stop at the integration deal. The monopoly lawsuit also accuses Apple of using its iron grip on the App Store to tilt the scales away from specific AI apps.&lt;/p&gt;&lt;p&gt;The lawsuit claims that highly-ranked apps from X and xAI are deliberately buried and excluded from the App Store’s prestigious “Must-Have Apps” list, while ChatGPT is prominently featured. This is allegedly backed up by delayed approvals for updates to the Grok app, further hobbling its ability to compete.&lt;/p&gt;&lt;p&gt;X and xAI argue this conduct harms everyone. By choking off competition, the partnership allegedly leads to less innovation, fewer choices, and higher prices for consumers. The broader AI monopoly lawsuit aims to tear down this arrangement and recover the billions of dollars in lost value and sales it claims to have suffered as a result.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Julian Hochgesang)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Proton’s privacy-first Lumo AI assistant gets a major upgrade&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfMuK0QK72AkxJ1g5fktmsAq0UGLGBzBCY0EFGvBgnFj5L-cG7OCDzuBAdciiQnuDoD-Ml_HLy0TfHwuMcoK8_ZTIp-eM9AdSAMvEP8_NG_BqdpeFn0zxhdy41ssT1KzR2QrrSZPA?key=in0vh7I7KhHbgTg4GAz8Sg" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/x-and-xai-sue-apple-and-openai-ai-monopoly-claims/</guid><pubDate>Tue, 26 Aug 2025 12:52:12 +0000</pubDate></item><item><title>[NEW] Simpler models can outperform deep learning at climate prediction (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/simpler-models-can-outperform-deep-learning-climate-prediction-0826</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202508/MIT-Climate-Emulators-01-press.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Environmental scientists are increasingly using enormous artificial intelligence models to make predictions about changes in weather and climate, but a new study by MIT researchers shows that bigger models are not always better.&lt;/p&gt;&lt;p&gt;The team demonstrates that, in certain climate scenarios, much simpler, physics-based models can generate more accurate predictions than state-of-the-art deep-learning models.&lt;/p&gt;&lt;p&gt;Their analysis also reveals that a benchmarking technique commonly used to evaluate machine-learning techniques for climate predictions can be distorted by natural variations in the data, like fluctuations in weather patterns. This could lead someone to believe a deep-learning model makes more accurate predictions when that is not the case.&lt;/p&gt;&lt;p&gt;The researchers developed a more robust way of evaluating these techniques, which shows that, while simple models are more accurate when estimating regional surface temperatures, deep-learning approaches can be the best choice for estimating local rainfall.&lt;/p&gt;&lt;p&gt;They used these results to enhance a simulation tool known as a&amp;nbsp;climate emulator, which can rapidly simulate the effect of human activities onto a future climate.&lt;/p&gt;&lt;p&gt;The researchers see their work as a “cautionary tale” about the risk of deploying large AI models for climate science. While deep-learning models have shown incredible success in domains such as natural language, climate science contains a proven set of physical laws and approximations, and the challenge becomes how to incorporate those into AI models.&lt;/p&gt;&lt;p&gt;“We are trying to develop models that are going to be useful and relevant for the kinds of things that decision-makers need going forward when making climate policy choices. While it might be attractive to use the latest, big-picture machine-learning model on a climate problem, what this study shows is that stepping back and really thinking about the problem fundamentals is important and useful,” says study senior author Noelle Selin, a professor in the MIT Institute for Data, Systems, and Society (IDSS) and the Department of Earth, Atmospheric and Planetary Sciences (EAPS), and director of the Center for Sustainability Science and Strategy.&lt;/p&gt;&lt;p&gt;Selin’s co-authors are lead author Björn Lütjens, a former EAPS postdoc who is now a research scientist at IBM Research; senior author Raffaele Ferrari, the Cecil and Ida Green Professor of Oceanography in EAPS and co-director of the Lorenz Center; and Duncan Watson-Parris, assistant professor at the University of California at San Diego. Selin and Ferrari are also co-principal investigators of the Bringing Computation to the Climate Challenge project, out of which this research emerged. The paper appears today in the &lt;em&gt;Journal of Advances in Modeling Earth Systems&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Comparing emulators&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Because the Earth’s climate is so complex, running a state-of-the-art climate model to predict how pollution levels will impact environmental factors like temperature can take weeks on the world’s most powerful supercomputers.&lt;/p&gt;&lt;p&gt;Scientists often create climate emulators, simpler approximations of a state-of-the art climate model, which are faster and more accessible. A policymaker could use a climate emulator to see how alternative assumptions on greenhouse gas emissions would affect future temperatures, helping them develop regulations.&lt;/p&gt;&lt;p&gt;But an emulator isn’t very useful if it makes inaccurate predictions about the local impacts of climate change. While deep learning has become increasingly popular for emulation, few studies have explored whether these models perform better than tried-and-true approaches.&lt;/p&gt;&lt;p&gt;The MIT researchers performed such a study. They compared a traditional technique called linear pattern scaling (LPS) with a deep-learning model using a common benchmark dataset for evaluating climate emulators.&lt;/p&gt;&lt;p&gt;Their results showed that LPS outperformed deep-learning models on predicting nearly all parameters they tested, including temperature and precipitation.&lt;/p&gt;&lt;p&gt;“Large AI methods are very appealing to scientists, but they rarely solve a completely new problem, so implementing an existing solution first is necessary to find out whether the complex machine-learning approach actually improves upon it,” says Lütjens.&lt;/p&gt;&lt;p&gt;Some initial results seemed to fly in the face of the researchers’ domain knowledge. The powerful deep-learning model should have been more accurate when making predictions about precipitation, since those data don’t follow a linear pattern.&lt;/p&gt;&lt;p&gt;They found that the high amount of natural variability in climate model runs can cause the deep learning model to perform poorly on unpredictable long-term oscillations, like El Niño/La Niña. This skews the benchmarking scores in favor of LPS, which averages out those oscillations.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Constructing a new evaluation&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;From there, the researchers constructed a new evaluation with more data that address natural climate variability. With this new evaluation, the deep-learning model performed slightly better than LPS for local precipitation, but LPS was still more accurate for temperature predictions.&lt;/p&gt;&lt;p&gt;“It is important to use the modeling tool that is right for the problem, but in order to do that you also have to set up the problem the right way in the first place,” Selin says.&lt;/p&gt;&lt;p&gt;Based on these results, the researchers incorporated LPS into a climate emulation platform to predict local temperature changes in different emission scenarios.&lt;/p&gt;&lt;p&gt;“We are not advocating that LPS should always be the goal. It still has limitations. For instance, LPS doesn’t predict variability or extreme weather events,”&amp;nbsp;Ferrari adds.&lt;/p&gt;&lt;p&gt;Rather, they hope their results emphasize the need to develop better benchmarking techniques, which could provide a fuller picture of which climate emulation technique is best suited for a particular situation.&lt;/p&gt;&lt;p&gt;“With an improved climate emulation benchmark, we could use more complex machine-learning methods to explore problems that are currently very hard to address, like the impacts of aerosols or estimations of extreme precipitation,” Lütjens says.&lt;/p&gt;&lt;p&gt;Ultimately, more accurate benchmarking techniques will help ensure policymakers are making decisions based on the best available information.&lt;/p&gt;&lt;p&gt;The researchers hope others build on their analysis, perhaps by studying additional improvements to climate emulation methods and benchmarks. Such research could explore impact-oriented metrics like drought indicators and wildfire risks, or new variables like regional wind speeds.&lt;/p&gt;&lt;p&gt;This research is funded, in part, by Schmidt Sciences, LLC, and is part of the MIT Climate Grand Challenges team for “Bringing Computation to the Climate Challenge.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202508/MIT-Climate-Emulators-01-press.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Environmental scientists are increasingly using enormous artificial intelligence models to make predictions about changes in weather and climate, but a new study by MIT researchers shows that bigger models are not always better.&lt;/p&gt;&lt;p&gt;The team demonstrates that, in certain climate scenarios, much simpler, physics-based models can generate more accurate predictions than state-of-the-art deep-learning models.&lt;/p&gt;&lt;p&gt;Their analysis also reveals that a benchmarking technique commonly used to evaluate machine-learning techniques for climate predictions can be distorted by natural variations in the data, like fluctuations in weather patterns. This could lead someone to believe a deep-learning model makes more accurate predictions when that is not the case.&lt;/p&gt;&lt;p&gt;The researchers developed a more robust way of evaluating these techniques, which shows that, while simple models are more accurate when estimating regional surface temperatures, deep-learning approaches can be the best choice for estimating local rainfall.&lt;/p&gt;&lt;p&gt;They used these results to enhance a simulation tool known as a&amp;nbsp;climate emulator, which can rapidly simulate the effect of human activities onto a future climate.&lt;/p&gt;&lt;p&gt;The researchers see their work as a “cautionary tale” about the risk of deploying large AI models for climate science. While deep-learning models have shown incredible success in domains such as natural language, climate science contains a proven set of physical laws and approximations, and the challenge becomes how to incorporate those into AI models.&lt;/p&gt;&lt;p&gt;“We are trying to develop models that are going to be useful and relevant for the kinds of things that decision-makers need going forward when making climate policy choices. While it might be attractive to use the latest, big-picture machine-learning model on a climate problem, what this study shows is that stepping back and really thinking about the problem fundamentals is important and useful,” says study senior author Noelle Selin, a professor in the MIT Institute for Data, Systems, and Society (IDSS) and the Department of Earth, Atmospheric and Planetary Sciences (EAPS), and director of the Center for Sustainability Science and Strategy.&lt;/p&gt;&lt;p&gt;Selin’s co-authors are lead author Björn Lütjens, a former EAPS postdoc who is now a research scientist at IBM Research; senior author Raffaele Ferrari, the Cecil and Ida Green Professor of Oceanography in EAPS and co-director of the Lorenz Center; and Duncan Watson-Parris, assistant professor at the University of California at San Diego. Selin and Ferrari are also co-principal investigators of the Bringing Computation to the Climate Challenge project, out of which this research emerged. The paper appears today in the &lt;em&gt;Journal of Advances in Modeling Earth Systems&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Comparing emulators&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Because the Earth’s climate is so complex, running a state-of-the-art climate model to predict how pollution levels will impact environmental factors like temperature can take weeks on the world’s most powerful supercomputers.&lt;/p&gt;&lt;p&gt;Scientists often create climate emulators, simpler approximations of a state-of-the art climate model, which are faster and more accessible. A policymaker could use a climate emulator to see how alternative assumptions on greenhouse gas emissions would affect future temperatures, helping them develop regulations.&lt;/p&gt;&lt;p&gt;But an emulator isn’t very useful if it makes inaccurate predictions about the local impacts of climate change. While deep learning has become increasingly popular for emulation, few studies have explored whether these models perform better than tried-and-true approaches.&lt;/p&gt;&lt;p&gt;The MIT researchers performed such a study. They compared a traditional technique called linear pattern scaling (LPS) with a deep-learning model using a common benchmark dataset for evaluating climate emulators.&lt;/p&gt;&lt;p&gt;Their results showed that LPS outperformed deep-learning models on predicting nearly all parameters they tested, including temperature and precipitation.&lt;/p&gt;&lt;p&gt;“Large AI methods are very appealing to scientists, but they rarely solve a completely new problem, so implementing an existing solution first is necessary to find out whether the complex machine-learning approach actually improves upon it,” says Lütjens.&lt;/p&gt;&lt;p&gt;Some initial results seemed to fly in the face of the researchers’ domain knowledge. The powerful deep-learning model should have been more accurate when making predictions about precipitation, since those data don’t follow a linear pattern.&lt;/p&gt;&lt;p&gt;They found that the high amount of natural variability in climate model runs can cause the deep learning model to perform poorly on unpredictable long-term oscillations, like El Niño/La Niña. This skews the benchmarking scores in favor of LPS, which averages out those oscillations.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Constructing a new evaluation&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;From there, the researchers constructed a new evaluation with more data that address natural climate variability. With this new evaluation, the deep-learning model performed slightly better than LPS for local precipitation, but LPS was still more accurate for temperature predictions.&lt;/p&gt;&lt;p&gt;“It is important to use the modeling tool that is right for the problem, but in order to do that you also have to set up the problem the right way in the first place,” Selin says.&lt;/p&gt;&lt;p&gt;Based on these results, the researchers incorporated LPS into a climate emulation platform to predict local temperature changes in different emission scenarios.&lt;/p&gt;&lt;p&gt;“We are not advocating that LPS should always be the goal. It still has limitations. For instance, LPS doesn’t predict variability or extreme weather events,”&amp;nbsp;Ferrari adds.&lt;/p&gt;&lt;p&gt;Rather, they hope their results emphasize the need to develop better benchmarking techniques, which could provide a fuller picture of which climate emulation technique is best suited for a particular situation.&lt;/p&gt;&lt;p&gt;“With an improved climate emulation benchmark, we could use more complex machine-learning methods to explore problems that are currently very hard to address, like the impacts of aerosols or estimations of extreme precipitation,” Lütjens says.&lt;/p&gt;&lt;p&gt;Ultimately, more accurate benchmarking techniques will help ensure policymakers are making decisions based on the best available information.&lt;/p&gt;&lt;p&gt;The researchers hope others build on their analysis, perhaps by studying additional improvements to climate emulation methods and benchmarks. Such research could explore impact-oriented metrics like drought indicators and wildfire risks, or new variables like regional wind speeds.&lt;/p&gt;&lt;p&gt;This research is funded, in part, by Schmidt Sciences, LLC, and is part of the MIT Climate Grand Challenges team for “Bringing Computation to the Climate Challenge.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/simpler-models-can-outperform-deep-learning-climate-prediction-0826</guid><pubDate>Tue, 26 Aug 2025 13:00:00 +0000</pubDate></item><item><title>[NEW] Google Gemini’s AI image model gets a ‘bananas’ upgrade (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/26/google-geminis-ai-image-model-gets-a-bananas-upgrade/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is upgrading its Gemini chatbot with a new AI image model that gives users finer control over editing photos, a step meant to catch up with OpenAI’s popular image tools and draw users from ChatGPT.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The update, called Gemini 2.5 Flash Image, rolls out starting Tuesday to all users in the Gemini app, as well as to developers via the Gemini API, Google AI Studio, and Vertex AI platforms.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Gemini’s new AI image model is designed to make more precise edits to images — based on natural language requests from users — while preserving the consistency of faces, animals, and other details, something that most rival tools struggle with. For instance, ask ChatGPT or xAI’s Grok to change the color of someone’s shirt in a photo, and the result might include a distorted face or an altered background.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="an animated GIF showing two pictures, one of an athlete and the other of a dog, in a new combined photo of the athlete cuddling the dog." class="wp-image-3039767" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/Blend-photos-together.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Gemini 2.5 Flash Image’s native image editor blends photos of a dog and person, while keeping their likeness&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Google’s new tool has already drawn attention. In recent weeks, social media users raved over an impressive AI image editor in the crowdsourced evaluation platform, LMArena. The model appeared to users anonymously under the pseudonym “nano-banana.”&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Google says it’s behind the model (if it wasn’t obvious already from all the banana-related hints), which is really the native image capability within its flagship Gemini 2.5 Flash AI model. Google says the image model is state-of-the-art on LMArena and other benchmarks.&lt;/p&gt;

&lt;figure class="wp-block-image alignwide size-full"&gt;&lt;img alt="alt" class="wp-image-3040005" height="2160" src="https://techcrunch.com/wp-content/uploads/2025/08/gemini-image__image-editing-1.png" width="3840" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Google claims its new AI image model is state-of-the-art on several benchmarks&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re really pushing visual quality forward, as well as the model’s ability to follow instructions,” said Nicole Brichtova, a product lead on visual generation models at Google DeepMind, in an interview with TechCrunch. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This update does a much better job making edits more seamlessly, and the model’s outputs are usable for whatever you want to use them for,” said Brichtova.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI image models have become a critical battleground for Big Tech. When OpenAI launched GPT-4o’s native image generator in March, it drove ChatGPT’s usage through the roof thanks to a frenzy of AI-generated Studio Ghibli memes that, according to OpenAI CEO Sam Altman, left the company’s GPUs “melting.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To keep up with OpenAI and Google, Meta announced last week that it would license AI image models from the startup Midjourney. Meanwhile, the a16z-backed German unicorn Black Forest Labs continues to dominate benchmarks with its FLUX AI image models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Perhaps Gemini’s impressive AI image editor can help Google close its user gap with OpenAI. ChatGPT now logs more than 700 million weekly users. On Google’s earnings call in July, the tech giant’s CEO Sundar Pichai revealed that Gemini had 450 million &lt;em&gt;monthly&lt;/em&gt; users — implying weekly users are even lower.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Brichtova says Google specifically designed the image model with consumer use cases in mind, such as helping users visualize their home and garden projects. The model also has better “world knowledge” and can combine multiple references in a single prompt; for example, merging an image of a sofa, a living room photo, and a color palette into one cohesive render.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="an animated GIF showing an image of an empty living room, with prompts displayed on screen such as &amp;quot;add paint&amp;quot; — and the room paint changes color. &amp;quot;Add sofa,&amp;quot; and a sofa is added. The demo shows the AI prompts changing the image in real-time." class="wp-image-3039768" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/multi-turn-editing.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Gemini 2.5 Flash Image lets users have “multi-turn” conversations with an AI image model&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;While Gemini’s new AI image generator makes it easier for users to make and edit realistic images, the company has safeguards that limit what users can create. Google has struggled with AI image generator safeguards in the past. At one point, the company apologized for Gemini generating historically inaccurate pictures of people, and rolled back the AI image generator altogether.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now, Google feels that it’s struck a better balance. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We want to give users creative control so that they can get from the models what they want,” said Brichtova. “But it’s not like anything goes.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The generative AI section of Google’s terms of service prohibits users from generating “non-consensual intimate imagery.” Those same kinds of safeguards don’t seem to exist for Grok, which allowed users to create AI-generated explicit images resembling celebrities, such as Taylor Swift.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To address the rise of deepfake imagery, which can make it hard for users to discern what’s real online, Brichtova says that Google applies visual watermarks to AI-generated images, as well as identifiers in its metadata. However, someone scrolling past an image on social media may not look for such identifiers.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is upgrading its Gemini chatbot with a new AI image model that gives users finer control over editing photos, a step meant to catch up with OpenAI’s popular image tools and draw users from ChatGPT.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The update, called Gemini 2.5 Flash Image, rolls out starting Tuesday to all users in the Gemini app, as well as to developers via the Gemini API, Google AI Studio, and Vertex AI platforms.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Gemini’s new AI image model is designed to make more precise edits to images — based on natural language requests from users — while preserving the consistency of faces, animals, and other details, something that most rival tools struggle with. For instance, ask ChatGPT or xAI’s Grok to change the color of someone’s shirt in a photo, and the result might include a distorted face or an altered background.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="an animated GIF showing two pictures, one of an athlete and the other of a dog, in a new combined photo of the athlete cuddling the dog." class="wp-image-3039767" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/Blend-photos-together.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Gemini 2.5 Flash Image’s native image editor blends photos of a dog and person, while keeping their likeness&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Google’s new tool has already drawn attention. In recent weeks, social media users raved over an impressive AI image editor in the crowdsourced evaluation platform, LMArena. The model appeared to users anonymously under the pseudonym “nano-banana.”&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Google says it’s behind the model (if it wasn’t obvious already from all the banana-related hints), which is really the native image capability within its flagship Gemini 2.5 Flash AI model. Google says the image model is state-of-the-art on LMArena and other benchmarks.&lt;/p&gt;

&lt;figure class="wp-block-image alignwide size-full"&gt;&lt;img alt="alt" class="wp-image-3040005" height="2160" src="https://techcrunch.com/wp-content/uploads/2025/08/gemini-image__image-editing-1.png" width="3840" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Google claims its new AI image model is state-of-the-art on several benchmarks&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re really pushing visual quality forward, as well as the model’s ability to follow instructions,” said Nicole Brichtova, a product lead on visual generation models at Google DeepMind, in an interview with TechCrunch. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This update does a much better job making edits more seamlessly, and the model’s outputs are usable for whatever you want to use them for,” said Brichtova.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI image models have become a critical battleground for Big Tech. When OpenAI launched GPT-4o’s native image generator in March, it drove ChatGPT’s usage through the roof thanks to a frenzy of AI-generated Studio Ghibli memes that, according to OpenAI CEO Sam Altman, left the company’s GPUs “melting.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To keep up with OpenAI and Google, Meta announced last week that it would license AI image models from the startup Midjourney. Meanwhile, the a16z-backed German unicorn Black Forest Labs continues to dominate benchmarks with its FLUX AI image models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Perhaps Gemini’s impressive AI image editor can help Google close its user gap with OpenAI. ChatGPT now logs more than 700 million weekly users. On Google’s earnings call in July, the tech giant’s CEO Sundar Pichai revealed that Gemini had 450 million &lt;em&gt;monthly&lt;/em&gt; users — implying weekly users are even lower.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Brichtova says Google specifically designed the image model with consumer use cases in mind, such as helping users visualize their home and garden projects. The model also has better “world knowledge” and can combine multiple references in a single prompt; for example, merging an image of a sofa, a living room photo, and a color palette into one cohesive render.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="an animated GIF showing an image of an empty living room, with prompts displayed on screen such as &amp;quot;add paint&amp;quot; — and the room paint changes color. &amp;quot;Add sofa,&amp;quot; and a sofa is added. The demo shows the AI prompts changing the image in real-time." class="wp-image-3039768" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/multi-turn-editing.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Gemini 2.5 Flash Image lets users have “multi-turn” conversations with an AI image model&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;While Gemini’s new AI image generator makes it easier for users to make and edit realistic images, the company has safeguards that limit what users can create. Google has struggled with AI image generator safeguards in the past. At one point, the company apologized for Gemini generating historically inaccurate pictures of people, and rolled back the AI image generator altogether.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now, Google feels that it’s struck a better balance. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We want to give users creative control so that they can get from the models what they want,” said Brichtova. “But it’s not like anything goes.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The generative AI section of Google’s terms of service prohibits users from generating “non-consensual intimate imagery.” Those same kinds of safeguards don’t seem to exist for Grok, which allowed users to create AI-generated explicit images resembling celebrities, such as Taylor Swift.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To address the rise of deepfake imagery, which can make it hard for users to discern what’s real online, Brichtova says that Google applies visual watermarks to AI-generated images, as well as identifiers in its metadata. However, someone scrolling past an image on social media may not look for such identifiers.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/26/google-geminis-ai-image-model-gets-a-bananas-upgrade/</guid><pubDate>Tue, 26 Aug 2025 14:00:00 +0000</pubDate></item><item><title>[NEW] Image editing in Gemini just got a major upgrade (Google DeepMind Blog)</title><link>https://deepmind.google/discover/blog/image-editing-in-gemini-just-got-a-major-upgrade/</link><description>&lt;div class="article-image-hero"&gt;
  &lt;div class="article-image-hero__container"&gt;
    &lt;figure class="article-image--full-aspect article-module"&gt;
      &lt;div class="aspect-ratio-image"&gt;
        &lt;div class="aspect-ratio-image__container"&gt;
          &lt;img alt="Text saying 'Reimagine your photos with a prompt' surrounded by a collage of AI-generated images, including a blonde woman in a bullfighting costume and a pair of pink rain boots. There are also prompt text boxes and the Gemini logo." class="aspect-ratio-image__image uni-progressive-image--blur" height="150px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Blog_hero_image_JSSFrGW.width-2200.format-webp.webp" width="360px" /&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      
    &lt;/figure&gt;
  &lt;/div&gt;
&lt;/div&gt;&lt;div class="uni-content uni-blog-article-container article-container__content
                      
                      "&gt;

            
              







            

            
            
&lt;!--article text--&gt;

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Today in the Gemini app, we're unveiling a new image editing model from Google DeepMind. People have been going &lt;i&gt;bananas&lt;/i&gt; over it already in early previews — it's the top-rated image editing model in the world. Now, we're excited to share that it's integrated into the Gemini app so you have more control than ever to create the perfect picture.&lt;/p&gt;&lt;h2&gt;Maintain your look as you edit&lt;/h2&gt;&lt;p&gt;We launched native image editing in the Gemini app earlier this year, and we’ve been working hard to improve it, with particular focus on maintaining a character's likeness from one image to the next. We know that when editing pictures of yourself or people you know well, subtle flaws matter — a depiction that’s "close but not quite the same" doesn’t feel right. That's why our latest update is designed to make photos of your friends, family and even your pets look consistently like themselves, whether you're trying out a 60’s beehive haircut or putting a tutu on your chihuahua.&lt;/p&gt;&lt;p&gt;Just give Gemini a photo to work with, and tell it what you'd like to change to add your unique touch. Gemini lets you combine photos to put yourself in a picture with your pet, change the background of a room to preview new wallpaper or place yourself anywhere in the world you can imagine — all while keeping you, you. Once you're done, you can even upload your edited image back into Gemini to turn your new photo into a fun video.&lt;/p&gt;&lt;h2&gt;Bring your vision to life with advanced editing&lt;/h2&gt;&lt;p&gt;Here are a few things to try as you explore this new image editing capability:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Give yourself a costume or location change&lt;/b&gt;: Upload a photo of a person or pet, and our model will keep their look the same in every image as you place them in new scenarios. Try putting yourself in different outfits or professions, or even see how you’d appear in another decade — all while still looking like you.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    















  
  



  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Blend photos together&lt;/b&gt;: You can now upload multiple photos and blend them together for a brand-new scene. For example, take your photo and another of your dog to create a perfect portrait of you both on the basketball court.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    















  
  



  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Try multi-turn editing&lt;/b&gt;: You can keep editing the images Gemini makes — take an empty room, paint the walls, then add a bookshelf, some furniture or a coffee table. Gemini's working with you all along to alter specific parts of an image while preserving the rest.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    















  
  



  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Mix up designs&lt;/b&gt;: Apply the style of one image to an object in another. You can take the color and texture of flower petals and apply it to a pair of rainboots, or design a dress using the pattern from a butterfly's wings.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    















  
  



  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;You can try this updated image editing capability in the Gemini app starting today. All images created or edited in the Gemini app include a visible watermark, as well as our invisible SynthID digital watermark, to clearly show they are AI-generated.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  


            
            

            
              


&lt;div class="
    uni-blog-article-tags
    article-tags
    
  "&gt;
  &lt;div class="uni-blog-article-tags__wrapper"&gt;
    &lt;span class="uni-blog-article-tags__label uni-eyebrow"&gt;POSTED IN:&lt;/span&gt;
  &lt;/div&gt;
  &lt;nav class="uni-blog-article-tags__container uni-click-tracker"&gt;
    &lt;ul class="uni-blog-article-tags__tags-list"&gt;
    
      &lt;li&gt;
        
        
        


  


Gemini


  


      &lt;/li&gt;
    

    
    &lt;/ul&gt;
  &lt;/nav&gt;
&lt;/div&gt;

            
          &lt;/div&gt;</description><content:encoded>&lt;div class="article-image-hero"&gt;
  &lt;div class="article-image-hero__container"&gt;
    &lt;figure class="article-image--full-aspect article-module"&gt;
      &lt;div class="aspect-ratio-image"&gt;
        &lt;div class="aspect-ratio-image__container"&gt;
          &lt;img alt="Text saying 'Reimagine your photos with a prompt' surrounded by a collage of AI-generated images, including a blonde woman in a bullfighting costume and a pair of pink rain boots. There are also prompt text boxes and the Gemini logo." class="aspect-ratio-image__image uni-progressive-image--blur" height="150px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Blog_hero_image_JSSFrGW.width-2200.format-webp.webp" width="360px" /&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      
    &lt;/figure&gt;
  &lt;/div&gt;
&lt;/div&gt;&lt;div class="uni-content uni-blog-article-container article-container__content
                      
                      "&gt;

            
              







            

            
            
&lt;!--article text--&gt;

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Today in the Gemini app, we're unveiling a new image editing model from Google DeepMind. People have been going &lt;i&gt;bananas&lt;/i&gt; over it already in early previews — it's the top-rated image editing model in the world. Now, we're excited to share that it's integrated into the Gemini app so you have more control than ever to create the perfect picture.&lt;/p&gt;&lt;h2&gt;Maintain your look as you edit&lt;/h2&gt;&lt;p&gt;We launched native image editing in the Gemini app earlier this year, and we’ve been working hard to improve it, with particular focus on maintaining a character's likeness from one image to the next. We know that when editing pictures of yourself or people you know well, subtle flaws matter — a depiction that’s "close but not quite the same" doesn’t feel right. That's why our latest update is designed to make photos of your friends, family and even your pets look consistently like themselves, whether you're trying out a 60’s beehive haircut or putting a tutu on your chihuahua.&lt;/p&gt;&lt;p&gt;Just give Gemini a photo to work with, and tell it what you'd like to change to add your unique touch. Gemini lets you combine photos to put yourself in a picture with your pet, change the background of a room to preview new wallpaper or place yourself anywhere in the world you can imagine — all while keeping you, you. Once you're done, you can even upload your edited image back into Gemini to turn your new photo into a fun video.&lt;/p&gt;&lt;h2&gt;Bring your vision to life with advanced editing&lt;/h2&gt;&lt;p&gt;Here are a few things to try as you explore this new image editing capability:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Give yourself a costume or location change&lt;/b&gt;: Upload a photo of a person or pet, and our model will keep their look the same in every image as you place them in new scenarios. Try putting yourself in different outfits or professions, or even see how you’d appear in another decade — all while still looking like you.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    















  
  



  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Blend photos together&lt;/b&gt;: You can now upload multiple photos and blend them together for a brand-new scene. For example, take your photo and another of your dog to create a perfect portrait of you both on the basketball court.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    















  
  



  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Try multi-turn editing&lt;/b&gt;: You can keep editing the images Gemini makes — take an empty room, paint the walls, then add a bookshelf, some furniture or a coffee table. Gemini's working with you all along to alter specific parts of an image while preserving the rest.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    















  
  



  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Mix up designs&lt;/b&gt;: Apply the style of one image to an object in another. You can take the color and texture of flower petals and apply it to a pair of rainboots, or design a dress using the pattern from a butterfly's wings.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    















  
  



  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;You can try this updated image editing capability in the Gemini app starting today. All images created or edited in the Gemini app include a visible watermark, as well as our invisible SynthID digital watermark, to clearly show they are AI-generated.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  


            
            

            
              


&lt;div class="
    uni-blog-article-tags
    article-tags
    
  "&gt;
  &lt;div class="uni-blog-article-tags__wrapper"&gt;
    &lt;span class="uni-blog-article-tags__label uni-eyebrow"&gt;POSTED IN:&lt;/span&gt;
  &lt;/div&gt;
  &lt;nav class="uni-blog-article-tags__container uni-click-tracker"&gt;
    &lt;ul class="uni-blog-article-tags__tags-list"&gt;
    
      &lt;li&gt;
        
        
        


  


Gemini


  


      &lt;/li&gt;
    

    
    &lt;/ul&gt;
  &lt;/nav&gt;
&lt;/div&gt;

            
          &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://deepmind.google/discover/blog/image-editing-in-gemini-just-got-a-major-upgrade/</guid><pubDate>Tue, 26 Aug 2025 14:00:59 +0000</pubDate></item><item><title>[NEW] Parents sue OpenAI over ChatGPT’s role in son’s suicide (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/26/parents-sue-openai-over-chatgpts-role-in-sons-suicide/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2191707579.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Before 16-year-old Adam Raine died by suicide, he had spent months consulting ChatGPT about his plans to end his life. Now, his parents are filing the first known wrongful death lawsuit against OpenAI, The New York Times reports.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Many consumer-facing AI chatbots are programmed to activate safety features if a user expresses intent to harm themselves or others. But research has shown that these safeguards are far from foolproof.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In Raine’s case, while using a paid version of ChatGPT-4o, the AI often encouraged him to seek professional help or contact a help line. However, he was able to bypass these guardrails by telling ChatGPT that he was asking about methods of suicide for a fictional story he was writing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has addressed these shortcomings on its blog. “As the world adapts to this new technology, we feel a deep responsibility to help those who need it most,” the post reads. “We are continuously improving how our models respond in sensitive interactions.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, the company acknowledged the limitations of the existing safety training for large models. “Our safeguards work more reliably in common, short exchanges,” the post continues. “We have learned over time that these safeguards can sometimes be less reliable in long interactions: as the back-and-forth grows, parts of the model’s safety training may degrade.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These issues are not unique to OpenAI. Character.AI, another AI chatbot maker, is also facing a lawsuit over its role in a teenager’s suicide. LLM-powered chatbots have also been linked to cases of AI-related delusions, which existing safeguards have struggled to detect.&lt;/p&gt;


&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2191707579.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Before 16-year-old Adam Raine died by suicide, he had spent months consulting ChatGPT about his plans to end his life. Now, his parents are filing the first known wrongful death lawsuit against OpenAI, The New York Times reports.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Many consumer-facing AI chatbots are programmed to activate safety features if a user expresses intent to harm themselves or others. But research has shown that these safeguards are far from foolproof.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In Raine’s case, while using a paid version of ChatGPT-4o, the AI often encouraged him to seek professional help or contact a help line. However, he was able to bypass these guardrails by telling ChatGPT that he was asking about methods of suicide for a fictional story he was writing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has addressed these shortcomings on its blog. “As the world adapts to this new technology, we feel a deep responsibility to help those who need it most,” the post reads. “We are continuously improving how our models respond in sensitive interactions.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, the company acknowledged the limitations of the existing safety training for large models. “Our safeguards work more reliably in common, short exchanges,” the post continues. “We have learned over time that these safeguards can sometimes be less reliable in long interactions: as the back-and-forth grows, parts of the model’s safety training may degrade.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These issues are not unique to OpenAI. Character.AI, another AI chatbot maker, is also facing a lawsuit over its role in a teenager’s suicide. LLM-powered chatbots have also been linked to cases of AI-related delusions, which existing safeguards have struggled to detect.&lt;/p&gt;


&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/26/parents-sue-openai-over-chatgpts-role-in-sons-suicide/</guid><pubDate>Tue, 26 Aug 2025 14:27:34 +0000</pubDate></item><item><title>[NEW] How one AI startup is helping rice farmers battle climate change (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/26/how-one-ai-startup-is-helping-rice-farmers-battle-climate-change/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-1650855311.jpeg?resize=1200,749" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Fixing climate change is no small task — just ask carbon removal developers like Mitti Labs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The New York-based startup has developed technology to measure how much methane is released by rice paddies and uses it to train hundreds of thousands of farmers in climate-friendly practices. It’s the sort of high-touch endeavor that venture capitalists typically avoid.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;So how has Mitti managed to raise funding from its investors? In short: partnerships.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mitti has started working with The Nature Conservancy on a partnership to promote regenerative, no-burn agriculture, the startup exclusively told TechCrunch, the latest in a string of deals that extend its reach. Mitti will use its AI-powered models to measure, report, and verify the work done by the nonprofit’s workers on the ground in India, where they’re helping farmers implement a swath of climate-friendly practices.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Most of the project operations on the ground are from locals from the villages where these projects are being implemented,” co-founder Xavier Laguarta told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Mitti’s main operations currently focus on developing projects that reduce the amount of methane generated by rice farming, the company is working to offer more software features to third parties, he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We can measure Scope 3 emissions from other project developers or corporations that are working with rice farmers,” Laguarta said, referring to emissions that an organization does not directly control. “Anyone who’s already running projects on the ground, that’s sort of like a SaaS solution that we can offer them.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mitti isn’t alone in chasing the SaaS-partnership angle. Mati Carbon, which recently won the Xprize Carbon grand prize, develops measurement, reporting, and verification software for enhanced rock weathering, in which minerals spread on farm fields both remove carbon and fertilize the soil.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Methane reduction projects generate carbon credits, which Mitti tracks using its software. The company takes a percentage of the credits’ sale and passes the remainder on to farmers and the community, he said. “Usually, farmers will see about a 15% improvement in their bottom line by joining our programs.” For smallholder farmers, who often teeter on the edge of profitability, such revenue can be meaningful.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mitti’s software studies various signals from rice farms to determine how much methane they release throughout the growing season. Rice farming is distinct from many other types of agriculture because the fields are flooded for much of the year. This creates anaerobic, or oxygen-free conditions, in the soil, which foster the growth and metabolism of a suite of microbes that generate methane.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Methane is a powerful greenhouse gas, warming the planet 82 times more than the equivalent amount of carbon dioxide over a 20-year period. Rice farming is a large source of human-caused methane emissions, contributing around 10% to 12% of the total.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mitti’s main data sources come from satellite imagery and radar, which can penetrate through clouds, plants, water, and the soil to determine what’s happening underground where the microbes live. It then feeds that information into AI models trained on satellite data and the results of extensive field studies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Smallholders play a large role in agriculture in India; the average farm size is one hectare (about 2.5 acres). Monitoring each with physical equipment would be cost-prohibitive. The remotely sensed data helps keep verification costs reasonable, and the partnerships help bring climate-friendly practices to millions of farmers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Ninety percent of rice is grown in Asia, and outside of potentially China, the majority of rice growing regions have these similar smallholder farmer dynamics,” Laguarta said. “A deep partnership that we have with the Nature Conservancy allows us to develop these tools that can then be used for a lot of other programs in the region.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-1650855311.jpeg?resize=1200,749" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Fixing climate change is no small task — just ask carbon removal developers like Mitti Labs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The New York-based startup has developed technology to measure how much methane is released by rice paddies and uses it to train hundreds of thousands of farmers in climate-friendly practices. It’s the sort of high-touch endeavor that venture capitalists typically avoid.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;So how has Mitti managed to raise funding from its investors? In short: partnerships.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mitti has started working with The Nature Conservancy on a partnership to promote regenerative, no-burn agriculture, the startup exclusively told TechCrunch, the latest in a string of deals that extend its reach. Mitti will use its AI-powered models to measure, report, and verify the work done by the nonprofit’s workers on the ground in India, where they’re helping farmers implement a swath of climate-friendly practices.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Most of the project operations on the ground are from locals from the villages where these projects are being implemented,” co-founder Xavier Laguarta told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Mitti’s main operations currently focus on developing projects that reduce the amount of methane generated by rice farming, the company is working to offer more software features to third parties, he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We can measure Scope 3 emissions from other project developers or corporations that are working with rice farmers,” Laguarta said, referring to emissions that an organization does not directly control. “Anyone who’s already running projects on the ground, that’s sort of like a SaaS solution that we can offer them.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mitti isn’t alone in chasing the SaaS-partnership angle. Mati Carbon, which recently won the Xprize Carbon grand prize, develops measurement, reporting, and verification software for enhanced rock weathering, in which minerals spread on farm fields both remove carbon and fertilize the soil.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Methane reduction projects generate carbon credits, which Mitti tracks using its software. The company takes a percentage of the credits’ sale and passes the remainder on to farmers and the community, he said. “Usually, farmers will see about a 15% improvement in their bottom line by joining our programs.” For smallholder farmers, who often teeter on the edge of profitability, such revenue can be meaningful.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mitti’s software studies various signals from rice farms to determine how much methane they release throughout the growing season. Rice farming is distinct from many other types of agriculture because the fields are flooded for much of the year. This creates anaerobic, or oxygen-free conditions, in the soil, which foster the growth and metabolism of a suite of microbes that generate methane.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Methane is a powerful greenhouse gas, warming the planet 82 times more than the equivalent amount of carbon dioxide over a 20-year period. Rice farming is a large source of human-caused methane emissions, contributing around 10% to 12% of the total.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mitti’s main data sources come from satellite imagery and radar, which can penetrate through clouds, plants, water, and the soil to determine what’s happening underground where the microbes live. It then feeds that information into AI models trained on satellite data and the results of extensive field studies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Smallholders play a large role in agriculture in India; the average farm size is one hectare (about 2.5 acres). Monitoring each with physical equipment would be cost-prohibitive. The remotely sensed data helps keep verification costs reasonable, and the partnerships help bring climate-friendly practices to millions of farmers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Ninety percent of rice is grown in Asia, and outside of potentially China, the majority of rice growing regions have these similar smallholder farmer dynamics,” Laguarta said. “A deep partnership that we have with the Nature Conservancy allows us to develop these tools that can then be used for a lot of other programs in the region.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/26/how-one-ai-startup-is-helping-rice-farmers-battle-climate-change/</guid><pubDate>Tue, 26 Aug 2025 15:21:19 +0000</pubDate></item><item><title>[NEW] AI’s dual nature: Genuine innovation amid localised bubbles (AI News)</title><link>https://www.artificialintelligence-news.com/news/ais-dual-nature-genuine-innovation-amid-localised-bubbles/</link><description>&lt;p&gt;AI’s growing dominance in the world, whether it be reshaping industries’ workflows or influencing investor portfolios, is redefining how society and economies evolve. Of course, the hype and buzz around AI has been and is hard to ignore, but the question is, does this hype often overshadow the real challenges and limitations of AI?&lt;/p&gt;&lt;p&gt;According to a new &lt;u&gt;Day Trading report&lt;/u&gt;, the excitement around the AI bubble points to signs of overvaluation reminiscent of the dot-com era. While some areas of AI are genuinely transformative, it’s not all boom or bust, but somewhere in the middle.&lt;/p&gt;&lt;p&gt;Dan Buckley, Chief Analyst at &lt;u&gt;DayTrading.com&lt;/u&gt;, believes AI is a genuine technological boom, but it comes with pockets of overhype and speculation along the way. “We’re seeing record capital inflows, sky-high valuations, one-sided sentiment, and investing driven by FOMO before common sense. Yet we’re also seeing real-world use cases for AI and infrastructure investment at an industrial scale,” he said.&lt;/p&gt;&lt;p&gt;“The best framing is generally that AI is a real boom containing localised bubbles, not a mania in the board.”&lt;/p&gt;&lt;p&gt;The question remains – is AI a bubble? A bubble refers to when the price of an asset, like a stock or share, and sometimes, even a whole industry, grows in financial value much higher than its actual worth. This typically happens due to overexcitement and investors “following the crowd,” rather than basing decisions on true factors like demand and profits.&lt;/p&gt;&lt;h2&gt;Stocks are overpriced&lt;/h2&gt;&lt;p&gt;Currently, a number of AI company prices, including Microsoft and Nvidia, are substantially higher than their actual earnings or sales. Normally, high stock prices are justified by high profits, but the valuations of newer AI companies are, at present, over-inflated as they assume large future profits that may never materialise. This is demonstrated by a significant $560 billion investment into AI by companies over the last two years, but the estimated incremental revenue from such companies is only £35 billion – a considerable $525 billion gap.&lt;/p&gt;&lt;h2&gt;AI hype ahead of results&lt;/h2&gt;&lt;p&gt;Society as a whole assumes AI will revolutionise just about everything, but Day Trading’s report discovered many companies are not generating enough earnings to warrant such excitement. Investors are pricing vast returns on young technologies in early adoption phases in a “hope” that returns will match their investments. Moreover, many companies are “AI washing,” a tactic to exaggerate their AI capabilities to market themselves as more valuable than perhaps traditional assessment.&lt;/p&gt;&lt;h2&gt;Financial risks&lt;/h2&gt;&lt;p&gt;Some established global players like Nvidia and Amazon finance their growth through robust cash flows, but many newer AI startups are relying heavily on venture capital or debt funding, thus making them highly vulnerable if funding conditions change. Current enthusiasm around AI can attract emergency funding in some cases, but this reliance on high-risk financing highlights the fragility present in some segments of the AI market.&lt;/p&gt;&lt;h2&gt;One-sided optimism&lt;/h2&gt;&lt;p&gt;Investor sentiment towards AI is very positive, but also bullish. Sceptical perspectives are rarely acknowledged, which may leave the AI market vulnerable to sudden corrections if confidence is lost. Historically, bubbles tend to coincide with rising volatility, but the S&amp;amp;P 500 has remained relatively calm so far, suggesting surface-level stability. However, this may reflect confidence among investors convinced of AI’s promise.&lt;/p&gt;&lt;h2&gt;Inexperienced investors fuelling AI hype?&lt;/h2&gt;&lt;p&gt;According to Day Trading, a surge in inexperienced investors jumping on the AI hype bandwagon may be inflating valuations and heightening the risk of sudden corrections. Much like behaviour seen in the dot-com bubble, new buyers are following extant narratives, at present based on social media buzz and news headlines, instead of focusing on current earnings or real value.&lt;/p&gt;&lt;h2&gt;Liquidity is keeping the AI infrastructure rolling&lt;/h2&gt;&lt;p&gt;Although interest rates are higher compared to pre-pandemic levels, major tech firms have enough liquidity to continue investing heavily in AI without taking too much risk. The ratio of fresh equity or uncertain borrowing remains relatively low.&lt;/p&gt;&lt;h2&gt;Speculative stockpiling&lt;/h2&gt;&lt;p&gt;Some AI companies, like CoreWeave and Open AI, are aggressively hoarding resources, including AI chips and engineering talent, in anticipation of demand. This creates further financial risk if growth in sales were to slow. With no clear ROI or business models in place, capital is at the mercy of AI growth, or lack of it.&lt;/p&gt;&lt;h2&gt;The bubble isn’t burst&lt;/h2&gt;&lt;p&gt;Day Trading’s report highlights a range of concerns, similar to the dot-com bubble of the late 1990s and early 2000s. For instance, AI is already being used at scale, delivering productivity gains, particularly in sectors like finance, logistics, and media, something that was not evident in the dot-com era.&lt;/p&gt;&lt;p&gt;Although AI companies claim to be creating real value right now, compared to infrastructure investments being made, only a few are enjoying profitable margins, like Microsoft and Nvidia.&lt;/p&gt;&lt;p&gt;Substantial investments have been made for long term growth, not short term fast return. Therefore, the true returns may yet materialise as AI’s full potential unfolds over time. Eric Schmidt, former CEO of Google described, “AI as infrastructure for a new industrial era, not just a passing tech fad.”&lt;/p&gt;&lt;p&gt;Dan Buckley does not think AI is just hype, but excessive optimism can be dangerous. “AI is real and valuable,” Buckley said. “But it’s when market sentiment outpaces real business results that I begin to worry about the gap becoming dangerous for investors.”&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;AI’s growing dominance in the world, whether it be reshaping industries’ workflows or influencing investor portfolios, is redefining how society and economies evolve. Of course, the hype and buzz around AI has been and is hard to ignore, but the question is, does this hype often overshadow the real challenges and limitations of AI?&lt;/p&gt;&lt;p&gt;According to a new &lt;u&gt;Day Trading report&lt;/u&gt;, the excitement around the AI bubble points to signs of overvaluation reminiscent of the dot-com era. While some areas of AI are genuinely transformative, it’s not all boom or bust, but somewhere in the middle.&lt;/p&gt;&lt;p&gt;Dan Buckley, Chief Analyst at &lt;u&gt;DayTrading.com&lt;/u&gt;, believes AI is a genuine technological boom, but it comes with pockets of overhype and speculation along the way. “We’re seeing record capital inflows, sky-high valuations, one-sided sentiment, and investing driven by FOMO before common sense. Yet we’re also seeing real-world use cases for AI and infrastructure investment at an industrial scale,” he said.&lt;/p&gt;&lt;p&gt;“The best framing is generally that AI is a real boom containing localised bubbles, not a mania in the board.”&lt;/p&gt;&lt;p&gt;The question remains – is AI a bubble? A bubble refers to when the price of an asset, like a stock or share, and sometimes, even a whole industry, grows in financial value much higher than its actual worth. This typically happens due to overexcitement and investors “following the crowd,” rather than basing decisions on true factors like demand and profits.&lt;/p&gt;&lt;h2&gt;Stocks are overpriced&lt;/h2&gt;&lt;p&gt;Currently, a number of AI company prices, including Microsoft and Nvidia, are substantially higher than their actual earnings or sales. Normally, high stock prices are justified by high profits, but the valuations of newer AI companies are, at present, over-inflated as they assume large future profits that may never materialise. This is demonstrated by a significant $560 billion investment into AI by companies over the last two years, but the estimated incremental revenue from such companies is only £35 billion – a considerable $525 billion gap.&lt;/p&gt;&lt;h2&gt;AI hype ahead of results&lt;/h2&gt;&lt;p&gt;Society as a whole assumes AI will revolutionise just about everything, but Day Trading’s report discovered many companies are not generating enough earnings to warrant such excitement. Investors are pricing vast returns on young technologies in early adoption phases in a “hope” that returns will match their investments. Moreover, many companies are “AI washing,” a tactic to exaggerate their AI capabilities to market themselves as more valuable than perhaps traditional assessment.&lt;/p&gt;&lt;h2&gt;Financial risks&lt;/h2&gt;&lt;p&gt;Some established global players like Nvidia and Amazon finance their growth through robust cash flows, but many newer AI startups are relying heavily on venture capital or debt funding, thus making them highly vulnerable if funding conditions change. Current enthusiasm around AI can attract emergency funding in some cases, but this reliance on high-risk financing highlights the fragility present in some segments of the AI market.&lt;/p&gt;&lt;h2&gt;One-sided optimism&lt;/h2&gt;&lt;p&gt;Investor sentiment towards AI is very positive, but also bullish. Sceptical perspectives are rarely acknowledged, which may leave the AI market vulnerable to sudden corrections if confidence is lost. Historically, bubbles tend to coincide with rising volatility, but the S&amp;amp;P 500 has remained relatively calm so far, suggesting surface-level stability. However, this may reflect confidence among investors convinced of AI’s promise.&lt;/p&gt;&lt;h2&gt;Inexperienced investors fuelling AI hype?&lt;/h2&gt;&lt;p&gt;According to Day Trading, a surge in inexperienced investors jumping on the AI hype bandwagon may be inflating valuations and heightening the risk of sudden corrections. Much like behaviour seen in the dot-com bubble, new buyers are following extant narratives, at present based on social media buzz and news headlines, instead of focusing on current earnings or real value.&lt;/p&gt;&lt;h2&gt;Liquidity is keeping the AI infrastructure rolling&lt;/h2&gt;&lt;p&gt;Although interest rates are higher compared to pre-pandemic levels, major tech firms have enough liquidity to continue investing heavily in AI without taking too much risk. The ratio of fresh equity or uncertain borrowing remains relatively low.&lt;/p&gt;&lt;h2&gt;Speculative stockpiling&lt;/h2&gt;&lt;p&gt;Some AI companies, like CoreWeave and Open AI, are aggressively hoarding resources, including AI chips and engineering talent, in anticipation of demand. This creates further financial risk if growth in sales were to slow. With no clear ROI or business models in place, capital is at the mercy of AI growth, or lack of it.&lt;/p&gt;&lt;h2&gt;The bubble isn’t burst&lt;/h2&gt;&lt;p&gt;Day Trading’s report highlights a range of concerns, similar to the dot-com bubble of the late 1990s and early 2000s. For instance, AI is already being used at scale, delivering productivity gains, particularly in sectors like finance, logistics, and media, something that was not evident in the dot-com era.&lt;/p&gt;&lt;p&gt;Although AI companies claim to be creating real value right now, compared to infrastructure investments being made, only a few are enjoying profitable margins, like Microsoft and Nvidia.&lt;/p&gt;&lt;p&gt;Substantial investments have been made for long term growth, not short term fast return. Therefore, the true returns may yet materialise as AI’s full potential unfolds over time. Eric Schmidt, former CEO of Google described, “AI as infrastructure for a new industrial era, not just a passing tech fad.”&lt;/p&gt;&lt;p&gt;Dan Buckley does not think AI is just hype, but excessive optimism can be dangerous. “AI is real and valuable,” Buckley said. “But it’s when market sentiment outpaces real business results that I begin to worry about the gap becoming dangerous for investors.”&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/ais-dual-nature-genuine-innovation-amid-localised-bubbles/</guid><pubDate>Tue, 26 Aug 2025 15:23:15 +0000</pubDate></item><item><title>[NEW] Gemini Nano Banana improves image editing consistency and control at scale for enterprises – but is not perfect (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/gemini-expands-image-editing-for-enterprises-consistency-collaboration-and-control-at-scale/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Google released Gemini 2.5 Flash Image, a new model that many beta users knew as nanobanana, which gives enterprises more choice for creative projects. It enables them to change the look of images they need quickly and with more control than what previous models offered.&lt;/p&gt;



&lt;p&gt;The model will be integrated into the Gemini app.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The model, built on top of Gemini 2.5 Flash, adds more capabilities to the native image editing on the Gemini app. Gemini 2.5 Flash Image maintains character likenesses between different images and has more consistency when editing pictures. If a user uploads a photo of their pet and then asks the model to change the background or add a hat to their dog, Gemini 2.5 Flash Image will do that without altering the subject of the picture.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“We know that when editing pictures of yourself or people you know well, subtle flaws matter, a depiction that’s ‘close but not quite the same’ doesn’t feel right,” Google said in a blog post written by Gemini Apps multimodal generation lead David Sharon and Google DeepMind Gemini image product lead Nicole Brichtova. “That’s why our latest update is designed to make photos of your friends, family and even your pets look consistently like themselves.”&amp;nbsp;&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;One complaint enterprises and some individual users had is that when prompting edits on AI-generated images, slight tweaks alter the photo too much. For example, someone may instruct the model to move a person’s position in the picture, and while the model does what it’s told, the person’s face is altered slightly.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3016071" height="450" src="https://venturebeat.com/wp-content/uploads/2025/08/Character-consistency.gif?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;All images generated on Gemini will include Google’s SynthID watermark. The model is available for all paid and free users of the Gemini app.&amp;nbsp;&lt;/p&gt;







&lt;p&gt;Speculation that Google plans to release a new image model ran rampant on social media platforms. Users on LM Arena saw a mysterious new model called nanobanana that followed “complex, multistep instructions with impressive accuracy,” as Andressen Horowitz partner Justine Moore put it in a post.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Mysterious new image edit model hit the arena ?&lt;/p&gt;&lt;p&gt;"Nano-banana" lets you upload TWO images and prompt to combine them.&lt;/p&gt;&lt;p&gt;It can follow complex, multi-step instructions with impressive accuracy. pic.twitter.com/Ylu54w7ge4&lt;/p&gt;— Justine Moore (@venturetwins) August 17, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;People soon noticed that the nanobanana model seemed to come from Google before several early testers confirmed it. Though at the time, Google did not confirm what it planned to do with the model on LM Arena.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Nano-banana is BANANAS! ?&lt;/p&gt;&lt;p&gt;Seriously, it took just my profile pic and this prompt: "Medium shot of the man facing the camera playing guitar on a stage in a bar" &lt;/p&gt;&lt;p&gt;What model is this? I’m betting Imagen 5! ? Any guesses? pic.twitter.com/SAQRcdW2zL&lt;/p&gt;— Anis Aydar (@anisaydar) August 15, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Google’s Nanobanana ? is about the drop an AI model that delivers pro-level Photoshop edits in seconds, with only text.&lt;/p&gt;&lt;p&gt;This the next generation of what "filters" we've been promised forever.&lt;/p&gt;&lt;p&gt;Here's a thread of 10 examples:&lt;/p&gt;&lt;p&gt;Changing facial expressions and the weather.&lt;/p&gt;&lt;p&gt;1/11 pic.twitter.com/M8WCf7JFNT&lt;/p&gt;— Deedy (@deedydas) August 23, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;Up until this week, speculation on when the model would come out continued, which is prophetic in a way.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;p&gt;Much of the excitement comes as the fight between model providers to offer more capable and realistic images and edits, showing how powerful multimodal models have become.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;However, Google still needs to fight off rivals like Qwen and its recently released Qwen-Image Edit and OpenAI, which added native AI image editing to ChatGPT and also made the model available as an API.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Of course, Adobe, long considered one of the leaders in the image editing space, added its flagship model Firefly to Photoshop and its other photo editing platforms.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-native-image-editing-nbsp"&gt;Native image editing&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;Gemini added native AI image editing on Gemini in March, which it offered to free users of the chat platform.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Bringing image editing features directly into the chat platform would allow enterprises to fix images or graphs without moving windows.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Users can upload a photo to Gemini, then tell the model what changes they want. Once they are satisfied, the new pictures can be reuploaded to Gemini and made into a video.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-video"&gt;&lt;video controls="controls" src="https://venturebeat.com/wp-content/uploads/2025/08/Design-mixing.mp4"&gt;&lt;/video&gt;&lt;/figure&gt;



&lt;p&gt;Other than adding a costume or a location change, Gemini 2.5 Flash Image can blend different photos, offers multi-turn editing and mix styles of one picture to another.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Google released Gemini 2.5 Flash Image, a new model that many beta users knew as nanobanana, which gives enterprises more choice for creative projects. It enables them to change the look of images they need quickly and with more control than what previous models offered.&lt;/p&gt;



&lt;p&gt;The model will be integrated into the Gemini app.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The model, built on top of Gemini 2.5 Flash, adds more capabilities to the native image editing on the Gemini app. Gemini 2.5 Flash Image maintains character likenesses between different images and has more consistency when editing pictures. If a user uploads a photo of their pet and then asks the model to change the background or add a hat to their dog, Gemini 2.5 Flash Image will do that without altering the subject of the picture.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“We know that when editing pictures of yourself or people you know well, subtle flaws matter, a depiction that’s ‘close but not quite the same’ doesn’t feel right,” Google said in a blog post written by Gemini Apps multimodal generation lead David Sharon and Google DeepMind Gemini image product lead Nicole Brichtova. “That’s why our latest update is designed to make photos of your friends, family and even your pets look consistently like themselves.”&amp;nbsp;&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;One complaint enterprises and some individual users had is that when prompting edits on AI-generated images, slight tweaks alter the photo too much. For example, someone may instruct the model to move a person’s position in the picture, and while the model does what it’s told, the person’s face is altered slightly.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3016071" height="450" src="https://venturebeat.com/wp-content/uploads/2025/08/Character-consistency.gif?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;All images generated on Gemini will include Google’s SynthID watermark. The model is available for all paid and free users of the Gemini app.&amp;nbsp;&lt;/p&gt;







&lt;p&gt;Speculation that Google plans to release a new image model ran rampant on social media platforms. Users on LM Arena saw a mysterious new model called nanobanana that followed “complex, multistep instructions with impressive accuracy,” as Andressen Horowitz partner Justine Moore put it in a post.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Mysterious new image edit model hit the arena ?&lt;/p&gt;&lt;p&gt;"Nano-banana" lets you upload TWO images and prompt to combine them.&lt;/p&gt;&lt;p&gt;It can follow complex, multi-step instructions with impressive accuracy. pic.twitter.com/Ylu54w7ge4&lt;/p&gt;— Justine Moore (@venturetwins) August 17, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;People soon noticed that the nanobanana model seemed to come from Google before several early testers confirmed it. Though at the time, Google did not confirm what it planned to do with the model on LM Arena.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Nano-banana is BANANAS! ?&lt;/p&gt;&lt;p&gt;Seriously, it took just my profile pic and this prompt: "Medium shot of the man facing the camera playing guitar on a stage in a bar" &lt;/p&gt;&lt;p&gt;What model is this? I’m betting Imagen 5! ? Any guesses? pic.twitter.com/SAQRcdW2zL&lt;/p&gt;— Anis Aydar (@anisaydar) August 15, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Google’s Nanobanana ? is about the drop an AI model that delivers pro-level Photoshop edits in seconds, with only text.&lt;/p&gt;&lt;p&gt;This the next generation of what "filters" we've been promised forever.&lt;/p&gt;&lt;p&gt;Here's a thread of 10 examples:&lt;/p&gt;&lt;p&gt;Changing facial expressions and the weather.&lt;/p&gt;&lt;p&gt;1/11 pic.twitter.com/M8WCf7JFNT&lt;/p&gt;— Deedy (@deedydas) August 23, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;Up until this week, speculation on when the model would come out continued, which is prophetic in a way.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;p&gt;Much of the excitement comes as the fight between model providers to offer more capable and realistic images and edits, showing how powerful multimodal models have become.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;However, Google still needs to fight off rivals like Qwen and its recently released Qwen-Image Edit and OpenAI, which added native AI image editing to ChatGPT and also made the model available as an API.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Of course, Adobe, long considered one of the leaders in the image editing space, added its flagship model Firefly to Photoshop and its other photo editing platforms.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-native-image-editing-nbsp"&gt;Native image editing&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;Gemini added native AI image editing on Gemini in March, which it offered to free users of the chat platform.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Bringing image editing features directly into the chat platform would allow enterprises to fix images or graphs without moving windows.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Users can upload a photo to Gemini, then tell the model what changes they want. Once they are satisfied, the new pictures can be reuploaded to Gemini and made into a video.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-video"&gt;&lt;video controls="controls" src="https://venturebeat.com/wp-content/uploads/2025/08/Design-mixing.mp4"&gt;&lt;/video&gt;&lt;/figure&gt;



&lt;p&gt;Other than adding a costume or a location change, Gemini 2.5 Flash Image can blend different photos, offers multi-turn editing and mix styles of one picture to another.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/gemini-expands-image-editing-for-enterprises-consistency-collaboration-and-control-at-scale/</guid><pubDate>Tue, 26 Aug 2025 15:55:58 +0000</pubDate></item><item><title>[NEW] Crescent library brings privacy to digital identity systems (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/blog/crescent-library-brings-privacy-to-digital-identity-systems/</link><description>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Three white line icons on a gradient background transitioning from blue to pink. From left to right: icon representing a computer chip, padlock icon, an avatar icon" class="wp-image-1148394" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Crescent-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;p&gt;Digital identities, the electronic credentials embedded in phone wallets, workplace logins, and other apps, are becoming ubiquitous. While they offer unprecedented convenience, they also create new privacy risks, particularly around tracking and surveillance.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;One of these risks is &lt;em&gt;linkability, &lt;/em&gt;the ability to associate one or more uses of a credential to a specific person. Currently, when people use their mobile driver’s license or log into various apps, hidden identifiers can link these separate activities together, building detailed profiles of user behavior.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To address this, we have released Crescent&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, a cryptographic library that adds &lt;em&gt;unlinkability &lt;/em&gt;to widely used identity formats, protecting privacy. These include JSON Web Tokens (the authentication standard behind many app logins) and mobile driver’s licenses. Crescent also works without requiring the organizations that issue these credentials to update their systems. &amp;nbsp;&lt;/p&gt;



&lt;p&gt;The protection goes beyond existing privacy features. Some digital identity systems already offer &lt;em&gt;selective disclosure&lt;/em&gt;, allowing users to share only specific pieces of information in each interaction. &amp;nbsp;&lt;/p&gt;



&lt;p&gt;But even with selective disclosure, credentials can still be linked through serial numbers, cryptographic signatures, or embedded identifiers. Crescent’s unlinkability feature is designed to prevent anything in the credential, beyond what a user explicitly chooses to reveal, from being used to connect their separate digital interactions.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 1: Unlinkability between a credential issuance and presentation" class="wp-image-1148323" height="242" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Crescent_fig1_unlinkability.png" width="400" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 1: Unlinkability between a credential issuance and presentation&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="two-paths-to-unlinkability"&gt;Two paths to unlinkability&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;To understand how Crescent works, it helps to examine the two main approaches researchers have developed for adding unlinkability to identity systems:&amp;nbsp;&lt;/p&gt;



&lt;ol class="wp-block-list" start="1"&gt;
&lt;li&gt;&lt;strong&gt;Specialized cryptographic signature schemes&lt;/strong&gt;. These schemes can provide unlinkability but require extensive changes to existing infrastructure. New algorithms must be standardized, implemented, and integrated into software and hardware platforms. For example, the BBS&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; signature scheme is currently being standardized by the Internet Engineering Task Force (IETF), but even after completion, adoption may be slow.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ol&gt;



&lt;ol class="wp-block-list" start="2"&gt;
&lt;li&gt;&lt;strong&gt;Zero-knowledge proofs with existing credentials&lt;/strong&gt;. This approach, used by Crescent&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, allows users to prove specific facts about their credentials without revealing the underlying data that could enable tracking. For example, someone could prove they hold a valid driver’s license and live in a particular ZIP code without exposing any other personal information or identifiers that could link this interaction to future ones.&amp;nbsp;&lt;/li&gt;
&lt;/ol&gt;



&lt;p&gt;Zero-knowledge proofs have become more practical since they were first developed 40 years ago but they are not as efficient as the cryptographic algorithms used in today’s credentials. Crescent addresses this computational challenge through preprocessing, performing the most complex calculations once in advance so that later proof generation is quick and efficient for mobile devices.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Beyond unlinkability, Crescent supports selective disclosure, allowing users to prove specific facts without revealing unnecessary details. For example, it can confirm that a credential is valid and unexpired without disclosing the exact expiration date, which might otherwise serve as a unique identifier. These privacy protections work even when credentials are stored in a phone’s secure hardware, which keeps them tied to the device and prevents unauthorized access.&lt;/p&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;Spotlight: Event Series&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;Microsoft Research Forum&lt;/h2&gt;
				
								&lt;p class="large" id="microsoft-research-forum"&gt;Join us for a continuous exchange of ideas about research in the era of general AI. Watch the first four episodes on demand.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;h2 class="wp-block-heading" id="behind-the-cryptographic-curtain"&gt;Behind the cryptographic curtain&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;At its core, Crescent uses a sophisticated form of cryptographic proof called a zero-knowledge SNARK (Zero-Knowledge Succinct Noninteractive Argument of Knowledge). This method allows one party to prove possession of information or credentials without revealing the underlying data itself.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Crescent specifically uses the Groth16 proof system, one of the first practical implementations of this technology. What makes Groth16 particularly useful is that its proofs are small in size, quick to verify, and can be shared in a single step without back-and-forth communication between the user and verifier.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The system works by first establishing shared cryptographic parameters based on a credential template. Multiple organizations issuing similar credentials, such as different state motor vehicle departments issuing mobile driver’s licenses, can use the same parameters as long as they follow compatible data formats and security standards.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The mathematical rules that define what each proof will verify are written using specialized programming tools that convert them into a Rank-1 Constraint System (R1CS), a mathematical framework that describes exactly what needs to be proven about a credential.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To make the system fast enough for real-world use, Crescent splits the proof generation into two distinct stages:&amp;nbsp;&lt;/p&gt;



&lt;ol class="wp-block-list" start="1"&gt;
&lt;li&gt;&lt;strong&gt;Prepare stage&lt;/strong&gt;. This step runs once and generates cryptographic values that can be stored on the user’s device for repeated use.&amp;nbsp;&lt;/li&gt;
&lt;/ol&gt;



&lt;ol class="wp-block-list" start="2"&gt;
&lt;li&gt;&lt;strong&gt;Show stage&lt;/strong&gt;. When a user needs to present their credential, this quicker step takes the stored values and randomizes them to prevent any connection to previous presentations. It also creates a compact cryptographic summary that reveals only the specific information needed for that particular interaction.&amp;nbsp;&lt;/li&gt;
&lt;/ol&gt;



&lt;p&gt;Figures 2 and 3 illustrate this credential-proving workflow and the division between the prepare and show steps.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 2: Crescent’s credential-proving workflow includes a compilation of a circuit to R1CS, followed by the prepare and show steps. The output zero-knowledge proof is sent to the verifier." class="wp-image-1148322" height="453" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Crescent_fig2_crescent_pipeline.png" width="1400" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 2: Crescent’s credential-proving workflow includes a compilation of a circuit to R1CS, followed by the prepare and show steps. The output zero-knowledge proof is sent to the verifier. &lt;/figcaption&gt;&lt;/figure&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 3: The Crescent presentation steps show the division between prepare and show steps." class="wp-image-1148321" height="443" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Crescent_fig3_proof_overview.png" width="1400" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 3: The Crescent presentation steps show the division between prepare and show steps.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="a-sample-application"&gt;A sample application&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;To demonstrate how Crescent works, we created a sample application covering two real-world scenarios: verifying employment and proving age for online access. The application includes sample code for setting up fictional issuers and verifiers as Rust servers, along with a browser-extension wallet for the user. The step numbers correspond to the steps in Figure 4.&amp;nbsp;&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="setup"&gt;Setup&amp;nbsp;&lt;/h3&gt;



&lt;ol class="wp-block-list" start="1"&gt;
&lt;li&gt;A Crescent service pre-generates the zero-knowledge parameters for creating and verifying proofs from JSON Web Tokens and mobile driver’s licenses.&amp;nbsp;&lt;/li&gt;
&lt;/ol&gt;



&lt;ol class="wp-block-list" start="2"&gt;
&lt;li&gt;The user obtains a mobile driver’s license from their Department of Motor Vehicles.&amp;nbsp;&lt;/li&gt;
&lt;/ol&gt;



&lt;ol class="wp-block-list" start="3"&gt;
&lt;li&gt;The user obtains a proof-of-employment JSON Web Token from their employer, Contoso.&amp;nbsp;&lt;/li&gt;
&lt;/ol&gt;



&lt;ol class="wp-block-list" start="4"&gt;
&lt;li&gt;These credentials and their private keys are stored in the Crescent wallet.&amp;nbsp;&lt;/li&gt;
&lt;/ol&gt;



&lt;h3 class="wp-block-heading" id="scenarios"&gt;Scenarios&amp;nbsp;&lt;/h3&gt;



&lt;ol class="wp-block-list" start="5"&gt;
&lt;li&gt;&lt;strong&gt;Employment verification&lt;/strong&gt;: The user presents their JSON Web Token to Fabrikam, an online health clinic, to prove they are employed at Contoso and eligible for workplace benefits. Fabrikam learns that the user works at Contoso but not the user’s identity, while Contoso remains unaware of the interaction.&amp;nbsp;&lt;/li&gt;
&lt;/ol&gt;



&lt;ol class="wp-block-list" start="6"&gt;
&lt;li&gt;&lt;strong&gt;Age verification&lt;/strong&gt;:&lt;strong&gt; &lt;/strong&gt;The user presents their mobile driver’s license to a social network, proving they are over 18. The proof confirms eligibility without revealing their age or identity.&amp;nbsp;&lt;/li&gt;
&lt;/ol&gt;



&lt;p&gt;Across both scenarios, Crescent ensures that credential presentations remain unlinkable, preventing any party from connecting them to the user.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;For simplicity, the sample defines its own issuance and presentation protocol, but it could be integrated into higher-level identity frameworks such as OpenID/OAuth, Verifiable Credentials, or the mobile driver’s license ecosystem.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 4. The sample architecture, from credential issuance to presentation." class="wp-image-1148404" height="502" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Crescent_fig4_sample-arch.png" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 4. The sample architecture, from credential issuance to presentation.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;To learn more about the project, visit the Crescent project GitHub&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; page, or check out our recent presentations given at the Real-Word Crypto 2025&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; and North Sec 2025&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; conferences.&amp;nbsp;&lt;/p&gt;




&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Three white line icons on a gradient background transitioning from blue to pink. From left to right: icon representing a computer chip, padlock icon, an avatar icon" class="wp-image-1148394" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Crescent-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;p&gt;Digital identities, the electronic credentials embedded in phone wallets, workplace logins, and other apps, are becoming ubiquitous. While they offer unprecedented convenience, they also create new privacy risks, particularly around tracking and surveillance.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;One of these risks is &lt;em&gt;linkability, &lt;/em&gt;the ability to associate one or more uses of a credential to a specific person. Currently, when people use their mobile driver’s license or log into various apps, hidden identifiers can link these separate activities together, building detailed profiles of user behavior.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To address this, we have released Crescent&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, a cryptographic library that adds &lt;em&gt;unlinkability &lt;/em&gt;to widely used identity formats, protecting privacy. These include JSON Web Tokens (the authentication standard behind many app logins) and mobile driver’s licenses. Crescent also works without requiring the organizations that issue these credentials to update their systems. &amp;nbsp;&lt;/p&gt;



&lt;p&gt;The protection goes beyond existing privacy features. Some digital identity systems already offer &lt;em&gt;selective disclosure&lt;/em&gt;, allowing users to share only specific pieces of information in each interaction. &amp;nbsp;&lt;/p&gt;



&lt;p&gt;But even with selective disclosure, credentials can still be linked through serial numbers, cryptographic signatures, or embedded identifiers. Crescent’s unlinkability feature is designed to prevent anything in the credential, beyond what a user explicitly chooses to reveal, from being used to connect their separate digital interactions.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 1: Unlinkability between a credential issuance and presentation" class="wp-image-1148323" height="242" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Crescent_fig1_unlinkability.png" width="400" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 1: Unlinkability between a credential issuance and presentation&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="two-paths-to-unlinkability"&gt;Two paths to unlinkability&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;To understand how Crescent works, it helps to examine the two main approaches researchers have developed for adding unlinkability to identity systems:&amp;nbsp;&lt;/p&gt;



&lt;ol class="wp-block-list" start="1"&gt;
&lt;li&gt;&lt;strong&gt;Specialized cryptographic signature schemes&lt;/strong&gt;. These schemes can provide unlinkability but require extensive changes to existing infrastructure. New algorithms must be standardized, implemented, and integrated into software and hardware platforms. For example, the BBS&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; signature scheme is currently being standardized by the Internet Engineering Task Force (IETF), but even after completion, adoption may be slow.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ol&gt;



&lt;ol class="wp-block-list" start="2"&gt;
&lt;li&gt;&lt;strong&gt;Zero-knowledge proofs with existing credentials&lt;/strong&gt;. This approach, used by Crescent&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, allows users to prove specific facts about their credentials without revealing the underlying data that could enable tracking. For example, someone could prove they hold a valid driver’s license and live in a particular ZIP code without exposing any other personal information or identifiers that could link this interaction to future ones.&amp;nbsp;&lt;/li&gt;
&lt;/ol&gt;



&lt;p&gt;Zero-knowledge proofs have become more practical since they were first developed 40 years ago but they are not as efficient as the cryptographic algorithms used in today’s credentials. Crescent addresses this computational challenge through preprocessing, performing the most complex calculations once in advance so that later proof generation is quick and efficient for mobile devices.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Beyond unlinkability, Crescent supports selective disclosure, allowing users to prove specific facts without revealing unnecessary details. For example, it can confirm that a credential is valid and unexpired without disclosing the exact expiration date, which might otherwise serve as a unique identifier. These privacy protections work even when credentials are stored in a phone’s secure hardware, which keeps them tied to the device and prevents unauthorized access.&lt;/p&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;Spotlight: Event Series&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;Microsoft Research Forum&lt;/h2&gt;
				
								&lt;p class="large" id="microsoft-research-forum"&gt;Join us for a continuous exchange of ideas about research in the era of general AI. Watch the first four episodes on demand.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;h2 class="wp-block-heading" id="behind-the-cryptographic-curtain"&gt;Behind the cryptographic curtain&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;At its core, Crescent uses a sophisticated form of cryptographic proof called a zero-knowledge SNARK (Zero-Knowledge Succinct Noninteractive Argument of Knowledge). This method allows one party to prove possession of information or credentials without revealing the underlying data itself.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Crescent specifically uses the Groth16 proof system, one of the first practical implementations of this technology. What makes Groth16 particularly useful is that its proofs are small in size, quick to verify, and can be shared in a single step without back-and-forth communication between the user and verifier.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The system works by first establishing shared cryptographic parameters based on a credential template. Multiple organizations issuing similar credentials, such as different state motor vehicle departments issuing mobile driver’s licenses, can use the same parameters as long as they follow compatible data formats and security standards.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The mathematical rules that define what each proof will verify are written using specialized programming tools that convert them into a Rank-1 Constraint System (R1CS), a mathematical framework that describes exactly what needs to be proven about a credential.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To make the system fast enough for real-world use, Crescent splits the proof generation into two distinct stages:&amp;nbsp;&lt;/p&gt;



&lt;ol class="wp-block-list" start="1"&gt;
&lt;li&gt;&lt;strong&gt;Prepare stage&lt;/strong&gt;. This step runs once and generates cryptographic values that can be stored on the user’s device for repeated use.&amp;nbsp;&lt;/li&gt;
&lt;/ol&gt;



&lt;ol class="wp-block-list" start="2"&gt;
&lt;li&gt;&lt;strong&gt;Show stage&lt;/strong&gt;. When a user needs to present their credential, this quicker step takes the stored values and randomizes them to prevent any connection to previous presentations. It also creates a compact cryptographic summary that reveals only the specific information needed for that particular interaction.&amp;nbsp;&lt;/li&gt;
&lt;/ol&gt;



&lt;p&gt;Figures 2 and 3 illustrate this credential-proving workflow and the division between the prepare and show steps.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 2: Crescent’s credential-proving workflow includes a compilation of a circuit to R1CS, followed by the prepare and show steps. The output zero-knowledge proof is sent to the verifier." class="wp-image-1148322" height="453" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Crescent_fig2_crescent_pipeline.png" width="1400" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 2: Crescent’s credential-proving workflow includes a compilation of a circuit to R1CS, followed by the prepare and show steps. The output zero-knowledge proof is sent to the verifier. &lt;/figcaption&gt;&lt;/figure&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 3: The Crescent presentation steps show the division between prepare and show steps." class="wp-image-1148321" height="443" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Crescent_fig3_proof_overview.png" width="1400" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 3: The Crescent presentation steps show the division between prepare and show steps.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="a-sample-application"&gt;A sample application&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;To demonstrate how Crescent works, we created a sample application covering two real-world scenarios: verifying employment and proving age for online access. The application includes sample code for setting up fictional issuers and verifiers as Rust servers, along with a browser-extension wallet for the user. The step numbers correspond to the steps in Figure 4.&amp;nbsp;&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="setup"&gt;Setup&amp;nbsp;&lt;/h3&gt;



&lt;ol class="wp-block-list" start="1"&gt;
&lt;li&gt;A Crescent service pre-generates the zero-knowledge parameters for creating and verifying proofs from JSON Web Tokens and mobile driver’s licenses.&amp;nbsp;&lt;/li&gt;
&lt;/ol&gt;



&lt;ol class="wp-block-list" start="2"&gt;
&lt;li&gt;The user obtains a mobile driver’s license from their Department of Motor Vehicles.&amp;nbsp;&lt;/li&gt;
&lt;/ol&gt;



&lt;ol class="wp-block-list" start="3"&gt;
&lt;li&gt;The user obtains a proof-of-employment JSON Web Token from their employer, Contoso.&amp;nbsp;&lt;/li&gt;
&lt;/ol&gt;



&lt;ol class="wp-block-list" start="4"&gt;
&lt;li&gt;These credentials and their private keys are stored in the Crescent wallet.&amp;nbsp;&lt;/li&gt;
&lt;/ol&gt;



&lt;h3 class="wp-block-heading" id="scenarios"&gt;Scenarios&amp;nbsp;&lt;/h3&gt;



&lt;ol class="wp-block-list" start="5"&gt;
&lt;li&gt;&lt;strong&gt;Employment verification&lt;/strong&gt;: The user presents their JSON Web Token to Fabrikam, an online health clinic, to prove they are employed at Contoso and eligible for workplace benefits. Fabrikam learns that the user works at Contoso but not the user’s identity, while Contoso remains unaware of the interaction.&amp;nbsp;&lt;/li&gt;
&lt;/ol&gt;



&lt;ol class="wp-block-list" start="6"&gt;
&lt;li&gt;&lt;strong&gt;Age verification&lt;/strong&gt;:&lt;strong&gt; &lt;/strong&gt;The user presents their mobile driver’s license to a social network, proving they are over 18. The proof confirms eligibility without revealing their age or identity.&amp;nbsp;&lt;/li&gt;
&lt;/ol&gt;



&lt;p&gt;Across both scenarios, Crescent ensures that credential presentations remain unlinkable, preventing any party from connecting them to the user.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;For simplicity, the sample defines its own issuance and presentation protocol, but it could be integrated into higher-level identity frameworks such as OpenID/OAuth, Verifiable Credentials, or the mobile driver’s license ecosystem.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 4. The sample architecture, from credential issuance to presentation." class="wp-image-1148404" height="502" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Crescent_fig4_sample-arch.png" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 4. The sample architecture, from credential issuance to presentation.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;To learn more about the project, visit the Crescent project GitHub&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; page, or check out our recent presentations given at the Real-Word Crypto 2025&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; and North Sec 2025&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; conferences.&amp;nbsp;&lt;/p&gt;




&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/blog/crescent-library-brings-privacy-to-digital-identity-systems/</guid><pubDate>Tue, 26 Aug 2025 16:00:00 +0000</pubDate></item><item><title>[NEW] Google Translate takes on Duolingo with new language learning tools (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/26/google-translate-takes-on-duolingo-with-new-language-learning-tools/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is rolling out a new AI-powered experimental feature in Google Translate designed to help people practice and learn a new language, the company announced on Tuesday. Translate is also gaining new live capabilities to make it easier to communicate in real time with a person speaking a different language.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new language practice feature is designed for both beginners starting to learn conversational skills and advanced speakers looking to brush up on their vocabulary, the company says. To do so, it creates tailored listening and speaking practice sessions that adapt to a user’s skill level and unique learning goals.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With this new language practice feature, Google is taking on Duolingo, the popular language learning app that uses a gamified approach to help users practice over 40 languages. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3039816" height="680" src="https://techcrunch.com/wp-content/uploads/2025/08/Google-Translate-Language-learning-GIF.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;To access the feature, you’ll select the “practice” option in the Google Translate app. From there, you can set skill level and goals. Google Translate then generates customized scenarios where you can either listen to conversations and tap the words you hear to build comprehension, or you can practice speaking. The exercises track users’ daily progress, Google says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The beta experience is rolling out in the Google Translate app for Android and iOS starting Tuesday. The feature is available first for English speakers practicing Spanish and French, as well as for Spanish, French, and Portuguese speakers practicing English.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google is also introducing the ability for users to have back-and-forth conversations with audio and on-screen translations through the Translate app.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Building on our existing live conversation experience, our advanced AI models are now making it even easier to have a live conversation in more than 70 languages — including Arabic, French, Hindi, Korean, Spanish, and Tamil,” Google wrote in a blog post. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3039819" height="680" src="https://techcrunch.com/wp-content/uploads/2025/08/Google-Translate-Live-GIF.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;You can tap the “Live translate” option in the Translate app and then select the language you want to translate by simply speaking. You’ll then hear the translation aloud alongside a transcript of your conversation in both languages. The app will translate and switch between the two languages that you and the other person are speaking. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google notes that the feature can identify pauses, accents, and intonations to allow for a natural-sounding conversation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The feature uses Google’s voice and speech recognition models to isolate sounds, which means you would be able to use the live capabilities in a loud restaurant or busy airport.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;These live translation capabilities are available starting Tuesday for users in the U.S., India, and Mexico.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“These updates are made possible by advancements in AI and machine learning,” Google wrote in its blog post. “As we continue to push the boundaries of language processing and understanding, we are able to serve a wider range of languages and improve the quality and speed of translations. And with our Gemini models in Translate, we’ve been able to take huge strides in translation quality, multimodal translation, and text-to-speech (TTS) capabilities.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google says that people translate around 1 trillion words across Translate, Search, Lens, and Circle to Search. The company believes these new AI-powered features will help overcome language barriers. &lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is rolling out a new AI-powered experimental feature in Google Translate designed to help people practice and learn a new language, the company announced on Tuesday. Translate is also gaining new live capabilities to make it easier to communicate in real time with a person speaking a different language.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new language practice feature is designed for both beginners starting to learn conversational skills and advanced speakers looking to brush up on their vocabulary, the company says. To do so, it creates tailored listening and speaking practice sessions that adapt to a user’s skill level and unique learning goals.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With this new language practice feature, Google is taking on Duolingo, the popular language learning app that uses a gamified approach to help users practice over 40 languages. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3039816" height="680" src="https://techcrunch.com/wp-content/uploads/2025/08/Google-Translate-Language-learning-GIF.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;To access the feature, you’ll select the “practice” option in the Google Translate app. From there, you can set skill level and goals. Google Translate then generates customized scenarios where you can either listen to conversations and tap the words you hear to build comprehension, or you can practice speaking. The exercises track users’ daily progress, Google says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The beta experience is rolling out in the Google Translate app for Android and iOS starting Tuesday. The feature is available first for English speakers practicing Spanish and French, as well as for Spanish, French, and Portuguese speakers practicing English.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google is also introducing the ability for users to have back-and-forth conversations with audio and on-screen translations through the Translate app.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Building on our existing live conversation experience, our advanced AI models are now making it even easier to have a live conversation in more than 70 languages — including Arabic, French, Hindi, Korean, Spanish, and Tamil,” Google wrote in a blog post. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3039819" height="680" src="https://techcrunch.com/wp-content/uploads/2025/08/Google-Translate-Live-GIF.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;You can tap the “Live translate” option in the Translate app and then select the language you want to translate by simply speaking. You’ll then hear the translation aloud alongside a transcript of your conversation in both languages. The app will translate and switch between the two languages that you and the other person are speaking. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google notes that the feature can identify pauses, accents, and intonations to allow for a natural-sounding conversation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The feature uses Google’s voice and speech recognition models to isolate sounds, which means you would be able to use the live capabilities in a loud restaurant or busy airport.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;These live translation capabilities are available starting Tuesday for users in the U.S., India, and Mexico.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“These updates are made possible by advancements in AI and machine learning,” Google wrote in its blog post. “As we continue to push the boundaries of language processing and understanding, we are able to serve a wider range of languages and improve the quality and speed of translations. And with our Gemini models in Translate, we’ve been able to take huge strides in translation quality, multimodal translation, and text-to-speech (TTS) capabilities.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google says that people translate around 1 trillion words across Translate, Search, Lens, and Circle to Search. The company believes these new AI-powered features will help overcome language barriers. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/26/google-translate-takes-on-duolingo-with-new-language-learning-tools/</guid><pubDate>Tue, 26 Aug 2025 16:00:00 +0000</pubDate></item><item><title>[NEW] Google improves Gemini AI image editing with “nano banana” model (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/08/google-improves-gemini-ai-image-editing-with-nano-banana-model/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Gemini 2.5 Flash Image is currently atop LMArena's image-editing leaderboard.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Gemini icon macro" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/04/Gemini-1-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Gemini icon macro" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/04/Gemini-1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Ryan Whitwam

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Something unusual happened in the world of AI image editing recently. A new model, known as "nano banana," started making the rounds with impressive abilities that landed it at the top of the LMArena leaderboard. Now, Google has revealed that nano banana is an innovation from Google DeepMind, and it's being rolled out to the Gemini app today.&lt;/p&gt;
&lt;p&gt;AI image editing allows you to modify images with a prompt rather than mucking around in Photoshop. Google first provided editing capabilities in Gemini earlier this year, and the model was more than competent out of the gate. But like all generative systems, the non-deterministic nature meant that elements of the image would often change in unpredictable ways. Google says nano banana (technically Gemini 2.5 Flash Image) has unrivaled consistency across edits—it can actually remember the details instead of rolling the dice every time you make a change.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2113789-1" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/Character-consistency.mp4?_=1" type="video/mp4" /&gt;Google says subjects will retain their appearance as you edit.&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Google says subjects will retain their appearance as you edit.

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;This unlocks several interesting uses for AI image editing. Google suggests uploading a photo of a person and changing their style or attire. For example, you can reimagine someone as a matador or a '90s sitcom character. Because the nano banana model can maintain consistency through edits, the results should still look like the person in the original source image. This is also the case when you make multiple edits in a row. Google says that even down the line, the results should look like the original source material.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2113789-2" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/Blend-photos-together.mp4?_=2" type="video/mp4" /&gt;The goodest boy.&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The goodest boy.

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Gemini's enhanced image editing can also merge multiple images, allowing you to use them as the fodder for a new image of your choosing. Google's example below takes separate images of a woman and a dog and uses them to generate a new snapshot of the dog getting cuddles—possibly the best use of generative AI yet. Gemini image editing can also merge things in more abstract ways and will follow your prompts to create just about anything that doesn't run afoul of the model's guard rails.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2113789-3" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/Multi-turn-editing.mp4?_=3" type="video/mp4" /&gt;The model remembers details instead of generating completely new things every time.&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The model remembers details instead of generating completely new things every time.

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;As with other Google AI image-generation models, the output of Gemini 2.5 Flash Image always comes with a visible "AI" watermark in the corner. The image also has an invisible SynthID digital watermark that can be detected even after moderate modification.&lt;/p&gt;
&lt;p&gt;You can give the new native image editing a shot today in the Gemini app. Google says the new image model will also roll out soon in the Gemini API, AI Studio, and Vertex AI for developers.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Gemini 2.5 Flash Image is currently atop LMArena's image-editing leaderboard.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Gemini icon macro" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/04/Gemini-1-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Gemini icon macro" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/04/Gemini-1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Ryan Whitwam

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Something unusual happened in the world of AI image editing recently. A new model, known as "nano banana," started making the rounds with impressive abilities that landed it at the top of the LMArena leaderboard. Now, Google has revealed that nano banana is an innovation from Google DeepMind, and it's being rolled out to the Gemini app today.&lt;/p&gt;
&lt;p&gt;AI image editing allows you to modify images with a prompt rather than mucking around in Photoshop. Google first provided editing capabilities in Gemini earlier this year, and the model was more than competent out of the gate. But like all generative systems, the non-deterministic nature meant that elements of the image would often change in unpredictable ways. Google says nano banana (technically Gemini 2.5 Flash Image) has unrivaled consistency across edits—it can actually remember the details instead of rolling the dice every time you make a change.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2113789-1" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/Character-consistency.mp4?_=1" type="video/mp4" /&gt;Google says subjects will retain their appearance as you edit.&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Google says subjects will retain their appearance as you edit.

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;This unlocks several interesting uses for AI image editing. Google suggests uploading a photo of a person and changing their style or attire. For example, you can reimagine someone as a matador or a '90s sitcom character. Because the nano banana model can maintain consistency through edits, the results should still look like the person in the original source image. This is also the case when you make multiple edits in a row. Google says that even down the line, the results should look like the original source material.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2113789-2" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/Blend-photos-together.mp4?_=2" type="video/mp4" /&gt;The goodest boy.&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The goodest boy.

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Gemini's enhanced image editing can also merge multiple images, allowing you to use them as the fodder for a new image of your choosing. Google's example below takes separate images of a woman and a dog and uses them to generate a new snapshot of the dog getting cuddles—possibly the best use of generative AI yet. Gemini image editing can also merge things in more abstract ways and will follow your prompts to create just about anything that doesn't run afoul of the model's guard rails.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2113789-3" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/Multi-turn-editing.mp4?_=3" type="video/mp4" /&gt;The model remembers details instead of generating completely new things every time.&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The model remembers details instead of generating completely new things every time.

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;As with other Google AI image-generation models, the output of Gemini 2.5 Flash Image always comes with a visible "AI" watermark in the corner. The image also has an invisible SynthID digital watermark that can be detected even after moderate modification.&lt;/p&gt;
&lt;p&gt;You can give the new native image editing a shot today in the Gemini app. Google says the new image model will also roll out soon in the Gemini API, AI Studio, and Vertex AI for developers.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/08/google-improves-gemini-ai-image-editing-with-nano-banana-model/</guid><pubDate>Tue, 26 Aug 2025 16:03:34 +0000</pubDate></item><item><title>[NEW] After falling behind in generative AI, IBM and AMD look to quantum for an edge (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/26/after-falling-behind-in-generative-ai-ibm-and-amd-look-to-quantum-for-an-edge/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/IBM_Quantum_System_Two.jpg?w=400" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;IBM and AMD are partnering to develop next-generation computing architectures that integrate IBM’s quantum systems with AMD’s AI-specialized chips. The move could position both the tech giant and chipmaker as key infrastructure players as they look to regain ground after falling behind on the generative AI boom.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Together, IBM and AMD will attempt to launch a commercially viable quantum computing architecture — one that’s scalable and open sourced. In other words, it will be more widely accessible to researchers and developers solving complex real-world problems in fields like drug and materials discovery, optimization, and logistics, per IBM.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Quantum computing will simulate the natural world and represent information in an entirely new way,” said Arvind Krishna, chairman and CEO of IBM, in a statement. “By exploring how quantum computers from IBM and the advanced high-performance compute technologies of AMD can work together, we will build a powerful hybrid model that pushes past the limits of traditional computing.”&lt;/p&gt;

&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Got a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at&amp;nbsp;&lt;/em&gt;&lt;em&gt;rebecca.bellan@techcrunch.com&lt;/em&gt;&lt;em&gt;&amp;nbsp;and Maxwell Zeff at&amp;nbsp;&lt;/em&gt;&lt;em&gt;maxwell.zeff@techcrunch.com&lt;/em&gt;&lt;em&gt;. For secure communication, you can contact us via Signal at&amp;nbsp;@rebeccabellan.491 and&amp;nbsp;@mzeff.88.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/IBM_Quantum_System_Two.jpg?w=400" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;IBM and AMD are partnering to develop next-generation computing architectures that integrate IBM’s quantum systems with AMD’s AI-specialized chips. The move could position both the tech giant and chipmaker as key infrastructure players as they look to regain ground after falling behind on the generative AI boom.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Together, IBM and AMD will attempt to launch a commercially viable quantum computing architecture — one that’s scalable and open sourced. In other words, it will be more widely accessible to researchers and developers solving complex real-world problems in fields like drug and materials discovery, optimization, and logistics, per IBM.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Quantum computing will simulate the natural world and represent information in an entirely new way,” said Arvind Krishna, chairman and CEO of IBM, in a statement. “By exploring how quantum computers from IBM and the advanced high-performance compute technologies of AMD can work together, we will build a powerful hybrid model that pushes past the limits of traditional computing.”&lt;/p&gt;

&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Got a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at&amp;nbsp;&lt;/em&gt;&lt;em&gt;rebecca.bellan@techcrunch.com&lt;/em&gt;&lt;em&gt;&amp;nbsp;and Maxwell Zeff at&amp;nbsp;&lt;/em&gt;&lt;em&gt;maxwell.zeff@techcrunch.com&lt;/em&gt;&lt;em&gt;. For secure communication, you can contact us via Signal at&amp;nbsp;@rebeccabellan.491 and&amp;nbsp;@mzeff.88.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/26/after-falling-behind-in-generative-ai-ibm-and-amd-look-to-quantum-for-an-edge/</guid><pubDate>Tue, 26 Aug 2025 16:04:02 +0000</pubDate></item><item><title>[NEW] Meta to spend tens of millions on pro-AI super PAC (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/26/meta-to-spend-tens-of-millions-on-pro-ai-super-pac/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-2225880947.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta plans to launch a super PAC to support California candidates favoring a light-touch approach to AI regulation, Politico reports. The news comes as other Silicon Valley behemoths, like Andreessen Horowitz and OpenAI’s Greg Brockman, pledge $100 million for a new pro-AI super PAC.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta will pour tens of millions into its new group, dubbed Mobilizing Economic Transformation Across California, according to Politico. Brian Rice, Meta’s VP of public policy and head of the new PAC, has argued that Sacramento’s regulatory environment “could stifle innovation, block AI progress, and put California’s technology leadership at risk.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Meta’s lobbying force earlier this year targeted state senator Scott Wiener’s SB-53 bill that would require AI firms to publish safety and security protocols and issue reports when safety incidents occur. Last year, it helped kill the Kids Online Safety Act that was widely expected to pass.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The social media giant has already donated to various down-ballet candidates from both parties. This new PAC signals an intent to influence statewide elections, including the next governor’s race in 2026.&lt;/p&gt;

&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Got a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at&amp;nbsp;&lt;/em&gt;&lt;em&gt;rebecca.bellan@techcrunch.com&lt;/em&gt;&lt;em&gt;&amp;nbsp;and Maxwell Zeff at&amp;nbsp;&lt;/em&gt;&lt;em&gt;maxwell.zeff@techcrunch.com&lt;/em&gt;&lt;em&gt;. For secure communication, you can contact us via Signal at&amp;nbsp;@rebeccabellan.491 and&amp;nbsp;@mzeff.88.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-2225880947.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta plans to launch a super PAC to support California candidates favoring a light-touch approach to AI regulation, Politico reports. The news comes as other Silicon Valley behemoths, like Andreessen Horowitz and OpenAI’s Greg Brockman, pledge $100 million for a new pro-AI super PAC.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta will pour tens of millions into its new group, dubbed Mobilizing Economic Transformation Across California, according to Politico. Brian Rice, Meta’s VP of public policy and head of the new PAC, has argued that Sacramento’s regulatory environment “could stifle innovation, block AI progress, and put California’s technology leadership at risk.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Meta’s lobbying force earlier this year targeted state senator Scott Wiener’s SB-53 bill that would require AI firms to publish safety and security protocols and issue reports when safety incidents occur. Last year, it helped kill the Kids Online Safety Act that was widely expected to pass.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The social media giant has already donated to various down-ballet candidates from both parties. This new PAC signals an intent to influence statewide elections, including the next governor’s race in 2026.&lt;/p&gt;

&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Got a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at&amp;nbsp;&lt;/em&gt;&lt;em&gt;rebecca.bellan@techcrunch.com&lt;/em&gt;&lt;em&gt;&amp;nbsp;and Maxwell Zeff at&amp;nbsp;&lt;/em&gt;&lt;em&gt;maxwell.zeff@techcrunch.com&lt;/em&gt;&lt;em&gt;. For secure communication, you can contact us via Signal at&amp;nbsp;@rebeccabellan.491 and&amp;nbsp;@mzeff.88.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/26/meta-to-spend-tens-of-millions-on-pro-ai-super-pac/</guid><pubDate>Tue, 26 Aug 2025 17:59:39 +0000</pubDate></item><item><title>[NEW] Libby’s library app adds an AI discovery feature, and not everyone is thrilled (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/26/libbys-library-app-adds-an-ai-discovery-feature-and-not-everyone-is-thrilled/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Library e-book and audiobook app Libby is adding AI, much to the disappointment of some readers and librarians, who would prefer not to have AI inserted into their favorite apps. The new feature, “Inspire Me,” allows users to get book recommendations by using prompts or from their previously saved titles in Libby.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To use the feature, readers tap on the “Inspire Me” options on Libby’s home page, where they can ask for fiction or nonfiction, then narrow down the suggestions by other factors, like age range, type of content, and more. For instance, you might tap on suggestions like “spine-tingling” or “amusing,” then on particular scenarios, such as “dark humor about modern family dysfunction” or “time travelers rescue dragons from medieval knights.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3039996" height="469" src="https://techcrunch.com/wp-content/uploads/2025/08/libby-ai.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Screenshot&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Overdrive/Libby&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The app will then display five relevant titles that match the requested inspiration. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Overdrive, the company that makes the Libby app, says the feature relies on each library’s digital collection, so it will point to books the library offers. It also prioritizes titles that are immediately available to borrow.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While a fairly basic use case for AI, some Libby users and librarians are pushing back at the addition via posts on social media sites, saying they’d prefer to get book recommendations without the use of AI technology. Others are worried about the potential privacy issues that come with some AI experiences.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Overdrive, however, clarifies in a policy document about Libby’s use of AI that it avoids collecting “inessential personal information,” and when it does use your personal information, it’s not shared with third parties or artificial intelligence models. The company also says that users’ details and activity aren’t shared with the AI model. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, if you share one of your saved tags with the AI to get suggestions, it doesn’t receive any details about you, your device, or the name or description of your tag — it only gets the titles to use for recommendations. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Perhaps expecting some pushback against the new addition, Overdrive stressed in its announcement that its goal was not to replace “human insight” with a generative AI feature. Rather, it says the feature could be used to “complement” librarian-led discovery. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Inspire Me uses responsible AI integration to help patrons dive deeper into the incredible catalogs their local libraries have curated,” according to a statement from Jen Leitman, OverDrive’s Chief Marketing Officer. “By surfacing titles that align with what readers are searching for, Inspire Me helps patrons discover more of the books their libraries have already invested in. It’s not about replacing human insight, it’s about making discovery easier, smarter, and more intuitive,” she noted.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company soft-launched the feature earlier this month, allowing users to search for “#InspireMe” in Libby’s app to gain access. Now officially announced and rolling out, all Libby users should expect to gain access to the feature in September. &lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Library e-book and audiobook app Libby is adding AI, much to the disappointment of some readers and librarians, who would prefer not to have AI inserted into their favorite apps. The new feature, “Inspire Me,” allows users to get book recommendations by using prompts or from their previously saved titles in Libby.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To use the feature, readers tap on the “Inspire Me” options on Libby’s home page, where they can ask for fiction or nonfiction, then narrow down the suggestions by other factors, like age range, type of content, and more. For instance, you might tap on suggestions like “spine-tingling” or “amusing,” then on particular scenarios, such as “dark humor about modern family dysfunction” or “time travelers rescue dragons from medieval knights.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3039996" height="469" src="https://techcrunch.com/wp-content/uploads/2025/08/libby-ai.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Screenshot&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Overdrive/Libby&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The app will then display five relevant titles that match the requested inspiration. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Overdrive, the company that makes the Libby app, says the feature relies on each library’s digital collection, so it will point to books the library offers. It also prioritizes titles that are immediately available to borrow.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While a fairly basic use case for AI, some Libby users and librarians are pushing back at the addition via posts on social media sites, saying they’d prefer to get book recommendations without the use of AI technology. Others are worried about the potential privacy issues that come with some AI experiences.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Overdrive, however, clarifies in a policy document about Libby’s use of AI that it avoids collecting “inessential personal information,” and when it does use your personal information, it’s not shared with third parties or artificial intelligence models. The company also says that users’ details and activity aren’t shared with the AI model. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, if you share one of your saved tags with the AI to get suggestions, it doesn’t receive any details about you, your device, or the name or description of your tag — it only gets the titles to use for recommendations. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Perhaps expecting some pushback against the new addition, Overdrive stressed in its announcement that its goal was not to replace “human insight” with a generative AI feature. Rather, it says the feature could be used to “complement” librarian-led discovery. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Inspire Me uses responsible AI integration to help patrons dive deeper into the incredible catalogs their local libraries have curated,” according to a statement from Jen Leitman, OverDrive’s Chief Marketing Officer. “By surfacing titles that align with what readers are searching for, Inspire Me helps patrons discover more of the books their libraries have already invested in. It’s not about replacing human insight, it’s about making discovery easier, smarter, and more intuitive,” she noted.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company soft-launched the feature earlier this month, allowing users to search for “#InspireMe” in Libby’s app to gain access. Now officially announced and rolling out, all Libby users should expect to gain access to the feature in September. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/26/libbys-library-app-adds-an-ai-discovery-feature-and-not-everyone-is-thrilled/</guid><pubDate>Tue, 26 Aug 2025 18:15:26 +0000</pubDate></item><item><title>[NEW] Why the U.S. government is not the savior Intel needs (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/26/why-the-u-s-government-is-not-the-savior-intel-needs/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-2228936694.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The Trump administration made an unprecedented, and confusing, move last week when it announced plans to convert money Intel was supposed to receive through Joe Biden-era government grant programs into a 10% equity stake.&lt;/p&gt;&lt;p&gt;While it remains unclear if converting those government grants into equity is even possible — that’s up for debate — it’s even less obvious how this move will solve Intel’s biggest problem,&amp;nbsp;its waffling foundry business. Even Intel is unconvinced.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Intel Foundry, which manufactures custom semiconductors for outside customers, has not been fruitful for the company. The business division lost out on potential big contracts, like one with Sony, according to Reuters, and has cost the company significantly more than it has brought in.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Intel Foundry reported an operating income loss of $3.1 billion in the second quarter. The company has also laid off thousands of people since the beginning of the year with the foundry business unit being hit especially hard.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Differences over how Intel would turnaround its struggling foundry business was partially responsible for Lip-Bu Tan’s resignation from the company board in August 2024. Tan was appointed CEO in spring 2025.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kevin Cassidy, a managing director at Rosenblatt Securities, told TechCrunch he doesn’t see how this deal will solve Intel’s problems. Intel Foundry doesn’t need money to solve its issues, he said, instead it needs to change its approach to its customers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“They didn’t understand customer service,” Cassidy said of Intel Foundry’s struggles to sign customers. “They have always manufactured internally, the manufacturing group was king. It’s hard to be a customer service-focused group when you think you know better.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Intel did not respond to a request for comment.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h2 class="wp-block-heading" id="h-ripple-effect"&gt;Ripple effect&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Intel recently acknowledged the potential downsides of this deal in an SEC filing posted Monday. The company highlighted the risks it carries for its investors and customers —&amp;nbsp;two groups of people Intel naturally relies on.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This deal dilutes existing shareholders and reduces their governance rights. The Trump administration said it would vote alongside Intel’s interests, which could help the company move its ideas forward; but business decisions that actively sour an existing investor base conflicts with efforts to drum up investor interest.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I would be disappointed if I was a stockholder,” Cassidy said. “Intel gave up another 430 million shares, and diluted my shares, and [they] were able to buy it at a 20% discount.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Intel also mentioned the potential impact this could have on its international business. The vast majority of the company’s revenue in its last fiscal year, 76%, came from outside the U.S., the company reported.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amid the current U.S.-led international trade turmoil, companies outside the United States will now have to grapple with whether or not to work with a company partially owned by the U.S. government.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-sending-signals"&gt;Sending signals&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Not everyone is doom and gloom about the recent transaction. Cody Acree, managing director and senior research analyst at Benchmark Company, told TechCrunch he doesn’t see the company’s international customers shying away from Intel.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Acree said the deal isn’t perfect, but the government’s commitment to Intel’s future may give the chipmaker the boost it needs —&amp;nbsp;even if it’s just a small step on a long road to recovery.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Intel has shown that it’s been struggling for the last decade and may need some kind of government intervention, a bail out is probably too harsh of a term, but the government intervention is being seen as at least a stepping stone toward reinvigorating Intel,” Acree said. “I don’t necessarily agree with it being a fix-all by any means. It’s at least encouraging to know that the government is backing Intel instead of challenging the leadership as they were a month ago.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Andrew Rocco, a stock strategist at Zacks Investment Research, agreed that a deal with the U.S. government could be positive. In an interview before the deal was formally announced, Rocco said that this could give Intel a bigger role in the administration’s current push for domestic AI prowess through initiatives like OpenAI, SoftBank, and Oracle’s Stargate initiative and bringing semiconductor manufacturing stateside.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The market is going to be so big, the datacenter and chip market, even if they get a small slice,” Rocco said. “There is room for them to succeed. This will be a positive. You have to have a five-to-10-year time horizon.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, both analysts cautioned the deal won’t be Intel’s savior. For a true, long-standing rescue, Intel needs to look inward. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While the Trump administration claims it will be a passive investor, that doesn’t mean its involvement can’t drum up business for the company, Acree said. While that hopefully wouldn’t come from pressure or force, Cassidy said, it definitely could.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even though the government might not have to. Unlike higher education, corporate America has proven itself more than happy to lean toward the Trump administration’s goals and policies. Companies have gutted their diversity, equity, and inclusion programs —&amp;nbsp;despite hurting themselves in the process. A prevalence of pro-America sentiment has become saturated in advertisements and company communication since Donald Trump took office in January.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If the Trump administration tells American companies to buy Intel’s chips and hardware, they might not have to do as much convincing to get companies on board.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Acree and Cassidy said the real test for Intel won’t be the deal, or even the optics of it. It will be whether Intel can drum up interest for its 14A chipmaking processor. Tan has said the company would not start production on its 14A chipmaking process until they secured substantial customer interest.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“There is still no guarantee that Intel is going to be able to come back into the market at the leading edge,” Cassidy said. “Intel has been burning cash for quite a few years, I don’t know if it is just more money to buy time to find the formula to get them back on the leading edge.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-2228936694.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The Trump administration made an unprecedented, and confusing, move last week when it announced plans to convert money Intel was supposed to receive through Joe Biden-era government grant programs into a 10% equity stake.&lt;/p&gt;&lt;p&gt;While it remains unclear if converting those government grants into equity is even possible — that’s up for debate — it’s even less obvious how this move will solve Intel’s biggest problem,&amp;nbsp;its waffling foundry business. Even Intel is unconvinced.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Intel Foundry, which manufactures custom semiconductors for outside customers, has not been fruitful for the company. The business division lost out on potential big contracts, like one with Sony, according to Reuters, and has cost the company significantly more than it has brought in.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Intel Foundry reported an operating income loss of $3.1 billion in the second quarter. The company has also laid off thousands of people since the beginning of the year with the foundry business unit being hit especially hard.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Differences over how Intel would turnaround its struggling foundry business was partially responsible for Lip-Bu Tan’s resignation from the company board in August 2024. Tan was appointed CEO in spring 2025.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kevin Cassidy, a managing director at Rosenblatt Securities, told TechCrunch he doesn’t see how this deal will solve Intel’s problems. Intel Foundry doesn’t need money to solve its issues, he said, instead it needs to change its approach to its customers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“They didn’t understand customer service,” Cassidy said of Intel Foundry’s struggles to sign customers. “They have always manufactured internally, the manufacturing group was king. It’s hard to be a customer service-focused group when you think you know better.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Intel did not respond to a request for comment.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h2 class="wp-block-heading" id="h-ripple-effect"&gt;Ripple effect&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Intel recently acknowledged the potential downsides of this deal in an SEC filing posted Monday. The company highlighted the risks it carries for its investors and customers —&amp;nbsp;two groups of people Intel naturally relies on.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This deal dilutes existing shareholders and reduces their governance rights. The Trump administration said it would vote alongside Intel’s interests, which could help the company move its ideas forward; but business decisions that actively sour an existing investor base conflicts with efforts to drum up investor interest.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I would be disappointed if I was a stockholder,” Cassidy said. “Intel gave up another 430 million shares, and diluted my shares, and [they] were able to buy it at a 20% discount.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Intel also mentioned the potential impact this could have on its international business. The vast majority of the company’s revenue in its last fiscal year, 76%, came from outside the U.S., the company reported.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amid the current U.S.-led international trade turmoil, companies outside the United States will now have to grapple with whether or not to work with a company partially owned by the U.S. government.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-sending-signals"&gt;Sending signals&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Not everyone is doom and gloom about the recent transaction. Cody Acree, managing director and senior research analyst at Benchmark Company, told TechCrunch he doesn’t see the company’s international customers shying away from Intel.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Acree said the deal isn’t perfect, but the government’s commitment to Intel’s future may give the chipmaker the boost it needs —&amp;nbsp;even if it’s just a small step on a long road to recovery.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Intel has shown that it’s been struggling for the last decade and may need some kind of government intervention, a bail out is probably too harsh of a term, but the government intervention is being seen as at least a stepping stone toward reinvigorating Intel,” Acree said. “I don’t necessarily agree with it being a fix-all by any means. It’s at least encouraging to know that the government is backing Intel instead of challenging the leadership as they were a month ago.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Andrew Rocco, a stock strategist at Zacks Investment Research, agreed that a deal with the U.S. government could be positive. In an interview before the deal was formally announced, Rocco said that this could give Intel a bigger role in the administration’s current push for domestic AI prowess through initiatives like OpenAI, SoftBank, and Oracle’s Stargate initiative and bringing semiconductor manufacturing stateside.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The market is going to be so big, the datacenter and chip market, even if they get a small slice,” Rocco said. “There is room for them to succeed. This will be a positive. You have to have a five-to-10-year time horizon.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, both analysts cautioned the deal won’t be Intel’s savior. For a true, long-standing rescue, Intel needs to look inward. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While the Trump administration claims it will be a passive investor, that doesn’t mean its involvement can’t drum up business for the company, Acree said. While that hopefully wouldn’t come from pressure or force, Cassidy said, it definitely could.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even though the government might not have to. Unlike higher education, corporate America has proven itself more than happy to lean toward the Trump administration’s goals and policies. Companies have gutted their diversity, equity, and inclusion programs —&amp;nbsp;despite hurting themselves in the process. A prevalence of pro-America sentiment has become saturated in advertisements and company communication since Donald Trump took office in January.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If the Trump administration tells American companies to buy Intel’s chips and hardware, they might not have to do as much convincing to get companies on board.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Acree and Cassidy said the real test for Intel won’t be the deal, or even the optics of it. It will be whether Intel can drum up interest for its 14A chipmaking processor. Tan has said the company would not start production on its 14A chipmaking process until they secured substantial customer interest.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“There is still no guarantee that Intel is going to be able to come back into the market at the leading edge,” Cassidy said. “Intel has been burning cash for quite a few years, I don’t know if it is just more money to buy time to find the formula to get them back on the leading edge.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/26/why-the-u-s-government-is-not-the-savior-intel-needs/</guid><pubDate>Tue, 26 Aug 2025 18:29:01 +0000</pubDate></item></channel></rss>