<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 27 Feb 2026 02:22:46 +0000</lastBuildDate><item><title>2 days left: Lock in the best discounts for TechCrunch Disrupt 2026 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/26/2-days-left-lock-in-the-best-discounts-for-techcrunch-disrupt-2026/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Super Early Bird pricing ends &lt;strong&gt;tomorrow, February 27, at 11:59 p.m. PT&lt;/strong&gt;. After that, prices for &lt;strong&gt;TechCrunch Disrupt 2026&lt;/strong&gt; go up. Miss this, and you’ll be paying more for the same access to one of the most anticipated tech events of the year. &lt;strong&gt;Register now&lt;/strong&gt; to secure discounts of up to $680 on your pass, or up to 30% on &lt;strong&gt;group passes&lt;/strong&gt;.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2026 2 days left" class="wp-image-3094855" height="383" src="https://techcrunch.com/wp-content/uploads/2026/02/TCD26_2Days-16X9-dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-disrupt-your-launchpad-in-the-tech-ecosystem"&gt;Disrupt: Your launchpad in the tech ecosystem&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;If you want to raise capital, hire top talent, launch your startup, or discover your next portfolio company, don’t miss&amp;nbsp;&lt;strong&gt;Disrupt&lt;/strong&gt;, taking place October 13–15 at San Francisco’s Moscone West.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Here’s&amp;nbsp;what&amp;nbsp;you’ll&amp;nbsp;gain by attending:&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Actionable insights&amp;nbsp;from builders, operators, and VCs actively shaping today’s market&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Direct access to the right investors&amp;nbsp;for your next round, or founders aligned with your portfolio&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Early visibility into breakthrough innovations&amp;nbsp;before they hit the broader market&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Connections that drive real impact, from partnerships to funding to career opportunities&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt" class="wp-image-2539741" height="383" src="https://techcrunch.com/wp-content/uploads/2023/05/ac_crowd.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-how-disrupt-nbsp-delivers-nbsp-value"&gt;How Disrupt&amp;nbsp;delivers&amp;nbsp;value&lt;/h3&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Access to&amp;nbsp;10,000+&amp;nbsp;founders, operators, and VCs&amp;nbsp;with targeted programming&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Tactical, real-world&amp;nbsp;onstage discussions&amp;nbsp;with&amp;nbsp;250+&amp;nbsp;of&amp;nbsp;today’s market leaders&amp;nbsp;spanning multiple industry stages, roundtables, and breakout sessions&lt;/li&gt;
&lt;/ul&gt;





&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;20,000+ curated&amp;nbsp;1:1 or small-group&amp;nbsp;networking&amp;nbsp;designed for&amp;nbsp;real, actionable results&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;80+ Side Events across the Bay Area&amp;nbsp;for networking, workshops, and social connections&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt Expo Hall" class="wp-image-2571166" height="383" src="https://techcrunch.com/wp-content/uploads/2023/07/expo_hall.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Eric Slomonson, The Photo Group&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-exclusive-nbsp-programming-for-founders-and-investors"&gt;Exclusive&amp;nbsp;programming for founders and investors&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Founder Pass&lt;/strong&gt;: Accelerate growth with the right insights, tools, and connections. Meet investors aligned with your startup.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Investor Pass&lt;/strong&gt;: Discover standout startups and expand your portfolio with curated access. Use matchmaking tools to make every conversation count.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-don-t-nbsp-miss-disrupt-at-the-biggest-discounts"&gt;Don’t&amp;nbsp;miss Disrupt at the biggest discounts&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;This window to the lowest ticket rates of the year is closing after tomorrow&amp;nbsp;ends.&amp;nbsp;&lt;strong&gt;Register now&lt;/strong&gt;&amp;nbsp;to secure your ticket with&amp;nbsp;up to a&amp;nbsp;$680 discount.&amp;nbsp;Or save up to 30%&amp;nbsp;with&amp;nbsp;&lt;strong&gt;community passes&lt;/strong&gt;&amp;nbsp;of 4+.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Salva Health Co-Founder &amp;amp; CEO Valentina Agudelo Vargas, winner of the Startup Battlefield 2024, poses onstage during TechCrunch Disrupt 2024 Day 3 at Moscone Center on October 30, 2024 in San Francisco." class="wp-image-2913234" height="453" src="https://techcrunch.com/wp-content/uploads/2024/11/54105085427_2cae9d0502_o.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kimberly White / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Super Early Bird pricing ends &lt;strong&gt;tomorrow, February 27, at 11:59 p.m. PT&lt;/strong&gt;. After that, prices for &lt;strong&gt;TechCrunch Disrupt 2026&lt;/strong&gt; go up. Miss this, and you’ll be paying more for the same access to one of the most anticipated tech events of the year. &lt;strong&gt;Register now&lt;/strong&gt; to secure discounts of up to $680 on your pass, or up to 30% on &lt;strong&gt;group passes&lt;/strong&gt;.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2026 2 days left" class="wp-image-3094855" height="383" src="https://techcrunch.com/wp-content/uploads/2026/02/TCD26_2Days-16X9-dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-disrupt-your-launchpad-in-the-tech-ecosystem"&gt;Disrupt: Your launchpad in the tech ecosystem&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;If you want to raise capital, hire top talent, launch your startup, or discover your next portfolio company, don’t miss&amp;nbsp;&lt;strong&gt;Disrupt&lt;/strong&gt;, taking place October 13–15 at San Francisco’s Moscone West.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Here’s&amp;nbsp;what&amp;nbsp;you’ll&amp;nbsp;gain by attending:&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Actionable insights&amp;nbsp;from builders, operators, and VCs actively shaping today’s market&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Direct access to the right investors&amp;nbsp;for your next round, or founders aligned with your portfolio&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Early visibility into breakthrough innovations&amp;nbsp;before they hit the broader market&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Connections that drive real impact, from partnerships to funding to career opportunities&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt" class="wp-image-2539741" height="383" src="https://techcrunch.com/wp-content/uploads/2023/05/ac_crowd.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-how-disrupt-nbsp-delivers-nbsp-value"&gt;How Disrupt&amp;nbsp;delivers&amp;nbsp;value&lt;/h3&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Access to&amp;nbsp;10,000+&amp;nbsp;founders, operators, and VCs&amp;nbsp;with targeted programming&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Tactical, real-world&amp;nbsp;onstage discussions&amp;nbsp;with&amp;nbsp;250+&amp;nbsp;of&amp;nbsp;today’s market leaders&amp;nbsp;spanning multiple industry stages, roundtables, and breakout sessions&lt;/li&gt;
&lt;/ul&gt;





&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;20,000+ curated&amp;nbsp;1:1 or small-group&amp;nbsp;networking&amp;nbsp;designed for&amp;nbsp;real, actionable results&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;80+ Side Events across the Bay Area&amp;nbsp;for networking, workshops, and social connections&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt Expo Hall" class="wp-image-2571166" height="383" src="https://techcrunch.com/wp-content/uploads/2023/07/expo_hall.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Eric Slomonson, The Photo Group&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-exclusive-nbsp-programming-for-founders-and-investors"&gt;Exclusive&amp;nbsp;programming for founders and investors&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Founder Pass&lt;/strong&gt;: Accelerate growth with the right insights, tools, and connections. Meet investors aligned with your startup.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Investor Pass&lt;/strong&gt;: Discover standout startups and expand your portfolio with curated access. Use matchmaking tools to make every conversation count.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-don-t-nbsp-miss-disrupt-at-the-biggest-discounts"&gt;Don’t&amp;nbsp;miss Disrupt at the biggest discounts&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;This window to the lowest ticket rates of the year is closing after tomorrow&amp;nbsp;ends.&amp;nbsp;&lt;strong&gt;Register now&lt;/strong&gt;&amp;nbsp;to secure your ticket with&amp;nbsp;up to a&amp;nbsp;$680 discount.&amp;nbsp;Or save up to 30%&amp;nbsp;with&amp;nbsp;&lt;strong&gt;community passes&lt;/strong&gt;&amp;nbsp;of 4+.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Salva Health Co-Founder &amp;amp; CEO Valentina Agudelo Vargas, winner of the Startup Battlefield 2024, poses onstage during TechCrunch Disrupt 2024 Day 3 at Moscone Center on October 30, 2024 in San Francisco." class="wp-image-2913234" height="453" src="https://techcrunch.com/wp-content/uploads/2024/11/54105085427_2cae9d0502_o.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kimberly White / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/26/2-days-left-lock-in-the-best-discounts-for-techcrunch-disrupt-2026/</guid><pubDate>Thu, 26 Feb 2026 15:00:00 +0000</pubDate></item><item><title>Finding value with AI and Industry 5.0 transformation (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/26/1133707/finding-value-with-ai-and-industry-5-0-transformation/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In association with&lt;/span&gt;EY&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;For years, Industry 4.0 transformation has centered on the convergence of intelligent technologies like AI, cloud, the internet of things, robotics, and digital twins. Industry 5.0 marks a pivotal shift from integrating emerging technologies to orchestrating them at scale. With Industry 5.0, the purpose of this interconnected web of technologies is more nuanced: to augment human potential, not just automate work, and enhance environmental sustainability.&lt;/p&gt;  &lt;figure class="wp-block-image alignright size-large"&gt;&lt;img alt="alt" class="wp-image-1133715" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/MIT_EY3_V8-revCoverPage.png?w=1555" width="1555" /&gt;&lt;/figure&gt;  &lt;p&gt;Industry 5.0 has ushered in a radically new level of collaboration between humans and machines, one that removes data silos and optimizes infrastructure, operations, and resource use to disrupt business models and create new forms of enterprise value. But without discipline in tracking value creation, investments risk being wasted on incremental efficiency gains rather than strategic growth.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;  &lt;p&gt;“To realize the promise of Industry 5.0, companies must move beyond cost and efficiency to focus on growth, resilience, and human-centric outcomes,” says Sachin Lulla, EY Americas industrials and energy transformation leader. “This requires not just new technologies, but new ways of working—where people and machines collaborate, and where value is measured not just in dollars saved, but in new opportunities created.”&lt;/p&gt;  &lt;p&gt;An MIT Technology Review Insights survey of 250 industry leaders from around the world reveals most industrial investments still target efficiency. And while the data shows human-centric and sustainable use cases deliver higher value, they are underfunded. The research shows most organizations are not realizing the full value potential of Industry 5.0 due to a combination of:&lt;/p&gt; 
 &lt;p&gt;• Culture, skills, and collaboration barriers.&lt;br /&gt;• Tactical and misaligned technology investments.&lt;br /&gt;• Use-case prioritization focused on efficiency over growth, sustainability, and well-being.&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1133717" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/MITTR_V1_EY32026SocialsCard3.png" /&gt;&lt;/figure&gt;  &lt;p&gt;The barrier to achieving Industry 5.0 transformation is not only about fixing the technology, according to research from EY and Saïd Business School at the University of Oxford, it is also about bolstering human-centric elements like strategy, culture, and leadership. Companies are investing heavily in digital transformation, but not always in ways that unlock the full human potential of Industry 5.0.&lt;/p&gt; 
 &lt;p&gt;“We’re not just doing digital work for work’s sake, what I call ‘chasing the digital fairies,’” says Chris Ware, general manager, iron ore digital, Rio Tinto. “We have to be very clear on what pieces of work we go after and why. Every domain has a unique roadmap about how to deliver the best value.”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Download the full report.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In association with&lt;/span&gt;EY&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;For years, Industry 4.0 transformation has centered on the convergence of intelligent technologies like AI, cloud, the internet of things, robotics, and digital twins. Industry 5.0 marks a pivotal shift from integrating emerging technologies to orchestrating them at scale. With Industry 5.0, the purpose of this interconnected web of technologies is more nuanced: to augment human potential, not just automate work, and enhance environmental sustainability.&lt;/p&gt;  &lt;figure class="wp-block-image alignright size-large"&gt;&lt;img alt="alt" class="wp-image-1133715" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/MIT_EY3_V8-revCoverPage.png?w=1555" width="1555" /&gt;&lt;/figure&gt;  &lt;p&gt;Industry 5.0 has ushered in a radically new level of collaboration between humans and machines, one that removes data silos and optimizes infrastructure, operations, and resource use to disrupt business models and create new forms of enterprise value. But without discipline in tracking value creation, investments risk being wasted on incremental efficiency gains rather than strategic growth.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;  &lt;p&gt;“To realize the promise of Industry 5.0, companies must move beyond cost and efficiency to focus on growth, resilience, and human-centric outcomes,” says Sachin Lulla, EY Americas industrials and energy transformation leader. “This requires not just new technologies, but new ways of working—where people and machines collaborate, and where value is measured not just in dollars saved, but in new opportunities created.”&lt;/p&gt;  &lt;p&gt;An MIT Technology Review Insights survey of 250 industry leaders from around the world reveals most industrial investments still target efficiency. And while the data shows human-centric and sustainable use cases deliver higher value, they are underfunded. The research shows most organizations are not realizing the full value potential of Industry 5.0 due to a combination of:&lt;/p&gt; 
 &lt;p&gt;• Culture, skills, and collaboration barriers.&lt;br /&gt;• Tactical and misaligned technology investments.&lt;br /&gt;• Use-case prioritization focused on efficiency over growth, sustainability, and well-being.&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1133717" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/MITTR_V1_EY32026SocialsCard3.png" /&gt;&lt;/figure&gt;  &lt;p&gt;The barrier to achieving Industry 5.0 transformation is not only about fixing the technology, according to research from EY and Saïd Business School at the University of Oxford, it is also about bolstering human-centric elements like strategy, culture, and leadership. Companies are investing heavily in digital transformation, but not always in ways that unlock the full human potential of Industry 5.0.&lt;/p&gt; 
 &lt;p&gt;“We’re not just doing digital work for work’s sake, what I call ‘chasing the digital fairies,’” says Chris Ware, general manager, iron ore digital, Rio Tinto. “We have to be very clear on what pieces of work we go after and why. Every domain has a unique roadmap about how to deliver the best value.”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Download the full report.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/26/1133707/finding-value-with-ai-and-industry-5-0-transformation/</guid><pubDate>Thu, 26 Feb 2026 15:00:59 +0000</pubDate></item><item><title>Google launches Nano Banana 2 model with faster image generation (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/26/google-launches-nano-banana-2-model-with-faster-image-generation/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google today announced the latest version of its popular image generation model, Nano Banana 2. The new model, which is technically Gemini 3.1 Flash Image, can create more realistic images than its predecessor. The model will also now become the default in the Gemini app for its Fast, Thinking, and Pro modes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company first released Nano Banana in August 2025, prompting people to generate millions of images in the Gemini app, especially in countries like India. In November, the company released Nano Banana Pro, which allows users to create more detailed and high-quality images.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The new Nano Banana 2 retains some of the high-fidelity characteristics of the Pro model but produces images faster. The company says you can create images with a resolution ranging from 512px to 4K, in different aspect ratios.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="A comparison of image generation between Nano Banana Pro and Nano Banana 2" class="wp-image-3097378" height="383" src="https://techcrunch.com/wp-content/uploads/2026/02/Museum.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Nano Banana 2 can maintain character consistency for up to five characters and fidelity of up to 14 objects in one workflow for better storytelling. Users can also issue complex requests with detailed nuances for image generation, Google says. In addition, users can create media with more vibrant lighting, richer textures, and sharper detail.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3097382" height="383" src="https://techcrunch.com/wp-content/uploads/2026/02/Multi-Input.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;With the launch, Nano Banana 2 will become the default model for image generation across all apps in the Gemini app. The company is also making it the default model for image generation in its video editing tool, Flow. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In Search, Nano Banana 2 will become the default for Google Search results via Google Lens and in AI Mode across 141 countries on the Google app and on the web across desktop and mobile.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Google’s higher-end plans, Google AI Pro and Ultra, subscribers can continue to use Nano Banana Pro for specialized tasks by regenerating images via the three-dot menu.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3097380" height="383" src="https://techcrunch.com/wp-content/uploads/2026/02/Translation.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;For developers, Nano Banana 2 will be available in preview through the Gemini API, Gemini CLI, and the Vertex API. It will also be available through AI Studio and the company’s development tool Antigravity, which was released last November. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company said that all images created through the new model will have a SynthID watermark, which is Google’s mark to denote AI-generated images. The images are also interoperable with C2PA Content Credentials, created by an industry body consisting of companies like Adobe, Microsoft, Google, OpenAI, and Meta. Google said that since launching the SynthID verification in the Gemini app in November, people have used it over 20 million times.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google today announced the latest version of its popular image generation model, Nano Banana 2. The new model, which is technically Gemini 3.1 Flash Image, can create more realistic images than its predecessor. The model will also now become the default in the Gemini app for its Fast, Thinking, and Pro modes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company first released Nano Banana in August 2025, prompting people to generate millions of images in the Gemini app, especially in countries like India. In November, the company released Nano Banana Pro, which allows users to create more detailed and high-quality images.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The new Nano Banana 2 retains some of the high-fidelity characteristics of the Pro model but produces images faster. The company says you can create images with a resolution ranging from 512px to 4K, in different aspect ratios.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="A comparison of image generation between Nano Banana Pro and Nano Banana 2" class="wp-image-3097378" height="383" src="https://techcrunch.com/wp-content/uploads/2026/02/Museum.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Nano Banana 2 can maintain character consistency for up to five characters and fidelity of up to 14 objects in one workflow for better storytelling. Users can also issue complex requests with detailed nuances for image generation, Google says. In addition, users can create media with more vibrant lighting, richer textures, and sharper detail.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3097382" height="383" src="https://techcrunch.com/wp-content/uploads/2026/02/Multi-Input.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;With the launch, Nano Banana 2 will become the default model for image generation across all apps in the Gemini app. The company is also making it the default model for image generation in its video editing tool, Flow. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In Search, Nano Banana 2 will become the default for Google Search results via Google Lens and in AI Mode across 141 countries on the Google app and on the web across desktop and mobile.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Google’s higher-end plans, Google AI Pro and Ultra, subscribers can continue to use Nano Banana Pro for specialized tasks by regenerating images via the three-dot menu.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3097380" height="383" src="https://techcrunch.com/wp-content/uploads/2026/02/Translation.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;For developers, Nano Banana 2 will be available in preview through the Gemini API, Gemini CLI, and the Vertex API. It will also be available through AI Studio and the company’s development tool Antigravity, which was released last November. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company said that all images created through the new model will have a SynthID watermark, which is Google’s mark to denote AI-generated images. The images are also interoperable with C2PA Content Credentials, created by an industry body consisting of companies like Adobe, Microsoft, Google, OpenAI, and Meta. Google said that since launching the SynthID verification in the Gemini app in November, people have used it over 20 million times.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/26/google-launches-nano-banana-2-model-with-faster-image-generation/</guid><pubDate>Thu, 26 Feb 2026 16:00:00 +0000</pubDate></item><item><title>Nano Banana 2: Combining Pro capabilities with lightning-fast speed (Google DeepMind News)</title><link>https://deepmind.google/blog/nano-banana-2-combining-pro-capabilities-with-lightning-fast-speed/</link><description>&lt;div class="article-image-hero"&gt;
  &lt;div class="article-image-hero__container"&gt;
    &lt;figure class="article-image--full-aspect article-module"&gt;
      &lt;div class="aspect-ratio-image"&gt;
        &lt;div class="aspect-ratio-image__container"&gt;
          &lt;img alt="Nano Banana 2 text with AI generated images around it" class="aspect-ratio-image__image uni-progressive-image--blur" height="150px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/NB2_Hero.width-2200.format-webp.webp" width="360px" /&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      
    &lt;/figure&gt;
  &lt;/div&gt;
&lt;/div&gt;&lt;div class="uni-content uni-blog-article-container article-container__content
                      
                      "&gt;

            
  
    



















&lt;div class="audio-player-tts"&gt;
  &lt;audio class="audio-player-tts__player" title="Nano Banana 2: Combining Pro capabilities with lightning\u002Dfast speed"&gt;
      &lt;source src="https://storage.googleapis.com/gweb-uniblog-publish-prod/media/tts_audio_83457_umbriel_2026_02_26_19_16_59.wav" type="audio/x-wav" /&gt;
      &lt;p&gt;Your browser does not support the audio element.&lt;/p&gt;
  &lt;/audio&gt;
  &lt;div class="audio-player-tts__container"&gt;
    &lt;div class="audio-player-tts__content"&gt;
      &lt;button class="audio-player-tts__preview-play"&gt;
        &lt;svg class="icon audio-player-tts__play-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

      &lt;/button&gt;
      &lt;div class="audio-player-tts__text-content"&gt;
        &lt;span class="audio-player-tts__text-content--title"&gt;
          Listen to article
          &lt;span class="audio-player-tts__disclaimer" tabindex="0"&gt;
            &lt;div class="audio-player-tts__disclaimer--copy uni-small-text"&gt;This content is generated by Google AI. Generative AI is experimental&lt;/div&gt;
            &lt;svg class="audio-player-tts__disclaimer--icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

          &lt;/span&gt;
        &lt;/span&gt;
        &lt;div class="audio-player-tts__duration uni-small-text"&gt;[[duration]] minutes&lt;/div&gt;
      &lt;/div&gt;
      &lt;button class="audio-player-tts__pause"&gt;
        &lt;svg class="icon audio-player-tts__icon-play" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

        &lt;svg class="icon audio-player-tts__icon-pause audio-player-tts__icon-pause--hidden" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

      &lt;/button&gt;
      &lt;div class="audio-player-tts__console"&gt;
        &lt;div class="audio-player-tts__time-bar"&gt;
          &lt;span class="audio-player-tts__current-time uni-small-text"&gt;&lt;/span&gt;
          &lt;div class="audio-player-tts__timeline-slider-container"&gt;
            &lt;input class="timeline__slider" max="100" step="5" tabindex="0" type="range" value="0" /&gt;
          &lt;/div&gt;
          &lt;span class="audio-player-tts__duration-time uni-small-text"&gt;&lt;/span&gt;
        &lt;/div&gt;
        &lt;button class="audio-player-tts__audio-settings"&gt;
          &lt;svg class="icon audio-player-tts__audio-settings--icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

        &lt;/button&gt;
        &lt;div class="audio-player-tts__settings-container"&gt;
          &lt;div class="audio-player-tts__settings--main uni-cta-text"&gt;
            &lt;button class="audio-player-tts__settings--current-voice"&gt;
              &lt;span class="audio-player-tts__settings--current-voice-info"&gt;
                &lt;svg class="audio-player-tts__settings--current-voice-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

                &lt;span&gt;Voice&lt;/span&gt;
              &lt;/span&gt;
              &lt;span class="audio-player-tts__settings--current-voice-next"&gt;
                &lt;span class="audio-player-tts__settings--current-voice-text uni-small-text"&gt;&lt;/span&gt;
                &lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

              &lt;/span&gt;
            &lt;/button&gt;
            &lt;button class="audio-player-tts__settings--current-speed"&gt;
              &lt;span class="audio-player-tts__settings--current-speed-info"&gt;
                  &lt;svg class="audio-player-tts__settings--current-speed-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

                  &lt;span&gt;Speed&lt;/span&gt;
                &lt;/span&gt;
                &lt;span class="audio-player-tts__settings--current-speed-next"&gt;
                  &lt;span class="audio-player-tts__settings--current-speed-text uni-small-text"&gt;&lt;/span&gt;
                  &lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

                &lt;/span&gt;
            &lt;/button&gt;
          &lt;/div&gt;
          &lt;div class="audio-player-tts__settings--voices uni-cta-text"&gt;
            &lt;button class="audio-player-tts__settings-back"&gt;&lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;
 &lt;span&gt;Voice&lt;/span&gt;&lt;/button&gt;
          &lt;/div&gt;
          &lt;div class="audio-player-tts__settings--speeds uni-cta-text"&gt;
            &lt;button class="audio-player-tts__settings-back"&gt;&lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;
 &lt;span&gt;Speed&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option"&gt;&lt;span&gt;0.75X&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option audio-player-tts__settings-option--selected"&gt;&lt;span&gt;1X&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option"&gt;&lt;span&gt;1.5X&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option"&gt;&lt;span&gt;2X&lt;/span&gt;&lt;/button&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

  





            
            
&lt;!--article text--&gt;

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;In August of last year, our Gemini Image model, Nano Banana, became a viral sensation, redefining image generation and editing. Then in November, we released Nano Banana Pro, offering users advanced intelligence and studio-quality creative control. Today, we’re bringing the best of both worlds to users across Google.&lt;/p&gt;&lt;p&gt;Introducing Nano Banana 2 (Gemini 3.1 Flash Image), our latest state-of-the-art image model. Now you can get the advanced world knowledge, quality and reasoning you love in Nano Banana Pro, at lightning-fast speed.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Intelligence and visual quality at Flash speed&lt;/h2&gt;&lt;p&gt;Nano Banana 2 brings the high-speed intelligence of Gemini Flash to visual generation, making rapid edits and iteration possible. It makes once-exclusive Pro features accessible to a wider audience, including:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Advanced world knowledge:&lt;/b&gt; The model pulls from Gemini’s real-world knowledge base, and is powered by real-time information and images from web search to more accurately render specific subjects. This deep understanding also helps you create infographics, turn notes into diagrams and generate data visualizations.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Precision text rendering and translation&lt;/b&gt;: Nano Banana 2 allows you to generate accurate, legible text for marketing mockups or greeting cards. You can even translate and localize text within an image to share your ideas globally.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    


































  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;A flat lay infographic depicting the water cycle&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Triptych infographic comparing cloud types&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Museum Clos Lucé in Synthetic Cubism style&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Localized "Native Wildlife" sign&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;&lt;i&gt;Read the prompts: Water Cycle&lt;/i&gt;



  &lt;sup&gt;1&lt;/sup&gt;

&lt;i&gt;, Cloud Infographic&lt;/i&gt;



  &lt;sup&gt;2&lt;/sup&gt;

&lt;i&gt;, Cubism&lt;/i&gt;



  &lt;sup&gt;3&lt;/sup&gt;

&lt;i&gt;, Wildlife Sign&lt;/i&gt;



  &lt;sup&gt;4&lt;/sup&gt;

&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Enhanced creative control&lt;/h2&gt;&lt;p&gt;Nano Banana 2 also dramatically closes the gap between speed and visual fidelity, delivering high-quality, photorealistic imagery. Here’s what our newest model offers and has improved on from the original Nano Banana:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Subject consistency:&lt;/b&gt; Maintain character resemblance of up to five characters and the fidelity of up to 14 objects in a single workflow, allowing you to storyboard and build narratives without altering the appearance of your inputs.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Precise instruction following:&lt;/b&gt; With enhanced instruction following, the model adheres more strictly to your complex requests, capturing the specific nuances of your idea so the image you get is the image you asked for.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Production-ready specs&lt;/b&gt;: Make attention grabbing assets with full control of various aspect ratios and resolutions from 512px to 4K, ensuring your visuals stay sharp whether they are for a vertical social post or a wide-screen backdrop.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Visual fidelity upgrade:&lt;/b&gt; Nano Banana 2 delivers vibrant lighting, richer textures and sharper details, maintaining high-quality aesthetics at the speed expected from Flash.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    


































  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Joyful characters and items at a farm&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Fluffy friends building a treehouse&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Misty panoramic aerial shot of a verdant valley&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Highly stylized pop-art fashion portrait in different aspect ratios&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;&lt;i&gt;Read the prompts: Farm&lt;/i&gt;



  &lt;sup&gt;5&lt;/sup&gt;

&lt;i&gt;, Treehouse&lt;/i&gt;



  &lt;sup&gt;6&lt;/sup&gt;

&lt;i&gt;, Valley&lt;/i&gt;



  &lt;sup&gt;7&lt;/sup&gt;

&lt;i&gt;, Portrait&lt;/i&gt;



  &lt;sup&gt;8&lt;/sup&gt;

&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Try Nano Banana 2 today&lt;/h2&gt;&lt;p&gt;Whatever your needs, we now offer the perfect tool for every workflow: Nano Banana Pro for high-fidelity tasks requiring maximum factual accuracy, or Nano Banana 2 for rapid generation, precise instruction following and integrated image-search grounding.&lt;/p&gt;&lt;p&gt;Nano Banana 2 is rolling out today across Google products, including:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Gemini app:&lt;/b&gt; Nano Banana 2 will replace Nano Banana Pro across the Fast, Thinking and Pro models. Google AI Pro and Ultra subscribers will keep access to Nano Banana Pro for specialized tasks by regenerating images via the three-dot menu.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Search:&lt;/b&gt; In AI Mode and Lens, through the Google app as well as mobile and desktop browsers. View availability here, including 141 new countries and territories and eight additional languages.&lt;/li&gt;&lt;li&gt;&lt;b&gt;AI Studio + API:&lt;/b&gt; Available in preview in AI Studio and Gemini API. Pricing here. Also available in Google Antigravity.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Google Cloud:&lt;/b&gt; Available in preview with the Gemini API in Vertex AI.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Flow:&lt;/b&gt; Nano Banana 2 is the new default image generation model in Flow, available to all Flow users for zero credits.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Google Ads:&lt;/b&gt; Nano Banana 2 is available now, powering suggestions while creating campaigns in Google Ads.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    


































  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Try Nano Banana 2 in the Gemini app, using the new templates feature.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;World knowledge from Nano Banana 2 in AI Mode in Search.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Subject preservation from Nano Banana 2 in Flow.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Read the prompts: AI Mode in Search



  &lt;sup&gt;9&lt;/sup&gt;

, Flow



  &lt;sup&gt;10&lt;/sup&gt;

&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Robust provenance: marking and verification&lt;/h2&gt;&lt;p&gt;As generative media evolves, so must the tools we use to identify and understand it. We continue to deepen our provenance approach, by coupling our state-of-the-art SynthID technology with interoperable C2PA Content Credentials, we provide users with a more holistic and contextual view of not just if AI was used, but how.&lt;/p&gt;&lt;p&gt;Our provenance tools are already making an impact. Since its launch in November, our SynthID verification feature in Gemini app has been used over 20 million times across various languages, helping people identify Google AI-generated images, video and audio. We’ll soon be bringing C2PA verification to the Gemini app, too.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    

  
    





&lt;div class="newsletter-form article-newsletter-form"&gt;
  &lt;div class="newsletter-form__container"&gt;
    &lt;div class="newsletter-form__envelope"&gt;
      &lt;div class="envelope-back"&gt;
        &lt;img alt="alt" src="https://blog.google/static/blogv2/images/newsletter-envelope-back.svg?version=pr20260219-1731" /&gt;
      &lt;/div&gt;
      &lt;div class="envelope-letter-approved"&gt;
        &lt;img alt="alt" src="https://blog.google/static/blogv2/images/newsletter-envelope-letter-approved.svg?version=pr20260219-1731" /&gt;
      &lt;/div&gt;
      &lt;div class="envelope-letter-google"&gt;
        &lt;img alt="alt" src="https://blog.google/static/blogv2/images/newsletter-envelope-letter-google.svg?version=pr20260219-1731" /&gt;
      &lt;/div&gt;
      &lt;div class="envelope-front"&gt;
        &lt;img alt="alt" src="https://blog.google/static/blogv2/images/newsletter-envelope-front.svg?version=pr20260219-1731" /&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class="newsletter-form__error"&gt;&lt;/div&gt;
    &lt;div class="newsletter-form__form-container" id="newsletter-form--form"&gt;
      &lt;form class="newsletter-form__form"&gt;
        &lt;h2 class="newsletter-form__title" id="subscribe_box_label"&gt;
          &lt;span class="newsletter-form__title--sr-visible"&gt;Get more stories from Google in your inbox.&lt;/span&gt;
          &lt;span&gt;Get more &lt;span class="newsletter-form__title--highlight"&gt;stories from Google&lt;/span&gt; in your inbox.&lt;/span&gt;
        &lt;/h2&gt;
        &lt;div class="newsletter-form__controls-container"&gt;
          &lt;div class="newsletter-form__input-container"&gt;
            &lt;div class="kw-form-input"&gt;
  &lt;input autocomplete="email" class="kw-form-input__field uni_subscribe_email" id="uni_subscribe_email" name="email" required="required" type="text" /&gt;
  &lt;label class="kw-form-input__label" for="uni_subscribe_email"&gt;
    Email address
  &lt;/label&gt;
  &lt;div class="kw-form-input__error uni_subscribe_email--error"&gt;&lt;/div&gt;
&lt;/div&gt;

          &lt;/div&gt;
          &lt;p class="newsletter-form__info-paragraph"&gt;
            Your information will be used in accordance with
            Google's privacy policy.
          &lt;/p&gt;
          &lt;button class="kw-button kw-button--high-emphasis newsletter-form__submit"&gt;
              Subscribe
          &lt;/button&gt;
        &lt;/div&gt;
      &lt;/form&gt;
    &lt;/div&gt;
    &lt;div class="newsletter-form__loading"&gt;
      &lt;div class="newsletter-form__loader"&gt;
        &lt;div&gt;&lt;/div&gt;
        &lt;div&gt;&lt;/div&gt;
        &lt;div&gt;&lt;/div&gt;
        &lt;div&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class="newsletter-form__success"&gt;
      &lt;div class="newsletter-form__success-text"&gt;
        &lt;p class="newsletter-form__success-text--intro newsletter-form__success-text--done-text" tabindex="-1"&gt;
          Done. Just one step more.
        &lt;/p&gt;
        &lt;p class="newsletter-form__success-text--confirmation uni-headline-4"&gt;
          Check your inbox to confirm your subscription.
        &lt;/p&gt;
        &lt;p class="newsletter-form__success-text--subscribed uni-headline-4"&gt;You are already subscribed to our newsletter.&lt;/p&gt;
      &lt;/div&gt;
      &lt;p class="newsletter-form__success-final-text"&gt;
        You can also subscribe with a
        &lt;button class="newsletter-form__different-email"&gt;different email address&lt;/button&gt;
        &lt;span&gt;
        .
        &lt;/span&gt;
      &lt;/p&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

  

  


            
            

            
              


&lt;div class="
    uni-blog-article-tags
    article-tags
    
  "&gt;
  &lt;div class="uni-blog-article-tags__wrapper"&gt;
    &lt;span class="uni-blog-article-tags__label uni-eyebrow"&gt;POSTED IN:&lt;/span&gt;
  &lt;/div&gt;
  &lt;nav class="uni-blog-article-tags__container uni-click-tracker"&gt;
    &lt;ul class="uni-blog-article-tags__tags-list"&gt;
    
      &lt;li&gt;
        
        
        


  


AI


  


      &lt;/li&gt;
    

    
      &lt;li&gt;
        
        
        


  


Gemini models


  


      &lt;/li&gt;
    
    &lt;/ul&gt;
  &lt;/nav&gt;
&lt;/div&gt;

            
          &lt;/div&gt;</description><content:encoded>&lt;div class="article-image-hero"&gt;
  &lt;div class="article-image-hero__container"&gt;
    &lt;figure class="article-image--full-aspect article-module"&gt;
      &lt;div class="aspect-ratio-image"&gt;
        &lt;div class="aspect-ratio-image__container"&gt;
          &lt;img alt="Nano Banana 2 text with AI generated images around it" class="aspect-ratio-image__image uni-progressive-image--blur" height="150px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/NB2_Hero.width-2200.format-webp.webp" width="360px" /&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      
    &lt;/figure&gt;
  &lt;/div&gt;
&lt;/div&gt;&lt;div class="uni-content uni-blog-article-container article-container__content
                      
                      "&gt;

            
  
    



















&lt;div class="audio-player-tts"&gt;
  &lt;audio class="audio-player-tts__player" title="Nano Banana 2: Combining Pro capabilities with lightning\u002Dfast speed"&gt;
      &lt;source src="https://storage.googleapis.com/gweb-uniblog-publish-prod/media/tts_audio_83457_umbriel_2026_02_26_19_16_59.wav" type="audio/x-wav" /&gt;
      &lt;p&gt;Your browser does not support the audio element.&lt;/p&gt;
  &lt;/audio&gt;
  &lt;div class="audio-player-tts__container"&gt;
    &lt;div class="audio-player-tts__content"&gt;
      &lt;button class="audio-player-tts__preview-play"&gt;
        &lt;svg class="icon audio-player-tts__play-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

      &lt;/button&gt;
      &lt;div class="audio-player-tts__text-content"&gt;
        &lt;span class="audio-player-tts__text-content--title"&gt;
          Listen to article
          &lt;span class="audio-player-tts__disclaimer" tabindex="0"&gt;
            &lt;div class="audio-player-tts__disclaimer--copy uni-small-text"&gt;This content is generated by Google AI. Generative AI is experimental&lt;/div&gt;
            &lt;svg class="audio-player-tts__disclaimer--icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

          &lt;/span&gt;
        &lt;/span&gt;
        &lt;div class="audio-player-tts__duration uni-small-text"&gt;[[duration]] minutes&lt;/div&gt;
      &lt;/div&gt;
      &lt;button class="audio-player-tts__pause"&gt;
        &lt;svg class="icon audio-player-tts__icon-play" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

        &lt;svg class="icon audio-player-tts__icon-pause audio-player-tts__icon-pause--hidden" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

      &lt;/button&gt;
      &lt;div class="audio-player-tts__console"&gt;
        &lt;div class="audio-player-tts__time-bar"&gt;
          &lt;span class="audio-player-tts__current-time uni-small-text"&gt;&lt;/span&gt;
          &lt;div class="audio-player-tts__timeline-slider-container"&gt;
            &lt;input class="timeline__slider" max="100" step="5" tabindex="0" type="range" value="0" /&gt;
          &lt;/div&gt;
          &lt;span class="audio-player-tts__duration-time uni-small-text"&gt;&lt;/span&gt;
        &lt;/div&gt;
        &lt;button class="audio-player-tts__audio-settings"&gt;
          &lt;svg class="icon audio-player-tts__audio-settings--icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

        &lt;/button&gt;
        &lt;div class="audio-player-tts__settings-container"&gt;
          &lt;div class="audio-player-tts__settings--main uni-cta-text"&gt;
            &lt;button class="audio-player-tts__settings--current-voice"&gt;
              &lt;span class="audio-player-tts__settings--current-voice-info"&gt;
                &lt;svg class="audio-player-tts__settings--current-voice-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

                &lt;span&gt;Voice&lt;/span&gt;
              &lt;/span&gt;
              &lt;span class="audio-player-tts__settings--current-voice-next"&gt;
                &lt;span class="audio-player-tts__settings--current-voice-text uni-small-text"&gt;&lt;/span&gt;
                &lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

              &lt;/span&gt;
            &lt;/button&gt;
            &lt;button class="audio-player-tts__settings--current-speed"&gt;
              &lt;span class="audio-player-tts__settings--current-speed-info"&gt;
                  &lt;svg class="audio-player-tts__settings--current-speed-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

                  &lt;span&gt;Speed&lt;/span&gt;
                &lt;/span&gt;
                &lt;span class="audio-player-tts__settings--current-speed-next"&gt;
                  &lt;span class="audio-player-tts__settings--current-speed-text uni-small-text"&gt;&lt;/span&gt;
                  &lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

                &lt;/span&gt;
            &lt;/button&gt;
          &lt;/div&gt;
          &lt;div class="audio-player-tts__settings--voices uni-cta-text"&gt;
            &lt;button class="audio-player-tts__settings-back"&gt;&lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;
 &lt;span&gt;Voice&lt;/span&gt;&lt;/button&gt;
          &lt;/div&gt;
          &lt;div class="audio-player-tts__settings--speeds uni-cta-text"&gt;
            &lt;button class="audio-player-tts__settings-back"&gt;&lt;svg class="icon tts-chevron" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;
 &lt;span&gt;Speed&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option"&gt;&lt;span&gt;0.75X&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option audio-player-tts__settings-option--selected"&gt;&lt;span&gt;1X&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option"&gt;&lt;span&gt;1.5X&lt;/span&gt;&lt;/button&gt;
            &lt;button class="audio-player-tts__settings-option"&gt;&lt;span&gt;2X&lt;/span&gt;&lt;/button&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

  





            
            
&lt;!--article text--&gt;

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;In August of last year, our Gemini Image model, Nano Banana, became a viral sensation, redefining image generation and editing. Then in November, we released Nano Banana Pro, offering users advanced intelligence and studio-quality creative control. Today, we’re bringing the best of both worlds to users across Google.&lt;/p&gt;&lt;p&gt;Introducing Nano Banana 2 (Gemini 3.1 Flash Image), our latest state-of-the-art image model. Now you can get the advanced world knowledge, quality and reasoning you love in Nano Banana Pro, at lightning-fast speed.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Intelligence and visual quality at Flash speed&lt;/h2&gt;&lt;p&gt;Nano Banana 2 brings the high-speed intelligence of Gemini Flash to visual generation, making rapid edits and iteration possible. It makes once-exclusive Pro features accessible to a wider audience, including:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Advanced world knowledge:&lt;/b&gt; The model pulls from Gemini’s real-world knowledge base, and is powered by real-time information and images from web search to more accurately render specific subjects. This deep understanding also helps you create infographics, turn notes into diagrams and generate data visualizations.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Precision text rendering and translation&lt;/b&gt;: Nano Banana 2 allows you to generate accurate, legible text for marketing mockups or greeting cards. You can even translate and localize text within an image to share your ideas globally.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    


































  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;A flat lay infographic depicting the water cycle&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Triptych infographic comparing cloud types&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Museum Clos Lucé in Synthetic Cubism style&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Localized "Native Wildlife" sign&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;&lt;i&gt;Read the prompts: Water Cycle&lt;/i&gt;



  &lt;sup&gt;1&lt;/sup&gt;

&lt;i&gt;, Cloud Infographic&lt;/i&gt;



  &lt;sup&gt;2&lt;/sup&gt;

&lt;i&gt;, Cubism&lt;/i&gt;



  &lt;sup&gt;3&lt;/sup&gt;

&lt;i&gt;, Wildlife Sign&lt;/i&gt;



  &lt;sup&gt;4&lt;/sup&gt;

&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Enhanced creative control&lt;/h2&gt;&lt;p&gt;Nano Banana 2 also dramatically closes the gap between speed and visual fidelity, delivering high-quality, photorealistic imagery. Here’s what our newest model offers and has improved on from the original Nano Banana:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Subject consistency:&lt;/b&gt; Maintain character resemblance of up to five characters and the fidelity of up to 14 objects in a single workflow, allowing you to storyboard and build narratives without altering the appearance of your inputs.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Precise instruction following:&lt;/b&gt; With enhanced instruction following, the model adheres more strictly to your complex requests, capturing the specific nuances of your idea so the image you get is the image you asked for.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Production-ready specs&lt;/b&gt;: Make attention grabbing assets with full control of various aspect ratios and resolutions from 512px to 4K, ensuring your visuals stay sharp whether they are for a vertical social post or a wide-screen backdrop.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Visual fidelity upgrade:&lt;/b&gt; Nano Banana 2 delivers vibrant lighting, richer textures and sharper details, maintaining high-quality aesthetics at the speed expected from Flash.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    


































  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Joyful characters and items at a farm&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Fluffy friends building a treehouse&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Misty panoramic aerial shot of a verdant valley&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Highly stylized pop-art fashion portrait in different aspect ratios&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;&lt;i&gt;Read the prompts: Farm&lt;/i&gt;



  &lt;sup&gt;5&lt;/sup&gt;

&lt;i&gt;, Treehouse&lt;/i&gt;



  &lt;sup&gt;6&lt;/sup&gt;

&lt;i&gt;, Valley&lt;/i&gt;



  &lt;sup&gt;7&lt;/sup&gt;

&lt;i&gt;, Portrait&lt;/i&gt;



  &lt;sup&gt;8&lt;/sup&gt;

&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Try Nano Banana 2 today&lt;/h2&gt;&lt;p&gt;Whatever your needs, we now offer the perfect tool for every workflow: Nano Banana Pro for high-fidelity tasks requiring maximum factual accuracy, or Nano Banana 2 for rapid generation, precise instruction following and integrated image-search grounding.&lt;/p&gt;&lt;p&gt;Nano Banana 2 is rolling out today across Google products, including:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Gemini app:&lt;/b&gt; Nano Banana 2 will replace Nano Banana Pro across the Fast, Thinking and Pro models. Google AI Pro and Ultra subscribers will keep access to Nano Banana Pro for specialized tasks by regenerating images via the three-dot menu.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Search:&lt;/b&gt; In AI Mode and Lens, through the Google app as well as mobile and desktop browsers. View availability here, including 141 new countries and territories and eight additional languages.&lt;/li&gt;&lt;li&gt;&lt;b&gt;AI Studio + API:&lt;/b&gt; Available in preview in AI Studio and Gemini API. Pricing here. Also available in Google Antigravity.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Google Cloud:&lt;/b&gt; Available in preview with the Gemini API in Vertex AI.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Flow:&lt;/b&gt; Nano Banana 2 is the new default image generation model in Flow, available to all Flow users for zero credits.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Google Ads:&lt;/b&gt; Nano Banana 2 is available now, powering suggestions while creating campaigns in Google Ads.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    


































  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Try Nano Banana 2 in the Gemini app, using the new templates feature.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;World knowledge from Nano Banana 2 in AI Mode in Search.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  
    
      &lt;div&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Subject preservation from Nano Banana 2 in Flow.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    
  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Read the prompts: AI Mode in Search



  &lt;sup&gt;9&lt;/sup&gt;

, Flow



  &lt;sup&gt;10&lt;/sup&gt;

&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Robust provenance: marking and verification&lt;/h2&gt;&lt;p&gt;As generative media evolves, so must the tools we use to identify and understand it. We continue to deepen our provenance approach, by coupling our state-of-the-art SynthID technology with interoperable C2PA Content Credentials, we provide users with a more holistic and contextual view of not just if AI was used, but how.&lt;/p&gt;&lt;p&gt;Our provenance tools are already making an impact. Since its launch in November, our SynthID verification feature in Gemini app has been used over 20 million times across various languages, helping people identify Google AI-generated images, video and audio. We’ll soon be bringing C2PA verification to the Gemini app, too.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    

  
    





&lt;div class="newsletter-form article-newsletter-form"&gt;
  &lt;div class="newsletter-form__container"&gt;
    &lt;div class="newsletter-form__envelope"&gt;
      &lt;div class="envelope-back"&gt;
        &lt;img alt="alt" src="https://blog.google/static/blogv2/images/newsletter-envelope-back.svg?version=pr20260219-1731" /&gt;
      &lt;/div&gt;
      &lt;div class="envelope-letter-approved"&gt;
        &lt;img alt="alt" src="https://blog.google/static/blogv2/images/newsletter-envelope-letter-approved.svg?version=pr20260219-1731" /&gt;
      &lt;/div&gt;
      &lt;div class="envelope-letter-google"&gt;
        &lt;img alt="alt" src="https://blog.google/static/blogv2/images/newsletter-envelope-letter-google.svg?version=pr20260219-1731" /&gt;
      &lt;/div&gt;
      &lt;div class="envelope-front"&gt;
        &lt;img alt="alt" src="https://blog.google/static/blogv2/images/newsletter-envelope-front.svg?version=pr20260219-1731" /&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class="newsletter-form__error"&gt;&lt;/div&gt;
    &lt;div class="newsletter-form__form-container" id="newsletter-form--form"&gt;
      &lt;form class="newsletter-form__form"&gt;
        &lt;h2 class="newsletter-form__title" id="subscribe_box_label"&gt;
          &lt;span class="newsletter-form__title--sr-visible"&gt;Get more stories from Google in your inbox.&lt;/span&gt;
          &lt;span&gt;Get more &lt;span class="newsletter-form__title--highlight"&gt;stories from Google&lt;/span&gt; in your inbox.&lt;/span&gt;
        &lt;/h2&gt;
        &lt;div class="newsletter-form__controls-container"&gt;
          &lt;div class="newsletter-form__input-container"&gt;
            &lt;div class="kw-form-input"&gt;
  &lt;input autocomplete="email" class="kw-form-input__field uni_subscribe_email" id="uni_subscribe_email" name="email" required="required" type="text" /&gt;
  &lt;label class="kw-form-input__label" for="uni_subscribe_email"&gt;
    Email address
  &lt;/label&gt;
  &lt;div class="kw-form-input__error uni_subscribe_email--error"&gt;&lt;/div&gt;
&lt;/div&gt;

          &lt;/div&gt;
          &lt;p class="newsletter-form__info-paragraph"&gt;
            Your information will be used in accordance with
            Google's privacy policy.
          &lt;/p&gt;
          &lt;button class="kw-button kw-button--high-emphasis newsletter-form__submit"&gt;
              Subscribe
          &lt;/button&gt;
        &lt;/div&gt;
      &lt;/form&gt;
    &lt;/div&gt;
    &lt;div class="newsletter-form__loading"&gt;
      &lt;div class="newsletter-form__loader"&gt;
        &lt;div&gt;&lt;/div&gt;
        &lt;div&gt;&lt;/div&gt;
        &lt;div&gt;&lt;/div&gt;
        &lt;div&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class="newsletter-form__success"&gt;
      &lt;div class="newsletter-form__success-text"&gt;
        &lt;p class="newsletter-form__success-text--intro newsletter-form__success-text--done-text" tabindex="-1"&gt;
          Done. Just one step more.
        &lt;/p&gt;
        &lt;p class="newsletter-form__success-text--confirmation uni-headline-4"&gt;
          Check your inbox to confirm your subscription.
        &lt;/p&gt;
        &lt;p class="newsletter-form__success-text--subscribed uni-headline-4"&gt;You are already subscribed to our newsletter.&lt;/p&gt;
      &lt;/div&gt;
      &lt;p class="newsletter-form__success-final-text"&gt;
        You can also subscribe with a
        &lt;button class="newsletter-form__different-email"&gt;different email address&lt;/button&gt;
        &lt;span&gt;
        .
        &lt;/span&gt;
      &lt;/p&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

  

  


            
            

            
              


&lt;div class="
    uni-blog-article-tags
    article-tags
    
  "&gt;
  &lt;div class="uni-blog-article-tags__wrapper"&gt;
    &lt;span class="uni-blog-article-tags__label uni-eyebrow"&gt;POSTED IN:&lt;/span&gt;
  &lt;/div&gt;
  &lt;nav class="uni-blog-article-tags__container uni-click-tracker"&gt;
    &lt;ul class="uni-blog-article-tags__tags-list"&gt;
    
      &lt;li&gt;
        
        
        


  


AI


  


      &lt;/li&gt;
    

    
      &lt;li&gt;
        
        
        


  


Gemini models


  


      &lt;/li&gt;
    
    &lt;/ul&gt;
  &lt;/nav&gt;
&lt;/div&gt;

            
          &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://deepmind.google/blog/nano-banana-2-combining-pro-capabilities-with-lightning-fast-speed/</guid><pubDate>Thu, 26 Feb 2026 16:01:50 +0000</pubDate></item><item><title>Bumble adds AI-powered photo feedback and profile guidance tools (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/26/bumble-adds-ai-powered-photo-feedback-and-profile-guidance-tools/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/07/bumble-app.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Bumble announced on Thursday that it’s adding a series of AI-driven features intended to help turn matches into lasting connections, including those that offer feedback and guidance on users’ bios, photos, and prompts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The dating app’s new AI-suggested profile guidance tool will roll out globally and give “personalized, actionable feedback” on users’ bios and prompts. For users in the U.S., the profile guidance feature can be augmented with an AI photo feedback tool, which can “help you choose the best photos and show up as your most authentic self.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;According to Bumble’s blog post explaining these features, it doesn’t seem like the insights from these AI tools are particularly groundbreaking — for example, Bumble says that its AI photo tool might encourage you to ditch photos where you’re wearing sunglasses that cover your face, and add a wider variety of photos, like ones taken outdoors or with friends. It’s advice you could’ve easily gotten from a friend 10 years ago, but it’s still new information to many users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In Canada, Bumble is testing another, non-AI feature called “Suggest a Date.” When a conversation stalls, a user can signal that they are open to meeting in person, which the company says is “a simple way to signal that they’re ready to connect offline.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, another way for people to “signal that they’re ready to connect offline” is to literally ask someone on a date. But realistically, it doesn’t seem like users are taking the plunge, so having an in-app way to indicate interest may motivate some potential couples to move their conversation IRL.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“With Suggest a Date, we’re creating a clear expression of intent and giving members a way to bypass the traditional back-and-forth and move toward meeting in real life,” Bumble CTO Vivek Sagi said in a statement. “When we reduce friction at the moments that matter most, we help people connect with clarity and confidence, and increase the likelihood of meaningful relationships forming offline.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bumble and other popular dating apps, like Match Group’s Tinder and Hinge, have all embraced AI-powered features in recent months. For instance, in December, Hinge introduced a tool to help generate more interesting conversation starters than “How are you?”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tinder may take things a step further. In Australia, Tinder is piloting a tool called Chemistry, which asks users to provide the app with access to their camera roll, which is a concerning amount of data to feed into an AI tool. Based on a user’s camera roll and answers to a series of questions, the AI can learn more about someone’s interests and personality to supposedly reduce “swipe fatigue” and suggest better matches. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s Facebook Dating tool does something similar — in October, it launched a feature that asks to use its AI on photos in your camera roll&amp;nbsp;that you haven’t yet shared in order to suggest AI edits.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As these companies try to come up with new ways to keep users happy, some young people have thrown in the towel on online dating altogether, instead seeking more real-world experiences that are not intermediated by an app.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/07/bumble-app.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Bumble announced on Thursday that it’s adding a series of AI-driven features intended to help turn matches into lasting connections, including those that offer feedback and guidance on users’ bios, photos, and prompts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The dating app’s new AI-suggested profile guidance tool will roll out globally and give “personalized, actionable feedback” on users’ bios and prompts. For users in the U.S., the profile guidance feature can be augmented with an AI photo feedback tool, which can “help you choose the best photos and show up as your most authentic self.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;According to Bumble’s blog post explaining these features, it doesn’t seem like the insights from these AI tools are particularly groundbreaking — for example, Bumble says that its AI photo tool might encourage you to ditch photos where you’re wearing sunglasses that cover your face, and add a wider variety of photos, like ones taken outdoors or with friends. It’s advice you could’ve easily gotten from a friend 10 years ago, but it’s still new information to many users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In Canada, Bumble is testing another, non-AI feature called “Suggest a Date.” When a conversation stalls, a user can signal that they are open to meeting in person, which the company says is “a simple way to signal that they’re ready to connect offline.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, another way for people to “signal that they’re ready to connect offline” is to literally ask someone on a date. But realistically, it doesn’t seem like users are taking the plunge, so having an in-app way to indicate interest may motivate some potential couples to move their conversation IRL.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“With Suggest a Date, we’re creating a clear expression of intent and giving members a way to bypass the traditional back-and-forth and move toward meeting in real life,” Bumble CTO Vivek Sagi said in a statement. “When we reduce friction at the moments that matter most, we help people connect with clarity and confidence, and increase the likelihood of meaningful relationships forming offline.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bumble and other popular dating apps, like Match Group’s Tinder and Hinge, have all embraced AI-powered features in recent months. For instance, in December, Hinge introduced a tool to help generate more interesting conversation starters than “How are you?”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tinder may take things a step further. In Australia, Tinder is piloting a tool called Chemistry, which asks users to provide the app with access to their camera roll, which is a concerning amount of data to feed into an AI tool. Based on a user’s camera roll and answers to a series of questions, the AI can learn more about someone’s interests and personality to supposedly reduce “swipe fatigue” and suggest better matches. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s Facebook Dating tool does something similar — in October, it launched a feature that asks to use its AI on photos in your camera roll&amp;nbsp;that you haven’t yet shared in order to suggest AI edits.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As these companies try to come up with new ways to keep users happy, some young people have thrown in the towel on online dating altogether, instead seeking more real-world experiences that are not intermediated by an app.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/26/bumble-adds-ai-powered-photo-feedback-and-profile-guidance-tools/</guid><pubDate>Thu, 26 Feb 2026 16:38:59 +0000</pubDate></item><item><title>Read AI launches an email-based ‘digital twin’ to help you with schedules and answers (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/26/read-ai-launches-an-email-based-digital-twin-to-help-you-with-schedules-and-answers/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meeting notetaker Read AI on Thursday launched an AI-powered email-based assistant called Ada, saying it helps users manage their schedules, answer questions based on a company’s knowledge base, and reply to out-of-office emails.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is calling Ada a “digital twin” that handles tasks for you around the clock. Read AI said that the assistant will be available to all users, and they can start configuring it by sending an email to “ada@read.ai” and writing “Get me started.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;When you ask Ada to find a time to meet with someone, it replies to the other person in the thread with your availability. If the other person replies that they are unavailable at those times and would like a different time slot, Ada responds with new options. While Ada has access to your calendar through Read AI, it does not reveal the nature of those meetings with other people.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ada can also answer questions using a company’s knowledge base, topics discussed in your prior meetings, and public internet searches. For instance, you can ask, “Ada, can you provide an update on how we are tracking for Q1 goals?” to get information.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;If someone else asks a question in a thread, Ada will prepare a response for you and help you refine it before it is sent to the other person. The startup said that Ada doesn’t reveal any sensitive information without your permission.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Read AI’s VP of Product, Justin Farris, said that the new feature doesn’t rely on MCPs (model context protocols, a technical standard for connecting AI tools to external services), and instead builds a knowledge graph based on meeting data and connected services for more contextual answers. He added that over time, the assistant will also take proactive actions for you. For instance, if you mentioned a follow-up item in a meeting, Ada will ask you to set that up after the meeting with contextual data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The way I describe our solution is that when you are bringing on a new employee, you train them. When you add Ada to your workflow and connect more services to give more context, it starts to ramp up and handle more tasks for you,” CEO David Shim told TechCrunch. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3097385" height="383" src="https://techcrunch.com/wp-content/uploads/2026/02/Read-AI-Ada-Capabilities.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Read AI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company said that while Ada currently works via email, it will soon be available on Slack and Teams.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the sidelines of Web Summit Qatar earlier this month, Shim told TechCrunch that the company now has over 5 million monthly active users and plans to grow that number to 10 million. He mentioned that the company sees 50,000 sign-ups every day and has a broader base of 100,000 users who consume Read AI’s content, like meeting summaries, without creating an account.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For Read AI, the U.S. remains the largest market with strong international growth. While 60% of users are outside the U.S., the revenue is split roughly equally. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company, which has raised over $81 million in funding, is increasingly adding AI-powered tools to its suite. Last year, it launched Search Copilot for knowledge discovery for users, and last month it added the ability to update customer-service relationship software, send custom emails from within a meeting report, and stay up to date on topics based on internal and web knowledge.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other meeting notetakers are also offering new tools to extract more insights and actions from meeting notes. Last September, Granola added “recipes” in the form of repeatable prompts to surface knowledge from meeting data. Quill, which came out of stealth with a $6.5 million funding round this week, also connects to various tools like Linear, Notion, and CRMs, and aims to automate tasks.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meeting notetaker Read AI on Thursday launched an AI-powered email-based assistant called Ada, saying it helps users manage their schedules, answer questions based on a company’s knowledge base, and reply to out-of-office emails.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is calling Ada a “digital twin” that handles tasks for you around the clock. Read AI said that the assistant will be available to all users, and they can start configuring it by sending an email to “ada@read.ai” and writing “Get me started.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;When you ask Ada to find a time to meet with someone, it replies to the other person in the thread with your availability. If the other person replies that they are unavailable at those times and would like a different time slot, Ada responds with new options. While Ada has access to your calendar through Read AI, it does not reveal the nature of those meetings with other people.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ada can also answer questions using a company’s knowledge base, topics discussed in your prior meetings, and public internet searches. For instance, you can ask, “Ada, can you provide an update on how we are tracking for Q1 goals?” to get information.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;If someone else asks a question in a thread, Ada will prepare a response for you and help you refine it before it is sent to the other person. The startup said that Ada doesn’t reveal any sensitive information without your permission.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Read AI’s VP of Product, Justin Farris, said that the new feature doesn’t rely on MCPs (model context protocols, a technical standard for connecting AI tools to external services), and instead builds a knowledge graph based on meeting data and connected services for more contextual answers. He added that over time, the assistant will also take proactive actions for you. For instance, if you mentioned a follow-up item in a meeting, Ada will ask you to set that up after the meeting with contextual data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The way I describe our solution is that when you are bringing on a new employee, you train them. When you add Ada to your workflow and connect more services to give more context, it starts to ramp up and handle more tasks for you,” CEO David Shim told TechCrunch. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3097385" height="383" src="https://techcrunch.com/wp-content/uploads/2026/02/Read-AI-Ada-Capabilities.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Read AI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company said that while Ada currently works via email, it will soon be available on Slack and Teams.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the sidelines of Web Summit Qatar earlier this month, Shim told TechCrunch that the company now has over 5 million monthly active users and plans to grow that number to 10 million. He mentioned that the company sees 50,000 sign-ups every day and has a broader base of 100,000 users who consume Read AI’s content, like meeting summaries, without creating an account.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For Read AI, the U.S. remains the largest market with strong international growth. While 60% of users are outside the U.S., the revenue is split roughly equally. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company, which has raised over $81 million in funding, is increasingly adding AI-powered tools to its suite. Last year, it launched Search Copilot for knowledge discovery for users, and last month it added the ability to update customer-service relationship software, send custom emails from within a meeting report, and stay up to date on topics based on internal and web knowledge.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other meeting notetakers are also offering new tools to extract more insights and actions from meeting notes. Last September, Granola added “recipes” in the form of repeatable prompts to surface knowledge from meeting data. Quill, which came out of stealth with a $6.5 million funding round this week, also connects to various tools like Linear, Notion, and CRMs, and aims to automate tasks.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/26/read-ai-launches-an-email-based-digital-twin-to-help-you-with-schedules-and-answers/</guid><pubDate>Thu, 26 Feb 2026 17:00:00 +0000</pubDate></item><item><title>CORPGEN advances AI agents for real work (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/blog/corpgen-advances-ai-agents-for-real-work/</link><description>&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="decorative icons in white on a blue and green gradient background" class="wp-image-1162851" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/CORPGEN-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;div class="wp-block-msr-immersive-section alignfull row wp-block-msr-immersive-section"&gt;
	
	&lt;div class="container"&gt;
		&lt;div class="wp-block-msr-immersive-section__inner wp-block-msr-immersive-section__inner--narrow"&gt;
			&lt;div class="wp-block-columns mb-10 pb-1 pr-1 is-layout-flex wp-container-core-columns-is-layout-9d6595d7 wp-block-columns-is-layout-flex"&gt;
&lt;div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"&gt;
&lt;h2 class="wp-block-heading h3" id="at-a-glance"&gt;At a glance&lt;/h2&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Today’s AI agent benchmarks test one task at a time, while real workplace productivity requires managing dozens of interdependent tasks at once. To reflect this, we created a setting called Multi-Horizon Task Environments (MHTEs).&lt;/li&gt;



&lt;li&gt;Under multi-task loads, leading computer-using agents degrade sharply, with completion rates dropping from 16.7% to 8.7%.&lt;/li&gt;



&lt;li&gt;CORPGEN introduces &lt;em&gt;digital employees&lt;/em&gt;, with hierarchical planning, memory isolation, and experiential learning, delivering up to 3.5 times higher completion rates than baselines across three independent agent backends.&lt;/li&gt;



&lt;li&gt;Because CORPGEN is architecture-agnostic and modular, its gains come from system design rather than any single base model, and it benefits directly as underlying models improve.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;		&lt;/div&gt;
	&lt;/div&gt;

	&lt;/div&gt;



&lt;p&gt;By mid-morning, a typical knowledge worker is already juggling a client report, a budget spreadsheet, a slide deck, and an email backlog, all interdependent and all demanding attention at once. For AI agents to be genuinely useful in that environment, they will need to operate the same way, but today’s best models are evaluated one task at a time, not dozens at once.&lt;/p&gt;



&lt;p&gt;In our paper, “CORPGEN: Simulating Corporate Environments with Autonomous Digital Employees in Multi-Horizon Task Environments,” we propose an agent framework that equips AI with the memory, planning, and learning capabilities to close that gap.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="introducing-multi-horizon-task-environments"&gt;Introducing Multi-Horizon Task Environments&lt;/h2&gt;



&lt;p&gt;Replicating the reality of workplace multitasking requires a new kind of evaluation environment. In response, we developed Multi-Horizon Task Environments (MHTEs), settings where an agent must manage multiple complex tasks simultaneously. Each task requires 10 to 30 dependent steps within a single session spanning five hours.&lt;/p&gt;



&lt;p&gt;To determine what a benchmark would need to test, we ran MHTEs at scale on some of today’s leading AI agents, exposing four weaknesses. First, memory fills up. An agent cannot hold details for multiple active tasks at once. Second, information from one task interferes with reasoning about another. Third, tasks don’t depend on each other in simple sequences. They form complex webs where an agent must constantly check whether upstream work is finished before it can move forward on anything downstream. Fourth, every action cycle requires reprioritizing across all active tasks, not simply resuming where the agent left off.&lt;/p&gt;



&lt;p&gt;We also tested three independent agent systems under increasing loads. As the number of concurrent tasks rose from 12 to 46, completion rates fell from 16.7% to 8.7% across all systems.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="corpgen-s-architecture"&gt;CORPGEN’s architecture&lt;/h2&gt;



&lt;p&gt;CORPGEN introduces &lt;em&gt;digital employees&lt;/em&gt;: LLM-powered AI agents with persistent identities, role-specific expertise, and realistic work schedules. They operate Microsoft Office applications through GUI automation and perform consistently within MHTEs over hours of continuous activity. Figure 1 illustrates how a digital employee moves through a full workday.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Diagram showing a digital employee's workday in three phases. Day Init on the left, where the agent loads memory and generates a daily plan. Execution Cycles in the center, where the agent repeatedly retrieves context, reasons and acts through a ReAct loop, and persists results across 50+ interleaved tasks. Day End on the right, where the agent generates a reflection and consolidates experience into long-term memory. Below the diagram, labels show the tiered memory architecture and experiential learning components." class="wp-image-1162865" height="1318" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/day_in_life_color_AH-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 1. Each day begins with a structured plan and memory loaded from previous sessions. The agent then works through overlapping tasks in repeated cycles, storing key outcomes at day’s end to inform the next session.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;CORPGEN addresses each of the four weaknesses of concurrent task execution—memory overload, cross-task interference, dependency complexity, and reprioritization—in a targeted way. Hierarchical planning breaks objectives into daily goals and then into moment-to-moment decisions, allowing the agent to act from a structured plan instead of reviewing all available tasks before each step.&lt;/p&gt;



&lt;p&gt;Subagents perform complex operations like web research in isolated contexts, preventing cross-task contamination. A tiered memory system enables selective recall of task-related information rather than retaining everything in active context. Adaptive summarization compresses routine observations while preserving critical information, keeping memory growth controlled. &lt;/p&gt;



&lt;p&gt;Because these mechanisms are not tied to a specific base model, we tested CORPGEN across three different agents. In each case, we observed consistent gains. The improvements came from the architecture, not from the strength of any particular model. Figure 2 shows how they fit together within CORPGEN’s architecture.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Architecture diagram of the CORPGEN framework. At center is the Digital Employee with persistent identity, execution engine, cognitive tools, sub-agents, and context management. On the left, Hierarchical Planning decomposes strategic objectives into tactical plans and operational actions. On the right, Sub-Agents as Tools shows a Research Agent and Computer-Use agent (UFO2) operating in isolated contexts. At the bottom, the Tiered Memory Architecture spans working memory, structured long-term memory, and semantic memory via Mem0. Experiential Learning in the bottom right captures successful trajectories and routes feedback to UFO2. Multi-Employee Collaboration at the top shows async communication via Email and Teams with no shared state." class="wp-image-1162863" height="1318" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/corpgen_arch_color_AH2-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 2. Four mechanisms support concurrent task execution in CORPGEN: hierarchical planning, isolated subagents, tiered memory, and adaptive summarization.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="how-digital-employees-collaborate"&gt;How digital employees collaborate&lt;/h2&gt;



&lt;p&gt;When multiple digital employees operate in the same environment, collaboration takes shape through standard communication channels, without predefined coordination rules. One employee sends an email requesting data; another picks it up in the next cycle, uses its memory to process it, and responds. This exchange mirrors real workplace communication.&lt;/p&gt;



&lt;p&gt;There is no shared internal state between agents. Coordination occurs entirely through email and Microsoft Teams, the same channels many workers use. Over time, these independent exchanges form recognizable organizational patterns. Some agents take on leadership roles; others provide support; shared documents become the connective tissue.&lt;/p&gt;



&lt;p&gt;When a communication path breaks, such as an email delivery error, agents reroute messages through alternate channels to keep work moving. The result is a virtual organization that behaves like a real one without being explicitly programmed to do so.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="evaluating-corpgen"&gt;Evaluating CORPGEN&lt;/h2&gt;



&lt;p&gt;We evaluated CORPGEN on a multi-task benchmark that combined up to 46 tasks into a single six-hour session. Three findings stood out.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Baselines degrade as load increases; CORPGEN does not.&lt;/strong&gt; All three baseline agent systems showed steady performance declines as task load rose. CORPGEN, by contrast, maintained or improved its completion rates at higher loads. At 46 tasks, CORPGEN completed 15.2% of tasks, compared with 4.3% for the baselines, roughly 3.5 times more.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Experiential learning drives the largest gains.&lt;/strong&gt; We introduced CORPGEN’s components sequentially: first the orchestration layer, then cognitive tools, and finally experiential learning. The first two produced moderate improvements. Experiential learning, in which agents store records of completed tasks and reuse them when they encounter structurally similar work, produced the largest increase, raising completion rates from 8.7% to 15.2%.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evaluation methodology changes the picture.&lt;/strong&gt; When we inspected the actual output files produced by agents, the results agreed with human judgements roughly 90% of the time. Evaluation based on screenshots and action logs agreed only about 40% of the time. This gap suggests that common evaluation approaches may underestimate what agents actually accomplish in practice.&lt;/p&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;video series&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;On Second Thought&lt;/h2&gt;
				
								&lt;p class="large" id="on-second-thought"&gt;A video series with Sinead Bovell built around the questions everyone’s asking about AI. With expert voices from across Microsoft, we break down the tension and promise of this rapidly changing technology, exploring what’s evolving and what’s possible.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;h2 class="wp-block-heading" id="implications-and-looking-forward"&gt;Implications and looking forward&lt;/h2&gt;



&lt;p&gt;The results suggest that memory and retrieval, not just raw model capability, may be a key bottleneck in getting agents to work in the real world. The largest gains came from experiential learning. Agents that learn from prior successes and apply those patterns to structurally similar tasks build an advantage over systems that respond to each task in isolation.&lt;/p&gt;



&lt;p&gt;CORPGEN also opens a new lens on how AI agents collaborate. Next steps include testing whether agents can maintain memory across multiple workdays and how they coordinate when working in teams. We are also exploring ways to make agents faster and more reliable by combining different methods of interacting with software.&lt;/p&gt;



&lt;hr class="wp-block-separator has-alpha-channel-opacity is-style-dots" /&gt;



&lt;h2 class="wp-block-heading" id="acknowledgments"&gt;Acknowledgments&lt;/h2&gt;



&lt;p&gt;This work is a result of a collaboration between the Office of the CTO at Microsoft and the Microsoft AI Development Accelerator Program (MAIDAP). We would like to thank the Microsoft Security Research team for providing resources that supported this research. We also thank the members of the Microsoft UFO2&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; team and the Mem0&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; project for their open-source contributions, which enabled key components of the CORPGEN architecture, and the OSWorld team for the benchmark that served as the foundation for our multi-task evaluation.&lt;/p&gt;



&lt;p&gt;Finally, we thank the many contributors to this research: Anjel Shaileshbhai Patel, Dayquan Julienne, Charlotte Siska, Manuel Raúl Meléndez Luján, Anthony Twum-Barimah, Mauricio Velazco, and Tianwei Chen.&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="decorative icons in white on a blue and green gradient background" class="wp-image-1162851" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/CORPGEN-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;div class="wp-block-msr-immersive-section alignfull row wp-block-msr-immersive-section"&gt;
	
	&lt;div class="container"&gt;
		&lt;div class="wp-block-msr-immersive-section__inner wp-block-msr-immersive-section__inner--narrow"&gt;
			&lt;div class="wp-block-columns mb-10 pb-1 pr-1 is-layout-flex wp-container-core-columns-is-layout-9d6595d7 wp-block-columns-is-layout-flex"&gt;
&lt;div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"&gt;
&lt;h2 class="wp-block-heading h3" id="at-a-glance"&gt;At a glance&lt;/h2&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Today’s AI agent benchmarks test one task at a time, while real workplace productivity requires managing dozens of interdependent tasks at once. To reflect this, we created a setting called Multi-Horizon Task Environments (MHTEs).&lt;/li&gt;



&lt;li&gt;Under multi-task loads, leading computer-using agents degrade sharply, with completion rates dropping from 16.7% to 8.7%.&lt;/li&gt;



&lt;li&gt;CORPGEN introduces &lt;em&gt;digital employees&lt;/em&gt;, with hierarchical planning, memory isolation, and experiential learning, delivering up to 3.5 times higher completion rates than baselines across three independent agent backends.&lt;/li&gt;



&lt;li&gt;Because CORPGEN is architecture-agnostic and modular, its gains come from system design rather than any single base model, and it benefits directly as underlying models improve.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;		&lt;/div&gt;
	&lt;/div&gt;

	&lt;/div&gt;



&lt;p&gt;By mid-morning, a typical knowledge worker is already juggling a client report, a budget spreadsheet, a slide deck, and an email backlog, all interdependent and all demanding attention at once. For AI agents to be genuinely useful in that environment, they will need to operate the same way, but today’s best models are evaluated one task at a time, not dozens at once.&lt;/p&gt;



&lt;p&gt;In our paper, “CORPGEN: Simulating Corporate Environments with Autonomous Digital Employees in Multi-Horizon Task Environments,” we propose an agent framework that equips AI with the memory, planning, and learning capabilities to close that gap.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="introducing-multi-horizon-task-environments"&gt;Introducing Multi-Horizon Task Environments&lt;/h2&gt;



&lt;p&gt;Replicating the reality of workplace multitasking requires a new kind of evaluation environment. In response, we developed Multi-Horizon Task Environments (MHTEs), settings where an agent must manage multiple complex tasks simultaneously. Each task requires 10 to 30 dependent steps within a single session spanning five hours.&lt;/p&gt;



&lt;p&gt;To determine what a benchmark would need to test, we ran MHTEs at scale on some of today’s leading AI agents, exposing four weaknesses. First, memory fills up. An agent cannot hold details for multiple active tasks at once. Second, information from one task interferes with reasoning about another. Third, tasks don’t depend on each other in simple sequences. They form complex webs where an agent must constantly check whether upstream work is finished before it can move forward on anything downstream. Fourth, every action cycle requires reprioritizing across all active tasks, not simply resuming where the agent left off.&lt;/p&gt;



&lt;p&gt;We also tested three independent agent systems under increasing loads. As the number of concurrent tasks rose from 12 to 46, completion rates fell from 16.7% to 8.7% across all systems.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="corpgen-s-architecture"&gt;CORPGEN’s architecture&lt;/h2&gt;



&lt;p&gt;CORPGEN introduces &lt;em&gt;digital employees&lt;/em&gt;: LLM-powered AI agents with persistent identities, role-specific expertise, and realistic work schedules. They operate Microsoft Office applications through GUI automation and perform consistently within MHTEs over hours of continuous activity. Figure 1 illustrates how a digital employee moves through a full workday.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Diagram showing a digital employee's workday in three phases. Day Init on the left, where the agent loads memory and generates a daily plan. Execution Cycles in the center, where the agent repeatedly retrieves context, reasons and acts through a ReAct loop, and persists results across 50+ interleaved tasks. Day End on the right, where the agent generates a reflection and consolidates experience into long-term memory. Below the diagram, labels show the tiered memory architecture and experiential learning components." class="wp-image-1162865" height="1318" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/day_in_life_color_AH-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 1. Each day begins with a structured plan and memory loaded from previous sessions. The agent then works through overlapping tasks in repeated cycles, storing key outcomes at day’s end to inform the next session.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;CORPGEN addresses each of the four weaknesses of concurrent task execution—memory overload, cross-task interference, dependency complexity, and reprioritization—in a targeted way. Hierarchical planning breaks objectives into daily goals and then into moment-to-moment decisions, allowing the agent to act from a structured plan instead of reviewing all available tasks before each step.&lt;/p&gt;



&lt;p&gt;Subagents perform complex operations like web research in isolated contexts, preventing cross-task contamination. A tiered memory system enables selective recall of task-related information rather than retaining everything in active context. Adaptive summarization compresses routine observations while preserving critical information, keeping memory growth controlled. &lt;/p&gt;



&lt;p&gt;Because these mechanisms are not tied to a specific base model, we tested CORPGEN across three different agents. In each case, we observed consistent gains. The improvements came from the architecture, not from the strength of any particular model. Figure 2 shows how they fit together within CORPGEN’s architecture.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Architecture diagram of the CORPGEN framework. At center is the Digital Employee with persistent identity, execution engine, cognitive tools, sub-agents, and context management. On the left, Hierarchical Planning decomposes strategic objectives into tactical plans and operational actions. On the right, Sub-Agents as Tools shows a Research Agent and Computer-Use agent (UFO2) operating in isolated contexts. At the bottom, the Tiered Memory Architecture spans working memory, structured long-term memory, and semantic memory via Mem0. Experiential Learning in the bottom right captures successful trajectories and routes feedback to UFO2. Multi-Employee Collaboration at the top shows async communication via Email and Teams with no shared state." class="wp-image-1162863" height="1318" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/corpgen_arch_color_AH2-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 2. Four mechanisms support concurrent task execution in CORPGEN: hierarchical planning, isolated subagents, tiered memory, and adaptive summarization.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="how-digital-employees-collaborate"&gt;How digital employees collaborate&lt;/h2&gt;



&lt;p&gt;When multiple digital employees operate in the same environment, collaboration takes shape through standard communication channels, without predefined coordination rules. One employee sends an email requesting data; another picks it up in the next cycle, uses its memory to process it, and responds. This exchange mirrors real workplace communication.&lt;/p&gt;



&lt;p&gt;There is no shared internal state between agents. Coordination occurs entirely through email and Microsoft Teams, the same channels many workers use. Over time, these independent exchanges form recognizable organizational patterns. Some agents take on leadership roles; others provide support; shared documents become the connective tissue.&lt;/p&gt;



&lt;p&gt;When a communication path breaks, such as an email delivery error, agents reroute messages through alternate channels to keep work moving. The result is a virtual organization that behaves like a real one without being explicitly programmed to do so.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="evaluating-corpgen"&gt;Evaluating CORPGEN&lt;/h2&gt;



&lt;p&gt;We evaluated CORPGEN on a multi-task benchmark that combined up to 46 tasks into a single six-hour session. Three findings stood out.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Baselines degrade as load increases; CORPGEN does not.&lt;/strong&gt; All three baseline agent systems showed steady performance declines as task load rose. CORPGEN, by contrast, maintained or improved its completion rates at higher loads. At 46 tasks, CORPGEN completed 15.2% of tasks, compared with 4.3% for the baselines, roughly 3.5 times more.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Experiential learning drives the largest gains.&lt;/strong&gt; We introduced CORPGEN’s components sequentially: first the orchestration layer, then cognitive tools, and finally experiential learning. The first two produced moderate improvements. Experiential learning, in which agents store records of completed tasks and reuse them when they encounter structurally similar work, produced the largest increase, raising completion rates from 8.7% to 15.2%.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evaluation methodology changes the picture.&lt;/strong&gt; When we inspected the actual output files produced by agents, the results agreed with human judgements roughly 90% of the time. Evaluation based on screenshots and action logs agreed only about 40% of the time. This gap suggests that common evaluation approaches may underestimate what agents actually accomplish in practice.&lt;/p&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;video series&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;On Second Thought&lt;/h2&gt;
				
								&lt;p class="large" id="on-second-thought"&gt;A video series with Sinead Bovell built around the questions everyone’s asking about AI. With expert voices from across Microsoft, we break down the tension and promise of this rapidly changing technology, exploring what’s evolving and what’s possible.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;h2 class="wp-block-heading" id="implications-and-looking-forward"&gt;Implications and looking forward&lt;/h2&gt;



&lt;p&gt;The results suggest that memory and retrieval, not just raw model capability, may be a key bottleneck in getting agents to work in the real world. The largest gains came from experiential learning. Agents that learn from prior successes and apply those patterns to structurally similar tasks build an advantage over systems that respond to each task in isolation.&lt;/p&gt;



&lt;p&gt;CORPGEN also opens a new lens on how AI agents collaborate. Next steps include testing whether agents can maintain memory across multiple workdays and how they coordinate when working in teams. We are also exploring ways to make agents faster and more reliable by combining different methods of interacting with software.&lt;/p&gt;



&lt;hr class="wp-block-separator has-alpha-channel-opacity is-style-dots" /&gt;



&lt;h2 class="wp-block-heading" id="acknowledgments"&gt;Acknowledgments&lt;/h2&gt;



&lt;p&gt;This work is a result of a collaboration between the Office of the CTO at Microsoft and the Microsoft AI Development Accelerator Program (MAIDAP). We would like to thank the Microsoft Security Research team for providing resources that supported this research. We also thank the members of the Microsoft UFO2&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; team and the Mem0&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; project for their open-source contributions, which enabled key components of the CORPGEN architecture, and the OSWorld team for the benchmark that served as the foundation for our multi-task evaluation.&lt;/p&gt;



&lt;p&gt;Finally, we thank the many contributors to this research: Anjel Shaileshbhai Patel, Dayquan Julienne, Charlotte Siska, Manuel Raúl Meléndez Luján, Anthony Twum-Barimah, Mauricio Velazco, and Tianwei Chen.&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/blog/corpgen-advances-ai-agents-for-real-work/</guid><pubDate>Thu, 26 Feb 2026 17:06:34 +0000</pubDate></item><item><title>Google reveals Nano Banana 2 AI image model, coming to Gemini today (AI - Ars Technica)</title><link>https://arstechnica.com/ai/2026/02/google-releases-nano-banana-2-ai-image-generator-promises-pro-results-with-flash-speed/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google’s new image model replaces the previous versions immediately.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Nano Banana 2" class="absolute inset-0 w-full h-full object-cover hidden" height="361" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/NB2_Hero.width-2200.format-webp-640x361.png" width="640" /&gt;
                  &lt;img alt="Nano Banana 2" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/NB2_Hero.width-2200.format-webp-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The last year has been big for Google’s AI efforts. Its rapid-fire model releases have brought it to parity with the likes of OpenAI and Anthropic and, in some cases, pushed it into the lead. The Nano Banana image generator was emblematic of that trend when it debuted last year, and subsequent updates only made it better. Now, Google has announced yet another update to its image model with Nano Banana 2, which is available starting today.&lt;/p&gt;
&lt;p&gt;Nano Banana 2 is more accurately known as Gemini 3.1 Flash Image—the previous Nano Banana models were based on the 3.0 branch. According to Google, the new release can deliver results similar to Nano Banana Pro but with the speed of the non-pro Flash variant.&lt;/p&gt;
&lt;p&gt;Google promises the new image generator will have more advanced world knowledge pulled from the Internet by the Gemini 3.1 LLM. This apparently gives it the necessary information to render objects with greater fidelity and create more accurate infographics. The days of squiggly AI text were already ending, but Google says Nano Banana 2 has Pro-like text accuracy in image outputs.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;With Nano Banana 2, Google promises consistency for up to five characters at a time, along with accurate rendering of as many as 14 different objects per workflow. This, along with richer textures and “vibrant” lighting will aid in visual storytelling with Nano Banana 2. Google is also expanding the range of available aspect ratios and resolutions, from 512px square up to 4K widescreen.&lt;/p&gt;
&lt;p&gt;So what can you do with Nano Banana 2? Google has provided some example images with associated prompts. These are, of course, handpicked images, but Nano Banana has been a popular image model for good reason. This degree of improvement seems believable based on past iterations of Nano Banana.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2142698 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="Google AI infographic" class="fullwidth full" height="768" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Infographic-1.png" width="1376" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Prompt: High-quality flat lay photography creating a DIY infographic that simply explains how the water cycle works, arranged on a clean, light gray textured background. The visual story flows from left to right in clear steps. Simple, clean black arrows are hand-drawn onto the background to guide the viewer’s eye. The overall mood is educational, modern, and easy to understand. The image is shot from a top-down, bird’s-eye view with soft, even lighting that minimizes shadows and keeps the focus on the process.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;figure class="ars-wp-img-shortcode id-2142712 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="AI museum comparison" class="fullwidth full" height="1080" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Museum.png" width="1920" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Prompt: Create an image of Museum Clos Lucé. In the style of bright colored Synthetic Cubism. No text. Your plan is to first search for visual references, and generate after. Aspect ratio 16:9.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;figure class="ars-wp-img-shortcode id-2142702 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="AI farm image" class="fullwidth full" height="1080" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Multi-Input.jpg" width="1920" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Create an image of these 14 characters and items having fun at the farm. The overall atmosphere is fun, silly and joyful. It is strictly important to keep identity consistent of all the 14 characters and items.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Google must be pretty confident in this model’s capabilities because it will be the only one available going forward. Starting now, Nano Banana 2 will replace both the standard and Pro variants of Nano Banana across the Gemini app, search, AI Studio, Vertex AI, and Flow.&lt;/p&gt;
&lt;p&gt;In the Gemini app and on the website, Nano Banana 2 will be the image generator for the Fast, Thinking, and Pro settings. It’s possible there will eventually be a Nano Banana 2 Pro—Google tends to release elements of new model families one at a time. For now, it’s all “Flash” Image.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google’s new image model replaces the previous versions immediately.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Nano Banana 2" class="absolute inset-0 w-full h-full object-cover hidden" height="361" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/NB2_Hero.width-2200.format-webp-640x361.png" width="640" /&gt;
                  &lt;img alt="Nano Banana 2" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/NB2_Hero.width-2200.format-webp-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The last year has been big for Google’s AI efforts. Its rapid-fire model releases have brought it to parity with the likes of OpenAI and Anthropic and, in some cases, pushed it into the lead. The Nano Banana image generator was emblematic of that trend when it debuted last year, and subsequent updates only made it better. Now, Google has announced yet another update to its image model with Nano Banana 2, which is available starting today.&lt;/p&gt;
&lt;p&gt;Nano Banana 2 is more accurately known as Gemini 3.1 Flash Image—the previous Nano Banana models were based on the 3.0 branch. According to Google, the new release can deliver results similar to Nano Banana Pro but with the speed of the non-pro Flash variant.&lt;/p&gt;
&lt;p&gt;Google promises the new image generator will have more advanced world knowledge pulled from the Internet by the Gemini 3.1 LLM. This apparently gives it the necessary information to render objects with greater fidelity and create more accurate infographics. The days of squiggly AI text were already ending, but Google says Nano Banana 2 has Pro-like text accuracy in image outputs.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;With Nano Banana 2, Google promises consistency for up to five characters at a time, along with accurate rendering of as many as 14 different objects per workflow. This, along with richer textures and “vibrant” lighting will aid in visual storytelling with Nano Banana 2. Google is also expanding the range of available aspect ratios and resolutions, from 512px square up to 4K widescreen.&lt;/p&gt;
&lt;p&gt;So what can you do with Nano Banana 2? Google has provided some example images with associated prompts. These are, of course, handpicked images, but Nano Banana has been a popular image model for good reason. This degree of improvement seems believable based on past iterations of Nano Banana.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2142698 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="Google AI infographic" class="fullwidth full" height="768" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Infographic-1.png" width="1376" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Prompt: High-quality flat lay photography creating a DIY infographic that simply explains how the water cycle works, arranged on a clean, light gray textured background. The visual story flows from left to right in clear steps. Simple, clean black arrows are hand-drawn onto the background to guide the viewer’s eye. The overall mood is educational, modern, and easy to understand. The image is shot from a top-down, bird’s-eye view with soft, even lighting that minimizes shadows and keeps the focus on the process.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;figure class="ars-wp-img-shortcode id-2142712 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="AI museum comparison" class="fullwidth full" height="1080" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Museum.png" width="1920" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Prompt: Create an image of Museum Clos Lucé. In the style of bright colored Synthetic Cubism. No text. Your plan is to first search for visual references, and generate after. Aspect ratio 16:9.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;figure class="ars-wp-img-shortcode id-2142702 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="AI farm image" class="fullwidth full" height="1080" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Multi-Input.jpg" width="1920" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Create an image of these 14 characters and items having fun at the farm. The overall atmosphere is fun, silly and joyful. It is strictly important to keep identity consistent of all the 14 characters and items.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Google must be pretty confident in this model’s capabilities because it will be the only one available going forward. Starting now, Nano Banana 2 will replace both the standard and Pro variants of Nano Banana across the Gemini app, search, AI Studio, Vertex AI, and Flow.&lt;/p&gt;
&lt;p&gt;In the Gemini app and on the website, Nano Banana 2 will be the image generator for the Fast, Thinking, and Pro settings. It’s possible there will eventually be a Nano Banana 2 Pro—Google tends to release elements of new model families one at a time. For now, it’s all “Flash” Image.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2026/02/google-releases-nano-banana-2-ai-image-generator-promises-pro-results-with-flash-speed/</guid><pubDate>Thu, 26 Feb 2026 17:12:10 +0000</pubDate></item><item><title>[NEW] Now Live: The World’s Most Powerful AI Factory for Pharmaceutical Discovery and Development (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/lilly-ai-factory-live/</link><description>&lt;!-- OneTrust Cookies Consent Notice start for nvidia.com --&gt;


&lt;!-- OneTrust Cookies Consent Notice end for nvidia.com --&gt;


	
	
	
	
	
	

	

	
&lt;!-- Broadcast could not find a linked parent for the canonical. --&gt;



	&lt;!-- This site is optimized with the Yoast SEO Premium plugin v27.0 (Yoast SEO v27.0) - https://yoast.com/product/yoast-seo-premium-wordpress/ --&gt;
	Now Live: Lilly AI Factory for Pharmaceutical Discovery and Development | NVIDIA Blog
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	&lt;!-- / Yoast SEO Premium plugin. --&gt;







































&lt;!-- Stream WordPress user activity plugin v4.1.1 --&gt;


	
				&lt;!-- Hotjar Tracking Code for NVIDIA --&gt;
			
			


				
				



		
		

&lt;div class="hfeed site" id="page"&gt;
	Skip to content

	&lt;!-- #masthead --&gt;
		
		&lt;div class="full-width-layout light"&gt;
		

		
&lt;div class="full-width-layout__hero light"&gt;
	&lt;div class="full-width-layout__hero-content light"&gt;
		&lt;div class="full-width-layout__hero-content__inner light"&gt;
			

							&lt;p&gt;
					Built with over 1,000 NVIDIA Blackwell Ultra GPUs, LillyPod is now online to power scientific research and supercharge the future of medicine.				&lt;/p&gt;
			
			
		&lt;/div&gt;
	&lt;/div&gt;

	

	&lt;/div&gt;

	
	
		&lt;div class="full-width-layout__sections"&gt;
&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Saving and improving lives — that most human endeavor — just got a super-computational boost.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lilly this week launched the most powerful AI factory wholly owned and operated by a pharmaceutical company to help its teams make meaningful medical advancements faster, more accurately and at unprecedented scale. Dubbed LillyPod, it’s the world’s first NVIDIA DGX SuperPOD with DGX B300 systems.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Powered by a DGX SuperPOD with 1,016 NVIDIA Blackwell Ultra GPUs, Lilly’s AI factory delivers more than 9,000 petaflops of AI performance. It was assembled in just four months.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-video-section"&gt;
	&lt;video class="full-width-layout__video js-responsive-video" loop="loop"&gt;Your browser does not support the video tag.&lt;/video&gt;
&lt;p&gt;
			&lt;span class="full-width-layout__media-caption-callout"&gt;
			LillyPod was inaugurated Wednesday at a ribbon-cutting in Indianapolis.		&lt;/span&gt;
	
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;“It’s a big day for us with the supercomputer coming on board, but it’s a day 150 years in the making,” said Diogo Rau, executive vice president and chief information and digital officer at Lilly. “LillyPod is a powerful symbol of who we are and why we do this work: to make life better for people around the world. We are, right here, right now, at the right moment to advance biology in a way that has just never been done before.”&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;Step Behind the Scenes of the LillyPod&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Computational power that once required 7 million Cray supercomputers now fits inside a single NVIDIA GPU — and LillyPod contains more than 1,000 of them. This infrastructure enables Lilly’s genomics team to harness 700 terabytes of data using over 290 terabytes of high-bandwidth GPU memory.&amp;nbsp;&lt;/p&gt;&lt;p&gt;“Computation is at the heart of biology and it is at the heart of science,” said Thomas Fuchs, senior vice president and chief AI officer at Lilly. “Being able to compute at scale is not something optional for a company like ours, it is absolutely necessary. So we are building the computational future of medicine and you see that in all areas along the pharmaceutical value chain.”&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__full-width-image-section"&gt;
			&lt;img alt="alt" class="full-width-layout__image" height="455" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/Lilly-AI-Factory_triptych1-scaled.png" width="2048" /&gt;	
	&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Lilly’s AI factory is set to support the large-scale training of protein diffusion models, small-molecule graph neural network models and genomics foundation models.&lt;/p&gt;&lt;p&gt;NVIDIA’s full-stack AI factory architecture offered with NVIDIA DGX SuperPOD — including accelerated computing, NVIDIA Spectrum-X Ethernet networking and optimized AI software — provides a secure, scalable platform for the highly regulated workflows of healthcare and life sciences.&amp;nbsp;&lt;/p&gt;&lt;p&gt;NVIDIA Mission Control software allows Lilly to manage its DGX SuperPOD, orchestrate workloads, monitor performance and automate AI operations securely and efficiently.&lt;/p&gt;&lt;p&gt;The supercomputer’s nearly 5,000 connections are built with more than 1,000 pounds of fiber cables. Lilly aims for its new AI supercomputing infrastructure to run on 100% renewable electricity by 2030, using efficient liquid cooling and minimal incremental energy impact.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__full-width-image-section"&gt;
			&lt;img alt="alt" class="full-width-layout__image" height="455" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/Lilly-AI-Factory_triptych2-scaled.png" width="2048" /&gt;	
	&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;Advancing Foundation Models, Physical and Agentic AI&amp;nbsp;&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;LillyPod is more than a tool — it’s a new scientific instrument that brings together proprietary data and advanced AI models.&amp;nbsp;&lt;/p&gt;&lt;p&gt;With this foundation, Lilly teams can analyze genomes, explore billions of chemical possibilities and apply AI across clinical development and manufacturing to design better trials, optimize production and accelerate decision‑making. Together, these capabilities enable faster, more precise and more scalable creation and delivery of medicines.&lt;/p&gt;&lt;p&gt;“LillyPod will usher in a new era of AI-driven drug discovery,” said Tim Coleman, senior vice president and chief technology officer at Lilly. “We believe that computation is foundational to science and that Lilly patients deserve every advantage that we can give them.”&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__full-width-video-section"&gt;
			&lt;video class="full-width-layout__video" loop="loop"&gt;
							&lt;source src="https://blogs.nvidia.com/wp-content/uploads/2025/10/lilly-scientists.mp4" type="video/mp4" /&gt;
						&lt;p&gt;Your browser does not support HTML5 video.&lt;/p&gt;
		&lt;/video&gt;
	
	&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Select models will be made available through Lilly TuneLab, an AI and machine learning platform that provides biotech companies with access to drug discovery models built on proprietary Lilly data generated at a cost of over $1 billion.&amp;nbsp;&lt;/p&gt;&lt;p&gt;As the first drug discovery platform with plans to offer both Lilly models and NVIDIA BioNeMo open foundation models for healthcare and life sciences, TuneLab uses a federated learning infrastructure built on NVIDIA FLARE, which enables biotech companies to tap into powerful proprietary AI models while keeping their data private and separate from other users. As more companies participate, the models improve, benefitting all users and further expanding AI access for the biotech ecosystem.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__full-width-video-section"&gt;
			&lt;video class="full-width-layout__video" loop="loop"&gt;
							&lt;source src="https://blogs.nvidia.com/wp-content/uploads/2025/10/lilly-mass-production.mp4" type="video/mp4" /&gt;
						&lt;p&gt;Your browser does not support HTML5 video.&lt;/p&gt;
		&lt;/video&gt;
	
	&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Historically, drug discovery has been constrained by the physical limits of the wet lab. Even highly productive teams can typically analyze roughly 2,000 molecular ideas per target per year, because each experiment requires physical synthesis and testing.&amp;nbsp;&lt;/p&gt;&lt;p&gt;“Now the supercomputer center essentially just breaks the physical limit [of the wet lab],” said Yue Wang Webster, vice president of research and development informatics at Lilly. “Now in the dry lab, you can test billions of molecule ideas at your fingertips.”&lt;/p&gt;&lt;p&gt;LillyPod removes this constraint by creating a computational dry lab at massive scale, where scientists can simulate and evaluate billions of molecular hypotheses in parallel before committing to physical experiments.&amp;nbsp;&lt;/p&gt;&lt;p&gt;With its internal AI platforms, Lilly employees can also use LillyPod to build chatbots, agentic workflows and research lab agents without reinventing the wheel.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-image-section"&gt;
			&lt;img alt="alt" class="full-width-layout__image" height="1365" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/Lilly-AI-Factory_2R7A2042-scaled.jpg" width="2048" /&gt;	
	&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;By combining science, data and compute power, Lilly and NVIDIA are breaking new ground for AI in life sciences.&lt;/p&gt;&lt;p&gt;“This machine is exactly how AI should be used,” said Fuchs. “It should be used for science. It should be used to lessen suffering and improve the human condition.”&lt;/p&gt;&lt;p&gt;Hear from Lilly at NVIDIA GTC in the following sessions:&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;i&gt;Learn more about Lilly’s collaboration with NVIDIA on &lt;/i&gt;&lt;i&gt;this AI factory&lt;/i&gt;&lt;i&gt; and an upcoming &lt;/i&gt;&lt;i&gt;co-innovation AI lab&lt;/i&gt;&lt;i&gt;.&amp;nbsp;&lt;/i&gt;&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
	&lt;div class="full-width-layout__news-section"&gt;
		&lt;p&gt;Related News&lt;/p&gt;

		
	&lt;/div&gt;
		&lt;/div&gt;
	


&lt;!-- #colophon --&gt;

&lt;/div&gt;&lt;!-- #page --&gt;


&lt;!-- #has-highlight-and-share --&gt;		&lt;svg class="hidden" height="0" width="0" xmlns="http://www.w3.org/2000/svg"&gt;
			
				&lt;g&gt;&lt;path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z" fill="currentColor"&gt;&lt;/g&gt;
			
			
				&lt;path d="M279.14 288l14.22-92.66h-88.91v-60.13c0-25.35 12.42-50.06 52.24-50.06h40.42V6.26S260.43 0 225.36 0c-73.22 0-121.08 44.38-121.08 124.72v70.62H22.89V288h81.39v224h100.17V288z" fill="currentColor"&gt;
			
			
				&lt;path d="M256 8C118.941 8 8 118.919 8 256c0 137.059 110.919 248 248 248 48.154 0 95.342-14.14 135.408-40.223 12.005-7.815 14.625-24.288 5.552-35.372l-10.177-12.433c-7.671-9.371-21.179-11.667-31.373-5.129C325.92 429.757 291.314 440 256 440c-101.458 0-184-82.542-184-184S154.542 72 256 72c100.139 0 184 57.619 184 160 0 38.786-21.093 79.742-58.17 83.693-17.349-.454-16.91-12.857-13.476-30.024l23.433-121.11C394.653 149.75 383.308 136 368.225 136h-44.981a13.518 13.518 0 0 0-13.432 11.993l-.01.092c-14.697-17.901-40.448-21.775-59.971-21.775-74.58 0-137.831 62.234-137.831 151.46 0 65.303 36.785 105.87 96 105.87 26.984 0 57.369-15.637 74.991-38.333 9.522 34.104 40.613 34.103 70.71 34.103C462.609 379.41 504 307.798 504 232 504 95.653 394.023 8 256 8zm-21.68 304.43c-22.249 0-36.07-15.623-36.07-40.771 0-44.993 30.779-72.729 58.63-72.729 22.292 0 35.601 15.241 35.601 40.77 0 45.061-33.875 72.73-58.161 72.73z" fill="currentColor"&gt;
			
			
				&lt;path d="M100.28 448H7.4V148.9h92.88zM53.79 108.1C24.09 108.1 0 83.5 0 53.8a53.79 53.79 0 0 1 107.58 0c0 29.7-24.1 54.3-53.79 54.3zM447.9 448h-92.68V302.4c0-34.7-.7-79.2-48.29-79.2-48.29 0-55.69 37.7-55.69 76.7V448h-92.78V148.9h89.08v40.8h1.3c12.4-23.5 42.69-48.3 87.88-48.3 94 0 111.28 61.9 111.28 142.3V448z" fill="currentColor"&gt;
			
			
				&lt;path d="M162.7 210c-1.8 3.3-25.2 44.4-70.1 123.5-4.9 8.3-10.8 12.5-17.7 12.5H9.8c-7.7 0-12.1-7.5-8.5-14.4l69-121.3c.2 0 .2-.1 0-.3l-43.9-75.6c-4.3-7.8.3-14.1 8.5-14.1H100c7.3 0 13.3 4.1 18 12.2l44.7 77.5zM382.6 46.1l-144 253v.3L330.2 466c3.9 7.1.2 14.1-8.5 14.1h-65.2c-7.6 0-13.6-4-18-12.2l-92.4-168.5c3.3-5.8 51.5-90.8 144.8-255.2 4.6-8.1 10.4-12.2 17.5-12.2h65.7c8 0 12.3 6.7 8.5 14.1z" fill="currentColor"&gt;
			
			
				&lt;path d="M380.9 97.1C339 55.1 283.2 32 223.9 32c-122.4 0-222 99.6-222 222 0 39.1 10.2 77.3 29.6 111L0 480l117.7-30.9c32.4 17.7 68.9 27 106.1 27h.1c122.3 0 224.1-99.6 224.1-222 0-59.3-25.2-115-67.1-157zm-157 341.6c-33.2 0-65.7-8.9-94-25.7l-6.7-4-69.8 18.3L72 359.2l-4.4-7c-18.5-29.4-28.2-63.3-28.2-98.2 0-101.7 82.8-184.5 184.6-184.5 49.3 0 95.6 19.2 130.4 54.1 34.8 34.9 56.2 81.2 56.1 130.5 0 101.8-84.9 184.6-186.6 184.6zm101.2-138.2c-5.5-2.8-32.8-16.2-37.9-18-5.1-1.9-8.8-2.8-12.5 2.8-3.7 5.6-14.3 18-17.6 21.8-3.2 3.7-6.5 4.2-12 1.4-32.6-16.3-54-29.1-75.5-66-5.7-9.8 5.7-9.1 16.3-30.3 1.8-3.7.9-6.9-.5-9.7-1.4-2.8-12.5-30.1-17.1-41.2-4.5-10.8-9.1-9.3-12.5-9.5-3.2-.2-6.9-.2-10.6-.2-3.7 0-9.7 1.4-14.8 6.9-5.1 5.6-19.4 19-19.4 46.3 0 27.3 19.9 53.7 22.6 57.4 2.8 3.7 39.1 59.7 94.8 83.8 35.2 15.2 49 16.5 66.6 13.9 10.7-1.6 32.8-13.4 37.4-26.4 4.6-13 4.6-24.1 3.2-26.4-1.3-2.5-5-3.9-10.5-6.6z" fill="currentColor"&gt;
			
			
				&lt;path d="M320 448v40c0 13.255-10.745 24-24 24H24c-13.255 0-24-10.745-24-24V120c0-13.255 10.745-24 24-24h72v296c0 30.879 25.121 56 56 56h168zm0-344V0H152c-13.255 0-24 10.745-24 24v368c0 13.255 10.745 24 24 24h272c13.255 0 24-10.745 24-24V128H344c-13.2 0-24-10.8-24-24zm120.971-31.029L375.029 7.029A24 24 0 0 0 358.059 0H352v96h96v-6.059a24 24 0 0 0-7.029-16.97z" fill="currentColor"&gt;
			
			
				&lt;path d="M352 320c-22.608 0-43.387 7.819-59.79 20.895l-102.486-64.054a96.551 96.551 0 0 0 0-41.683l102.486-64.054C308.613 184.181 329.392 192 352 192c53.019 0 96-42.981 96-96S405.019 0 352 0s-96 42.981-96 96c0 7.158.79 14.13 2.276 20.841L155.79 180.895C139.387 167.819 118.608 160 96 160c-53.019 0-96 42.981-96 96s42.981 96 96 96c22.608 0 43.387-7.819 59.79-20.895l102.486 64.054A96.301 96.301 0 0 0 256 416c0 53.019 42.981 96 96 96s96-42.981 96-96-42.981-96-96-96z" fill="currentColor"&gt;
			
			
				&lt;path d="M440.3 203.5c-15 0-28.2 6.2-37.9 15.9-35.7-24.7-83.8-40.6-137.1-42.3L293 52.3l88.2 19.8c0 21.6 17.6 39.2 39.2 39.2 22 0 39.7-18.1 39.7-39.7s-17.6-39.7-39.7-39.7c-15.4 0-28.7 9.3-35.3 22l-97.4-21.6c-4.9-1.3-9.7 2.2-11 7.1L246.3 177c-52.9 2.2-100.5 18.1-136.3 42.8-9.7-10.1-23.4-16.3-38.4-16.3-55.6 0-73.8 74.6-22.9 100.1-1.8 7.9-2.6 16.3-2.6 24.7 0 83.8 94.4 151.7 210.3 151.7 116.4 0 210.8-67.9 210.8-151.7 0-8.4-.9-17.2-3.1-25.1 49.9-25.6 31.5-99.7-23.8-99.7zM129.4 308.9c0-22 17.6-39.7 39.7-39.7 21.6 0 39.2 17.6 39.2 39.7 0 21.6-17.6 39.2-39.2 39.2-22 .1-39.7-17.6-39.7-39.2zm214.3 93.5c-36.4 36.4-139.1 36.4-175.5 0-4-3.5-4-9.7 0-13.7 3.5-3.5 9.7-3.5 13.2 0 27.8 28.5 120 29 149 0 3.5-3.5 9.7-3.5 13.2 0 4.1 4 4.1 10.2.1 13.7zm-.8-54.2c-21.6 0-39.2-17.6-39.2-39.2 0-22 17.6-39.7 39.2-39.7 22 0 39.7 17.6 39.7 39.7-.1 21.5-17.7 39.2-39.7 39.2z" fill="currentColor"&gt;
			
			
				&lt;path d="M446.7 98.6l-67.6 318.8c-5.1 22.5-18.4 28.1-37.3 17.5l-103-75.9-49.7 47.8c-5.5 5.5-10.1 10.1-20.7 10.1l7.4-104.9 190.9-172.5c8.3-7.4-1.8-11.5-12.9-4.1L117.8 284 16.2 252.2c-22.1-6.9-22.5-22.1 4.6-32.7L418.2 66.4c18.4-6.9 34.5 4.1 28.5 32.2z" fill="currentColor"&gt;
			
			
				&lt;g&gt;
					&lt;path d="M97.2800192,3.739673 L100.160021,15.3787704 C88.8306631,18.1647705 77.9879854,22.6484879 68.0000023,28.6777391 L61.8399988,18.3985363 C72.8467373,11.7537029 84.7951803,6.81153332 97.2800192,3.739673 Z M158.720055,3.739673 L155.840053,15.3787704 C167.169411,18.1647705 178.012089,22.6484879 188.000072,28.6777391 L194.200075,18.3985363 C183.180932,11.7499974 171.218739,6.80771878 158.720055,3.739673 L158.720055,3.739673 Z M18.3999736,61.8351679 C11.7546212,72.8410466 6.81206547,84.7885562 3.73996516,97.2724198 L15.3799719,100.152197 C18.1661896,88.8237238 22.6502573,77.981893 28.6799796,67.9946902 L18.3999736,61.8351679 Z M11.9999699,127.990038 C11.9961044,122.172725 12.4306685,116.363392 13.2999707,110.611385 L1.43996383,108.811525 C-0.479938607,121.525138 -0.479938607,134.454937 1.43996383,147.168551 L13.2999707,145.36869 C12.4306685,139.616684 11.9961044,133.807351 11.9999699,127.990038 L11.9999699,127.990038 Z M194.160075,237.581539 L188.000072,227.302336 C178.024494,233.327885 167.195565,237.811494 155.880053,240.601305 L158.760055,252.240403 C171.231048,249.164732 183.165742,244.222671 194.160075,237.581539 L194.160075,237.581539 Z M244.000104,127.990038 C244.00397,133.807351 243.569406,139.616684 242.700103,145.36869 L254.56011,147.168551 C256.480013,134.454937 256.480013,121.525138 254.56011,108.811525 L242.700103,110.611385 C243.569406,116.363392 244.00397,122.172725 244.000104,127.990038 Z M252.260109,158.707656 L240.620102,155.827879 C237.833884,167.156352 233.349817,177.998183 227.320094,187.985385 L237.6001,194.184905 C244.249159,183.166622 249.191823,171.205364 252.260109,158.707656 L252.260109,158.707656 Z M145.380047,242.701142 C133.858209,244.43447 122.141865,244.43447 110.620027,242.701142 L108.820026,254.560223 C121.534632,256.479975 134.465442,256.479975 147.180048,254.560223 L145.380047,242.701142 Z M221.380091,196.804701 C214.461479,206.174141 206.175877,214.452354 196.800077,221.362797 L203.920081,231.022048 C214.262958,223.418011 223.404944,214.303705 231.040097,203.984145 L221.380091,196.804701 Z M196.800077,34.6172785 C206.177345,41.5338058 214.463023,49.8188367 221.380091,59.1953726 L231.040097,51.9959309 C223.429284,41.6822474 214.31457,32.5682452 204.000081,24.9580276 L196.800077,34.6172785 Z M34.619983,59.1953726 C41.5370506,49.8188367 49.8227288,41.5338058 59.1999972,34.6172785 L51.9999931,24.9580276 C41.6855038,32.5682452 32.5707896,41.6822474 24.9599774,51.9959309 L34.619983,59.1953726 Z M237.6001,61.8351679 L227.320094,67.9946902 C233.346114,77.969489 237.830073,88.7975718 240.620102,100.1122 L252.260109,97.2324229 C249.184198,84.7624043 244.241751,72.8286423 237.6001,61.8351679 L237.6001,61.8351679 Z M110.620027,13.2989317 C122.141865,11.5656035 133.858209,11.5656035 145.380047,13.2989317 L147.180048,1.43985134 C134.465442,-0.479901112 121.534632,-0.479901112 108.820026,1.43985134 L110.620027,13.2989317 Z M40.7799866,234.201801 L15.9999722,239.981353 L21.7799756,215.203275 L10.0999688,212.463487 L4.3199655,237.241566 C3.3734444,241.28318 4.58320332,245.526897 7.51859925,248.462064 C10.4539952,251.39723 14.6980441,252.606895 18.7399738,251.660448 L43.4999881,245.980888 L40.7799866,234.201801 Z M12.5999703,201.764317 L24.279977,204.484106 L28.2799793,187.305438 C22.4496684,177.507146 18.1025197,166.899584 15.3799719,155.827879 L3.73996516,158.707656 C6.34937618,169.311891 10.3154147,179.535405 15.539972,189.125297 L12.5999703,201.764317 Z M68.6000027,227.762301 L51.4199927,231.761991 L54.1399943,243.441085 L66.7800016,240.501313 C76.3706428,245.725462 86.5949557,249.691191 97.2000192,252.300398 L100.080021,240.6613 C89.0307035,237.906432 78.4495684,233.532789 68.6800027,227.682307 L68.6000027,227.762301 Z M128.000037,23.9980665 C90.1565244,24.0177003 55.3105242,44.590631 37.01511,77.715217 C18.7196958,110.839803 19.8628631,151.287212 39.9999861,183.325747 L29.9999803,225.982439 L72.660005,215.983214 C110.077932,239.548522 158.307237,236.876754 192.892851,209.322653 C227.478464,181.768552 240.856271,135.358391 226.242944,93.6248278 C211.629616,51.8912646 172.221191,23.9617202 128.000037,23.9980665 Z" fill="currentColor"&gt;
				&lt;/g&gt;
			
			
				&lt;g&gt;
					&lt;path d="M357.1,324.5c-24.1,15.3-57.2,21.4-79.1,23.6l18.4,18.1l67,67c24.5,25.1-15.4,64.4-40.2,40.2c-16.8-17-41.4-41.6-67-67.3
						l-67,67.2c-24.8,24.2-64.7-15.5-39.9-40.2c17-17,41.4-41.6,67-67l18.1-18.1c-21.6-2.3-55.3-8-79.6-23.6
						c-28.6-18.5-41.2-29.3-30.1-51.8c6.5-12.8,24.3-23.6,48-5c0,0,31.9,25.4,83.4,25.4s83.4-25.4,83.4-25.4c23.6-18.5,41.4-7.8,48,5
						C398.3,295.1,385.7,305.9,357.1,324.5L357.1,324.5z M142,145c0-63,51.2-114,114-114s114,51,114,114c0,62.7-51.2,113.7-114,113.7
						S142,207.7,142,145L142,145z M200,145c0,30.8,25.1,56,56,56s56-25.1,56-56c0-31.1-25.1-56.2-56-56.2S200,113.9,200,145z" fill="currentColor"&gt;
				&lt;/g&gt;
			
			
				&lt;g transform="translate(0,664)"&gt;
					&lt;path d="m 1073.3513,-606.40537 h 196.278 c 179.2103,0 221.8795,42.66915 221.8795,221.8795 v 196.27799 c 0,179.2103512 -42.6692,221.879451 -221.8795,221.879451 h -196.278 c -179.21038,0 -221.87951,-42.6691298 -221.87951,-221.879451 v -196.27801 c 0,-179.21035 42.66913,-221.87946 221.87951,-221.87948 z" fill="currentColor"&gt;
					&lt;path d="m 1375.0576,-393.98425 c 2.9513,-9.7072 0,-16.85429 -14.1342,-16.85429 h -46.6693 c -11.8763,0 -17.3521,6.16927 -20.3212,12.97854 0,0 -23.7347,56.82106 -57.3544,93.74763 -10.8806,10.66728 -15.8232,14.08081 -21.7613,14.08081 -2.969,0 -7.2715,-3.39577 -7.2715,-13.12075 v -90.83194 c 0,-11.66288 -3.4491,-16.85429 -13.3341,-16.85429 h -73.3553 c -7.4138,0 -11.8763,5.40476 -11.8763,10.54286 0,11.0406 16.8188,13.60078 18.5433,44.67814 v 67.52388 c 0,14.80973 -2.7202,17.49433 -8.6583,17.49433 -15.8231,0 -54.3143,-57.08773 -77.16,-122.40705 -4.4447,-12.71185 -8.9427,-17.83214 -20.8723,-17.83214 h -46.68718 c -13.3341,0 -16.0009,6.16925 -16.0009,12.97852 0,12.12515 15.8232,72.35973 73.69318,152.02656 38.58,54.40315 92.8942,83.89819 142.3726,83.89819 29.6729,0 33.3353,-6.54262 33.3353,-17.83216 v -41.12238 c 0,-13.10297 2.809,-15.71646 12.214,-15.71646 6.9338,0 18.7922,3.41353 46.4916,29.63728 31.6463,31.09512 36.8555,45.03372 54.6698,45.03372 h 46.6694 c 13.3341,0 20.0189,-6.54262 16.1787,-19.46781 -4.2313,-12.88962 -19.3433,-31.57515 -39.38,-53.74532 -10.8807,-12.62294 -27.2016,-26.22375 -32.1441,-33.03302 -6.9338,-8.72941 -4.9603,-12.62294 0,-20.39227 0,0 56.8566,-78.68897 62.7947,-105.41058 z" fill="currentColor"&gt;
					&lt;path d="m 567.69877,-429.06912 c 3.15618,-10.38133 0,-18.0247 -15.11579,-18.0247 h -49.91013 c -12.70096,0 -18.55706,6.59763 -21.73232,13.87977 0,0 -25.38286,60.76685 -61.33724,100.25768 -11.63627,11.40806 -16.92197,15.05863 -23.27242,15.05863 -3.17519,0 -7.77644,-3.63156 -7.77644,-14.0319 v -97.13948 c 0,-12.47278 -3.68869,-18.0247 -14.26014,-18.0247 h -78.44923 c -7.92857,0 -12.70097,5.78005 -12.70097,11.27491 0,11.80736 17.98666,14.54527 19.83094,47.78071 v 72.21293 c 0,15.83815 -2.9091,18.70918 -9.25948,18.70918 -16.92197,0 -58.08598,-61.05206 -82.51817,-130.90731 -4.75337,-13.59458 -9.56381,-19.07042 -22.32175,-19.07042 h -49.92915 c -14.26014,0 -17.11213,6.59763 -17.11213,13.87977 0,12.96714 16.92197,77.38454 78.81059,162.58363 41.25909,58.18101 99.34506,89.72424 152.25931,89.72424 31.73343,0 35.65018,-6.99691 35.65018,-19.07043 v -43.978 c 0,-14.01288 3.00405,-16.80786 13.0622,-16.80786 7.41521,0 20.09716,3.65057 49.71998,31.69536 33.84387,33.25443 39.41486,48.16093 58.46622,48.16093 h 49.91026 c 14.26,0 21.40913,-6.99691 17.30216,-20.81966 -4.5252,-13.78473 -20.68653,-33.76783 -42.11468,-57.47752 -11.63621,-13.49953 -29.09043,-28.04479 -34.37631,-35.32694 -7.41508,-9.33557 -5.30458,-13.4995 0,-21.80835 0,0 60.80491,-84.15334 67.15549,-112.73048 z" fill="currentColor"&gt;
				&lt;/g&gt;
			
			&lt;path d="M309.8 480.3c-13.6 14.5-50 31.7-97.4 31.7-120.8 0-147-88.8-147-140.6v-144H17.9c-5.5 0-10-4.5-10-10v-68c0-7.2 4.5-13.6 11.3-16 62-21.8 81.5-76 84.3-117.1.8-11 6.5-16.3 16.1-16.3h70.9c5.5 0 10 4.5 10 10v115.2h83c5.5 0 10 4.4 10 9.9v81.7c0 5.5-4.5 10-10 10h-83.4V360c0 34.2 23.7 53.6 68 35.8 4.8-1.9 9-3.2 12.7-2.2 3.5.9 5.8 3.4 7.4 7.9l22 64.3c1.8 5 3.3 10.6-.4 14.5z" fill="currentColor"&gt;
			&lt;path d="M512 208L320 384H288V288H208c-61.9 0-112 50.1-112 112c0 48 32 80 32 80s-128-48-128-176c0-97.2 78.8-176 176-176H288V32h32L512 208z" fill="currentColor"&gt;
			&lt;path d="M309.8 480.3c-13.6 14.5-50 31.7-97.4 31.7-120.8 0-147-88.8-147-140.6v-144H17.9c-5.5 0-10-4.5-10-10v-68c0-7.2 4.5-13.6 11.3-16 62-21.8 81.5-76 84.3-117.1.8-11 6.5-16.3 16.1-16.3h70.9c5.5 0 10 4.5 10 10v115.2h83c5.5 0 10 4.4 10 9.9v81.7c0 5.5-4.5 10-10 10h-83.4V360c0 34.2 23.7 53.6 68 35.8 4.8-1.9 9-3.2 12.7-2.2 3.5.9 5.8 3.4 7.4 7.9l22 64.3c1.8 5 3.3 10.6-.4 14.5z" fill="currentColor"&gt;
			&lt;path d="M433 179.1c0-97.2-63.7-125.7-63.7-125.7-62.5-28.7-228.6-28.4-290.5 0 0 0-63.7 28.5-63.7 125.7 0 115.7-6.6 259.4 105.6 289.1 40.5 10.7 75.3 13 103.3 11.4 50.8-2.8 79.3-18.1 79.3-18.1l-1.7-36.9s-36.3 11.4-77.1 10.1c-40.4-1.4-83-4.4-89.6-54a102.5 102.5 0 0 1 -.9-13.9c85.6 20.9 158.7 9.1 178.8 6.7 56.1-6.7 105-41.3 111.2-72.9 9.8-49.8 9-121.5 9-121.5zm-75.1 125.2h-46.6v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.3V197c0-58.5-64-56.6-64-6.9v114.2H90.2c0-122.1-5.2-147.9 18.4-175 25.9-28.9 79.8-30.8 103.8 6.1l11.6 19.5 11.6-19.5c24.1-37.1 78.1-34.8 103.8-6.1 23.7 27.3 18.4 53 18.4 175z" fill="currentColor"&gt;
			
				&lt;path d="M331.5 235.7c2.2 .9 4.2 1.9 6.3 2.8c29.2 14.1 50.6 35.2 61.8 61.4c15.7 36.5 17.2 95.8-30.3 143.2c-36.2 36.2-80.3 52.5-142.6 53h-.3c-70.2-.5-124.1-24.1-160.4-70.2c-32.3-41-48.9-98.1-49.5-169.6V256v-.2C17 184.3 33.6 127.2 65.9 86.2C102.2 40.1 156.2 16.5 226.4 16h.3c70.3 .5 124.9 24 162.3 69.9c18.4 22.7 32 50 40.6 81.7l-40.4 10.8c-7.1-25.8-17.8-47.8-32.2-65.4c-29.2-35.8-73-54.2-130.5-54.6c-57 .5-100.1 18.8-128.2 54.4C72.1 146.1 58.5 194.3 58 256c.5 61.7 14.1 109.9 40.3 143.3c28 35.6 71.2 53.9 128.2 54.4c51.4-.4 85.4-12.6 113.7-40.9c32.3-32.2 31.7-71.8 21.4-95.9c-6.1-14.2-17.1-26-31.9-34.9c-3.7 26.9-11.8 48.3-24.7 64.8c-17.1 21.8-41.4 33.6-72.7 35.3c-23.6 1.3-46.3-4.4-63.9-16c-20.8-13.8-33-34.8-34.3-59.3c-2.5-48.3 35.7-83 95.2-86.4c21.1-1.2 40.9-.3 59.2 2.8c-2.4-14.8-7.3-26.6-14.6-35.2c-10-11.7-25.6-17.7-46.2-17.8H227c-16.6 0-39 4.6-53.3 26.3l-34.4-23.6c19.2-29.1 50.3-45.1 87.8-45.1h.8c62.6 .4 99.9 39.5 103.7 107.7l-.2 .2zm-156 68.8c1.3 25.1 28.4 36.8 54.6 35.3c25.6-1.4 54.6-11.4 59.5-73.2c-13.2-2.9-27.8-4.4-43.4-4.4c-4.8 0-9.6 .1-14.4 .4c-42.9 2.4-57.2 23.2-56.2 41.8l-.1 .1z" fill="currentColor"&gt;
			
			
				&lt;path d="M407.8 294.7c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3zM288 227.1C261.9 176.4 190.9 81.9 124.9 35.3C61.6-9.4 37.5-1.7 21.6 5.5C3.3 13.8 0 41.9 0 58.4S9.1 194 15 213.9c19.5 65.7 89.1 87.9 153.2 80.7c3.3-.5 6.6-.9 10-1.4c-3.3 .5-6.6 1-10 1.4C74.3 308.6-9.1 342.8 100.3 464.5C220.6 589.1 265.1 437.8 288 361.1c22.9 76.7 49.2 222.5 185.6 103.4c102.4-103.4 28.1-156-65.8-169.9c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3c64.1 7.1 133.6-15.1 153.2-80.7C566.9 194 576 75 576 58.4s-3.3-44.7-21.6-52.9c-15.8-7.1-40-14.9-103.2 29.8C385.1 81.9 314.1 176.4 288 227.1z" fill="currentColor"&gt;
			
			
				&lt;path d="M204 6.5C101.4 6.5 0 74.9 0 185.6 0 256 39.6 296 63.6 296c9.9 0 15.6-27.6 15.6-35.4 0-9.3-23.7-29.1-23.7-67.8 0-80.4 61.2-137.4 140.4-137.4 68.1 0 118.5 38.7 118.5 109.8 0 53.1-21.3 152.7-90.3 152.7-24.9 0-46.2-18-46.2-43.8 0-37.8 26.4-74.4 26.4-113.4 0-66.2-93.9-54.2-93.9 25.8 0 16.8 2.1 35.4 9.6 50.7-13.8 59.4-42 147.9-42 209.1 0 18.9 2.7 37.5 4.5 56.4 3.4 3.8 1.7 3.4 6.9 1.5 50.4-69 48.6-82.5 71.4-172.8 12.3 23.4 44.1 36 69.3 36 106.2 0 153.9-103.5 153.9-196.8C384 71.3 298.2 6.5 204 6.5z" fill="currentColor"&gt;
			
		&lt;/svg&gt;
		&lt;div id="has-mastodon-prompt"&gt;
			&lt;h3&gt;Share on Mastodon&lt;/h3&gt;
			
		&lt;/div&gt;</description><content:encoded>&lt;!-- OneTrust Cookies Consent Notice start for nvidia.com --&gt;


&lt;!-- OneTrust Cookies Consent Notice end for nvidia.com --&gt;


	
	
	
	
	
	

	

	
&lt;!-- Broadcast could not find a linked parent for the canonical. --&gt;



	&lt;!-- This site is optimized with the Yoast SEO Premium plugin v27.0 (Yoast SEO v27.0) - https://yoast.com/product/yoast-seo-premium-wordpress/ --&gt;
	Now Live: Lilly AI Factory for Pharmaceutical Discovery and Development | NVIDIA Blog
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	&lt;!-- / Yoast SEO Premium plugin. --&gt;







































&lt;!-- Stream WordPress user activity plugin v4.1.1 --&gt;


	
				&lt;!-- Hotjar Tracking Code for NVIDIA --&gt;
			
			


				
				



		
		

&lt;div class="hfeed site" id="page"&gt;
	Skip to content

	&lt;!-- #masthead --&gt;
		
		&lt;div class="full-width-layout light"&gt;
		

		
&lt;div class="full-width-layout__hero light"&gt;
	&lt;div class="full-width-layout__hero-content light"&gt;
		&lt;div class="full-width-layout__hero-content__inner light"&gt;
			

							&lt;p&gt;
					Built with over 1,000 NVIDIA Blackwell Ultra GPUs, LillyPod is now online to power scientific research and supercharge the future of medicine.				&lt;/p&gt;
			
			
		&lt;/div&gt;
	&lt;/div&gt;

	

	&lt;/div&gt;

	
	
		&lt;div class="full-width-layout__sections"&gt;
&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Saving and improving lives — that most human endeavor — just got a super-computational boost.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lilly this week launched the most powerful AI factory wholly owned and operated by a pharmaceutical company to help its teams make meaningful medical advancements faster, more accurately and at unprecedented scale. Dubbed LillyPod, it’s the world’s first NVIDIA DGX SuperPOD with DGX B300 systems.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Powered by a DGX SuperPOD with 1,016 NVIDIA Blackwell Ultra GPUs, Lilly’s AI factory delivers more than 9,000 petaflops of AI performance. It was assembled in just four months.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-video-section"&gt;
	&lt;video class="full-width-layout__video js-responsive-video" loop="loop"&gt;Your browser does not support the video tag.&lt;/video&gt;
&lt;p&gt;
			&lt;span class="full-width-layout__media-caption-callout"&gt;
			LillyPod was inaugurated Wednesday at a ribbon-cutting in Indianapolis.		&lt;/span&gt;
	
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;“It’s a big day for us with the supercomputer coming on board, but it’s a day 150 years in the making,” said Diogo Rau, executive vice president and chief information and digital officer at Lilly. “LillyPod is a powerful symbol of who we are and why we do this work: to make life better for people around the world. We are, right here, right now, at the right moment to advance biology in a way that has just never been done before.”&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;Step Behind the Scenes of the LillyPod&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Computational power that once required 7 million Cray supercomputers now fits inside a single NVIDIA GPU — and LillyPod contains more than 1,000 of them. This infrastructure enables Lilly’s genomics team to harness 700 terabytes of data using over 290 terabytes of high-bandwidth GPU memory.&amp;nbsp;&lt;/p&gt;&lt;p&gt;“Computation is at the heart of biology and it is at the heart of science,” said Thomas Fuchs, senior vice president and chief AI officer at Lilly. “Being able to compute at scale is not something optional for a company like ours, it is absolutely necessary. So we are building the computational future of medicine and you see that in all areas along the pharmaceutical value chain.”&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__full-width-image-section"&gt;
			&lt;img alt="alt" class="full-width-layout__image" height="455" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/Lilly-AI-Factory_triptych1-scaled.png" width="2048" /&gt;	
	&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Lilly’s AI factory is set to support the large-scale training of protein diffusion models, small-molecule graph neural network models and genomics foundation models.&lt;/p&gt;&lt;p&gt;NVIDIA’s full-stack AI factory architecture offered with NVIDIA DGX SuperPOD — including accelerated computing, NVIDIA Spectrum-X Ethernet networking and optimized AI software — provides a secure, scalable platform for the highly regulated workflows of healthcare and life sciences.&amp;nbsp;&lt;/p&gt;&lt;p&gt;NVIDIA Mission Control software allows Lilly to manage its DGX SuperPOD, orchestrate workloads, monitor performance and automate AI operations securely and efficiently.&lt;/p&gt;&lt;p&gt;The supercomputer’s nearly 5,000 connections are built with more than 1,000 pounds of fiber cables. Lilly aims for its new AI supercomputing infrastructure to run on 100% renewable electricity by 2030, using efficient liquid cooling and minimal incremental energy impact.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__full-width-image-section"&gt;
			&lt;img alt="alt" class="full-width-layout__image" height="455" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/Lilly-AI-Factory_triptych2-scaled.png" width="2048" /&gt;	
	&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;Advancing Foundation Models, Physical and Agentic AI&amp;nbsp;&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;LillyPod is more than a tool — it’s a new scientific instrument that brings together proprietary data and advanced AI models.&amp;nbsp;&lt;/p&gt;&lt;p&gt;With this foundation, Lilly teams can analyze genomes, explore billions of chemical possibilities and apply AI across clinical development and manufacturing to design better trials, optimize production and accelerate decision‑making. Together, these capabilities enable faster, more precise and more scalable creation and delivery of medicines.&lt;/p&gt;&lt;p&gt;“LillyPod will usher in a new era of AI-driven drug discovery,” said Tim Coleman, senior vice president and chief technology officer at Lilly. “We believe that computation is foundational to science and that Lilly patients deserve every advantage that we can give them.”&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__full-width-video-section"&gt;
			&lt;video class="full-width-layout__video" loop="loop"&gt;
							&lt;source src="https://blogs.nvidia.com/wp-content/uploads/2025/10/lilly-scientists.mp4" type="video/mp4" /&gt;
						&lt;p&gt;Your browser does not support HTML5 video.&lt;/p&gt;
		&lt;/video&gt;
	
	&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Select models will be made available through Lilly TuneLab, an AI and machine learning platform that provides biotech companies with access to drug discovery models built on proprietary Lilly data generated at a cost of over $1 billion.&amp;nbsp;&lt;/p&gt;&lt;p&gt;As the first drug discovery platform with plans to offer both Lilly models and NVIDIA BioNeMo open foundation models for healthcare and life sciences, TuneLab uses a federated learning infrastructure built on NVIDIA FLARE, which enables biotech companies to tap into powerful proprietary AI models while keeping their data private and separate from other users. As more companies participate, the models improve, benefitting all users and further expanding AI access for the biotech ecosystem.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__full-width-video-section"&gt;
			&lt;video class="full-width-layout__video" loop="loop"&gt;
							&lt;source src="https://blogs.nvidia.com/wp-content/uploads/2025/10/lilly-mass-production.mp4" type="video/mp4" /&gt;
						&lt;p&gt;Your browser does not support HTML5 video.&lt;/p&gt;
		&lt;/video&gt;
	
	&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Historically, drug discovery has been constrained by the physical limits of the wet lab. Even highly productive teams can typically analyze roughly 2,000 molecular ideas per target per year, because each experiment requires physical synthesis and testing.&amp;nbsp;&lt;/p&gt;&lt;p&gt;“Now the supercomputer center essentially just breaks the physical limit [of the wet lab],” said Yue Wang Webster, vice president of research and development informatics at Lilly. “Now in the dry lab, you can test billions of molecule ideas at your fingertips.”&lt;/p&gt;&lt;p&gt;LillyPod removes this constraint by creating a computational dry lab at massive scale, where scientists can simulate and evaluate billions of molecular hypotheses in parallel before committing to physical experiments.&amp;nbsp;&lt;/p&gt;&lt;p&gt;With its internal AI platforms, Lilly employees can also use LillyPod to build chatbots, agentic workflows and research lab agents without reinventing the wheel.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-image-section"&gt;
			&lt;img alt="alt" class="full-width-layout__image" height="1365" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/Lilly-AI-Factory_2R7A2042-scaled.jpg" width="2048" /&gt;	
	&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;By combining science, data and compute power, Lilly and NVIDIA are breaking new ground for AI in life sciences.&lt;/p&gt;&lt;p&gt;“This machine is exactly how AI should be used,” said Fuchs. “It should be used for science. It should be used to lessen suffering and improve the human condition.”&lt;/p&gt;&lt;p&gt;Hear from Lilly at NVIDIA GTC in the following sessions:&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;i&gt;Learn more about Lilly’s collaboration with NVIDIA on &lt;/i&gt;&lt;i&gt;this AI factory&lt;/i&gt;&lt;i&gt; and an upcoming &lt;/i&gt;&lt;i&gt;co-innovation AI lab&lt;/i&gt;&lt;i&gt;.&amp;nbsp;&lt;/i&gt;&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
	&lt;div class="full-width-layout__news-section"&gt;
		&lt;p&gt;Related News&lt;/p&gt;

		
	&lt;/div&gt;
		&lt;/div&gt;
	


&lt;!-- #colophon --&gt;

&lt;/div&gt;&lt;!-- #page --&gt;


&lt;!-- #has-highlight-and-share --&gt;		&lt;svg class="hidden" height="0" width="0" xmlns="http://www.w3.org/2000/svg"&gt;
			
				&lt;g&gt;&lt;path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z" fill="currentColor"&gt;&lt;/g&gt;
			
			
				&lt;path d="M279.14 288l14.22-92.66h-88.91v-60.13c0-25.35 12.42-50.06 52.24-50.06h40.42V6.26S260.43 0 225.36 0c-73.22 0-121.08 44.38-121.08 124.72v70.62H22.89V288h81.39v224h100.17V288z" fill="currentColor"&gt;
			
			
				&lt;path d="M256 8C118.941 8 8 118.919 8 256c0 137.059 110.919 248 248 248 48.154 0 95.342-14.14 135.408-40.223 12.005-7.815 14.625-24.288 5.552-35.372l-10.177-12.433c-7.671-9.371-21.179-11.667-31.373-5.129C325.92 429.757 291.314 440 256 440c-101.458 0-184-82.542-184-184S154.542 72 256 72c100.139 0 184 57.619 184 160 0 38.786-21.093 79.742-58.17 83.693-17.349-.454-16.91-12.857-13.476-30.024l23.433-121.11C394.653 149.75 383.308 136 368.225 136h-44.981a13.518 13.518 0 0 0-13.432 11.993l-.01.092c-14.697-17.901-40.448-21.775-59.971-21.775-74.58 0-137.831 62.234-137.831 151.46 0 65.303 36.785 105.87 96 105.87 26.984 0 57.369-15.637 74.991-38.333 9.522 34.104 40.613 34.103 70.71 34.103C462.609 379.41 504 307.798 504 232 504 95.653 394.023 8 256 8zm-21.68 304.43c-22.249 0-36.07-15.623-36.07-40.771 0-44.993 30.779-72.729 58.63-72.729 22.292 0 35.601 15.241 35.601 40.77 0 45.061-33.875 72.73-58.161 72.73z" fill="currentColor"&gt;
			
			
				&lt;path d="M100.28 448H7.4V148.9h92.88zM53.79 108.1C24.09 108.1 0 83.5 0 53.8a53.79 53.79 0 0 1 107.58 0c0 29.7-24.1 54.3-53.79 54.3zM447.9 448h-92.68V302.4c0-34.7-.7-79.2-48.29-79.2-48.29 0-55.69 37.7-55.69 76.7V448h-92.78V148.9h89.08v40.8h1.3c12.4-23.5 42.69-48.3 87.88-48.3 94 0 111.28 61.9 111.28 142.3V448z" fill="currentColor"&gt;
			
			
				&lt;path d="M162.7 210c-1.8 3.3-25.2 44.4-70.1 123.5-4.9 8.3-10.8 12.5-17.7 12.5H9.8c-7.7 0-12.1-7.5-8.5-14.4l69-121.3c.2 0 .2-.1 0-.3l-43.9-75.6c-4.3-7.8.3-14.1 8.5-14.1H100c7.3 0 13.3 4.1 18 12.2l44.7 77.5zM382.6 46.1l-144 253v.3L330.2 466c3.9 7.1.2 14.1-8.5 14.1h-65.2c-7.6 0-13.6-4-18-12.2l-92.4-168.5c3.3-5.8 51.5-90.8 144.8-255.2 4.6-8.1 10.4-12.2 17.5-12.2h65.7c8 0 12.3 6.7 8.5 14.1z" fill="currentColor"&gt;
			
			
				&lt;path d="M380.9 97.1C339 55.1 283.2 32 223.9 32c-122.4 0-222 99.6-222 222 0 39.1 10.2 77.3 29.6 111L0 480l117.7-30.9c32.4 17.7 68.9 27 106.1 27h.1c122.3 0 224.1-99.6 224.1-222 0-59.3-25.2-115-67.1-157zm-157 341.6c-33.2 0-65.7-8.9-94-25.7l-6.7-4-69.8 18.3L72 359.2l-4.4-7c-18.5-29.4-28.2-63.3-28.2-98.2 0-101.7 82.8-184.5 184.6-184.5 49.3 0 95.6 19.2 130.4 54.1 34.8 34.9 56.2 81.2 56.1 130.5 0 101.8-84.9 184.6-186.6 184.6zm101.2-138.2c-5.5-2.8-32.8-16.2-37.9-18-5.1-1.9-8.8-2.8-12.5 2.8-3.7 5.6-14.3 18-17.6 21.8-3.2 3.7-6.5 4.2-12 1.4-32.6-16.3-54-29.1-75.5-66-5.7-9.8 5.7-9.1 16.3-30.3 1.8-3.7.9-6.9-.5-9.7-1.4-2.8-12.5-30.1-17.1-41.2-4.5-10.8-9.1-9.3-12.5-9.5-3.2-.2-6.9-.2-10.6-.2-3.7 0-9.7 1.4-14.8 6.9-5.1 5.6-19.4 19-19.4 46.3 0 27.3 19.9 53.7 22.6 57.4 2.8 3.7 39.1 59.7 94.8 83.8 35.2 15.2 49 16.5 66.6 13.9 10.7-1.6 32.8-13.4 37.4-26.4 4.6-13 4.6-24.1 3.2-26.4-1.3-2.5-5-3.9-10.5-6.6z" fill="currentColor"&gt;
			
			
				&lt;path d="M320 448v40c0 13.255-10.745 24-24 24H24c-13.255 0-24-10.745-24-24V120c0-13.255 10.745-24 24-24h72v296c0 30.879 25.121 56 56 56h168zm0-344V0H152c-13.255 0-24 10.745-24 24v368c0 13.255 10.745 24 24 24h272c13.255 0 24-10.745 24-24V128H344c-13.2 0-24-10.8-24-24zm120.971-31.029L375.029 7.029A24 24 0 0 0 358.059 0H352v96h96v-6.059a24 24 0 0 0-7.029-16.97z" fill="currentColor"&gt;
			
			
				&lt;path d="M352 320c-22.608 0-43.387 7.819-59.79 20.895l-102.486-64.054a96.551 96.551 0 0 0 0-41.683l102.486-64.054C308.613 184.181 329.392 192 352 192c53.019 0 96-42.981 96-96S405.019 0 352 0s-96 42.981-96 96c0 7.158.79 14.13 2.276 20.841L155.79 180.895C139.387 167.819 118.608 160 96 160c-53.019 0-96 42.981-96 96s42.981 96 96 96c22.608 0 43.387-7.819 59.79-20.895l102.486 64.054A96.301 96.301 0 0 0 256 416c0 53.019 42.981 96 96 96s96-42.981 96-96-42.981-96-96-96z" fill="currentColor"&gt;
			
			
				&lt;path d="M440.3 203.5c-15 0-28.2 6.2-37.9 15.9-35.7-24.7-83.8-40.6-137.1-42.3L293 52.3l88.2 19.8c0 21.6 17.6 39.2 39.2 39.2 22 0 39.7-18.1 39.7-39.7s-17.6-39.7-39.7-39.7c-15.4 0-28.7 9.3-35.3 22l-97.4-21.6c-4.9-1.3-9.7 2.2-11 7.1L246.3 177c-52.9 2.2-100.5 18.1-136.3 42.8-9.7-10.1-23.4-16.3-38.4-16.3-55.6 0-73.8 74.6-22.9 100.1-1.8 7.9-2.6 16.3-2.6 24.7 0 83.8 94.4 151.7 210.3 151.7 116.4 0 210.8-67.9 210.8-151.7 0-8.4-.9-17.2-3.1-25.1 49.9-25.6 31.5-99.7-23.8-99.7zM129.4 308.9c0-22 17.6-39.7 39.7-39.7 21.6 0 39.2 17.6 39.2 39.7 0 21.6-17.6 39.2-39.2 39.2-22 .1-39.7-17.6-39.7-39.2zm214.3 93.5c-36.4 36.4-139.1 36.4-175.5 0-4-3.5-4-9.7 0-13.7 3.5-3.5 9.7-3.5 13.2 0 27.8 28.5 120 29 149 0 3.5-3.5 9.7-3.5 13.2 0 4.1 4 4.1 10.2.1 13.7zm-.8-54.2c-21.6 0-39.2-17.6-39.2-39.2 0-22 17.6-39.7 39.2-39.7 22 0 39.7 17.6 39.7 39.7-.1 21.5-17.7 39.2-39.7 39.2z" fill="currentColor"&gt;
			
			
				&lt;path d="M446.7 98.6l-67.6 318.8c-5.1 22.5-18.4 28.1-37.3 17.5l-103-75.9-49.7 47.8c-5.5 5.5-10.1 10.1-20.7 10.1l7.4-104.9 190.9-172.5c8.3-7.4-1.8-11.5-12.9-4.1L117.8 284 16.2 252.2c-22.1-6.9-22.5-22.1 4.6-32.7L418.2 66.4c18.4-6.9 34.5 4.1 28.5 32.2z" fill="currentColor"&gt;
			
			
				&lt;g&gt;
					&lt;path d="M97.2800192,3.739673 L100.160021,15.3787704 C88.8306631,18.1647705 77.9879854,22.6484879 68.0000023,28.6777391 L61.8399988,18.3985363 C72.8467373,11.7537029 84.7951803,6.81153332 97.2800192,3.739673 Z M158.720055,3.739673 L155.840053,15.3787704 C167.169411,18.1647705 178.012089,22.6484879 188.000072,28.6777391 L194.200075,18.3985363 C183.180932,11.7499974 171.218739,6.80771878 158.720055,3.739673 L158.720055,3.739673 Z M18.3999736,61.8351679 C11.7546212,72.8410466 6.81206547,84.7885562 3.73996516,97.2724198 L15.3799719,100.152197 C18.1661896,88.8237238 22.6502573,77.981893 28.6799796,67.9946902 L18.3999736,61.8351679 Z M11.9999699,127.990038 C11.9961044,122.172725 12.4306685,116.363392 13.2999707,110.611385 L1.43996383,108.811525 C-0.479938607,121.525138 -0.479938607,134.454937 1.43996383,147.168551 L13.2999707,145.36869 C12.4306685,139.616684 11.9961044,133.807351 11.9999699,127.990038 L11.9999699,127.990038 Z M194.160075,237.581539 L188.000072,227.302336 C178.024494,233.327885 167.195565,237.811494 155.880053,240.601305 L158.760055,252.240403 C171.231048,249.164732 183.165742,244.222671 194.160075,237.581539 L194.160075,237.581539 Z M244.000104,127.990038 C244.00397,133.807351 243.569406,139.616684 242.700103,145.36869 L254.56011,147.168551 C256.480013,134.454937 256.480013,121.525138 254.56011,108.811525 L242.700103,110.611385 C243.569406,116.363392 244.00397,122.172725 244.000104,127.990038 Z M252.260109,158.707656 L240.620102,155.827879 C237.833884,167.156352 233.349817,177.998183 227.320094,187.985385 L237.6001,194.184905 C244.249159,183.166622 249.191823,171.205364 252.260109,158.707656 L252.260109,158.707656 Z M145.380047,242.701142 C133.858209,244.43447 122.141865,244.43447 110.620027,242.701142 L108.820026,254.560223 C121.534632,256.479975 134.465442,256.479975 147.180048,254.560223 L145.380047,242.701142 Z M221.380091,196.804701 C214.461479,206.174141 206.175877,214.452354 196.800077,221.362797 L203.920081,231.022048 C214.262958,223.418011 223.404944,214.303705 231.040097,203.984145 L221.380091,196.804701 Z M196.800077,34.6172785 C206.177345,41.5338058 214.463023,49.8188367 221.380091,59.1953726 L231.040097,51.9959309 C223.429284,41.6822474 214.31457,32.5682452 204.000081,24.9580276 L196.800077,34.6172785 Z M34.619983,59.1953726 C41.5370506,49.8188367 49.8227288,41.5338058 59.1999972,34.6172785 L51.9999931,24.9580276 C41.6855038,32.5682452 32.5707896,41.6822474 24.9599774,51.9959309 L34.619983,59.1953726 Z M237.6001,61.8351679 L227.320094,67.9946902 C233.346114,77.969489 237.830073,88.7975718 240.620102,100.1122 L252.260109,97.2324229 C249.184198,84.7624043 244.241751,72.8286423 237.6001,61.8351679 L237.6001,61.8351679 Z M110.620027,13.2989317 C122.141865,11.5656035 133.858209,11.5656035 145.380047,13.2989317 L147.180048,1.43985134 C134.465442,-0.479901112 121.534632,-0.479901112 108.820026,1.43985134 L110.620027,13.2989317 Z M40.7799866,234.201801 L15.9999722,239.981353 L21.7799756,215.203275 L10.0999688,212.463487 L4.3199655,237.241566 C3.3734444,241.28318 4.58320332,245.526897 7.51859925,248.462064 C10.4539952,251.39723 14.6980441,252.606895 18.7399738,251.660448 L43.4999881,245.980888 L40.7799866,234.201801 Z M12.5999703,201.764317 L24.279977,204.484106 L28.2799793,187.305438 C22.4496684,177.507146 18.1025197,166.899584 15.3799719,155.827879 L3.73996516,158.707656 C6.34937618,169.311891 10.3154147,179.535405 15.539972,189.125297 L12.5999703,201.764317 Z M68.6000027,227.762301 L51.4199927,231.761991 L54.1399943,243.441085 L66.7800016,240.501313 C76.3706428,245.725462 86.5949557,249.691191 97.2000192,252.300398 L100.080021,240.6613 C89.0307035,237.906432 78.4495684,233.532789 68.6800027,227.682307 L68.6000027,227.762301 Z M128.000037,23.9980665 C90.1565244,24.0177003 55.3105242,44.590631 37.01511,77.715217 C18.7196958,110.839803 19.8628631,151.287212 39.9999861,183.325747 L29.9999803,225.982439 L72.660005,215.983214 C110.077932,239.548522 158.307237,236.876754 192.892851,209.322653 C227.478464,181.768552 240.856271,135.358391 226.242944,93.6248278 C211.629616,51.8912646 172.221191,23.9617202 128.000037,23.9980665 Z" fill="currentColor"&gt;
				&lt;/g&gt;
			
			
				&lt;g&gt;
					&lt;path d="M357.1,324.5c-24.1,15.3-57.2,21.4-79.1,23.6l18.4,18.1l67,67c24.5,25.1-15.4,64.4-40.2,40.2c-16.8-17-41.4-41.6-67-67.3
						l-67,67.2c-24.8,24.2-64.7-15.5-39.9-40.2c17-17,41.4-41.6,67-67l18.1-18.1c-21.6-2.3-55.3-8-79.6-23.6
						c-28.6-18.5-41.2-29.3-30.1-51.8c6.5-12.8,24.3-23.6,48-5c0,0,31.9,25.4,83.4,25.4s83.4-25.4,83.4-25.4c23.6-18.5,41.4-7.8,48,5
						C398.3,295.1,385.7,305.9,357.1,324.5L357.1,324.5z M142,145c0-63,51.2-114,114-114s114,51,114,114c0,62.7-51.2,113.7-114,113.7
						S142,207.7,142,145L142,145z M200,145c0,30.8,25.1,56,56,56s56-25.1,56-56c0-31.1-25.1-56.2-56-56.2S200,113.9,200,145z" fill="currentColor"&gt;
				&lt;/g&gt;
			
			
				&lt;g transform="translate(0,664)"&gt;
					&lt;path d="m 1073.3513,-606.40537 h 196.278 c 179.2103,0 221.8795,42.66915 221.8795,221.8795 v 196.27799 c 0,179.2103512 -42.6692,221.879451 -221.8795,221.879451 h -196.278 c -179.21038,0 -221.87951,-42.6691298 -221.87951,-221.879451 v -196.27801 c 0,-179.21035 42.66913,-221.87946 221.87951,-221.87948 z" fill="currentColor"&gt;
					&lt;path d="m 1375.0576,-393.98425 c 2.9513,-9.7072 0,-16.85429 -14.1342,-16.85429 h -46.6693 c -11.8763,0 -17.3521,6.16927 -20.3212,12.97854 0,0 -23.7347,56.82106 -57.3544,93.74763 -10.8806,10.66728 -15.8232,14.08081 -21.7613,14.08081 -2.969,0 -7.2715,-3.39577 -7.2715,-13.12075 v -90.83194 c 0,-11.66288 -3.4491,-16.85429 -13.3341,-16.85429 h -73.3553 c -7.4138,0 -11.8763,5.40476 -11.8763,10.54286 0,11.0406 16.8188,13.60078 18.5433,44.67814 v 67.52388 c 0,14.80973 -2.7202,17.49433 -8.6583,17.49433 -15.8231,0 -54.3143,-57.08773 -77.16,-122.40705 -4.4447,-12.71185 -8.9427,-17.83214 -20.8723,-17.83214 h -46.68718 c -13.3341,0 -16.0009,6.16925 -16.0009,12.97852 0,12.12515 15.8232,72.35973 73.69318,152.02656 38.58,54.40315 92.8942,83.89819 142.3726,83.89819 29.6729,0 33.3353,-6.54262 33.3353,-17.83216 v -41.12238 c 0,-13.10297 2.809,-15.71646 12.214,-15.71646 6.9338,0 18.7922,3.41353 46.4916,29.63728 31.6463,31.09512 36.8555,45.03372 54.6698,45.03372 h 46.6694 c 13.3341,0 20.0189,-6.54262 16.1787,-19.46781 -4.2313,-12.88962 -19.3433,-31.57515 -39.38,-53.74532 -10.8807,-12.62294 -27.2016,-26.22375 -32.1441,-33.03302 -6.9338,-8.72941 -4.9603,-12.62294 0,-20.39227 0,0 56.8566,-78.68897 62.7947,-105.41058 z" fill="currentColor"&gt;
					&lt;path d="m 567.69877,-429.06912 c 3.15618,-10.38133 0,-18.0247 -15.11579,-18.0247 h -49.91013 c -12.70096,0 -18.55706,6.59763 -21.73232,13.87977 0,0 -25.38286,60.76685 -61.33724,100.25768 -11.63627,11.40806 -16.92197,15.05863 -23.27242,15.05863 -3.17519,0 -7.77644,-3.63156 -7.77644,-14.0319 v -97.13948 c 0,-12.47278 -3.68869,-18.0247 -14.26014,-18.0247 h -78.44923 c -7.92857,0 -12.70097,5.78005 -12.70097,11.27491 0,11.80736 17.98666,14.54527 19.83094,47.78071 v 72.21293 c 0,15.83815 -2.9091,18.70918 -9.25948,18.70918 -16.92197,0 -58.08598,-61.05206 -82.51817,-130.90731 -4.75337,-13.59458 -9.56381,-19.07042 -22.32175,-19.07042 h -49.92915 c -14.26014,0 -17.11213,6.59763 -17.11213,13.87977 0,12.96714 16.92197,77.38454 78.81059,162.58363 41.25909,58.18101 99.34506,89.72424 152.25931,89.72424 31.73343,0 35.65018,-6.99691 35.65018,-19.07043 v -43.978 c 0,-14.01288 3.00405,-16.80786 13.0622,-16.80786 7.41521,0 20.09716,3.65057 49.71998,31.69536 33.84387,33.25443 39.41486,48.16093 58.46622,48.16093 h 49.91026 c 14.26,0 21.40913,-6.99691 17.30216,-20.81966 -4.5252,-13.78473 -20.68653,-33.76783 -42.11468,-57.47752 -11.63621,-13.49953 -29.09043,-28.04479 -34.37631,-35.32694 -7.41508,-9.33557 -5.30458,-13.4995 0,-21.80835 0,0 60.80491,-84.15334 67.15549,-112.73048 z" fill="currentColor"&gt;
				&lt;/g&gt;
			
			&lt;path d="M309.8 480.3c-13.6 14.5-50 31.7-97.4 31.7-120.8 0-147-88.8-147-140.6v-144H17.9c-5.5 0-10-4.5-10-10v-68c0-7.2 4.5-13.6 11.3-16 62-21.8 81.5-76 84.3-117.1.8-11 6.5-16.3 16.1-16.3h70.9c5.5 0 10 4.5 10 10v115.2h83c5.5 0 10 4.4 10 9.9v81.7c0 5.5-4.5 10-10 10h-83.4V360c0 34.2 23.7 53.6 68 35.8 4.8-1.9 9-3.2 12.7-2.2 3.5.9 5.8 3.4 7.4 7.9l22 64.3c1.8 5 3.3 10.6-.4 14.5z" fill="currentColor"&gt;
			&lt;path d="M512 208L320 384H288V288H208c-61.9 0-112 50.1-112 112c0 48 32 80 32 80s-128-48-128-176c0-97.2 78.8-176 176-176H288V32h32L512 208z" fill="currentColor"&gt;
			&lt;path d="M309.8 480.3c-13.6 14.5-50 31.7-97.4 31.7-120.8 0-147-88.8-147-140.6v-144H17.9c-5.5 0-10-4.5-10-10v-68c0-7.2 4.5-13.6 11.3-16 62-21.8 81.5-76 84.3-117.1.8-11 6.5-16.3 16.1-16.3h70.9c5.5 0 10 4.5 10 10v115.2h83c5.5 0 10 4.4 10 9.9v81.7c0 5.5-4.5 10-10 10h-83.4V360c0 34.2 23.7 53.6 68 35.8 4.8-1.9 9-3.2 12.7-2.2 3.5.9 5.8 3.4 7.4 7.9l22 64.3c1.8 5 3.3 10.6-.4 14.5z" fill="currentColor"&gt;
			&lt;path d="M433 179.1c0-97.2-63.7-125.7-63.7-125.7-62.5-28.7-228.6-28.4-290.5 0 0 0-63.7 28.5-63.7 125.7 0 115.7-6.6 259.4 105.6 289.1 40.5 10.7 75.3 13 103.3 11.4 50.8-2.8 79.3-18.1 79.3-18.1l-1.7-36.9s-36.3 11.4-77.1 10.1c-40.4-1.4-83-4.4-89.6-54a102.5 102.5 0 0 1 -.9-13.9c85.6 20.9 158.7 9.1 178.8 6.7 56.1-6.7 105-41.3 111.2-72.9 9.8-49.8 9-121.5 9-121.5zm-75.1 125.2h-46.6v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.3V197c0-58.5-64-56.6-64-6.9v114.2H90.2c0-122.1-5.2-147.9 18.4-175 25.9-28.9 79.8-30.8 103.8 6.1l11.6 19.5 11.6-19.5c24.1-37.1 78.1-34.8 103.8-6.1 23.7 27.3 18.4 53 18.4 175z" fill="currentColor"&gt;
			
				&lt;path d="M331.5 235.7c2.2 .9 4.2 1.9 6.3 2.8c29.2 14.1 50.6 35.2 61.8 61.4c15.7 36.5 17.2 95.8-30.3 143.2c-36.2 36.2-80.3 52.5-142.6 53h-.3c-70.2-.5-124.1-24.1-160.4-70.2c-32.3-41-48.9-98.1-49.5-169.6V256v-.2C17 184.3 33.6 127.2 65.9 86.2C102.2 40.1 156.2 16.5 226.4 16h.3c70.3 .5 124.9 24 162.3 69.9c18.4 22.7 32 50 40.6 81.7l-40.4 10.8c-7.1-25.8-17.8-47.8-32.2-65.4c-29.2-35.8-73-54.2-130.5-54.6c-57 .5-100.1 18.8-128.2 54.4C72.1 146.1 58.5 194.3 58 256c.5 61.7 14.1 109.9 40.3 143.3c28 35.6 71.2 53.9 128.2 54.4c51.4-.4 85.4-12.6 113.7-40.9c32.3-32.2 31.7-71.8 21.4-95.9c-6.1-14.2-17.1-26-31.9-34.9c-3.7 26.9-11.8 48.3-24.7 64.8c-17.1 21.8-41.4 33.6-72.7 35.3c-23.6 1.3-46.3-4.4-63.9-16c-20.8-13.8-33-34.8-34.3-59.3c-2.5-48.3 35.7-83 95.2-86.4c21.1-1.2 40.9-.3 59.2 2.8c-2.4-14.8-7.3-26.6-14.6-35.2c-10-11.7-25.6-17.7-46.2-17.8H227c-16.6 0-39 4.6-53.3 26.3l-34.4-23.6c19.2-29.1 50.3-45.1 87.8-45.1h.8c62.6 .4 99.9 39.5 103.7 107.7l-.2 .2zm-156 68.8c1.3 25.1 28.4 36.8 54.6 35.3c25.6-1.4 54.6-11.4 59.5-73.2c-13.2-2.9-27.8-4.4-43.4-4.4c-4.8 0-9.6 .1-14.4 .4c-42.9 2.4-57.2 23.2-56.2 41.8l-.1 .1z" fill="currentColor"&gt;
			
			
				&lt;path d="M407.8 294.7c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3zM288 227.1C261.9 176.4 190.9 81.9 124.9 35.3C61.6-9.4 37.5-1.7 21.6 5.5C3.3 13.8 0 41.9 0 58.4S9.1 194 15 213.9c19.5 65.7 89.1 87.9 153.2 80.7c3.3-.5 6.6-.9 10-1.4c-3.3 .5-6.6 1-10 1.4C74.3 308.6-9.1 342.8 100.3 464.5C220.6 589.1 265.1 437.8 288 361.1c22.9 76.7 49.2 222.5 185.6 103.4c102.4-103.4 28.1-156-65.8-169.9c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3c64.1 7.1 133.6-15.1 153.2-80.7C566.9 194 576 75 576 58.4s-3.3-44.7-21.6-52.9c-15.8-7.1-40-14.9-103.2 29.8C385.1 81.9 314.1 176.4 288 227.1z" fill="currentColor"&gt;
			
			
				&lt;path d="M204 6.5C101.4 6.5 0 74.9 0 185.6 0 256 39.6 296 63.6 296c9.9 0 15.6-27.6 15.6-35.4 0-9.3-23.7-29.1-23.7-67.8 0-80.4 61.2-137.4 140.4-137.4 68.1 0 118.5 38.7 118.5 109.8 0 53.1-21.3 152.7-90.3 152.7-24.9 0-46.2-18-46.2-43.8 0-37.8 26.4-74.4 26.4-113.4 0-66.2-93.9-54.2-93.9 25.8 0 16.8 2.1 35.4 9.6 50.7-13.8 59.4-42 147.9-42 209.1 0 18.9 2.7 37.5 4.5 56.4 3.4 3.8 1.7 3.4 6.9 1.5 50.4-69 48.6-82.5 71.4-172.8 12.3 23.4 44.1 36 69.3 36 106.2 0 153.9-103.5 153.9-196.8C384 71.3 298.2 6.5 204 6.5z" fill="currentColor"&gt;
			
		&lt;/svg&gt;
		&lt;div id="has-mastodon-prompt"&gt;
			&lt;h3&gt;Share on Mastodon&lt;/h3&gt;
			
		&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/lilly-ai-factory-live/</guid><pubDate>Thu, 26 Feb 2026 19:00:58 +0000</pubDate></item><item><title>[NEW] Mistral AI inks a deal with global consulting giant Accenture (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/26/mistral-ai-inks-a-deal-with-global-consulting-giant-accenture/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/04/GettyImages-2147859992-e1713960898378.jpg?resize=1200,676" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Enterprises have struggled to find a return on investment from adopting AI tools. Now AI companies are trying a new tactic to get their tech to stick by partnering with consultants.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Thursday, French AI research lab Mistral AI and global consulting giant Accenture announced a multiyear partnership. The deal entails the two companies working together to develop enterprise tech powered by Mistral’s AI models for clients.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Financial terms and duration of the deal were not disclosed. TechCrunch reached out for more information.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This deal also includes Accenture becoming a Mistral customer and rolling out its technology to its underlying employees.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Mistral is often seen as a smaller European peer to the sprawling U.S. AI “startups,” the partnership proves that Mistral can still land the same sizable customers, given that OpenAI and Anthropic recently announced deals with Accenture as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The agreement comes as AI companies are increasingly partnering with consultants. For instance, OpenAI just announced its “Frontier Alliance” initiative with four large consulting firms, including Accenture, on Monday to help push its new OpenAI Frontier AI agent governance platform to enterprise customers. Anthropic is also partnered with IBM and Deloitte.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Will partnering with consulting firms be the trick to finding more enterprise AI adoption? It’s unclear, but what is clear is that AI companies are definitely trying to find out.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/04/GettyImages-2147859992-e1713960898378.jpg?resize=1200,676" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Enterprises have struggled to find a return on investment from adopting AI tools. Now AI companies are trying a new tactic to get their tech to stick by partnering with consultants.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Thursday, French AI research lab Mistral AI and global consulting giant Accenture announced a multiyear partnership. The deal entails the two companies working together to develop enterprise tech powered by Mistral’s AI models for clients.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Financial terms and duration of the deal were not disclosed. TechCrunch reached out for more information.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This deal also includes Accenture becoming a Mistral customer and rolling out its technology to its underlying employees.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Mistral is often seen as a smaller European peer to the sprawling U.S. AI “startups,” the partnership proves that Mistral can still land the same sizable customers, given that OpenAI and Anthropic recently announced deals with Accenture as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The agreement comes as AI companies are increasingly partnering with consultants. For instance, OpenAI just announced its “Frontier Alliance” initiative with four large consulting firms, including Accenture, on Monday to help push its new OpenAI Frontier AI agent governance platform to enterprise customers. Anthropic is also partnered with IBM and Deloitte.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Will partnering with consulting firms be the trick to finding more enterprise AI adoption? It’s unclear, but what is clear is that AI companies are definitely trying to find out.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/26/mistral-ai-inks-a-deal-with-global-consulting-giant-accenture/</guid><pubDate>Thu, 26 Feb 2026 19:17:27 +0000</pubDate></item><item><title>[NEW] Sophia Space raises $10M seed to demo novel space computers (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/26/sophia-space-raises-10m-seed-to-demo-novel-space-computers/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/Sophia-TCS40.jpeg?resize=1200,676" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As space companies itch to push the most advanced chips into orbit, the problem of cooling those high-powered processors is top of mind.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s cold in space&amp;nbsp;… [but] there’s no airflow, and so the only way to dissipate is through conduction,” Nvidia CEO Jensen Huang said when asked about space-based data centers during his firm’s most recent earnings call.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Now, Sophia Space has raised $10 million from investors, including Alpha Funds, KDDI Green Partners Fund, and Unlock Venture Partners. The company plans to prove out a new approach to passively cooling space computers on the ground, then buy a satellite bus from Apex Space and show that it works in orbit by late 2027 or early 2028.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Companies like SpaceX, Google, or Starcloud are examining traditional satellite form factors for their proposed space data center constellations, which rely on large radiators to keep chips in optimal thermal condition. But Sophia Space’s founders — CTO Leon Alkalai, CEO Rob DeMillo, and chief growth officer Brian Monnin — have a different approach.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s tech comes from an unusual source: a $100-million-endowed program at Caltech to develop orbital solar plants that would beam electricity to Earth below. The researchers ultimately settled on a sail-like structure that is thin and flexible compared to boxy, traditional satellites.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While technical and regulatory challenges make producing electricity for Earth difficult, Alkalai, a fellow at the Caltech-managed Jet Propulsion Laboratory, was struck by the idea of using the design to power space-based processors. (Aetherflux, a space solar power startup, has had a similar realization.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sophia, an Nvidia partner, has designed modular server racks with integrated solar panels it calls TILES, which are 1 meter by 1 meter in area and a few centimeters in depth. By adopting this thin form factor, DeMillo says that processors can sit against a passive heat spreader, eliminating the need for active cooling. He expects 92% of the power it generates will go to processing, a significant gain on traditional designs. This design requires, however, a sophisticated software management system to balance activity across the processors.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;By the 2030s, Sophia hopes to be building larger space data centers out of thousands of TILEs, envisioning a 50-meter-by-50-meter structure delivering 1 MW of computing power. DeMillo argues that attempting to build space data centers with less efficient systems will not be economical and that a single structure rather than a distributed network linked by lasers will be easier to execute.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;First, however, Sophia plans to begin by offering its TILEs to satellite operators that require compute solutions on orbit. Potential partners include Earth-observation satellites collecting large amounts of sensor data, missile warning and tracking systems that the Pentagon is investing billions of dollars to build, or even increasingly complex communications networks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The dirty little secret of the satellite industry is we’ve got all these amazing sensors up there that produce terabytes, or even petabytes, of data every few minutes, and they throw most of it out because they can’t do the computing on board and they can’t get round trip back and forth to the surface fast enough,” DeMillo told TechCrunch.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/Sophia-TCS40.jpeg?resize=1200,676" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As space companies itch to push the most advanced chips into orbit, the problem of cooling those high-powered processors is top of mind.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s cold in space&amp;nbsp;… [but] there’s no airflow, and so the only way to dissipate is through conduction,” Nvidia CEO Jensen Huang said when asked about space-based data centers during his firm’s most recent earnings call.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Now, Sophia Space has raised $10 million from investors, including Alpha Funds, KDDI Green Partners Fund, and Unlock Venture Partners. The company plans to prove out a new approach to passively cooling space computers on the ground, then buy a satellite bus from Apex Space and show that it works in orbit by late 2027 or early 2028.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Companies like SpaceX, Google, or Starcloud are examining traditional satellite form factors for their proposed space data center constellations, which rely on large radiators to keep chips in optimal thermal condition. But Sophia Space’s founders — CTO Leon Alkalai, CEO Rob DeMillo, and chief growth officer Brian Monnin — have a different approach.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s tech comes from an unusual source: a $100-million-endowed program at Caltech to develop orbital solar plants that would beam electricity to Earth below. The researchers ultimately settled on a sail-like structure that is thin and flexible compared to boxy, traditional satellites.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While technical and regulatory challenges make producing electricity for Earth difficult, Alkalai, a fellow at the Caltech-managed Jet Propulsion Laboratory, was struck by the idea of using the design to power space-based processors. (Aetherflux, a space solar power startup, has had a similar realization.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sophia, an Nvidia partner, has designed modular server racks with integrated solar panels it calls TILES, which are 1 meter by 1 meter in area and a few centimeters in depth. By adopting this thin form factor, DeMillo says that processors can sit against a passive heat spreader, eliminating the need for active cooling. He expects 92% of the power it generates will go to processing, a significant gain on traditional designs. This design requires, however, a sophisticated software management system to balance activity across the processors.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;By the 2030s, Sophia hopes to be building larger space data centers out of thousands of TILEs, envisioning a 50-meter-by-50-meter structure delivering 1 MW of computing power. DeMillo argues that attempting to build space data centers with less efficient systems will not be economical and that a single structure rather than a distributed network linked by lasers will be easier to execute.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;First, however, Sophia plans to begin by offering its TILEs to satellite operators that require compute solutions on orbit. Potential partners include Earth-observation satellites collecting large amounts of sensor data, missile warning and tracking systems that the Pentagon is investing billions of dollars to build, or even increasingly complex communications networks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The dirty little secret of the satellite industry is we’ve got all these amazing sensors up there that produce terabytes, or even petabytes, of data every few minutes, and they throw most of it out because they can’t do the computing on board and they can’t get round trip back and forth to the surface fast enough,” DeMillo told TechCrunch.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/26/sophia-space-raises-10m-seed-to-demo-novel-space-computers/</guid><pubDate>Thu, 26 Feb 2026 19:55:20 +0000</pubDate></item><item><title>[NEW] So, we’re getting Prada Meta AI glasses, right? (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/26/so-were-getting-prada-meta-ai-glasses-right/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/zuck-meta.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Could Meta be preparing to launch a Prada version of its Meta AI glasses? That’s the speculation after Mark Zuckerberg and his wife, Priscilla, were spotted sitting in the front row of Prada’s Fall/Winter 2026 Fashion Week show in Milan on Thursday. The social media exec was seen chatting with his seatmate, Lorenzo Bertelli, Prada’s chief merchandising officer and son of head designer Miuccia Prada.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Zuckerberg has been working to polish his image in recent years, including with upgraded threads, it’s likely that he wasn’t at Prada for the fashion, but rather because of an upcoming collaboration with the brand.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;CNBC reported last summer that Prada AI glasses were in the works, among others. However, Meta has yet to publicly announce such a deal. (The company has not yet responded to a request for comment about Zuckerberg’s presence in Milan.)&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;EssilorLuxottica, the French-Italian eyewear brand and Ray-Ban maker, has been working with Meta on these high-tech devices since their debut, initially under the Ray-Ban Stories brand. This month, the company announced it sold over 7 million AI glasses in 2025, up from 2 million in the prior year. Those sales included both Ray-Ban Meta and Oakley Meta glasses, the latter designed more for the athletic types.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now, it seems, Prada AI glasses could be next, given that Prada and EssilorLuxottica already renewed their licensing deal for eyewear under the Prada and Miu Miu brands for the next ten years. (The existing agreement, which expired on December 31, 2025, was later extended through December 31, 2030, with the provision for renewal until December 31, 2035.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Prada AI glasses could give Meta a foothold in the high-fashion market, a niche that its Oakleys and Ray-Bans don’t yet fill. Establishing the glasses as a luxury symbol could also benefit Meta’s brand overall.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, there are some concerns that AI glasses aren’t the right fit for a world that’s seeing an increased consumer backlash against surveillance devices, which have recently led people to rip out their Ring doorbells and smash Flock cameras. This shift could see Meta reconsidering whether it will add facial-recognition features to its glasses, as The New York Times recently reported. The news drew criticism for what had otherwise been a modestly successful tech product and has even prompted one developer to build an app that will warn you if someone is wearing the AI glasses near you.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/zuck-meta.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Could Meta be preparing to launch a Prada version of its Meta AI glasses? That’s the speculation after Mark Zuckerberg and his wife, Priscilla, were spotted sitting in the front row of Prada’s Fall/Winter 2026 Fashion Week show in Milan on Thursday. The social media exec was seen chatting with his seatmate, Lorenzo Bertelli, Prada’s chief merchandising officer and son of head designer Miuccia Prada.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Zuckerberg has been working to polish his image in recent years, including with upgraded threads, it’s likely that he wasn’t at Prada for the fashion, but rather because of an upcoming collaboration with the brand.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;CNBC reported last summer that Prada AI glasses were in the works, among others. However, Meta has yet to publicly announce such a deal. (The company has not yet responded to a request for comment about Zuckerberg’s presence in Milan.)&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;EssilorLuxottica, the French-Italian eyewear brand and Ray-Ban maker, has been working with Meta on these high-tech devices since their debut, initially under the Ray-Ban Stories brand. This month, the company announced it sold over 7 million AI glasses in 2025, up from 2 million in the prior year. Those sales included both Ray-Ban Meta and Oakley Meta glasses, the latter designed more for the athletic types.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now, it seems, Prada AI glasses could be next, given that Prada and EssilorLuxottica already renewed their licensing deal for eyewear under the Prada and Miu Miu brands for the next ten years. (The existing agreement, which expired on December 31, 2025, was later extended through December 31, 2030, with the provision for renewal until December 31, 2035.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Prada AI glasses could give Meta a foothold in the high-fashion market, a niche that its Oakleys and Ray-Bans don’t yet fill. Establishing the glasses as a luxury symbol could also benefit Meta’s brand overall.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, there are some concerns that AI glasses aren’t the right fit for a world that’s seeing an increased consumer backlash against surveillance devices, which have recently led people to rip out their Ring doorbells and smash Flock cameras. This shift could see Meta reconsidering whether it will add facial-recognition features to its glasses, as The New York Times recently reported. The news drew criticism for what had otherwise been a modestly successful tech product and has even prompted one developer to build an app that will warn you if someone is wearing the AI glasses near you.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/26/so-were-getting-prada-meta-ai-glasses-right/</guid><pubDate>Thu, 26 Feb 2026 20:11:55 +0000</pubDate></item><item><title>[NEW] xAI spent $7M building wall that barely muffles annoying power plant noise (AI - Ars Technica)</title><link>https://arstechnica.com/tech-policy/2026/02/pops-whines-and-roars-xai-accused-of-torturing-neighbors-of-noisy-power-plant/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        “Temu sound wall” not enough to quell fury over xAI’s power plant.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="403" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1768218692-640x403.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="644" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1768218692.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Anadolu / Contributor | Anadolu

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p style="font-weight: 400;"&gt;For miles around xAI’s makeshift power plant in Southaven, Mississippi, neighbors have endured months of constant roaring, erupting pops, and bursts of high-pitched whining from 27 temporary gas turbines installed without consulting the community.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;In a report on Thursday, NBC News interviewed residents fighting to shut down xAI’s turbines. They confirmed that xAI operates the turbines day and night, allegedly tormenting residents in order to power xAI founder Elon Musk’s unbridled AI ambitions.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;Eventually, 41 permanent gas turbines—that supposedly won’t be as noisy—will be installed, if xAI can secure the permitting. In the meantime, xAI has erected a $7 million “sound barrier” that’s supposed to mitigate some of the noise.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;However, residents told NBC News that the wall that xAI built does little to quiet the din.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;Taylor Logsdon, who lives near the power plant, said that neighbors nearby jokingly call it the “Temu sound wall,” referencing the Chinese e-commerce site known for peddling cheap, rather than high-quality goods. For Logsdon, the wall has not helped to calm her dogs, which have been unsettled by sudden booms and squeals that videos show can frequently be heard amid the turbines’ continual jet engine-like hum. Some residents are just as unsettled as the dogs, describing the noises from the plant as “scary.”&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;A nonprofit environmental advocacy group, the Safe and Sound Coalition, has been collecting evidence, hoping to raise awareness in the community to block xAI from obtaining permits for its permanent turbines. The group’s website links to videos documenting the noise, noise analysis reports, and public records showing how challenging it’s been to track xAI’s communications with public officials.&lt;/p&gt;
&lt;div&gt;&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Safe and Sound Coalition video documents constant roars after a “loud bang” signaled “something popped off.”

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;&lt;/div&gt;
&lt;p style="font-weight: 400;"&gt;For example, public records requests to the city of Southaven seeking information on xAI exemptions to noise ordinances or communications about the sound wall turned up nothing. A director overseeing the city’s planning and development claimed that the office was not “involved with the noise barrier wall” and could provide no details. Similarly, a permit clerk for the city’s building department confirmed there were no documents to share.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Asked for comment, a spokesperson for the coalition told Ars that the “absence of documentation raises transparency concerns.”&lt;/p&gt;
&lt;p&gt;“When decisions with community impact are made without accessible records, it creates an accountability gap and limits the public’s ability to understand how those decisions were evaluated or authorized,” the spokesperson said.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;An IT worker who co-founded the coalition, Jason Haley, told NBC News that xAI’s wall showed that the city could have required the company to do more to prevent noise pollution before upsetting community members.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;“If you knew the noise was going to be an issue, put in a sound wall first,” Haley said. “Do some other stuff first before you torture us. That’s not that hard of an ask.”&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;xAI did not immediately respond to Ars’ request to comment. According to NBC News, the company has yet to make public a noise analysis that it conducted.&lt;/p&gt;
&lt;h2&gt;xAI’s turbines spark other concerns&lt;/h2&gt;
&lt;p style="font-weight: 400;"&gt;xAI has maintained that it follows the law when rushing at breakneck speeds to build infrastructure to support its AI innovations. In Southaven, xAI was approved to operate the temporary gas turbines at the power plant for 12 months, without any additional permitting required.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;Now it’s seeking permits for the permanent turbines, which residents worry could be nearly as loud, while possibly introducing more smog into an area that’s mostly homes, churches, parks, and schools, the Safe and Sound Coalition’s website said.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;Pollutants could increase risks of asthma, heart attacks, stroke, and cancer, a community flyer the coalition distributed warned, urging attendance at a public meeting where residents could finally air their complaints (a meeting which NBC News’ report thoroughly documented). The flyer also suggested that the city’s main drinking water supply could be affected and perhaps tainted if the power plant’s wastewater contains toxic chemicals, since there isn’t a graywater recycling plant nearby. For residents, it’s hard to tell if things will ever get better. One noise analysis the coalition shared found that the daily sound of the turbines was higher on an “annoyance scale” than when entire neighborhoods set off New Year’s Eve fireworks.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p style="font-weight: 400;"&gt;“Our water, air, power grid, utility bills, property values, and health are all at risk,” the Safe and Sound Coalition’s website said. “We’re already facing toxic pollution and relentless industrial noise. There is no clear oversight, no transparency, and no plan to protect the people living nearby.”&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;The coalition expects that if enough community members protest the plant, the permitting agency will deny xAI’s permits and order any potentially dangerous turbines to be shut down. But other groups are taking a different approach, considering suing xAI if it continues operating the unpermitted gas turbines in Southaven.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;Earlier this month, the Southern Environmental Law Center (SELC) joined the NAACP in sending xAI a notice of intent to sue. In that letter, groups warned that the Environmental Protection Agency (EPA) recently changed a rule that they argued now requires permits for the temporary turbines. They gave xAI 60 days to respond.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;The same groups previously sent a legal threat to xAI, opposing alleged data center pollution in Memphis, Tenn. xAI eventually secured permits for some of the gas turbines sparking scrutiny there, which many locals found “devastating.” Further concerning, residents relying on drone imagery—with no other way to keep track of how many turbines xAI was running—warned that the permits only covered 15 of 24 turbines on site.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;EPA shrugs off xAI permitting concerns&lt;/h2&gt;
&lt;p style="font-weight: 400;"&gt;It’s unclear whether the SELC can win if it takes xAI to court, or whether&amp;nbsp;the EPA would ever intervene if that action could be construed as delaying Trump’s order to rush permitting and build as many data centers as fast as possible to power AI.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;The SELC declined Ars’ request to comment, but the EPA’s administrator, Lee Zeldin, seemed to negate that argument in an interview with Fox Business in January. Asked directly about xAI’s gas turbines, Zeldin confirmed that the EPA was working closely on permitting with local officials in Southaven and Shelby County—where xAI built a massive data center sparking protests.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p style="font-weight: 400;"&gt;Rather than suggesting that the EPA might be preparing to review xAI’s unpermitted gas turbines, Zeldin emphasized that for Donald Trump, it “is about getting permits done faster.”&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;“EPA has the power to slow things down; EPA also has the power to speed things up, and that’s where the Trump EPA is,” Zeldin said.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;Permitting for the Southaven project’s permanent gas turbines may be approved as soon as next month, NBC News reported.&lt;/p&gt;
&lt;h2&gt;Residents skeptical second sound barrier will be better&lt;/h2&gt;
&lt;p style="font-weight: 400;"&gt;For Southaven, xAI’s power plant—along with a planned data center, which Musk has dubbed “MACROHARDRR” to mock Microsoft—represents a chance to surge the local economy. That prospect seemingly swayed government support for the projects, which has apparently not waned in the face of mounting protests.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;When Musk bought the dormant power plant, “it was the largest private investment in state history,” Tate Reeves, Mississippi’s Republican governor, claimed. Additionally, xAI’s affiliated company that’s behind the projects, MZX Tech, donated $1.38 million to the city’s police department, NBC News reported. Both the plant and the data center “are expected to bring in millions of dollars and new jobs,” Reeves said.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;For Southaven residents, the only hope they have that the noise may die down any time soon is that construction on another sound barrier will be finished in the next two months, NBC News reported. Supposedly, engineers were taking time to study “what type of sound barrier would be most effective” amid complaints about the current sound barrier.&lt;/p&gt;
&lt;p&gt;A spokesperson for the Safe and Sound Coalition told Ars that the group remains “skeptical” that the new wall will be any better than the first sound barrier.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“To our understanding, sound barriers can reduce certain frequencies under controlled conditions, but turbine noise involves low-frequency sounds and tonal components that often reach beyond barriers,” the coalition’s spokesperson said. “The most effective method for reducing industrial noise exposure is typically distance from residential areas, which is not a mitigation option in this scenario given the facility’s proximity to homes.”&lt;/p&gt;
&lt;p&gt;The coalition urged xAI to be transparent and to share data backing mitigation claims if it wants the community to believe that the second sound barrier will make any difference.&lt;/p&gt;
&lt;p&gt;“Without transparent modeling, validated field measurements, and independent verification, it is difficult to assess whether the barrier will meaningfully address the ongoing nuisance experienced by nearby residents,” the coalition’s spokesperson said. “Mitigation claims are only meaningful if they are supported by transparent data.”&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Mayor labels protestors Musk haters&lt;/h2&gt;
&lt;p style="font-weight: 400;"&gt;At least one city official, Mayor Darren Musselwhite, has suggested that community backlash is “political.” Although he acknowledged that the noise was a “legitimate concern,” he also claimed on Facebook that some people protesting xAI’s facility were simply Elon Musk haters, NBC News reported.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;“Southaven is now under attack by all who choose to oppose Elon Musk because of his high-profile political stances,” Musselwhite wrote.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;However, residents told NBC News that “their concerns have nothing to do with politics.” One person interviewed even praised Musk’s work with the Department of Government Efficiency.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;Instead, they’re worried that local officials seeing dollar signs have potentially let xAI exploit loopholes to pollute communities without any warning. The community flyer from the Safe and Sound Coalition criticized what they viewed as shady behavior from local officials:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p style="font-weight: 400;"&gt;“This project was started behind our backs, with zero community input. Local officials have repeatedly downplayed concerns, spun the facts, and misled residents about the true impacts and the deals made with xAI. Many people only found out after the turbines were up and running.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The coalition’s spokesperson told Ars that a health impact analysis published on behalf of the SELC provides “meaningful insight” into the biggest health risks. That concluded that using the EPA’s COBRA health impact model, emissions from running 41 permanent turbines at the Southaven plant “are estimated to result in $30–$44 million per year in health-related damages, including costs from premature deaths, hospital visits, and lost productivity. Over a typical 30-year operating life, these impacts would amount to approximately $588–$862 million in cumulative discounted public-health costs, borne largely by residents of Tennessee and Mississippi.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Additionally, the largest amount of harmful pollutants increases are expected to be “concentrated in communities that are disproportionately Black, highly socially vulnerable, and have elevated baseline asthma prevalence,” the report said.&lt;/p&gt;
&lt;p&gt;If the permits are issued, the Coalition’s spokesperson told Ars that the group expects to continue gathering reports of “firsthand experiences” from nearby residents, which will “continue to provide valuable information regarding ongoing impacts.” The group plans to continue engaging with officials and pushing for greater accountability and transparent monitoring, as well as documenting noise conditions, reviewing emissions reports, and collecting independent data where feasible.&lt;/p&gt;
&lt;p&gt;“The Coalition’s focus is long-term community protection, which means tracking compliance, advocating for corrective action if standards are not met, and ensuring residents have access to accurate information about environmental and health impacts,” the spokesperson said. “Permit approval would not resolve community concerns; it would shift our focus toward ongoing oversight and enforcement.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        “Temu sound wall” not enough to quell fury over xAI’s power plant.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="403" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1768218692-640x403.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="644" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1768218692.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Anadolu / Contributor | Anadolu

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p style="font-weight: 400;"&gt;For miles around xAI’s makeshift power plant in Southaven, Mississippi, neighbors have endured months of constant roaring, erupting pops, and bursts of high-pitched whining from 27 temporary gas turbines installed without consulting the community.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;In a report on Thursday, NBC News interviewed residents fighting to shut down xAI’s turbines. They confirmed that xAI operates the turbines day and night, allegedly tormenting residents in order to power xAI founder Elon Musk’s unbridled AI ambitions.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;Eventually, 41 permanent gas turbines—that supposedly won’t be as noisy—will be installed, if xAI can secure the permitting. In the meantime, xAI has erected a $7 million “sound barrier” that’s supposed to mitigate some of the noise.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;However, residents told NBC News that the wall that xAI built does little to quiet the din.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;Taylor Logsdon, who lives near the power plant, said that neighbors nearby jokingly call it the “Temu sound wall,” referencing the Chinese e-commerce site known for peddling cheap, rather than high-quality goods. For Logsdon, the wall has not helped to calm her dogs, which have been unsettled by sudden booms and squeals that videos show can frequently be heard amid the turbines’ continual jet engine-like hum. Some residents are just as unsettled as the dogs, describing the noises from the plant as “scary.”&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;A nonprofit environmental advocacy group, the Safe and Sound Coalition, has been collecting evidence, hoping to raise awareness in the community to block xAI from obtaining permits for its permanent turbines. The group’s website links to videos documenting the noise, noise analysis reports, and public records showing how challenging it’s been to track xAI’s communications with public officials.&lt;/p&gt;
&lt;div&gt;&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Safe and Sound Coalition video documents constant roars after a “loud bang” signaled “something popped off.”

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;&lt;/div&gt;
&lt;p style="font-weight: 400;"&gt;For example, public records requests to the city of Southaven seeking information on xAI exemptions to noise ordinances or communications about the sound wall turned up nothing. A director overseeing the city’s planning and development claimed that the office was not “involved with the noise barrier wall” and could provide no details. Similarly, a permit clerk for the city’s building department confirmed there were no documents to share.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Asked for comment, a spokesperson for the coalition told Ars that the “absence of documentation raises transparency concerns.”&lt;/p&gt;
&lt;p&gt;“When decisions with community impact are made without accessible records, it creates an accountability gap and limits the public’s ability to understand how those decisions were evaluated or authorized,” the spokesperson said.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;An IT worker who co-founded the coalition, Jason Haley, told NBC News that xAI’s wall showed that the city could have required the company to do more to prevent noise pollution before upsetting community members.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;“If you knew the noise was going to be an issue, put in a sound wall first,” Haley said. “Do some other stuff first before you torture us. That’s not that hard of an ask.”&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;xAI did not immediately respond to Ars’ request to comment. According to NBC News, the company has yet to make public a noise analysis that it conducted.&lt;/p&gt;
&lt;h2&gt;xAI’s turbines spark other concerns&lt;/h2&gt;
&lt;p style="font-weight: 400;"&gt;xAI has maintained that it follows the law when rushing at breakneck speeds to build infrastructure to support its AI innovations. In Southaven, xAI was approved to operate the temporary gas turbines at the power plant for 12 months, without any additional permitting required.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;Now it’s seeking permits for the permanent turbines, which residents worry could be nearly as loud, while possibly introducing more smog into an area that’s mostly homes, churches, parks, and schools, the Safe and Sound Coalition’s website said.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;Pollutants could increase risks of asthma, heart attacks, stroke, and cancer, a community flyer the coalition distributed warned, urging attendance at a public meeting where residents could finally air their complaints (a meeting which NBC News’ report thoroughly documented). The flyer also suggested that the city’s main drinking water supply could be affected and perhaps tainted if the power plant’s wastewater contains toxic chemicals, since there isn’t a graywater recycling plant nearby. For residents, it’s hard to tell if things will ever get better. One noise analysis the coalition shared found that the daily sound of the turbines was higher on an “annoyance scale” than when entire neighborhoods set off New Year’s Eve fireworks.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p style="font-weight: 400;"&gt;“Our water, air, power grid, utility bills, property values, and health are all at risk,” the Safe and Sound Coalition’s website said. “We’re already facing toxic pollution and relentless industrial noise. There is no clear oversight, no transparency, and no plan to protect the people living nearby.”&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;The coalition expects that if enough community members protest the plant, the permitting agency will deny xAI’s permits and order any potentially dangerous turbines to be shut down. But other groups are taking a different approach, considering suing xAI if it continues operating the unpermitted gas turbines in Southaven.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;Earlier this month, the Southern Environmental Law Center (SELC) joined the NAACP in sending xAI a notice of intent to sue. In that letter, groups warned that the Environmental Protection Agency (EPA) recently changed a rule that they argued now requires permits for the temporary turbines. They gave xAI 60 days to respond.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;The same groups previously sent a legal threat to xAI, opposing alleged data center pollution in Memphis, Tenn. xAI eventually secured permits for some of the gas turbines sparking scrutiny there, which many locals found “devastating.” Further concerning, residents relying on drone imagery—with no other way to keep track of how many turbines xAI was running—warned that the permits only covered 15 of 24 turbines on site.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;EPA shrugs off xAI permitting concerns&lt;/h2&gt;
&lt;p style="font-weight: 400;"&gt;It’s unclear whether the SELC can win if it takes xAI to court, or whether&amp;nbsp;the EPA would ever intervene if that action could be construed as delaying Trump’s order to rush permitting and build as many data centers as fast as possible to power AI.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;The SELC declined Ars’ request to comment, but the EPA’s administrator, Lee Zeldin, seemed to negate that argument in an interview with Fox Business in January. Asked directly about xAI’s gas turbines, Zeldin confirmed that the EPA was working closely on permitting with local officials in Southaven and Shelby County—where xAI built a massive data center sparking protests.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p style="font-weight: 400;"&gt;Rather than suggesting that the EPA might be preparing to review xAI’s unpermitted gas turbines, Zeldin emphasized that for Donald Trump, it “is about getting permits done faster.”&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;“EPA has the power to slow things down; EPA also has the power to speed things up, and that’s where the Trump EPA is,” Zeldin said.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;Permitting for the Southaven project’s permanent gas turbines may be approved as soon as next month, NBC News reported.&lt;/p&gt;
&lt;h2&gt;Residents skeptical second sound barrier will be better&lt;/h2&gt;
&lt;p style="font-weight: 400;"&gt;For Southaven, xAI’s power plant—along with a planned data center, which Musk has dubbed “MACROHARDRR” to mock Microsoft—represents a chance to surge the local economy. That prospect seemingly swayed government support for the projects, which has apparently not waned in the face of mounting protests.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;When Musk bought the dormant power plant, “it was the largest private investment in state history,” Tate Reeves, Mississippi’s Republican governor, claimed. Additionally, xAI’s affiliated company that’s behind the projects, MZX Tech, donated $1.38 million to the city’s police department, NBC News reported. Both the plant and the data center “are expected to bring in millions of dollars and new jobs,” Reeves said.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;For Southaven residents, the only hope they have that the noise may die down any time soon is that construction on another sound barrier will be finished in the next two months, NBC News reported. Supposedly, engineers were taking time to study “what type of sound barrier would be most effective” amid complaints about the current sound barrier.&lt;/p&gt;
&lt;p&gt;A spokesperson for the Safe and Sound Coalition told Ars that the group remains “skeptical” that the new wall will be any better than the first sound barrier.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“To our understanding, sound barriers can reduce certain frequencies under controlled conditions, but turbine noise involves low-frequency sounds and tonal components that often reach beyond barriers,” the coalition’s spokesperson said. “The most effective method for reducing industrial noise exposure is typically distance from residential areas, which is not a mitigation option in this scenario given the facility’s proximity to homes.”&lt;/p&gt;
&lt;p&gt;The coalition urged xAI to be transparent and to share data backing mitigation claims if it wants the community to believe that the second sound barrier will make any difference.&lt;/p&gt;
&lt;p&gt;“Without transparent modeling, validated field measurements, and independent verification, it is difficult to assess whether the barrier will meaningfully address the ongoing nuisance experienced by nearby residents,” the coalition’s spokesperson said. “Mitigation claims are only meaningful if they are supported by transparent data.”&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Mayor labels protestors Musk haters&lt;/h2&gt;
&lt;p style="font-weight: 400;"&gt;At least one city official, Mayor Darren Musselwhite, has suggested that community backlash is “political.” Although he acknowledged that the noise was a “legitimate concern,” he also claimed on Facebook that some people protesting xAI’s facility were simply Elon Musk haters, NBC News reported.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;“Southaven is now under attack by all who choose to oppose Elon Musk because of his high-profile political stances,” Musselwhite wrote.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;However, residents told NBC News that “their concerns have nothing to do with politics.” One person interviewed even praised Musk’s work with the Department of Government Efficiency.&lt;/p&gt;
&lt;p style="font-weight: 400;"&gt;Instead, they’re worried that local officials seeing dollar signs have potentially let xAI exploit loopholes to pollute communities without any warning. The community flyer from the Safe and Sound Coalition criticized what they viewed as shady behavior from local officials:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p style="font-weight: 400;"&gt;“This project was started behind our backs, with zero community input. Local officials have repeatedly downplayed concerns, spun the facts, and misled residents about the true impacts and the deals made with xAI. Many people only found out after the turbines were up and running.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The coalition’s spokesperson told Ars that a health impact analysis published on behalf of the SELC provides “meaningful insight” into the biggest health risks. That concluded that using the EPA’s COBRA health impact model, emissions from running 41 permanent turbines at the Southaven plant “are estimated to result in $30–$44 million per year in health-related damages, including costs from premature deaths, hospital visits, and lost productivity. Over a typical 30-year operating life, these impacts would amount to approximately $588–$862 million in cumulative discounted public-health costs, borne largely by residents of Tennessee and Mississippi.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Additionally, the largest amount of harmful pollutants increases are expected to be “concentrated in communities that are disproportionately Black, highly socially vulnerable, and have elevated baseline asthma prevalence,” the report said.&lt;/p&gt;
&lt;p&gt;If the permits are issued, the Coalition’s spokesperson told Ars that the group expects to continue gathering reports of “firsthand experiences” from nearby residents, which will “continue to provide valuable information regarding ongoing impacts.” The group plans to continue engaging with officials and pushing for greater accountability and transparent monitoring, as well as documenting noise conditions, reviewing emissions reports, and collecting independent data where feasible.&lt;/p&gt;
&lt;p&gt;“The Coalition’s focus is long-term community protection, which means tracking compliance, advocating for corrective action if standards are not met, and ensuring residents have access to accurate information about environmental and health impacts,” the spokesperson said. “Permit approval would not resolve community concerns; it would shift our focus toward ongoing oversight and enforcement.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2026/02/pops-whines-and-roars-xai-accused-of-torturing-neighbors-of-noisy-power-plant/</guid><pubDate>Thu, 26 Feb 2026 22:19:39 +0000</pubDate></item><item><title>[NEW] Perplexity announces "Computer," an AI agent that assigns work to other AI agents (AI - Ars Technica)</title><link>https://arstechnica.com/ai/2026/02/perplexity-announces-computer-an-ai-agent-that-assigns-work-to-other-ai-agents/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        It’s also a buttoned-down, ostensibly safer take on the OpenClaw concept.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A logo says &amp;quot;Perplexity Computer&amp;quot; next to a shiny bubble" class="absolute inset-0 w-full h-full object-cover hidden" height="305" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Perplexity-Computer-640x305.jpg" width="640" /&gt;
                  &lt;img alt="A logo says &amp;quot;Perplexity Computer&amp;quot; next to a shiny bubble" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Perplexity-Computer-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The vague marketing image for Perplexity Computer.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Perplexity

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Perplexity has introduced “Computer,” a new tool that allows users to assign tasks and see them carried out by a system that coordinates multiple agents running various models.&lt;/p&gt;
&lt;p&gt;The company claims that Computer, currently available to Perplexity Max subscribers, is “a system that creates and executes entire workflows” and “capable of running for hours or even months.”&lt;/p&gt;
&lt;p&gt;The idea is that the user describes a specific outcome—something like “plan and execute a local digital marketing campaign for my restaurant” or “build me an Android app that helps me do a specific kind of research for my job.” Computer then ideates subtasks and assigns them to multiple agents as needed, running the models Perplexity deems best for those tasks.&lt;/p&gt;
&lt;p&gt;The core reasoning engine currently runs Anthropic’s Claude Opus 4.6, while Gemini is used for deep research, Nano Banana for image generation, Veo 3.1 for video production, Grok for lightweight tasks where speed is a consideration, and ChatGPT 5.2 for “long-context recall and wide search.”&lt;/p&gt;
&lt;p&gt;This kind of best-model-for-the-task approach differs from some competing products like Claude Cowork, which only uses Anthropic’s models.&lt;/p&gt;
&lt;p&gt;All this happens in the cloud, with prebuilt integrations. “Every task runs in an isolated compute environment with access to a real filesystem, a real browser, and real tool integrations,” Perplexity says.&lt;/p&gt;
&lt;p&gt;The idea is partly that this workflow was what some power users were already doing, and this aims to make that possible for a wider range of people who don’t want to deal with all that setup. People were already using multiple models and tailoring them to specific tasks based on perceived capabilities, while, for example, using MCP (Model Context Protocol) to give those models access to data and applications on their local machines. Perplexity Computer takes a different approach, but the goal is the same: have AI agents running tailor-picked models to perform tasks involving your own files, services, and applications.&lt;/p&gt;
&lt;p&gt;Then there is OpenClaw, which you could perceive as the immediate predecessor to this concept.&lt;/p&gt;
&lt;h2&gt;The story so far&lt;/h2&gt;
&lt;p&gt;If you haven’t been following the wild OpenClaw craze, here’s the quick summary: originally titled ClawdBot, then Moltbot, OpenClaw was an agentic AI tool that leveraged large language models to independently operate as a sort of background or ambient process on your local machine, performing a wide range of tasks from sorting through your email history to building websites to, well, basically whatever you could imagine.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Given the right permissions and with the proper plugins, it could create, modify, or delete the user’s files and otherwise change things far beyond what most users could achieve with existing models and MCP (Model Context Protocol). Users would use files like USER.MD, MEMORY.MD, SOUL.MD, or HEARTBEAT.MD to give the tool context about its goals and how to work toward them independently, sometimes running for long stretches without direct user input.&lt;/p&gt;
&lt;p&gt;On one hand, that meant it could do impressive things—the first glimpses of the sort of knowledge work that AI boosters have been saying agentic AI would ultimately do. On the other hand, it was prone to serious errors and vulnerable to prompt injection and other security problems, in part due to a Wild West of unverified plugins.&lt;/p&gt;
&lt;p&gt;The same toolkit that was used to create a viral Reddit clone populated by AI agents was also, at least in one case, responsible for deleting a user’s emails against her will.&lt;/p&gt;
&lt;h2&gt;Stay in your lane&lt;/h2&gt;
&lt;p&gt;Perplexity Computer aims to address those concerns in a few ways. First, its core process occurs in the cloud, not on the user’s local machine. Second, it lives within a walled garden with a curated list of integrations, in contrast to OpenClaw’s unregulated frontier.&lt;/p&gt;
&lt;p&gt;This is, of course, an imperfect analogy, but you could say that if OpenClaw were the open web of AI agent tools, then Computer is Apple’s App Store. While you’re more limited in what you can do, you’re not trusting packages from unverified sources with access to your system.&lt;/p&gt;
&lt;p&gt;There could still be risks, though. For one thing, LLMs make mistakes, and those could be consequential if Computer is working with data you don’t have backed up elsewhere or if you’re not verifying the outputs, for example.&lt;/p&gt;
&lt;p&gt;Perplexity Computer aims to button up, refine, and contain the wild power of the viral OpenClaw agentic AI tool—competing with the likes of Claude Cowork—by optimizing subtasks by selecting models best suited to&amp;nbsp;them.&lt;/p&gt;
&lt;p&gt;It surely won’t be the last existing AI player to try and do this sort of thing. After all, OpenAI hired OpenClaw’s developer, with CEO Sam Altman suggesting that some of what we saw in OpenClaw will be essential to the company’s product vision moving forward.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        It’s also a buttoned-down, ostensibly safer take on the OpenClaw concept.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A logo says &amp;quot;Perplexity Computer&amp;quot; next to a shiny bubble" class="absolute inset-0 w-full h-full object-cover hidden" height="305" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Perplexity-Computer-640x305.jpg" width="640" /&gt;
                  &lt;img alt="A logo says &amp;quot;Perplexity Computer&amp;quot; next to a shiny bubble" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Perplexity-Computer-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The vague marketing image for Perplexity Computer.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Perplexity

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Perplexity has introduced “Computer,” a new tool that allows users to assign tasks and see them carried out by a system that coordinates multiple agents running various models.&lt;/p&gt;
&lt;p&gt;The company claims that Computer, currently available to Perplexity Max subscribers, is “a system that creates and executes entire workflows” and “capable of running for hours or even months.”&lt;/p&gt;
&lt;p&gt;The idea is that the user describes a specific outcome—something like “plan and execute a local digital marketing campaign for my restaurant” or “build me an Android app that helps me do a specific kind of research for my job.” Computer then ideates subtasks and assigns them to multiple agents as needed, running the models Perplexity deems best for those tasks.&lt;/p&gt;
&lt;p&gt;The core reasoning engine currently runs Anthropic’s Claude Opus 4.6, while Gemini is used for deep research, Nano Banana for image generation, Veo 3.1 for video production, Grok for lightweight tasks where speed is a consideration, and ChatGPT 5.2 for “long-context recall and wide search.”&lt;/p&gt;
&lt;p&gt;This kind of best-model-for-the-task approach differs from some competing products like Claude Cowork, which only uses Anthropic’s models.&lt;/p&gt;
&lt;p&gt;All this happens in the cloud, with prebuilt integrations. “Every task runs in an isolated compute environment with access to a real filesystem, a real browser, and real tool integrations,” Perplexity says.&lt;/p&gt;
&lt;p&gt;The idea is partly that this workflow was what some power users were already doing, and this aims to make that possible for a wider range of people who don’t want to deal with all that setup. People were already using multiple models and tailoring them to specific tasks based on perceived capabilities, while, for example, using MCP (Model Context Protocol) to give those models access to data and applications on their local machines. Perplexity Computer takes a different approach, but the goal is the same: have AI agents running tailor-picked models to perform tasks involving your own files, services, and applications.&lt;/p&gt;
&lt;p&gt;Then there is OpenClaw, which you could perceive as the immediate predecessor to this concept.&lt;/p&gt;
&lt;h2&gt;The story so far&lt;/h2&gt;
&lt;p&gt;If you haven’t been following the wild OpenClaw craze, here’s the quick summary: originally titled ClawdBot, then Moltbot, OpenClaw was an agentic AI tool that leveraged large language models to independently operate as a sort of background or ambient process on your local machine, performing a wide range of tasks from sorting through your email history to building websites to, well, basically whatever you could imagine.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Given the right permissions and with the proper plugins, it could create, modify, or delete the user’s files and otherwise change things far beyond what most users could achieve with existing models and MCP (Model Context Protocol). Users would use files like USER.MD, MEMORY.MD, SOUL.MD, or HEARTBEAT.MD to give the tool context about its goals and how to work toward them independently, sometimes running for long stretches without direct user input.&lt;/p&gt;
&lt;p&gt;On one hand, that meant it could do impressive things—the first glimpses of the sort of knowledge work that AI boosters have been saying agentic AI would ultimately do. On the other hand, it was prone to serious errors and vulnerable to prompt injection and other security problems, in part due to a Wild West of unverified plugins.&lt;/p&gt;
&lt;p&gt;The same toolkit that was used to create a viral Reddit clone populated by AI agents was also, at least in one case, responsible for deleting a user’s emails against her will.&lt;/p&gt;
&lt;h2&gt;Stay in your lane&lt;/h2&gt;
&lt;p&gt;Perplexity Computer aims to address those concerns in a few ways. First, its core process occurs in the cloud, not on the user’s local machine. Second, it lives within a walled garden with a curated list of integrations, in contrast to OpenClaw’s unregulated frontier.&lt;/p&gt;
&lt;p&gt;This is, of course, an imperfect analogy, but you could say that if OpenClaw were the open web of AI agent tools, then Computer is Apple’s App Store. While you’re more limited in what you can do, you’re not trusting packages from unverified sources with access to your system.&lt;/p&gt;
&lt;p&gt;There could still be risks, though. For one thing, LLMs make mistakes, and those could be consequential if Computer is working with data you don’t have backed up elsewhere or if you’re not verifying the outputs, for example.&lt;/p&gt;
&lt;p&gt;Perplexity Computer aims to button up, refine, and contain the wild power of the viral OpenClaw agentic AI tool—competing with the likes of Claude Cowork—by optimizing subtasks by selecting models best suited to&amp;nbsp;them.&lt;/p&gt;
&lt;p&gt;It surely won’t be the last existing AI player to try and do this sort of thing. After all, OpenAI hired OpenClaw’s developer, with CEO Sam Altman suggesting that some of what we saw in OpenClaw will be essential to the company’s product vision moving forward.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2026/02/perplexity-announces-computer-an-ai-agent-that-assigns-work-to-other-ai-agents/</guid><pubDate>Thu, 26 Feb 2026 22:53:18 +0000</pubDate></item><item><title>[NEW] Anthropic CEO stands firm as Pentagon deadline looms (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/26/anthropic-ceo-stands-firm-as-pentagon-deadline-looms/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/GettyImages-2261514463.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic CEO Dario Amodei said Thursday that he “cannot in good conscience accede to [the Pentagon’s] request” to give the military unrestricted access to its AI systems.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Anthropic understands that the Department of War, not private companies, makes military decisions,” Amodei wrote in a statement. “However, in a narrow set of cases, we believe AI can undermine, rather than defend, democratic values. Some uses are also simply outside the bounds of what today’s technology can safely and reliably do.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The two cases are: mass surveillance of Americans and fully autonomous weapons with no human in the loop. The Pentagon believes it should be able to use Anthropic’s model for all lawful purposes, and that its uses shouldn’t be dictated by a private company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amodei’s statement comes less than 24 hours ahead of the Friday 5:01 p.m. deadline Defense Secretary Pete Hegseth has given Anthropic to either acquiesce to his demands, or face the consequences. The Department of Defense has attempted to force Amodei’s hand by either labeling Anthropic a supply chain risk — a designation reserved for foreign adversaries — or invoke the Defense Production Act and effectively force the firm to do its bidding. The DPA gives the president the authority to force companies to prioritize or expand production for national defense.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amodei pointed out the contradiction in those two threats. “One labels us a security risk; the other labels Claude as essential to national security.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He added that it’s the Department’s right to choose contractors most aligned with its vision, “but given the substantial value that Anthropic’s technology provides to our armed forces, we hope they reconsider.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic is currently the only frontier AI lab that has classified-ready systems for the military, though the DOD is reportedly getting xAI ready for the job. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“Our strong preference is to continue to serve the Department and our warfighters—with our two requested safeguards in place,” Amodei said. “Should the Department choose to offboard Anthropic, we will work to enable a smooth transition to another provider, avoiding any disruption to ongoing military planning, operations, or other critical missions.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TLDR, he’s saying: “We can just part ways. There’s no need to be nasty about it.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/GettyImages-2261514463.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic CEO Dario Amodei said Thursday that he “cannot in good conscience accede to [the Pentagon’s] request” to give the military unrestricted access to its AI systems.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Anthropic understands that the Department of War, not private companies, makes military decisions,” Amodei wrote in a statement. “However, in a narrow set of cases, we believe AI can undermine, rather than defend, democratic values. Some uses are also simply outside the bounds of what today’s technology can safely and reliably do.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The two cases are: mass surveillance of Americans and fully autonomous weapons with no human in the loop. The Pentagon believes it should be able to use Anthropic’s model for all lawful purposes, and that its uses shouldn’t be dictated by a private company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amodei’s statement comes less than 24 hours ahead of the Friday 5:01 p.m. deadline Defense Secretary Pete Hegseth has given Anthropic to either acquiesce to his demands, or face the consequences. The Department of Defense has attempted to force Amodei’s hand by either labeling Anthropic a supply chain risk — a designation reserved for foreign adversaries — or invoke the Defense Production Act and effectively force the firm to do its bidding. The DPA gives the president the authority to force companies to prioritize or expand production for national defense.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amodei pointed out the contradiction in those two threats. “One labels us a security risk; the other labels Claude as essential to national security.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He added that it’s the Department’s right to choose contractors most aligned with its vision, “but given the substantial value that Anthropic’s technology provides to our armed forces, we hope they reconsider.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic is currently the only frontier AI lab that has classified-ready systems for the military, though the DOD is reportedly getting xAI ready for the job. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“Our strong preference is to continue to serve the Department and our warfighters—with our two requested safeguards in place,” Amodei said. “Should the Department choose to offboard Anthropic, we will work to enable a smooth transition to another provider, avoiding any disruption to ongoing military planning, operations, or other critical missions.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TLDR, he’s saying: “We can just part ways. There’s no need to be nasty about it.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/26/anthropic-ceo-stands-firm-as-pentagon-deadline-looms/</guid><pubDate>Thu, 26 Feb 2026 23:19:06 +0000</pubDate></item><item><title>[NEW] Jack Dorsey just halved the size of Block’s employee base — and he says your company is next (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/26/jack-dorsey-block-layoffs-4000-halved-employees-your-company-is-next/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2018/09/GettyImages-1027231340.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Jack Dorsey has long been an open admirer of Elon Musk. Now, it seems, he may have been taking notes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Thursday, Dorsey announced that Block, the payments company he founded that operates Square, Cash App, and Tidal, is cutting more than 4,000 employees, nearly half its global workforce, taking it from over 10,000 workers down to just under 6,000. Investors responded enthusiastically, sending the stock up more than 24% in after-hours trading.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;It isn’t the first time a major tech company has done something of the sort. In November 2022, Musk slashed roughly 50% of Twitter’s staff in a single stroke after taking the company private, a move that rattled many in Silicon Valley and rewrote the unofficial rules for how far a CEO could go in one shot.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Dorsey was in an unusual position to watch it unfold. He’d rolled his roughly 2.4% ownership stake in Twitter into Musk’s takeover rather than taking a cash payout, making him one of the largest outside investors in what became X.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The two men have had one of tech’s stranger relationships, with warm words giving way to public shots, then back again. Dorsey championed Musk’s Twitter acquisition, then said Musk “should have walked away.” He helped launch Bluesky, the decentralized Twitter alternative, then quit its board and called X “freedom technology.” Both are also vocal Bitcoin advocates — Block and&amp;nbsp;Tesla each carry the cryptocurrency on their balance sheets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Dorsey framed Thursday’s cuts as a proactive, even empathetic, choice, and not a financial emergency. (The 4,000 people losing their jobs may see it differently.) “Repeated rounds of cuts are destructive to morale, to focus, and to the trust that customers and shareholders place in our ability to lead,” he wrote on X. He predicted that within a year, most companies will arrive at the same place. “I’d rather get there honestly and on our own terms than be forced into it reactively,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The cuts are being driven, at least officially, by AI. Block CFO Amrita Ahuja said the cuts will position the company to “move faster with smaller, highly talented teams using AI to automate more work.” &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Salesforce and Amazon are among a growing list of other companies that have made enormous staffing cuts citing the increased gains they are seeing from AI, though a Forrester Research report last month cast some doubt on how real those gains are versus the likelihood that many layoffs are financially driven.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2018/09/GettyImages-1027231340.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Jack Dorsey has long been an open admirer of Elon Musk. Now, it seems, he may have been taking notes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Thursday, Dorsey announced that Block, the payments company he founded that operates Square, Cash App, and Tidal, is cutting more than 4,000 employees, nearly half its global workforce, taking it from over 10,000 workers down to just under 6,000. Investors responded enthusiastically, sending the stock up more than 24% in after-hours trading.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;It isn’t the first time a major tech company has done something of the sort. In November 2022, Musk slashed roughly 50% of Twitter’s staff in a single stroke after taking the company private, a move that rattled many in Silicon Valley and rewrote the unofficial rules for how far a CEO could go in one shot.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Dorsey was in an unusual position to watch it unfold. He’d rolled his roughly 2.4% ownership stake in Twitter into Musk’s takeover rather than taking a cash payout, making him one of the largest outside investors in what became X.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The two men have had one of tech’s stranger relationships, with warm words giving way to public shots, then back again. Dorsey championed Musk’s Twitter acquisition, then said Musk “should have walked away.” He helped launch Bluesky, the decentralized Twitter alternative, then quit its board and called X “freedom technology.” Both are also vocal Bitcoin advocates — Block and&amp;nbsp;Tesla each carry the cryptocurrency on their balance sheets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Dorsey framed Thursday’s cuts as a proactive, even empathetic, choice, and not a financial emergency. (The 4,000 people losing their jobs may see it differently.) “Repeated rounds of cuts are destructive to morale, to focus, and to the trust that customers and shareholders place in our ability to lead,” he wrote on X. He predicted that within a year, most companies will arrive at the same place. “I’d rather get there honestly and on our own terms than be forced into it reactively,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The cuts are being driven, at least officially, by AI. Block CFO Amrita Ahuja said the cuts will position the company to “move faster with smaller, highly talented teams using AI to automate more work.” &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Salesforce and Amazon are among a growing list of other companies that have made enormous staffing cuts citing the increased gains they are seeing from AI, though a Forrester Research report last month cast some doubt on how real those gains are versus the likelihood that many layoffs are financially driven.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/26/jack-dorsey-block-layoffs-4000-halved-employees-your-company-is-next/</guid><pubDate>Thu, 26 Feb 2026 23:43:32 +0000</pubDate></item></channel></rss>