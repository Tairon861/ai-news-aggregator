<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Mon, 22 Sep 2025 18:28:16 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>New tool makes generative AI models more likely to create breakthrough materials (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/new-tool-makes-generative-ai-models-likely-create-breakthrough-materials-0922</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202509/MIT-genmaterial-01-press.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;The artificial intelligence models that turn text into images are also useful for generating new materials. Over the last few years, generative materials models from companies like Google, Microsoft, and Meta have drawn on their training data to help researchers design tens of millions of new materials.&lt;/p&gt;&lt;p&gt;But when it comes to designing materials with exotic quantum properties like superconductivity or unique magnetic states, those models struggle. That’s too bad, because humans could use the help. For example, after a decade of research into a class of materials that could revolutionize quantum computing, called quantum spin liquids, only a dozen material candidates have been identified. The bottleneck means there are fewer materials to serve as the basis for technological breakthroughs.&lt;/p&gt;&lt;p&gt;Now, MIT researchers have developed a technique that lets popular generative materials models create promising quantum materials by following specific design rules. The rules, or constraints, steer models to create materials with unique structures that give rise to quantum properties.&lt;/p&gt;&lt;p&gt;“The models from these large companies generate materials optimized for stability,” says Mingda Li, MIT’s Class of 1947 Career Development Professor. “Our perspective is that’s not usually how materials science advances. We don’t need 10 million new materials to change the world. We just need one really good material.”&lt;/p&gt;&lt;p&gt;The approach is described today in a paper published by &lt;em&gt;Nature Materials&lt;/em&gt;. The researchers applied their technique to generate millions of candidate materials consisting of geometric lattice structures associated with quantum properties. From that pool, they synthesized two actual materials with exotic magnetic traits.&lt;/p&gt;&lt;p&gt;“People in the quantum community really care about these geometric constraints, like the Kagome lattices that are two overlapping, upside-down triangles. We created materials with Kagome lattices because those materials can mimic the behavior of rare earth elements, so they are of high technical importance.” Li says.&lt;/p&gt;&lt;p&gt;Li is the senior author of the paper. His MIT co-authors include PhD students Ryotaro Okabe,&amp;nbsp;Mouyang Cheng, Abhijatmedhi Chotrattanapituk, and Denisse Cordova Carrizales; postdoc Manasi Mandal; undergraduate researchers Kiran Mak and Bowen Yu; visiting scholar Nguyen Tuan Hung; Xiang Fu ’22, PhD ’24; and professor of electrical engineering and computer science Tommi Jaakkola, who is an affiliate of the Computer Science and Artificial Intelligence Laboratory (CSAIL) and Institute for Data, Systems, and Society. Additional co-authors include Yao Wang of Emory University, Weiwei Xie of Michigan State University, YQ Cheng of Oak Ridge National Laboratory, and Robert Cava of Princeton University.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Steering models toward impact&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;A material’s properties are determined by its structure, and quantum materials are no different. Certain atomic structures are more likely to give rise to exotic quantum properties than others. For instance, square lattices can serve as a platform for high-temperature superconductors, while other shapes known as Kagome and Lieb lattices can support the creation of materials that could be useful for quantum computing.&lt;/p&gt;&lt;p&gt;To help a popular class of generative models known as a diffusion models produce materials that conform to particular geometric patterns, the researchers created SCIGEN (short for Structural Constraint Integration in GENerative model). SCIGEN is a computer code that ensures diffusion models adhere to user-defined constraints at each iterative generation step. With SCIGEN, users can give any generative AI diffusion model geometric structural rules to follow as it generates materials.&lt;/p&gt;&lt;p&gt;AI diffusion models work by sampling from their training dataset to generate structures that reflect the distribution of structures found in the dataset. SCIGEN blocks generations that don’t align with the structural rules.&lt;/p&gt;&lt;p&gt;To test SCIGEN, the researchers applied it to a popular AI materials generation model known as DiffCSP. They had the SCIGEN-equipped model generate materials with unique geometric patterns known as Archimedean lattices, which are collections of 2D lattice tilings of different polygons. Archimedean lattices can lead to a range of quantum phenomena and have been the focus of much research.&lt;/p&gt;&lt;p&gt;“Archimedean lattices give rise to quantum spin liquids and so-called flat bands, which can mimic the properties of rare earths without rare earth elements, so they are extremely important,” says Cheng, a co-corresponding author of the work. “Other Archimedean lattice materials have large pores that could be used for carbon capture and other applications, so it’s a collection of special materials. In some cases, there are no known materials with that lattice, so I think it will be really interesting to find the first material that fits in that lattice.”&lt;/p&gt;&lt;p&gt;The model generated over 10 million material candidates with Archimedean lattices. One million of those materials survived a screening for stability. Using the supercomputers in Oak Ridge National Laboratory, the researchers then took a smaller sample of 26,000 materials and ran detailed simulations to understand how the materials’ underlying atoms behaved. The researchers found magnetism in 41 percent of those structures.&lt;/p&gt;&lt;p&gt;From that subset, the researchers synthesized two previously undiscovered compounds, TiPdBi and TiPbSb, at Xie and Cava’s labs. Subsequent experiments showed the AI model’s predictions largely aligned with the actual material’s properties.&lt;/p&gt;&lt;p&gt;“We wanted to discover new materials that could have a huge potential impact by incorporating these structures that have been known to give rise to quantum properties,” says Okabe, the paper’s first author. “We already know that these materials with specific geometric patterns are interesting, so it’s natural to start with them.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Accelerating material breakthroughs&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Quantum spin liquids could unlock quantum computing by enabling stable, error-resistant qubits that serve as the basis of quantum operations. But no quantum spin liquid materials have been confirmed. Xie and Cava believe SCIGEN could accelerate the search for these materials.&lt;/p&gt;&lt;p&gt;“There’s a big search for quantum computer materials and topological superconductors, and these are all related to the geometric patterns of materials,” Xie says. “But experimental progress has been very, very slow,” Cava adds. “Many of these quantum spin liquid materials are subject to constraints: They have to be in a triangular lattice or a Kagome lattice. If the materials satisfy those constraints, the quantum researchers get excited; it’s a necessary but not sufficient condition. So, by generating many, many materials like that, it immediately gives experimentalists hundreds or thousands more candidates to play with to accelerate quantum computer materials research.”&lt;/p&gt;&lt;p&gt;“This work presents a new tool, leveraging machine learning, that can predict which materials will have specific elements in a desired geometric pattern,” says Drexel University Professor Steve May, who was not involved in the research. “This should speed up the development of previously unexplored materials for applications in next-generation electronic, magnetic, or optical technologies.”&lt;/p&gt;&lt;p&gt;The researchers stress that experimentation is still critical to assess whether AI-generated materials can be synthesized and how their actual properties compare with model predictions. Future work on SCIGEN could incorporate additional design rules into generative models, including chemical and functional constraints.&lt;/p&gt;&lt;p&gt;“People who want to change the world care about material properties more than the stability and structure of materials,” Okabe says. “With our approach, the ratio of stable materials goes down, but it opens the door to generate a whole bunch of promising materials.”&lt;/p&gt;&lt;p&gt;The work was supported, in part, by the U.S. Department of Energy, the National Energy Research Scientific Computing Center, the National Science Foundation, and Oak Ridge National Laboratory.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202509/MIT-genmaterial-01-press.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;The artificial intelligence models that turn text into images are also useful for generating new materials. Over the last few years, generative materials models from companies like Google, Microsoft, and Meta have drawn on their training data to help researchers design tens of millions of new materials.&lt;/p&gt;&lt;p&gt;But when it comes to designing materials with exotic quantum properties like superconductivity or unique magnetic states, those models struggle. That’s too bad, because humans could use the help. For example, after a decade of research into a class of materials that could revolutionize quantum computing, called quantum spin liquids, only a dozen material candidates have been identified. The bottleneck means there are fewer materials to serve as the basis for technological breakthroughs.&lt;/p&gt;&lt;p&gt;Now, MIT researchers have developed a technique that lets popular generative materials models create promising quantum materials by following specific design rules. The rules, or constraints, steer models to create materials with unique structures that give rise to quantum properties.&lt;/p&gt;&lt;p&gt;“The models from these large companies generate materials optimized for stability,” says Mingda Li, MIT’s Class of 1947 Career Development Professor. “Our perspective is that’s not usually how materials science advances. We don’t need 10 million new materials to change the world. We just need one really good material.”&lt;/p&gt;&lt;p&gt;The approach is described today in a paper published by &lt;em&gt;Nature Materials&lt;/em&gt;. The researchers applied their technique to generate millions of candidate materials consisting of geometric lattice structures associated with quantum properties. From that pool, they synthesized two actual materials with exotic magnetic traits.&lt;/p&gt;&lt;p&gt;“People in the quantum community really care about these geometric constraints, like the Kagome lattices that are two overlapping, upside-down triangles. We created materials with Kagome lattices because those materials can mimic the behavior of rare earth elements, so they are of high technical importance.” Li says.&lt;/p&gt;&lt;p&gt;Li is the senior author of the paper. His MIT co-authors include PhD students Ryotaro Okabe,&amp;nbsp;Mouyang Cheng, Abhijatmedhi Chotrattanapituk, and Denisse Cordova Carrizales; postdoc Manasi Mandal; undergraduate researchers Kiran Mak and Bowen Yu; visiting scholar Nguyen Tuan Hung; Xiang Fu ’22, PhD ’24; and professor of electrical engineering and computer science Tommi Jaakkola, who is an affiliate of the Computer Science and Artificial Intelligence Laboratory (CSAIL) and Institute for Data, Systems, and Society. Additional co-authors include Yao Wang of Emory University, Weiwei Xie of Michigan State University, YQ Cheng of Oak Ridge National Laboratory, and Robert Cava of Princeton University.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Steering models toward impact&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;A material’s properties are determined by its structure, and quantum materials are no different. Certain atomic structures are more likely to give rise to exotic quantum properties than others. For instance, square lattices can serve as a platform for high-temperature superconductors, while other shapes known as Kagome and Lieb lattices can support the creation of materials that could be useful for quantum computing.&lt;/p&gt;&lt;p&gt;To help a popular class of generative models known as a diffusion models produce materials that conform to particular geometric patterns, the researchers created SCIGEN (short for Structural Constraint Integration in GENerative model). SCIGEN is a computer code that ensures diffusion models adhere to user-defined constraints at each iterative generation step. With SCIGEN, users can give any generative AI diffusion model geometric structural rules to follow as it generates materials.&lt;/p&gt;&lt;p&gt;AI diffusion models work by sampling from their training dataset to generate structures that reflect the distribution of structures found in the dataset. SCIGEN blocks generations that don’t align with the structural rules.&lt;/p&gt;&lt;p&gt;To test SCIGEN, the researchers applied it to a popular AI materials generation model known as DiffCSP. They had the SCIGEN-equipped model generate materials with unique geometric patterns known as Archimedean lattices, which are collections of 2D lattice tilings of different polygons. Archimedean lattices can lead to a range of quantum phenomena and have been the focus of much research.&lt;/p&gt;&lt;p&gt;“Archimedean lattices give rise to quantum spin liquids and so-called flat bands, which can mimic the properties of rare earths without rare earth elements, so they are extremely important,” says Cheng, a co-corresponding author of the work. “Other Archimedean lattice materials have large pores that could be used for carbon capture and other applications, so it’s a collection of special materials. In some cases, there are no known materials with that lattice, so I think it will be really interesting to find the first material that fits in that lattice.”&lt;/p&gt;&lt;p&gt;The model generated over 10 million material candidates with Archimedean lattices. One million of those materials survived a screening for stability. Using the supercomputers in Oak Ridge National Laboratory, the researchers then took a smaller sample of 26,000 materials and ran detailed simulations to understand how the materials’ underlying atoms behaved. The researchers found magnetism in 41 percent of those structures.&lt;/p&gt;&lt;p&gt;From that subset, the researchers synthesized two previously undiscovered compounds, TiPdBi and TiPbSb, at Xie and Cava’s labs. Subsequent experiments showed the AI model’s predictions largely aligned with the actual material’s properties.&lt;/p&gt;&lt;p&gt;“We wanted to discover new materials that could have a huge potential impact by incorporating these structures that have been known to give rise to quantum properties,” says Okabe, the paper’s first author. “We already know that these materials with specific geometric patterns are interesting, so it’s natural to start with them.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Accelerating material breakthroughs&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Quantum spin liquids could unlock quantum computing by enabling stable, error-resistant qubits that serve as the basis of quantum operations. But no quantum spin liquid materials have been confirmed. Xie and Cava believe SCIGEN could accelerate the search for these materials.&lt;/p&gt;&lt;p&gt;“There’s a big search for quantum computer materials and topological superconductors, and these are all related to the geometric patterns of materials,” Xie says. “But experimental progress has been very, very slow,” Cava adds. “Many of these quantum spin liquid materials are subject to constraints: They have to be in a triangular lattice or a Kagome lattice. If the materials satisfy those constraints, the quantum researchers get excited; it’s a necessary but not sufficient condition. So, by generating many, many materials like that, it immediately gives experimentalists hundreds or thousands more candidates to play with to accelerate quantum computer materials research.”&lt;/p&gt;&lt;p&gt;“This work presents a new tool, leveraging machine learning, that can predict which materials will have specific elements in a desired geometric pattern,” says Drexel University Professor Steve May, who was not involved in the research. “This should speed up the development of previously unexplored materials for applications in next-generation electronic, magnetic, or optical technologies.”&lt;/p&gt;&lt;p&gt;The researchers stress that experimentation is still critical to assess whether AI-generated materials can be synthesized and how their actual properties compare with model predictions. Future work on SCIGEN could incorporate additional design rules into generative models, including chemical and functional constraints.&lt;/p&gt;&lt;p&gt;“People who want to change the world care about material properties more than the stability and structure of materials,” Okabe says. “With our approach, the ratio of stable materials goes down, but it opens the door to generate a whole bunch of promising materials.”&lt;/p&gt;&lt;p&gt;The work was supported, in part, by the U.S. Department of Energy, the National Energy Research Scientific Computing Center, the National Science Foundation, and Oak Ridge National Laboratory.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/new-tool-makes-generative-ai-models-likely-create-breakthrough-materials-0922</guid><pubDate>Mon, 22 Sep 2025 09:00:00 +0000</pubDate></item><item><title>This medical startup uses LLMs to run appointments and make diagnoses (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/22/1123873/medical-diagnosis-llm/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/stethoscope-ai2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Imagine this: You’ve been feeling unwell, so you call up your doctor’s office to make an appointment. To your surprise, they schedule you in for the next day. At the appointment, you aren’t rushed through describing your health concerns; instead, you have a full half hour to share your symptoms and worries and the exhaustive details of your health history with someone who listens attentively and asks thoughtful follow-up questions. You leave with a diagnosis, a treatment plan, and the sense that, for once, you’ve been able to discuss your health with the care that it merits.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The catch? You might not have spoken to a doctor, or other licensed medical practitioner, at all.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;This is the new reality for patients at a small number of clinics in Southern California that are run by the medical startup Akido Labs. These patients—some of whom are on Medicaid—can access specialist appointments on short notice, a privilege typically only afforded to the wealthy few who patronize concierge clinics.&lt;/p&gt;  &lt;p&gt;The key difference is that Akido patients spend relatively little time, or even no time at all, with their doctors. Instead, they see a medical assistant, who can lend a sympathetic ear but has limited clinical training. The job of formulating diagnoses and concocting a treatment plan is done by a proprietary, LLM-based system called ScopeAI that transcribes and analyzes the dialogue between patient and assistant. A doctor then approves, or corrects, the AI system’s recommendations.&lt;/p&gt; 
 &lt;p&gt;“Our focus is really on what we can do to pull the doctor out of the visit,” says Jared Goodner, Akido’s CTO.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;According to Prashant Samant, Akido’s CEO, this approach allows doctors to see four to five times as many patients as they could previously. There’s good reason to want doctors to be much more productive. Americans are getting older and sicker, and many struggle to access adequate health care. The pending 15% reduction in federal funding for Medicaid will only make the situation worse.&lt;/p&gt; 
 &lt;p&gt;But experts aren’t convinced that displacing so much of the cognitive work of medicine onto AI is the right way to remedy the doctor shortage. There’s a big gap in expertise between doctors and AI-enhanced medical assistants, says Emma Pierson, a computer scientist at UC Berkeley.&amp;nbsp; Jumping such a gap may introduce risks. “I am broadly excited about the potential of AI to expand access to medical expertise,” she says. “It’s just not obvious to me that this particular way is the way to do it.”&lt;/p&gt;  &lt;p&gt;AI is already everywhere in medicine. Computer vision tools identify cancers during preventive scans, automated research systems allow doctors to quickly sort through the medical literature, and LLM-powered medical scribes can take appointment notes on a clinician’s behalf. But these systems are designed to support doctors as they go about their typical medical routines.&lt;/p&gt;  &lt;p&gt;What distinguishes ScopeAI, Goodner says, is its ability to independently complete the cognitive tasks that constitute a medical visit, from eliciting a patient’s medical history to coming up with a list of potential diagnoses to identifying the most likely diagnosis and proposing appropriate next steps.&lt;/p&gt;  &lt;p&gt;Under the hood, ScopeAI is a set of large language models, each of which can perform a specific step in the visit—from generating appropriate follow-up questions based on what a patient has said to to populating a list of likely conditions. For the most part, these LLMs are fine-tuned versions of Meta’s open-access Llama models, though Goodner says that the system also makes use of Anthropic’s Claude models.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;During the appointment, assistants read off questions from the ScopeAI interface, and ScopeAI produces new questions as it analyzes what the patient says. For the doctors who will review its outputs later, ScopeAI produces a concise note that includes a summary of the patient’s visit, the most likely diagnosis, two or three alternative diagnoses, and recommended next steps, such as referrals or prescriptions. It also lists a justification for each diagnosis and recommendation.&lt;/p&gt;  &lt;p&gt;ScopeAI is currently being used in cardiology, endocrinology, and primary care clinics and by Akido’s street medicine team, which serves the Los Angeles homeless population. That team—which is led by Steven Hochman, a doctor who specializes in addiction medicine—meets patients out in the community to help them access medical care, including treatment for substance use disorders.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Previously, in order to prescribe a drug to treat an opioid addiction, Hochman would have to meet the patient in person; now, caseworkers armed with ScopeAI can interview patients on their own, and Hochman can approve or reject the system’s recommendations later. “It allows me to be in 10 places at once,” he says.&lt;/p&gt;  &lt;p&gt;Since they started using ScopeAI, the team has been able to get patients access to medications to help treat their substance use within 24 hours—something that Hochman calls “unheard of.”&lt;/p&gt; 

 &lt;p&gt;This arrangement is only possible because homeless patients typically get their health insurance from Medicaid, the public insurance system for low-income Americans. While Medicaid allows doctors to approve ScopeAI prescriptions and treatment plans asynchronously, both for street medicine and clinic visits, many other insurance providers require that doctors speak directly with patients before approving those recommendations. Pierson says that discrepancy raises concerns. “You worry about that exacerbating health disparities,” she says.&lt;/p&gt;  &lt;p&gt;Samant is aware of the appearance of inequity, and he says the discrepancy isn’t intentional—it’s just a feature of how the insurance plans currently work. He also notes that being seen quickly by an AI-enhanced medical assistant may be better than dealing with long wait times and limited provider availability, which is the status quo for Medicaid patients. And all Akido patients can opt for traditional doctor’s appointments, if they are willing to wait for them, he says.&lt;/p&gt;  &lt;p&gt;Part of the challenge of deploying a tool like ScopeAI is navigating a regulatory and insurance landscape that wasn’t designed for AI systems that can independently direct medical appointments. Glenn Cohen, a professor at Harvard Law School, says that any AI system that effectively acts as a “doctor in a box” would likely need to be approved by the FDA and could run afoul of medical licensure laws, which dictate that only doctors and other licensed professionals can practice medicine.&lt;/p&gt;  &lt;p&gt;The California Medical Practice Act says that AI can't replace a doctor’s responsibility to diagnose and treat a patient, but doctors are allowed to use AI in their work, and they don’t need to see patients in-person or in real-time before diagnosing them. Neither the FDA nor the Medical Board of California were able to say whether or not ScopeAI was on solid legal footing based only on a written description of the system.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;But Samant is confident that Akido is in compliance, as ScopeAI was intentionally designed to fall short of being a “doctor in a box.” Because the system requires a human doctor to review and approve of all of its diagnostic and treatment recommendations, he says, it doesn’t require FDA approval.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;At the clinic, this delicate balance between AI and doctor decision making happens entirely behind the scenes. Patients don’t ever see the ScopeAI interface directly—instead, they speak with a medical assistant who asks questions in the way that a doctor might in a typical appointment. That arrangement might make patients feel more comfortable. But Zeke Emanuel, a professor of medical ethics and health policy at the University of Pennsylvania who served in the Obama and Biden administrations, worries that this comfort could be obscuring from patients the extent to which an algorithm is influencing their care.&lt;/p&gt;  &lt;p&gt;Pierson agrees. “That certainly isn’t really what was traditionally meant by the human touch in medicine,” she says.&lt;/p&gt;  &lt;p&gt;DeAndre Siringoringo, a medical assistant who works at Akido’s cardiology office in Rancho Cucamonga, says that while he tells the patients he works with that an AI system will be listening to the appointment in order to gather information for their doctor, he doesn’t inform them about the specifics of how ScopeAI works, including the fact that it makes diagnostic recommendations to doctors.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Because all ScopeAI recommendations are reviewed by a doctor, that might not seem like such a big deal—it’s the doctor who makes the final diagnosis, not the AI. But it’s been widely documented that doctors using AI systems tend to go along with the system’s recommendations more often than they should, a phenomenon known as automation bias.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;At this point, it’s impossible to know whether automation bias is affecting doctors’ decisions at Akido clinics, though Pierson says it’s a risk—especially when doctors aren’t physically present for appointments. “I worry that it might predispose you to sort of nodding along in a way that you might not if you were actually in the room watching this happen,” she says.&lt;/p&gt; 
 &lt;p&gt;An Akido spokesperson says that automation bias is a valid concern for any AI tool that assists a doctor’s decision-making and that the company has made efforts to mitigate that bias. “We designed ScopeAI specifically to reduce bias by proactively countering blind spots that can influence medical decisions, which historically lean heavily on physician intuition and personal experience,” she says. “We also train physicians explicitly on how to use ScopeAI thoughtfully, so they retain accountability and avoid over-reliance.”&lt;/p&gt;  &lt;p&gt;Akido evaluates ScopeAI’s performance by testing it on historical data and monitoring how often doctors correct its recommendations; those corrections are also used to further train the underlying models. Before deploying ScopeAI in a given specialty, Akido ensures that when tested on historical data sets, the system includes the correct diagnosis in its top three recommendations at least 92% of the time.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;But Akido hasn’t undertaken more rigorous testing, such as studies that compare ScopeAI appointments with traditional in-person or telehealth appointments, in order to determine whether the system improves—or at least maintains—patient outcomes. Such a study could help indicate whether automation bias is a meaningful concern.&lt;/p&gt;  &lt;p&gt;“Making medical care cheaper and more accessible is a laudable goal,” Pierson says. “But I just think it’s important to conduct strong evaluations comparing to that baseline.”&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/stethoscope-ai2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Imagine this: You’ve been feeling unwell, so you call up your doctor’s office to make an appointment. To your surprise, they schedule you in for the next day. At the appointment, you aren’t rushed through describing your health concerns; instead, you have a full half hour to share your symptoms and worries and the exhaustive details of your health history with someone who listens attentively and asks thoughtful follow-up questions. You leave with a diagnosis, a treatment plan, and the sense that, for once, you’ve been able to discuss your health with the care that it merits.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The catch? You might not have spoken to a doctor, or other licensed medical practitioner, at all.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;This is the new reality for patients at a small number of clinics in Southern California that are run by the medical startup Akido Labs. These patients—some of whom are on Medicaid—can access specialist appointments on short notice, a privilege typically only afforded to the wealthy few who patronize concierge clinics.&lt;/p&gt;  &lt;p&gt;The key difference is that Akido patients spend relatively little time, or even no time at all, with their doctors. Instead, they see a medical assistant, who can lend a sympathetic ear but has limited clinical training. The job of formulating diagnoses and concocting a treatment plan is done by a proprietary, LLM-based system called ScopeAI that transcribes and analyzes the dialogue between patient and assistant. A doctor then approves, or corrects, the AI system’s recommendations.&lt;/p&gt; 
 &lt;p&gt;“Our focus is really on what we can do to pull the doctor out of the visit,” says Jared Goodner, Akido’s CTO.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;According to Prashant Samant, Akido’s CEO, this approach allows doctors to see four to five times as many patients as they could previously. There’s good reason to want doctors to be much more productive. Americans are getting older and sicker, and many struggle to access adequate health care. The pending 15% reduction in federal funding for Medicaid will only make the situation worse.&lt;/p&gt; 
 &lt;p&gt;But experts aren’t convinced that displacing so much of the cognitive work of medicine onto AI is the right way to remedy the doctor shortage. There’s a big gap in expertise between doctors and AI-enhanced medical assistants, says Emma Pierson, a computer scientist at UC Berkeley.&amp;nbsp; Jumping such a gap may introduce risks. “I am broadly excited about the potential of AI to expand access to medical expertise,” she says. “It’s just not obvious to me that this particular way is the way to do it.”&lt;/p&gt;  &lt;p&gt;AI is already everywhere in medicine. Computer vision tools identify cancers during preventive scans, automated research systems allow doctors to quickly sort through the medical literature, and LLM-powered medical scribes can take appointment notes on a clinician’s behalf. But these systems are designed to support doctors as they go about their typical medical routines.&lt;/p&gt;  &lt;p&gt;What distinguishes ScopeAI, Goodner says, is its ability to independently complete the cognitive tasks that constitute a medical visit, from eliciting a patient’s medical history to coming up with a list of potential diagnoses to identifying the most likely diagnosis and proposing appropriate next steps.&lt;/p&gt;  &lt;p&gt;Under the hood, ScopeAI is a set of large language models, each of which can perform a specific step in the visit—from generating appropriate follow-up questions based on what a patient has said to to populating a list of likely conditions. For the most part, these LLMs are fine-tuned versions of Meta’s open-access Llama models, though Goodner says that the system also makes use of Anthropic’s Claude models.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;During the appointment, assistants read off questions from the ScopeAI interface, and ScopeAI produces new questions as it analyzes what the patient says. For the doctors who will review its outputs later, ScopeAI produces a concise note that includes a summary of the patient’s visit, the most likely diagnosis, two or three alternative diagnoses, and recommended next steps, such as referrals or prescriptions. It also lists a justification for each diagnosis and recommendation.&lt;/p&gt;  &lt;p&gt;ScopeAI is currently being used in cardiology, endocrinology, and primary care clinics and by Akido’s street medicine team, which serves the Los Angeles homeless population. That team—which is led by Steven Hochman, a doctor who specializes in addiction medicine—meets patients out in the community to help them access medical care, including treatment for substance use disorders.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Previously, in order to prescribe a drug to treat an opioid addiction, Hochman would have to meet the patient in person; now, caseworkers armed with ScopeAI can interview patients on their own, and Hochman can approve or reject the system’s recommendations later. “It allows me to be in 10 places at once,” he says.&lt;/p&gt;  &lt;p&gt;Since they started using ScopeAI, the team has been able to get patients access to medications to help treat their substance use within 24 hours—something that Hochman calls “unheard of.”&lt;/p&gt; 

 &lt;p&gt;This arrangement is only possible because homeless patients typically get their health insurance from Medicaid, the public insurance system for low-income Americans. While Medicaid allows doctors to approve ScopeAI prescriptions and treatment plans asynchronously, both for street medicine and clinic visits, many other insurance providers require that doctors speak directly with patients before approving those recommendations. Pierson says that discrepancy raises concerns. “You worry about that exacerbating health disparities,” she says.&lt;/p&gt;  &lt;p&gt;Samant is aware of the appearance of inequity, and he says the discrepancy isn’t intentional—it’s just a feature of how the insurance plans currently work. He also notes that being seen quickly by an AI-enhanced medical assistant may be better than dealing with long wait times and limited provider availability, which is the status quo for Medicaid patients. And all Akido patients can opt for traditional doctor’s appointments, if they are willing to wait for them, he says.&lt;/p&gt;  &lt;p&gt;Part of the challenge of deploying a tool like ScopeAI is navigating a regulatory and insurance landscape that wasn’t designed for AI systems that can independently direct medical appointments. Glenn Cohen, a professor at Harvard Law School, says that any AI system that effectively acts as a “doctor in a box” would likely need to be approved by the FDA and could run afoul of medical licensure laws, which dictate that only doctors and other licensed professionals can practice medicine.&lt;/p&gt;  &lt;p&gt;The California Medical Practice Act says that AI can't replace a doctor’s responsibility to diagnose and treat a patient, but doctors are allowed to use AI in their work, and they don’t need to see patients in-person or in real-time before diagnosing them. Neither the FDA nor the Medical Board of California were able to say whether or not ScopeAI was on solid legal footing based only on a written description of the system.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;But Samant is confident that Akido is in compliance, as ScopeAI was intentionally designed to fall short of being a “doctor in a box.” Because the system requires a human doctor to review and approve of all of its diagnostic and treatment recommendations, he says, it doesn’t require FDA approval.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;At the clinic, this delicate balance between AI and doctor decision making happens entirely behind the scenes. Patients don’t ever see the ScopeAI interface directly—instead, they speak with a medical assistant who asks questions in the way that a doctor might in a typical appointment. That arrangement might make patients feel more comfortable. But Zeke Emanuel, a professor of medical ethics and health policy at the University of Pennsylvania who served in the Obama and Biden administrations, worries that this comfort could be obscuring from patients the extent to which an algorithm is influencing their care.&lt;/p&gt;  &lt;p&gt;Pierson agrees. “That certainly isn’t really what was traditionally meant by the human touch in medicine,” she says.&lt;/p&gt;  &lt;p&gt;DeAndre Siringoringo, a medical assistant who works at Akido’s cardiology office in Rancho Cucamonga, says that while he tells the patients he works with that an AI system will be listening to the appointment in order to gather information for their doctor, he doesn’t inform them about the specifics of how ScopeAI works, including the fact that it makes diagnostic recommendations to doctors.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Because all ScopeAI recommendations are reviewed by a doctor, that might not seem like such a big deal—it’s the doctor who makes the final diagnosis, not the AI. But it’s been widely documented that doctors using AI systems tend to go along with the system’s recommendations more often than they should, a phenomenon known as automation bias.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;At this point, it’s impossible to know whether automation bias is affecting doctors’ decisions at Akido clinics, though Pierson says it’s a risk—especially when doctors aren’t physically present for appointments. “I worry that it might predispose you to sort of nodding along in a way that you might not if you were actually in the room watching this happen,” she says.&lt;/p&gt; 
 &lt;p&gt;An Akido spokesperson says that automation bias is a valid concern for any AI tool that assists a doctor’s decision-making and that the company has made efforts to mitigate that bias. “We designed ScopeAI specifically to reduce bias by proactively countering blind spots that can influence medical decisions, which historically lean heavily on physician intuition and personal experience,” she says. “We also train physicians explicitly on how to use ScopeAI thoughtfully, so they retain accountability and avoid over-reliance.”&lt;/p&gt;  &lt;p&gt;Akido evaluates ScopeAI’s performance by testing it on historical data and monitoring how often doctors correct its recommendations; those corrections are also used to further train the underlying models. Before deploying ScopeAI in a given specialty, Akido ensures that when tested on historical data sets, the system includes the correct diagnosis in its top three recommendations at least 92% of the time.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;But Akido hasn’t undertaken more rigorous testing, such as studies that compare ScopeAI appointments with traditional in-person or telehealth appointments, in order to determine whether the system improves—or at least maintains—patient outcomes. Such a study could help indicate whether automation bias is a meaningful concern.&lt;/p&gt;  &lt;p&gt;“Making medical care cheaper and more accessible is a laudable goal,” Pierson says. “But I just think it’s important to conduct strong evaluations comparing to that baseline.”&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/22/1123873/medical-diagnosis-llm/</guid><pubDate>Mon, 22 Sep 2025 09:10:47 +0000</pubDate></item><item><title>An oil and gas giant signed a $1 billion deal with Commonwealth Fusion Systems (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/22/1123870/commonwealth-fusion-eni/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/CFS-ARC-Facility-Aerial-illustration.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Eni, one of the world’s largest oil and gas companies, just agreed to buy $1 billion in electricity from a power plant being built by Commonwealth Fusion Systems. The deal is the latest to illustrate just how much investment Commonwealth and other fusion companies are courting as they attempt to take fusion power from the lab to the power grid.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;“This is showing in concrete terms that people that use large amounts of energy, that know the energy market—they want fusion power, and they’re willing to contract for it and to pay for it,” said Bob Mumgaard, cofounder and CEO of Commonwealth, on a press call about the deal.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;The agreement will see Eni purchase electricity from Commonwealth’s first commercial fusion power plant, in Virginia. The facility is still in the planning stages but is scheduled to come online in the early 2030s.&lt;/p&gt;  &lt;p&gt;The news comes a few weeks after Commonwealth announced a $863 million funding round, bringing its total funding raised to date to nearly $3 billion. The fusion company also announced earlier this year that Google would be its first commercial power customer for the Virginia plant.&lt;/p&gt; 
 &lt;p&gt;Commonwealth, a spinout from MIT’s Plasma Science and Fusion Center, is widely considered one of the leading companies in fusion power. Investment in the company represents nearly one-third of the total global investment in private fusion companies. (&lt;em&gt;MIT Technology Review&lt;/em&gt; is owned by MIT but is editorially independent.)&lt;/p&gt;  &lt;p&gt;Eni has invested in Commonwealth since 2018 and participated in the latest fundraising round. The vast majority of the company’s business is in oil and gas, but in recent years it’s made investments in technologies like biofuels and renewables.&lt;/p&gt; 
 &lt;p&gt;“A company like us—we cannot stay and wait for things to happen,” says Lorenzo Fiorillo, Eni’s director of technology, research and development, and digital.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;One open question is what, exactly, Eni plans to do with this electricity. When asked about it on the press call, Fiorillo referenced wind and solar plants that Eni owns and said the plan “is not different from what we do in other areas in the US and the world.” (Eni sells electricity from power plants that it owns, including renewable and fossil-fuel plants.)&lt;/p&gt;  &lt;p&gt;Commonwealth is building tokamak fusion reactors that use superconducting magnets to hold plasma in place. That plasma is where fusion reactions happen, forcing hydrogen atoms together to release large amounts of energy.&lt;/p&gt;  &lt;p&gt;The company’s first demonstration reactor, which it calls Sparc, is over 65% complete, and the team is testing components and assembling them. The plan is for the reactor, which is located outside Boston, to make plasma within two years and then demonstrate that it can generate more energy than is required to run it.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;While Sparc is still under construction, Commonwealth is working on plans for Arc, its first commercial power plant. That facility should begin construction in 2027 or 2028 and generate electricity for the grid in the early 2030s, Mumgaard says.&lt;/p&gt;  &lt;p&gt;Despite the billions of dollars Commonwealth has already raised, the company still needs more money to build its Arc power plant—that will be a multibillion-dollar project, Mumgaard said on a press call in August about the company’s latest fundraising round.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The latest commitment from Eni could help Commonwealth secure the funding it needs to get Arc built. “These agreements are a really good way to create the right environment for building up more investment,” says Paul Wilson, chair of the department of nuclear engineering and engineering physics at the University of Wisconsin, Madison.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;Even though commercial fusion energy is still years away at a minimum, investors and big tech companies have pumped money into the industry and signed agreements to buy power from plants once they’re operational.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;Helion, another leading fusion startup, has plans to produce electricity from its first reactor in 2028 (an aggressive timeline that has some experts expressing skepticism). That facility will have a full generating capacity of 50 megawatts, and in 2023 Microsoft signed an agreement to purchase energy from the facility in order to help power its data centers.&lt;/p&gt;  &lt;p&gt;As billions of dollars pour into the fusion industry, there are still many milestones ahead. To date, only the National Ignition Facility at Lawrence Livermore National Laboratory has demonstrated that a fusion reactor can generate more energy than the amount put into the reaction. No commercial project has achieved that yet.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“There’s a lot of capital going out now to these startup companies,” says Ed Morse, a professor of nuclear engineering at the University of California, Berkeley. “What I’m not seeing is a peer-reviewed scientific article that makes me feel like, boy, we really turned the corner with the physics.”&lt;/p&gt;  &lt;p&gt;But others are taking major commercial deals from Commonwealth and others as reasons to be optimistic. “Fusion is moving from the lab to be a proper industry,” says Sehila Gonzalez de Vicente, global director of fusion energy at the nonprofit Clean Air Task Force. “This is very good for the whole sector to be perceived as a real source of energy.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/CFS-ARC-Facility-Aerial-illustration.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Eni, one of the world’s largest oil and gas companies, just agreed to buy $1 billion in electricity from a power plant being built by Commonwealth Fusion Systems. The deal is the latest to illustrate just how much investment Commonwealth and other fusion companies are courting as they attempt to take fusion power from the lab to the power grid.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;“This is showing in concrete terms that people that use large amounts of energy, that know the energy market—they want fusion power, and they’re willing to contract for it and to pay for it,” said Bob Mumgaard, cofounder and CEO of Commonwealth, on a press call about the deal.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;The agreement will see Eni purchase electricity from Commonwealth’s first commercial fusion power plant, in Virginia. The facility is still in the planning stages but is scheduled to come online in the early 2030s.&lt;/p&gt;  &lt;p&gt;The news comes a few weeks after Commonwealth announced a $863 million funding round, bringing its total funding raised to date to nearly $3 billion. The fusion company also announced earlier this year that Google would be its first commercial power customer for the Virginia plant.&lt;/p&gt; 
 &lt;p&gt;Commonwealth, a spinout from MIT’s Plasma Science and Fusion Center, is widely considered one of the leading companies in fusion power. Investment in the company represents nearly one-third of the total global investment in private fusion companies. (&lt;em&gt;MIT Technology Review&lt;/em&gt; is owned by MIT but is editorially independent.)&lt;/p&gt;  &lt;p&gt;Eni has invested in Commonwealth since 2018 and participated in the latest fundraising round. The vast majority of the company’s business is in oil and gas, but in recent years it’s made investments in technologies like biofuels and renewables.&lt;/p&gt; 
 &lt;p&gt;“A company like us—we cannot stay and wait for things to happen,” says Lorenzo Fiorillo, Eni’s director of technology, research and development, and digital.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;One open question is what, exactly, Eni plans to do with this electricity. When asked about it on the press call, Fiorillo referenced wind and solar plants that Eni owns and said the plan “is not different from what we do in other areas in the US and the world.” (Eni sells electricity from power plants that it owns, including renewable and fossil-fuel plants.)&lt;/p&gt;  &lt;p&gt;Commonwealth is building tokamak fusion reactors that use superconducting magnets to hold plasma in place. That plasma is where fusion reactions happen, forcing hydrogen atoms together to release large amounts of energy.&lt;/p&gt;  &lt;p&gt;The company’s first demonstration reactor, which it calls Sparc, is over 65% complete, and the team is testing components and assembling them. The plan is for the reactor, which is located outside Boston, to make plasma within two years and then demonstrate that it can generate more energy than is required to run it.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;While Sparc is still under construction, Commonwealth is working on plans for Arc, its first commercial power plant. That facility should begin construction in 2027 or 2028 and generate electricity for the grid in the early 2030s, Mumgaard says.&lt;/p&gt;  &lt;p&gt;Despite the billions of dollars Commonwealth has already raised, the company still needs more money to build its Arc power plant—that will be a multibillion-dollar project, Mumgaard said on a press call in August about the company’s latest fundraising round.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The latest commitment from Eni could help Commonwealth secure the funding it needs to get Arc built. “These agreements are a really good way to create the right environment for building up more investment,” says Paul Wilson, chair of the department of nuclear engineering and engineering physics at the University of Wisconsin, Madison.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;Even though commercial fusion energy is still years away at a minimum, investors and big tech companies have pumped money into the industry and signed agreements to buy power from plants once they’re operational.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;Helion, another leading fusion startup, has plans to produce electricity from its first reactor in 2028 (an aggressive timeline that has some experts expressing skepticism). That facility will have a full generating capacity of 50 megawatts, and in 2023 Microsoft signed an agreement to purchase energy from the facility in order to help power its data centers.&lt;/p&gt;  &lt;p&gt;As billions of dollars pour into the fusion industry, there are still many milestones ahead. To date, only the National Ignition Facility at Lawrence Livermore National Laboratory has demonstrated that a fusion reactor can generate more energy than the amount put into the reaction. No commercial project has achieved that yet.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“There’s a lot of capital going out now to these startup companies,” says Ed Morse, a professor of nuclear engineering at the University of California, Berkeley. “What I’m not seeing is a peer-reviewed scientific article that makes me feel like, boy, we really turned the corner with the physics.”&lt;/p&gt;  &lt;p&gt;But others are taking major commercial deals from Commonwealth and others as reasons to be optimistic. “Fusion is moving from the lab to be a proper industry,” says Sehila Gonzalez de Vicente, global director of fusion energy at the nonprofit Clean Air Task Force. “This is very good for the whole sector to be perceived as a real source of energy.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/22/1123870/commonwealth-fusion-eni/</guid><pubDate>Mon, 22 Sep 2025 11:00:00 +0000</pubDate></item><item><title>How BMC can be the ‘orchestrator of orchestrators’ for enterprise agentic AI (AI News)</title><link>https://www.artificialintelligence-news.com/news/how-bmc-can-be-the-orchestrator-of-orchestrators-for-enterprise-agentic-ai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/09/Untitled-design-62-1024x573.png" /&gt;&lt;/div&gt;&lt;p&gt;Agentic AI is, in the opinion of McKinsey, the way to ‘break out of the gen AI paradox.’ &amp;nbsp;Nearly four in five companies are using generative AI, according to the consultancy giant’s research, but comparatively few are getting any bottom-line value from it.&lt;/p&gt;&lt;p&gt;The answer to the question of value, therefore, may be in orchestration. As a CIO.com article from July postulates, some experts see the orchestration function as ‘the point when agents become agentic.’&lt;/p&gt;&lt;p&gt;This is where BMC sees an opportunity with its Control-M platform, which enables organisations to automate the scheduling and processing of business workflows across various platforms and applications from a single point of control. Last month BMC was named as a leader in Gartner’s Magic Quadrant for service orchestration and automation platforms.&lt;/p&gt;&lt;p&gt;BMC sees Control-M, in the words of director of solutions marketing Basil Faruqui, as the ‘orchestrator of orchestrators’, connecting multiple tools together. Faruqui predicts that, potentially within 12 months to two years, this orchestration will move from applications and APIs to agents.&lt;/p&gt;&lt;p&gt;Salesforce, for example, has Agentforce, which it calls a ‘digital labour platform’, enabling companies visibility and control in scaling AI agents; and for Faruqui, that is where the puck is going. “Whether it’s a data warehouse, whether it’s a CRM like Salesforce or SAP, all of these things will be automating their functions using agentic AI,” he says. “[The orchestrator’s role] is going to change; it’s going to be automating and connecting agents across systems.&lt;/p&gt;&lt;p&gt;“That’s really where we see our future in this ‘agent economy’, so to speak,” adds Faruqui. “We see Control-M playing the role of, really, being the orchestrator of agents across systems.”&lt;/p&gt;&lt;p&gt;Faruqui notes a recent meeting with the CTO of a major healthcare organisation, processing north of $10 billion each month in claims, in which they said initial testing of gen AI and LLMs was ‘transformative’. Applying gen AI to claims processing could cut down time of operations in ‘orders of magnitude.’ But as Faruqui puts it, technology for an enterprise is only producing value once it’s running in production – and operational and governance challenges remain a principal barrier. Orchestration therefore helps bridge the gap.&lt;/p&gt;&lt;p&gt;Another positive Faruqui, who is speaking at AI &amp;amp; Big Data Expo Europe later this month, notes is the breadth and depth of investment in this space. “[For] sponsorship, a lot of these projects are not at the CIO or CTO level. It’s really coming from the board,” he says. “We’re actually seeing, in some cases, that companies are starting to report on the progress of their AI initiatives in their letter to the shareholders.&lt;/p&gt;&lt;p&gt;“This is going to move fast, which means that, from the vendor side we have to be ready, not in three years, [but] six months,” says Faruqui. “And we in BMC, we are working through a very bold vision where we see this agent economy really taking off; and really, orchestration is the vehicle for business outcomes.”&lt;/p&gt;&lt;p&gt;&lt;em&gt;Watch the full conversation with Basil&lt;/em&gt;:&lt;/p&gt;&lt;figure class="wp-block-video"&gt;&lt;/figure&gt;&lt;p&gt;&lt;em&gt;Basil Faruqui is speaking at the &lt;/em&gt;&lt;em&gt;AI &amp;amp; Big Data Expo Europe&lt;/em&gt;&lt;em&gt;, in Amsterdam on September 24-25, on the panel session ‘Building Robust Pipelines-Best Practices for Scalability and Efficiency’. &lt;/em&gt;&lt;em&gt;Register your place today&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/09/Untitled-design-62-1024x573.png" /&gt;&lt;/div&gt;&lt;p&gt;Agentic AI is, in the opinion of McKinsey, the way to ‘break out of the gen AI paradox.’ &amp;nbsp;Nearly four in five companies are using generative AI, according to the consultancy giant’s research, but comparatively few are getting any bottom-line value from it.&lt;/p&gt;&lt;p&gt;The answer to the question of value, therefore, may be in orchestration. As a CIO.com article from July postulates, some experts see the orchestration function as ‘the point when agents become agentic.’&lt;/p&gt;&lt;p&gt;This is where BMC sees an opportunity with its Control-M platform, which enables organisations to automate the scheduling and processing of business workflows across various platforms and applications from a single point of control. Last month BMC was named as a leader in Gartner’s Magic Quadrant for service orchestration and automation platforms.&lt;/p&gt;&lt;p&gt;BMC sees Control-M, in the words of director of solutions marketing Basil Faruqui, as the ‘orchestrator of orchestrators’, connecting multiple tools together. Faruqui predicts that, potentially within 12 months to two years, this orchestration will move from applications and APIs to agents.&lt;/p&gt;&lt;p&gt;Salesforce, for example, has Agentforce, which it calls a ‘digital labour platform’, enabling companies visibility and control in scaling AI agents; and for Faruqui, that is where the puck is going. “Whether it’s a data warehouse, whether it’s a CRM like Salesforce or SAP, all of these things will be automating their functions using agentic AI,” he says. “[The orchestrator’s role] is going to change; it’s going to be automating and connecting agents across systems.&lt;/p&gt;&lt;p&gt;“That’s really where we see our future in this ‘agent economy’, so to speak,” adds Faruqui. “We see Control-M playing the role of, really, being the orchestrator of agents across systems.”&lt;/p&gt;&lt;p&gt;Faruqui notes a recent meeting with the CTO of a major healthcare organisation, processing north of $10 billion each month in claims, in which they said initial testing of gen AI and LLMs was ‘transformative’. Applying gen AI to claims processing could cut down time of operations in ‘orders of magnitude.’ But as Faruqui puts it, technology for an enterprise is only producing value once it’s running in production – and operational and governance challenges remain a principal barrier. Orchestration therefore helps bridge the gap.&lt;/p&gt;&lt;p&gt;Another positive Faruqui, who is speaking at AI &amp;amp; Big Data Expo Europe later this month, notes is the breadth and depth of investment in this space. “[For] sponsorship, a lot of these projects are not at the CIO or CTO level. It’s really coming from the board,” he says. “We’re actually seeing, in some cases, that companies are starting to report on the progress of their AI initiatives in their letter to the shareholders.&lt;/p&gt;&lt;p&gt;“This is going to move fast, which means that, from the vendor side we have to be ready, not in three years, [but] six months,” says Faruqui. “And we in BMC, we are working through a very bold vision where we see this agent economy really taking off; and really, orchestration is the vehicle for business outcomes.”&lt;/p&gt;&lt;p&gt;&lt;em&gt;Watch the full conversation with Basil&lt;/em&gt;:&lt;/p&gt;&lt;figure class="wp-block-video"&gt;&lt;/figure&gt;&lt;p&gt;&lt;em&gt;Basil Faruqui is speaking at the &lt;/em&gt;&lt;em&gt;AI &amp;amp; Big Data Expo Europe&lt;/em&gt;&lt;em&gt;, in Amsterdam on September 24-25, on the panel session ‘Building Robust Pipelines-Best Practices for Scalability and Efficiency’. &lt;/em&gt;&lt;em&gt;Register your place today&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/how-bmc-can-be-the-orchestrator-of-orchestrators-for-enterprise-agentic-ai/</guid><pubDate>Mon, 22 Sep 2025 11:00:45 +0000</pubDate></item><item><title>The Download: the LLM will see you now, and a new fusion power deal (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/22/1123889/the-download-the-llm-will-see-you-now-and-a-new-fusion-power-deal/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;This medical startup uses LLMs to run appointments and make diagnoses&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Patients at a small number of clinics in Southern California run by the medical startup Akido Labs are spending relatively little time, or even no time at all, with their doctors. Instead, they see a medical assistant, who can lend a sympathetic ear but has limited clinical training.&lt;/p&gt;&lt;p&gt;The job of formulating diagnoses and concocting a treatment plan is done by an LLM-based system called ScopeAI that transcribes and analyzes the dialogue between patient and assistant. A doctor then approves, or corrects, the AI system’s recommendations.&lt;/p&gt;&lt;p&gt;According to Akido’s CEO, this approach allows doctors to see four to five times as many patients as they could previously. But experts aren’t convinced that displacing so much of the cognitive work of medicine onto AI is the right way to remedy the doctor shortage. Read the full story.&lt;/p&gt;&lt;p&gt;&lt;em&gt;—Grace Huckins&lt;/em&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;An oil and gas giant signed a $1 billion deal with Commonwealth Fusion Systems&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Eni, one of the world’s largest oil and gas companies, just agreed to buy $1 billion in electricity from a power plant being built by Commonwealth Fusion Systems. The deal is the latest to illustrate just how much investment Commonwealth and other fusion companies are courting as they attempt to take fusion power from the lab to the power grid.&lt;/p&gt;&lt;p&gt;The agreement will see Eni purchase electricity from Commonwealth’s first commercial fusion power plant, in Virginia. The facility is still in the planning stages but is scheduled to come online in the early 2030s. Read the full story.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Casey Crownhart&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;strong&gt;1 Trump officials are expected to link Tylenol to autism&lt;/strong&gt;&lt;br /&gt;They’re also likely to tout a lesser-known drug called leucovorin as a potential treatment. (WP $)&lt;br /&gt;+ &lt;em&gt;They’ll warn women in the early stages of pregnancy that they should only take Tylenol to treat high fevers. &lt;/em&gt;(Politico)&lt;br /&gt;+ &lt;em&gt;But a huge study found no connection last year. &lt;/em&gt;(Axios)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 Trump wants to charge skilled foreign workers $100,000 for H-1B visas&lt;/strong&gt;&lt;br /&gt;The decision is highly likely to harm US growth, especially in its tech sector. (The Guardian)&lt;br /&gt;+ &lt;em&gt;The visa has been a lifeline for hundreds of thousands of tech workers. &lt;/em&gt;(BBC)&lt;br /&gt;+ &lt;em&gt;Indian outsourcing companies are struggling to pivot. &lt;/em&gt;(Bloomberg $)&lt;br /&gt;+ &lt;em&gt;Tech firms are sending memos to their workers on the visa. &lt;/em&gt;(Insider $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 The European Commission wants to ax cookie consent banners&lt;/strong&gt;&lt;br /&gt;A 2009 law triggered an influx in pesky pop-ups that the EU now wants to get rid of. (Politico)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 The Murdochs and Michael Dell are among TikTok’s potential buyers&lt;/strong&gt;&lt;br /&gt;The media mogul family and Dell founder are interested in shares, Trump says. (CNN)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;5 Inside China’s plan to put its data centers to work&lt;/strong&gt;&lt;br /&gt;A mega-cluster of centers is springing up in the city of Wuhu. (FT $)&lt;br /&gt;+ &lt;em&gt;China built hundreds of AI data centers to catch the AI boom. Now many stand unused. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 Seattle’s tech scene is in trouble&lt;br /&gt;&lt;/strong&gt;When its biggest firms slash their workforces, where does that leave everyone else? (WSJ $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Innocent people are being scammed into scamming&lt;br /&gt;&lt;/strong&gt;Chinese gangs are imprisoning trafficking victims in compounds on the Myanmar-Thai border. (Reuters)&lt;br /&gt;+ &lt;em&gt;Inside a romance scam compound—and how people get tricked into being there. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 Europe’s reusable rocket dream isn’t entirely dead&lt;br /&gt;&lt;/strong&gt;But progress has been a lot slower than it should be. (Ars Technica)&lt;br /&gt;+ &lt;em&gt;Elon Musk’s utter dominance of space tech is hard to overestimate. &lt;/em&gt;(Wired $)&lt;br /&gt;+ &lt;em&gt;Europe is finally getting serious about commercial rockets. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;9 How ChatGPT fares as a financial stock picker&lt;/strong&gt;&lt;br /&gt;Be prepared to roll the dice. (Fast Company $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 Silicon Valley is ditching dating apps&lt;/strong&gt;&lt;br /&gt;And turning to elite matchmakers instead. (The Information $)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
 &lt;p class="has-large-font-size"&gt;&lt;strong&gt;"I didn't sleep all night. I kept thinking: What if I get stuck outside the US?"&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Akaash Hazarika, a Salesforce engineer, tells Insider he was forced to cut his vacation to Toronto short and rush back to America after the Trump administration announced changes to the H-1B skilled foreign worker visa.&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1123890" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/image_3df930.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;The quest to figure out farming on Mars&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Once upon a time, water flowed across the surface of Mars. Waves lapped against shorelines, strong winds gusted and howled, and driving rain fell from thick, cloudy skies. It wasn’t really so different from our own planet 4 billion years ago, except for one crucial detail—its size. Mars is about half the diameter of Earth, and that’s where things went wrong.&lt;/p&gt;&lt;p&gt;The Martian core cooled quickly, soon leaving the planet without a magnetic field. This, in turn, left it vulnerable to the solar wind, which swept away much of its atmosphere. Without a critical shield from the sun’s ultraviolet rays, Mars could not retain its heat. Some of the oceans evaporated, and the subsurface absorbed the rest, with only a bit of water left behind and frozen at its poles. If ever a blade of grass grew on Mars, those days are over.&lt;/p&gt;&lt;p&gt;But could they begin again? And what would it take to grow plants to feed future astronauts on Mars? Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—David W. Brown&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+&amp;nbsp; These abandoned blogs are a relic of the bygone internet (bring them back!)&lt;br /&gt;+ How to strengthen your bond with your reluctant cat 😾&lt;br /&gt;+ How &lt;em&gt;Metal Gear Solid&lt;/em&gt; inspired the video to one of the greatest hits of the late 90s.&lt;br /&gt;+ If I had to explain British culture to someone, I’d just send them this video.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;This medical startup uses LLMs to run appointments and make diagnoses&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Patients at a small number of clinics in Southern California run by the medical startup Akido Labs are spending relatively little time, or even no time at all, with their doctors. Instead, they see a medical assistant, who can lend a sympathetic ear but has limited clinical training.&lt;/p&gt;&lt;p&gt;The job of formulating diagnoses and concocting a treatment plan is done by an LLM-based system called ScopeAI that transcribes and analyzes the dialogue between patient and assistant. A doctor then approves, or corrects, the AI system’s recommendations.&lt;/p&gt;&lt;p&gt;According to Akido’s CEO, this approach allows doctors to see four to five times as many patients as they could previously. But experts aren’t convinced that displacing so much of the cognitive work of medicine onto AI is the right way to remedy the doctor shortage. Read the full story.&lt;/p&gt;&lt;p&gt;&lt;em&gt;—Grace Huckins&lt;/em&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;An oil and gas giant signed a $1 billion deal with Commonwealth Fusion Systems&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Eni, one of the world’s largest oil and gas companies, just agreed to buy $1 billion in electricity from a power plant being built by Commonwealth Fusion Systems. The deal is the latest to illustrate just how much investment Commonwealth and other fusion companies are courting as they attempt to take fusion power from the lab to the power grid.&lt;/p&gt;&lt;p&gt;The agreement will see Eni purchase electricity from Commonwealth’s first commercial fusion power plant, in Virginia. The facility is still in the planning stages but is scheduled to come online in the early 2030s. Read the full story.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Casey Crownhart&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;strong&gt;1 Trump officials are expected to link Tylenol to autism&lt;/strong&gt;&lt;br /&gt;They’re also likely to tout a lesser-known drug called leucovorin as a potential treatment. (WP $)&lt;br /&gt;+ &lt;em&gt;They’ll warn women in the early stages of pregnancy that they should only take Tylenol to treat high fevers. &lt;/em&gt;(Politico)&lt;br /&gt;+ &lt;em&gt;But a huge study found no connection last year. &lt;/em&gt;(Axios)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 Trump wants to charge skilled foreign workers $100,000 for H-1B visas&lt;/strong&gt;&lt;br /&gt;The decision is highly likely to harm US growth, especially in its tech sector. (The Guardian)&lt;br /&gt;+ &lt;em&gt;The visa has been a lifeline for hundreds of thousands of tech workers. &lt;/em&gt;(BBC)&lt;br /&gt;+ &lt;em&gt;Indian outsourcing companies are struggling to pivot. &lt;/em&gt;(Bloomberg $)&lt;br /&gt;+ &lt;em&gt;Tech firms are sending memos to their workers on the visa. &lt;/em&gt;(Insider $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 The European Commission wants to ax cookie consent banners&lt;/strong&gt;&lt;br /&gt;A 2009 law triggered an influx in pesky pop-ups that the EU now wants to get rid of. (Politico)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 The Murdochs and Michael Dell are among TikTok’s potential buyers&lt;/strong&gt;&lt;br /&gt;The media mogul family and Dell founder are interested in shares, Trump says. (CNN)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;5 Inside China’s plan to put its data centers to work&lt;/strong&gt;&lt;br /&gt;A mega-cluster of centers is springing up in the city of Wuhu. (FT $)&lt;br /&gt;+ &lt;em&gt;China built hundreds of AI data centers to catch the AI boom. Now many stand unused. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 Seattle’s tech scene is in trouble&lt;br /&gt;&lt;/strong&gt;When its biggest firms slash their workforces, where does that leave everyone else? (WSJ $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Innocent people are being scammed into scamming&lt;br /&gt;&lt;/strong&gt;Chinese gangs are imprisoning trafficking victims in compounds on the Myanmar-Thai border. (Reuters)&lt;br /&gt;+ &lt;em&gt;Inside a romance scam compound—and how people get tricked into being there. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 Europe’s reusable rocket dream isn’t entirely dead&lt;br /&gt;&lt;/strong&gt;But progress has been a lot slower than it should be. (Ars Technica)&lt;br /&gt;+ &lt;em&gt;Elon Musk’s utter dominance of space tech is hard to overestimate. &lt;/em&gt;(Wired $)&lt;br /&gt;+ &lt;em&gt;Europe is finally getting serious about commercial rockets. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;9 How ChatGPT fares as a financial stock picker&lt;/strong&gt;&lt;br /&gt;Be prepared to roll the dice. (Fast Company $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 Silicon Valley is ditching dating apps&lt;/strong&gt;&lt;br /&gt;And turning to elite matchmakers instead. (The Information $)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
 &lt;p class="has-large-font-size"&gt;&lt;strong&gt;"I didn't sleep all night. I kept thinking: What if I get stuck outside the US?"&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Akaash Hazarika, a Salesforce engineer, tells Insider he was forced to cut his vacation to Toronto short and rush back to America after the Trump administration announced changes to the H-1B skilled foreign worker visa.&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1123890" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/image_3df930.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;The quest to figure out farming on Mars&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Once upon a time, water flowed across the surface of Mars. Waves lapped against shorelines, strong winds gusted and howled, and driving rain fell from thick, cloudy skies. It wasn’t really so different from our own planet 4 billion years ago, except for one crucial detail—its size. Mars is about half the diameter of Earth, and that’s where things went wrong.&lt;/p&gt;&lt;p&gt;The Martian core cooled quickly, soon leaving the planet without a magnetic field. This, in turn, left it vulnerable to the solar wind, which swept away much of its atmosphere. Without a critical shield from the sun’s ultraviolet rays, Mars could not retain its heat. Some of the oceans evaporated, and the subsurface absorbed the rest, with only a bit of water left behind and frozen at its poles. If ever a blade of grass grew on Mars, those days are over.&lt;/p&gt;&lt;p&gt;But could they begin again? And what would it take to grow plants to feed future astronauts on Mars? Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—David W. Brown&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+&amp;nbsp; These abandoned blogs are a relic of the bygone internet (bring them back!)&lt;br /&gt;+ How to strengthen your bond with your reluctant cat 😾&lt;br /&gt;+ How &lt;em&gt;Metal Gear Solid&lt;/em&gt; inspired the video to one of the greatest hits of the late 90s.&lt;br /&gt;+ If I had to explain British culture to someone, I’d just send them this video.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/22/1123889/the-download-the-llm-will-see-you-now-and-a-new-fusion-power-deal/</guid><pubDate>Mon, 22 Sep 2025 12:10:00 +0000</pubDate></item><item><title>[NEW] Strengthening our Frontier Safety Framework (Google DeepMind Blog)</title><link>https://deepmind.google/discover/blog/strengthening-our-frontier-safety-framework/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://lh3.googleusercontent.com/5BoA_b7WmI3cAdTSdL3SSSZozPhYRLwrs8JZtimXQmhUD7jmT8LKHQHSaz8QYb-d-nBxHFVY-Z5iJnmXdvwTDLDzBZDO0n4BHCvawaD44S5BY-9SDA=w1200-h630-n-nu" /&gt;&lt;/div&gt;&lt;p class="gdm-rich-text__subtitle"&gt;We’re expanding our risk domains and refining our risk assessment process.&lt;/p&gt;&lt;p&gt;AI breakthroughs are transforming our everyday lives, from advancing mathematics, biology and astronomy to realizing the potential of personalized education. As we build increasingly powerful AI models, we’re committed to responsibly developing our technologies and taking an evidence-based approach to staying ahead of emerging risks.&lt;/p&gt;&lt;p&gt;Today, we’re publishing the third iteration of our Frontier Safety Framework (FSF) — our most comprehensive approach yet to identifying and mitigating severe risks from advanced AI models.&lt;/p&gt;&lt;p&gt;This update builds upon our ongoing collaborations with experts across industry, academia and government. We’ve also incorporated lessons learned from implementing previous versions and evolving best practices in frontier AI safety.&lt;/p&gt;&lt;h2&gt;Key updates to the Framework&lt;/h2&gt;&lt;h4&gt;Addressing the risks of harmful manipulation&lt;/h4&gt;&lt;p&gt;With this update, we’re introducing a Critical Capability Level (CCL)* focused on harmful manipulation — specifically, AI models with powerful manipulative capabilities that could be misused to systematically and substantially change beliefs and behaviors in identified high stakes contexts over the course of interactions with the model, reasonably resulting in additional expected harm at severe scale.&lt;/p&gt;&lt;p&gt;This addition builds on and operationalizes research we’ve done to identify and evaluate mechanisms that drive manipulation from generative AI. Going forward, we'll continue to invest in this domain to better understand and measure the risks associated with harmful manipulation.&lt;/p&gt;&lt;h4&gt;Adapting our approach to misalignment risks&lt;/h4&gt;&lt;p&gt;We’ve also expanded our Framework to address potential future scenarios where misaligned AI models might interfere with operators’ ability to direct, modify or shut down their operations.&lt;/p&gt;&lt;p&gt;While our previous version of the Framework included an exploratory approach centered on instrumental reasoning CCLs (i.e., warning levels specific to when an AI model starts to think deceptively), with this update we now provide further protocols for our machine learning research and development CCLs focused on models that could accelerate AI research and development to potentially destabilizing levels.&lt;/p&gt;&lt;p&gt;In addition to the misuse risks arising from these capabilities, there are also misalignment risks stemming from a model’s potential for undirected action at these capability levels, and the likely integration of such models into AI development and deployment processes.&lt;/p&gt;&lt;p&gt;To address risks posed by CCLs, we conduct safety case reviews prior to external launches when relevant CCLs are reached. This involves performing detailed analyses demonstrating how risks have been reduced to manageable levels. For advanced machine learning research and development CCLs, large-scale internal deployments can also pose risk, so we are now expanding this approach to include such deployments.&lt;/p&gt;&lt;h4&gt;Sharpening our risk assessment process&lt;/h4&gt;&lt;p&gt;Our Framework is designed to address risks in proportion to their severity. We’ve sharpened our CCL definitions specifically to identify the critical threats that warrant the most rigorous governance and mitigation strategies. We continue to apply safety and security mitigations before specific CCL thresholds are reached and as part of our standard model development approach.&lt;/p&gt;&lt;p&gt;Lastly, in this update, we go into more detail about our risk assessment process. Building on our core early-warning evaluations, we describe how we conduct holistic assessments that include systematic risk identification, comprehensive analyses of model capabilities and explicit determinations of risk acceptability.&lt;/p&gt;&lt;h2&gt;Advancing our commitment to frontier safety&lt;/h2&gt;&lt;p&gt;This latest update to our Frontier Safety Framework represents our continued commitment to taking a scientific and evidence-based approach to tracking and staying ahead of AI risks as capabilities advance toward AGI. By expanding our risk domains and strengthening our risk assessment processes, we aim to ensure that transformative AI benefits humanity, while minimizing potential harms.&lt;/p&gt;&lt;p&gt;Our Framework will continue evolving based on new research, stakeholder input and lessons from implementation. We remain committed to working collaboratively across industry, academia and government.&lt;/p&gt;&lt;p&gt;The path to beneficial AGI requires not just technical breakthroughs, but also robust frameworks to mitigate risks along the way. We hope that our updated Frontier Safety Framework contributes meaningfully to this collective effort.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://lh3.googleusercontent.com/5BoA_b7WmI3cAdTSdL3SSSZozPhYRLwrs8JZtimXQmhUD7jmT8LKHQHSaz8QYb-d-nBxHFVY-Z5iJnmXdvwTDLDzBZDO0n4BHCvawaD44S5BY-9SDA=w1200-h630-n-nu" /&gt;&lt;/div&gt;&lt;p class="gdm-rich-text__subtitle"&gt;We’re expanding our risk domains and refining our risk assessment process.&lt;/p&gt;&lt;p&gt;AI breakthroughs are transforming our everyday lives, from advancing mathematics, biology and astronomy to realizing the potential of personalized education. As we build increasingly powerful AI models, we’re committed to responsibly developing our technologies and taking an evidence-based approach to staying ahead of emerging risks.&lt;/p&gt;&lt;p&gt;Today, we’re publishing the third iteration of our Frontier Safety Framework (FSF) — our most comprehensive approach yet to identifying and mitigating severe risks from advanced AI models.&lt;/p&gt;&lt;p&gt;This update builds upon our ongoing collaborations with experts across industry, academia and government. We’ve also incorporated lessons learned from implementing previous versions and evolving best practices in frontier AI safety.&lt;/p&gt;&lt;h2&gt;Key updates to the Framework&lt;/h2&gt;&lt;h4&gt;Addressing the risks of harmful manipulation&lt;/h4&gt;&lt;p&gt;With this update, we’re introducing a Critical Capability Level (CCL)* focused on harmful manipulation — specifically, AI models with powerful manipulative capabilities that could be misused to systematically and substantially change beliefs and behaviors in identified high stakes contexts over the course of interactions with the model, reasonably resulting in additional expected harm at severe scale.&lt;/p&gt;&lt;p&gt;This addition builds on and operationalizes research we’ve done to identify and evaluate mechanisms that drive manipulation from generative AI. Going forward, we'll continue to invest in this domain to better understand and measure the risks associated with harmful manipulation.&lt;/p&gt;&lt;h4&gt;Adapting our approach to misalignment risks&lt;/h4&gt;&lt;p&gt;We’ve also expanded our Framework to address potential future scenarios where misaligned AI models might interfere with operators’ ability to direct, modify or shut down their operations.&lt;/p&gt;&lt;p&gt;While our previous version of the Framework included an exploratory approach centered on instrumental reasoning CCLs (i.e., warning levels specific to when an AI model starts to think deceptively), with this update we now provide further protocols for our machine learning research and development CCLs focused on models that could accelerate AI research and development to potentially destabilizing levels.&lt;/p&gt;&lt;p&gt;In addition to the misuse risks arising from these capabilities, there are also misalignment risks stemming from a model’s potential for undirected action at these capability levels, and the likely integration of such models into AI development and deployment processes.&lt;/p&gt;&lt;p&gt;To address risks posed by CCLs, we conduct safety case reviews prior to external launches when relevant CCLs are reached. This involves performing detailed analyses demonstrating how risks have been reduced to manageable levels. For advanced machine learning research and development CCLs, large-scale internal deployments can also pose risk, so we are now expanding this approach to include such deployments.&lt;/p&gt;&lt;h4&gt;Sharpening our risk assessment process&lt;/h4&gt;&lt;p&gt;Our Framework is designed to address risks in proportion to their severity. We’ve sharpened our CCL definitions specifically to identify the critical threats that warrant the most rigorous governance and mitigation strategies. We continue to apply safety and security mitigations before specific CCL thresholds are reached and as part of our standard model development approach.&lt;/p&gt;&lt;p&gt;Lastly, in this update, we go into more detail about our risk assessment process. Building on our core early-warning evaluations, we describe how we conduct holistic assessments that include systematic risk identification, comprehensive analyses of model capabilities and explicit determinations of risk acceptability.&lt;/p&gt;&lt;h2&gt;Advancing our commitment to frontier safety&lt;/h2&gt;&lt;p&gt;This latest update to our Frontier Safety Framework represents our continued commitment to taking a scientific and evidence-based approach to tracking and staying ahead of AI risks as capabilities advance toward AGI. By expanding our risk domains and strengthening our risk assessment processes, we aim to ensure that transformative AI benefits humanity, while minimizing potential harms.&lt;/p&gt;&lt;p&gt;Our Framework will continue evolving based on new research, stakeholder input and lessons from implementation. We remain committed to working collaboratively across industry, academia and government.&lt;/p&gt;&lt;p&gt;The path to beneficial AGI requires not just technical breakthroughs, but also robust frameworks to mitigate risks along the way. We hope that our updated Frontier Safety Framework contributes meaningfully to this collective effort.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://deepmind.google/discover/blog/strengthening-our-frontier-safety-framework/</guid><pubDate>Mon, 22 Sep 2025 13:09:37 +0000</pubDate></item><item><title>[NEW] 5 days left to save up to $668 on your TechCrunch Disrupt 2025 pass (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/22/5-days-left-to-save-up-to-668-on-your-techcrunch-disrupt-2025-pass-dont-pay-more-for-the-same-seat/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;There’s still time — but just barely. Register for&lt;strong&gt; &lt;/strong&gt;&lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; by September 26 and &lt;strong&gt;save up to $668&lt;/strong&gt; before Regular Bird pricing disappears.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Disrupt 2025&lt;/strong&gt; gives you an exclusive look at tomorrow’s tech. &lt;strong&gt;Founders&lt;/strong&gt; can connect with the right investors and partners to scale their startups. &lt;strong&gt;Investors&lt;/strong&gt; can discover their next portfolio company. Tech innovators and visionaries can glimpse the future of technology while building the connections that help them grow. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With &lt;strong&gt;10,000 tech and VC leaders&lt;/strong&gt; in one place, you’re bound to find the insights and relationships you need. Join us for the 20th anniversary of TechCrunch, &lt;strong&gt;October 27–29&lt;/strong&gt;, at San Francisco’s Moscone West. &lt;strong&gt;Register now to pocket big savings&lt;/strong&gt; before this week ends.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 5 days left" class="wp-image-3010128" height="383" src="https://techcrunch.com/wp-content/uploads/2025/05/TC25_5Days-16X9-Dark.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-at-disrupt-2025-you-ll"&gt;At Disrupt 2025, you’ll:&lt;/h2&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Box CEO Aaron Levie on stage at TechCrunch Disrupt in San Francisco in 2019." class="wp-image-2833981" height="454" src="https://techcrunch.com/wp-content/uploads/2024/08/GettyImages-1178603809.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Steve Jennings / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Connect with thousands&lt;/strong&gt; of founders, investors, and operators. Discover your next startup investment, find the right investor to scale, or meet the key operators shaping the tech landscape. From curated meetings to impromptu encounters in the Expo Hall, or a spontaneous introduction at the investor/founder-exclusive Deal Flow Cafe — there’s no better place to forge the connections that help you grow.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt 2024 networking student" class="wp-image-2896237" height="453" src="https://techcrunch.com/wp-content/uploads/2024/10/Networking_disrupt.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch / TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Explore what’s next across all five industry stages&lt;/strong&gt; over three full days. Eyeballing an IPO? Head to the &lt;strong&gt;Going Public Stage&lt;/strong&gt;. Thinking of launching, or already launched? The &lt;strong&gt;Builders Stage&lt;/strong&gt; offers three days of programming packed with tactical insights to help founders at every stage scale faster. Scaling an AI startup, or just fascinated by AI? Don’t miss two full days at the &lt;strong&gt;AI Stage&lt;/strong&gt;. Curious about space tech? The &lt;strong&gt;Space Stage&lt;/strong&gt; delivers a full day of orbital insights. And on the &lt;strong&gt;Disrupt Stage&lt;/strong&gt;, hear from some of the biggest names in today’s tech.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt AI Stage" class="wp-image-3048038" height="454" src="https://techcrunch.com/wp-content/uploads/2025/09/Disrupt-2025-AI-Stage.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Slava Blazer Photography&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Experience the intense Startup Battlefield 200&lt;/strong&gt; pitch competition, where the top 20 TechCrunch-vetted early-stage startups pitch on the Disrupt Stage for a $100,000 prize. Hear seasoned VCs give feedback on what makes a winning pitch, and what it takes to build a viable startup.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Salva Health Co-Founder &amp;amp; CEO Valentina Agudelo Vargas, winner of the Startup Battlefield 2024, poses onstage during TechCrunch Disrupt 2024 Day 3 at Moscone Center on October 30, 2024 in San Francisco." class="wp-image-2913234" height="453" src="https://techcrunch.com/wp-content/uploads/2024/11/54105085427_2cae9d0502_o.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kimberly White / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-2331246" height="356" src="https://techcrunch.com/wp-content/uploads/2022/06/roundtable_1200x628.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Witness the future of tech with 100+ startups&lt;/strong&gt; showcasing in the bustling Expo Hall and throughout the venue. Meet brands pushing innovation to the forefront of the tech ecosystem, and try hands-on demos of their cutting-edge products. &lt;strong&gt;Want your brand in the spotlight for all three days?&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt Expo Hall" class="wp-image-2571166" height="383" src="https://techcrunch.com/wp-content/uploads/2023/07/expo_hall.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Eric Slomonson, The Photo Group&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-september-26-is-the-last-day-for-ticket-savings"&gt;September 26 is the last day for ticket savings&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;You have until &lt;strong&gt;September 26&lt;/strong&gt; at 11:59 p.m. to &lt;strong&gt;secure up to $668 in ticket savings&lt;/strong&gt;. Whether you’re a founder looking to scale or prepare for an IPO, a tech innovator seeking a firsthand look at tomorrow’s tech, or an investor hunting for the next big opportunity, don’t miss Disrupt 2025. &lt;strong&gt;Register your pass now.&lt;/strong&gt;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;There’s still time — but just barely. Register for&lt;strong&gt; &lt;/strong&gt;&lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; by September 26 and &lt;strong&gt;save up to $668&lt;/strong&gt; before Regular Bird pricing disappears.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Disrupt 2025&lt;/strong&gt; gives you an exclusive look at tomorrow’s tech. &lt;strong&gt;Founders&lt;/strong&gt; can connect with the right investors and partners to scale their startups. &lt;strong&gt;Investors&lt;/strong&gt; can discover their next portfolio company. Tech innovators and visionaries can glimpse the future of technology while building the connections that help them grow. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With &lt;strong&gt;10,000 tech and VC leaders&lt;/strong&gt; in one place, you’re bound to find the insights and relationships you need. Join us for the 20th anniversary of TechCrunch, &lt;strong&gt;October 27–29&lt;/strong&gt;, at San Francisco’s Moscone West. &lt;strong&gt;Register now to pocket big savings&lt;/strong&gt; before this week ends.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 5 days left" class="wp-image-3010128" height="383" src="https://techcrunch.com/wp-content/uploads/2025/05/TC25_5Days-16X9-Dark.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-at-disrupt-2025-you-ll"&gt;At Disrupt 2025, you’ll:&lt;/h2&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Box CEO Aaron Levie on stage at TechCrunch Disrupt in San Francisco in 2019." class="wp-image-2833981" height="454" src="https://techcrunch.com/wp-content/uploads/2024/08/GettyImages-1178603809.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Steve Jennings / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Connect with thousands&lt;/strong&gt; of founders, investors, and operators. Discover your next startup investment, find the right investor to scale, or meet the key operators shaping the tech landscape. From curated meetings to impromptu encounters in the Expo Hall, or a spontaneous introduction at the investor/founder-exclusive Deal Flow Cafe — there’s no better place to forge the connections that help you grow.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt 2024 networking student" class="wp-image-2896237" height="453" src="https://techcrunch.com/wp-content/uploads/2024/10/Networking_disrupt.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch / TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Explore what’s next across all five industry stages&lt;/strong&gt; over three full days. Eyeballing an IPO? Head to the &lt;strong&gt;Going Public Stage&lt;/strong&gt;. Thinking of launching, or already launched? The &lt;strong&gt;Builders Stage&lt;/strong&gt; offers three days of programming packed with tactical insights to help founders at every stage scale faster. Scaling an AI startup, or just fascinated by AI? Don’t miss two full days at the &lt;strong&gt;AI Stage&lt;/strong&gt;. Curious about space tech? The &lt;strong&gt;Space Stage&lt;/strong&gt; delivers a full day of orbital insights. And on the &lt;strong&gt;Disrupt Stage&lt;/strong&gt;, hear from some of the biggest names in today’s tech.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt AI Stage" class="wp-image-3048038" height="454" src="https://techcrunch.com/wp-content/uploads/2025/09/Disrupt-2025-AI-Stage.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Slava Blazer Photography&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Experience the intense Startup Battlefield 200&lt;/strong&gt; pitch competition, where the top 20 TechCrunch-vetted early-stage startups pitch on the Disrupt Stage for a $100,000 prize. Hear seasoned VCs give feedback on what makes a winning pitch, and what it takes to build a viable startup.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Salva Health Co-Founder &amp;amp; CEO Valentina Agudelo Vargas, winner of the Startup Battlefield 2024, poses onstage during TechCrunch Disrupt 2024 Day 3 at Moscone Center on October 30, 2024 in San Francisco." class="wp-image-2913234" height="453" src="https://techcrunch.com/wp-content/uploads/2024/11/54105085427_2cae9d0502_o.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Kimberly White / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-2331246" height="356" src="https://techcrunch.com/wp-content/uploads/2022/06/roundtable_1200x628.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Witness the future of tech with 100+ startups&lt;/strong&gt; showcasing in the bustling Expo Hall and throughout the venue. Meet brands pushing innovation to the forefront of the tech ecosystem, and try hands-on demos of their cutting-edge products. &lt;strong&gt;Want your brand in the spotlight for all three days?&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt Expo Hall" class="wp-image-2571166" height="383" src="https://techcrunch.com/wp-content/uploads/2023/07/expo_hall.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Eric Slomonson, The Photo Group&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-september-26-is-the-last-day-for-ticket-savings"&gt;September 26 is the last day for ticket savings&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;You have until &lt;strong&gt;September 26&lt;/strong&gt; at 11:59 p.m. to &lt;strong&gt;secure up to $668 in ticket savings&lt;/strong&gt;. Whether you’re a founder looking to scale or prepare for an IPO, a tech innovator seeking a firsthand look at tomorrow’s tech, or an investor hunting for the next big opportunity, don’t miss Disrupt 2025. &lt;strong&gt;Register your pass now.&lt;/strong&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/22/5-days-left-to-save-up-to-668-on-your-techcrunch-disrupt-2025-pass-dont-pay-more-for-the-same-seat/</guid><pubDate>Mon, 22 Sep 2025 14:00:00 +0000</pubDate></item><item><title>[NEW] Using AI to assist in rare disease diagnosis (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/blog/using-ai-to-assist-in-rare-disease-diagnosis/</link><description>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Icons representing individual and group connections to a central computer monitor with a globe, symbolizing online connectivity, set against a gradient background transitioning from blue to pink." class="wp-image-1143080" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/AItoAssistDiagnosis-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;p&gt;In the promising and rapidly evolving field of genetic analysis, the ability to accurately interpret whole genome sequencing data is crucial for diagnosing and improving outcomes for people with rare genetic diseases. Yet despite technological advancements, genetic professionals face steep challenges in managing and synthesizing the vast amounts of data required for these analyses. Fewer than 50% of&amp;nbsp;initial&amp;nbsp;cases yield a diagnosis, and while reanalysis can lead to new findings, the process remains&amp;nbsp;time-consuming and complex.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To better understand and address these challenges, Microsoft Research—in collaboration with Drexel University and the Broad Institute​​—conducted a comprehensive study titled&amp;nbsp;&lt;em&gt;AI-Enhanced Sensemaking: Exploring the Design of a Generative AI-Based Assistant to Support Genetic Professionals&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&lt;/em&gt;&amp;nbsp;The study was recently published in a special edition of&amp;nbsp;&lt;em&gt;ACM Transactions on Interactive Intelligent Systems&lt;/em&gt;&amp;nbsp;journal focused on generative AI.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The study focused on integrating generative AI to support the complex, time-intensive, and information-dense sensemaking tasks inherent in whole genome sequencing analysis. Through detailed empirical research and collaborative design sessions with experts in the field, we identified key obstacles genetic professionals face and proposed AI-driven solutions to enhance their workflows.&amp;nbsp;​&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;​We&amp;nbsp;developed strategies for how generative AI can help synthesize biomedical data, enabling AI-expert collaboration to increase the diagnoses of previously unsolved rare diseases—ultimately aiming to improve patients’ quality of life and life expectancy.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="whole-genome-sequencing-in-rare-disease-diagnosis"&gt;Whole genome sequencing in rare disease diagnosis&lt;/h2&gt;



&lt;p&gt;Rare diseases affect up to half a billion people globally and obtaining a diagnosis can take multiple years. These diagnoses often involve specialist consultations, laboratory tests, imaging studies, and invasive procedures. Whole genome sequencing is used to identify genetic variants responsible for these diseases by comparing a patient’s DNA sequence to reference genomes.&amp;nbsp;​​Genetic professionals use bioinformatics tools such as&amp;nbsp;&lt;em&gt;seqr,&amp;nbsp;&lt;/em&gt;an open-source, web-based tool for rare disease case analysis and project management to assist them in filtering and prioritizing&amp;nbsp; &amp;gt; 1 million variants to determine their potential role in disease.&amp;nbsp;A critical component of&amp;nbsp;their&amp;nbsp;work is sensemaking: the process of searching, filtering, and synthesizing data to build, refine, and present models from complex sets of gene and variant information.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;​​The multi-step sequencing process​​​&amp;nbsp;typically takes three to 12 weeks and requires extensive amounts of evidence and time to synthesize and aggregate information&amp;nbsp;​​to understand the gene and variant effects for the patient.&amp;nbsp;If a patient’s case goes unsolved, their whole genome sequencing data is set aside until enough time has passed to warrant a reanalysis​​. This creates a backlog of patient cases​​. The ability to easily&amp;nbsp;identify&amp;nbsp;when new scientific evidence&amp;nbsp;emerges&amp;nbsp;and when to reanalyze an unsolved patient case is key to shortening the time patients suffer with an unknown rare disease diagnosis.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="the-promise-of-ai-systems-to-assist-with-complex-human-tasks"&gt;The promise of AI systems to assist with complex human tasks&lt;/h2&gt;



&lt;p&gt;Approximately 87% of AI systems never reach deployment&amp;nbsp;​simply because they solve​​​&amp;nbsp;the wrong problems.&amp;nbsp;​​Understanding the AI support desired by different types of professionals, their current workflows, and AI capabilities is critical to successful AI system deployment and use. Matching technology capabilities with user tasks is particularly challenging in AI design because AI models can generate numerous outputs, and their capabilities can be unclear.&amp;nbsp;​To design an effective​​​&amp;nbsp;AI-based system​, one needs to identify​&amp;nbsp;​​tasks AI can support,&amp;nbsp;​​determine​​​​​​&amp;nbsp;the appropriate level of AI involvement, and&amp;nbsp;​​design​​​​​​&amp;nbsp;user-AI interactions. This necessitates considering how humans interact with technology and how&amp;nbsp;​​AI&amp;nbsp;can best be incorporated into workflows and tools.&lt;/p&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;PODCAST SERIES&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;The AI Revolution in Medicine, Revisited&lt;/h2&gt;
				
								&lt;p class="large" id="the-ai-revolution-in-medicine-revisited"&gt;Join Microsoft’s Peter Lee on a journey to discover how AI is impacting healthcare and what it means for the future of medicine.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;h2 class="wp-block-heading" id="study-objectives-and-co-designing-a-genetic-ai-assistant"&gt;Study objectives and co-designing a genetic AI assistant&lt;/h2&gt;



&lt;p&gt;Our study aimed to understand the current challenges and needs of genetic professionals performing whole genome sequencing analyses and explore the tasks where they want an AI assistant to support them in their work. The first phase of our study involved interviews with 17 genetics professionals to better understand their workflows, tools, and challenges. They included genetic analysts directly involved in interpreting data, as well as other roles participating in whole genome sequencing. In the second phase of our study, we conducted co-design sessions with study participants on how an AI assistant could support their workflows. We then developed a prototype of an AI assistant, which was further tested and refined with study participants in follow-up design walk-through sessions.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="identifying-challenges-in-whole-genome-sequencing-analysis"&gt;Identifying challenges in whole genome sequencing analysis&lt;/h2&gt;



&lt;p&gt;Through our in-depth interviews with genetic professionals, our study uncovered three critical challenges in whole genome sequencing analysis:&lt;/p&gt;



&lt;ol class="wp-block-list"&gt;
&lt;li&gt;&lt;em&gt;Information Overload&lt;/em&gt;: Genetic analysts need to gather and synthesize vast amounts of data from multiple sources. This task is incredibly time-consuming and prone to human error.&lt;/li&gt;



&lt;li&gt;&lt;em&gt;Collaborative Sharing&lt;/em&gt;: Sharing findings with others in the field can be cumbersome and inefficient, often relying on outdated methods that slow the collaborative analysis process.&lt;/li&gt;



&lt;li&gt;&lt;em&gt;Prioritizing Reanalysis&lt;/em&gt;: Given the continuous influx of new scientific discoveries, prioritizing unsolved cases to reanalyze is a daunting challenge. Analysts need a systematic approach to identify cases that might benefit most from reanalysis.&lt;/li&gt;
&lt;/ol&gt;



&lt;p&gt;Genetic professionals highlighted the time-consuming nature of gathering and synthesizing information about genes and variants from different data sources. Other genetic professionals may have insights into certain genes and variants, but sharing and interpreting information with others for collaborative sensemaking requires significant time and effort. Although new scientific findings could affect unsolved cases through reanalysis, prioritizing cases based on new findings was challenging given the number of unsolved cases and limited time of genetic professionals.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="co-designing-with-experts-and-ai-human-sensemaking-tasks"&gt;Co-designing with experts and AI-human sensemaking tasks&lt;/h2&gt;



&lt;p&gt;Our study participants prioritized two potential tasks of an AI assistant. The first task was flagging cases for reanalysis based on new scientific findings. The assistant would alert analysts to unsolved cases that could benefit from new research, providing relevant updates drawn from recent publications. The second task focused on aggregating and synthesizing information about genes and variants from the scientific literature. This feature would compile essential information from numerous scientific papers about genes and variants, presenting it in a user-friendly format and saving analysts significant time and effort. Participants emphasized the need to balance selectivity with comprehensiveness in the evidence they review. They also envisioned collaborating with other genetic professionals to interpret, edit, and verify artifacts generated by the AI assistant.&lt;/p&gt;



&lt;p&gt;Genetic professionals require both broad and focused evidence at different stages of their workflow. The AI assistant prototypes were designed to allow flexible filtering and thorough evidence aggregation, ensuring users can delve into comprehensive data or selectively focus on pertinent details. The prototypes included features for collaborative sensemaking, enabling users to interpret, edit, and verify AI-generated information collectively. This&amp;nbsp;​​approach not only&amp;nbsp;​underscores​​​&amp;nbsp;the trustworthiness of AI outputs, but also facilitates shared understanding and decision-making among genetic professionals.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="design-implications-for-expert-ai-sensemaking"&gt;Design implications for expert-AI sensemaking&lt;/h2&gt;



&lt;p&gt;In the&amp;nbsp;shifting frontiers of genome sequence analysis,&amp;nbsp;leveraging generative AI to enhance sensemaking offers intriguing possibilities​​. The task of staying&amp;nbsp;​​current​​​​​​, synthesizing information from diverse sources, and making informed decisions&amp;nbsp;​​is challenging​​​​​​.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Our study participants emphasized the hurdles in integrating data from multiple sources without losing critical components, documenting decision rationales, and fostering collaborative environments. Generative AI models, with their advanced capabilities, have started to address these challenges by automatically generating interactive artifacts to support sensemaking. However, the effectiveness of such systems hinges on careful design considerations,&amp;nbsp;​​particularly in how they facilitate distributed sensemaking, support both initial and ongoing sensemaking, and combine evidence from multiple modalities. We next discuss three design considerations for using generative AI models to support sensemaking.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="distributed-expert-ai-sensemaking-design"&gt;Distributed expert-AI sensemaking design&lt;/h2&gt;



&lt;p&gt;Generative AI models can create artifacts that aid an individual user’s sensemaking process; however, the true potential lies in sharing these artifacts among users to foster collective understanding and efficiency. Participants in our study emphasized the importance of explainability, feedback, and trust when interacting with AI-generated content.&amp;nbsp;​​​​​​​​​​Trust is gained by​​​​​​&amp;nbsp;viewing portions of artifacts marked as correct by other users, or observing edits made to AI-generated information​​.&amp;nbsp;​​Some​​​​​​&amp;nbsp;users​, however,​&amp;nbsp;cautioned against over-reliance on AI, which could obscure underlying inaccuracies. Thus, design strategies should ensure that any corrections are clearly marked&amp;nbsp;​​and annotated​​​​​​. Furthermore, to enhance distributed sensemaking, visibility of others’ notes and context-specific synthesis through AI can streamline the process​​.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="initial-expert-ai-sensemaking-and-re-sensemaking-design"&gt;Initial expert-AI sensemaking and re-sensemaking design&lt;/h2&gt;



&lt;p&gt;In our fast-paced, information-driven world,&amp;nbsp;​​it is essential to understand a situation both&amp;nbsp;initially&amp;nbsp;and again when new information arises.​​&amp;nbsp;​​Sensemaking is inherently temporal, reflecting and shaping our understanding of time as we revisit tasks to reevaluate past decisions or incorporate new information. Generative AI plays a pivotal role here by transforming static data into dynamic artifacts that evolve, offering a comprehensive view of past rationales. Such AI-generated artifacts provide continuity, allowing users—both&amp;nbsp;original decision-makers or new individuals—to access the rationale behind decisions made in earlier task instances. By continuously editing and updating these artifacts, generative AI highlights new information since the last review, supporting ongoing understanding and decision-making.&amp;nbsp;Moreover, AI systems enhance&amp;nbsp;​​transparency​​​​​​&amp;nbsp;by summarizing previous notes and questions, offering insights into earlier thought processes and facilitating a deeper understanding of how conclusions were drawn. This reflective capability not only can reinforce initial sensemaking efforts but also equips users with the clarity needed for informed re-sensemaking as new data emerges.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="combining-evidence-from-multiple-modalities-to-enhance-ai-expert-sensemaking"&gt;Combining evidence from multiple modalities to enhance AI-expert sensemaking&lt;/h2&gt;



&lt;p&gt;​​​The​​​​​​&amp;nbsp;ability to combine evidence from multiple modalities is essential for effective sensemaking. Users often need to integrate diverse types of data—text, images, spatial coordinates, and more—into a coherent narrative to make informed decisions. Consider the case of search and rescue operations, where workers must rapidly synthesize information from texts, photographs, and GPS data to strategize their efforts. Recent advancements in multimodal generative AI models have empowered users by incorporating and synthesizing these varied inputs into a unified, comprehensive view. For instance, a participant in our study illustrated this capability by using a generative AI model to merge text from scientific publications with a visual gene structure depiction. This integration&amp;nbsp;​​could create​​​​​​&amp;nbsp;an image that contextualizes an individual’s genetic variant within the&amp;nbsp;​​context​​​​​​&amp;nbsp;of documented variants. Such advanced synthesis enables users to capture complex relationships and insights briefly, streamlining decision-making and expanding the potential for innovative solutions across diverse fields.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="sensemaking-process-with-ai-assistant"&gt;Sensemaking Process with AI Assistant&lt;/h2&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure: Sensemaking process when interpreting variants with the introduction of prototype AI assistant. Gray boxes represent sensemaking activities which are currently performed by an analyst but are human-in-the-loop processes with involvement of our prototype AI assistant. Non-gray boxes represent activities reserved for analyst completion without assistance by our AI assistant prototype. Within the foraging searching and synthesizing processes, examples of data sources and data types for each, respectively, are connected by dotted lines." class="wp-image-1142535" height="481" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/FIG1_Mandi-Hall.png" width="952" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure: Sensemaking process when interpreting variants with the introduction of prototype AI assistant. Gray boxes represent sensemaking activities which are currently performed by an analyst but are human-in-the-loop processes with involvement of our prototype AI assistant. Non-gray boxes represent activities reserved for analyst completion without assistance by our AI assistant prototype. Within the foraging searching and synthesizing processes, examples of data sources and data types for each, respectively, are connected by dotted lines.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="conclusion"&gt;Conclusion&lt;/h2&gt;



&lt;p&gt;We explored the potential of generative AI&amp;nbsp;to support​​ genetic professionals​&amp;nbsp;​in diagnosing rare diseases​​. By designing an AI-based assistant, we aim to streamline whole genome sequencing analysis, helping professionals diagnose rare genetic diseases more efficiently. Our study unfolded in two key phases:&amp;nbsp;​pinpointing​​​&amp;nbsp;existing challenges in analysis, and design ideation, where we crafted a prototype AI assistant. This tool is designed to boost diagnostic yield and cut down diagnosis time by flagging cases for reanalysis and synthesizing crucial gene and variant data. Despite valuable findings, more research is needed​​. Future research will involve testing the AI assistant in real-time, task-based user testing with genetic professionals to assess the AI’s impact on their workflow. The promise of AI advancements lies in solving the right user problems and building the appropriate solutions, achieved through collaboration among model developers, domain experts, system designers, and HCI researchers. By fostering these collaborations, we aim to develop robust, personalized AI assistants tailored to specific domains.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="join-the-conversation"&gt;Join the conversation&lt;/h2&gt;



&lt;p&gt;Join us as we continue to explore the transformative potential of generative AI in genetic analysis, and please read the full text publication&amp;nbsp;here&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. Follow us on social media, share this post with your network, and let us know your thoughts on how AI can transform genetic research. If interested in our other related research work, check out&amp;nbsp;Evidence Aggregator: AI reasoning applied to rare disease diagnosis.&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;&amp;nbsp;&lt;/p&gt;




&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Icons representing individual and group connections to a central computer monitor with a globe, symbolizing online connectivity, set against a gradient background transitioning from blue to pink." class="wp-image-1143080" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/AItoAssistDiagnosis-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;p&gt;In the promising and rapidly evolving field of genetic analysis, the ability to accurately interpret whole genome sequencing data is crucial for diagnosing and improving outcomes for people with rare genetic diseases. Yet despite technological advancements, genetic professionals face steep challenges in managing and synthesizing the vast amounts of data required for these analyses. Fewer than 50% of&amp;nbsp;initial&amp;nbsp;cases yield a diagnosis, and while reanalysis can lead to new findings, the process remains&amp;nbsp;time-consuming and complex.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To better understand and address these challenges, Microsoft Research—in collaboration with Drexel University and the Broad Institute​​—conducted a comprehensive study titled&amp;nbsp;&lt;em&gt;AI-Enhanced Sensemaking: Exploring the Design of a Generative AI-Based Assistant to Support Genetic Professionals&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&lt;/em&gt;&amp;nbsp;The study was recently published in a special edition of&amp;nbsp;&lt;em&gt;ACM Transactions on Interactive Intelligent Systems&lt;/em&gt;&amp;nbsp;journal focused on generative AI.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The study focused on integrating generative AI to support the complex, time-intensive, and information-dense sensemaking tasks inherent in whole genome sequencing analysis. Through detailed empirical research and collaborative design sessions with experts in the field, we identified key obstacles genetic professionals face and proposed AI-driven solutions to enhance their workflows.&amp;nbsp;​&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;​We&amp;nbsp;developed strategies for how generative AI can help synthesize biomedical data, enabling AI-expert collaboration to increase the diagnoses of previously unsolved rare diseases—ultimately aiming to improve patients’ quality of life and life expectancy.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="whole-genome-sequencing-in-rare-disease-diagnosis"&gt;Whole genome sequencing in rare disease diagnosis&lt;/h2&gt;



&lt;p&gt;Rare diseases affect up to half a billion people globally and obtaining a diagnosis can take multiple years. These diagnoses often involve specialist consultations, laboratory tests, imaging studies, and invasive procedures. Whole genome sequencing is used to identify genetic variants responsible for these diseases by comparing a patient’s DNA sequence to reference genomes.&amp;nbsp;​​Genetic professionals use bioinformatics tools such as&amp;nbsp;&lt;em&gt;seqr,&amp;nbsp;&lt;/em&gt;an open-source, web-based tool for rare disease case analysis and project management to assist them in filtering and prioritizing&amp;nbsp; &amp;gt; 1 million variants to determine their potential role in disease.&amp;nbsp;A critical component of&amp;nbsp;their&amp;nbsp;work is sensemaking: the process of searching, filtering, and synthesizing data to build, refine, and present models from complex sets of gene and variant information.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;​​The multi-step sequencing process​​​&amp;nbsp;typically takes three to 12 weeks and requires extensive amounts of evidence and time to synthesize and aggregate information&amp;nbsp;​​to understand the gene and variant effects for the patient.&amp;nbsp;If a patient’s case goes unsolved, their whole genome sequencing data is set aside until enough time has passed to warrant a reanalysis​​. This creates a backlog of patient cases​​. The ability to easily&amp;nbsp;identify&amp;nbsp;when new scientific evidence&amp;nbsp;emerges&amp;nbsp;and when to reanalyze an unsolved patient case is key to shortening the time patients suffer with an unknown rare disease diagnosis.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="the-promise-of-ai-systems-to-assist-with-complex-human-tasks"&gt;The promise of AI systems to assist with complex human tasks&lt;/h2&gt;



&lt;p&gt;Approximately 87% of AI systems never reach deployment&amp;nbsp;​simply because they solve​​​&amp;nbsp;the wrong problems.&amp;nbsp;​​Understanding the AI support desired by different types of professionals, their current workflows, and AI capabilities is critical to successful AI system deployment and use. Matching technology capabilities with user tasks is particularly challenging in AI design because AI models can generate numerous outputs, and their capabilities can be unclear.&amp;nbsp;​To design an effective​​​&amp;nbsp;AI-based system​, one needs to identify​&amp;nbsp;​​tasks AI can support,&amp;nbsp;​​determine​​​​​​&amp;nbsp;the appropriate level of AI involvement, and&amp;nbsp;​​design​​​​​​&amp;nbsp;user-AI interactions. This necessitates considering how humans interact with technology and how&amp;nbsp;​​AI&amp;nbsp;can best be incorporated into workflows and tools.&lt;/p&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;PODCAST SERIES&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;The AI Revolution in Medicine, Revisited&lt;/h2&gt;
				
								&lt;p class="large" id="the-ai-revolution-in-medicine-revisited"&gt;Join Microsoft’s Peter Lee on a journey to discover how AI is impacting healthcare and what it means for the future of medicine.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;h2 class="wp-block-heading" id="study-objectives-and-co-designing-a-genetic-ai-assistant"&gt;Study objectives and co-designing a genetic AI assistant&lt;/h2&gt;



&lt;p&gt;Our study aimed to understand the current challenges and needs of genetic professionals performing whole genome sequencing analyses and explore the tasks where they want an AI assistant to support them in their work. The first phase of our study involved interviews with 17 genetics professionals to better understand their workflows, tools, and challenges. They included genetic analysts directly involved in interpreting data, as well as other roles participating in whole genome sequencing. In the second phase of our study, we conducted co-design sessions with study participants on how an AI assistant could support their workflows. We then developed a prototype of an AI assistant, which was further tested and refined with study participants in follow-up design walk-through sessions.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="identifying-challenges-in-whole-genome-sequencing-analysis"&gt;Identifying challenges in whole genome sequencing analysis&lt;/h2&gt;



&lt;p&gt;Through our in-depth interviews with genetic professionals, our study uncovered three critical challenges in whole genome sequencing analysis:&lt;/p&gt;



&lt;ol class="wp-block-list"&gt;
&lt;li&gt;&lt;em&gt;Information Overload&lt;/em&gt;: Genetic analysts need to gather and synthesize vast amounts of data from multiple sources. This task is incredibly time-consuming and prone to human error.&lt;/li&gt;



&lt;li&gt;&lt;em&gt;Collaborative Sharing&lt;/em&gt;: Sharing findings with others in the field can be cumbersome and inefficient, often relying on outdated methods that slow the collaborative analysis process.&lt;/li&gt;



&lt;li&gt;&lt;em&gt;Prioritizing Reanalysis&lt;/em&gt;: Given the continuous influx of new scientific discoveries, prioritizing unsolved cases to reanalyze is a daunting challenge. Analysts need a systematic approach to identify cases that might benefit most from reanalysis.&lt;/li&gt;
&lt;/ol&gt;



&lt;p&gt;Genetic professionals highlighted the time-consuming nature of gathering and synthesizing information about genes and variants from different data sources. Other genetic professionals may have insights into certain genes and variants, but sharing and interpreting information with others for collaborative sensemaking requires significant time and effort. Although new scientific findings could affect unsolved cases through reanalysis, prioritizing cases based on new findings was challenging given the number of unsolved cases and limited time of genetic professionals.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="co-designing-with-experts-and-ai-human-sensemaking-tasks"&gt;Co-designing with experts and AI-human sensemaking tasks&lt;/h2&gt;



&lt;p&gt;Our study participants prioritized two potential tasks of an AI assistant. The first task was flagging cases for reanalysis based on new scientific findings. The assistant would alert analysts to unsolved cases that could benefit from new research, providing relevant updates drawn from recent publications. The second task focused on aggregating and synthesizing information about genes and variants from the scientific literature. This feature would compile essential information from numerous scientific papers about genes and variants, presenting it in a user-friendly format and saving analysts significant time and effort. Participants emphasized the need to balance selectivity with comprehensiveness in the evidence they review. They also envisioned collaborating with other genetic professionals to interpret, edit, and verify artifacts generated by the AI assistant.&lt;/p&gt;



&lt;p&gt;Genetic professionals require both broad and focused evidence at different stages of their workflow. The AI assistant prototypes were designed to allow flexible filtering and thorough evidence aggregation, ensuring users can delve into comprehensive data or selectively focus on pertinent details. The prototypes included features for collaborative sensemaking, enabling users to interpret, edit, and verify AI-generated information collectively. This&amp;nbsp;​​approach not only&amp;nbsp;​underscores​​​&amp;nbsp;the trustworthiness of AI outputs, but also facilitates shared understanding and decision-making among genetic professionals.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="design-implications-for-expert-ai-sensemaking"&gt;Design implications for expert-AI sensemaking&lt;/h2&gt;



&lt;p&gt;In the&amp;nbsp;shifting frontiers of genome sequence analysis,&amp;nbsp;leveraging generative AI to enhance sensemaking offers intriguing possibilities​​. The task of staying&amp;nbsp;​​current​​​​​​, synthesizing information from diverse sources, and making informed decisions&amp;nbsp;​​is challenging​​​​​​.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Our study participants emphasized the hurdles in integrating data from multiple sources without losing critical components, documenting decision rationales, and fostering collaborative environments. Generative AI models, with their advanced capabilities, have started to address these challenges by automatically generating interactive artifacts to support sensemaking. However, the effectiveness of such systems hinges on careful design considerations,&amp;nbsp;​​particularly in how they facilitate distributed sensemaking, support both initial and ongoing sensemaking, and combine evidence from multiple modalities. We next discuss three design considerations for using generative AI models to support sensemaking.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="distributed-expert-ai-sensemaking-design"&gt;Distributed expert-AI sensemaking design&lt;/h2&gt;



&lt;p&gt;Generative AI models can create artifacts that aid an individual user’s sensemaking process; however, the true potential lies in sharing these artifacts among users to foster collective understanding and efficiency. Participants in our study emphasized the importance of explainability, feedback, and trust when interacting with AI-generated content.&amp;nbsp;​​​​​​​​​​Trust is gained by​​​​​​&amp;nbsp;viewing portions of artifacts marked as correct by other users, or observing edits made to AI-generated information​​.&amp;nbsp;​​Some​​​​​​&amp;nbsp;users​, however,​&amp;nbsp;cautioned against over-reliance on AI, which could obscure underlying inaccuracies. Thus, design strategies should ensure that any corrections are clearly marked&amp;nbsp;​​and annotated​​​​​​. Furthermore, to enhance distributed sensemaking, visibility of others’ notes and context-specific synthesis through AI can streamline the process​​.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="initial-expert-ai-sensemaking-and-re-sensemaking-design"&gt;Initial expert-AI sensemaking and re-sensemaking design&lt;/h2&gt;



&lt;p&gt;In our fast-paced, information-driven world,&amp;nbsp;​​it is essential to understand a situation both&amp;nbsp;initially&amp;nbsp;and again when new information arises.​​&amp;nbsp;​​Sensemaking is inherently temporal, reflecting and shaping our understanding of time as we revisit tasks to reevaluate past decisions or incorporate new information. Generative AI plays a pivotal role here by transforming static data into dynamic artifacts that evolve, offering a comprehensive view of past rationales. Such AI-generated artifacts provide continuity, allowing users—both&amp;nbsp;original decision-makers or new individuals—to access the rationale behind decisions made in earlier task instances. By continuously editing and updating these artifacts, generative AI highlights new information since the last review, supporting ongoing understanding and decision-making.&amp;nbsp;Moreover, AI systems enhance&amp;nbsp;​​transparency​​​​​​&amp;nbsp;by summarizing previous notes and questions, offering insights into earlier thought processes and facilitating a deeper understanding of how conclusions were drawn. This reflective capability not only can reinforce initial sensemaking efforts but also equips users with the clarity needed for informed re-sensemaking as new data emerges.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="combining-evidence-from-multiple-modalities-to-enhance-ai-expert-sensemaking"&gt;Combining evidence from multiple modalities to enhance AI-expert sensemaking&lt;/h2&gt;



&lt;p&gt;​​​The​​​​​​&amp;nbsp;ability to combine evidence from multiple modalities is essential for effective sensemaking. Users often need to integrate diverse types of data—text, images, spatial coordinates, and more—into a coherent narrative to make informed decisions. Consider the case of search and rescue operations, where workers must rapidly synthesize information from texts, photographs, and GPS data to strategize their efforts. Recent advancements in multimodal generative AI models have empowered users by incorporating and synthesizing these varied inputs into a unified, comprehensive view. For instance, a participant in our study illustrated this capability by using a generative AI model to merge text from scientific publications with a visual gene structure depiction. This integration&amp;nbsp;​​could create​​​​​​&amp;nbsp;an image that contextualizes an individual’s genetic variant within the&amp;nbsp;​​context​​​​​​&amp;nbsp;of documented variants. Such advanced synthesis enables users to capture complex relationships and insights briefly, streamlining decision-making and expanding the potential for innovative solutions across diverse fields.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="sensemaking-process-with-ai-assistant"&gt;Sensemaking Process with AI Assistant&lt;/h2&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure: Sensemaking process when interpreting variants with the introduction of prototype AI assistant. Gray boxes represent sensemaking activities which are currently performed by an analyst but are human-in-the-loop processes with involvement of our prototype AI assistant. Non-gray boxes represent activities reserved for analyst completion without assistance by our AI assistant prototype. Within the foraging searching and synthesizing processes, examples of data sources and data types for each, respectively, are connected by dotted lines." class="wp-image-1142535" height="481" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/FIG1_Mandi-Hall.png" width="952" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure: Sensemaking process when interpreting variants with the introduction of prototype AI assistant. Gray boxes represent sensemaking activities which are currently performed by an analyst but are human-in-the-loop processes with involvement of our prototype AI assistant. Non-gray boxes represent activities reserved for analyst completion without assistance by our AI assistant prototype. Within the foraging searching and synthesizing processes, examples of data sources and data types for each, respectively, are connected by dotted lines.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="conclusion"&gt;Conclusion&lt;/h2&gt;



&lt;p&gt;We explored the potential of generative AI&amp;nbsp;to support​​ genetic professionals​&amp;nbsp;​in diagnosing rare diseases​​. By designing an AI-based assistant, we aim to streamline whole genome sequencing analysis, helping professionals diagnose rare genetic diseases more efficiently. Our study unfolded in two key phases:&amp;nbsp;​pinpointing​​​&amp;nbsp;existing challenges in analysis, and design ideation, where we crafted a prototype AI assistant. This tool is designed to boost diagnostic yield and cut down diagnosis time by flagging cases for reanalysis and synthesizing crucial gene and variant data. Despite valuable findings, more research is needed​​. Future research will involve testing the AI assistant in real-time, task-based user testing with genetic professionals to assess the AI’s impact on their workflow. The promise of AI advancements lies in solving the right user problems and building the appropriate solutions, achieved through collaboration among model developers, domain experts, system designers, and HCI researchers. By fostering these collaborations, we aim to develop robust, personalized AI assistants tailored to specific domains.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="join-the-conversation"&gt;Join the conversation&lt;/h2&gt;



&lt;p&gt;Join us as we continue to explore the transformative potential of generative AI in genetic analysis, and please read the full text publication&amp;nbsp;here&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. Follow us on social media, share this post with your network, and let us know your thoughts on how AI can transform genetic research. If interested in our other related research work, check out&amp;nbsp;Evidence Aggregator: AI reasoning applied to rare disease diagnosis.&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;&amp;nbsp;&lt;/p&gt;




&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/blog/using-ai-to-assist-in-rare-disease-diagnosis/</guid><pubDate>Mon, 22 Sep 2025 14:17:03 +0000</pubDate></item><item><title>[NEW] Clock’s ticking: Get hands-on experience volunteering at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/22/clocks-ticking-get-hands-on-experience-volunteering-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;September 30 is the final deadline to &lt;strong&gt;apply to volunteer&lt;/strong&gt; at &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; — and we’re officially in countdown mode.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Whether you dream of launching your own startup, building community, or producing global-scale events, volunteering gives you an unmatched, behind-the-scenes look at how a world-class tech conference comes to life in San Francisco.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-2363054" height="356" src="https://techcrunch.com/wp-content/uploads/2022/07/volunteer_header.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-as-a-volunteer-you-ll"&gt;&lt;strong&gt; As a volunteer, you’ll:&lt;/strong&gt;&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Get free access to Disrupt when you’re not on shift.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Gain hands-on experience with event production, logistics, and registration.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Meet startup founders, investors, speakers, and other tech enthusiasts.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Walk away with real connections and an insider’s view of the startup ecosystem.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-apply-before-this-once-a-year-chance-passes"&gt;Apply before this once-a-year chance passes&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;If you’re ready to level up your experience and join the action in San Francisco, now’s the time to step up. Only accepting applications from Bay Area residents.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Apply to volunteer before September 30&lt;/strong&gt;.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 no anniversary" class="wp-image-3040972" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_Disrupt_General_Article_No-Anniversary-at-all_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;September 30 is the final deadline to &lt;strong&gt;apply to volunteer&lt;/strong&gt; at &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; — and we’re officially in countdown mode.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Whether you dream of launching your own startup, building community, or producing global-scale events, volunteering gives you an unmatched, behind-the-scenes look at how a world-class tech conference comes to life in San Francisco.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-2363054" height="356" src="https://techcrunch.com/wp-content/uploads/2022/07/volunteer_header.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-as-a-volunteer-you-ll"&gt;&lt;strong&gt; As a volunteer, you’ll:&lt;/strong&gt;&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Get free access to Disrupt when you’re not on shift.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Gain hands-on experience with event production, logistics, and registration.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Meet startup founders, investors, speakers, and other tech enthusiasts.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Walk away with real connections and an insider’s view of the startup ecosystem.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-apply-before-this-once-a-year-chance-passes"&gt;Apply before this once-a-year chance passes&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;If you’re ready to level up your experience and join the action in San Francisco, now’s the time to step up. Only accepting applications from Bay Area residents.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Apply to volunteer before September 30&lt;/strong&gt;.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 no anniversary" class="wp-image-3040972" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_Disrupt_General_Article_No-Anniversary-at-all_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/22/clocks-ticking-get-hands-on-experience-volunteering-at-techcrunch-disrupt-2025/</guid><pubDate>Mon, 22 Sep 2025 15:30:00 +0000</pubDate></item><item><title>[NEW] Public trust deficit is a major hurdle for AI growth (AI News)</title><link>https://www.artificialintelligence-news.com/news/public-trust-deficit-major-hurdle-for-ai-growth/</link><description>&lt;p&gt;While politicians tout AI’s promise of growth and efficiency, a new report reveals a public trust deficit in the technology. Many are deeply sceptical, creating a major headache for governments’ plans.&lt;/p&gt;&lt;p&gt;A deep dive by the Tony Blair Institute for Global Change (TBI) and Ipsos has put some hard numbers on this feeling of unease. It turns out that a lack of trust is the biggest single reason people are shying away from using generative AI. It’s not just a vague worry; it’s a genuine barrier holding back the AI revolution politicians are so excited about.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-public-trust-in-ai-increases-with-usage"&gt;Public trust in AI increases with usage&lt;/h3&gt;&lt;p&gt;The report shows an interesting split in how we see AI. On one hand, more than half of us have dabbled with generative AI tools in the last year. That’s pretty fast adoption for a technology that was barely on the public radar a few years ago.&lt;/p&gt;&lt;p&gt;However, nearly half the country has never used AI, either at home or for work. This creates a huge divide in how people feel about AI and its growth. The data suggests the more you use AI, the more you tend to trust it.&lt;/p&gt;&lt;p&gt;For people who have never used AI, 56 percent see it as a risk to society. But for the folks who use it every week, that number is cut by more than half, dropping to 26 percent. It’s a classic case of familiarity breeding comfort. If you’ve never had a positive experience with AI, it’s much easier to believe the scary headlines. Seeing its limitations first-hand also helps to counter fears that everyone is about to be replaced by AI.&lt;/p&gt;&lt;p&gt;This divide in public trust towards AI is also shaped by who you are. Younger people are generally more optimistic, while older generations are warier. Professionals in the tech world feel ready for what’s coming, but those in sectors like healthcare and education? They’re feeling far less confident, even though their jobs are likely to be more affected by AI growth.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-it-s-not-what-you-do-it-s-the-way-that-you-do-it"&gt;It’s not what you do, it’s the way that you do it&lt;/h3&gt;&lt;p&gt;Among the most revealing parts of the report is that our feelings about AI change depending on the job it’s doing.&lt;/p&gt;&lt;p&gt;We’re quite happy for AI to help sort out traffic jams or speed up cancer detection. Why? Because we can see the direct, positive benefit to our lives. It’s technology that’s clearly working for us.&lt;/p&gt;&lt;p&gt;But ask people how they feel about AI monitoring their performance at work or being used to target them with political ads, and the mood sours instantly. The acceptance plummets. This shows our concerns aren’t really about the growth of AI itself, but about its purpose.&lt;/p&gt;&lt;p&gt;We want to know that AI is being used for good and that rules are in place so that big tech companies aren’t left completely in the driver’s seat.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-how-do-we-increase-public-trust-in-ai-to-support-growth"&gt;How do we increase public trust in AI to support growth?&lt;/h3&gt;&lt;p&gt;The TBI report doesn’t just point out the problem; it offers a clear path forward to build what it calls “justified trust.”&lt;/p&gt;&lt;p&gt;First, the government needs to change the way it talks about AI. Forget abstract promises of boosting GDP. Instead, talk about what it means for people’s lives: getting a hospital appointment faster, making public services easier to use, or cutting down your daily commute. Show, don’t just tell about the benefits of AI growth.&lt;/p&gt;&lt;p&gt;Next, prove it works. When AI is used in public services, we need to see the evidence that it’s actually making things better for real people, not just more efficient for a spreadsheet. The measure of success should be our experience, not just a technical benchmark.&lt;/p&gt;&lt;p&gt;Of course, none of this works without proper rules and training. Regulators need the power and know-how to keep AI in check, and we all need access to training to feel confident using these new tools safely and effectively. The goal is to make AI something we can all work with, not something that feels like it’s being done to us.&lt;/p&gt;&lt;p&gt;Building public trust in AI to support its growth is about building trust in the people and institutions in charge of it. If the government can show that it’s committed to making AI work for everyone, it might just bring the public along for the ride.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Trump jokes about AI while US and UK sign new tech deal&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Banner for the AI &amp;amp; Big Data Expo event series." class="wp-image-109137" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;While politicians tout AI’s promise of growth and efficiency, a new report reveals a public trust deficit in the technology. Many are deeply sceptical, creating a major headache for governments’ plans.&lt;/p&gt;&lt;p&gt;A deep dive by the Tony Blair Institute for Global Change (TBI) and Ipsos has put some hard numbers on this feeling of unease. It turns out that a lack of trust is the biggest single reason people are shying away from using generative AI. It’s not just a vague worry; it’s a genuine barrier holding back the AI revolution politicians are so excited about.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-public-trust-in-ai-increases-with-usage"&gt;Public trust in AI increases with usage&lt;/h3&gt;&lt;p&gt;The report shows an interesting split in how we see AI. On one hand, more than half of us have dabbled with generative AI tools in the last year. That’s pretty fast adoption for a technology that was barely on the public radar a few years ago.&lt;/p&gt;&lt;p&gt;However, nearly half the country has never used AI, either at home or for work. This creates a huge divide in how people feel about AI and its growth. The data suggests the more you use AI, the more you tend to trust it.&lt;/p&gt;&lt;p&gt;For people who have never used AI, 56 percent see it as a risk to society. But for the folks who use it every week, that number is cut by more than half, dropping to 26 percent. It’s a classic case of familiarity breeding comfort. If you’ve never had a positive experience with AI, it’s much easier to believe the scary headlines. Seeing its limitations first-hand also helps to counter fears that everyone is about to be replaced by AI.&lt;/p&gt;&lt;p&gt;This divide in public trust towards AI is also shaped by who you are. Younger people are generally more optimistic, while older generations are warier. Professionals in the tech world feel ready for what’s coming, but those in sectors like healthcare and education? They’re feeling far less confident, even though their jobs are likely to be more affected by AI growth.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-it-s-not-what-you-do-it-s-the-way-that-you-do-it"&gt;It’s not what you do, it’s the way that you do it&lt;/h3&gt;&lt;p&gt;Among the most revealing parts of the report is that our feelings about AI change depending on the job it’s doing.&lt;/p&gt;&lt;p&gt;We’re quite happy for AI to help sort out traffic jams or speed up cancer detection. Why? Because we can see the direct, positive benefit to our lives. It’s technology that’s clearly working for us.&lt;/p&gt;&lt;p&gt;But ask people how they feel about AI monitoring their performance at work or being used to target them with political ads, and the mood sours instantly. The acceptance plummets. This shows our concerns aren’t really about the growth of AI itself, but about its purpose.&lt;/p&gt;&lt;p&gt;We want to know that AI is being used for good and that rules are in place so that big tech companies aren’t left completely in the driver’s seat.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-how-do-we-increase-public-trust-in-ai-to-support-growth"&gt;How do we increase public trust in AI to support growth?&lt;/h3&gt;&lt;p&gt;The TBI report doesn’t just point out the problem; it offers a clear path forward to build what it calls “justified trust.”&lt;/p&gt;&lt;p&gt;First, the government needs to change the way it talks about AI. Forget abstract promises of boosting GDP. Instead, talk about what it means for people’s lives: getting a hospital appointment faster, making public services easier to use, or cutting down your daily commute. Show, don’t just tell about the benefits of AI growth.&lt;/p&gt;&lt;p&gt;Next, prove it works. When AI is used in public services, we need to see the evidence that it’s actually making things better for real people, not just more efficient for a spreadsheet. The measure of success should be our experience, not just a technical benchmark.&lt;/p&gt;&lt;p&gt;Of course, none of this works without proper rules and training. Regulators need the power and know-how to keep AI in check, and we all need access to training to feel confident using these new tools safely and effectively. The goal is to make AI something we can all work with, not something that feels like it’s being done to us.&lt;/p&gt;&lt;p&gt;Building public trust in AI to support its growth is about building trust in the people and institutions in charge of it. If the government can show that it’s committed to making AI work for everyone, it might just bring the public along for the ride.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Trump jokes about AI while US and UK sign new tech deal&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Banner for the AI &amp;amp; Big Data Expo event series." class="wp-image-109137" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/public-trust-deficit-major-hurdle-for-ai-growth/</guid><pubDate>Mon, 22 Sep 2025 15:47:14 +0000</pubDate></item><item><title>[NEW] Oracle promotes two presidents to co-CEO role (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/22/oracle-promotes-two-presidents-to-co-ceo-role/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2015/09/456307736.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Oracle is shaking up its&amp;nbsp;executive&amp;nbsp;suite as&amp;nbsp;it sets its sights set on AI infrastructure dominance.&amp;nbsp;The company announced Monday that it is promoting&amp;nbsp;Clay Magouyrk and Mike Sicilia&amp;nbsp;to&amp;nbsp;co-CEO&amp;nbsp;roles.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Magouyrk&amp;nbsp;joined Oracle in 2014 from Amazon Web Services. He&amp;nbsp;was a founding member of&amp;nbsp;Oracle’s cloud engineering team and has served as the president of Oracle’s cloud infrastructure business unit&amp;nbsp;for more than a decade.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Sicilia&amp;nbsp;has served as the president of Oracle’s industries division since&amp;nbsp;June. He held&amp;nbsp;several&amp;nbsp;different roles&amp;nbsp;at the company since he&amp;nbsp;joined through&amp;nbsp;Oracle’s acquisition of project portfolio management&amp;nbsp;company&amp;nbsp;Primavera Systems in 2008.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Safra Catz, who has&amp;nbsp;been Oracle’s CEO since&amp;nbsp;2014,&amp;nbsp;is moving into a&amp;nbsp;new role as the executive vice chair of Oracle’s board of directors.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Today, Oracle is recognized as the cloud of choice for both AI training and inferencing.&amp;nbsp;I’m&amp;nbsp;very proud&amp;nbsp;of that,” Catz said in a statement. “Oracle’s technology and business have never been stronger. And our breathtaking growth rate points to an even more prosperous future. At this time of strength is the right moment to pass the CEO role to the next generation of capable executives.” &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While traditionally known as a cloud infrastructure provider, Oracle has recently started to cement its place in the AI infrastructure race as well.&amp;nbsp;Earlier this year, the company announced its participation in the&amp;nbsp;$500 billion&amp;nbsp;Stargate Project,&amp;nbsp;alongside OpenAI and SoftBank,&amp;nbsp;to build data centers and AI infrastructure in the U.S.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Earlier this month, it was reported that the company inked a&amp;nbsp;landmark&amp;nbsp;deal with OpenAI&amp;nbsp;to&amp;nbsp;supply the&amp;nbsp;AI company with&amp;nbsp;$300 billion&amp;nbsp;worth of&amp;nbsp;compute. On Friday,&amp;nbsp;Reuters reported that the company was signing a smaller —&amp;nbsp;but still sizable —&amp;nbsp;$20 billion&amp;nbsp;compute&amp;nbsp;deal&amp;nbsp;with Meta.&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch reached out to Oracle for more information on the transition.&amp;nbsp;&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2015/09/456307736.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Oracle is shaking up its&amp;nbsp;executive&amp;nbsp;suite as&amp;nbsp;it sets its sights set on AI infrastructure dominance.&amp;nbsp;The company announced Monday that it is promoting&amp;nbsp;Clay Magouyrk and Mike Sicilia&amp;nbsp;to&amp;nbsp;co-CEO&amp;nbsp;roles.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Magouyrk&amp;nbsp;joined Oracle in 2014 from Amazon Web Services. He&amp;nbsp;was a founding member of&amp;nbsp;Oracle’s cloud engineering team and has served as the president of Oracle’s cloud infrastructure business unit&amp;nbsp;for more than a decade.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Sicilia&amp;nbsp;has served as the president of Oracle’s industries division since&amp;nbsp;June. He held&amp;nbsp;several&amp;nbsp;different roles&amp;nbsp;at the company since he&amp;nbsp;joined through&amp;nbsp;Oracle’s acquisition of project portfolio management&amp;nbsp;company&amp;nbsp;Primavera Systems in 2008.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Safra Catz, who has&amp;nbsp;been Oracle’s CEO since&amp;nbsp;2014,&amp;nbsp;is moving into a&amp;nbsp;new role as the executive vice chair of Oracle’s board of directors.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Today, Oracle is recognized as the cloud of choice for both AI training and inferencing.&amp;nbsp;I’m&amp;nbsp;very proud&amp;nbsp;of that,” Catz said in a statement. “Oracle’s technology and business have never been stronger. And our breathtaking growth rate points to an even more prosperous future. At this time of strength is the right moment to pass the CEO role to the next generation of capable executives.” &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While traditionally known as a cloud infrastructure provider, Oracle has recently started to cement its place in the AI infrastructure race as well.&amp;nbsp;Earlier this year, the company announced its participation in the&amp;nbsp;$500 billion&amp;nbsp;Stargate Project,&amp;nbsp;alongside OpenAI and SoftBank,&amp;nbsp;to build data centers and AI infrastructure in the U.S.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Earlier this month, it was reported that the company inked a&amp;nbsp;landmark&amp;nbsp;deal with OpenAI&amp;nbsp;to&amp;nbsp;supply the&amp;nbsp;AI company with&amp;nbsp;$300 billion&amp;nbsp;worth of&amp;nbsp;compute. On Friday,&amp;nbsp;Reuters reported that the company was signing a smaller —&amp;nbsp;but still sizable —&amp;nbsp;$20 billion&amp;nbsp;compute&amp;nbsp;deal&amp;nbsp;with Meta.&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch reached out to Oracle for more information on the transition.&amp;nbsp;&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/22/oracle-promotes-two-presidents-to-co-ceo-role/</guid><pubDate>Mon, 22 Sep 2025 16:45:19 +0000</pubDate></item><item><title>[NEW] Google’s Gemini AI is coming to your TV (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/22/googles-gemini-ai-is-coming-to-your-tv/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google’s AI assistant, Gemini, is coming to your TV. On Monday, the company announced it’s introducing Gemini for Google TV, allowing TV owners to engage in free-flowing, natural language conversations with the AI. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When fully rolled out, this expansion of Gemini to a new platform will bring Google’s AI to over 300 million active Google TV and other Android TV OS-powered devices. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In terms of TV-related questions, Google suggests its Gemini AI could be used to help people with different interests settle on something to watch that they would both like, or to catch you up on what you missed in a past season of a favorite show. You could also get Gemini to help you find a movie or show when you can’t remember the title or ask about a title’s reviews to help determine if it’s worth watching.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, because it’s Gemini, you can ask any other type of question, too, just as you could with the AI chatbot on your smartphone.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt; For instance, kids and parents could use the AI to get homework help or brainstorm school project ideas, families could use Gemini to plan their next vacation, or individual users could leverage the AI to teach themselves a new skill, among other things.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="a photo of a Google TV showing a response on screen showing a prompt: &amp;quot;explain why volcanoes erupt to my third grader&amp;quot;." class="wp-image-3048543" height="562" src="https://techcrunch.com/wp-content/uploads/2025/09/Volcano_Gemini_TV-Shell.width-1000.format-webp.webp" width="1000" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company stresses that Gemini’s addition doesn’t mean that you won’t be able to do the same things you used to be able to do through the (non-AI) Google Assistant integration. Those commands will still work, says Google.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Gemini rollout to Google TV begins on the TCL QM9K series starting today. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Later in the year, Gemini will arrive on the Google TV Streamer, Walmart onn 4K Pro, 2025 Hisense U7, U8, and UX models, and 2025 TCL QM7K, QM8K, and X11K models. More functionality will be added over time.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google’s AI assistant, Gemini, is coming to your TV. On Monday, the company announced it’s introducing Gemini for Google TV, allowing TV owners to engage in free-flowing, natural language conversations with the AI. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When fully rolled out, this expansion of Gemini to a new platform will bring Google’s AI to over 300 million active Google TV and other Android TV OS-powered devices. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In terms of TV-related questions, Google suggests its Gemini AI could be used to help people with different interests settle on something to watch that they would both like, or to catch you up on what you missed in a past season of a favorite show. You could also get Gemini to help you find a movie or show when you can’t remember the title or ask about a title’s reviews to help determine if it’s worth watching.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, because it’s Gemini, you can ask any other type of question, too, just as you could with the AI chatbot on your smartphone.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt; For instance, kids and parents could use the AI to get homework help or brainstorm school project ideas, families could use Gemini to plan their next vacation, or individual users could leverage the AI to teach themselves a new skill, among other things.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="a photo of a Google TV showing a response on screen showing a prompt: &amp;quot;explain why volcanoes erupt to my third grader&amp;quot;." class="wp-image-3048543" height="562" src="https://techcrunch.com/wp-content/uploads/2025/09/Volcano_Gemini_TV-Shell.width-1000.format-webp.webp" width="1000" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company stresses that Gemini’s addition doesn’t mean that you won’t be able to do the same things you used to be able to do through the (non-AI) Google Assistant integration. Those commands will still work, says Google.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Gemini rollout to Google TV begins on the TCL QM9K series starting today. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Later in the year, Gemini will arrive on the Google TV Streamer, Walmart onn 4K Pro, 2025 Hisense U7, U8, and UX models, and 2025 TCL QM7K, QM8K, and X11K models. More functionality will be added over time.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/22/googles-gemini-ai-is-coming-to-your-tv/</guid><pubDate>Mon, 22 Sep 2025 16:56:53 +0000</pubDate></item><item><title>[NEW] Nvidia plans to invest up to $100B in OpenAI (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/22/nvidia-plans-to-invest-up-to-100b-in-openai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/11/GettyImages-2183848501.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Nvidia announced Monday it plans to invest up to $100 billion in OpenAI as part of a deal to build out massive data centers for training and running AI models. The companies say they signed a letter of intent to deploy 10 gigawatts — enough to power millions of homes — worth of Nvidia systems to power OpenAI’s next generation of AI infrastructure. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal may help OpenAI as it reduces its reliance on Microsoft, its largest investor and supplier of cloud computing resources. In January, Microsoft announced changes to its partnership with OpenAI, allowing the ChatGPT-maker to build additional AI infrastructure with other partners. Since then, OpenAI has teamed up with various partners on AI data center projects, such as Stargate. Nvidia says the deal will complement existing partnerships OpenAI has, including agreements with Microsoft, Oracle, and SoftBank.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI says it will work with Nvidia as a “preferred strategic compute and networking partner” for its AI factory growth. It’s unclear whether Nvidia’s investment will be paid out in chips, cloud credits, cash, or otherwise.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/11/GettyImages-2183848501.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Nvidia announced Monday it plans to invest up to $100 billion in OpenAI as part of a deal to build out massive data centers for training and running AI models. The companies say they signed a letter of intent to deploy 10 gigawatts — enough to power millions of homes — worth of Nvidia systems to power OpenAI’s next generation of AI infrastructure. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal may help OpenAI as it reduces its reliance on Microsoft, its largest investor and supplier of cloud computing resources. In January, Microsoft announced changes to its partnership with OpenAI, allowing the ChatGPT-maker to build additional AI infrastructure with other partners. Since then, OpenAI has teamed up with various partners on AI data center projects, such as Stargate. Nvidia says the deal will complement existing partnerships OpenAI has, including agreements with Microsoft, Oracle, and SoftBank.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI says it will work with Nvidia as a “preferred strategic compute and networking partner” for its AI factory growth. It’s unclear whether Nvidia’s investment will be paid out in chips, cloud credits, cash, or otherwise.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/22/nvidia-plans-to-invest-up-to-100b-in-openai/</guid><pubDate>Mon, 22 Sep 2025 17:24:33 +0000</pubDate></item><item><title>[NEW] The billion-dollar infrastructure deals powering the AI boom (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/22/the-billion-dollar-infrastructure-deals-powering-the-ai-boom/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/08/GettyImages-1297856112.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;It takes a lot of computing power to run an AI product – and as the tech industry races to tap the power of AI models, there’s a parallel race underway to build the infrastructure that will power them. On a recent earnings call, Nvidia CEO Jensen Huang estimated that between $3 and $4 trillion will be spent on AI infrastructure by the end of the decade – with much of that money coming from AI companies themselves. Along the way, they’re placing immense strain on power grids, and pushing the industry’s building capacity to its limit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Below, we’ve laid out everything we know about the biggest AI infrastructure projects, including major spending from Meta, Oracle, Microsoft, Google, and OpenAI. We’ll keep it updated as the boom continues, and the numbers climb even higher.&lt;/p&gt;







&lt;p class="has-h-3-font-size wp-block-paragraph"&gt;&lt;strong&gt;Microsoft’s $1 billion investment in OpenAI&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is arguably the deal that kicked off the whole contemporary AI boom: in 2019, Microsoft made a $1 billion investment in a buzzy non-profit called OpenAI, known mostly for its association with Elon Musk. Crucially, the deal made Microsoft the exclusive cloud provider for OpenAI – and as the demands of model-training became more intense, more of Microsoft’s investment started to come in the form of Azure cloud credit rather than cash. It was a great deal for both sides: Microsoft was able to claim more Azure sales, and OpenAI got more money for its biggest single expense. In the years that followed, Microsoft would build its investment up to nearly $14 billion – a move that is set to pay off enormously when OpenAI converts into a for-profit company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The partnership between the two companies has unwound more recently. In January, OpenAI announced it would no longer be using Microsoft’s cloud exclusively, instead giving the company a right of first refusal on future infrastructure demands but pursuing others if Azure couldn’t meet their needs. More recently, Microsoft began exploring other foundation models to power its AI products, establishing even more independence from the AI giant.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s arrangement with Microsoft was so successful that it’s become a common practice for AI services to sign on with a particular cloud provider. Anthropic has received $8 billion in investment from Amazon, while making kernel-level modifications on the company’s hardware to make it better-suited for AI training. Google Cloud has also signed on smaller AI companies like Loveable and Windsurf as “primary computing partners,” although those deals did not involve any investment. And even OpenAI has gone back to the well, receiving a $100 billion investment from Nvidia in September, giving it capacity to buy even more of the company’s GPUs.&lt;/p&gt;

&lt;p class="has-h-3-font-size wp-block-paragraph"&gt;&lt;strong&gt;The rise of Oracle&lt;/strong&gt;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;On June 30th 2025, Oracle revealed in an SEC filing that it had signed a $30 billion cloud services deal with an unnamed partner, more than the company’s cloud revenues for all of the previous fiscal year. OpenAI was eventually revealed as the partner, securing Oracle a spot alongside Google as one of the OpenAI’s string of post-Microsoft hosting partners. Unsurprisingly, the company’s stock went shooting up.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A few months later, it happened again. On September 10th, Oracle revealed a five-year, $300 billion deal for compute power, set to begin in 2027. Oracle’s stock climbed even higher, briefly making founder Larry Ellison the richest man in the world. The sheer scale of the deal is stunning: OpenAI does not have $300 billion to spend, so the figure presumes immense growth for both companies, and more than a little faith. But before a single dollar is spent, the deal has already cemented Oracle as one of the leading AI infrastructure providers – and a financial force to be reckoned with.&lt;/p&gt;

&lt;p class="has-h-3-font-size wp-block-paragraph"&gt;&lt;strong&gt;Building tomorrow’s hyperscale data centers&lt;/strong&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For companies like Meta that already have significant legacy infrastructure, the story is more complicated – although equally expensive. Mark Zuckerberg has said that Meta plans to spend $600 billion on US infrastructure through the end of 2028. In just the first half of 2025, the company spent $30 billion more than the previous year, driven largely by the company’s growing AI ambitions. Some of that spending goes toward big ticket cloud contracts, like a recent $10 billion deal with Google Cloud, but even more resources are being poured into two massive new data centers. A new 2,250-acre site in Louisiana, dubbed Hyperion, will cost an estimated $10 billion to build out and provide an estimated 5 gigawatts of compute power. Notably, the site includes an arrangement with a local nuclear power plant to handle the increased energy load. A smaller site in Ohio, called Prometheus, is expected to come online in 2026, powered by natural gas.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That kind of buildout comes with real environmental costs. Elon Musk’s xAI built its own hybrid data center and power-generation plant in South Memphis, Tennessee. The plant has quickly become one of the county’s largest emitters of smog-producing chemicals, thanks to a string of natural gas turbines that experts say violate the Clean Air Act.&lt;/p&gt;

&lt;p class="has-h-3-font-size wp-block-paragraph"&gt;&lt;strong&gt;The Stargate moonshot&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Just two days after his second inauguration, President Trump announced a joint venture between SoftBank, OpenAI and Oracle, meant to spend $500 billion building AI infrastructure in the United States. Named “Stargate” after the 1994 film, the project arrived with incredible amounts of hype, with Trump calling it “the largest AI infrastructure project in history. Sam Altman seemed to agree, saying, ​​”I think this will be the most important project of this era.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In broad strokes, the plan was for SoftBank to provide the funding, with Oracle handling the buildout with input from OpenAI. Overseeing it all was Trump, who promised to clear away any regulatory hurdles that might slow down the build. But there were doubts from the beginning, including from Elon Musk, Altman’s business rival, who claimed the project did not have the available funds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As the hype has died down, the project has lost some momentum. In August, Bloomberg reported that the partners were failing to reach consensus. Nonetheless, the project has moved forward with the construction of eight data centers in Abilene, Texas, with construction on the final building set to be finished by the end of 2026.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/08/GettyImages-1297856112.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;It takes a lot of computing power to run an AI product – and as the tech industry races to tap the power of AI models, there’s a parallel race underway to build the infrastructure that will power them. On a recent earnings call, Nvidia CEO Jensen Huang estimated that between $3 and $4 trillion will be spent on AI infrastructure by the end of the decade – with much of that money coming from AI companies themselves. Along the way, they’re placing immense strain on power grids, and pushing the industry’s building capacity to its limit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Below, we’ve laid out everything we know about the biggest AI infrastructure projects, including major spending from Meta, Oracle, Microsoft, Google, and OpenAI. We’ll keep it updated as the boom continues, and the numbers climb even higher.&lt;/p&gt;







&lt;p class="has-h-3-font-size wp-block-paragraph"&gt;&lt;strong&gt;Microsoft’s $1 billion investment in OpenAI&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is arguably the deal that kicked off the whole contemporary AI boom: in 2019, Microsoft made a $1 billion investment in a buzzy non-profit called OpenAI, known mostly for its association with Elon Musk. Crucially, the deal made Microsoft the exclusive cloud provider for OpenAI – and as the demands of model-training became more intense, more of Microsoft’s investment started to come in the form of Azure cloud credit rather than cash. It was a great deal for both sides: Microsoft was able to claim more Azure sales, and OpenAI got more money for its biggest single expense. In the years that followed, Microsoft would build its investment up to nearly $14 billion – a move that is set to pay off enormously when OpenAI converts into a for-profit company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The partnership between the two companies has unwound more recently. In January, OpenAI announced it would no longer be using Microsoft’s cloud exclusively, instead giving the company a right of first refusal on future infrastructure demands but pursuing others if Azure couldn’t meet their needs. More recently, Microsoft began exploring other foundation models to power its AI products, establishing even more independence from the AI giant.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s arrangement with Microsoft was so successful that it’s become a common practice for AI services to sign on with a particular cloud provider. Anthropic has received $8 billion in investment from Amazon, while making kernel-level modifications on the company’s hardware to make it better-suited for AI training. Google Cloud has also signed on smaller AI companies like Loveable and Windsurf as “primary computing partners,” although those deals did not involve any investment. And even OpenAI has gone back to the well, receiving a $100 billion investment from Nvidia in September, giving it capacity to buy even more of the company’s GPUs.&lt;/p&gt;

&lt;p class="has-h-3-font-size wp-block-paragraph"&gt;&lt;strong&gt;The rise of Oracle&lt;/strong&gt;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;On June 30th 2025, Oracle revealed in an SEC filing that it had signed a $30 billion cloud services deal with an unnamed partner, more than the company’s cloud revenues for all of the previous fiscal year. OpenAI was eventually revealed as the partner, securing Oracle a spot alongside Google as one of the OpenAI’s string of post-Microsoft hosting partners. Unsurprisingly, the company’s stock went shooting up.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A few months later, it happened again. On September 10th, Oracle revealed a five-year, $300 billion deal for compute power, set to begin in 2027. Oracle’s stock climbed even higher, briefly making founder Larry Ellison the richest man in the world. The sheer scale of the deal is stunning: OpenAI does not have $300 billion to spend, so the figure presumes immense growth for both companies, and more than a little faith. But before a single dollar is spent, the deal has already cemented Oracle as one of the leading AI infrastructure providers – and a financial force to be reckoned with.&lt;/p&gt;

&lt;p class="has-h-3-font-size wp-block-paragraph"&gt;&lt;strong&gt;Building tomorrow’s hyperscale data centers&lt;/strong&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For companies like Meta that already have significant legacy infrastructure, the story is more complicated – although equally expensive. Mark Zuckerberg has said that Meta plans to spend $600 billion on US infrastructure through the end of 2028. In just the first half of 2025, the company spent $30 billion more than the previous year, driven largely by the company’s growing AI ambitions. Some of that spending goes toward big ticket cloud contracts, like a recent $10 billion deal with Google Cloud, but even more resources are being poured into two massive new data centers. A new 2,250-acre site in Louisiana, dubbed Hyperion, will cost an estimated $10 billion to build out and provide an estimated 5 gigawatts of compute power. Notably, the site includes an arrangement with a local nuclear power plant to handle the increased energy load. A smaller site in Ohio, called Prometheus, is expected to come online in 2026, powered by natural gas.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That kind of buildout comes with real environmental costs. Elon Musk’s xAI built its own hybrid data center and power-generation plant in South Memphis, Tennessee. The plant has quickly become one of the county’s largest emitters of smog-producing chemicals, thanks to a string of natural gas turbines that experts say violate the Clean Air Act.&lt;/p&gt;

&lt;p class="has-h-3-font-size wp-block-paragraph"&gt;&lt;strong&gt;The Stargate moonshot&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Just two days after his second inauguration, President Trump announced a joint venture between SoftBank, OpenAI and Oracle, meant to spend $500 billion building AI infrastructure in the United States. Named “Stargate” after the 1994 film, the project arrived with incredible amounts of hype, with Trump calling it “the largest AI infrastructure project in history. Sam Altman seemed to agree, saying, ​​”I think this will be the most important project of this era.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In broad strokes, the plan was for SoftBank to provide the funding, with Oracle handling the buildout with input from OpenAI. Overseeing it all was Trump, who promised to clear away any regulatory hurdles that might slow down the build. But there were doubts from the beginning, including from Elon Musk, Altman’s business rival, who claimed the project did not have the available funds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As the hype has died down, the project has lost some momentum. In August, Bloomberg reported that the partners were failing to reach consensus. Nonetheless, the project has moved forward with the construction of eight data centers in Abilene, Texas, with construction on the final building set to be finished by the end of 2026.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/22/the-billion-dollar-infrastructure-deals-powering-the-ai-boom/</guid><pubDate>Mon, 22 Sep 2025 17:35:27 +0000</pubDate></item><item><title>[NEW] DeepMind AI safety report explores the perils of “misaligned” AI (AI – Ars Technica)</title><link>https://arstechnica.com/google/2025/09/deepmind-ai-safety-report-explores-the-perils-of-misaligned-ai/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        DeepMind releases version 3.0 of its AI Frontier Safety Framework with new tips to stop bad bots.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/04/deepmind-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/04/deepmind-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Jacob Porczyki/Nurphoto

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Generative AI models are far from perfect, but that hasn't stopped businesses and even governments from giving these robots important tasks. But what happens when AI goes bad? Researchers at Google DeepMind spend a lot of time thinking about how generative AI systems can become threats, detailing it all in the company's Frontier Safety Framework. DeepMind recently released version 3.0&amp;nbsp;of the framework to explore more ways AI could go off the rails, including the possibility that models could ignore user attempts to shut them down.&lt;/p&gt;
&lt;p&gt;DeepMind's safety framework is based on so-called "critical capability levels" (CCLs). These are essentially risk assessment rubrics that aim to measure an AI model's capabilities and define the point at which its behavior becomes dangerous in areas like cybersecurity or biosciences. The document also details the ways developers can address the CCLs DeepMind identifies in their own models.&lt;/p&gt;
&lt;p&gt;Google and other firms that have delved deeply into generative AI employ a number of techniques to prevent AI from acting maliciously. Although calling an AI "malicious" lends it intentionality that fancy estimation architectures don't have. What we're talking about here is the possibility of misuse or malfunction that is baked into the nature of generative AI systems.&lt;/p&gt;
&lt;p&gt;The updated framework (PDF) says that developers should take precautions to ensure model security. Specifically, it calls for proper safeguarding of model weights for more powerful AI systems. The researchers fear that exfiltration of model weights would give bad actors the chance to disable the guardrails that have been designed to prevent malicious behavior. This could lead to CCLs like a bot that creates more effective malware or assists in designing biological weapons.&lt;/p&gt;
&lt;p&gt;DeepMind also calls out the possibility that an AI could be tuned to be manipulative and systematically change people's beliefs—this CCL seems pretty plausible given how people grow attached to chatbots. However, the team doesn't have a great answer here, noting that this is a "low-velocity" threat, and our existing "social defenses" should be enough to do the job without new restrictions that could stymie innovation. This might assume too much of people, though.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;DeepMind also addresses something of a meta-concern about AI. The researchers say that a powerful AI in the wrong hands could be dangerous if it is used to accelerate machine learning research, resulting in the creation of more capable and unrestricted AI models. DeepMind says this could "have a significant effect on society’s ability to adapt to and govern powerful AI models." DeepMind ranks this as a more severe threat than most other CCLs.&lt;/p&gt;
&lt;h2&gt;The misaligned AI&lt;/h2&gt;
&lt;p&gt;Most AI security mitigations follow from the assumption that the model is at least trying to follow instructions. Despite years of hallucination, researchers have not managed to make these models completely trustworthy or accurate, but it's possible that a model's incentives could be warped, either accidentally or on purpose. If a misaligned AI begins to actively work against humans or ignore instructions, that's a new kind of problem that goes beyond simple hallucination.&lt;/p&gt;
&lt;p&gt;Version 3 of the Frontier Safety Framework introduces an "exploratory approach" to understanding the risks of a misaligned AI. There have already been documented instances of generative AI models engaging in deception and defiant behavior, and DeepMind researchers express concern that it may be difficult to monitor for this kind of behavior in the future.&lt;/p&gt;
&lt;p&gt;A misaligned AI might ignore human instructions, produce fraudulent outputs, or refuse to stop operating when requested. For the time being, there's a fairly straightforward way to combat this outcome. Today's most advanced simulated reasoning models produce "scratchpad" outputs during the thinking process. Devs are advised to use an automated monitor to double-check the model's chain-of-thought output for evidence misalignment or deception.&lt;/p&gt;
&lt;p&gt;Google says this CCL could become more severe in the future. The team believes models in the coming years may evolve to have effective simulated reasoning without producing a verifiable chain of thought. So your overseer guardrail wouldn't be able to peer into the reasoning process of such a model. For this theoretical advanced AI, it may be impossible to completely rule out that the model is working against the interests of its human operator.&lt;/p&gt;
&lt;p&gt;The framework doesn't have a good solution to this problem just yet. DeepMind says it is researching possible mitigations for a misaligned AI, but it's hard to know when or if this problem will become a reality. These "thinking" models have only been common for about a year, and there's still a lot we don't know about how they arrive at a given output.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        DeepMind releases version 3.0 of its AI Frontier Safety Framework with new tips to stop bad bots.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/04/deepmind-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/04/deepmind-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Jacob Porczyki/Nurphoto

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Generative AI models are far from perfect, but that hasn't stopped businesses and even governments from giving these robots important tasks. But what happens when AI goes bad? Researchers at Google DeepMind spend a lot of time thinking about how generative AI systems can become threats, detailing it all in the company's Frontier Safety Framework. DeepMind recently released version 3.0&amp;nbsp;of the framework to explore more ways AI could go off the rails, including the possibility that models could ignore user attempts to shut them down.&lt;/p&gt;
&lt;p&gt;DeepMind's safety framework is based on so-called "critical capability levels" (CCLs). These are essentially risk assessment rubrics that aim to measure an AI model's capabilities and define the point at which its behavior becomes dangerous in areas like cybersecurity or biosciences. The document also details the ways developers can address the CCLs DeepMind identifies in their own models.&lt;/p&gt;
&lt;p&gt;Google and other firms that have delved deeply into generative AI employ a number of techniques to prevent AI from acting maliciously. Although calling an AI "malicious" lends it intentionality that fancy estimation architectures don't have. What we're talking about here is the possibility of misuse or malfunction that is baked into the nature of generative AI systems.&lt;/p&gt;
&lt;p&gt;The updated framework (PDF) says that developers should take precautions to ensure model security. Specifically, it calls for proper safeguarding of model weights for more powerful AI systems. The researchers fear that exfiltration of model weights would give bad actors the chance to disable the guardrails that have been designed to prevent malicious behavior. This could lead to CCLs like a bot that creates more effective malware or assists in designing biological weapons.&lt;/p&gt;
&lt;p&gt;DeepMind also calls out the possibility that an AI could be tuned to be manipulative and systematically change people's beliefs—this CCL seems pretty plausible given how people grow attached to chatbots. However, the team doesn't have a great answer here, noting that this is a "low-velocity" threat, and our existing "social defenses" should be enough to do the job without new restrictions that could stymie innovation. This might assume too much of people, though.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;DeepMind also addresses something of a meta-concern about AI. The researchers say that a powerful AI in the wrong hands could be dangerous if it is used to accelerate machine learning research, resulting in the creation of more capable and unrestricted AI models. DeepMind says this could "have a significant effect on society’s ability to adapt to and govern powerful AI models." DeepMind ranks this as a more severe threat than most other CCLs.&lt;/p&gt;
&lt;h2&gt;The misaligned AI&lt;/h2&gt;
&lt;p&gt;Most AI security mitigations follow from the assumption that the model is at least trying to follow instructions. Despite years of hallucination, researchers have not managed to make these models completely trustworthy or accurate, but it's possible that a model's incentives could be warped, either accidentally or on purpose. If a misaligned AI begins to actively work against humans or ignore instructions, that's a new kind of problem that goes beyond simple hallucination.&lt;/p&gt;
&lt;p&gt;Version 3 of the Frontier Safety Framework introduces an "exploratory approach" to understanding the risks of a misaligned AI. There have already been documented instances of generative AI models engaging in deception and defiant behavior, and DeepMind researchers express concern that it may be difficult to monitor for this kind of behavior in the future.&lt;/p&gt;
&lt;p&gt;A misaligned AI might ignore human instructions, produce fraudulent outputs, or refuse to stop operating when requested. For the time being, there's a fairly straightforward way to combat this outcome. Today's most advanced simulated reasoning models produce "scratchpad" outputs during the thinking process. Devs are advised to use an automated monitor to double-check the model's chain-of-thought output for evidence misalignment or deception.&lt;/p&gt;
&lt;p&gt;Google says this CCL could become more severe in the future. The team believes models in the coming years may evolve to have effective simulated reasoning without producing a verifiable chain of thought. So your overseer guardrail wouldn't be able to peer into the reasoning process of such a model. For this theoretical advanced AI, it may be impossible to completely rule out that the model is working against the interests of its human operator.&lt;/p&gt;
&lt;p&gt;The framework doesn't have a good solution to this problem just yet. DeepMind says it is researching possible mitigations for a misaligned AI, but it's hard to know when or if this problem will become a reality. These "thinking" models have only been common for about a year, and there's still a lot we don't know about how they arrive at a given output.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/google/2025/09/deepmind-ai-safety-report-explores-the-perils-of-misaligned-ai/</guid><pubDate>Mon, 22 Sep 2025 18:18:00 +0000</pubDate></item></channel></rss>