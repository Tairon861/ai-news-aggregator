<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 09 Jul 2025 18:32:26 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>[NEW] Why the AI moratorium’s defeat may signal a new political era (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/09/1119867/why-the-ai-moratoriums-defeat-may-signal-a-new-political-era/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/AP25099732252814.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;The “Big, Beautiful Bill” that President Donald Trump signed into law on July 4 was chock full of controversial policies—Medicaid work requirements, increased funding for ICE, and an end to tax credits for clean energy and vehicles, to name just a few. But one highly contested provision was missing. Just days earlier, during a late-night voting session, the Senate had killed the bill’s 10-year moratorium on state-level AI regulation.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“We really dodged a bullet,” says Scott Wiener, a California state senator and the author of SB 1047, a bill that would have made companies liable for harms caused by large AI models. It was vetoed by Governor Gavin Newsom last year, but Wiener is now working to pass SB 53, which establishes whistleblower protections for employees of AI companies. Had the federal AI regulation moratorium passed, he says, that bill likely would have been dead.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The moratorium could also have killed laws that have already been adopted around the country, including a Colorado law that targets algorithmic discrimination, laws in Utah and California aimed at making AI-generated content more identifiable, and other legislation focused on preserving data privacy and keeping children safe online. Proponents of the moratorium, such OpenAI and Senator Ted Cruz, have said that a “patchwork” of state-level regulations would place an undue burden on technology companies and stymie innovation. Federal regulation, they argue, is a better approach—but there is currently no federal AI regulation in place.&lt;/p&gt;  &lt;p&gt;Wiener and other state lawmakers can now get back to work writing and passing AI policy, at least for the time being—with the tailwind of a major moral victory at their backs. The movement to defeat the moratorium was impressively bipartisan: 40 state attorneys general signed a letter to Congress opposing the measure, as did a group of over 250 Republican and Democratic state lawmakers. And while congressional Democrats were united against the moratorium, the final nail in its coffin was hammered in by Senator Marsha Blackburn of Tennessee, a Tea Party conservative and Trump ally who backed out of a compromise with Cruz at the eleventh hour.&lt;/p&gt; 
 &lt;p&gt;The moratorium fight may have signaled a bigger political shift. “In the last few months, we’ve seen a much broader and more diverse coalition form in support of AI regulation generally,” says Amba Kak, co–executive director of the AI Now Institute. After years of relative inaction, politicians are getting concerned about the risks of unregulated artificial intelligence.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Granted, there’s an argument to be made that the moratorium’s defeat was highly contingent. Blackburn appears to have been motivated almost entirely by concerns about children’s online safety and the rights of country musicians to control their own likenesses; state lawmakers, meanwhile, were affronted by the federal government’s attempt to defang legislation that they had already passed. &lt;/p&gt; 
 &lt;p&gt;And even though powerful technology firms such as Andreessen Horowitz and OpenAI reportedly lobbied in favor of the moratorium, continuing to push for it might not have been worth it to the Trump administration and its allies—at least not at the expense of tax breaks and entitlement cuts. Baobao Zhang, an associate professor of political science at Syracuse University, says that the administration may have been willing to give up on the moratorium in order to push through the rest of the bill by its self-imposed Independence Day deadline.&lt;/p&gt;  &lt;p&gt;Andreessen Horowitz did not respond to a request for comment. OpenAI noted that the company was opposed to a state-by-state approach to AI regulation but did not respond to specific questions regarding the moratorium’s defeat.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It’s almost certainly the case that the moratorium’s breadth, as well as its decade-long duration, helped opponents marshall a diverse coalition to their side. But that breadth isn’t incidental—it’s related to the very nature of AI. Blackburn, who represents country musicians in Nashville, and Wiener, who represents software developers in San Francisco, have a shared interest in AI regulation precisely because such a powerful and general-purpose tool has the potential to affect so many people’s well-being and livelihood. “There are real anxieties that are touching people of all classes,” Kak says. “It’s creating solidarities that maybe didn’t exist before.”&lt;/p&gt;  &lt;p&gt;Faced with outspoken advocates, concerned constituents, and the constant buzz of AI discourse, politicians from both sides of the aisle are starting to argue for taking AI extremely seriously. One of the most prominent anti-moratorium voices was Marjorie Taylor Greene, who voted for the version of the bill containing the moratorium before admitting that she hadn’t read it thoroughly and committing to opposing the moratorium moving forward. “We have no idea what AI will be capable of in the next 10 years,” she posted last month.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;And two weeks ago, Pete Buttigieg, President Biden’s transportation secretary, published a Substack post entitled “We Are Still Underreacting on AI.” “The terms of what it is like to be a human are about to change in ways that rival the transformations of the Enlightenment or the Industrial Revolution, only much more quickly,” he wrote.&lt;/p&gt;  &lt;p&gt;Wiener has noticed a shift among his peers. “More and more policymakers understand that we can’t just ignore this,” he says. But awareness is several steps short of effective legislation, and regulation opponents aren’t giving up the fight. The Trump administration is reportedly working on a slate of executive actions aimed at making more energy available for AI training and deployment, and Cruz says he is planning to introduce his own anti-regulation bill.&lt;/p&gt;  &lt;p&gt;Meanwhile, proponents of regulation will need to figure out how to channel the broad opposition to the moratorium into support for specific policies. It won’t be a simple task. “It’s easy for all of us to agree on what we don’t want,” Kak says. “The harder question is: What is it that we &lt;em&gt;do&lt;/em&gt; want?”&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/AP25099732252814.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;The “Big, Beautiful Bill” that President Donald Trump signed into law on July 4 was chock full of controversial policies—Medicaid work requirements, increased funding for ICE, and an end to tax credits for clean energy and vehicles, to name just a few. But one highly contested provision was missing. Just days earlier, during a late-night voting session, the Senate had killed the bill’s 10-year moratorium on state-level AI regulation.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“We really dodged a bullet,” says Scott Wiener, a California state senator and the author of SB 1047, a bill that would have made companies liable for harms caused by large AI models. It was vetoed by Governor Gavin Newsom last year, but Wiener is now working to pass SB 53, which establishes whistleblower protections for employees of AI companies. Had the federal AI regulation moratorium passed, he says, that bill likely would have been dead.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The moratorium could also have killed laws that have already been adopted around the country, including a Colorado law that targets algorithmic discrimination, laws in Utah and California aimed at making AI-generated content more identifiable, and other legislation focused on preserving data privacy and keeping children safe online. Proponents of the moratorium, such OpenAI and Senator Ted Cruz, have said that a “patchwork” of state-level regulations would place an undue burden on technology companies and stymie innovation. Federal regulation, they argue, is a better approach—but there is currently no federal AI regulation in place.&lt;/p&gt;  &lt;p&gt;Wiener and other state lawmakers can now get back to work writing and passing AI policy, at least for the time being—with the tailwind of a major moral victory at their backs. The movement to defeat the moratorium was impressively bipartisan: 40 state attorneys general signed a letter to Congress opposing the measure, as did a group of over 250 Republican and Democratic state lawmakers. And while congressional Democrats were united against the moratorium, the final nail in its coffin was hammered in by Senator Marsha Blackburn of Tennessee, a Tea Party conservative and Trump ally who backed out of a compromise with Cruz at the eleventh hour.&lt;/p&gt; 
 &lt;p&gt;The moratorium fight may have signaled a bigger political shift. “In the last few months, we’ve seen a much broader and more diverse coalition form in support of AI regulation generally,” says Amba Kak, co–executive director of the AI Now Institute. After years of relative inaction, politicians are getting concerned about the risks of unregulated artificial intelligence.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Granted, there’s an argument to be made that the moratorium’s defeat was highly contingent. Blackburn appears to have been motivated almost entirely by concerns about children’s online safety and the rights of country musicians to control their own likenesses; state lawmakers, meanwhile, were affronted by the federal government’s attempt to defang legislation that they had already passed. &lt;/p&gt; 
 &lt;p&gt;And even though powerful technology firms such as Andreessen Horowitz and OpenAI reportedly lobbied in favor of the moratorium, continuing to push for it might not have been worth it to the Trump administration and its allies—at least not at the expense of tax breaks and entitlement cuts. Baobao Zhang, an associate professor of political science at Syracuse University, says that the administration may have been willing to give up on the moratorium in order to push through the rest of the bill by its self-imposed Independence Day deadline.&lt;/p&gt;  &lt;p&gt;Andreessen Horowitz did not respond to a request for comment. OpenAI noted that the company was opposed to a state-by-state approach to AI regulation but did not respond to specific questions regarding the moratorium’s defeat.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It’s almost certainly the case that the moratorium’s breadth, as well as its decade-long duration, helped opponents marshall a diverse coalition to their side. But that breadth isn’t incidental—it’s related to the very nature of AI. Blackburn, who represents country musicians in Nashville, and Wiener, who represents software developers in San Francisco, have a shared interest in AI regulation precisely because such a powerful and general-purpose tool has the potential to affect so many people’s well-being and livelihood. “There are real anxieties that are touching people of all classes,” Kak says. “It’s creating solidarities that maybe didn’t exist before.”&lt;/p&gt;  &lt;p&gt;Faced with outspoken advocates, concerned constituents, and the constant buzz of AI discourse, politicians from both sides of the aisle are starting to argue for taking AI extremely seriously. One of the most prominent anti-moratorium voices was Marjorie Taylor Greene, who voted for the version of the bill containing the moratorium before admitting that she hadn’t read it thoroughly and committing to opposing the moratorium moving forward. “We have no idea what AI will be capable of in the next 10 years,” she posted last month.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;And two weeks ago, Pete Buttigieg, President Biden’s transportation secretary, published a Substack post entitled “We Are Still Underreacting on AI.” “The terms of what it is like to be a human are about to change in ways that rival the transformations of the Enlightenment or the Industrial Revolution, only much more quickly,” he wrote.&lt;/p&gt;  &lt;p&gt;Wiener has noticed a shift among his peers. “More and more policymakers understand that we can’t just ignore this,” he says. But awareness is several steps short of effective legislation, and regulation opponents aren’t giving up the fight. The Trump administration is reportedly working on a slate of executive actions aimed at making more energy available for AI training and deployment, and Cruz says he is planning to introduce his own anti-regulation bill.&lt;/p&gt;  &lt;p&gt;Meanwhile, proponents of regulation will need to figure out how to channel the broad opposition to the moratorium into support for specific policies. It won’t be a simple task. “It’s easy for all of us to agree on what we don’t want,” Kak says. “The harder question is: What is it that we &lt;em&gt;do&lt;/em&gt; want?”&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/09/1119867/why-the-ai-moratoriums-defeat-may-signal-a-new-political-era/</guid><pubDate>Wed, 09 Jul 2025 09:00:00 +0000</pubDate></item><item><title>Inside OpenAI’s empire: A conversation with Karen Hao (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/09/1119784/inside-openais-empire-a-conversation-with-karen-hao/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/MITTR-Roundtables-Video-Library-Thumbnail.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;Hello, everyone, and welcome to this special edition of Roundtables. These are our subscriber-only events where you get to listen in to conversations between editors and reporters. Now, I’m delighted to say we’ve got an absolute cracker of an event today. I’m very happy to have our prodigal daughter, Karen Hao, a fabulous AI journalist, here with us to talk about her new book. Hello, Karen, how are you doing?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;Good. Thank you so much for having me back, Niall.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Niall Firth:&lt;/strong&gt; Lovely to have you. So I’m sure you all know Karen and that’s why you’re here. But to give you a quick, quick synopsis, Karen has a degree in mechanical engineering from MIT. She was &lt;em&gt;MIT Technology Review&lt;/em&gt;’s senior editor for AI and has won countless awards, been cited in Congress, written for the &lt;em&gt;Wall Street Journal&lt;/em&gt; and &lt;em&gt;The Atlantic,&lt;/em&gt; and set up a series at the Pulitzer Center to teach journalists how to cover AI.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But most important of all, she’s here to discuss her new book, which I’ve got a copy of here, &lt;em&gt;Empire of AI.&lt;/em&gt; The UK version is subtitled “Inside the reckless race for total domination,” and the US one, I believe, is “Dreams and nightmares in Sam Altman’s OpenAI.”&lt;/p&gt; 
 &lt;p&gt;It’s been an absolute sensation, a &lt;em&gt;New York Times&lt;/em&gt; chart topper. An incredible feat of reporting—like 300 interviews, including 90 with people inside OpenAI. And it’s a brilliant look at not just OpenAI’s rise, and the character of Sam Altman, which is very interesting in its own right, but also a really astute look at what kind of AI we’re building and who holds the keys.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Karen, the core of the book, the rise and rise of OpenAI, was one of your first big features at &lt;em&gt;MIT Technology Review&lt;/em&gt;&lt;em&gt;.&lt;/em&gt; It’s a brilliant story that lifted the lid for the first time on what was going on at OpenAI … and they really hated it, right?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao:&lt;/strong&gt; Yes, and first of all, thank you to everyone for being here. It’s always great to be home. I do still consider &lt;em&gt;MIT Tech Review&lt;/em&gt; to be my journalistic home, and that story was—I only did it because Niall assigned it after I said, “Hey, it seems like OpenAI is kind of an interesting thing,” and he was like, you should profile them. And I had never written a profile about a company before, and I didn’t think that I would have it in me, and Niall believed that I would be able to do it. So it really didn’t happen other than because of you.&lt;/p&gt;  &lt;p&gt;I went into the piece with an open mind about—let me understand what OpenAI is. Let me take what they say at face value. They were founded as a nonprofit. They have this mission to ensure artificial general intelligence benefits all of humanity. What do they mean by that? How are they trying to achieve that ultimately? How are they striking this balance between mission-driven AI development and the need to raise money and capital?&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;And through the course of embedding within the company for three days, and then interviewing dozens of people outside the company or around the company … I came to realize that there was a fundamental disconnect between what they were publicly espousing and accumulating a lot of goodwill from and how they were operating. And that is what I ended up focusing my profile on, and that is why they were not very pleased.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;And how have you seen OpenAI change even since you did the profile? That sort of misalignment feels like it’s got messier and more confusing in the years since.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;Absolutely. I mean, it’s kind of remarkable that OpenAI, you could argue that they are now one of the most capitalistic corporations in Silicon Valley. They just raised $40 billion, in the largest-ever private fundraising round in tech industry history. They’re valued at $300 billion. And yet they still say that they are first and foremost a nonprofit.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I think this really gets to the heart of how much OpenAI has tried to position and reposition itself throughout its decade-long history, to ultimately play into the narratives that they think are going to do best with the public and with policymakers, in spite of what they might actually be doing in terms of developing their technologies and commercializing them.&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;Niall Firth:&lt;/strong&gt; You cite Sam Altman saying, you know, the race for AGI is what motivated a lot of this, and I’ll come back to that a bit before the end. But he talks about it as like the Manhattan Project for AI. You cite him quoting Oppenheimer (of course, you know, there’s no self-aggrandizing there): “Technology happens because it’s possible,” he says in the book.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And it feels to me like this is one of the themes of the book: the idea that technology doesn’t just happen because it comes along. It comes because of choices that people make. It’s not an inevitability that things are the way they are and that people are who they are. What they think is important—that influences the direction of travel. So what does this mean, in practice, if that’s the case?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;With OpenAI in particular, they made a very key decision early on in their history that led to all of the AI technologies that we see dominating the marketplace and dominating headlines today. And that was a decision to try and advance AI progress through scaling the existing techniques that were available to them. At the time when OpenAI started, at the end of 2015, and then, when they made that decision, in roughly around 2017, this was a very unpopular perspective within the broader AI research field.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;There were kind of two competing ideas about how to advance AI progress, or rather a spectrum of ideas, bookended by two extremes. One extreme being, we have all the techniques we need, and we should just aggressively scale. And the other one being that we don’t actually have the techniques we need. We need to continue innovating and doing fundamental AI research to get more breakthroughs. And largely the field assumed that this side of the spectrum [focusing on fundamental AI research] was the most likely approach for getting advancements, but OpenAI was anomalously committed to the other extreme—this idea that we can just take neural networks and pump ever more data, and train on ever larger supercomputers, larger than have ever been built in history.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;The reason why they made that decision was because they were competing against Google, which had a dominant monopoly on AI talent. And OpenAI knew that they didn’t necessarily have the ability to beat Google simply by trying to get research breakthroughs. That’s a very hard path. When you’re doing fundamental research, you never really know when the breakthrough might appear. It’s not a very linear line of progress, but scaling is sort of linear. As long as you just pump more data and more compute, you can get gains. And so they thought, we can just do this faster than anyone else. And that’s the way that we’re going to leap ahead of Google. And it particularly aligned with Sam Altman’s skillset, as well, because he is a once-in-a-generation fundraising talent, and when you’re going for scale to advance AI models, the primary bottleneck is capital.&lt;/p&gt;  &lt;p&gt;And so it was kind of a great fit for what he had to offer, which is, he knows how to accumulate capital, and he knows how to accumulate it very quickly. So that is ultimately how you can see that technology is a product of human choices and human perspectives. And they’re the specific skills and strengths that that team had at the time for how they wanted to move forward.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;And to be fair, I mean, it works, right? It was amazing, fabulous. You know the breakthroughs that happened, GPT-2 to GPT-3, just from scale and data and compute, kind of were mind-blowing really, as we look back on it now.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao:&lt;/strong&gt; Yeah, it is remarkable how much it did work, because there was a lot of skepticism about the idea that scale could lead to the kind of technical progress that we’ve seen. But one of my biggest critiques of this particular approach is that there’s also an extraordinary amount of costs that come with this particular pathway to getting more advancements. And there are many different pathways to advancing AI, so we could have actually gotten all of these benefits, and moving forward, we could continue to get more benefits from AI, without actually engaging in a hugely consumptive, hugely costly approach to its development.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Niall Firth:&lt;/strong&gt; Yeah, so in terms of consumptive, that’s something we’ve touched on here quite recently at MIT Technology Review, like the energy costs of AI. The data center costs are absolutely extraordinary, right? Like the data behind it is incredible. And it’s only gonna get worse in the next few years if we continue down this path, right?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao:&lt;/strong&gt; Yeah … so first of all, everyone should read the series that &lt;em&gt;Tech Review&lt;/em&gt; put out, if you haven’t already, on the energy question, because it really does break down everything from what is the energy consumption of the smallest unit of interacting with these models, all the way up until the highest level.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;The number that I have seen a lot, and that I’ve been repeating, is there was a McKinsey report that was looking at if we continue to just look at the pace at which data centers and supercomputers are being built and scaled, in the next five years, we would have to add two to six times the amount of energy consumed by California onto the grid. And most of that will have to be serviced by fossil fuels, because these data centers and supercomputers have to run 24/7, so we cannot rely solely on renewable energy. We do not have enough nuclear power capacity to power these colossal pieces of infrastructure. And so we’re already accelerating the climate crisis.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And we’re also accelerating a public-health crisis, the pumping of thousands of tons of air pollutants into the air from coal plants that are having their lives extended and methane gas turbines that are being built in service of powering these data centers. And in addition to that, there’s also an acceleration of the freshwater crisis, because these pieces of infrastructure have to be cooled with freshwater resources. It has to be fresh water, because if it’s any other type of water, it corrodes the equipment, it leads to bacterial growth.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;And Bloomberg recently had a story that showed that two-thirds of these data centers are actually going into water-scarce areas, into places where the communities already do not have enough fresh water at their disposal. So that is one dimension of many that I refer to when I say, the extraordinary costs of this particular pathway for AI development.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth:&lt;/strong&gt; So in terms of costs and the extractive process of making AI, I wanted to give you the chance to talk about the other theme of the book, apart from just OpenAI’s explosion. It’s the colonial way of looking at the way AI is made: the empire. I’m saying this obviously because we’re here, but this is an idea that came out of reporting you started at &lt;em&gt;MIT Technology Review&lt;/em&gt; and then continued into the book. Tell us about how this framing helps us understand how AI is made now.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao:&lt;/strong&gt; Yeah, so this was a framing that I started thinking a lot about when I was working on the AI Colonialism series for &lt;em&gt;Tech Review.&lt;/em&gt; It was a series of stories that looked at the way that, pre-ChatGPT, the commercialization of AI and its deployment into the world was already leading to entrenchment of historical inequities into the present day.&lt;/p&gt;  &lt;p&gt;And one example was a story that was about how facial recognition companies were swarming into South Africa to try and harvest more data from South Africa during a time when they were getting criticized for the fact that their technologies did not accurately recognize black faces. And the deployment of those facial recognition technologies into South Africa, into the streets of Johannesburg, was leading to what South African scholars were calling a recreation of a digital apartheid—the controlling of black bodies, movement of black people.&lt;/p&gt; 
 &lt;p&gt;And this idea really haunted me for a really long time. Through my reporting in that series, there were so many examples that I kept hitting upon of this thesis, that the AI industry was perpetuating. It felt like it was becoming this neocolonial force. And then, when ChatGPT came out, it became clear that this was just accelerating.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;When you accelerate the scale of these technologies, and you start training them on the entirety of the Internet, and you start using these supercomputers that are the size of dozens—if not hundreds—of football fields. Then you really start talking about an extraordinary global level of extraction and exploitation that is happening to produce these technologies. And then the historical power imbalances become even more obvious.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;p&gt;And so there are four parallels that I draw in my book between what I have now termed empires of AI versus empires of old. The first one is that empires lay claim to resources that are not their own. So these companies are scraping all this data that is not their own, taking all the intellectual property that is not their own.&lt;/p&gt;  &lt;p&gt;The second is that empires exploit a lot of labor. So we see them moving to countries in the Global South or other economically vulnerable communities to contract workers to do some of the worst work in the development pipeline for producing these technologies—and also producing technologies that then inherently are labor-automating and engage in labor exploitation in and of themselves.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_14"&gt; &lt;p&gt;And the third feature is that the empires monopolize knowledge production. So, in the last 10 years, we’ve seen the AI industry monopolize more and more of the AI researchers in the world. So AI researchers are no longer contributing to open science, working in universities or independent institutions, and the effect on the research is what you would imagine would happen if most of the climate scientists in the world were being bankrolled by oil and gas companies. You would not be getting a clear picture, and we are not getting a clear picture, of the limitations of these technologies, or if there are better ways to develop these technologies.&lt;/p&gt;  &lt;p&gt;And the fourth and final feature is that empires always engage in this aggressive race rhetoric, where there are good empires and evil empires. And they, the good empire, have to be strong enough to beat back the evil empire, and that is why they should have unfettered license to consume all of these resources and exploit all of this labor. And if the evil empire gets the technology first, humanity goes to hell. But if the good empire gets the technology first, they’ll civilize the world, and humanity gets to go to heaven. So on many different levels, like the empire theme, I felt like it was the most comprehensive way to name exactly how these companies operate, and exactly what their impacts are on the world.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth:&lt;/strong&gt; Yeah, brilliant. I mean, you talk about the evil empire. What happens if the evil empire gets it first? And what I mentioned at the top is AGI. For me, it’s almost like the extra character in the book all the way through. It’s sort of looming over everything, like the ghost at the feast, sort of saying like, this is the thing that motivates everything at OpenAI. This is the thing we’ve got to get to before anyone else gets to it.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;There’s a bit in the book about how they’re talking internally at OpenAI, like, we’ve got to make sure that AGI is in US hands where it’s safe versus like anywhere else. And some of the international staff are openly like—that’s kind of a weird way to frame it, isn’t it? Why is the US version of AGI better than others?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;So tell us a bit about how it drives what they do. And AGI isn’t an inevitable fact that’s just happening anyway, is it? It’s not even a thing yet.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;There’s not even consensus around whether or not it’s even possible or what it even is. There was recently a &lt;em&gt;New York Times&lt;/em&gt; story by Cade Metz that was citing a survey of long-standing AI researchers in the field, and 75% of them still think that we don’t have the techniques yet for reaching AGI, whatever that means. And the most classic definition or understanding of what AGI is, is being able to fully recreate human intelligence in software. But the problem is, we also don’t have scientific consensus around what human intelligence is. And so one of the aspects that I talk about a lot in the book is that, when there is a vacuum of shared meaning around this term, and what it would look like, when would we have arrived at it? What capabilities should we be evaluating these systems on to determine that we’ve gotten there? It can basically just be whatever OpenAI wants.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;So it’s kind of just this ever-present goalpost that keeps shifting, depending on where the company wants to go. You know, they have a full range, a variety of different definitions that they’ve used throughout the years. In fact, they even have a joke internally: If you ask 13 OpenAI researchers what AGI is, you’ll get 15 definitions. So they are kind of self-aware that this is not really a real term and it doesn’t really have that much meaning.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But it does serve this purpose of creating a kind of quasi-religious fervor around what they’re doing, where people think that they have to keep driving towards this horizon, and that one day when they get there, it’s going to have a civilizationally transformative impact. And therefore, what else should you be working on in your life, but this? And who else should be working on it, but you?&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_16"&gt; &lt;p&gt;And so it is their justification not just for continuing to push and scale and consume all these resources—because none of that consumption, none of that harm matters anymore if you end up hitting this destination. But they also use it as a way to develop their technologies in a very deeply anti-democratic way, where they say, we are the only people that have the expertise, that have the right to carefully control the development of this technology and usher it into the world. And we cannot let anyone else participate because it’s just too powerful of a technology.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;You talk about the factions, particularly the religious framing. AGI has been around as a concept for a while—it was very niche, very kind of nerdy fun, really, to talk about—to suddenly become extremely mainstream. And they have the boomers versus doomers dichotomy. Where are you on that spectrum?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;So the boomers are people who think that AGI is going to bring us to utopia, and the doomers think AGI is going to devastate all of humanity. And to me these are actually two sides of the same coin. They both believe that AGI is possible, and it’s imminent, and it’s going to change everything.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And I am not on this spectrum. I’m in a third space, which is the AI accountability space, which is rooted in the observation that these companies have accumulated an extraordinary amount of power, both economic and political power, to go back to the empire analogy.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Ultimately, the thing that we need to do in order to not return to an age of empire and erode a lot of democratic norms is to hold these companies accountable with all the tools at our disposal, and to recognize all the harms that they are already perpetuating through a misguided approach to AI development.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;I’ve got a couple of questions from readers. I’m gonna try to pull them together a little bit because Abbas asks, what would post-imperial AI look like? And there was a question from Liam basically along the same lines. How do you make a more ethical version of AI that is not within this framework?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;We sort of already touched a little bit upon this idea. But there are so many different ways to develop AI. There are myriads of techniques throughout the history of AI development, which is decades long. There have been various shifts in the winds of which techniques ultimately rise and fall. And it isn’t based solely on the scientific or technical merit of any particular technique. Oftentimes certain techniques become more popular because of business reasons or because of the funder’s ideologies. And that’s sort of what we’re seeing today with the complete indexing of AI development on large-scale AI model development.&lt;/p&gt;  &lt;p&gt;And ultimately, these large-scale models … We talked about how it’s a remarkable technical leap, but in terms of social progress or economic progress, the benefits of these models have been kind of middling. And the way that I see us shifting to AI models that are going to be A) more beneficial and B) not so imperial is to refocus on task-specific AI systems that are tackling well-scoped challenges that inherently lend themselves to the strengths of AI systems that are inherently computational optimization problems.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_18"&gt; &lt;p&gt;So I’m talking about things like using AI to integrate more renewable energy into the grid. This is something that we definitely need. We need to more quickly accelerate our electrification of the grid, and one of the challenges of using more renewable energy is the unpredictability of it. And this is a key strength of AI technologies, being able to have predictive capabilities and optimization capabilities where you can match the energy generation of different renewables with the energy demands of different people that are drawing from the grid.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;Quite a few people have been asking, in the chat, different versions of the same question. If you were an early-career AI scientist, or if you were involved in AI, what can you do yourself to bring about a more ethical version of AI? Do you have any power left, or is it too late?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;No, I don’t think it’s too late at all. I mean, as I’ve been talking with a lot of people just in the lay public, one of the biggest challenges that they have is they don’t have any alternatives for AI. They want the benefits of AI, but they also do not want to participate in a supply chain that is really harmful. And so the first question is, always, is there an alternative? Which tools do I shift to? And unfortunately, there just aren’t that many alternatives right now.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And so the first thing that I would say to early-career AI researchers and entrepreneurs is to build those alternatives, because there are plenty of people that are actually really excited about the possibility of switching to more ethical alternatives. And one of the analogies I often use is that we kind of need to do with the AI industry what happened with the fashion industry. There was also a lot of environmental exploitation, labor exploitation in the fashion industry, and there was enough consumer demand that it created new markets for ethical and sustainably sourced fashion. And so we kind of need to see just more options occupying that space.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;Do you feel optimistic about the future? Or where do you sit? You know, things aren’t great as you spell them out now. Where’s the hope for us?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao:&lt;/strong&gt; I am. I’m super optimistic. Part of the reason why I’m optimistic is because you know, a few years ago, when I started writing about AI at &lt;em&gt;Tech Review,&lt;/em&gt; I remember people would say, wow, that’s a really niche beat. Do you have enough to write about?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And now, I mean, everyone is talking about AI, and I think that’s the first step to actually getting to a better place with AI development. The amount of public awareness and attention and scrutiny that is now going into how we develop these technologies, how we use these technologies, is really, really important. Like, we need to be having this public debate and that in and of itself is a significant step change from what we had before.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But the next step, and part of the reason why I wrote this book, is we need to convert the awareness into action, and people should take an active role. Every single person should feel that they have an active role in shaping the future of AI development, if you think about all of the different ways that you interface with the AI development supply chain and deployment supply chain—like you give your data or withhold your data.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_20"&gt; &lt;p&gt;There are probably data centers that are being built around you right now. If you’re a parent, there’s some kind of AI policy being crafted at [your kid’s] school. There’s some kind of AI policy being crafted at your workplace. These are all what I consider sites of democratic contestation, where you can use those opportunities to assert your voice about how you want AI to be developed and deployed. If you do not want these companies to use certain kinds of data, push back when they just take the data.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I closed all of my personal social media accounts because I just did not like the fact that they were scraping my personal photos to train their generative AI models. I’ve seen parents and students and teachers start forming committees within schools to talk about what their AI policy should be and to draft it collectively as a community. Same with businesses. They’re doing the same thing. If we all kind of step up to play that active role, I am super optimistic that we’ll get to a better place.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth:&lt;/strong&gt; Mark, in the chat, mentions the Māori story from New Zealand towards the end of your book, and that’s an example of sort of community-led AI in action, isn’t it?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;Yeah. There was a community in New Zealand that really wanted to help revitalize the Māori language by building a speech recognition tool that could recognize Māori, and therefore be able to transcribe a rich repository of archival audio of their ancestors speaking Māori. And the first thing that they did when engaging in that project was they asked the community, do you want this AI tool?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth:&lt;/strong&gt; Imagine that.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;I know! It’s such a radical concept, this idea of consent at every stage. But they first asked that; the community wholeheartedly said yes. They then engaged in a public education campaign to explain to people, okay, what does it take to develop an AI tool? Well, we are going to need data. We’re going to need audio transcription pairs to train this AI model. So then they ran a public contest in which they were able to get dozens, if not hundreds, of people in their community to donate data to this project. And then they made sure that when they developed the model, they actively explained to the community at every step how their data was being used, how it would be stored, how it would continue to be protected. And any other project that would use the data has to get permission and consent from the community first.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_22"&gt; &lt;p&gt;And so it was a completely democratic process, for whether they wanted the tool, how to develop the tool, and how the tool should continue to be used, and how their data should continue to be used over time.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;Great. I know we’ve gone a bit over time. I’ve got two more things I’m going to ask you, basically putting together lots of questions people have asked in the chat about your view on what role regulations should play. What are your thoughts on that?&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_24"&gt;&lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;Yeah, I mean, in an ideal world where we actually had a functioning government, regulation should absolutely play a huge role. And it shouldn’t just be thinking about once an AI model is built, how to regulate that. But still thinking about the full supply chain of AI development, regulating the data and what’s allowed to be trained in these models, regulating the land use. And what pieces of land are allowed to build data centers? How much energy and water are the data centers allowed to consume? And also regulating the transparency. We don’t know what data is in these training data sets, and we don’t know the environmental costs of training these models. We don’t know how much water these data centers consume and that is all information that these companies actively withhold to prevent democratic processes from happening. So if there were one major intervention that regulators could have, it should be to dramatically increase the amount of transparency along the supply chain.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;Okay, great. So just to bring it back around to OpenAI and Sam Altman to finish with. He famously sent an email around, didn’t he? After your original &lt;em&gt;Tech Review&lt;/em&gt; story, saying this is not great. We don’t like this. And he didn’t want to speak to you for your book, either, did he?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao:&lt;/strong&gt; No, he did not.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;No. But imagine Sam Altman is in the chat here. He’s subscribed to &lt;em&gt;Technology Review&lt;/em&gt; and is watching this Roundtables because he wants to know what you’re saying about him. If you could talk to him directly, what would you like to ask him?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao:&lt;/strong&gt; What degree of harm do you need to see in order to realize that you should take a different path?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;Nice, blunt, to the point. All right, Karen, thank you so much for your time.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;Thank you so much, everyone.&lt;/p&gt;  &lt;p&gt;MIT Technology Review Roundtables is a subscriber-only online event series where experts discuss the latest developments and what’s next in emerging technologies. Sign up to get notified about upcoming sessions.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/MITTR-Roundtables-Video-Library-Thumbnail.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;Hello, everyone, and welcome to this special edition of Roundtables. These are our subscriber-only events where you get to listen in to conversations between editors and reporters. Now, I’m delighted to say we’ve got an absolute cracker of an event today. I’m very happy to have our prodigal daughter, Karen Hao, a fabulous AI journalist, here with us to talk about her new book. Hello, Karen, how are you doing?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;Good. Thank you so much for having me back, Niall.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Niall Firth:&lt;/strong&gt; Lovely to have you. So I’m sure you all know Karen and that’s why you’re here. But to give you a quick, quick synopsis, Karen has a degree in mechanical engineering from MIT. She was &lt;em&gt;MIT Technology Review&lt;/em&gt;’s senior editor for AI and has won countless awards, been cited in Congress, written for the &lt;em&gt;Wall Street Journal&lt;/em&gt; and &lt;em&gt;The Atlantic,&lt;/em&gt; and set up a series at the Pulitzer Center to teach journalists how to cover AI.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But most important of all, she’s here to discuss her new book, which I’ve got a copy of here, &lt;em&gt;Empire of AI.&lt;/em&gt; The UK version is subtitled “Inside the reckless race for total domination,” and the US one, I believe, is “Dreams and nightmares in Sam Altman’s OpenAI.”&lt;/p&gt; 
 &lt;p&gt;It’s been an absolute sensation, a &lt;em&gt;New York Times&lt;/em&gt; chart topper. An incredible feat of reporting—like 300 interviews, including 90 with people inside OpenAI. And it’s a brilliant look at not just OpenAI’s rise, and the character of Sam Altman, which is very interesting in its own right, but also a really astute look at what kind of AI we’re building and who holds the keys.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Karen, the core of the book, the rise and rise of OpenAI, was one of your first big features at &lt;em&gt;MIT Technology Review&lt;/em&gt;&lt;em&gt;.&lt;/em&gt; It’s a brilliant story that lifted the lid for the first time on what was going on at OpenAI … and they really hated it, right?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao:&lt;/strong&gt; Yes, and first of all, thank you to everyone for being here. It’s always great to be home. I do still consider &lt;em&gt;MIT Tech Review&lt;/em&gt; to be my journalistic home, and that story was—I only did it because Niall assigned it after I said, “Hey, it seems like OpenAI is kind of an interesting thing,” and he was like, you should profile them. And I had never written a profile about a company before, and I didn’t think that I would have it in me, and Niall believed that I would be able to do it. So it really didn’t happen other than because of you.&lt;/p&gt;  &lt;p&gt;I went into the piece with an open mind about—let me understand what OpenAI is. Let me take what they say at face value. They were founded as a nonprofit. They have this mission to ensure artificial general intelligence benefits all of humanity. What do they mean by that? How are they trying to achieve that ultimately? How are they striking this balance between mission-driven AI development and the need to raise money and capital?&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;And through the course of embedding within the company for three days, and then interviewing dozens of people outside the company or around the company … I came to realize that there was a fundamental disconnect between what they were publicly espousing and accumulating a lot of goodwill from and how they were operating. And that is what I ended up focusing my profile on, and that is why they were not very pleased.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;And how have you seen OpenAI change even since you did the profile? That sort of misalignment feels like it’s got messier and more confusing in the years since.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;Absolutely. I mean, it’s kind of remarkable that OpenAI, you could argue that they are now one of the most capitalistic corporations in Silicon Valley. They just raised $40 billion, in the largest-ever private fundraising round in tech industry history. They’re valued at $300 billion. And yet they still say that they are first and foremost a nonprofit.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I think this really gets to the heart of how much OpenAI has tried to position and reposition itself throughout its decade-long history, to ultimately play into the narratives that they think are going to do best with the public and with policymakers, in spite of what they might actually be doing in terms of developing their technologies and commercializing them.&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;Niall Firth:&lt;/strong&gt; You cite Sam Altman saying, you know, the race for AGI is what motivated a lot of this, and I’ll come back to that a bit before the end. But he talks about it as like the Manhattan Project for AI. You cite him quoting Oppenheimer (of course, you know, there’s no self-aggrandizing there): “Technology happens because it’s possible,” he says in the book.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And it feels to me like this is one of the themes of the book: the idea that technology doesn’t just happen because it comes along. It comes because of choices that people make. It’s not an inevitability that things are the way they are and that people are who they are. What they think is important—that influences the direction of travel. So what does this mean, in practice, if that’s the case?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;With OpenAI in particular, they made a very key decision early on in their history that led to all of the AI technologies that we see dominating the marketplace and dominating headlines today. And that was a decision to try and advance AI progress through scaling the existing techniques that were available to them. At the time when OpenAI started, at the end of 2015, and then, when they made that decision, in roughly around 2017, this was a very unpopular perspective within the broader AI research field.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;There were kind of two competing ideas about how to advance AI progress, or rather a spectrum of ideas, bookended by two extremes. One extreme being, we have all the techniques we need, and we should just aggressively scale. And the other one being that we don’t actually have the techniques we need. We need to continue innovating and doing fundamental AI research to get more breakthroughs. And largely the field assumed that this side of the spectrum [focusing on fundamental AI research] was the most likely approach for getting advancements, but OpenAI was anomalously committed to the other extreme—this idea that we can just take neural networks and pump ever more data, and train on ever larger supercomputers, larger than have ever been built in history.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;The reason why they made that decision was because they were competing against Google, which had a dominant monopoly on AI talent. And OpenAI knew that they didn’t necessarily have the ability to beat Google simply by trying to get research breakthroughs. That’s a very hard path. When you’re doing fundamental research, you never really know when the breakthrough might appear. It’s not a very linear line of progress, but scaling is sort of linear. As long as you just pump more data and more compute, you can get gains. And so they thought, we can just do this faster than anyone else. And that’s the way that we’re going to leap ahead of Google. And it particularly aligned with Sam Altman’s skillset, as well, because he is a once-in-a-generation fundraising talent, and when you’re going for scale to advance AI models, the primary bottleneck is capital.&lt;/p&gt;  &lt;p&gt;And so it was kind of a great fit for what he had to offer, which is, he knows how to accumulate capital, and he knows how to accumulate it very quickly. So that is ultimately how you can see that technology is a product of human choices and human perspectives. And they’re the specific skills and strengths that that team had at the time for how they wanted to move forward.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;And to be fair, I mean, it works, right? It was amazing, fabulous. You know the breakthroughs that happened, GPT-2 to GPT-3, just from scale and data and compute, kind of were mind-blowing really, as we look back on it now.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao:&lt;/strong&gt; Yeah, it is remarkable how much it did work, because there was a lot of skepticism about the idea that scale could lead to the kind of technical progress that we’ve seen. But one of my biggest critiques of this particular approach is that there’s also an extraordinary amount of costs that come with this particular pathway to getting more advancements. And there are many different pathways to advancing AI, so we could have actually gotten all of these benefits, and moving forward, we could continue to get more benefits from AI, without actually engaging in a hugely consumptive, hugely costly approach to its development.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Niall Firth:&lt;/strong&gt; Yeah, so in terms of consumptive, that’s something we’ve touched on here quite recently at MIT Technology Review, like the energy costs of AI. The data center costs are absolutely extraordinary, right? Like the data behind it is incredible. And it’s only gonna get worse in the next few years if we continue down this path, right?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao:&lt;/strong&gt; Yeah … so first of all, everyone should read the series that &lt;em&gt;Tech Review&lt;/em&gt; put out, if you haven’t already, on the energy question, because it really does break down everything from what is the energy consumption of the smallest unit of interacting with these models, all the way up until the highest level.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;The number that I have seen a lot, and that I’ve been repeating, is there was a McKinsey report that was looking at if we continue to just look at the pace at which data centers and supercomputers are being built and scaled, in the next five years, we would have to add two to six times the amount of energy consumed by California onto the grid. And most of that will have to be serviced by fossil fuels, because these data centers and supercomputers have to run 24/7, so we cannot rely solely on renewable energy. We do not have enough nuclear power capacity to power these colossal pieces of infrastructure. And so we’re already accelerating the climate crisis.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And we’re also accelerating a public-health crisis, the pumping of thousands of tons of air pollutants into the air from coal plants that are having their lives extended and methane gas turbines that are being built in service of powering these data centers. And in addition to that, there’s also an acceleration of the freshwater crisis, because these pieces of infrastructure have to be cooled with freshwater resources. It has to be fresh water, because if it’s any other type of water, it corrodes the equipment, it leads to bacterial growth.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;And Bloomberg recently had a story that showed that two-thirds of these data centers are actually going into water-scarce areas, into places where the communities already do not have enough fresh water at their disposal. So that is one dimension of many that I refer to when I say, the extraordinary costs of this particular pathway for AI development.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth:&lt;/strong&gt; So in terms of costs and the extractive process of making AI, I wanted to give you the chance to talk about the other theme of the book, apart from just OpenAI’s explosion. It’s the colonial way of looking at the way AI is made: the empire. I’m saying this obviously because we’re here, but this is an idea that came out of reporting you started at &lt;em&gt;MIT Technology Review&lt;/em&gt; and then continued into the book. Tell us about how this framing helps us understand how AI is made now.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao:&lt;/strong&gt; Yeah, so this was a framing that I started thinking a lot about when I was working on the AI Colonialism series for &lt;em&gt;Tech Review.&lt;/em&gt; It was a series of stories that looked at the way that, pre-ChatGPT, the commercialization of AI and its deployment into the world was already leading to entrenchment of historical inequities into the present day.&lt;/p&gt;  &lt;p&gt;And one example was a story that was about how facial recognition companies were swarming into South Africa to try and harvest more data from South Africa during a time when they were getting criticized for the fact that their technologies did not accurately recognize black faces. And the deployment of those facial recognition technologies into South Africa, into the streets of Johannesburg, was leading to what South African scholars were calling a recreation of a digital apartheid—the controlling of black bodies, movement of black people.&lt;/p&gt; 
 &lt;p&gt;And this idea really haunted me for a really long time. Through my reporting in that series, there were so many examples that I kept hitting upon of this thesis, that the AI industry was perpetuating. It felt like it was becoming this neocolonial force. And then, when ChatGPT came out, it became clear that this was just accelerating.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;When you accelerate the scale of these technologies, and you start training them on the entirety of the Internet, and you start using these supercomputers that are the size of dozens—if not hundreds—of football fields. Then you really start talking about an extraordinary global level of extraction and exploitation that is happening to produce these technologies. And then the historical power imbalances become even more obvious.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;p&gt;And so there are four parallels that I draw in my book between what I have now termed empires of AI versus empires of old. The first one is that empires lay claim to resources that are not their own. So these companies are scraping all this data that is not their own, taking all the intellectual property that is not their own.&lt;/p&gt;  &lt;p&gt;The second is that empires exploit a lot of labor. So we see them moving to countries in the Global South or other economically vulnerable communities to contract workers to do some of the worst work in the development pipeline for producing these technologies—and also producing technologies that then inherently are labor-automating and engage in labor exploitation in and of themselves.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_14"&gt; &lt;p&gt;And the third feature is that the empires monopolize knowledge production. So, in the last 10 years, we’ve seen the AI industry monopolize more and more of the AI researchers in the world. So AI researchers are no longer contributing to open science, working in universities or independent institutions, and the effect on the research is what you would imagine would happen if most of the climate scientists in the world were being bankrolled by oil and gas companies. You would not be getting a clear picture, and we are not getting a clear picture, of the limitations of these technologies, or if there are better ways to develop these technologies.&lt;/p&gt;  &lt;p&gt;And the fourth and final feature is that empires always engage in this aggressive race rhetoric, where there are good empires and evil empires. And they, the good empire, have to be strong enough to beat back the evil empire, and that is why they should have unfettered license to consume all of these resources and exploit all of this labor. And if the evil empire gets the technology first, humanity goes to hell. But if the good empire gets the technology first, they’ll civilize the world, and humanity gets to go to heaven. So on many different levels, like the empire theme, I felt like it was the most comprehensive way to name exactly how these companies operate, and exactly what their impacts are on the world.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth:&lt;/strong&gt; Yeah, brilliant. I mean, you talk about the evil empire. What happens if the evil empire gets it first? And what I mentioned at the top is AGI. For me, it’s almost like the extra character in the book all the way through. It’s sort of looming over everything, like the ghost at the feast, sort of saying like, this is the thing that motivates everything at OpenAI. This is the thing we’ve got to get to before anyone else gets to it.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;There’s a bit in the book about how they’re talking internally at OpenAI, like, we’ve got to make sure that AGI is in US hands where it’s safe versus like anywhere else. And some of the international staff are openly like—that’s kind of a weird way to frame it, isn’t it? Why is the US version of AGI better than others?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;So tell us a bit about how it drives what they do. And AGI isn’t an inevitable fact that’s just happening anyway, is it? It’s not even a thing yet.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;There’s not even consensus around whether or not it’s even possible or what it even is. There was recently a &lt;em&gt;New York Times&lt;/em&gt; story by Cade Metz that was citing a survey of long-standing AI researchers in the field, and 75% of them still think that we don’t have the techniques yet for reaching AGI, whatever that means. And the most classic definition or understanding of what AGI is, is being able to fully recreate human intelligence in software. But the problem is, we also don’t have scientific consensus around what human intelligence is. And so one of the aspects that I talk about a lot in the book is that, when there is a vacuum of shared meaning around this term, and what it would look like, when would we have arrived at it? What capabilities should we be evaluating these systems on to determine that we’ve gotten there? It can basically just be whatever OpenAI wants.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;So it’s kind of just this ever-present goalpost that keeps shifting, depending on where the company wants to go. You know, they have a full range, a variety of different definitions that they’ve used throughout the years. In fact, they even have a joke internally: If you ask 13 OpenAI researchers what AGI is, you’ll get 15 definitions. So they are kind of self-aware that this is not really a real term and it doesn’t really have that much meaning.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But it does serve this purpose of creating a kind of quasi-religious fervor around what they’re doing, where people think that they have to keep driving towards this horizon, and that one day when they get there, it’s going to have a civilizationally transformative impact. And therefore, what else should you be working on in your life, but this? And who else should be working on it, but you?&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_16"&gt; &lt;p&gt;And so it is their justification not just for continuing to push and scale and consume all these resources—because none of that consumption, none of that harm matters anymore if you end up hitting this destination. But they also use it as a way to develop their technologies in a very deeply anti-democratic way, where they say, we are the only people that have the expertise, that have the right to carefully control the development of this technology and usher it into the world. And we cannot let anyone else participate because it’s just too powerful of a technology.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;You talk about the factions, particularly the religious framing. AGI has been around as a concept for a while—it was very niche, very kind of nerdy fun, really, to talk about—to suddenly become extremely mainstream. And they have the boomers versus doomers dichotomy. Where are you on that spectrum?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;So the boomers are people who think that AGI is going to bring us to utopia, and the doomers think AGI is going to devastate all of humanity. And to me these are actually two sides of the same coin. They both believe that AGI is possible, and it’s imminent, and it’s going to change everything.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And I am not on this spectrum. I’m in a third space, which is the AI accountability space, which is rooted in the observation that these companies have accumulated an extraordinary amount of power, both economic and political power, to go back to the empire analogy.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Ultimately, the thing that we need to do in order to not return to an age of empire and erode a lot of democratic norms is to hold these companies accountable with all the tools at our disposal, and to recognize all the harms that they are already perpetuating through a misguided approach to AI development.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;I’ve got a couple of questions from readers. I’m gonna try to pull them together a little bit because Abbas asks, what would post-imperial AI look like? And there was a question from Liam basically along the same lines. How do you make a more ethical version of AI that is not within this framework?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;We sort of already touched a little bit upon this idea. But there are so many different ways to develop AI. There are myriads of techniques throughout the history of AI development, which is decades long. There have been various shifts in the winds of which techniques ultimately rise and fall. And it isn’t based solely on the scientific or technical merit of any particular technique. Oftentimes certain techniques become more popular because of business reasons or because of the funder’s ideologies. And that’s sort of what we’re seeing today with the complete indexing of AI development on large-scale AI model development.&lt;/p&gt;  &lt;p&gt;And ultimately, these large-scale models … We talked about how it’s a remarkable technical leap, but in terms of social progress or economic progress, the benefits of these models have been kind of middling. And the way that I see us shifting to AI models that are going to be A) more beneficial and B) not so imperial is to refocus on task-specific AI systems that are tackling well-scoped challenges that inherently lend themselves to the strengths of AI systems that are inherently computational optimization problems.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_18"&gt; &lt;p&gt;So I’m talking about things like using AI to integrate more renewable energy into the grid. This is something that we definitely need. We need to more quickly accelerate our electrification of the grid, and one of the challenges of using more renewable energy is the unpredictability of it. And this is a key strength of AI technologies, being able to have predictive capabilities and optimization capabilities where you can match the energy generation of different renewables with the energy demands of different people that are drawing from the grid.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;Quite a few people have been asking, in the chat, different versions of the same question. If you were an early-career AI scientist, or if you were involved in AI, what can you do yourself to bring about a more ethical version of AI? Do you have any power left, or is it too late?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;No, I don’t think it’s too late at all. I mean, as I’ve been talking with a lot of people just in the lay public, one of the biggest challenges that they have is they don’t have any alternatives for AI. They want the benefits of AI, but they also do not want to participate in a supply chain that is really harmful. And so the first question is, always, is there an alternative? Which tools do I shift to? And unfortunately, there just aren’t that many alternatives right now.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And so the first thing that I would say to early-career AI researchers and entrepreneurs is to build those alternatives, because there are plenty of people that are actually really excited about the possibility of switching to more ethical alternatives. And one of the analogies I often use is that we kind of need to do with the AI industry what happened with the fashion industry. There was also a lot of environmental exploitation, labor exploitation in the fashion industry, and there was enough consumer demand that it created new markets for ethical and sustainably sourced fashion. And so we kind of need to see just more options occupying that space.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;Do you feel optimistic about the future? Or where do you sit? You know, things aren’t great as you spell them out now. Where’s the hope for us?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao:&lt;/strong&gt; I am. I’m super optimistic. Part of the reason why I’m optimistic is because you know, a few years ago, when I started writing about AI at &lt;em&gt;Tech Review,&lt;/em&gt; I remember people would say, wow, that’s a really niche beat. Do you have enough to write about?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And now, I mean, everyone is talking about AI, and I think that’s the first step to actually getting to a better place with AI development. The amount of public awareness and attention and scrutiny that is now going into how we develop these technologies, how we use these technologies, is really, really important. Like, we need to be having this public debate and that in and of itself is a significant step change from what we had before.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But the next step, and part of the reason why I wrote this book, is we need to convert the awareness into action, and people should take an active role. Every single person should feel that they have an active role in shaping the future of AI development, if you think about all of the different ways that you interface with the AI development supply chain and deployment supply chain—like you give your data or withhold your data.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_20"&gt; &lt;p&gt;There are probably data centers that are being built around you right now. If you’re a parent, there’s some kind of AI policy being crafted at [your kid’s] school. There’s some kind of AI policy being crafted at your workplace. These are all what I consider sites of democratic contestation, where you can use those opportunities to assert your voice about how you want AI to be developed and deployed. If you do not want these companies to use certain kinds of data, push back when they just take the data.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I closed all of my personal social media accounts because I just did not like the fact that they were scraping my personal photos to train their generative AI models. I’ve seen parents and students and teachers start forming committees within schools to talk about what their AI policy should be and to draft it collectively as a community. Same with businesses. They’re doing the same thing. If we all kind of step up to play that active role, I am super optimistic that we’ll get to a better place.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth:&lt;/strong&gt; Mark, in the chat, mentions the Māori story from New Zealand towards the end of your book, and that’s an example of sort of community-led AI in action, isn’t it?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;Yeah. There was a community in New Zealand that really wanted to help revitalize the Māori language by building a speech recognition tool that could recognize Māori, and therefore be able to transcribe a rich repository of archival audio of their ancestors speaking Māori. And the first thing that they did when engaging in that project was they asked the community, do you want this AI tool?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth:&lt;/strong&gt; Imagine that.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;I know! It’s such a radical concept, this idea of consent at every stage. But they first asked that; the community wholeheartedly said yes. They then engaged in a public education campaign to explain to people, okay, what does it take to develop an AI tool? Well, we are going to need data. We’re going to need audio transcription pairs to train this AI model. So then they ran a public contest in which they were able to get dozens, if not hundreds, of people in their community to donate data to this project. And then they made sure that when they developed the model, they actively explained to the community at every step how their data was being used, how it would be stored, how it would continue to be protected. And any other project that would use the data has to get permission and consent from the community first.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_22"&gt; &lt;p&gt;And so it was a completely democratic process, for whether they wanted the tool, how to develop the tool, and how the tool should continue to be used, and how their data should continue to be used over time.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;Great. I know we’ve gone a bit over time. I’ve got two more things I’m going to ask you, basically putting together lots of questions people have asked in the chat about your view on what role regulations should play. What are your thoughts on that?&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_24"&gt;&lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;Yeah, I mean, in an ideal world where we actually had a functioning government, regulation should absolutely play a huge role. And it shouldn’t just be thinking about once an AI model is built, how to regulate that. But still thinking about the full supply chain of AI development, regulating the data and what’s allowed to be trained in these models, regulating the land use. And what pieces of land are allowed to build data centers? How much energy and water are the data centers allowed to consume? And also regulating the transparency. We don’t know what data is in these training data sets, and we don’t know the environmental costs of training these models. We don’t know how much water these data centers consume and that is all information that these companies actively withhold to prevent democratic processes from happening. So if there were one major intervention that regulators could have, it should be to dramatically increase the amount of transparency along the supply chain.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;Okay, great. So just to bring it back around to OpenAI and Sam Altman to finish with. He famously sent an email around, didn’t he? After your original &lt;em&gt;Tech Review&lt;/em&gt; story, saying this is not great. We don’t like this. And he didn’t want to speak to you for your book, either, did he?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao:&lt;/strong&gt; No, he did not.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;No. But imagine Sam Altman is in the chat here. He’s subscribed to &lt;em&gt;Technology Review&lt;/em&gt; and is watching this Roundtables because he wants to know what you’re saying about him. If you could talk to him directly, what would you like to ask him?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao:&lt;/strong&gt; What degree of harm do you need to see in order to realize that you should take a different path?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Niall Firth: &lt;/strong&gt;Nice, blunt, to the point. All right, Karen, thank you so much for your time.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Karen Hao: &lt;/strong&gt;Thank you so much, everyone.&lt;/p&gt;  &lt;p&gt;MIT Technology Review Roundtables is a subscriber-only online event series where experts discuss the latest developments and what’s next in emerging technologies. Sign up to get notified about upcoming sessions.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/09/1119784/inside-openais-empire-a-conversation-with-karen-hao/</guid><pubDate>Wed, 09 Jul 2025 09:10:29 +0000</pubDate></item><item><title>The Download: a conversation with Karen Hao, and how did life begin? (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/09/1119923/the-download-a-conversation-with-karen-hao-and-how-did-life-begin/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Inside OpenAI’s empire: A conversation with Karen Hao&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;In a wide-ranging Roundtables conversation for MIT Technology Review subscribers, journalist and author Karen Hao recently spoke about her new book, &lt;em&gt;Empire of AI: Dreams and Nightmares in Sam Altman’s OpenAI&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;She talked with executive editor Niall Firth about how she first covered the company in 2020 while on staff at MIT Technology Review. They discussed how the AI industry now functions like an empire and went on to examine what ethically-made AI looks like.&lt;/p&gt;&lt;p&gt;Read the transcript of the conversation, which has been lightly edited and condensed. And, if you’re already a subscriber, you can watch the on-demand recording of the event here.&amp;nbsp;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;MIT Technology Review Narrated: How did life begin?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;How life begins is one of the biggest and hardest questions in science. All we know is that something happened on Earth more than 3.5 billion years ago, and it may well have occurred on many other worlds in the universe as well. Could AI help us to unpick the mysteries around the origins of life and detect signs of it on other worlds?&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;This is our latest story to be turned into a MIT Technology Review Narrated podcast, which&amp;nbsp;&lt;br /&gt;we’re publishing each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it’s released.&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 xAI’s Grok went on an anti-Semitic rant&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Days after Elon Musk said new updates would lessen its reliance on mainstream media. (WP $)&lt;br /&gt;+ &lt;em&gt;The chatbot started to call itself ‘MechaHitler.’ &lt;/em&gt;(WSJ $)&lt;br /&gt;+ &lt;em&gt;What Grok’s neo-Nazi turn tells us about xAI. &lt;/em&gt;(The Atlantic $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;strong&gt;2 Musk loyalists are fighting to keep DOGE running&lt;/strong&gt;&lt;br /&gt;As officials seek to diminish the department’s role. (WSJ $)&lt;br /&gt;+ &lt;em&gt;DOGE’s tech takeover threatens the safety and stability of our critical data. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 An imposter used AI to successfully impersonate Marco Rubio&lt;/strong&gt;&lt;br /&gt;They were able to send voice and text messages to fellow politicians. (WP $)&lt;br /&gt;+ &lt;em&gt;It’s not the first time Rubio has been targeted like this. &lt;/em&gt;(FT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 Terrorist groups are using AI to recruit and plan&lt;/strong&gt;&lt;br /&gt;Counter-terror agencies are struggling to keep up. (The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 How the crypto faithful won over the President&lt;/strong&gt;&lt;br /&gt;The industry’s successful Trump courtship sparked a lobbying bonanza. (NYT $)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;6 Wanted: 115,000 Nvidia chips for China’s data centers&lt;br /&gt;&lt;/strong&gt;But the US doesn’t seem to know how many restricted chips are already in the country. (Bloomberg $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 For startups, protecting companies from AI threats isn’t big business&lt;br /&gt;&lt;/strong&gt;Smaller firms are only making modest gains—for now. (The Information $)&lt;br /&gt;+ &lt;em&gt;Cyberattacks by AI agents are coming. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 Inside Zimbabwe’s dangerous EV lithium mines&lt;br /&gt;&lt;/strong&gt;Many residents worry that China is exploiting them. (Rest of World)&lt;br /&gt;+ &lt;em&gt;How one mine could unlock billions in EV subsidies. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 ‘The Milk Guy’ is delivering raw dairy around NYC&lt;/strong&gt;&lt;br /&gt;Mmm, delicious listeria, salmonella, and E. coli. (NY Mag $)&lt;br /&gt;+ &lt;em&gt;RFK Jr barred Democrats from being vaccine advisors. &lt;/em&gt;(Ars Technica)&lt;br /&gt;+ &lt;em&gt;The Department of Health and Human Services is searching for two new vaccines against deadly viruses. &lt;/em&gt;(Undark)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;10 Take a look at these beautiful star clusters&lt;/strong&gt;&lt;br /&gt;Courtesy of the Hubble Space Telescope and the James Webb Space Telescope. (Ars Technica)&lt;br /&gt;+ &lt;em&gt;See the stunning first images from the Vera C. Rubin Observatory. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“People are going to die.”&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;—Clement Nkubizi, the country director for the nonprofit Action Against Hunger in South Sudan, tells Wired that their food stock is running critically low in the wake of USAID cuts.&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfpM4iSKDKESfRE8dtWt9FeqQ1ufknplS0GI5omvwo4qZXBgRKP5R9CxuOQ2FVkZKaeX6fdg8CjPNndAeZzB2tva0bZrgO7ss4GKZTHhLvAWHBA9sHuqCT6cfWc7sL6754KrGhk?key=jwt8GONxQlylLoe59hwzNg" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;The world is moving closer to a new cold war fought with authoritarian tech&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Despite President Biden’s assurances that the US is not seeking a new cold war, one is brewing between the world’s autocracies and democracies—and technology is fueling it.&lt;/p&gt;&lt;p&gt;Authoritarian states are following China’s lead and are trending toward more digital rights abuses by increasing the mass digital surveillance of citizens, censorship, and controls on individual expression.&lt;/p&gt;&lt;p&gt;And while democracies also use massive amounts of surveillance technology, it’s the tech trade relationships between authoritarian countries that’s enabling the rise of digitally enabled social control. Read the full story.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Inside OpenAI’s empire: A conversation with Karen Hao&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;In a wide-ranging Roundtables conversation for MIT Technology Review subscribers, journalist and author Karen Hao recently spoke about her new book, &lt;em&gt;Empire of AI: Dreams and Nightmares in Sam Altman’s OpenAI&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;She talked with executive editor Niall Firth about how she first covered the company in 2020 while on staff at MIT Technology Review. They discussed how the AI industry now functions like an empire and went on to examine what ethically-made AI looks like.&lt;/p&gt;&lt;p&gt;Read the transcript of the conversation, which has been lightly edited and condensed. And, if you’re already a subscriber, you can watch the on-demand recording of the event here.&amp;nbsp;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;MIT Technology Review Narrated: How did life begin?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;How life begins is one of the biggest and hardest questions in science. All we know is that something happened on Earth more than 3.5 billion years ago, and it may well have occurred on many other worlds in the universe as well. Could AI help us to unpick the mysteries around the origins of life and detect signs of it on other worlds?&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;This is our latest story to be turned into a MIT Technology Review Narrated podcast, which&amp;nbsp;&lt;br /&gt;we’re publishing each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it’s released.&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 xAI’s Grok went on an anti-Semitic rant&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Days after Elon Musk said new updates would lessen its reliance on mainstream media. (WP $)&lt;br /&gt;+ &lt;em&gt;The chatbot started to call itself ‘MechaHitler.’ &lt;/em&gt;(WSJ $)&lt;br /&gt;+ &lt;em&gt;What Grok’s neo-Nazi turn tells us about xAI. &lt;/em&gt;(The Atlantic $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;strong&gt;2 Musk loyalists are fighting to keep DOGE running&lt;/strong&gt;&lt;br /&gt;As officials seek to diminish the department’s role. (WSJ $)&lt;br /&gt;+ &lt;em&gt;DOGE’s tech takeover threatens the safety and stability of our critical data. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 An imposter used AI to successfully impersonate Marco Rubio&lt;/strong&gt;&lt;br /&gt;They were able to send voice and text messages to fellow politicians. (WP $)&lt;br /&gt;+ &lt;em&gt;It’s not the first time Rubio has been targeted like this. &lt;/em&gt;(FT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 Terrorist groups are using AI to recruit and plan&lt;/strong&gt;&lt;br /&gt;Counter-terror agencies are struggling to keep up. (The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 How the crypto faithful won over the President&lt;/strong&gt;&lt;br /&gt;The industry’s successful Trump courtship sparked a lobbying bonanza. (NYT $)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;6 Wanted: 115,000 Nvidia chips for China’s data centers&lt;br /&gt;&lt;/strong&gt;But the US doesn’t seem to know how many restricted chips are already in the country. (Bloomberg $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 For startups, protecting companies from AI threats isn’t big business&lt;br /&gt;&lt;/strong&gt;Smaller firms are only making modest gains—for now. (The Information $)&lt;br /&gt;+ &lt;em&gt;Cyberattacks by AI agents are coming. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 Inside Zimbabwe’s dangerous EV lithium mines&lt;br /&gt;&lt;/strong&gt;Many residents worry that China is exploiting them. (Rest of World)&lt;br /&gt;+ &lt;em&gt;How one mine could unlock billions in EV subsidies. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 ‘The Milk Guy’ is delivering raw dairy around NYC&lt;/strong&gt;&lt;br /&gt;Mmm, delicious listeria, salmonella, and E. coli. (NY Mag $)&lt;br /&gt;+ &lt;em&gt;RFK Jr barred Democrats from being vaccine advisors. &lt;/em&gt;(Ars Technica)&lt;br /&gt;+ &lt;em&gt;The Department of Health and Human Services is searching for two new vaccines against deadly viruses. &lt;/em&gt;(Undark)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;10 Take a look at these beautiful star clusters&lt;/strong&gt;&lt;br /&gt;Courtesy of the Hubble Space Telescope and the James Webb Space Telescope. (Ars Technica)&lt;br /&gt;+ &lt;em&gt;See the stunning first images from the Vera C. Rubin Observatory. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“People are going to die.”&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;—Clement Nkubizi, the country director for the nonprofit Action Against Hunger in South Sudan, tells Wired that their food stock is running critically low in the wake of USAID cuts.&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfpM4iSKDKESfRE8dtWt9FeqQ1ufknplS0GI5omvwo4qZXBgRKP5R9CxuOQ2FVkZKaeX6fdg8CjPNndAeZzB2tva0bZrgO7ss4GKZTHhLvAWHBA9sHuqCT6cfWc7sL6754KrGhk?key=jwt8GONxQlylLoe59hwzNg" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;The world is moving closer to a new cold war fought with authoritarian tech&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Despite President Biden’s assurances that the US is not seeking a new cold war, one is brewing between the world’s autocracies and democracies—and technology is fueling it.&lt;/p&gt;&lt;p&gt;Authoritarian states are following China’s lead and are trending toward more digital rights abuses by increasing the mass digital surveillance of citizens, censorship, and controls on individual expression.&lt;/p&gt;&lt;p&gt;And while democracies also use massive amounts of surveillance technology, it’s the tech trade relationships between authoritarian countries that’s enabling the rise of digitally enabled social control. Read the full story.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/09/1119923/the-download-a-conversation-with-karen-hao-and-how-did-life-begin/</guid><pubDate>Wed, 09 Jul 2025 12:10:00 +0000</pubDate></item><item><title>[NEW] 6 days until TechCrunch All Stage kicks off in Boston — and up to $475 in ticket savings disappear (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/09/6-days-until-techcrunch-all-stage-kicks-off-in-boston-and-up-to-475-in-ticket-savings-disappear/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In just 6 days, the doors to &lt;strong&gt;TechCrunch All Stage&lt;/strong&gt; swing open at Boston’s SoWa Power Station — and your chance to save up to &lt;strong&gt;$475&lt;/strong&gt; slams shut.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This isn’t just another founder event. It’s the summit designed to help startups move faster, fundraise smarter, and scale more effectively. Whether you’re refining your pitch, preparing to raise capital, or leading a growing team, TC All Stage delivers the tools, tactics, and connections you need to move forward.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Right now, Founder Passes are only $100 and Investor Passes are $200 — the lowest prices available. Once they’re gone, ticket prices rise to full rate. Don’t wait to secure your spot and maximize your savings. &lt;strong&gt;Register here&lt;/strong&gt;.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch All Stage 2025 6 days left" class="wp-image-3019631" height="383" src="https://techcrunch.com/wp-content/uploads/2025/06/16x9_GeneralArticleImageHeader_TCAllStage_Countdown.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-real-strategies-and-actionable-insights"&gt;Real strategies and actionable insights&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;At TC All Stage, the focus is on substance. You’ll get direct access to startup strategies that actually work — shared by operators and investors who have built, backed, and scaled successful companies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Here’s what’s happening on July 15 in Boston:&lt;/strong&gt;&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Breakout sessions&lt;/strong&gt; focused on fundraising, growth-stage scaling, startup hiring, and how AI is being used to build real businesses.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Roundtable discussions&lt;/strong&gt; that address the tough questions and give honest, practical answers.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;The &lt;strong&gt;“&lt;/strong&gt;&lt;strong&gt;So You Think You Can Pitch&lt;/strong&gt;&lt;strong&gt;” &lt;/strong&gt;showdown, featuring live feedback from seasoned VCs.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Curated networking powered by Braindate&lt;/strong&gt; to help you meet the people who can move your startup forward.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Side Events&lt;/strong&gt;&lt;strong&gt; &lt;/strong&gt;around Boston for deeper conversations and meaningful connections outside the main agenda.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Early Stage 2024 audience" class="wp-image-2987302" height="453" src="https://techcrunch.com/wp-content/uploads/2025/03/Early-Stage-2024-audience.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Halo Creative&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-meet-the-voices-behind-the-sessions"&gt;Meet the voices behind the sessions&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Explore the &lt;strong&gt;TC All Stage agenda&lt;/strong&gt; and hear from some of the most respected names in venture and startup building:&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Ellen Chisa, Boldstart Ventures — building from inception with conviction.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Cathy Gao, Sapphire Ventures — navigating Series C and growth-stage capital.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Chris Gardner, Underscore VC — blending human and AI in product development.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Charles Hudson, Precursor Ventures — what VCs really look for at pre-seed.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Mo Jomaa, CapitalG — preparing for IPO readiness from the beginning.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Brandon Krieg, Stash — how technology is opening the doors to investing for everyone.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Tiffany Luck, NEA — crafting the perfect pitch with strategy and storytelling.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Jennifer Neundorfer, January Ventures — what AI means for early-stage company building.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Nikki Parker, Insight Partners — building a growth-focused PR and marketing strategy from seed to public.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Jahanvi Sardana, Index Ventures — how to scale with intentionality.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Charles E. Hudson from Precursor Ventures is one of the judges at Startup Battlefield at TechCrunch Disrupt 2022 in San Francisco." class="wp-image-2428159" height="454" src="https://techcrunch.com/wp-content/uploads/2022/10/TechCrunch-Disrupt-Haje-Kamps-559.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Haje Kamps&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-just-days-left-to-save-before-tc-all-stage-kicks-off-on-july-15"&gt;Just days left to save before TC All Stage kicks off on July 15&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC All Stage is on July 15 — just 6 days away.&lt;/strong&gt; This is your final opportunity to access the lowest ticket rates and get in the room with the founders, investors, and experts shaping the next wave of startups. &lt;strong&gt;Register now and save up to $475 before prices rise at the door.&lt;/strong&gt;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In just 6 days, the doors to &lt;strong&gt;TechCrunch All Stage&lt;/strong&gt; swing open at Boston’s SoWa Power Station — and your chance to save up to &lt;strong&gt;$475&lt;/strong&gt; slams shut.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This isn’t just another founder event. It’s the summit designed to help startups move faster, fundraise smarter, and scale more effectively. Whether you’re refining your pitch, preparing to raise capital, or leading a growing team, TC All Stage delivers the tools, tactics, and connections you need to move forward.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Right now, Founder Passes are only $100 and Investor Passes are $200 — the lowest prices available. Once they’re gone, ticket prices rise to full rate. Don’t wait to secure your spot and maximize your savings. &lt;strong&gt;Register here&lt;/strong&gt;.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch All Stage 2025 6 days left" class="wp-image-3019631" height="383" src="https://techcrunch.com/wp-content/uploads/2025/06/16x9_GeneralArticleImageHeader_TCAllStage_Countdown.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-real-strategies-and-actionable-insights"&gt;Real strategies and actionable insights&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;At TC All Stage, the focus is on substance. You’ll get direct access to startup strategies that actually work — shared by operators and investors who have built, backed, and scaled successful companies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Here’s what’s happening on July 15 in Boston:&lt;/strong&gt;&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Breakout sessions&lt;/strong&gt; focused on fundraising, growth-stage scaling, startup hiring, and how AI is being used to build real businesses.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Roundtable discussions&lt;/strong&gt; that address the tough questions and give honest, practical answers.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;The &lt;strong&gt;“&lt;/strong&gt;&lt;strong&gt;So You Think You Can Pitch&lt;/strong&gt;&lt;strong&gt;” &lt;/strong&gt;showdown, featuring live feedback from seasoned VCs.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Curated networking powered by Braindate&lt;/strong&gt; to help you meet the people who can move your startup forward.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Side Events&lt;/strong&gt;&lt;strong&gt; &lt;/strong&gt;around Boston for deeper conversations and meaningful connections outside the main agenda.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Early Stage 2024 audience" class="wp-image-2987302" height="453" src="https://techcrunch.com/wp-content/uploads/2025/03/Early-Stage-2024-audience.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Halo Creative&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-meet-the-voices-behind-the-sessions"&gt;Meet the voices behind the sessions&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Explore the &lt;strong&gt;TC All Stage agenda&lt;/strong&gt; and hear from some of the most respected names in venture and startup building:&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Ellen Chisa, Boldstart Ventures — building from inception with conviction.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Cathy Gao, Sapphire Ventures — navigating Series C and growth-stage capital.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Chris Gardner, Underscore VC — blending human and AI in product development.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Charles Hudson, Precursor Ventures — what VCs really look for at pre-seed.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Mo Jomaa, CapitalG — preparing for IPO readiness from the beginning.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Brandon Krieg, Stash — how technology is opening the doors to investing for everyone.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Tiffany Luck, NEA — crafting the perfect pitch with strategy and storytelling.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Jennifer Neundorfer, January Ventures — what AI means for early-stage company building.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Nikki Parker, Insight Partners — building a growth-focused PR and marketing strategy from seed to public.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Jahanvi Sardana, Index Ventures — how to scale with intentionality.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Charles E. Hudson from Precursor Ventures is one of the judges at Startup Battlefield at TechCrunch Disrupt 2022 in San Francisco." class="wp-image-2428159" height="454" src="https://techcrunch.com/wp-content/uploads/2022/10/TechCrunch-Disrupt-Haje-Kamps-559.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Haje Kamps&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-just-days-left-to-save-before-tc-all-stage-kicks-off-on-july-15"&gt;Just days left to save before TC All Stage kicks off on July 15&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC All Stage is on July 15 — just 6 days away.&lt;/strong&gt; This is your final opportunity to access the lowest ticket rates and get in the room with the founders, investors, and experts shaping the next wave of startups. &lt;strong&gt;Register now and save up to $475 before prices rise at the door.&lt;/strong&gt;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/09/6-days-until-techcrunch-all-stage-kicks-off-in-boston-and-up-to-475-in-ticket-savings-disappear/</guid><pubDate>Wed, 09 Jul 2025 14:00:00 +0000</pubDate></item><item><title>[NEW] Google brings Gemini to Wear OS watches, adds AI Mode to Circle to Search (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/09/google-brings-gemini-to-wear-os-watches-adds-ai-mode-to-circle-to-search/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google announced on Wednesday that it’s rolling out Gemini to Wear OS watches, nearly two months after teasing the move back in May. The tech giant is also adding new Circle to Search capabilities by integrating its AI Mode search experience directly into the feature and adding support for gaming-related queries.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gemini is rolling out to watches from Pixel, Samsung, OPPO, OnePlus, and Xiaomi that are running Wear OS 4+ over the coming weeks, the company says.&amp;nbsp;The announcement is part of Google’s plans to&amp;nbsp;replace Google Assistant with Gemini&amp;nbsp;across all of its devices and platforms.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;To start talking to Gemini, users need to say, “Hey, Google,” press and hold the side button on their watch, or tap on the Gemini app icon on their watch screen.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users will be able to ask Gemini questions like, “For how long should I roast sliced vegetables, and at what temperature?” when busy cooking with messy hands. Or a user could ask, “Do I need an umbrella today?” when heading out the door.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Additionally, users can utilize Gemini to complete tasks across multiple apps. For example, a user could ask Gemini to “Summarize my last email from Emily” or “Add my son’s next five baseball games to my calendar.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google notes that users can ask Gemini to remember important details such as “Remember I parked on level 4, spot 27” or “Remind me to go grocery shopping after work.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3025830" height="407" src="https://techcrunch.com/wp-content/uploads/2025/07/gemini-wearos.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;As for the new Circle to Search capabilities, Google says it’s making it easier to explore information to get quick help. Launched last year, Circle to Search allows users to initiate a Google search by circling, highlighting, scribbling, or tapping on something they see on their screen.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Now users will be able to use AI Mode’s advanced reasoning to dig into complex topics and ask follow-up questions, all without switching apps.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After starting a search with Circle to Search, an AI Overview will appear in the results. From there, users can scroll to the bottom and tap “Dive deeper with AI Mode” to ask follow-up questions and explore more about the visual search.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is also making it easier to use AI Mode in Google Lens, as it’s now available through the Google app on both Android and iOS. The capability is now available in the U.S. and India. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In addition, Google says users can now use Circle to Search when gaming on mobile. For example, you could leverage Circle to Search to identify a new character or find a winning strategy when playing a game.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google also announced that it’s making AI Overviews more helpful, as responses are now better formatted and easier to read. The tech giant notes that AI Overviews can break down key information and include more visuals.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last, Google announced that Pixel 9 Pro owners get a full year of the company’s&amp;nbsp;Google AI Pro&amp;nbsp;subscription for free. This includes&amp;nbsp;access to Veo 3, which lets you describe an idea and to generate a short video with natural audio.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google announced on Wednesday that it’s rolling out Gemini to Wear OS watches, nearly two months after teasing the move back in May. The tech giant is also adding new Circle to Search capabilities by integrating its AI Mode search experience directly into the feature and adding support for gaming-related queries.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gemini is rolling out to watches from Pixel, Samsung, OPPO, OnePlus, and Xiaomi that are running Wear OS 4+ over the coming weeks, the company says.&amp;nbsp;The announcement is part of Google’s plans to&amp;nbsp;replace Google Assistant with Gemini&amp;nbsp;across all of its devices and platforms.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;To start talking to Gemini, users need to say, “Hey, Google,” press and hold the side button on their watch, or tap on the Gemini app icon on their watch screen.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users will be able to ask Gemini questions like, “For how long should I roast sliced vegetables, and at what temperature?” when busy cooking with messy hands. Or a user could ask, “Do I need an umbrella today?” when heading out the door.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Additionally, users can utilize Gemini to complete tasks across multiple apps. For example, a user could ask Gemini to “Summarize my last email from Emily” or “Add my son’s next five baseball games to my calendar.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google notes that users can ask Gemini to remember important details such as “Remember I parked on level 4, spot 27” or “Remind me to go grocery shopping after work.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3025830" height="407" src="https://techcrunch.com/wp-content/uploads/2025/07/gemini-wearos.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;As for the new Circle to Search capabilities, Google says it’s making it easier to explore information to get quick help. Launched last year, Circle to Search allows users to initiate a Google search by circling, highlighting, scribbling, or tapping on something they see on their screen.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Now users will be able to use AI Mode’s advanced reasoning to dig into complex topics and ask follow-up questions, all without switching apps.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After starting a search with Circle to Search, an AI Overview will appear in the results. From there, users can scroll to the bottom and tap “Dive deeper with AI Mode” to ask follow-up questions and explore more about the visual search.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is also making it easier to use AI Mode in Google Lens, as it’s now available through the Google app on both Android and iOS. The capability is now available in the U.S. and India. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In addition, Google says users can now use Circle to Search when gaming on mobile. For example, you could leverage Circle to Search to identify a new character or find a winning strategy when playing a game.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google also announced that it’s making AI Overviews more helpful, as responses are now better formatted and easier to read. The tech giant notes that AI Overviews can break down key information and include more visuals.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last, Google announced that Pixel 9 Pro owners get a full year of the company’s&amp;nbsp;Google AI Pro&amp;nbsp;subscription for free. This includes&amp;nbsp;access to Veo 3, which lets you describe an idea and to generate a short video with natural audio.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/09/google-brings-gemini-to-wear-os-watches-adds-ai-mode-to-circle-to-search/</guid><pubDate>Wed, 09 Jul 2025 14:00:00 +0000</pubDate></item><item><title>[NEW] Tencent improves testing creative AI models with new benchmark (AI News)</title><link>https://www.artificialintelligence-news.com/news/tencent-improves-testing-creative-ai-models-new-benchmark/</link><description>&lt;p&gt;Tencent has introduced a new benchmark, ArtifactsBench, that aims to fix current problems with testing creative AI models.&lt;/p&gt;&lt;p&gt;Ever asked an AI to build something like a simple webpage or a chart and received something that works but has a poor user experience? The buttons might be in the wrong place, the colours might clash, or the animations feel clunky. It’s a common problem, and it highlights a huge challenge in the world of AI development: how do you teach a machine to have good taste?&lt;/p&gt;&lt;p&gt;For a long time, we’ve been testing AI models on their ability to write code that is functionally correct. These tests could confirm the code would run, but they were completely “blind to the visual fidelity and interactive integrity that define modern user experiences.”&lt;/p&gt;&lt;p&gt;This is the exact problem ArtifactsBench has been designed to solve. It’s less of a test and more of an automated art critic for AI-generated code&lt;/p&gt;&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;&lt;blockquote class="cmplz-placeholder-element twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;🚀Thrilled to introduce #ArtifactsBench! We're bridging the visual-interactive gap in code generation evaluation.&lt;/p&gt;&lt;p&gt;Our benchmark uses a novel automated, multimodal pipeline to assess LLMs on 1,825 diverse tasks. An MLLM-as-Judge evaluates visual artifacts, achieving 94.4% ranking… pic.twitter.com/84xClcnNyS&lt;/p&gt;— Hunyuan (@TencentHunyuan) July 9, 2025&lt;/blockquote&gt;&lt;/div&gt;&lt;/figure&gt;&lt;h3 class="wp-block-heading" id="h-getting-it-right-like-a-human-would-should"&gt;Getting it right, like a human &lt;s&gt;would&lt;/s&gt; should&lt;/h3&gt;&lt;p&gt;So, how does Tencent’s AI benchmark work? First, an AI is given a creative task from a catalogue of over 1,800 challenges, from building data visualisations and web apps to making interactive mini-games.&lt;/p&gt;&lt;p&gt;Once the AI generates the code, ArtifactsBench gets to work. It automatically builds and runs the code in a safe and sandboxed environment.&lt;/p&gt;&lt;p&gt;To see how the application behaves, it captures a series of screenshots over time. This allows it to check for things like animations, state changes after a button click, and other dynamic user feedback.&lt;/p&gt;&lt;p&gt;Finally, it hands over all this evidence – the original request, the AI’s code, and the screenshots – to a Multimodal LLM (MLLM), to act as a judge.&lt;/p&gt;&lt;p&gt;This MLLM judge isn’t just giving a vague opinion and instead uses a detailed, per-task checklist to score the result across ten different metrics. Scoring includes functionality, user experience, and even aesthetic quality. This ensures the scoring is fair, consistent, and thorough.&lt;/p&gt;&lt;p&gt;The big question is, does this automated judge actually have good taste? The results suggest it does.&lt;/p&gt;&lt;p&gt;When the rankings from ArtifactsBench were compared to WebDev Arena, the gold-standard platform where real humans vote on the best AI creations, they matched up with a 94.4% consistency. This is a massive leap from older automated benchmarks, which only managed around 69.4% consistency.&lt;/p&gt;&lt;p&gt;On top of this, the framework’s judgments showed over 90% agreement with professional human developers.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-tencent-evaluates-the-creativity-of-top-ai-models-with-its-new-benchmark"&gt;Tencent evaluates the creativity of top AI models with its new benchmark&lt;/h3&gt;&lt;p&gt;When Tencent put more than 30 of the world’s top AI models through their paces, the leaderboard was revealing. While top commercial models from Google (Gemini-2.5-Pro) and Anthropic (Claude 4.0-Sonnet) took the lead, the tests unearthed a fascinating insight.&lt;/p&gt;&lt;p&gt;You might think that an AI specialised in writing code would be the best at these tasks. But the opposite was true. The research found that “the holistic capabilities of generalist models often surpass those of specialized ones.”&lt;/p&gt;&lt;p&gt;A general-purpose model, Qwen-2.5-Instruct, actually beat its more specialised siblings, Qwen-2.5-coder (a code-specific model) and Qwen2.5-VL (a vision-specialised model).&lt;/p&gt;&lt;p&gt;The researchers believe this is because creating a great visual application isn’t just about coding or visual understanding in isolation and requires a blend of skills.&lt;/p&gt;&lt;p&gt;“Robust reasoning, nuanced instruction following, and an implicit sense of design aesthetics,” the researchers highlight as example vital skills. These are the kinds of well-rounded, almost human-like abilities that the best generalist models are beginning to develop.&lt;/p&gt;&lt;p&gt;Tencent hopes its ArtifactsBench benchmark can reliably evaluate these qualities and thus measure future progress in the ability for AI to create things that are not just functional but what users actually want to use.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Tencent Hunyuan3D-PolyGen: A model for ‘art-grade’ 3D assets&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Tencent has introduced a new benchmark, ArtifactsBench, that aims to fix current problems with testing creative AI models.&lt;/p&gt;&lt;p&gt;Ever asked an AI to build something like a simple webpage or a chart and received something that works but has a poor user experience? The buttons might be in the wrong place, the colours might clash, or the animations feel clunky. It’s a common problem, and it highlights a huge challenge in the world of AI development: how do you teach a machine to have good taste?&lt;/p&gt;&lt;p&gt;For a long time, we’ve been testing AI models on their ability to write code that is functionally correct. These tests could confirm the code would run, but they were completely “blind to the visual fidelity and interactive integrity that define modern user experiences.”&lt;/p&gt;&lt;p&gt;This is the exact problem ArtifactsBench has been designed to solve. It’s less of a test and more of an automated art critic for AI-generated code&lt;/p&gt;&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;&lt;blockquote class="cmplz-placeholder-element twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;🚀Thrilled to introduce #ArtifactsBench! We're bridging the visual-interactive gap in code generation evaluation.&lt;/p&gt;&lt;p&gt;Our benchmark uses a novel automated, multimodal pipeline to assess LLMs on 1,825 diverse tasks. An MLLM-as-Judge evaluates visual artifacts, achieving 94.4% ranking… pic.twitter.com/84xClcnNyS&lt;/p&gt;— Hunyuan (@TencentHunyuan) July 9, 2025&lt;/blockquote&gt;&lt;/div&gt;&lt;/figure&gt;&lt;h3 class="wp-block-heading" id="h-getting-it-right-like-a-human-would-should"&gt;Getting it right, like a human &lt;s&gt;would&lt;/s&gt; should&lt;/h3&gt;&lt;p&gt;So, how does Tencent’s AI benchmark work? First, an AI is given a creative task from a catalogue of over 1,800 challenges, from building data visualisations and web apps to making interactive mini-games.&lt;/p&gt;&lt;p&gt;Once the AI generates the code, ArtifactsBench gets to work. It automatically builds and runs the code in a safe and sandboxed environment.&lt;/p&gt;&lt;p&gt;To see how the application behaves, it captures a series of screenshots over time. This allows it to check for things like animations, state changes after a button click, and other dynamic user feedback.&lt;/p&gt;&lt;p&gt;Finally, it hands over all this evidence – the original request, the AI’s code, and the screenshots – to a Multimodal LLM (MLLM), to act as a judge.&lt;/p&gt;&lt;p&gt;This MLLM judge isn’t just giving a vague opinion and instead uses a detailed, per-task checklist to score the result across ten different metrics. Scoring includes functionality, user experience, and even aesthetic quality. This ensures the scoring is fair, consistent, and thorough.&lt;/p&gt;&lt;p&gt;The big question is, does this automated judge actually have good taste? The results suggest it does.&lt;/p&gt;&lt;p&gt;When the rankings from ArtifactsBench were compared to WebDev Arena, the gold-standard platform where real humans vote on the best AI creations, they matched up with a 94.4% consistency. This is a massive leap from older automated benchmarks, which only managed around 69.4% consistency.&lt;/p&gt;&lt;p&gt;On top of this, the framework’s judgments showed over 90% agreement with professional human developers.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-tencent-evaluates-the-creativity-of-top-ai-models-with-its-new-benchmark"&gt;Tencent evaluates the creativity of top AI models with its new benchmark&lt;/h3&gt;&lt;p&gt;When Tencent put more than 30 of the world’s top AI models through their paces, the leaderboard was revealing. While top commercial models from Google (Gemini-2.5-Pro) and Anthropic (Claude 4.0-Sonnet) took the lead, the tests unearthed a fascinating insight.&lt;/p&gt;&lt;p&gt;You might think that an AI specialised in writing code would be the best at these tasks. But the opposite was true. The research found that “the holistic capabilities of generalist models often surpass those of specialized ones.”&lt;/p&gt;&lt;p&gt;A general-purpose model, Qwen-2.5-Instruct, actually beat its more specialised siblings, Qwen-2.5-coder (a code-specific model) and Qwen2.5-VL (a vision-specialised model).&lt;/p&gt;&lt;p&gt;The researchers believe this is because creating a great visual application isn’t just about coding or visual understanding in isolation and requires a blend of skills.&lt;/p&gt;&lt;p&gt;“Robust reasoning, nuanced instruction following, and an implicit sense of design aesthetics,” the researchers highlight as example vital skills. These are the kinds of well-rounded, almost human-like abilities that the best generalist models are beginning to develop.&lt;/p&gt;&lt;p&gt;Tencent hopes its ArtifactsBench benchmark can reliably evaluate these qualities and thus measure future progress in the ability for AI to create things that are not just functional but what users actually want to use.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Tencent Hunyuan3D-PolyGen: A model for ‘art-grade’ 3D assets&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/tencent-improves-testing-creative-ai-models-new-benchmark/</guid><pubDate>Wed, 09 Jul 2025 14:10:13 +0000</pubDate></item><item><title>[NEW] Get your exhibit table at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/09/get-your-exhibit-table-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Time is running out to secure your exhibit table at &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, October 27-29, at Moscone West in San Francisco. This is your chance to get your startup in front of &lt;strong&gt;10,000+ startup pioneers, VC leaders, and tech enthusiasts&lt;/strong&gt;.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Learn more and grab your table here&lt;/strong&gt;&lt;strong&gt; &lt;/strong&gt;before your competitor does.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-maximum-exposure-for-your-startup"&gt;Maximum exposure for your startup&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;For three full days, you’ll put your innovation directly in front of an eager, influential audience.&lt;/p&gt;







&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Expand Your Reach:&lt;/strong&gt; Showcase your solutions in the bustling Disrupt Expo Hall. Forge partnerships that will drive immediate growth.&amp;nbsp;&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Maximize Connections:&lt;/strong&gt; Get &lt;strong&gt;10 conference passes&lt;/strong&gt; for you and your team. Engage directly with decision-makers through main-stage discussions, breakout sessions, and exclusive roundtables.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Boost Your Brand Visibility:&lt;/strong&gt; Promote your brand to the entire TechCrunch audience — before, during, and after the event — across multiple platforms.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Unmatched ROI:&lt;/strong&gt; For just &lt;strong&gt;$10,000&lt;/strong&gt;, this package delivers maximum exposure, essential networking, and extensive marketing support.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-2791592" height="454" src="https://techcrunch.com/wp-content/uploads/2024/06/expo_startup.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Slava Blazer Photography&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-what-you-get-with-your-table"&gt;What you get with your table&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;6’ x 30″ exhibit table with linen and two chairs&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;11” x 14” tabletop sign with your startup’s branding&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Lead generation via TechCrunch Disrupt app&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Complimentary partner Wi-Fi access&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Silver Tier sponsor branding&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Entry-level listing in sponsor directory&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;One Founder Pass (additional founder perks)&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;10 passes for your team and guests (5 Expo+, 5 General Admission)&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;50% off additional General Admission Passes&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Access to the TechCrunch Disrupt press list&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Logo on “thank you” slide during breaks&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Company logo and description on event partner page&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Logo and profile in TechCrunch Disrupt mobile app&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Company name in select TechCrunch sponsor announcements&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Acknowledgment during closing ceremony&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-limited-tables-and-limited-time"&gt;Limited tables and limited time&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Limited exhibit tables are available. Act now!&lt;/strong&gt; Secure your spot and amplify your brand at Disrupt 2025 — one of the most anticipated tech conferences of the year. &lt;strong&gt;Visit this exhibit page and reserve your booth today&lt;/strong&gt;&lt;strong&gt;!&lt;/strong&gt;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-2571166" height="383" src="https://techcrunch.com/wp-content/uploads/2023/07/expo_hall.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Eric Slomonson, The Photo Group&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Time is running out to secure your exhibit table at &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, October 27-29, at Moscone West in San Francisco. This is your chance to get your startup in front of &lt;strong&gt;10,000+ startup pioneers, VC leaders, and tech enthusiasts&lt;/strong&gt;.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Learn more and grab your table here&lt;/strong&gt;&lt;strong&gt; &lt;/strong&gt;before your competitor does.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-maximum-exposure-for-your-startup"&gt;Maximum exposure for your startup&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;For three full days, you’ll put your innovation directly in front of an eager, influential audience.&lt;/p&gt;







&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Expand Your Reach:&lt;/strong&gt; Showcase your solutions in the bustling Disrupt Expo Hall. Forge partnerships that will drive immediate growth.&amp;nbsp;&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Maximize Connections:&lt;/strong&gt; Get &lt;strong&gt;10 conference passes&lt;/strong&gt; for you and your team. Engage directly with decision-makers through main-stage discussions, breakout sessions, and exclusive roundtables.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Boost Your Brand Visibility:&lt;/strong&gt; Promote your brand to the entire TechCrunch audience — before, during, and after the event — across multiple platforms.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Unmatched ROI:&lt;/strong&gt; For just &lt;strong&gt;$10,000&lt;/strong&gt;, this package delivers maximum exposure, essential networking, and extensive marketing support.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-2791592" height="454" src="https://techcrunch.com/wp-content/uploads/2024/06/expo_startup.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Slava Blazer Photography&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-what-you-get-with-your-table"&gt;What you get with your table&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;6’ x 30″ exhibit table with linen and two chairs&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;11” x 14” tabletop sign with your startup’s branding&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Lead generation via TechCrunch Disrupt app&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Complimentary partner Wi-Fi access&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Silver Tier sponsor branding&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Entry-level listing in sponsor directory&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;One Founder Pass (additional founder perks)&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;10 passes for your team and guests (5 Expo+, 5 General Admission)&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;50% off additional General Admission Passes&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Access to the TechCrunch Disrupt press list&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Logo on “thank you” slide during breaks&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Company logo and description on event partner page&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Logo and profile in TechCrunch Disrupt mobile app&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Company name in select TechCrunch sponsor announcements&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Acknowledgment during closing ceremony&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-limited-tables-and-limited-time"&gt;Limited tables and limited time&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Limited exhibit tables are available. Act now!&lt;/strong&gt; Secure your spot and amplify your brand at Disrupt 2025 — one of the most anticipated tech conferences of the year. &lt;strong&gt;Visit this exhibit page and reserve your booth today&lt;/strong&gt;&lt;strong&gt;!&lt;/strong&gt;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-2571166" height="383" src="https://techcrunch.com/wp-content/uploads/2023/07/expo_hall.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Eric Slomonson, The Photo Group&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/09/get-your-exhibit-table-at-techcrunch-disrupt-2025/</guid><pubDate>Wed, 09 Jul 2025 15:00:00 +0000</pubDate></item><item><title>[NEW] Perplexity launches Comet, an AI-powered web browser (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/09/perplexity-launches-comet-an-ai-powered-web-browser/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Perplexity on Wednesday launched its first AI-powered web browser, called Comet, marking the startup’s latest effort to challenge Google Search as the primary avenue people use to find information online.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At launch, Comet will be available first to subscribers of Perplexity’s $200-per-month Max plan, as well as a small group of invitees that signed up to a waitlist.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3025968" height="399" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-08-at-11.09.41PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Here’s what a New tab looks like for me on Comet (Credit: Maxwell Zeff/Perplexity)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Comet’s headline feature is Perplexity’s AI search engine, which is pre-installed and set as the default, putting the company’s core product — AI generated summaries of search results — front and center.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Users can also access Comet Assistant, a new AI agent from Perplexity that lives in the web browser and aims to automate routine tasks. Perplexity says the assistant can summarize emails and calendar events, manage tabs, and navigate webpages on behalf of users. Users can access Comet Assistant by opening a sidecar on any webpage, which lets the AI agent see what’s on the webpage and answer questions about it.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3025956" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/cmp_find_emails.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Comet Assistant in your email inbox (Credit: Perplexity)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Perplexity has released several products and initiatives in recent months, but none feel quite as consequential as Comet. The company’s CEO, Aravind Srinivas, has significantly hyped up Comet’s launch in particular, perhaps because he sees it as vital in Perplexity’s battle against Google.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With Comet, Perplexity is aiming to reach users directly without having to go through Google Chrome, the most popular browser currently. While AI-powered browsers present uncharted territory for many users, Google itself seems convinced this is the direction browsers are headed: the Search giant has deployed several AI integrations into Chrome in recent months, not to mention AI mode, an AI search product with a striking resemblance to Perplexity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Srinivas said in March that his goal with Comet was to “develop an operating system with which you can do almost everything,” enabling Perplexity’s AI to help users across apps and websites. Becoming the default browser for users can translate to “infinite retention,” Srinivas said in June, which would ostensibly lead to more requests on Perplexity.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3025971" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/cmp_reddit_ama.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Perplexity’s Comet Assistant can open new tabs for you (Credit: Perplexity)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;That said, Comet is entering a crowded arena. While Google Chrome and Apple’s Safari hold most of the market, The Browser Company launched an AI-powered browser, Dia, in June that seems to offer many of the same features as Comet. OpenAI has also reportedly considered launching its own browser to compete with Google, and has even hired some key members from the original Google Chrome team in the last year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Comet could get an initial leg up in the browser wars if a meaningful chunk of Perplexity users sign up for the product. Srinivas recently said that Perplexity saw 780 million queries in May 2025, and that the company’s search products are seeing more than 20% growth month-over-month. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Taking on Google Search is no small task, but Perplexity seems to have the right idea by launching a browser of its own. But the startup’s team may find it even harder to convince users to switch browsers than weaning them off Google Search.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-hands-on-with-comet"&gt;Hands on with Comet&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The most unique aspect of this browser seems to be Comet Assistant. During our testing, we found Comet’s AI agent to be surprisingly helpful for simple tasks, but it quickly falls apart when given more complex requests. Using Comet Assistant to its fullest potential also requires you to hand over an uncomfortable level of access to Perplexity.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;My favorite way to use Comet Assistant, so far, is loading it in the sidecar while I’m browsing the web. Perplexity’s on-browser AI agent can automatically see what I’m looking at, so I can simply ask it questions without needing to open a new window or copy and paste text or links. It’s right there, and it always has the context for what I’m looking at.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3025962" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/cmp_summarize_webpage.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Comet Assistant can see your webpage (credit: Perplexity)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Comet Assistant was able to answer questions about posts on social media, YouTube videos, and even sentences I just wrote in a Google Doc. I imagine this will streamline workflows for millions of people that are sending screenshots, files, and links to ChatGPT all day.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Next, I tried getting Comet Assistant to look through my Google Calendar. But before I could do so, I had to give Perplexity significant access to my Google Account — a lot of access. Just look at how long this list is.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3025936" height="349" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-08-at-4.19.00PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;(Credit: Maxwell Zeff/Perplexity)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;I have to say, giving Perplexity permission to view my screen, send emails, look at my contacts, and add events to my Calendar made me a little uneasy. But it seems AI agents need this kind of access to be useful.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nevertheless, Comet Assistant did a reasonably good job looking through my Calendar. It notified me about some upcoming events, and offered me some advice on when to leave my home, and how to navigate public transit, to get to those events. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The assistant was also able to summarize emails I received that morning from noteworthy senders — in my case, important startups and tech companies with upcoming news. I’ve found that AI agents have a very difficult time parsing through what’s important in an email inbox, but Comet Assistant fared pretty well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Comet Assistant fails at more complicated tasks. For example, I tried asking it to help me find a long-term parking spot at San Francisco’s airport for an upcoming trip, specifically places with good reviews that cost less than $15 a day. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The assistant offered up several options that seemed to fit the criteria, so I asked it to book me a spot at one of the locations for the dates I’d be away. The agent navigated the parking lot’s website for me, entered in dates, and even some of my information, then asked me to review what it did and check-out.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Turns out, Comet Assistant hallucinated and entered completely wrong dates, later telling me that the dates I wanted were booked, but still wanted to have me complete the check-out anyways. I had to tell the AI agent that the dates were non-negotiable, and asked it to find another location. It ran into the same problem again.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI agents that mess up key details like this are not new. My experience with OpenAI’s agent, Operator, and Perplexity’s previous shopping agent yielded similar results. Clearly, hallucinations stand in the way of these products becoming real tools. Until AI companies can solve them, AI agents will still be a novelty for complex tasks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nevertheless, Comet does seem to offer some new capabilities that may just give Perplexity a leg up over the competition in the modern browser wars.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Perplexity on Wednesday launched its first AI-powered web browser, called Comet, marking the startup’s latest effort to challenge Google Search as the primary avenue people use to find information online.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At launch, Comet will be available first to subscribers of Perplexity’s $200-per-month Max plan, as well as a small group of invitees that signed up to a waitlist.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3025968" height="399" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-08-at-11.09.41PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Here’s what a New tab looks like for me on Comet (Credit: Maxwell Zeff/Perplexity)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Comet’s headline feature is Perplexity’s AI search engine, which is pre-installed and set as the default, putting the company’s core product — AI generated summaries of search results — front and center.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Users can also access Comet Assistant, a new AI agent from Perplexity that lives in the web browser and aims to automate routine tasks. Perplexity says the assistant can summarize emails and calendar events, manage tabs, and navigate webpages on behalf of users. Users can access Comet Assistant by opening a sidecar on any webpage, which lets the AI agent see what’s on the webpage and answer questions about it.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3025956" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/cmp_find_emails.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Comet Assistant in your email inbox (Credit: Perplexity)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Perplexity has released several products and initiatives in recent months, but none feel quite as consequential as Comet. The company’s CEO, Aravind Srinivas, has significantly hyped up Comet’s launch in particular, perhaps because he sees it as vital in Perplexity’s battle against Google.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With Comet, Perplexity is aiming to reach users directly without having to go through Google Chrome, the most popular browser currently. While AI-powered browsers present uncharted territory for many users, Google itself seems convinced this is the direction browsers are headed: the Search giant has deployed several AI integrations into Chrome in recent months, not to mention AI mode, an AI search product with a striking resemblance to Perplexity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Srinivas said in March that his goal with Comet was to “develop an operating system with which you can do almost everything,” enabling Perplexity’s AI to help users across apps and websites. Becoming the default browser for users can translate to “infinite retention,” Srinivas said in June, which would ostensibly lead to more requests on Perplexity.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3025971" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/cmp_reddit_ama.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Perplexity’s Comet Assistant can open new tabs for you (Credit: Perplexity)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;That said, Comet is entering a crowded arena. While Google Chrome and Apple’s Safari hold most of the market, The Browser Company launched an AI-powered browser, Dia, in June that seems to offer many of the same features as Comet. OpenAI has also reportedly considered launching its own browser to compete with Google, and has even hired some key members from the original Google Chrome team in the last year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Comet could get an initial leg up in the browser wars if a meaningful chunk of Perplexity users sign up for the product. Srinivas recently said that Perplexity saw 780 million queries in May 2025, and that the company’s search products are seeing more than 20% growth month-over-month. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Taking on Google Search is no small task, but Perplexity seems to have the right idea by launching a browser of its own. But the startup’s team may find it even harder to convince users to switch browsers than weaning them off Google Search.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-hands-on-with-comet"&gt;Hands on with Comet&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The most unique aspect of this browser seems to be Comet Assistant. During our testing, we found Comet’s AI agent to be surprisingly helpful for simple tasks, but it quickly falls apart when given more complex requests. Using Comet Assistant to its fullest potential also requires you to hand over an uncomfortable level of access to Perplexity.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;My favorite way to use Comet Assistant, so far, is loading it in the sidecar while I’m browsing the web. Perplexity’s on-browser AI agent can automatically see what I’m looking at, so I can simply ask it questions without needing to open a new window or copy and paste text or links. It’s right there, and it always has the context for what I’m looking at.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3025962" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/cmp_summarize_webpage.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Comet Assistant can see your webpage (credit: Perplexity)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Comet Assistant was able to answer questions about posts on social media, YouTube videos, and even sentences I just wrote in a Google Doc. I imagine this will streamline workflows for millions of people that are sending screenshots, files, and links to ChatGPT all day.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Next, I tried getting Comet Assistant to look through my Google Calendar. But before I could do so, I had to give Perplexity significant access to my Google Account — a lot of access. Just look at how long this list is.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3025936" height="349" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-08-at-4.19.00PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;(Credit: Maxwell Zeff/Perplexity)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;I have to say, giving Perplexity permission to view my screen, send emails, look at my contacts, and add events to my Calendar made me a little uneasy. But it seems AI agents need this kind of access to be useful.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nevertheless, Comet Assistant did a reasonably good job looking through my Calendar. It notified me about some upcoming events, and offered me some advice on when to leave my home, and how to navigate public transit, to get to those events. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The assistant was also able to summarize emails I received that morning from noteworthy senders — in my case, important startups and tech companies with upcoming news. I’ve found that AI agents have a very difficult time parsing through what’s important in an email inbox, but Comet Assistant fared pretty well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Comet Assistant fails at more complicated tasks. For example, I tried asking it to help me find a long-term parking spot at San Francisco’s airport for an upcoming trip, specifically places with good reviews that cost less than $15 a day. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The assistant offered up several options that seemed to fit the criteria, so I asked it to book me a spot at one of the locations for the dates I’d be away. The agent navigated the parking lot’s website for me, entered in dates, and even some of my information, then asked me to review what it did and check-out.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Turns out, Comet Assistant hallucinated and entered completely wrong dates, later telling me that the dates I wanted were booked, but still wanted to have me complete the check-out anyways. I had to tell the AI agent that the dates were non-negotiable, and asked it to find another location. It ran into the same problem again.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI agents that mess up key details like this are not new. My experience with OpenAI’s agent, Operator, and Perplexity’s previous shopping agent yielded similar results. Clearly, hallucinations stand in the way of these products becoming real tools. Until AI companies can solve them, AI agents will still be a novelty for complex tasks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nevertheless, Comet does seem to offer some new capabilities that may just give Perplexity a leg up over the competition in the modern browser wars.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/09/perplexity-launches-comet-an-ai-powered-web-browser/</guid><pubDate>Wed, 09 Jul 2025 15:00:00 +0000</pubDate></item><item><title>[NEW] iMerit believes better-quality data, not more data, is the future of AI (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/09/imerit-believes-better-quality-data-not-more-data-is-the-future-of-ai/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI data platform iMerit believes the next step toward integrating AI tools at the enterprise level is not more data, but better data. And better data doesn’t come from hordes of gig workers, but from experts across mathematics, medicine, healthcare, finance, autonomy, and other cognitive fields, the company says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“What’s become exceedingly important is the ability to attract and retain the best cognitive experts, because we have to take these large models and make them very customized towards solving enterprise AI problems,” Radha Basu, CEO and founder of iMerit, told TechCrunch.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The California- and India-based startup has for the past nine years quietly built itself into a trusted data annotation partner for companies working in computer vision, medical imaging, autonomous mobility, and other AI applications that require high-accuracy, human-in-the-loop labeling.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now, iMerit is bringing its Scholars program out of beta, the company exclusively told TechCrunch. The goal of the program is to build a growing workforce of experts to fine-tune generative AI models for enterprise applications and, increasingly, foundational models.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;iMerit already calls some of the top AI firms customers, including three of the big seven generative AI companies, eight of the top autonomous vehicle companies, three large U.S. government agencies, and two of the top three cloud providers, according to the company.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3026066" height="417" src="https://techcrunch.com/wp-content/uploads/2025/07/Math-CoT.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;iMerit Scholars workflow example focused on mathematics&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;iMerit&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The news comes as Scale AI, arguably the biggest name in AI data annotation, has lost its founder and CEO Alexandr Wang to Meta, which also acquired a 49% in the company. In the wake of Meta’s investment, many of Scale’s major clients pulled back, including Google, OpenAI, Microsoft, and xAI, out of concerns that Meta could gain access to their product roadmaps.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;iMerit doesn’t claim to replace Scale AI’s core offering of high-throughput, developer-focused “blitz data.” Instead, it’s betting that now is the right moment to double down on expert-led, high-quality data, the kind that requires deep human judgment and domain-specific oversight.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re the adults in the room,” Rob Laing, iMerit’s VP of global specialist workforce, told TechCrunch. “A lot of money is being spent on AI right now. There are some very intelligent people building large platforms of human workforces. The output that they’re getting from that mass approach and that very quick speed to market approach is not at the level of quality that enterprises need.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Basu brought up the example of healthcare scribes that have come to market off the back of foundational large language models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If you don’t have the expertise of the cardiologist or the physician, what you’re doing is basically creating something that’s maybe 50% or 60% accurate,” Basu said. “You want that to be 99%. You want to question the model. You want to break it. You want to fix it. That is what expert-led AI is making possible for enterprise.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;iMerit’s experts are tasked with finetuning, or “tormenting,” enterprise and foundational AI models using the startup’s proprietary platform Ango Hub. Ango allows iMerit’s “Scholars” to interact with the customer’s model to generate and evaluate problems for the model to solve.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For iMerritt, attracting and retaining cognitive experts is key to success because the experts aren’t just doing a few tasks and disappearing; they’re working on projects for multiple years. iMerit boasts a 91% retention rate, with 50% of its experts being women.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Laing, whose experience founding the human translation platform myGengo helped him understand how to crowdsource, said it’s relatively easy to get warm bodies to perform menial tasks. Creating community requires a more human-centered approach.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Instead of someone being a name on a database, when someone joins the Scholars program, they actually meet folks on the team,” Laing said. “They have collaborative discussions. They’re very much pushed to work at the highest possible level. And we are very, very, very selective about how we bring people in.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think what we’re going to see over the next couple of years is that companies like iMerit that are really focusing on that engagement, that retention, and that quality, are going to be the go-to companies for people to train the AI,” Laing added.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Today, iMerit works with over 4,000 Scholars and hopes to bring on more as it scales. Basu told TechCrunch that even though the company hasn’t raised since 2020 — when it brought on investors like Khosla Ventures, Omidyar Network, Dell.org, and British International Investment — iMerit is sustainable and profitable. With its own cash reserves, iMerit can afford to scale to 10,000 experts, Basu said. To scale further would require more outside investment, which iMerit is open to, but not desperate for.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;iMerit has been working on Scholars for the past year, mainly with a focus on healthcare. The goal is to grow across other enterprise applications, including finance and medicine. Laing noted that generative AI is its fastest-growing area as top AI firms work with iMerit to improve their foundation models.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The free data out there on the internet is gone, and the lower level of human input data has also become commoditized,” Laing said. “Where these folks are going is really trying to tune these things to achieve AGI or superintelligence.”&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI data platform iMerit believes the next step toward integrating AI tools at the enterprise level is not more data, but better data. And better data doesn’t come from hordes of gig workers, but from experts across mathematics, medicine, healthcare, finance, autonomy, and other cognitive fields, the company says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“What’s become exceedingly important is the ability to attract and retain the best cognitive experts, because we have to take these large models and make them very customized towards solving enterprise AI problems,” Radha Basu, CEO and founder of iMerit, told TechCrunch.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The California- and India-based startup has for the past nine years quietly built itself into a trusted data annotation partner for companies working in computer vision, medical imaging, autonomous mobility, and other AI applications that require high-accuracy, human-in-the-loop labeling.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now, iMerit is bringing its Scholars program out of beta, the company exclusively told TechCrunch. The goal of the program is to build a growing workforce of experts to fine-tune generative AI models for enterprise applications and, increasingly, foundational models.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;iMerit already calls some of the top AI firms customers, including three of the big seven generative AI companies, eight of the top autonomous vehicle companies, three large U.S. government agencies, and two of the top three cloud providers, according to the company.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3026066" height="417" src="https://techcrunch.com/wp-content/uploads/2025/07/Math-CoT.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;iMerit Scholars workflow example focused on mathematics&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;iMerit&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The news comes as Scale AI, arguably the biggest name in AI data annotation, has lost its founder and CEO Alexandr Wang to Meta, which also acquired a 49% in the company. In the wake of Meta’s investment, many of Scale’s major clients pulled back, including Google, OpenAI, Microsoft, and xAI, out of concerns that Meta could gain access to their product roadmaps.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;iMerit doesn’t claim to replace Scale AI’s core offering of high-throughput, developer-focused “blitz data.” Instead, it’s betting that now is the right moment to double down on expert-led, high-quality data, the kind that requires deep human judgment and domain-specific oversight.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re the adults in the room,” Rob Laing, iMerit’s VP of global specialist workforce, told TechCrunch. “A lot of money is being spent on AI right now. There are some very intelligent people building large platforms of human workforces. The output that they’re getting from that mass approach and that very quick speed to market approach is not at the level of quality that enterprises need.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Basu brought up the example of healthcare scribes that have come to market off the back of foundational large language models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If you don’t have the expertise of the cardiologist or the physician, what you’re doing is basically creating something that’s maybe 50% or 60% accurate,” Basu said. “You want that to be 99%. You want to question the model. You want to break it. You want to fix it. That is what expert-led AI is making possible for enterprise.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;iMerit’s experts are tasked with finetuning, or “tormenting,” enterprise and foundational AI models using the startup’s proprietary platform Ango Hub. Ango allows iMerit’s “Scholars” to interact with the customer’s model to generate and evaluate problems for the model to solve.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For iMerritt, attracting and retaining cognitive experts is key to success because the experts aren’t just doing a few tasks and disappearing; they’re working on projects for multiple years. iMerit boasts a 91% retention rate, with 50% of its experts being women.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Laing, whose experience founding the human translation platform myGengo helped him understand how to crowdsource, said it’s relatively easy to get warm bodies to perform menial tasks. Creating community requires a more human-centered approach.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Instead of someone being a name on a database, when someone joins the Scholars program, they actually meet folks on the team,” Laing said. “They have collaborative discussions. They’re very much pushed to work at the highest possible level. And we are very, very, very selective about how we bring people in.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think what we’re going to see over the next couple of years is that companies like iMerit that are really focusing on that engagement, that retention, and that quality, are going to be the go-to companies for people to train the AI,” Laing added.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Today, iMerit works with over 4,000 Scholars and hopes to bring on more as it scales. Basu told TechCrunch that even though the company hasn’t raised since 2020 — when it brought on investors like Khosla Ventures, Omidyar Network, Dell.org, and British International Investment — iMerit is sustainable and profitable. With its own cash reserves, iMerit can afford to scale to 10,000 experts, Basu said. To scale further would require more outside investment, which iMerit is open to, but not desperate for.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;iMerit has been working on Scholars for the past year, mainly with a focus on healthcare. The goal is to grow across other enterprise applications, including finance and medicine. Laing noted that generative AI is its fastest-growing area as top AI firms work with iMerit to improve their foundation models.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The free data out there on the internet is gone, and the lower level of human input data has also become commoditized,” Laing said. “Where these folks are going is really trying to tune these things to achieve AGI or superintelligence.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/09/imerit-believes-better-quality-data-not-more-data-is-the-future-of-ai/</guid><pubDate>Wed, 09 Jul 2025 15:20:14 +0000</pubDate></item><item><title>[NEW] Pinecone founder Edo Liberty explores the real missing link in enterprise AI at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/09/pinecone-founder-edo-liberty-explores-the-real-missing-link-in-enterprise-ai-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;At &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, the AI conversation goes deeper than just the latest models. On one of the AI Stages, Edo Liberty, founder and CEO of Pinecone, will deliver a session that challenges one of the most persistent assumptions in the field — that raw intelligence alone is enough. With 10,000+ startup and VC leaders expected in San Francisco from October 27–29, &lt;strong&gt;this fireside chat&lt;/strong&gt; and presentation is one of the must-attend moments for anyone building AI systems that actually work in the real world.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Edo Liberty" class="wp-image-3025928" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/TC25_-Edo-Liberty-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-intelligence-is-only-half-the-equation"&gt;Intelligence is only half the equation&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;For AI to be truly useful to businesses, it needs more than language fluency or prediction accuracy. It needs knowledge. Proprietary data, domain-specific insights, real-time information retrieval — these are the ingredients that power task completion, accurate answers, and enterprise value. Liberty will break down the critical difference between intelligence and knowledge, and explain why delivering both is the key to unlocking AI’s true impact.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As the founder of Pinecone, Liberty is leading one of the most important infrastructure companies in the AI ecosystem. Pinecone’s vector database helps organizations build high-performance AI applications at scale, with reliable retrieval and memory systems that enable real-time use of massive knowledge bases.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-from-amazon-ai-to-academia-to-building-infrastructure-for-the-next-era"&gt;From Amazon AI to academia to building infrastructure for the next era&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Before launching Pinecone, Liberty served as Director of Research at AWS and led Amazon AI Labs, where he worked on key services like SageMaker and OpenSearch. He also ran Yahoo’s research lab in New York, taught at Princeton and Tel Aviv University, and authored more than 75 papers and patents on machine learning, data mining, and streaming algorithms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At Disrupt 2025, Liberty brings all of that experience to bear in a session that will speak to technical leaders, AI founders, enterprise builders, and anyone trying to bridge the gap between promise and performance in artificial intelligence.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Catch this conversation on one of the two AI Stages at TechCrunch Disrupt 2025, happening October 27–29 at Moscone West in San Francisco. The exact session timing to be announced on the &lt;strong&gt;Disrupt agenda page&lt;/strong&gt;, so be sure to check back in often for frequent updates. Register now to join more than 10,000 startup and VC leaders and &lt;strong&gt;save up to $675&lt;/strong&gt; before prices increase.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;At &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, the AI conversation goes deeper than just the latest models. On one of the AI Stages, Edo Liberty, founder and CEO of Pinecone, will deliver a session that challenges one of the most persistent assumptions in the field — that raw intelligence alone is enough. With 10,000+ startup and VC leaders expected in San Francisco from October 27–29, &lt;strong&gt;this fireside chat&lt;/strong&gt; and presentation is one of the must-attend moments for anyone building AI systems that actually work in the real world.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Edo Liberty" class="wp-image-3025928" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/TC25_-Edo-Liberty-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-intelligence-is-only-half-the-equation"&gt;Intelligence is only half the equation&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;For AI to be truly useful to businesses, it needs more than language fluency or prediction accuracy. It needs knowledge. Proprietary data, domain-specific insights, real-time information retrieval — these are the ingredients that power task completion, accurate answers, and enterprise value. Liberty will break down the critical difference between intelligence and knowledge, and explain why delivering both is the key to unlocking AI’s true impact.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As the founder of Pinecone, Liberty is leading one of the most important infrastructure companies in the AI ecosystem. Pinecone’s vector database helps organizations build high-performance AI applications at scale, with reliable retrieval and memory systems that enable real-time use of massive knowledge bases.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-from-amazon-ai-to-academia-to-building-infrastructure-for-the-next-era"&gt;From Amazon AI to academia to building infrastructure for the next era&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Before launching Pinecone, Liberty served as Director of Research at AWS and led Amazon AI Labs, where he worked on key services like SageMaker and OpenSearch. He also ran Yahoo’s research lab in New York, taught at Princeton and Tel Aviv University, and authored more than 75 papers and patents on machine learning, data mining, and streaming algorithms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At Disrupt 2025, Liberty brings all of that experience to bear in a session that will speak to technical leaders, AI founders, enterprise builders, and anyone trying to bridge the gap between promise and performance in artificial intelligence.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Catch this conversation on one of the two AI Stages at TechCrunch Disrupt 2025, happening October 27–29 at Moscone West in San Francisco. The exact session timing to be announced on the &lt;strong&gt;Disrupt agenda page&lt;/strong&gt;, so be sure to check back in often for frequent updates. Register now to join more than 10,000 startup and VC leaders and &lt;strong&gt;save up to $675&lt;/strong&gt; before prices increase.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/09/pinecone-founder-edo-liberty-explores-the-real-missing-link-in-enterprise-ai-at-techcrunch-disrupt-2025/</guid><pubDate>Wed, 09 Jul 2025 15:30:00 +0000</pubDate></item><item><title>[NEW] Blok is using AI personas to simulate real-world app usage (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/09/blok-is-using-ai-persons-to-simulate-real-world-app-usage/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI-powered coding tools like Cursor, Replit, Claude Code, and Lovable are helping developers write many lines of code every day to ship products faster. However, app makers still have to rely on either shipping full beta versions of their apps or using simulation software to gauge how upcoming features will work.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Blok, a company that is coming out of stealth, allows developers to use AI to simulate different user personas to test an app’s features and learn how to make their apps better.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company was founded by Tom Charman and Olivia Higgs in 2024. Both have been serial entrepreneurs and worked on startups together as well in areas including travel and learning.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3025994" height="453" src="https://techcrunch.com/wp-content/uploads/2025/07/Founder-Headshots-3.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Founders Tom Charman and Olivia Higgs Image Credits: Blok&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;To date, the startup has raised $7.5 million across two rounds. Its seed round of $5 million was led by MaC Venture Capital, with participation from people working at Discord, Google, Meta, Apple, Snapchat, and Pinterest. Blok’s pre-seed round was with Protagonist with participation from Rackhouse, Ryan Hoover’s Weekend Fund, and Blank Ventures.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Marlon Nichols, Managing GP at MaC Venture Capital, said that Blok is often compared to Otptimizly and Amplitude, but those tools are more reactive. He said that Blok is edging them out by providing a predictive layer of testing for apps. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We backed Blok because we believe product development is at an inflection point. Teams are shipping faster than ever, but they’re still making critical decisions based on A/B tests and gut instinct. Blok’s simulation engine flips that model —&amp;nbsp;giving teams the ability to predict user behavior before a single line of code is written,” he told TechCrunch over email.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Higgs said that the need for testing is increasing as the complexity of interfaces has increased over time. She mentioned that they interviewed more than 100 product engineers to understand problems faced by product teams. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“There is a real need for increased testing because the bar for visual interfaces is getting a lot higher. We’re seeing people interact with technology through chat, through voice. So if you’re introducing visual UI [elements] into the mix, you have to make sure that you are not introducing unnecessary friction into a user’s workflow,” she said.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3025996" height="396" src="https://techcrunch.com/wp-content/uploads/2025/07/Blok-experiment.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Image Credits: Blok&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Charman said that both big and small companies face different problems. While small companies don’t have cohorts to test out their products and get live feedback, big companies want to avoid stuffing features into their apps and making them clunky. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are trying to reach a place where companies don’t need to release their features on an experimental basis and wait for a few weeks or months for results to show up,” he said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;When a customer starts working with Blok, they upload their event log data from Amplitude, Mixpanel, or Segment. Blok then performs behavioral modeling and creates different user personas for app makers to test. These personas would roughly cover most of an app’s user base. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3025998" height="396" src="https://techcrunch.com/wp-content/uploads/2025/07/Blok-personas.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Image Credits: Blok&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Then the development team submits a Figma design and experiment details — including the hypothesis they want to test and the user goal they want to achieve — to Blok, and the user persona agents then try to run the simulation many times. At the end, Blok will show insights about how users would use a particular feature and give recommendations. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These insights include an overall report of the experiment and details about what went well and what could be improved. Teams can also look at a persona-wise report and suggestions. Plus, since it is 2025, there is a chatbot that you can ask queries to about your experiment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Blok has put its product behind a waitlist and is working with an initial set of customers, largely developing solutions in finance and healthcare. The startups said that these areas are ideal to target as they can’t put out bad experiments in public and play around with the product a lot. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup charges companies through a SaaS model, but it is also figuring out how to balance out compute costs. The company is aiming to hit mid-single-digit millions in revenue this year and open up to more customers. &lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI-powered coding tools like Cursor, Replit, Claude Code, and Lovable are helping developers write many lines of code every day to ship products faster. However, app makers still have to rely on either shipping full beta versions of their apps or using simulation software to gauge how upcoming features will work.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Blok, a company that is coming out of stealth, allows developers to use AI to simulate different user personas to test an app’s features and learn how to make their apps better.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company was founded by Tom Charman and Olivia Higgs in 2024. Both have been serial entrepreneurs and worked on startups together as well in areas including travel and learning.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3025994" height="453" src="https://techcrunch.com/wp-content/uploads/2025/07/Founder-Headshots-3.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Founders Tom Charman and Olivia Higgs Image Credits: Blok&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;To date, the startup has raised $7.5 million across two rounds. Its seed round of $5 million was led by MaC Venture Capital, with participation from people working at Discord, Google, Meta, Apple, Snapchat, and Pinterest. Blok’s pre-seed round was with Protagonist with participation from Rackhouse, Ryan Hoover’s Weekend Fund, and Blank Ventures.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Marlon Nichols, Managing GP at MaC Venture Capital, said that Blok is often compared to Otptimizly and Amplitude, but those tools are more reactive. He said that Blok is edging them out by providing a predictive layer of testing for apps. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We backed Blok because we believe product development is at an inflection point. Teams are shipping faster than ever, but they’re still making critical decisions based on A/B tests and gut instinct. Blok’s simulation engine flips that model —&amp;nbsp;giving teams the ability to predict user behavior before a single line of code is written,” he told TechCrunch over email.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Higgs said that the need for testing is increasing as the complexity of interfaces has increased over time. She mentioned that they interviewed more than 100 product engineers to understand problems faced by product teams. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“There is a real need for increased testing because the bar for visual interfaces is getting a lot higher. We’re seeing people interact with technology through chat, through voice. So if you’re introducing visual UI [elements] into the mix, you have to make sure that you are not introducing unnecessary friction into a user’s workflow,” she said.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3025996" height="396" src="https://techcrunch.com/wp-content/uploads/2025/07/Blok-experiment.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Image Credits: Blok&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Charman said that both big and small companies face different problems. While small companies don’t have cohorts to test out their products and get live feedback, big companies want to avoid stuffing features into their apps and making them clunky. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are trying to reach a place where companies don’t need to release their features on an experimental basis and wait for a few weeks or months for results to show up,” he said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;When a customer starts working with Blok, they upload their event log data from Amplitude, Mixpanel, or Segment. Blok then performs behavioral modeling and creates different user personas for app makers to test. These personas would roughly cover most of an app’s user base. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3025998" height="396" src="https://techcrunch.com/wp-content/uploads/2025/07/Blok-personas.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Image Credits: Blok&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Then the development team submits a Figma design and experiment details — including the hypothesis they want to test and the user goal they want to achieve — to Blok, and the user persona agents then try to run the simulation many times. At the end, Blok will show insights about how users would use a particular feature and give recommendations. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These insights include an overall report of the experiment and details about what went well and what could be improved. Teams can also look at a persona-wise report and suggestions. Plus, since it is 2025, there is a chatbot that you can ask queries to about your experiment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Blok has put its product behind a waitlist and is working with an initial set of customers, largely developing solutions in finance and healthcare. The startups said that these areas are ideal to target as they can’t put out bad experiments in public and play around with the product a lot. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup charges companies through a SaaS model, but it is also figuring out how to balance out compute costs. The company is aiming to hit mid-single-digit millions in revenue this year and open up to more customers. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/09/blok-is-using-ai-persons-to-simulate-real-world-app-usage/</guid><pubDate>Wed, 09 Jul 2025 16:00:00 +0000</pubDate></item><item><title>[NEW] MedGemma: Our most capable open models for health AI development (The latest research from Google)</title><link>https://research.google/blog/medgemma-our-most-capable-open-models-for-health-ai-development/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Healthcare is increasingly embracing AI to improve workflow management, patient communication, and diagnostic and treatment support. It’s critical that these AI-based systems are not only high-performing, but also efficient and privacy-preserving. It’s with these considerations in mind that we built and recently released Health AI Developer Foundations (HAI-DEF). HAI-DEF is a collection of lightweight open models designed to offer developers robust starting points for their own health research and application development. Because HAI-DEF models are open, developers retain full control over privacy, infrastructure and modifications to the models. In May of this year, we expanded the HAI-DEF collection with MedGemma, a collection of generative models based on Gemma 3 that are designed to accelerate healthcare and lifesciences AI development.&lt;/p&gt;&lt;p&gt;Today, we’re proud to announce two new models in this collection. The first is MedGemma 27B Multimodal, which complements the previously-released 4B Multimodal and 27B text-only models by adding support for complex multimodal and longitudinal electronic health record interpretation. The second new model is MedSigLIP, a lightweight image and text encoder for classification, search, and related tasks. MedSigLIP is based on the same image encoder that powers the 4B and 27B MedGemma models.&lt;/p&gt;&lt;p&gt;MedGemma and MedSigLIP are strong starting points for medical research and product development. MedGemma is useful for medical text or imaging tasks that require generating free text, like report generation or visual question answering. MedSigLIP is recommended for imaging tasks that involve structured outputs like classification or retrieval. All of the above models can be run on a single GPU, and MedGemma 4B and MedSigLIP can even be adapted to run on mobile hardware.&lt;/p&gt;&lt;p&gt;Full details of MedGemma and MedSigLIP development and evaluation can be found in the MedGemma technical report.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Healthcare is increasingly embracing AI to improve workflow management, patient communication, and diagnostic and treatment support. It’s critical that these AI-based systems are not only high-performing, but also efficient and privacy-preserving. It’s with these considerations in mind that we built and recently released Health AI Developer Foundations (HAI-DEF). HAI-DEF is a collection of lightweight open models designed to offer developers robust starting points for their own health research and application development. Because HAI-DEF models are open, developers retain full control over privacy, infrastructure and modifications to the models. In May of this year, we expanded the HAI-DEF collection with MedGemma, a collection of generative models based on Gemma 3 that are designed to accelerate healthcare and lifesciences AI development.&lt;/p&gt;&lt;p&gt;Today, we’re proud to announce two new models in this collection. The first is MedGemma 27B Multimodal, which complements the previously-released 4B Multimodal and 27B text-only models by adding support for complex multimodal and longitudinal electronic health record interpretation. The second new model is MedSigLIP, a lightweight image and text encoder for classification, search, and related tasks. MedSigLIP is based on the same image encoder that powers the 4B and 27B MedGemma models.&lt;/p&gt;&lt;p&gt;MedGemma and MedSigLIP are strong starting points for medical research and product development. MedGemma is useful for medical text or imaging tasks that require generating free text, like report generation or visual question answering. MedSigLIP is recommended for imaging tasks that involve structured outputs like classification or retrieval. All of the above models can be run on a single GPU, and MedGemma 4B and MedSigLIP can even be adapted to run on mobile hardware.&lt;/p&gt;&lt;p&gt;Full details of MedGemma and MedSigLIP development and evaluation can be found in the MedGemma technical report.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/medgemma-our-most-capable-open-models-for-health-ai-development/</guid><pubDate>Wed, 09 Jul 2025 17:00:00 +0000</pubDate></item><item><title>[NEW] ChatGPT hallucinated about music app Soundslice so often, the founder made the lie come true (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/09/chatgpt-hallucinated-about-music-app-soundslice-so-often-the-founder-made-the-lie-come-true/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Earlier this month, Adrian Holovaty, founder of music-teaching platform Soundslice, solved a mystery that had been plaguing him for weeks. Weird images of what were clearly ChatGPT sessions kept being uploaded to the site.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Once he solved it, he realized that ChatGPT had become one of his company’s greatest hype men – but it was also lying to people about what his app could do.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Holovaty is best known as one of the creators of the open-source Django project, a popular Python web development framework (though he retired from managing the project in 2014). In 2012, he launched Soundslice, which remains “proudly bootstrapped,” he tells TechCrunch. Currently, he’s focused on his music career both as an artist and as a founder.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Soundslice is an app for teaching music, used by students and teachers. It’s known for its video player synchronized to the music notations that guide users on how the notes should be played.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It also offers a feature called “sheet music scanner” that allows users to upload an image of paper sheet music and, using AI, will automatically turn that into an interactive sheet, complete with notations. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Holovaty carefully watches this feature’s error logs to see what problems occur, where to add improvements, he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s where he started seeing the uploaded ChatGPT sessions. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;They were creating a bunch of error logs. Instead of images of sheet music, these were images of words and a box of symbols known as ASCII tablature. That’s a basic text-based system used for guitar notations that uses a regular keyboard. (There’s no treble key, for instance, on your standard QWERTY keyboard.)&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Soundslice uploaded images" class="wp-image-3026106" height="386" src="https://techcrunch.com/wp-content/uploads/2025/07/Soundslice-upload-images.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Adrian Holovaty&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The volume of these ChatGPT session images was not so onerous that it was costing his company money to store them and crushing his app’s bandwidth, Holovaty said. He was baffled, he wrote in a blog post about the situation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our scanning system wasn’t intended to support this style of notation. Why, then, were we being bombarded with so many ASCII tab ChatGPT screenshots? I was mystified for weeks — until I messed around with ChatGPT myself.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That’s how he saw ChatGPT telling people they could hear this music by opening a Soundslice account and uploading the image of the chat session. Only, they couldn’t. Uploading those images wouldn’t translate the ASCII tab into audio notes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He was struck with a new problem. “The main cost was reputational: new Soundslice users were going in with a false expectation. They’d been confidently told we would do something that we don’t actually do,” he described to TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He and his team discussed their options: Slap disclaimers all over the site about it — “No, we can’t turn a ChatGPT session into hearable music” — or build that feature into the scanner, even though he had never before considered supporting that offbeat musical notation system.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He opted to build the feature.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“My feelings on this are conflicted. I’m happy to add a tool that helps people. But I feel like our hand was forced in a weird way. Should we really be developing features in response to misinformation?” he wrote.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He also wondered if this was the first documented case of a company having to develop a feature because ChatGPT kept repeating, to many people, its hallucination about it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The fellow programmers on Hacker News had an interesting take about it: Several of them said that it’s no different than an over-eager human salesperson promising the world to prospects and then forcing developers to deliver new features. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think that’s a very apt and amusing comparison!” Holovaty agreed.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Earlier this month, Adrian Holovaty, founder of music-teaching platform Soundslice, solved a mystery that had been plaguing him for weeks. Weird images of what were clearly ChatGPT sessions kept being uploaded to the site.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Once he solved it, he realized that ChatGPT had become one of his company’s greatest hype men – but it was also lying to people about what his app could do.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Holovaty is best known as one of the creators of the open-source Django project, a popular Python web development framework (though he retired from managing the project in 2014). In 2012, he launched Soundslice, which remains “proudly bootstrapped,” he tells TechCrunch. Currently, he’s focused on his music career both as an artist and as a founder.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Soundslice is an app for teaching music, used by students and teachers. It’s known for its video player synchronized to the music notations that guide users on how the notes should be played.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It also offers a feature called “sheet music scanner” that allows users to upload an image of paper sheet music and, using AI, will automatically turn that into an interactive sheet, complete with notations. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Holovaty carefully watches this feature’s error logs to see what problems occur, where to add improvements, he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s where he started seeing the uploaded ChatGPT sessions. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;They were creating a bunch of error logs. Instead of images of sheet music, these were images of words and a box of symbols known as ASCII tablature. That’s a basic text-based system used for guitar notations that uses a regular keyboard. (There’s no treble key, for instance, on your standard QWERTY keyboard.)&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Soundslice uploaded images" class="wp-image-3026106" height="386" src="https://techcrunch.com/wp-content/uploads/2025/07/Soundslice-upload-images.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Adrian Holovaty&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The volume of these ChatGPT session images was not so onerous that it was costing his company money to store them and crushing his app’s bandwidth, Holovaty said. He was baffled, he wrote in a blog post about the situation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our scanning system wasn’t intended to support this style of notation. Why, then, were we being bombarded with so many ASCII tab ChatGPT screenshots? I was mystified for weeks — until I messed around with ChatGPT myself.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That’s how he saw ChatGPT telling people they could hear this music by opening a Soundslice account and uploading the image of the chat session. Only, they couldn’t. Uploading those images wouldn’t translate the ASCII tab into audio notes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He was struck with a new problem. “The main cost was reputational: new Soundslice users were going in with a false expectation. They’d been confidently told we would do something that we don’t actually do,” he described to TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He and his team discussed their options: Slap disclaimers all over the site about it — “No, we can’t turn a ChatGPT session into hearable music” — or build that feature into the scanner, even though he had never before considered supporting that offbeat musical notation system.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He opted to build the feature.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“My feelings on this are conflicted. I’m happy to add a tool that helps people. But I feel like our hand was forced in a weird way. Should we really be developing features in response to misinformation?” he wrote.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He also wondered if this was the first documented case of a company having to develop a feature because ChatGPT kept repeating, to many people, its hallucination about it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The fellow programmers on Hacker News had an interesting take about it: Several of them said that it’s no different than an over-eager human salesperson promising the world to prospects and then forcing developers to deliver new features. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think that’s a very apt and amusing comparison!” Holovaty agreed.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/09/chatgpt-hallucinated-about-music-app-soundslice-so-often-the-founder-made-the-lie-come-true/</guid><pubDate>Wed, 09 Jul 2025 17:20:14 +0000</pubDate></item><item><title>[NEW] SaaS is in the past. The future belongs to agents, says Narada AI’s CEO (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/podcast/saas-is-in-the-past-the-future-belongs-to-agents-says-narada-ais-ceo/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/54569914657_d267199249_o.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;“SaaS is going away,” said Dave Park, co-founder and CEO of Narada AI. The company is betting big on a different future for enterprise software, one powered by agentic AI.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Change is coming “in the not-too-distant future,” Park said on Equity, TechCrunch’s flagship podcast. “The typical knowledge worker today deals with anywhere from 17 to 25 different SaaS tools and portals every day, wasting two and a half hours just manually looking up or updating these systems. We believe in a future where it’ll just be the data, the databases, and AI agents or agentic models that take your request and operate across those silos to get the job done.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Narada AI, which made its debut at TechCrunch Disrupt 2024 and is based on UC Berkeley research, has developed large action models: a spin on LLMs that can reason through and complete multi-step tasks across different work tools even when APIs are missing.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Park joined Rebecca Bellan on Equity to talk about the rise of agentic AI, what it actually is, how it differs from traditional automation, and what real-world changes enterprises need to make to deploy it at scale. The timing for the conversation is ripe: YC’s most recent batch included 70+ agentic startups, and major players like Grammarly are building full AI work stacks through partnerships and acquisitions.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear more about:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;What most people misunderstand about automation and who’s getting caught in the agentic hype.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;How tools like Narada could eventually help solopreneurs and smaller teams, not just the enterprise giants.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Why the future of software might not be “using” apps at all.&lt;/li&gt;
&lt;/ul&gt;



&lt;p class="wp-block-paragraph"&gt;Equity will be back on Friday with our weekly news rundown, so don’t miss it!&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Subscribe to us on&lt;/em&gt;&lt;em&gt; &lt;/em&gt;&lt;em&gt;Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/54569914657_d267199249_o.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;“SaaS is going away,” said Dave Park, co-founder and CEO of Narada AI. The company is betting big on a different future for enterprise software, one powered by agentic AI.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Change is coming “in the not-too-distant future,” Park said on Equity, TechCrunch’s flagship podcast. “The typical knowledge worker today deals with anywhere from 17 to 25 different SaaS tools and portals every day, wasting two and a half hours just manually looking up or updating these systems. We believe in a future where it’ll just be the data, the databases, and AI agents or agentic models that take your request and operate across those silos to get the job done.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Narada AI, which made its debut at TechCrunch Disrupt 2024 and is based on UC Berkeley research, has developed large action models: a spin on LLMs that can reason through and complete multi-step tasks across different work tools even when APIs are missing.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Park joined Rebecca Bellan on Equity to talk about the rise of agentic AI, what it actually is, how it differs from traditional automation, and what real-world changes enterprises need to make to deploy it at scale. The timing for the conversation is ripe: YC’s most recent batch included 70+ agentic startups, and major players like Grammarly are building full AI work stacks through partnerships and acquisitions.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear more about:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;What most people misunderstand about automation and who’s getting caught in the agentic hype.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;How tools like Narada could eventually help solopreneurs and smaller teams, not just the enterprise giants.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Why the future of software might not be “using” apps at all.&lt;/li&gt;
&lt;/ul&gt;



&lt;p class="wp-block-paragraph"&gt;Equity will be back on Friday with our weekly news rundown, so don’t miss it!&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Subscribe to us on&lt;/em&gt;&lt;em&gt; &lt;/em&gt;&lt;em&gt;Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/podcast/saas-is-in-the-past-the-future-belongs-to-agents-says-narada-ais-ceo/</guid><pubDate>Wed, 09 Jul 2025 17:21:25 +0000</pubDate></item><item><title>[NEW] YouTube prepares crackdown on ‘mass-produced’ and ‘repetitive’ videos, as concern over AI slop grows (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/09/youtube-prepares-crackdown-on-mass-produced-and-repetitive-videos-as-concern-over-ai-slop-grows/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2021/12/GettyImages-1184040131.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;YouTube is preparing to update its policies to crack down on creators’ ability to generate revenue from “inauthentic” content, including mass-produced videos and other types of repetitive content — things that have become easier to generate with the help of AI technology.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On July 15, the company will update its YouTube Partner Program (YPP) Monetization policies with more detailed guidelines around what type of content can earn creators money and what cannot. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The exact policy language itself has not yet been released, but a page on YouTube’s Help documentation explains that creators have always been required to upload “original” and “authentic” content. The update says that the new language will help creators to better understand what “inauthentic” content looks like today.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some YouTube creators were concerned that the update would limit their ability to monetize certain types of videos, like reaction videos or those featuring clips, but a post from YouTube Head of Editorial &amp;amp; Creator Liaison, Rene Ritchie, says that’s not the case.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a video update published on Tuesday, Ritchie says that the change is just a “minor update” to YouTube’s longstanding YPP policies and is designed to better identify when content is mass-produced or repetitive. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, Ritchie adds, this type of content has been ineligible for monetization for years, as it’s content that viewers often consider spam.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;What Ritche is not saying, however, is how much easier it is to create such videos these days.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the rise of AI technology, YouTube has become flooded with AI slop, a term referencing low-quality media or content made using generative AI technology. For instance, it’s common to find an AI voice overlaid on photos, video clips, or other repurposed content, thanks to text-to-video AI tools. Some channels filled with AI music have millions of subscribers. Fake, AI-generated videos about news events, like the Diddy trial, have racked up millions of views.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In another example, a true crime murder series on YouTube that went viral was found to be entirely AI-generated, 404 Media reported earlier this year. Even YouTube CEO Neal Mohan’s likeness was used in an AI-generated phishing scam on the site, despite having tools in place that allow users to report deepfake videos.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While YouTube may downplay the coming changes as a “minor” update or clarification, the reality is that allowing this type of content to grow and its creators to profit could ultimately damage YouTube’s reputation and value. It’s no surprise, then, that the company wants clear policies in place that allow it to enact mass bans of AI slop creators from YPP.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2021/12/GettyImages-1184040131.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;YouTube is preparing to update its policies to crack down on creators’ ability to generate revenue from “inauthentic” content, including mass-produced videos and other types of repetitive content — things that have become easier to generate with the help of AI technology.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On July 15, the company will update its YouTube Partner Program (YPP) Monetization policies with more detailed guidelines around what type of content can earn creators money and what cannot. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The exact policy language itself has not yet been released, but a page on YouTube’s Help documentation explains that creators have always been required to upload “original” and “authentic” content. The update says that the new language will help creators to better understand what “inauthentic” content looks like today.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some YouTube creators were concerned that the update would limit their ability to monetize certain types of videos, like reaction videos or those featuring clips, but a post from YouTube Head of Editorial &amp;amp; Creator Liaison, Rene Ritchie, says that’s not the case.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a video update published on Tuesday, Ritchie says that the change is just a “minor update” to YouTube’s longstanding YPP policies and is designed to better identify when content is mass-produced or repetitive. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, Ritchie adds, this type of content has been ineligible for monetization for years, as it’s content that viewers often consider spam.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;What Ritche is not saying, however, is how much easier it is to create such videos these days.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the rise of AI technology, YouTube has become flooded with AI slop, a term referencing low-quality media or content made using generative AI technology. For instance, it’s common to find an AI voice overlaid on photos, video clips, or other repurposed content, thanks to text-to-video AI tools. Some channels filled with AI music have millions of subscribers. Fake, AI-generated videos about news events, like the Diddy trial, have racked up millions of views.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In another example, a true crime murder series on YouTube that went viral was found to be entirely AI-generated, 404 Media reported earlier this year. Even YouTube CEO Neal Mohan’s likeness was used in an AI-generated phishing scam on the site, despite having tools in place that allow users to report deepfake videos.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While YouTube may downplay the coming changes as a “minor” update or clarification, the reality is that allowing this type of content to grow and its creators to profit could ultimately damage YouTube’s reputation and value. It’s no surprise, then, that the company wants clear policies in place that allow it to enact mass bans of AI slop creators from YPP.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/09/youtube-prepares-crackdown-on-mass-produced-and-repetitive-videos-as-concern-over-ai-slop-grows/</guid><pubDate>Wed, 09 Jul 2025 17:23:13 +0000</pubDate></item></channel></rss>