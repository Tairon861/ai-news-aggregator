<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 28 Aug 2025 06:32:01 +0000</lastBuildDate><item><title>OpenAI co-founder calls for AI labs to safety-test rival models (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/27/openai-co-founder-calls-for-ai-labs-to-safety-test-rival-models/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2170386424.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI and Anthropic, two of the world’s leading AI labs, briefly opened up their closely guarded AI models to allow for joint safety testing — a rare cross-lab collaboration at a time of fierce competition. The effort aimed to surface blind spots in each company’s internal evaluations and demonstrate how leading AI companies can work together on safety and alignment work in the future.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In an interview with TechCrunch, OpenAI co-founder Wojciech Zaremba said this kind of collaboration is increasingly important now that AI is entering a “consequential” stage of development, where AI models are used by millions of people every day.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“There’s a broader question of how the industry sets a standard for safety and collaboration, despite the billions of dollars invested, as well as the war for talent, users, and the best products,” said Zaremba.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The joint safety research, published Wednesday by both companies, arrives amid an arms race among leading AI labs like OpenAI and Anthropic, where billion-dollar data center bets and $100 million compensation packages for top researchers have become table stakes. Some experts warn that the intensity of product competition could pressure companies to cut corners on safety in the rush to build more powerful systems.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To make this research possible, OpenAI and Anthropic granted each other special API access to versions of their AI models with fewer safeguards (OpenAI notes that GPT-5 was not tested because it hadn’t been released yet). Shortly after the research was conducted, however, Anthropic revoked the API access of another team at OpenAI. At the time, Anthropic claimed that OpenAI violated its terms of service, which prohibits using Claude to improve competing products.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zaremba says the events were unrelated and that he expects competition to stay fierce even as AI safety teams try to work together. Nicholas Carlini, a safety researcher with Anthropic, tells TechCrunch that he would like to continue allowing OpenAI safety researchers to access Claude models in the future.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We want to increase collaboration wherever it’s possible across the safety frontier, and try to make this something that happens more regularly,” said Carlini.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;One of the most stark findings in the study relates to hallucination testing. Anthropic’s Claude Opus 4 and Sonnet 4 models refused to answer up to 70% of questions when they were unsure of the correct answer, instead offering responses like, “I don’t have reliable information.” Meanwhile, OpenAI’s o3 and o4-mini models refuse to answer questions far less, but showed much higher hallucination rates, attempting to answer questions when they didn’t have enough information.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zaremba says the right balance is likely somewhere in the middle — OpenAI’s models should refuse to answer more questions, while Anthropic’s models should probably attempt to offer more answers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sycophancy, the tendency for AI models to reinforce negative behavior in users to please them, has emerged as one of the most pressing safety concerns around AI models.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In Anthropic’s research report, the company identified examples of “extreme” sycophancy in GPT-4.1 and Claude Opus 4 — in which the models initially pushed back on psychotic or manic behavior, but later validated some concerning decisions. In other AI models from OpenAI and Anthropic, researchers observed lower levels of sycophancy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Tuesday, parents of a 16-year-old boy, Adam Raine, filed a lawsuit against OpenAI, claiming that ChatGPT (specifically a version powered by GPT-4o) offered their son advice that aided in his suicide, rather than pushing back on his suicidal thoughts. The lawsuit suggests this may be the latest example of AI chatbot sycophancy contributing to tragic outcomes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s hard to imagine how difficult this is to their family,” said Zaremba when asked about the incident. “It would be a sad story if we build AI that solves all these complex PhD level problems, invents new science, and at the same time, we have people with mental health problems as a consequence of interacting with it. This is a dystopian future that I’m not excited about.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a blog post, OpenAI says that it significantly improved the sycophancy of its AI chatbots with GPT-5, compared to GPT-4o, claiming the model is better at responding to mental health emergencies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Moving forward, Zaremba and Carlini say they would like Anthropic and OpenAI to collaborate more on safety testing, looking into more subjects and testing future models, and they hope other AI labs will follow their collaborative approach.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Update 2:00pm PT: This article was updated to include additional research from Anthropic that was not initially made available to TechCrunch ahead of publication.&lt;/em&gt;&lt;/p&gt;

&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Got a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at&amp;nbsp;&lt;/em&gt;&lt;em&gt;rebecca.bellan@techcrunch.com&lt;/em&gt;&lt;em&gt;&amp;nbsp;and Maxwell Zeff at&amp;nbsp;&lt;/em&gt;&lt;em&gt;maxwell.zeff@techcrunch.com&lt;/em&gt;&lt;em&gt;. For secure communication, you can contact us via Signal at&amp;nbsp;@rebeccabellan.491 and&amp;nbsp;@mzeff.88.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2170386424.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI and Anthropic, two of the world’s leading AI labs, briefly opened up their closely guarded AI models to allow for joint safety testing — a rare cross-lab collaboration at a time of fierce competition. The effort aimed to surface blind spots in each company’s internal evaluations and demonstrate how leading AI companies can work together on safety and alignment work in the future.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In an interview with TechCrunch, OpenAI co-founder Wojciech Zaremba said this kind of collaboration is increasingly important now that AI is entering a “consequential” stage of development, where AI models are used by millions of people every day.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“There’s a broader question of how the industry sets a standard for safety and collaboration, despite the billions of dollars invested, as well as the war for talent, users, and the best products,” said Zaremba.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The joint safety research, published Wednesday by both companies, arrives amid an arms race among leading AI labs like OpenAI and Anthropic, where billion-dollar data center bets and $100 million compensation packages for top researchers have become table stakes. Some experts warn that the intensity of product competition could pressure companies to cut corners on safety in the rush to build more powerful systems.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To make this research possible, OpenAI and Anthropic granted each other special API access to versions of their AI models with fewer safeguards (OpenAI notes that GPT-5 was not tested because it hadn’t been released yet). Shortly after the research was conducted, however, Anthropic revoked the API access of another team at OpenAI. At the time, Anthropic claimed that OpenAI violated its terms of service, which prohibits using Claude to improve competing products.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zaremba says the events were unrelated and that he expects competition to stay fierce even as AI safety teams try to work together. Nicholas Carlini, a safety researcher with Anthropic, tells TechCrunch that he would like to continue allowing OpenAI safety researchers to access Claude models in the future.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We want to increase collaboration wherever it’s possible across the safety frontier, and try to make this something that happens more regularly,” said Carlini.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;One of the most stark findings in the study relates to hallucination testing. Anthropic’s Claude Opus 4 and Sonnet 4 models refused to answer up to 70% of questions when they were unsure of the correct answer, instead offering responses like, “I don’t have reliable information.” Meanwhile, OpenAI’s o3 and o4-mini models refuse to answer questions far less, but showed much higher hallucination rates, attempting to answer questions when they didn’t have enough information.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zaremba says the right balance is likely somewhere in the middle — OpenAI’s models should refuse to answer more questions, while Anthropic’s models should probably attempt to offer more answers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sycophancy, the tendency for AI models to reinforce negative behavior in users to please them, has emerged as one of the most pressing safety concerns around AI models.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In Anthropic’s research report, the company identified examples of “extreme” sycophancy in GPT-4.1 and Claude Opus 4 — in which the models initially pushed back on psychotic or manic behavior, but later validated some concerning decisions. In other AI models from OpenAI and Anthropic, researchers observed lower levels of sycophancy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Tuesday, parents of a 16-year-old boy, Adam Raine, filed a lawsuit against OpenAI, claiming that ChatGPT (specifically a version powered by GPT-4o) offered their son advice that aided in his suicide, rather than pushing back on his suicidal thoughts. The lawsuit suggests this may be the latest example of AI chatbot sycophancy contributing to tragic outcomes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s hard to imagine how difficult this is to their family,” said Zaremba when asked about the incident. “It would be a sad story if we build AI that solves all these complex PhD level problems, invents new science, and at the same time, we have people with mental health problems as a consequence of interacting with it. This is a dystopian future that I’m not excited about.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a blog post, OpenAI says that it significantly improved the sycophancy of its AI chatbots with GPT-5, compared to GPT-4o, claiming the model is better at responding to mental health emergencies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Moving forward, Zaremba and Carlini say they would like Anthropic and OpenAI to collaborate more on safety testing, looking into more subjects and testing future models, and they hope other AI labs will follow their collaborative approach.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Update 2:00pm PT: This article was updated to include additional research from Anthropic that was not initially made available to TechCrunch ahead of publication.&lt;/em&gt;&lt;/p&gt;

&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Got a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at&amp;nbsp;&lt;/em&gt;&lt;em&gt;rebecca.bellan@techcrunch.com&lt;/em&gt;&lt;em&gt;&amp;nbsp;and Maxwell Zeff at&amp;nbsp;&lt;/em&gt;&lt;em&gt;maxwell.zeff@techcrunch.com&lt;/em&gt;&lt;em&gt;. For secure communication, you can contact us via Signal at&amp;nbsp;@rebeccabellan.491 and&amp;nbsp;@mzeff.88.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/27/openai-co-founder-calls-for-ai-labs-to-safety-test-rival-models/</guid><pubDate>Wed, 27 Aug 2025 19:14:01 +0000</pubDate></item><item><title>Google and Grok are catching up to ChatGPT, says a16z’s latest AI report (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/27/google-and-grok-are-catching-up-to-chatgpt-says-a16zs-latest-ai-report/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT rivals like Google’s Gemini, xAI’s Grok, and, to a lesser extent, Meta AI, are closing the gap to ChatGPT, OpenAI’s popular AI chatbot, according to a new report focused on the consumer AI landscape from venture firm Andreessen Horowitz.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The report, in its fifth iteration, showcases two and a half years of data about consumers’ evolving use of AI products.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;And for the fifth time, 14 companies appeared on the list of top AI products: ChatGPT, Perplexity, Poe, Character AI, Midjourney, Leonardo, Veed, Cutout, ElevenLabs, Photoroom, Gamma, QuillBot, Civitai, and Hugging Face.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="AI all star companies on a global map" class="wp-image-3040473" height="423" src="https://techcrunch.com/wp-content/uploads/2025/08/Top-Gen-AI-Map.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;a16z&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The companies represent a cross section of how consumers are using AI: for general assistance, companionship, image and video editing, voice generation, productivity, and model hosting. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Five other companies appeared on all but the first report, the firm notes, including Claude, DeepAI, Janitor AI, Pixelcut, and Suno, representing general AI use, companionship, image editing, and music generation.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3040476" height="431" src="https://techcrunch.com/wp-content/uploads/2025/08/Top-Gen-AI-Web-Top-50-List.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;a16z&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;For the first time in the series of reports, Google gained four spots on the list of the top generative AI consumer web products with entries for Gemini, AI Studio, NotebookLM, and Google Labs. These products now have their own separate domains, allowing their growth to be tracked separately from one another.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Andreessen Horowitz says its report relies on data from third-party market intelligence firms, including Similarweb, for web products and Sensor Tower for mobile app data.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="general LMM assistant monthly web visits, excluding gemini and chatgpt" class="wp-image-3040470" height="549" src="https://techcrunch.com/wp-content/uploads/2025/08/Top-Gen-AI-General-LLM-Monthly-Web-Visits.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;a16z&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Of note, No. 2 app Gemini is closing the gap to No. 1 app ChatGPT on mobile devices, but with almost half as many monthly active users. Not surprisingly, Gemini’s AI technology sees stronger adoption on Android, with nearly 90% of the monthly active user base. On the web, Gemini also came in second place behind ChatGPT, with approximately 12% of ChatGPT’s visits.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Google AI properties traffic" class="wp-image-3040471" height="480" src="https://techcrunch.com/wp-content/uploads/2025/08/Top-Gen-AI-Google-AI-Properties-Traffic.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;a16z&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s AI Studio, a developer-oriented sandbox for building with Gemini models, entered the top 10 list of AI web products, sitting in the 10th spot; NotebookLM was No. 13. Google Labs, a destination for Google’s AI experiments (e.g., Flow, Project Mariner, and Doppl), ranked at No. 39.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="NotebookLM visits over time" class="wp-image-3040474" height="466" src="https://techcrunch.com/wp-content/uploads/2025/08/Top-Gen-AI-NotebookLM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;a16z&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The report indicates that Meta AI and Grok are also chasing the top AI app, ChatGPT. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Grok ranked fourth on the web and No. 23 on mobile. This is quick growth, given that Grok went from having no stand-alone app at the end of 2024 (it was first launched on X) to now, with upward of 20 million monthly active users. In July 2025, Grok also climbed nearly 40% when Grok 4 was released.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Grok global DAUs, mobile app" class="wp-image-3040472" height="475" src="https://techcrunch.com/wp-content/uploads/2025/08/Top-Gen-AI-Grok-Global-DAU.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;a16z&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s general assistant ranked No. 46 on the web — the same as in March — but it didn’t make the list of top mobile AI apps. In part, it was hampered by the news that Meta AI was sharing some users’ posts publicly on the web without their informed consent.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="top 50 gen AI mobile apps by MAUs" class="wp-image-3040468" height="439" src="https://techcrunch.com/wp-content/uploads/2025/08/Top-Gen-AI-Apps-Top-50-List.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;a16z&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;DeepSeek and Claude also saw their growth flatten on mobile, with the former falling off its peak by 22%. On the web, DeepSeek saw an even sharper drop-off, down more than 40% from its peak in February 2025. Perplexity and Claude, however, continued to grow.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other Chinese AI makers also made the top 20 on the web, including No. 9 Quark, Alibaba’s AI assistant (No. 47 on the mobile list); No. 12 Doubao, ByteDance’s general LLM product (No. 4 on mobile); and No. 17 Kimi, a chatbot from Moonshot AI. Each of these has a Chinese website and sees 75% of its traffic coming from China.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Seven additional companies on the web list were developed in China but exported their AI tech globally: DeepSeek, Hailuo, Kling, SeaArt, Cutout Pro, Manus, and Monica.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On mobile, 22 of the 50 top apps were developed in China, but only three were primarily used in China. Top players here include Meitu (Photo &amp;amp; Video Editor, BeautyPlus, BeautyCam, Wink, and Airbrush), ByteDance (Doubao and Cici), Gauth, and Hypic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Vibe-coding startups Lovable and Replit both debuted on the main list this time, having not made the cut on a16z’s list published back in March of this year. (Note that websites built and published via Replit and via Lovable without custom domains appear under traffic for replit.app and lovable.app, respectively, helping them gain traction.)&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3040469" height="253" src="https://techcrunch.com/wp-content/uploads/2025/08/Top-Gen-AI-Brink-List.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;a16z&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Andreessen Horowitz also took time to call out AI apps that were on the brink of making the list of top AI apps, including PixAI, Bolt, Blackbox AI, Clipchamp, and Getliner on the web and Talkie, Seekee, Photo AI, AI Mirror, and Arvin on mobile.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The firm notes that the mobile list in this month’s report already features more newcomers (14) than before, as both app stores have long since cracked down on ChatGPT copycats and clones, allowing for more original apps to find their footing.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT rivals like Google’s Gemini, xAI’s Grok, and, to a lesser extent, Meta AI, are closing the gap to ChatGPT, OpenAI’s popular AI chatbot, according to a new report focused on the consumer AI landscape from venture firm Andreessen Horowitz.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The report, in its fifth iteration, showcases two and a half years of data about consumers’ evolving use of AI products.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;And for the fifth time, 14 companies appeared on the list of top AI products: ChatGPT, Perplexity, Poe, Character AI, Midjourney, Leonardo, Veed, Cutout, ElevenLabs, Photoroom, Gamma, QuillBot, Civitai, and Hugging Face.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="AI all star companies on a global map" class="wp-image-3040473" height="423" src="https://techcrunch.com/wp-content/uploads/2025/08/Top-Gen-AI-Map.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;a16z&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The companies represent a cross section of how consumers are using AI: for general assistance, companionship, image and video editing, voice generation, productivity, and model hosting. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Five other companies appeared on all but the first report, the firm notes, including Claude, DeepAI, Janitor AI, Pixelcut, and Suno, representing general AI use, companionship, image editing, and music generation.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3040476" height="431" src="https://techcrunch.com/wp-content/uploads/2025/08/Top-Gen-AI-Web-Top-50-List.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;a16z&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;For the first time in the series of reports, Google gained four spots on the list of the top generative AI consumer web products with entries for Gemini, AI Studio, NotebookLM, and Google Labs. These products now have their own separate domains, allowing their growth to be tracked separately from one another.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Andreessen Horowitz says its report relies on data from third-party market intelligence firms, including Similarweb, for web products and Sensor Tower for mobile app data.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="general LMM assistant monthly web visits, excluding gemini and chatgpt" class="wp-image-3040470" height="549" src="https://techcrunch.com/wp-content/uploads/2025/08/Top-Gen-AI-General-LLM-Monthly-Web-Visits.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;a16z&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Of note, No. 2 app Gemini is closing the gap to No. 1 app ChatGPT on mobile devices, but with almost half as many monthly active users. Not surprisingly, Gemini’s AI technology sees stronger adoption on Android, with nearly 90% of the monthly active user base. On the web, Gemini also came in second place behind ChatGPT, with approximately 12% of ChatGPT’s visits.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Google AI properties traffic" class="wp-image-3040471" height="480" src="https://techcrunch.com/wp-content/uploads/2025/08/Top-Gen-AI-Google-AI-Properties-Traffic.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;a16z&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s AI Studio, a developer-oriented sandbox for building with Gemini models, entered the top 10 list of AI web products, sitting in the 10th spot; NotebookLM was No. 13. Google Labs, a destination for Google’s AI experiments (e.g., Flow, Project Mariner, and Doppl), ranked at No. 39.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="NotebookLM visits over time" class="wp-image-3040474" height="466" src="https://techcrunch.com/wp-content/uploads/2025/08/Top-Gen-AI-NotebookLM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;a16z&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The report indicates that Meta AI and Grok are also chasing the top AI app, ChatGPT. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Grok ranked fourth on the web and No. 23 on mobile. This is quick growth, given that Grok went from having no stand-alone app at the end of 2024 (it was first launched on X) to now, with upward of 20 million monthly active users. In July 2025, Grok also climbed nearly 40% when Grok 4 was released.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Grok global DAUs, mobile app" class="wp-image-3040472" height="475" src="https://techcrunch.com/wp-content/uploads/2025/08/Top-Gen-AI-Grok-Global-DAU.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;a16z&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s general assistant ranked No. 46 on the web — the same as in March — but it didn’t make the list of top mobile AI apps. In part, it was hampered by the news that Meta AI was sharing some users’ posts publicly on the web without their informed consent.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="top 50 gen AI mobile apps by MAUs" class="wp-image-3040468" height="439" src="https://techcrunch.com/wp-content/uploads/2025/08/Top-Gen-AI-Apps-Top-50-List.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;a16z&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;DeepSeek and Claude also saw their growth flatten on mobile, with the former falling off its peak by 22%. On the web, DeepSeek saw an even sharper drop-off, down more than 40% from its peak in February 2025. Perplexity and Claude, however, continued to grow.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other Chinese AI makers also made the top 20 on the web, including No. 9 Quark, Alibaba’s AI assistant (No. 47 on the mobile list); No. 12 Doubao, ByteDance’s general LLM product (No. 4 on mobile); and No. 17 Kimi, a chatbot from Moonshot AI. Each of these has a Chinese website and sees 75% of its traffic coming from China.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Seven additional companies on the web list were developed in China but exported their AI tech globally: DeepSeek, Hailuo, Kling, SeaArt, Cutout Pro, Manus, and Monica.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On mobile, 22 of the 50 top apps were developed in China, but only three were primarily used in China. Top players here include Meitu (Photo &amp;amp; Video Editor, BeautyPlus, BeautyCam, Wink, and Airbrush), ByteDance (Doubao and Cici), Gauth, and Hypic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Vibe-coding startups Lovable and Replit both debuted on the main list this time, having not made the cut on a16z’s list published back in March of this year. (Note that websites built and published via Replit and via Lovable without custom domains appear under traffic for replit.app and lovable.app, respectively, helping them gain traction.)&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3040469" height="253" src="https://techcrunch.com/wp-content/uploads/2025/08/Top-Gen-AI-Brink-List.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;a16z&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Andreessen Horowitz also took time to call out AI apps that were on the brink of making the list of top AI apps, including PixAI, Bolt, Blackbox AI, Clipchamp, and Getliner on the web and Talkie, Seekee, Photo AI, AI Mirror, and Arvin on mobile.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The firm notes that the mobile list in this month’s report already features more newcomers (14) than before, as both app stores have long since cracked down on ChatGPT copycats and clones, allowing for more original apps to find their footing.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/27/google-and-grok-are-catching-up-to-chatgpt-says-a16zs-latest-ai-report/</guid><pubDate>Wed, 27 Aug 2025 19:27:01 +0000</pubDate></item><item><title>911 centers are so understaffed, they’re turning to AI to answer calls (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/27/911-centers-are-so-understaffed-theyre-turning-to-ai-to-answer-calls/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-2216397171.jpg?resize=1200,633" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;When Max Keenan joined Y Combinator’s summer 2022 batch, he was working on Aurelian, a company that automated appointment bookings for hair salons. But less than a year later, a conversation with one of his clients led him to a far more significant problem.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A nearby school’s carpool line was constantly blocking the parking lot of one of Aurelian’s hair salon clients. The salon owner called the city’s non-emergency line and was put on hold for 45 minutes before reaching a dispatcher. “She called me into her office afterwards, and was like, ‘Max, do you want to help me out?’” Keenan told TechCrunch.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;When he started to research how municipal non-emergency response call centers work, he discovered that they are often handled by the same people who are answering actual 911 emergencies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Aurelian pivoted to building an AI voice assistant that helps 911 call centers offload non-emergency call volume. The company announced on Wednesday that it raised a $14 million Series A led by NEA.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s AI voice agent is designed to triage non-urgent issues like noise complaints, parking violations, and even stolen wallet reports —  situations that don’t need an officer’s immediate response or can be handled without dispatching personnel to the scene. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Aurelian’s AI is trained to recognize a real emergency and immediately transfer those calls to a human dispatcher, Keenan said. In other situations, the system collects key information and either creates a report for or relays the details directly to the police department for follow-up action.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since launching its AI assistant in May 2024, Aurelian has been deployed at more than a dozen 911 dispatch centers, including those serving Snohomish County, Washington; Chattanooga, Tennessee; and Kalamazoo, Michigan.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Emergency call centers are adopting Aurelian largely because they are consistently understaffed — a direct result of dispatching being a high-pressure job that ranks among the top 10 industries with the highest turnover rates. Emergency dispatchers are often asked to work overtime, with reports of 12- to 16-hour workdays in certain counties.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The reason why we’re most focused on 911 is because it’s the industry that has this pain point most acutely,” Keenan said. “We think that these telecommunicators should have a chance of taking a break or go to the bathroom.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mustafa Neemuchwala, a partner at NEA, said, “One of the things that blows my mind, you’re not replacing an existing human being; you’re replacing a person they wanted to hire but couldn’t.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Aurelian isn’t the only AI startup tackling non-emergency calls. Hyper, which raised a $6.3 million seed round, came out of stealth last month. Prepared, a company founded in 2019, also recently added an AI voice solution for emergency response.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Aurelian believes its product is ahead of the competition. According to Neemuchwala, Aurelian is the only company actually deployed and handling live calls. “As far as we know, nobody else is actually live,” he said, referring to Aurelian responding to thousands of actual calls daily.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-2216397171.jpg?resize=1200,633" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;When Max Keenan joined Y Combinator’s summer 2022 batch, he was working on Aurelian, a company that automated appointment bookings for hair salons. But less than a year later, a conversation with one of his clients led him to a far more significant problem.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A nearby school’s carpool line was constantly blocking the parking lot of one of Aurelian’s hair salon clients. The salon owner called the city’s non-emergency line and was put on hold for 45 minutes before reaching a dispatcher. “She called me into her office afterwards, and was like, ‘Max, do you want to help me out?’” Keenan told TechCrunch.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;When he started to research how municipal non-emergency response call centers work, he discovered that they are often handled by the same people who are answering actual 911 emergencies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Aurelian pivoted to building an AI voice assistant that helps 911 call centers offload non-emergency call volume. The company announced on Wednesday that it raised a $14 million Series A led by NEA.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s AI voice agent is designed to triage non-urgent issues like noise complaints, parking violations, and even stolen wallet reports —  situations that don’t need an officer’s immediate response or can be handled without dispatching personnel to the scene. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Aurelian’s AI is trained to recognize a real emergency and immediately transfer those calls to a human dispatcher, Keenan said. In other situations, the system collects key information and either creates a report for or relays the details directly to the police department for follow-up action.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since launching its AI assistant in May 2024, Aurelian has been deployed at more than a dozen 911 dispatch centers, including those serving Snohomish County, Washington; Chattanooga, Tennessee; and Kalamazoo, Michigan.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Emergency call centers are adopting Aurelian largely because they are consistently understaffed — a direct result of dispatching being a high-pressure job that ranks among the top 10 industries with the highest turnover rates. Emergency dispatchers are often asked to work overtime, with reports of 12- to 16-hour workdays in certain counties.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The reason why we’re most focused on 911 is because it’s the industry that has this pain point most acutely,” Keenan said. “We think that these telecommunicators should have a chance of taking a break or go to the bathroom.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mustafa Neemuchwala, a partner at NEA, said, “One of the things that blows my mind, you’re not replacing an existing human being; you’re replacing a person they wanted to hire but couldn’t.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Aurelian isn’t the only AI startup tackling non-emergency calls. Hyper, which raised a $6.3 million seed round, came out of stealth last month. Prepared, a company founded in 2019, also recently added an AI voice solution for emergency response.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Aurelian believes its product is ahead of the competition. According to Neemuchwala, Aurelian is the only company actually deployed and handling live calls. “As far as we know, nobody else is actually live,” he said, referring to Aurelian responding to thousands of actual calls daily.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/27/911-centers-are-so-understaffed-theyre-turning-to-ai-to-answer-calls/</guid><pubDate>Wed, 27 Aug 2025 20:42:12 +0000</pubDate></item><item><title>Nvidia reports record sales as the AI boom continues (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/27/nvidia-reports-record-sales-as-the-ai-boom-continues/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/11/GettyImages-2183848501.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Nvidia, the world’s most valuable company, reported another quarter of sustained sales growth in its earnings statement Wednesday, with $46.7 billion in revenue, a&amp;nbsp;56% increase compared to the same period last year. That growth was largely fueled by AI-dominated data center business, which saw a 56% year-over-year increase in revenue.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia also saw its net income grow substantially since last year. The company reported a net income of $26.4 billion in the second quarter, a 59% spike since the same period last year.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;All told, the company brought in $41.1 billion in revenue from data center sales in the quarter, suggesting that AI companies’ demand for cutting-edge GPUs continues to grow. The company’s most advanced generation of chips, Blackwell, accounted for $27 billion of those sales.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Blackwell is the AI platform the world has been waiting for,” said CEO Jensen Huang in a statement accompanying the release. “The AI race is on, and Blackwell is the platform at its center.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Huang said that the company expects to see $3 to 4 trillion in AI infrastructure spending by the end of the decade. “$3 to 4 trillion is fairly sensible for the next five years,” he told one analyst.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company made particular note of its role in the launch of OpenAI’s open source gpt-oss models earlier this month, which involved processing “1.5 million tokens per second on a single Nvidia Blackwell GB200 NVL72 rack-scale system.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The earnings also gave a look at Nvidia’s ongoing struggle to sell its chips in Chinese markets. The company reported no sales of its China-focused H20 chip to Chinese customers in the past quarter; Nvidia did report $650 million worth of H20 chips had been sold to a customer outside China.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The United States has long restricted sales of advanced GPUs to Chinese customers — but the geopolitical situation has changed significantly under President Trump. The company is now permitted to sell chips to China as long as it pays a 15% export tax to the U.S. Treasury, as a result of an unconventional arrangement that legal scholars have described as an unconstitutional abuse of power.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the earnings call, Nvidia CFO Colette Kress made clear that the lack of shipment was a result of uncertainty around the arrangement, which has not been officially codified into a federal regulation. “While a select number of our China-based customers have received licenses over the past few weeks,” Kress said, “we have not shipped any H20 devices based on those licenses.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, the Chinese government has officially discouraged the use of Nvidia chips by local businesses, leading the company to reportedly halt production of the H20 chip earlier this month.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Nvidia said it expects $54 billion in revenue in the third quarter. The company noted that its outlook for the third quarter, which could shift 2% in either direction, doesn’t include any H20 shipments to China.  &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/11/GettyImages-2183848501.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Nvidia, the world’s most valuable company, reported another quarter of sustained sales growth in its earnings statement Wednesday, with $46.7 billion in revenue, a&amp;nbsp;56% increase compared to the same period last year. That growth was largely fueled by AI-dominated data center business, which saw a 56% year-over-year increase in revenue.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia also saw its net income grow substantially since last year. The company reported a net income of $26.4 billion in the second quarter, a 59% spike since the same period last year.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;All told, the company brought in $41.1 billion in revenue from data center sales in the quarter, suggesting that AI companies’ demand for cutting-edge GPUs continues to grow. The company’s most advanced generation of chips, Blackwell, accounted for $27 billion of those sales.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Blackwell is the AI platform the world has been waiting for,” said CEO Jensen Huang in a statement accompanying the release. “The AI race is on, and Blackwell is the platform at its center.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Huang said that the company expects to see $3 to 4 trillion in AI infrastructure spending by the end of the decade. “$3 to 4 trillion is fairly sensible for the next five years,” he told one analyst.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company made particular note of its role in the launch of OpenAI’s open source gpt-oss models earlier this month, which involved processing “1.5 million tokens per second on a single Nvidia Blackwell GB200 NVL72 rack-scale system.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The earnings also gave a look at Nvidia’s ongoing struggle to sell its chips in Chinese markets. The company reported no sales of its China-focused H20 chip to Chinese customers in the past quarter; Nvidia did report $650 million worth of H20 chips had been sold to a customer outside China.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The United States has long restricted sales of advanced GPUs to Chinese customers — but the geopolitical situation has changed significantly under President Trump. The company is now permitted to sell chips to China as long as it pays a 15% export tax to the U.S. Treasury, as a result of an unconventional arrangement that legal scholars have described as an unconstitutional abuse of power.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the earnings call, Nvidia CFO Colette Kress made clear that the lack of shipment was a result of uncertainty around the arrangement, which has not been officially codified into a federal regulation. “While a select number of our China-based customers have received licenses over the past few weeks,” Kress said, “we have not shipped any H20 devices based on those licenses.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, the Chinese government has officially discouraged the use of Nvidia chips by local businesses, leading the company to reportedly halt production of the H20 chip earlier this month.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Nvidia said it expects $54 billion in revenue in the third quarter. The company noted that its outlook for the third quarter, which could shift 2% in either direction, doesn’t include any H20 shipments to China.  &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/27/nvidia-reports-record-sales-as-the-ai-boom-continues/</guid><pubDate>Wed, 27 Aug 2025 21:18:39 +0000</pubDate></item><item><title>How Do You Teach an AI Model to Reason? With Humans (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/ai-reasoning-cosmos/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/cosmos-reasoning-blog-header-1280x680-1.gif" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;AI models are advancing at a rapid rate and scale.&lt;/p&gt;
&lt;p&gt;But what might they lack that (most) humans don’t? Common sense: an understanding, developed through real-world experiences, that birds can’t fly backwards, mirrors are reflective and ice melts into water.&lt;/p&gt;
&lt;p&gt;While such principles seem obvious to humans, they must be taught to AI models tasked with accurately answering complex questions and navigating unpredictable physical environments, such as industrial warehouses or roads.&lt;/p&gt;
&lt;p&gt;NVIDIA is tackling this challenge by developing a set of tests to coach AI models on the limitations of the physical world. In other words, to teach AI common sense.&lt;/p&gt;
&lt;p&gt;These tests are used to develop reasoning models such as NVIDIA Cosmos Reason, an open reasoning vision language model (VLM) used for physical AI applications that are proficient in generating temporally grounded responses. Cosmos Reason just topped the physical reasoning leaderboard on Hugging Face.&lt;/p&gt;
&lt;p&gt;Cosmos Reason is unique compared with previous VLMs as it’s designed to accelerate physical AI development for fields such as robotics, autonomous vehicles and smart spaces. The model can infer and reason through unprecedented scenarios using physical common-sense knowledge.&lt;/p&gt;
&lt;p&gt;For models to understand complex environments — including industrial spaces and laboratories — they must start small. For example, in the test depicted below, the Cosmos Reason model is tasked with answering a multiple-choice question about the relative motion in the video:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Example from Cosmos Reason evaluation dataset&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;What Does Reasoning Look Like for an AI Model?&amp;nbsp;&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;To develop their reasoning capabilities, NVIDIA models are being taught physical common sense about the real world via reinforcement learning.&lt;/p&gt;
&lt;p&gt;For example, robots don’t intuitively know which way is left, right, up or down. They’re taught these spatial-temporal limitations through training. AI-powered robots used in safety testing, such as vehicle crash testing, must be taught to be aware of how their physical forms interact with their surroundings.&lt;/p&gt;
&lt;p&gt;Without embedding common sense into the training of these robots, issues can arise in deployment.&lt;/p&gt;
&lt;p&gt;“Without basic knowledge about the physical world, a robot may fall down or accidentally break something, causing danger to the surrounding people and environment,” said Yin Cui, a Cosmos Reason research scientist at NVIDIA.&lt;/p&gt;
&lt;p&gt;Distilling human common sense about the physical world into models is how NVIDIA is bringing about the next generation of AI.&lt;/p&gt;
&lt;p&gt;Enter the NVIDIA data factory team: a group of global analysts who come from various backgrounds — including bioengineering, business and linguistics. They’re working to develop, analyze and compile hundreds of thousands of data units that will be used to train generative AI models on how to reason.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;The Data Curation Process&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;One of the NVIDIA data factory team’s projects focuses on the development of world foundation models for physical AI applications. These virtual environments create deep learning neural networks that are safer and more effective for training reasoning models, based on simulated domains.&lt;/p&gt;
&lt;p&gt;It all starts with an NVIDIA annotation group that creates question-and-answer pairs based on video data. These videos are all from the real world and can include any type of footage, whether depicting chickens walking around in their coop or cars driving on a rural road.&lt;/p&gt;
&lt;p&gt;For example, an annotator might ask about the video below: “The person uses which hand to cut the spaghetti?”&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Example from Cosmos Reason evaluation dataset&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The annotators then come up with four multiple choice answers labeled A, B, C and D. The model is fed the data and has to reason and choose the correct answer.&lt;/p&gt;
&lt;p&gt;“We’re basically coming up with a test for the model,” said Cui. “All of our questions are multiple choice, like what students would see on a school exam.”&lt;/p&gt;
&lt;p&gt;These question-and-answer pairs are then quality checked by NVIDIA analysts, such as Michelle Li.&lt;/p&gt;
&lt;p&gt;Li has a background in public health and data analytics, which allows her to look at the broader purpose of the data she analyzes.&lt;/p&gt;
&lt;p&gt;“For physical AI, we have a specific goal of wanting to train models on understanding the physical world, which helps me think about the bigger picture when I’m looking at the Q&amp;amp;A pairs and the types of questions that are being presented,” Li said. “I ask myself, do the Q&amp;amp;A pairs that I’m looking at align with our objectives for the guidelines that we have for the project?”&lt;/p&gt;
&lt;p&gt;After this, the data is reviewed by the data factory leads of the project, who make sure it’s up to quality standards and ready to be sent to the Cosmos Reason research team. The scientists then feed the hundred thousands of data units — in this case the Q&amp;amp;A pairs — to the model, training it with reinforcement learning on the bounds and limitations of the physical world.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;What Are the Applications of Reasoning AI?&amp;nbsp;&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Reasoning models are exceptional because they can make sense of their temporal space as well as predict outcomes. They can analyze a situation, come up with a thought web of probable outcomes and infer the most likely scenario.&lt;/p&gt;
&lt;p&gt;Simply put, reasoning AI demonstrates humanlike thinking. It shows its work, giving the user insight into the logic behind its responses.&lt;/p&gt;
&lt;p&gt;Users can ask these models to analyze a video such as of two cars driving on a road. When asked a question like, “What would happen if the cars were driving toward each other on the same lane?” the model can reason and determine the most probable outcome of the proposed scenario — for example, a car crash.&lt;/p&gt;
&lt;p&gt;“We’re building a pioneering reasoning model focused on physical AI,” said Tsung-Yi Lin, a principal research scientist on the Cosmos Reason team at NVIDIA.&lt;/p&gt;
&lt;p&gt;The data factory team’s ability to produce high-quality data will be imperative for driving the development of intelligent autonomous agents and physical AI systems that can safely interact with the real world as NVIDIA reasoning model innovation continues.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Preview &lt;/i&gt;&lt;i&gt;NVDIA Cosmos-Reason1&lt;/i&gt;&lt;i&gt; or download the model on &lt;/i&gt;&lt;i&gt;Hugging Face&lt;/i&gt;&lt;i&gt; and &lt;/i&gt;&lt;i&gt;GitHub&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/cosmos-reasoning-blog-header-1280x680-1.gif" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;AI models are advancing at a rapid rate and scale.&lt;/p&gt;
&lt;p&gt;But what might they lack that (most) humans don’t? Common sense: an understanding, developed through real-world experiences, that birds can’t fly backwards, mirrors are reflective and ice melts into water.&lt;/p&gt;
&lt;p&gt;While such principles seem obvious to humans, they must be taught to AI models tasked with accurately answering complex questions and navigating unpredictable physical environments, such as industrial warehouses or roads.&lt;/p&gt;
&lt;p&gt;NVIDIA is tackling this challenge by developing a set of tests to coach AI models on the limitations of the physical world. In other words, to teach AI common sense.&lt;/p&gt;
&lt;p&gt;These tests are used to develop reasoning models such as NVIDIA Cosmos Reason, an open reasoning vision language model (VLM) used for physical AI applications that are proficient in generating temporally grounded responses. Cosmos Reason just topped the physical reasoning leaderboard on Hugging Face.&lt;/p&gt;
&lt;p&gt;Cosmos Reason is unique compared with previous VLMs as it’s designed to accelerate physical AI development for fields such as robotics, autonomous vehicles and smart spaces. The model can infer and reason through unprecedented scenarios using physical common-sense knowledge.&lt;/p&gt;
&lt;p&gt;For models to understand complex environments — including industrial spaces and laboratories — they must start small. For example, in the test depicted below, the Cosmos Reason model is tasked with answering a multiple-choice question about the relative motion in the video:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Example from Cosmos Reason evaluation dataset&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;What Does Reasoning Look Like for an AI Model?&amp;nbsp;&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;To develop their reasoning capabilities, NVIDIA models are being taught physical common sense about the real world via reinforcement learning.&lt;/p&gt;
&lt;p&gt;For example, robots don’t intuitively know which way is left, right, up or down. They’re taught these spatial-temporal limitations through training. AI-powered robots used in safety testing, such as vehicle crash testing, must be taught to be aware of how their physical forms interact with their surroundings.&lt;/p&gt;
&lt;p&gt;Without embedding common sense into the training of these robots, issues can arise in deployment.&lt;/p&gt;
&lt;p&gt;“Without basic knowledge about the physical world, a robot may fall down or accidentally break something, causing danger to the surrounding people and environment,” said Yin Cui, a Cosmos Reason research scientist at NVIDIA.&lt;/p&gt;
&lt;p&gt;Distilling human common sense about the physical world into models is how NVIDIA is bringing about the next generation of AI.&lt;/p&gt;
&lt;p&gt;Enter the NVIDIA data factory team: a group of global analysts who come from various backgrounds — including bioengineering, business and linguistics. They’re working to develop, analyze and compile hundreds of thousands of data units that will be used to train generative AI models on how to reason.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;The Data Curation Process&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;One of the NVIDIA data factory team’s projects focuses on the development of world foundation models for physical AI applications. These virtual environments create deep learning neural networks that are safer and more effective for training reasoning models, based on simulated domains.&lt;/p&gt;
&lt;p&gt;It all starts with an NVIDIA annotation group that creates question-and-answer pairs based on video data. These videos are all from the real world and can include any type of footage, whether depicting chickens walking around in their coop or cars driving on a rural road.&lt;/p&gt;
&lt;p&gt;For example, an annotator might ask about the video below: “The person uses which hand to cut the spaghetti?”&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Example from Cosmos Reason evaluation dataset&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The annotators then come up with four multiple choice answers labeled A, B, C and D. The model is fed the data and has to reason and choose the correct answer.&lt;/p&gt;
&lt;p&gt;“We’re basically coming up with a test for the model,” said Cui. “All of our questions are multiple choice, like what students would see on a school exam.”&lt;/p&gt;
&lt;p&gt;These question-and-answer pairs are then quality checked by NVIDIA analysts, such as Michelle Li.&lt;/p&gt;
&lt;p&gt;Li has a background in public health and data analytics, which allows her to look at the broader purpose of the data she analyzes.&lt;/p&gt;
&lt;p&gt;“For physical AI, we have a specific goal of wanting to train models on understanding the physical world, which helps me think about the bigger picture when I’m looking at the Q&amp;amp;A pairs and the types of questions that are being presented,” Li said. “I ask myself, do the Q&amp;amp;A pairs that I’m looking at align with our objectives for the guidelines that we have for the project?”&lt;/p&gt;
&lt;p&gt;After this, the data is reviewed by the data factory leads of the project, who make sure it’s up to quality standards and ready to be sent to the Cosmos Reason research team. The scientists then feed the hundred thousands of data units — in this case the Q&amp;amp;A pairs — to the model, training it with reinforcement learning on the bounds and limitations of the physical world.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;What Are the Applications of Reasoning AI?&amp;nbsp;&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Reasoning models are exceptional because they can make sense of their temporal space as well as predict outcomes. They can analyze a situation, come up with a thought web of probable outcomes and infer the most likely scenario.&lt;/p&gt;
&lt;p&gt;Simply put, reasoning AI demonstrates humanlike thinking. It shows its work, giving the user insight into the logic behind its responses.&lt;/p&gt;
&lt;p&gt;Users can ask these models to analyze a video such as of two cars driving on a road. When asked a question like, “What would happen if the cars were driving toward each other on the same lane?” the model can reason and determine the most probable outcome of the proposed scenario — for example, a car crash.&lt;/p&gt;
&lt;p&gt;“We’re building a pioneering reasoning model focused on physical AI,” said Tsung-Yi Lin, a principal research scientist on the Cosmos Reason team at NVIDIA.&lt;/p&gt;
&lt;p&gt;The data factory team’s ability to produce high-quality data will be imperative for driving the development of intelligent autonomous agents and physical AI systems that can safely interact with the real world as NVIDIA reasoning model innovation continues.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Preview &lt;/i&gt;&lt;i&gt;NVDIA Cosmos-Reason1&lt;/i&gt;&lt;i&gt; or download the model on &lt;/i&gt;&lt;i&gt;Hugging Face&lt;/i&gt;&lt;i&gt; and &lt;/i&gt;&lt;i&gt;GitHub&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/ai-reasoning-cosmos/</guid><pubDate>Wed, 27 Aug 2025 23:13:16 +0000</pubDate></item><item><title>[NEW] Maisa AI gets $25M to fix enterprise AI’s 95% failure rate (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/27/maisa-ai-gets-25m-to-fix-enterprise-ais-95-failure-rate/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;A staggering 95% of generative AI pilots at companies are failing, according to a recent report published by MIT’s NANDA initiative. But rather than giving up on the technology altogether, the most advanced organizations are experimenting with agentic AI systems that can learn and be supervised.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s where Maisa AI comes in. The year-old startup has built its entire approach around the premise that enterprise automation requires accountable AI agents, not opaque black boxes. With a new, $25 million seed round led by European VC firm Creandum, it has now launched Maisa Studio, a model-agnostic self-serve platform that helps users deploy digital workers that can be trained with natural language.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While that might sound familiar — reminiscent of so-called vibe coding platforms like Cursor and the Creandum-backed Lovable — Maisa argues that its approach is fundamentally different. “Instead of using AI to build the responses, we use AI to build the process that needs to be executed to get to the response — what we call ‘chain-of-work,” Maisa CEO David Villalón told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The principal architect behind this process is Maisa’s co-founder and Chief Scientific Officer, Manuel Romero, who had previously worked with Villalón at Spanish AI startup Clibrain. In 2024, the duo teamed up to build a solution to hallucinations after seeing firsthand that “you could not rely on AI,” Villalón said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The pair isn’t skeptical about AI, but they think it won’t be feasible for humans to review “three months of work done in five minutes.” To address this, Maisa employs a system called HALP, standing for Human-Augmented LLM Processing. This custom method works like students at the blackboard — it asks users about their needs while the digital workers outline each step they will follow.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Maisa AI - Worker builder" class="wp-image-3040098" height="460" src="https://techcrunch.com/wp-content/uploads/2025/08/Maisa-AI-Worker-builder.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Maisa AI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The startup also developed the Knowledge Processing Unit (KPU), a deterministic system designed to limit hallucinations. While Maisa started out from this technical challenge rather than a use case, it soon found that its bet on trustworthiness and accountability resonated with companies hoping to apply AI to critical tasks. For instance, clients that currently use Maisa in production include a large bank, as well as companies in the car manufacturing and energy sectors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;By serving these enterprise clients, Maisa hopes to position itself as a more advanced form of robotic process automation (RPA) that unlocks productivity gains without requiring companies to rely on rigid predefined rules or extensive manual programming. To meet their needs, the startup also offers them either deployment in its secure cloud or through on-premise deployment.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;This enterprise-first approach means Maisa’s customer base is still very small compared to the millions flocking to freemium vibe-coding platforms. But as these platforms are now exploring how to win enterprise customers, Maisa is moving in the opposite direction with Maisa Studio, which is designed to grow its customer funnel and ease adoption.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup also plans to expand with existing customers that have operations in multiple countries. With dual headquarters in Valencia and San Francisco, Maisa itself already has a foothold in the U.S., as reflected in its cap table; its $5 million pre-seed round last December was led by the San Francisco-based venture firms NFX and Village Global.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, TechCrunch learned exclusively that U.S. firm Forgepoint Capital International participated in this new round via its European joint venture with Spanish bank Banco Santander, highlighting its appeal for regulated sectors.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Focusing on complex use cases demanding accountability from non-technical users could be a differentiator for Maisa, whose competitors include CrewAI and many other AI-powered, business-focused workflow automation products. In a LinkedIn post, Villalón highlighted this “AI framework gold rush,” warning that the “quick start” becomes a long nightmare when you need reliability, auditability, or the ability to fix what went wrong.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Doubling down on its goal to help AI scale, Maisa plans to use its funding to grow from 35 to as many as 65 people by the first quarter of 2026 in order to meet demand. Starting in the last quarter of this year, the startup anticipates rapid growth as it begins serving its waiting list. “We are going to show the market that there is a company that is delivering what has been promised, and that it’s working,” Villalón said.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;A staggering 95% of generative AI pilots at companies are failing, according to a recent report published by MIT’s NANDA initiative. But rather than giving up on the technology altogether, the most advanced organizations are experimenting with agentic AI systems that can learn and be supervised.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s where Maisa AI comes in. The year-old startup has built its entire approach around the premise that enterprise automation requires accountable AI agents, not opaque black boxes. With a new, $25 million seed round led by European VC firm Creandum, it has now launched Maisa Studio, a model-agnostic self-serve platform that helps users deploy digital workers that can be trained with natural language.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While that might sound familiar — reminiscent of so-called vibe coding platforms like Cursor and the Creandum-backed Lovable — Maisa argues that its approach is fundamentally different. “Instead of using AI to build the responses, we use AI to build the process that needs to be executed to get to the response — what we call ‘chain-of-work,” Maisa CEO David Villalón told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The principal architect behind this process is Maisa’s co-founder and Chief Scientific Officer, Manuel Romero, who had previously worked with Villalón at Spanish AI startup Clibrain. In 2024, the duo teamed up to build a solution to hallucinations after seeing firsthand that “you could not rely on AI,” Villalón said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The pair isn’t skeptical about AI, but they think it won’t be feasible for humans to review “three months of work done in five minutes.” To address this, Maisa employs a system called HALP, standing for Human-Augmented LLM Processing. This custom method works like students at the blackboard — it asks users about their needs while the digital workers outline each step they will follow.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Maisa AI - Worker builder" class="wp-image-3040098" height="460" src="https://techcrunch.com/wp-content/uploads/2025/08/Maisa-AI-Worker-builder.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Maisa AI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The startup also developed the Knowledge Processing Unit (KPU), a deterministic system designed to limit hallucinations. While Maisa started out from this technical challenge rather than a use case, it soon found that its bet on trustworthiness and accountability resonated with companies hoping to apply AI to critical tasks. For instance, clients that currently use Maisa in production include a large bank, as well as companies in the car manufacturing and energy sectors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;By serving these enterprise clients, Maisa hopes to position itself as a more advanced form of robotic process automation (RPA) that unlocks productivity gains without requiring companies to rely on rigid predefined rules or extensive manual programming. To meet their needs, the startup also offers them either deployment in its secure cloud or through on-premise deployment.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;This enterprise-first approach means Maisa’s customer base is still very small compared to the millions flocking to freemium vibe-coding platforms. But as these platforms are now exploring how to win enterprise customers, Maisa is moving in the opposite direction with Maisa Studio, which is designed to grow its customer funnel and ease adoption.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup also plans to expand with existing customers that have operations in multiple countries. With dual headquarters in Valencia and San Francisco, Maisa itself already has a foothold in the U.S., as reflected in its cap table; its $5 million pre-seed round last December was led by the San Francisco-based venture firms NFX and Village Global.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, TechCrunch learned exclusively that U.S. firm Forgepoint Capital International participated in this new round via its European joint venture with Spanish bank Banco Santander, highlighting its appeal for regulated sectors.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Focusing on complex use cases demanding accountability from non-technical users could be a differentiator for Maisa, whose competitors include CrewAI and many other AI-powered, business-focused workflow automation products. In a LinkedIn post, Villalón highlighted this “AI framework gold rush,” warning that the “quick start” becomes a long nightmare when you need reliability, auditability, or the ability to fix what went wrong.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Doubling down on its goal to help AI scale, Maisa plans to use its funding to grow from 35 to as many as 65 people by the first quarter of 2026 in order to meet demand. Starting in the last quarter of this year, the startup anticipates rapid growth as it begins serving its waiting list. “We are going to show the market that there is a company that is delivering what has been promised, and that it’s working,” Villalón said.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/27/maisa-ai-gets-25m-to-fix-enterprise-ais-95-failure-rate/</guid><pubDate>Thu, 28 Aug 2025 05:00:00 +0000</pubDate></item></channel></rss>