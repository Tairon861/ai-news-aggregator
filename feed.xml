<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 29 Oct 2025 12:47:34 +0000</lastBuildDate><item><title>[NEW] OpenAI unveils open-weight AI safety models for developers (AI News)</title><link>https://www.artificialintelligence-news.com/news/openai-unveils-open-weight-ai-safety-models-for-developers/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/openai-new-ai-safety-models-artificial-intelligence-developers-open-development-gpt.jpg" /&gt;&lt;/div&gt;&lt;p&gt;We use technologies like cookies to store and/or access device information. We do this to improve browsing experience and to show personalized ads. Consenting to these technologies will allow us to process data such as browsing behavior or unique IDs on this site. Not consenting or withdrawing consent, may adversely affect certain features and functions.&lt;/p&gt;&lt;!-- categories start --&gt;&lt;div class="cmplz-categories"&gt; &lt;details class="cmplz-category cmplz-functional"&gt;   &lt;p&gt; &lt;span class="cmplz-description-functional"&gt;The technical storage or access is strictly necessary for the legitimate purpose of enabling the use of a specific service explicitly requested by the subscriber or user, or for the sole purpose of carrying out the transmission of a communication over an electronic communications network.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt; &lt;details class="cmplz-category cmplz-preferences"&gt;   &lt;p&gt; &lt;span class="cmplz-description-preferences"&gt;The technical storage or access is necessary for the legitimate purpose of storing preferences that are not requested by the subscriber or user.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt; &lt;details class="cmplz-category cmplz-statistics"&gt;   &lt;p&gt; &lt;span class="cmplz-description-statistics"&gt;The technical storage or access that is used exclusively for statistical purposes.&lt;/span&gt; &lt;span class="cmplz-description-statistics-anonymous"&gt;The technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt; &lt;details class="cmplz-category cmplz-marketing"&gt;   &lt;p&gt; &lt;span class="cmplz-description-marketing"&gt;The technical storage or access is required to create user profiles to send advertising, or to track the user on a website or across several websites for similar marketing purposes.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt;&lt;/div&gt;&lt;!-- categories end --&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/openai-new-ai-safety-models-artificial-intelligence-developers-open-development-gpt.jpg" /&gt;&lt;/div&gt;&lt;p&gt;We use technologies like cookies to store and/or access device information. We do this to improve browsing experience and to show personalized ads. Consenting to these technologies will allow us to process data such as browsing behavior or unique IDs on this site. Not consenting or withdrawing consent, may adversely affect certain features and functions.&lt;/p&gt;&lt;!-- categories start --&gt;&lt;div class="cmplz-categories"&gt; &lt;details class="cmplz-category cmplz-functional"&gt;   &lt;p&gt; &lt;span class="cmplz-description-functional"&gt;The technical storage or access is strictly necessary for the legitimate purpose of enabling the use of a specific service explicitly requested by the subscriber or user, or for the sole purpose of carrying out the transmission of a communication over an electronic communications network.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt; &lt;details class="cmplz-category cmplz-preferences"&gt;   &lt;p&gt; &lt;span class="cmplz-description-preferences"&gt;The technical storage or access is necessary for the legitimate purpose of storing preferences that are not requested by the subscriber or user.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt; &lt;details class="cmplz-category cmplz-statistics"&gt;   &lt;p&gt; &lt;span class="cmplz-description-statistics"&gt;The technical storage or access that is used exclusively for statistical purposes.&lt;/span&gt; &lt;span class="cmplz-description-statistics-anonymous"&gt;The technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt; &lt;details class="cmplz-category cmplz-marketing"&gt;   &lt;p&gt; &lt;span class="cmplz-description-marketing"&gt;The technical storage or access is required to create user profiles to send advertising, or to track the user on a website or across several websites for similar marketing purposes.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt;&lt;/div&gt;&lt;!-- categories end --&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/openai-unveils-open-weight-ai-safety-models-for-developers/</guid><pubDate>Wed, 29 Oct 2025 09:31:52 +0000</pubDate></item><item><title>[NEW] DeepSeek may have found a new way to improve AI’s ability to remember (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/29/1126932/deepseek-ocr-visual-compression/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/ocr-patches2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 chronoton/executive-summary_0"&gt;&lt;div class="chronotonExecutiveSummary__summaryContainer--3bc10da0658ecd8e2ef22c6023461fb5"&gt;&lt;button class="chronotonExecutiveSummary__toggleButton--1cd6118db37e8a8252fc4cd8bbadcb85" type="button"&gt;&lt;span class="chronotonExecutiveSummary__toggleText--a713e14989fe65c5162db2b69cb422c9"&gt;EXECUTIVE SUMMARY&lt;/span&gt;&lt;svg class="chronotonExecutiveSummary__toggleArrow--a8c1be9c06a9f066a767b3af80d859a1" fill="none" height="7" viewBox="0 0 11 7" width="11" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M1 1L5.5 5.5L10 1" stroke="#58C0B3" stroke-linecap="round" stroke-width="1.5"&gt;&lt;/svg&gt;&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_1"&gt; &lt;p&gt;An AI model released by Chinese AI company DeepSeek uses new techniques that could significantly improve AI’s ability to “remember.”&lt;/p&gt;  &lt;p&gt;Released last week, the optical character recognition (OCR) model works by extracting text from an image and turning it into machine-readable words. This is the same technology that powers scanner apps, translation of text in photos, and many accessibility tools.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;OCR is already a mature field with numerous high-performing systems, and according to the paper and some early reviews, DeepSeek’s new model performs on par with top models on key benchmarks.&lt;/p&gt;  &lt;p&gt;But researchers say the model’s main innovation lies in how it processes information—specifically, how it stores and retrieves memories. Improving how AI models “remember” information could reduce how much computing power they need to run, thus mitigating AI’s large (and growing) carbon footprint.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;Currently, most large language models break text down into thousands of tiny units called tokens. This turns the text into representations that models can understand. However, these tokens quickly become expensive to store and compute with as conversations with end users grow longer. When a user chats with an AI for lengthy periods, this challenge can cause the AI to forget things the user has already told it and get information muddled, a problem some call “context rot.”&lt;/p&gt;  &lt;p&gt;The new methods developed by DeepSeek (and published in its latest paper) could help to overcome this issue. Instead of storing words as tokens, its system packs written information into image form, almost as if it’s taking a picture of pages from a book. This allows the model to retain nearly the same information while using far fewer tokens, the researchers found.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Essentially, the OCR model is a testbed for these new methods that permit more information to be packed into AI models more efficiently.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Besides using visual tokens instead of just text ones, the model is built on a type of tiered compression that is not unlike how human memories fade: Older or less critical content is stored in a slightly more blurry form in order to save space. Despite that, the paper’s authors argue that this compressed content can still remain accessible in the background, while maintaining a high level of system efficiency.&lt;/p&gt;  &lt;p&gt;Text tokens have long been the default building block in AI systems. Using visual tokens instead is unconventional, and as a result, DeepSeek’s model is quickly capturing researchers’ attention. Andrej Karpathy, the former Tesla AI chief and a founding member of OpenAI, praised the paper on X, saying that images may ultimately be better than text as inputs for LLMs. Text tokens might be “wasteful and just terrible at the input,” he wrote.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Manling Li, an assistant professor of computer science at Northwestern University, says the paper offers a new framework for addressing the existing challenges in AI memory. “While the idea of using image-based tokens for context storage isn’t entirely new, this is the first study I’ve seen that takes it this far and shows it might actually work,” Li says.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__container--08c53dd3bc9bd04e1e42e5f7ca641ab2"&gt;&lt;div class="whyItMatters__header--19f7f372f181cc6d4c06bc7362a44382"&gt;&lt;div class="whyItMatters__title--4af28c786a2bc93df05db111c6c30618"&gt;&lt;span class="whyItMatters__askAi--577f5fe6f54de43e37258d0f2aff4394"&gt;Ask AI&lt;/span&gt;&lt;div&gt;&lt;span class="whyItMatters__whyItMattersTitle--a3694998bb578e159bbd16690b8da390"&gt;Why it matters to you?&lt;/span&gt;&lt;span class="whyItMatters__betaBadge--9e84228b864d33d5b55479433fc91b8a"&gt;BETA&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__description--e1334886c092fa469388d7a24e1e1a55"&gt;&lt;span class="initial-description"&gt;Here’s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates—it might get weird&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="whyItMatters__questionContainer--ec1159210954852b9178c549600959a0"&gt;&lt;div&gt;&lt;button class="whyItMatters__actionButton--674934b6df433ac81e613372979cdb6c" type="button"&gt;Tell me why it matters&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;The method could open up new possibilities in AI research and applications, especially in creating more useful AI agents, says Zihan Wang, a PhD candidate at Northwestern University. He believes that since conversations with AI are continuous, this approach could help models remember more and assist users more effectively.&lt;/p&gt;  &lt;p&gt;The technique can also be used to produce more training data for AI models. Model developers are currently grappling with a severe shortage of quality text to train systems on. But the DeepSeek paper says that the company’s OCR system can generate over 200,000 pages of training data a day on a single GPU.&lt;/p&gt;  &lt;p&gt;The model and paper, however, are only an early exploration of using image tokens rather than text tokens for AI memorization. Li says she hopes to see visual tokens applied not just to memory storage but also to reasoning. Future work, she says, should explore how to make AI’s memory fade in a more dynamic way, akin to how we can recall a life-changing moment from years ago but forget what we ate for lunch last week. Currently, even with DeepSeek’s methods, AI tends to forget and remember in a very linear way—recalling whatever was most recent, but not necessarily what was most important, she says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Despite its attempts to keep a low profile, DeepSeek, based in Hangzhou, China, has built a reputation for pushing the frontier in AI research. The company shocked the industry at the start of this year with the release of DeepSeek-R1, an open-source reasoning model that rivaled leading Western systems in performance despite using far fewer computing resources.&amp;nbsp;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/ocr-patches2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 chronoton/executive-summary_0"&gt;&lt;div class="chronotonExecutiveSummary__summaryContainer--3bc10da0658ecd8e2ef22c6023461fb5"&gt;&lt;button class="chronotonExecutiveSummary__toggleButton--1cd6118db37e8a8252fc4cd8bbadcb85" type="button"&gt;&lt;span class="chronotonExecutiveSummary__toggleText--a713e14989fe65c5162db2b69cb422c9"&gt;EXECUTIVE SUMMARY&lt;/span&gt;&lt;svg class="chronotonExecutiveSummary__toggleArrow--a8c1be9c06a9f066a767b3af80d859a1" fill="none" height="7" viewBox="0 0 11 7" width="11" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M1 1L5.5 5.5L10 1" stroke="#58C0B3" stroke-linecap="round" stroke-width="1.5"&gt;&lt;/svg&gt;&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_1"&gt; &lt;p&gt;An AI model released by Chinese AI company DeepSeek uses new techniques that could significantly improve AI’s ability to “remember.”&lt;/p&gt;  &lt;p&gt;Released last week, the optical character recognition (OCR) model works by extracting text from an image and turning it into machine-readable words. This is the same technology that powers scanner apps, translation of text in photos, and many accessibility tools.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;OCR is already a mature field with numerous high-performing systems, and according to the paper and some early reviews, DeepSeek’s new model performs on par with top models on key benchmarks.&lt;/p&gt;  &lt;p&gt;But researchers say the model’s main innovation lies in how it processes information—specifically, how it stores and retrieves memories. Improving how AI models “remember” information could reduce how much computing power they need to run, thus mitigating AI’s large (and growing) carbon footprint.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;Currently, most large language models break text down into thousands of tiny units called tokens. This turns the text into representations that models can understand. However, these tokens quickly become expensive to store and compute with as conversations with end users grow longer. When a user chats with an AI for lengthy periods, this challenge can cause the AI to forget things the user has already told it and get information muddled, a problem some call “context rot.”&lt;/p&gt;  &lt;p&gt;The new methods developed by DeepSeek (and published in its latest paper) could help to overcome this issue. Instead of storing words as tokens, its system packs written information into image form, almost as if it’s taking a picture of pages from a book. This allows the model to retain nearly the same information while using far fewer tokens, the researchers found.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Essentially, the OCR model is a testbed for these new methods that permit more information to be packed into AI models more efficiently.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Besides using visual tokens instead of just text ones, the model is built on a type of tiered compression that is not unlike how human memories fade: Older or less critical content is stored in a slightly more blurry form in order to save space. Despite that, the paper’s authors argue that this compressed content can still remain accessible in the background, while maintaining a high level of system efficiency.&lt;/p&gt;  &lt;p&gt;Text tokens have long been the default building block in AI systems. Using visual tokens instead is unconventional, and as a result, DeepSeek’s model is quickly capturing researchers’ attention. Andrej Karpathy, the former Tesla AI chief and a founding member of OpenAI, praised the paper on X, saying that images may ultimately be better than text as inputs for LLMs. Text tokens might be “wasteful and just terrible at the input,” he wrote.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Manling Li, an assistant professor of computer science at Northwestern University, says the paper offers a new framework for addressing the existing challenges in AI memory. “While the idea of using image-based tokens for context storage isn’t entirely new, this is the first study I’ve seen that takes it this far and shows it might actually work,” Li says.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__container--08c53dd3bc9bd04e1e42e5f7ca641ab2"&gt;&lt;div class="whyItMatters__header--19f7f372f181cc6d4c06bc7362a44382"&gt;&lt;div class="whyItMatters__title--4af28c786a2bc93df05db111c6c30618"&gt;&lt;span class="whyItMatters__askAi--577f5fe6f54de43e37258d0f2aff4394"&gt;Ask AI&lt;/span&gt;&lt;div&gt;&lt;span class="whyItMatters__whyItMattersTitle--a3694998bb578e159bbd16690b8da390"&gt;Why it matters to you?&lt;/span&gt;&lt;span class="whyItMatters__betaBadge--9e84228b864d33d5b55479433fc91b8a"&gt;BETA&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__description--e1334886c092fa469388d7a24e1e1a55"&gt;&lt;span class="initial-description"&gt;Here’s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates—it might get weird&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="whyItMatters__questionContainer--ec1159210954852b9178c549600959a0"&gt;&lt;div&gt;&lt;button class="whyItMatters__actionButton--674934b6df433ac81e613372979cdb6c" type="button"&gt;Tell me why it matters&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;The method could open up new possibilities in AI research and applications, especially in creating more useful AI agents, says Zihan Wang, a PhD candidate at Northwestern University. He believes that since conversations with AI are continuous, this approach could help models remember more and assist users more effectively.&lt;/p&gt;  &lt;p&gt;The technique can also be used to produce more training data for AI models. Model developers are currently grappling with a severe shortage of quality text to train systems on. But the DeepSeek paper says that the company’s OCR system can generate over 200,000 pages of training data a day on a single GPU.&lt;/p&gt;  &lt;p&gt;The model and paper, however, are only an early exploration of using image tokens rather than text tokens for AI memorization. Li says she hopes to see visual tokens applied not just to memory storage but also to reasoning. Future work, she says, should explore how to make AI’s memory fade in a more dynamic way, akin to how we can recall a life-changing moment from years ago but forget what we ate for lunch last week. Currently, even with DeepSeek’s methods, AI tends to forget and remember in a very linear way—recalling whatever was most recent, but not necessarily what was most important, she says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Despite its attempts to keep a low profile, DeepSeek, based in Hangzhou, China, has built a reputation for pushing the frontier in AI research. The company shocked the industry at the start of this year with the release of DeepSeek-R1, an open-source reasoning model that rivaled leading Western systems in performance despite using far fewer computing resources.&amp;nbsp;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/29/1126932/deepseek-ocr-visual-compression/</guid><pubDate>Wed, 29 Oct 2025 10:00:00 +0000</pubDate></item><item><title>[NEW] The AI Hype Index: Data centers’ neighbors are pivoting to power blackouts (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/29/1126834/the-ai-hype-index-data-centers-neighbors-are-pivoting-to-power-blackouts/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/October-thumb.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt;&lt;p&gt;Separating AI reality from hyped-up fiction isn’t always easy. That’s why we’ve created the AI Hype Index—a simple, at-a-glance summary of everything you need to know about the state of the industry.&lt;/p&gt;    &lt;p&gt;Just about all businesses these days seem to be pivoting to AI, even when they don’t seem to know exactly why they’re investing in it—or even what it really does. “Optimization,” “scaling,” and “maximizing efficiency” are convenient buzzwords bandied about to describe what AI can achieve in theory, but for most of AI companies’ eager customers, the hundreds of billions of dollars they’re pumping into the industry aren’t adding up. And maybe they never will.&lt;/p&gt;  &lt;p&gt;This month’s news doesn’t exactly cast the technology in a glowing light either. A bunch of NGOs and aid agencies are using AI models to generate images of fake suffering people to guilt their Instagram followers. AI translators are pumping out low-quality Wikipedia pages in the languages most vulnerable to going extinct. And thanks to the construction of new AI data centers, lots of neighborhoods living in their shadows are getting forced into their own sort of pivots—fighting back against the power blackouts and water shortages the data centers cause. How’s that for optimization?&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/October-thumb.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt;&lt;p&gt;Separating AI reality from hyped-up fiction isn’t always easy. That’s why we’ve created the AI Hype Index—a simple, at-a-glance summary of everything you need to know about the state of the industry.&lt;/p&gt;    &lt;p&gt;Just about all businesses these days seem to be pivoting to AI, even when they don’t seem to know exactly why they’re investing in it—or even what it really does. “Optimization,” “scaling,” and “maximizing efficiency” are convenient buzzwords bandied about to describe what AI can achieve in theory, but for most of AI companies’ eager customers, the hundreds of billions of dollars they’re pumping into the industry aren’t adding up. And maybe they never will.&lt;/p&gt;  &lt;p&gt;This month’s news doesn’t exactly cast the technology in a glowing light either. A bunch of NGOs and aid agencies are using AI models to generate images of fake suffering people to guilt their Instagram followers. AI translators are pumping out low-quality Wikipedia pages in the languages most vulnerable to going extinct. And thanks to the construction of new AI data centers, lots of neighborhoods living in their shadows are getting forced into their own sort of pivots—fighting back against the power blackouts and water shortages the data centers cause. How’s that for optimization?&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/29/1126834/the-ai-hype-index-data-centers-neighbors-are-pivoting-to-power-blackouts/</guid><pubDate>Wed, 29 Oct 2025 10:41:19 +0000</pubDate></item><item><title>[NEW] Counterintuitive’s new chip aims escape the AI ‘twin trap’ (AI News)</title><link>https://www.artificialintelligence-news.com/news/ai-twin-trap-next-generation-chip-and-software/</link><description>&lt;p&gt;AI startup company, Counterintuitive, has set out to build “reasoning-native computing,” enabling machines to understand rather than simply mimic. Such a breakthrough has the potential to shift AI from pattern recognition to genuine comprehension, paving the way for systems that can think and make decisions – in other words, to be more “human-like.”&lt;/p&gt;&lt;p&gt;Counterintuitive Chairman, Gerard Rego, spoke of what the company terms the ‘twin trap’ problem facing AI, stating the company’s first goal is to solve two key problems that limit current AI systems that prevent even the largest AI systems from being stable, efficient, and genuinely intelligent.&lt;/p&gt;&lt;p&gt;The first trap highlights how today’s AI systems lack reliable, reproducible numerical foundations, having been built on outdated mathematical grounds. Examples include floating-point arithmetic that was designed decades ago for speed in tasks including gaming and graphics. Precision and consistency is therefore lacking.&lt;/p&gt;&lt;p&gt;In numerical systems, each mathematical operation introduces tiny rounding errors that can build up over time. Because of this, running the same AI model twice can provide different results, causing non-determinism. Inconsistency of this nature makes it harder to verify, reproduce, and/or audit AI decisions, particularly in fields like law, finance, and healthcare. If AI outputs can not be explained or proven clearly, they become ‘hallucinations’ – a term coined for their “lack of provability.”&lt;/p&gt;&lt;p&gt;Modern AI has a fundamental struggle with precision that lacks truth, creating an invisible wall. The flaw has become a rigid limit, affecting overall performances, increasing costs, and wasting energy on noise corrections.&lt;/p&gt;&lt;p&gt;Modern AI struggles with precision that lacks truth, creating an invisible wall. The flaw has turned into a rigid limit, affecting performance, increasing costs, and wasting energy on computational noise corrections.&lt;/p&gt;&lt;p&gt;The second trap is found in architecture. Current AI models have no memory. Instead, they predict the next frame or token with no reasoning that helped them achieve the prediction. It’s like predictive text, just on steroids, the company says. Once modern models output something, they don’t retain why they made such a decision and are unable to revisit or build on their own reasoning. It may appear that AI has reason, but it’s only mimicking reasoning, not truly understanding how conclusions are reached.&lt;/p&gt;&lt;p&gt;“Counterintuitive is building a world-class team of mathematicians, computer scientists, physicists and engineers who are veterans of leading global research labs and technology companies, and who understand the Twin Trap fundamental and solve it,” Rego said.&lt;/p&gt;&lt;p&gt;Rego’s team has more than 80 patents pending, spanning deterministic reasoning hardware, causal memory systems, and software frameworks that it believes has the potential to “define the next generation of computing based on reasoning – not mimicry.”&lt;/p&gt;&lt;p&gt;Counterintuitive’s reasoning-native computing research aims to produce the first reasoning chip and software reasoning stack that pushes AI beyond its current limits.&lt;/p&gt;&lt;p&gt;The company’s artificial reasoning unit (ARU) is a new type of compute, rather than a processor, that focuses on memory-driven reasoning and executes causal logic in silicon, unlike GPUs. “Our ARU stack is more than a new chip category being developed – it’s a clean break from probabilistic computing,” said Counterintuitive co-founder, Syam Appala.&lt;/p&gt;&lt;p&gt;“The ARU will usher in the next age of computing, redefining intelligence from imitation to understanding and powering the applications that impact the most important sectors of the economy without the need for massive hardware, data centre and energy budgets.”&lt;/p&gt;&lt;p&gt;By integrating memory-driven causal logic into both hardware and software, Counterintuitive aims to develop systems that are more reliable and auditable. It marks a shift from traditional speed-focused, probabilistic AI black-box models towards more transparent and accountable reasoning.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “Abacus” by blaahhi is licensed under CC BY 2.0.)&lt;/em&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;AI startup company, Counterintuitive, has set out to build “reasoning-native computing,” enabling machines to understand rather than simply mimic. Such a breakthrough has the potential to shift AI from pattern recognition to genuine comprehension, paving the way for systems that can think and make decisions – in other words, to be more “human-like.”&lt;/p&gt;&lt;p&gt;Counterintuitive Chairman, Gerard Rego, spoke of what the company terms the ‘twin trap’ problem facing AI, stating the company’s first goal is to solve two key problems that limit current AI systems that prevent even the largest AI systems from being stable, efficient, and genuinely intelligent.&lt;/p&gt;&lt;p&gt;The first trap highlights how today’s AI systems lack reliable, reproducible numerical foundations, having been built on outdated mathematical grounds. Examples include floating-point arithmetic that was designed decades ago for speed in tasks including gaming and graphics. Precision and consistency is therefore lacking.&lt;/p&gt;&lt;p&gt;In numerical systems, each mathematical operation introduces tiny rounding errors that can build up over time. Because of this, running the same AI model twice can provide different results, causing non-determinism. Inconsistency of this nature makes it harder to verify, reproduce, and/or audit AI decisions, particularly in fields like law, finance, and healthcare. If AI outputs can not be explained or proven clearly, they become ‘hallucinations’ – a term coined for their “lack of provability.”&lt;/p&gt;&lt;p&gt;Modern AI has a fundamental struggle with precision that lacks truth, creating an invisible wall. The flaw has become a rigid limit, affecting overall performances, increasing costs, and wasting energy on noise corrections.&lt;/p&gt;&lt;p&gt;Modern AI struggles with precision that lacks truth, creating an invisible wall. The flaw has turned into a rigid limit, affecting performance, increasing costs, and wasting energy on computational noise corrections.&lt;/p&gt;&lt;p&gt;The second trap is found in architecture. Current AI models have no memory. Instead, they predict the next frame or token with no reasoning that helped them achieve the prediction. It’s like predictive text, just on steroids, the company says. Once modern models output something, they don’t retain why they made such a decision and are unable to revisit or build on their own reasoning. It may appear that AI has reason, but it’s only mimicking reasoning, not truly understanding how conclusions are reached.&lt;/p&gt;&lt;p&gt;“Counterintuitive is building a world-class team of mathematicians, computer scientists, physicists and engineers who are veterans of leading global research labs and technology companies, and who understand the Twin Trap fundamental and solve it,” Rego said.&lt;/p&gt;&lt;p&gt;Rego’s team has more than 80 patents pending, spanning deterministic reasoning hardware, causal memory systems, and software frameworks that it believes has the potential to “define the next generation of computing based on reasoning – not mimicry.”&lt;/p&gt;&lt;p&gt;Counterintuitive’s reasoning-native computing research aims to produce the first reasoning chip and software reasoning stack that pushes AI beyond its current limits.&lt;/p&gt;&lt;p&gt;The company’s artificial reasoning unit (ARU) is a new type of compute, rather than a processor, that focuses on memory-driven reasoning and executes causal logic in silicon, unlike GPUs. “Our ARU stack is more than a new chip category being developed – it’s a clean break from probabilistic computing,” said Counterintuitive co-founder, Syam Appala.&lt;/p&gt;&lt;p&gt;“The ARU will usher in the next age of computing, redefining intelligence from imitation to understanding and powering the applications that impact the most important sectors of the economy without the need for massive hardware, data centre and energy budgets.”&lt;/p&gt;&lt;p&gt;By integrating memory-driven causal logic into both hardware and software, Counterintuitive aims to develop systems that are more reliable and auditable. It marks a shift from traditional speed-focused, probabilistic AI black-box models towards more transparent and accountable reasoning.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “Abacus” by blaahhi is licensed under CC BY 2.0.)&lt;/em&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/ai-twin-trap-next-generation-chip-and-software/</guid><pubDate>Wed, 29 Oct 2025 12:22:06 +0000</pubDate></item><item><title>[NEW] Phia’s founders on how AI is changing online shopping (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/29/phias-founders-on-how-ai-is-changing-online-shopping/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;When Phia‘s founders Phoebe Gates and Sophia Kianni decided to build an AI startup, they targeted an area they understood well: online shopping.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The founders, who met at Stanford when they were randomly paired up as roommates, understood e-commerce because they had spent hours upon hours trying to find the right items to expand their wardrobe. And AI, they realized, had the potential to help people discover, shop and buy in new ways. They also realized that capability was a market opportunity.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“There felt like there was this giant white space for, like, what should we actually buy, and why doesn’t everyone have a personal shopper in their pocket?” said Gates on stage at TechCrunch Disrupt 2025 on Tuesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup emerged from a class project where it proved its initial demand. But the service didn’t launch to the public until Phia found the right product-market fit, Kianni says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The tool, available as a browser extension and app, lets shoppers compare prices, including for second-hand items, adding a sustainability factor to the shopping experience.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Phia says it integrates with more than 150 second-hand platforms, and has over 350 million items in its in-house search database. Kianni pointed out that buying second-hand represents an 80% reduction in carbon footprint, compared with buying new. Plus, it’s cheaper.&lt;/p&gt;

&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3063419" height="453" src="https://techcrunch.com/wp-content/uploads/2025/10/2243869776.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Sophia Kianni, Co-Founder of Phia. &lt;strong&gt;Image Credits:&lt;/strong&gt; Kimberly White/Getty Images for TechCrunch&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Getty Images for TechCrunch / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Kianni said the service also helps users understand the value of what they’re buying. “If you’re looking at a $500 handbag on Phia, you can quickly understand, can you resell that item for $300 or $400? Or, on the contrary, if it’s a fast-fashion piece and you’re buying it for $100 bucks, is it only reselling for $10? Does it immediately depreciate and lose 90% of its value?”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup is also developing an AI shopping advisor that will help users understand value factors like a good deal, or what an item’s retained value may be, as well as fashion basics like whether the item will fit based on the user’s previous orders and returns. The founders said the sizing insights feature is currently in beta with a small group of users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The founders have used a variety of tactics to attract an audience, including an ambassador program, making their own content about the product’s development, and even starting a podcast. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The ability to acquire hundreds of thousands of downloads at a very low cost through the podcast and the various different distribution vehicles has been really important,” said Kianni.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Plus, Gates said, sharing the realities of building a startup with their audience helped Phia’s potential users connect with the founders and their story.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think there was a bit of an ego death that we had to go through,” Gates said. “At first, it’s like, ‘I want to look good in all of our content.’ But if you want people to engage with it, and you want to make content at the volume that we need to, you need to be able to just pull back the curtain.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gates, whose dad is&lt;em&gt; yes, that Gates&lt;/em&gt;, acknowledges that she’s come to the startup experience from a position of privilege, but says they don’t necessarily go to him for advice.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“So, while my dad — I think he’s a genius — he’s not the one shopping on Phia, right? Like, he’s not hunting for the best deal across different sites. He’s not comparing his wish list items for his spring break trip,” she said. &lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;When Phia‘s founders Phoebe Gates and Sophia Kianni decided to build an AI startup, they targeted an area they understood well: online shopping.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The founders, who met at Stanford when they were randomly paired up as roommates, understood e-commerce because they had spent hours upon hours trying to find the right items to expand their wardrobe. And AI, they realized, had the potential to help people discover, shop and buy in new ways. They also realized that capability was a market opportunity.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“There felt like there was this giant white space for, like, what should we actually buy, and why doesn’t everyone have a personal shopper in their pocket?” said Gates on stage at TechCrunch Disrupt 2025 on Tuesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup emerged from a class project where it proved its initial demand. But the service didn’t launch to the public until Phia found the right product-market fit, Kianni says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The tool, available as a browser extension and app, lets shoppers compare prices, including for second-hand items, adding a sustainability factor to the shopping experience.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Phia says it integrates with more than 150 second-hand platforms, and has over 350 million items in its in-house search database. Kianni pointed out that buying second-hand represents an 80% reduction in carbon footprint, compared with buying new. Plus, it’s cheaper.&lt;/p&gt;

&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3063419" height="453" src="https://techcrunch.com/wp-content/uploads/2025/10/2243869776.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Sophia Kianni, Co-Founder of Phia. &lt;strong&gt;Image Credits:&lt;/strong&gt; Kimberly White/Getty Images for TechCrunch&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Getty Images for TechCrunch / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Kianni said the service also helps users understand the value of what they’re buying. “If you’re looking at a $500 handbag on Phia, you can quickly understand, can you resell that item for $300 or $400? Or, on the contrary, if it’s a fast-fashion piece and you’re buying it for $100 bucks, is it only reselling for $10? Does it immediately depreciate and lose 90% of its value?”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup is also developing an AI shopping advisor that will help users understand value factors like a good deal, or what an item’s retained value may be, as well as fashion basics like whether the item will fit based on the user’s previous orders and returns. The founders said the sizing insights feature is currently in beta with a small group of users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The founders have used a variety of tactics to attract an audience, including an ambassador program, making their own content about the product’s development, and even starting a podcast. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The ability to acquire hundreds of thousands of downloads at a very low cost through the podcast and the various different distribution vehicles has been really important,” said Kianni.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Plus, Gates said, sharing the realities of building a startup with their audience helped Phia’s potential users connect with the founders and their story.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think there was a bit of an ego death that we had to go through,” Gates said. “At first, it’s like, ‘I want to look good in all of our content.’ But if you want people to engage with it, and you want to make content at the volume that we need to, you need to be able to just pull back the curtain.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gates, whose dad is&lt;em&gt; yes, that Gates&lt;/em&gt;, acknowledges that she’s come to the startup experience from a position of privilege, but says they don’t necessarily go to him for advice.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“So, while my dad — I think he’s a genius — he’s not the one shopping on Phia, right? Like, he’s not hunting for the best deal across different sites. He’s not comparing his wish list items for his spring break trip,” she said. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/29/phias-founders-on-how-ai-is-changing-online-shopping/</guid><pubDate>Wed, 29 Oct 2025 12:43:50 +0000</pubDate></item></channel></rss>