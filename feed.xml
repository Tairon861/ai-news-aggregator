<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 20 Aug 2025 06:33:25 +0000</lastBuildDate><item><title>[NEW] Qwen-Image Edit gives Photoshop a run for its money with AI-powered text-to-image edits that work in seconds (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/qwen-image-edit-gives-photoshop-a-run-for-its-money-with-ai-powered-text-to-image-edits-that-work-in-seconds/</link><description>&lt;p&gt;Adobe Photoshop is among the most recognizable pieces of software ever created, used by more than 90% of the world’s creative professionals, according to Photutorial.&lt;/p&gt;&lt;p&gt;So the fact that a &lt;strong&gt;new open source AI model&lt;/strong&gt; — Qwen-Image Edit, released yesterday by Chinese e-commerce giant Alibaba’s Qwen Team of AI researchers — is&lt;strong&gt; now able to accomplish a huge number of Photoshop-like editing jobs with text inputs alone&lt;/strong&gt;, is a notable achievement.&lt;/p&gt;&lt;p&gt;Built on the 20-billion-parameter Qwen-Image foundation model released earlier this month, Qwen-Image-Edit extends the system’s unique strengths in text rendering to cover a wide spectrum of editing tasks, from subtle appearance changes to broader semantic transformations.&lt;/p&gt;&lt;p&gt;Simply upload a starting image — I tried one of myself from VentureBeat’s last annual Transform conference in San Francisco — and then type instructions of what you want to change, and Qwen-Image-Edit will return a new image with those edits applied.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Input image example:&lt;/p&gt;



&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-3015788" height="470" src="https://venturebeat.com/wp-content/uploads/2025/08/tumblr_inline_syz91yFD9E1rnhd8o_500.png" width="461" /&gt;&lt;figcaption class="wp-element-caption"&gt;Photo credit: Michael O’Donnell Photography&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Output image example with prompt: “Make the man wearing a tuxedo.”&lt;/p&gt;



&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3015789" height="600" src="https://venturebeat.com/wp-content/uploads/2025/08/1755620145-2.png?w=600" width="600" /&gt;&lt;/figure&gt;



&lt;p&gt;The model is available now across several platforms, including &lt;strong&gt;Qwen Chat&lt;/strong&gt;, &lt;strong&gt;Hugging Face&lt;/strong&gt;, &lt;strong&gt;ModelScope&lt;/strong&gt;, &lt;strong&gt;GitHub&lt;/strong&gt;, and through the &lt;strong&gt;Alibaba Cloud application programming interface (API)&lt;/strong&gt;, the latter which allows any third-party developer or enterprise to integrate this new model into their own applications and workflows. &lt;/p&gt;



&lt;p&gt;I created my examples above on Qwen Chat, the Qwen Team’s rival to OpenAI’s ChatGPT, however, it should be noted for any aspiring users that generations are limited to about 8 free jobs (input/outputs) per 12 hour period before it resets. Paying users can have access to more jobs.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015793" height="600" src="https://venturebeat.com/wp-content/uploads/2025/08/Screenshot-2025-08-19-at-4.14.12%E2%80%AFPM.png?w=737" width="737" /&gt;&lt;/figure&gt;



&lt;p&gt;With support for both English and Chinese inputs, and a dual focus on both semantic meaning and visual fidelity, Qwen-Image-Edit aims to lower barriers to professional-grade visual content creation.&lt;/p&gt;



&lt;p&gt;And given that the model is available as an open source code under an Apache 2.0 license, it’s safe for enterprises to take, download and set up for free on their own hardware or virtual clouds/machines, potentially resulting in a huge cost savings from proprietary software like Photoshop. &lt;/p&gt;



&lt;p&gt;As &lt;strong&gt;Junyang Lin, a Qwen Team researcher wrote on X, “it can remove a strand of hair, very delicate image modification.”&lt;/strong&gt;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;p&gt;The team’s announcement echoes this sentiment, presenting Qwen-Image-Edit not as an entirely new system, but as a natural extension of Qwen-Image that applies its unique text rendering and dual-encoding approach directly to editing tasks.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-dual-encodings-allow-for-edits-preserving-style-and-content-of-original-image"&gt;Dual encodings allow for edits preserving style and content of original image&lt;/h2&gt;



&lt;p&gt;Qwen-Image-Edit builds on the foundation established by &lt;strong&gt;Qwen-Image&lt;/strong&gt;, which was introduced earlier this year as a large-scale model specializing in both image generation and text rendering. &lt;/p&gt;



&lt;p&gt;Qwen-Image’s technical report highlighted its ability to handle complex tasks like paragraph-level text rendering, Chinese and English characters, and multi-line layouts with accuracy. &lt;/p&gt;



&lt;p&gt;The report also emphasized a &lt;strong&gt;dual-encoding mechanism&lt;/strong&gt;, feeding images simultaneously into Qwen2.5-VL for semantic control and a variational autoencoder (VAE) for reconstructive detail. This approach allows edits that remain faithful to both the intent of the prompt and the look of the original image.&lt;/p&gt;



&lt;p&gt;Those same architectural choices underpin Qwen-Image-Edit. By leveraging dual encodings, the model can adjust at two levels: &lt;strong&gt;semantic edits&lt;/strong&gt; that change the meaning or structure of a scene, and &lt;strong&gt;appearance edits&lt;/strong&gt; that introduce or remove elements while keeping the rest untouched. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Semantic editing&lt;/strong&gt; includes creating new intellectual property, rotating objects 90 or 180 degrees to reveal different views, or transforming an input into another style such as Studio Ghibli-inspired art. These edits typically modify many pixels but preserve the underlying identity of objects.&lt;/p&gt;



&lt;p&gt;Here’s an example of semantic editing from Shridhar Athinarayanan, an engineer at AI applications platform Replicate, who used a Replicate-hosted implementation or “inference” of Qwen to reskin a photo of Manhattan to look like a toy Lego set.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;p&gt;&lt;strong&gt;Appearance editing&lt;/strong&gt; focuses on precise, local changes. In these cases, most of the image remains unchanged while specific objects are altered. Demonstrations include adding a signboard that generates a reflection in water, removing stray hair strands from a portrait, and changing the color of a single letter in a text image.&lt;/p&gt;



&lt;p&gt;One good example of appearance editing with Qwen-Image Edit comes from AnswerAI co-founder and CEO Thomas Hill who posted a side-by-side on X showing his wife in her wedding dress below an archway and another with the same archway covered with graffiti:&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;p&gt;Combined with Qwen’s established strength in rendering Chinese and English text, the editing-focused system is positioned as a flexible tool for creators who need more than simple generative imagery.&lt;/p&gt;



&lt;p&gt;The dual control over semantic scope and appearance fidelity means the same tool can serve very different needs, from creative IP development to production-level photo retouching.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-adding-or-removing-text-to-images"&gt;Adding or removing text to images&lt;/h2&gt;



&lt;p&gt;Another standout capability is &lt;strong&gt;bilingual text editing&lt;/strong&gt;. Qwen-Image-Edit allows users to add, remove, or modify text in both Chinese and English while preserving font, size, and style. &lt;/p&gt;



&lt;p&gt;This expands on Qwen-Image’s reputation for strong text rendering, particularly in challenging scenarios like intricate Chinese characters.&lt;/p&gt;



&lt;p&gt;In practice, this allows for accurate editing of posters, signs, T-shirts, or calligraphy artworks where small text details matter, as seen in another example from Replicate below.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;p&gt;One demonstration involved correcting errors in a piece of generated Chinese calligraphy through a step-by-step chained editing process. &lt;/p&gt;



&lt;p&gt;Users could highlight incorrect regions, instruct the system to fix them, and then further refine details until the correct characters were rendered. This iterative approach shows how the model can be applied to high-stakes editing tasks where precision is essential.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-applications-and-use-cases"&gt;Applications and use cases&lt;/h2&gt;



&lt;p&gt;The Qwen team has highlighted a range of potential applications:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Creative design and IP expansion&lt;/strong&gt;, such as generating mascot-based emoji packs.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Advertising and content creation&lt;/strong&gt;, where logos, signage, and text-heavy visuals can be customized.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Virtual avatars and art&lt;/strong&gt;, with style transfer supporting unique character representations.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Photography and personal use&lt;/strong&gt;, including background adjustments, clothing changes, and object removal.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Cultural preservation&lt;/strong&gt;, demonstrated through correcting classical calligraphy works.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;By bridging fine-grained editing with broader creative transformations, Qwen-Image-Edit caters to professionals who need control while remaining approachable for casual experimentation.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-benchmarking-and-performance"&gt;Benchmarking and performance&lt;/h2&gt;



&lt;p&gt;According to the Qwen team, evaluations across public benchmarks indicate that Qwen-Image-Edit delivers &lt;strong&gt;state-of-the-art performance&lt;/strong&gt; in image editing. &lt;/p&gt;



&lt;p&gt;This follows from the broader Qwen-Image technical evaluations, where the base model achieved leading results in both general image generation and text rendering tasks. &lt;/p&gt;



&lt;p&gt;While specific editing benchmark figures were not detailed in the release, Qwen-Image itself ranked highly in independent evaluations such as AI Arena, where human raters compared outputs across models from different providers.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-api-pricing-and-availability"&gt;API pricing and availability&lt;/h2&gt;



&lt;p&gt;Through &lt;strong&gt;Alibaba Cloud Model Studio&lt;/strong&gt;, developers can access Qwen-Image-Edit as an API. Pricing is set at &lt;strong&gt;$0.045 per image&lt;/strong&gt;, with a free quota of &lt;strong&gt;100 images valid for 180 days&lt;/strong&gt; after activation. &lt;/p&gt;



&lt;p&gt;The service is initially available in the &lt;strong&gt;Singapore region&lt;/strong&gt;, with a rate limit of &lt;strong&gt;five requests per second&lt;/strong&gt; and up to &lt;strong&gt;two concurrent tasks per account&lt;/strong&gt;.&lt;/p&gt;



&lt;p&gt;To use the API, developers must obtain a Model Studio API key and can call the model via HTTP or through the DashScope SDK in Python or Java. &lt;/p&gt;



&lt;p&gt;Images can be submitted as URLs or in Base64 format, with supported resolutions ranging from 512 to 4,096 pixels and file sizes up to 10 MB. Output images are hosted on Alibaba Cloud Object Storage with links valid for 24 hours, requiring users to download and save results promptly.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-s-next-for-qwen"&gt;What’s next for Qwen?&lt;/h2&gt;



&lt;p&gt;Qwen positions Image-Edit as a step towar&lt;strong&gt;d lowering barriers for visual content creation.&lt;/strong&gt; By making precise, style-consistent editing more accessible, the model &lt;strong&gt;could support applications from design studios to casual users refining personal projects.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;The system also signals a broader trend in AI development: moving beyond single-purpose generation toward tools that integrate editing, correction, and refinement. &lt;/p&gt;



&lt;p&gt;With both semantic flexibility and appearance-level precision, Qwen-Image-Edit reflects this shift, blending the generative strengths of large models with the reliability required for professional editing.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;p&gt;Adobe Photoshop is among the most recognizable pieces of software ever created, used by more than 90% of the world’s creative professionals, according to Photutorial.&lt;/p&gt;&lt;p&gt;So the fact that a &lt;strong&gt;new open source AI model&lt;/strong&gt; — Qwen-Image Edit, released yesterday by Chinese e-commerce giant Alibaba’s Qwen Team of AI researchers — is&lt;strong&gt; now able to accomplish a huge number of Photoshop-like editing jobs with text inputs alone&lt;/strong&gt;, is a notable achievement.&lt;/p&gt;&lt;p&gt;Built on the 20-billion-parameter Qwen-Image foundation model released earlier this month, Qwen-Image-Edit extends the system’s unique strengths in text rendering to cover a wide spectrum of editing tasks, from subtle appearance changes to broader semantic transformations.&lt;/p&gt;&lt;p&gt;Simply upload a starting image — I tried one of myself from VentureBeat’s last annual Transform conference in San Francisco — and then type instructions of what you want to change, and Qwen-Image-Edit will return a new image with those edits applied.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Input image example:&lt;/p&gt;



&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-3015788" height="470" src="https://venturebeat.com/wp-content/uploads/2025/08/tumblr_inline_syz91yFD9E1rnhd8o_500.png" width="461" /&gt;&lt;figcaption class="wp-element-caption"&gt;Photo credit: Michael O’Donnell Photography&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Output image example with prompt: “Make the man wearing a tuxedo.”&lt;/p&gt;



&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3015789" height="600" src="https://venturebeat.com/wp-content/uploads/2025/08/1755620145-2.png?w=600" width="600" /&gt;&lt;/figure&gt;



&lt;p&gt;The model is available now across several platforms, including &lt;strong&gt;Qwen Chat&lt;/strong&gt;, &lt;strong&gt;Hugging Face&lt;/strong&gt;, &lt;strong&gt;ModelScope&lt;/strong&gt;, &lt;strong&gt;GitHub&lt;/strong&gt;, and through the &lt;strong&gt;Alibaba Cloud application programming interface (API)&lt;/strong&gt;, the latter which allows any third-party developer or enterprise to integrate this new model into their own applications and workflows. &lt;/p&gt;



&lt;p&gt;I created my examples above on Qwen Chat, the Qwen Team’s rival to OpenAI’s ChatGPT, however, it should be noted for any aspiring users that generations are limited to about 8 free jobs (input/outputs) per 12 hour period before it resets. Paying users can have access to more jobs.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015793" height="600" src="https://venturebeat.com/wp-content/uploads/2025/08/Screenshot-2025-08-19-at-4.14.12%E2%80%AFPM.png?w=737" width="737" /&gt;&lt;/figure&gt;



&lt;p&gt;With support for both English and Chinese inputs, and a dual focus on both semantic meaning and visual fidelity, Qwen-Image-Edit aims to lower barriers to professional-grade visual content creation.&lt;/p&gt;



&lt;p&gt;And given that the model is available as an open source code under an Apache 2.0 license, it’s safe for enterprises to take, download and set up for free on their own hardware or virtual clouds/machines, potentially resulting in a huge cost savings from proprietary software like Photoshop. &lt;/p&gt;



&lt;p&gt;As &lt;strong&gt;Junyang Lin, a Qwen Team researcher wrote on X, “it can remove a strand of hair, very delicate image modification.”&lt;/strong&gt;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;p&gt;The team’s announcement echoes this sentiment, presenting Qwen-Image-Edit not as an entirely new system, but as a natural extension of Qwen-Image that applies its unique text rendering and dual-encoding approach directly to editing tasks.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-dual-encodings-allow-for-edits-preserving-style-and-content-of-original-image"&gt;Dual encodings allow for edits preserving style and content of original image&lt;/h2&gt;



&lt;p&gt;Qwen-Image-Edit builds on the foundation established by &lt;strong&gt;Qwen-Image&lt;/strong&gt;, which was introduced earlier this year as a large-scale model specializing in both image generation and text rendering. &lt;/p&gt;



&lt;p&gt;Qwen-Image’s technical report highlighted its ability to handle complex tasks like paragraph-level text rendering, Chinese and English characters, and multi-line layouts with accuracy. &lt;/p&gt;



&lt;p&gt;The report also emphasized a &lt;strong&gt;dual-encoding mechanism&lt;/strong&gt;, feeding images simultaneously into Qwen2.5-VL for semantic control and a variational autoencoder (VAE) for reconstructive detail. This approach allows edits that remain faithful to both the intent of the prompt and the look of the original image.&lt;/p&gt;



&lt;p&gt;Those same architectural choices underpin Qwen-Image-Edit. By leveraging dual encodings, the model can adjust at two levels: &lt;strong&gt;semantic edits&lt;/strong&gt; that change the meaning or structure of a scene, and &lt;strong&gt;appearance edits&lt;/strong&gt; that introduce or remove elements while keeping the rest untouched. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Semantic editing&lt;/strong&gt; includes creating new intellectual property, rotating objects 90 or 180 degrees to reveal different views, or transforming an input into another style such as Studio Ghibli-inspired art. These edits typically modify many pixels but preserve the underlying identity of objects.&lt;/p&gt;



&lt;p&gt;Here’s an example of semantic editing from Shridhar Athinarayanan, an engineer at AI applications platform Replicate, who used a Replicate-hosted implementation or “inference” of Qwen to reskin a photo of Manhattan to look like a toy Lego set.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;p&gt;&lt;strong&gt;Appearance editing&lt;/strong&gt; focuses on precise, local changes. In these cases, most of the image remains unchanged while specific objects are altered. Demonstrations include adding a signboard that generates a reflection in water, removing stray hair strands from a portrait, and changing the color of a single letter in a text image.&lt;/p&gt;



&lt;p&gt;One good example of appearance editing with Qwen-Image Edit comes from AnswerAI co-founder and CEO Thomas Hill who posted a side-by-side on X showing his wife in her wedding dress below an archway and another with the same archway covered with graffiti:&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;p&gt;Combined with Qwen’s established strength in rendering Chinese and English text, the editing-focused system is positioned as a flexible tool for creators who need more than simple generative imagery.&lt;/p&gt;



&lt;p&gt;The dual control over semantic scope and appearance fidelity means the same tool can serve very different needs, from creative IP development to production-level photo retouching.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-adding-or-removing-text-to-images"&gt;Adding or removing text to images&lt;/h2&gt;



&lt;p&gt;Another standout capability is &lt;strong&gt;bilingual text editing&lt;/strong&gt;. Qwen-Image-Edit allows users to add, remove, or modify text in both Chinese and English while preserving font, size, and style. &lt;/p&gt;



&lt;p&gt;This expands on Qwen-Image’s reputation for strong text rendering, particularly in challenging scenarios like intricate Chinese characters.&lt;/p&gt;



&lt;p&gt;In practice, this allows for accurate editing of posters, signs, T-shirts, or calligraphy artworks where small text details matter, as seen in another example from Replicate below.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;p&gt;One demonstration involved correcting errors in a piece of generated Chinese calligraphy through a step-by-step chained editing process. &lt;/p&gt;



&lt;p&gt;Users could highlight incorrect regions, instruct the system to fix them, and then further refine details until the correct characters were rendered. This iterative approach shows how the model can be applied to high-stakes editing tasks where precision is essential.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-applications-and-use-cases"&gt;Applications and use cases&lt;/h2&gt;



&lt;p&gt;The Qwen team has highlighted a range of potential applications:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Creative design and IP expansion&lt;/strong&gt;, such as generating mascot-based emoji packs.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Advertising and content creation&lt;/strong&gt;, where logos, signage, and text-heavy visuals can be customized.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Virtual avatars and art&lt;/strong&gt;, with style transfer supporting unique character representations.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Photography and personal use&lt;/strong&gt;, including background adjustments, clothing changes, and object removal.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Cultural preservation&lt;/strong&gt;, demonstrated through correcting classical calligraphy works.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;By bridging fine-grained editing with broader creative transformations, Qwen-Image-Edit caters to professionals who need control while remaining approachable for casual experimentation.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-benchmarking-and-performance"&gt;Benchmarking and performance&lt;/h2&gt;



&lt;p&gt;According to the Qwen team, evaluations across public benchmarks indicate that Qwen-Image-Edit delivers &lt;strong&gt;state-of-the-art performance&lt;/strong&gt; in image editing. &lt;/p&gt;



&lt;p&gt;This follows from the broader Qwen-Image technical evaluations, where the base model achieved leading results in both general image generation and text rendering tasks. &lt;/p&gt;



&lt;p&gt;While specific editing benchmark figures were not detailed in the release, Qwen-Image itself ranked highly in independent evaluations such as AI Arena, where human raters compared outputs across models from different providers.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-api-pricing-and-availability"&gt;API pricing and availability&lt;/h2&gt;



&lt;p&gt;Through &lt;strong&gt;Alibaba Cloud Model Studio&lt;/strong&gt;, developers can access Qwen-Image-Edit as an API. Pricing is set at &lt;strong&gt;$0.045 per image&lt;/strong&gt;, with a free quota of &lt;strong&gt;100 images valid for 180 days&lt;/strong&gt; after activation. &lt;/p&gt;



&lt;p&gt;The service is initially available in the &lt;strong&gt;Singapore region&lt;/strong&gt;, with a rate limit of &lt;strong&gt;five requests per second&lt;/strong&gt; and up to &lt;strong&gt;two concurrent tasks per account&lt;/strong&gt;.&lt;/p&gt;



&lt;p&gt;To use the API, developers must obtain a Model Studio API key and can call the model via HTTP or through the DashScope SDK in Python or Java. &lt;/p&gt;



&lt;p&gt;Images can be submitted as URLs or in Base64 format, with supported resolutions ranging from 512 to 4,096 pixels and file sizes up to 10 MB. Output images are hosted on Alibaba Cloud Object Storage with links valid for 24 hours, requiring users to download and save results promptly.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-s-next-for-qwen"&gt;What’s next for Qwen?&lt;/h2&gt;



&lt;p&gt;Qwen positions Image-Edit as a step towar&lt;strong&gt;d lowering barriers for visual content creation.&lt;/strong&gt; By making precise, style-consistent editing more accessible, the model &lt;strong&gt;could support applications from design studios to casual users refining personal projects.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;The system also signals a broader trend in AI development: moving beyond single-purpose generation toward tools that integrate editing, correction, and refinement. &lt;/p&gt;



&lt;p&gt;With both semantic flexibility and appearance-level precision, Qwen-Image-Edit reflects this shift, blending the generative strengths of large models with the reliability required for professional editing.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/qwen-image-edit-gives-photoshop-a-run-for-its-money-with-ai-powered-text-to-image-edits-that-work-in-seconds/</guid><pubDate>Tue, 19 Aug 2025 20:27:37 +0000</pubDate></item><item><title>[NEW] DeepSeek V3.1 just dropped — and it might be the most powerful open AI yet (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/deepseek-v3-1-just-dropped-and-it-might-be-the-most-powerful-open-ai-yet/</link><description>&lt;p&gt;Chinese artificial intelligence startup DeepSeek made waves across the global AI community Tuesday with the quiet release of its most ambitious model yet — a 685-billion parameter system that challenges the dominance of American AI giants while reshaping the competitive landscape through open-source accessibility.&lt;/p&gt;&lt;p&gt;The Hangzhou-based company, backed by High-Flyer Capital Management, uploaded DeepSeek V3.1 to Hugging Face without fanfare, a characteristically understated approach that belies the model’s potential impact. Within hours, early performance tests revealed benchmark scores that rival proprietary systems from OpenAI and Anthropic, while the model’s open-source license ensures global access unconstrained by geopolitical tensions.&lt;/p&gt;&lt;p&gt;The release of DeepSeek V3.1 represents more than just another incremental improvement in AI capabilities. It signals a fundamental shift in how the world’s most advanced artificial intelligence systems might be developed, distributed, and controlled — with potentially profound implications for the ongoing technological competition between the United States and China.&lt;/p&gt;&lt;p&gt;Within hours of its Hugging Face debut, DeepSeek V3.1 began climbing popularity rankings, drawing praise from researchers worldwide who downloaded and tested its capabilities. The model achieved a 71.6% score on the prestigious Aider coding benchmark, establishing itself as one of the top-performing models available and directly challenging the dominance of American AI giants.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Deepseek V3.1 is already 4th trending on HF with a silent release without model card ??? &lt;/p&gt;&lt;p&gt;The power of 80,000 followers on @huggingface (first org with 100k when?)! pic.twitter.com/OjeBfWQ7St&lt;/p&gt;— clem ? (@ClementDelangue) August 19, 2025&lt;/blockquote&gt; 



&lt;h2 class="wp-block-heading" id="h-how-deepseek-v3-1-delivers-breakthrough-performance"&gt;How DeepSeek V3.1 delivers breakthrough performance&lt;/h2&gt;



&lt;p&gt;DeepSeek V3.1 delivers remarkable engineering achievements that redefine expectations for AI model performance. The system processes up to 128,000 tokens of context — roughly equivalent to a 400-page book — while maintaining response speeds that dwarf slower reasoning-based competitors. The model supports multiple precision formats, from standard BF16 to experimental FP8, allowing developers to optimize performance for their specific hardware constraints.&lt;/p&gt;



&lt;p&gt;The real breakthrough lies in what DeepSeek calls its “hybrid architecture.” Unlike previous attempts at combining different AI capabilities, which often resulted in systems that performed poorly at everything, V3.1 seamlessly integrates chat, reasoning, and coding functions into a single, coherent model.&lt;/p&gt;



&lt;p&gt;“Deepseek v3.1 scores 71.6% on aider – non-reasoning SOTA,” tweeted AI researcher Andrew Christianson, adding that it is “1% more than Claude Opus 4 while being 68 times cheaper.”  The achievement places DeepSeek in rarified company, matching performance levels previously reserved for the most expensive proprietary systems.&lt;/p&gt;



&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;"1% more than Claude Opus 4 while being 68 times cheaper." pic.twitter.com/vKb6wWwjXq&lt;/p&gt;— Andrew I. Christianson (@ai_christianson) August 19, 2025&lt;/blockquote&gt; 



&lt;p&gt;Community analysis revealed sophisticated technical innovations hidden beneath the surface. Researcher “Rookie“, who is also a moderator of the subreddits r/DeepSeek &amp;amp; r/LocalLLaMA, claims they discovered four new special tokens embedded in the model’s architecture: search capabilities that allow real-time web integration and thinking tokens that enable internal reasoning processes. These additions suggest DeepSeek has solved fundamental challenges that have plagued other hybrid systems.&lt;/p&gt;



&lt;p&gt;The model’s efficiency proves equally impressive. At roughly $1.01 per complete coding task, DeepSeek V3.1 delivers results comparable to systems costing nearly $70 per equivalent workload. For enterprise users managing thousands of daily AI interactions, such cost differences translate into millions of dollars in potential savings.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-strategic-timing-reveals-calculated-challenge-to-american-ai-dominance"&gt;Strategic timing reveals calculated challenge to American AI dominance&lt;/h2&gt;



&lt;p&gt;DeepSeek timed its release with surgical precision. The V3.1 launch comes just weeks after OpenAI unveiled GPT-5 and Anthropic launched Claude 4, both positioned as frontier models representing the cutting edge of artificial intelligence capability. By matching their performance while maintaining open source accessibility, DeepSeek directly challenges the fundamental business models underlying American AI leadership.&lt;/p&gt;



&lt;p&gt;The strategic implications extend far beyond technical specifications. While American companies maintain strict control over their most advanced systems, requiring expensive API access and imposing usage restrictions, DeepSeek makes comparable capabilities freely available for download, modification, and deployment anywhere in the world.&lt;/p&gt;



&lt;p&gt;This philosophical divide reflects broader differences in how the two superpowers approach technological development. American firms like OpenAI and Anthropic view their models as valuable intellectual property requiring protection and monetization. Chinese companies increasingly treat advanced AI as a public good that accelerates innovation through widespread access.&lt;/p&gt;



&lt;p&gt;“DeepSeek quietly removed the R1 tag. Now every entry point defaults to V3.1—128k context, unified responses, consistent style,” observed journalist Poe Zhao. “Looks less like multiple public models, more like a strategic consolidation. A Chinese answer to the fragmentation risk in the LLM race.”&lt;/p&gt;



&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;DeepSeek quietly removed the R1 tag. Now every entry point defaults to V3.1—128k context, unified responses, consistent style. Looks less like multiple public models, more like a strategic consolidation. A Chinese answer to the fragmentation risk in the LLM race. pic.twitter.com/hbS6NjaYAw&lt;/p&gt;— Poe Zhao (@poezhao0605) August 19, 2025&lt;/blockquote&gt; 



&lt;p&gt;The consolidation strategy suggests DeepSeek has learned from earlier mistakes, both its own and those of competitors. Previous hybrid models, including initial versions from Chinese rival Qwen, suffered from performance degradation when attempting to combine different capabilities. DeepSeek appears to have cracked that code.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-open-source-strategy-disrupts-traditional-ai-economics"&gt;How open source strategy disrupts traditional AI economics&lt;/h2&gt;



&lt;p&gt;DeepSeek’s approach fundamentally challenges assumptions about how frontier AI systems should be developed and distributed. Traditional venture capital-backed approaches require massive investments in computing infrastructure, research talent, and regulatory compliance — costs that must eventually be recouped through premium pricing.&lt;/p&gt;



&lt;p&gt;DeepSeek’s open source strategy turns this model upside down. By making advanced capabilities freely available, the company accelerates adoption while potentially undermining competitors’ ability to maintain high margins on similar capabilities. The approach mirrors earlier disruptions in software, where open source alternatives eventually displaced proprietary solutions across entire industries.&lt;/p&gt;



&lt;p&gt;Enterprise decision makers face both exciting opportunities and complex challenges. Organizations can now download, customize, and deploy frontier-level AI capabilities without ongoing licensing fees or usage restrictions. The model’s 700GB size requires substantial computational resources, but cloud providers will likely offer hosted versions that eliminate infrastructure barriers.&lt;/p&gt;



&lt;p&gt;“That’s almost the same score as R1 0528 (71.4% with $4.8), but quicker and cheaper, right?” noted one Reddit user analyzing benchmark results. “R1 0528 quality but instant instead of having to wait minutes for a response.”&lt;/p&gt;



&lt;p&gt;The speed advantage could prove particularly valuable for interactive applications where users expect immediate responses. Previous reasoning models, while capable, often required minutes to process complex queries — making them unsuitable for real-time use cases.&lt;/p&gt;



&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;DeepSeek-V3-0324&lt;/p&gt;&lt;p&gt;write a p5.js program that shows a ball bouncing inside a spinning hexagon. The ball should be affected by gravity and friction, and it must bounce off the rotating walls realistically https://t.co/yT2Pfd0wPt pic.twitter.com/AUG6Tkmpau&lt;/p&gt;— AK (@_akhaliq) March 25, 2025&lt;/blockquote&gt; 







&lt;p&gt;The international response to DeepSeek V3.1 reveals how quickly technical excellence transcends geopolitical boundaries. Developers from around the world began downloading, testing, and praising the model’s capabilities within hours of release, regardless of its Chinese origins.&lt;/p&gt;



&lt;p&gt;“Open Source AI is at its peak right now… just look at the current Hugging Face trending list,” tweeted Hugging Face head of product Victor Mustar, noting that Chinese models increasingly dominate the platform’s most popular downloads. The trend suggests that technical merit, rather than national origin, drives adoption decisions among developers.&lt;/p&gt;



&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Open Source AI is at its peak right now… just look at the current Hugging Face trending list:&lt;/p&gt;&lt;p&gt;? Qwen/Qwen-Image-Edit&lt;br /&gt;? google/gemma-3-270m&lt;br /&gt;? tencent/Hunyuan-GameCraft-1.0&lt;br /&gt;? openai/gpt-oss-20b&lt;br /&gt;? zai-org/GLM-4.5V&lt;br /&gt;? deepseek-ai/DeepSeek-V3.1-Base&lt;br /&gt;? google/gemma-3-270m-it… pic.twitter.com/57zuEbOqmK&lt;/p&gt;— Victor M (@victormustar) August 19, 2025&lt;/blockquote&gt; 



&lt;p&gt;Community analysis proceeded at breakneck pace, with researchers reverse-engineering architectural details and performance characteristics within hours of release. AI developer Teortaxes, a long-term DeepSeek observer, noted the company’s apparent strategy: “I’ve long been saying that they hate maintaining separate model lines and will collapse everything into a single product and artifact as soon as possible. This may be it.”&lt;/p&gt;



&lt;p&gt;The rapid community embrace reflects broader shifts in how AI development occurs. Rather than relying solely on corporate research labs, the field increasingly benefits from distributed innovation across global communities of researchers, developers, and enthusiasts.&lt;/p&gt;



&lt;p&gt;Such collaborative development accelerates innovation while making it more difficult for any single company or country to maintain permanent technological advantages. As Chinese models gain recognition for technical excellence, the traditional dominance of American AI companies faces unprecedented challenges.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-deepseek-s-success-means-for-the-future-of-ai-competition"&gt;What DeepSeek’s success means for the future of AI competition&lt;/h2&gt;



&lt;p&gt;DeepSeek’s achievement demonstrates that frontier AI capabilities no longer require the massive resources and proprietary approaches that have characterized American AI development. Smaller, more focused teams can achieve comparable results through different strategies, fundamentally altering the competitive landscape.&lt;/p&gt;



&lt;p&gt;This democratization of AI development could reshape global technology leadership. Countries and companies previously locked out of frontier AI development due to resource constraints can now access, modify, and build upon cutting-edge capabilities. The shift could accelerate AI adoption worldwide while reducing dependence on American technology platforms.&lt;/p&gt;



&lt;p&gt;American AI companies face an existential challenge. If open source alternatives can match proprietary performance while offering greater flexibility and lower costs, the traditional advantages of closed development disappear. Companies will need to demonstrate substantial superior value to justify premium pricing.&lt;/p&gt;



&lt;p&gt;The competition may ultimately benefit global innovation by forcing all participants to advance capabilities more rapidly. However, it also raises fundamental questions about sustainable business models in an industry where marginal costs approach zero and competitive advantages prove ephemeral.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-new-paradigm-when-artificial-intelligence-becomes-truly-artificial"&gt;The new paradigm: when artificial intelligence becomes truly artificial&lt;/h2&gt;



&lt;p&gt;DeepSeek V3.1‘s emergence signals more than technological progress — it represents the moment when artificial intelligence began living up to its name. For too long, the world’s most advanced AI systems remained artificially scarce, locked behind corporate paywalls and geographic restrictions that had little to do with the technology’s inherent capabilities.&lt;/p&gt;



&lt;p&gt;DeepSeek’s demonstration that frontier performance can coexist with open access reveals the artificial barriers that once defined AI competition are crumbling. The democratization isn’t just about making powerful tools available — it’s about exposing that the scarcity was always manufactured, not inevitable.&lt;/p&gt;



&lt;p&gt;The irony proves unmistakable: in seeking to make their intelligence artificial, DeepSeek has made the entire industry’s gatekeeping look artificial instead. As one community observer noted about the company’s roadmap, even more dramatic breakthroughs may be forthcoming. If V3.1 represents merely a stepping stone to V4, the current disruption may pale in comparison to what lies ahead.&lt;/p&gt;



&lt;p&gt;The global AI race has fundamentally changed. What began as a competition over who could build the most powerful systems has evolved into a contest over who can make those systems most accessible. In that race, artificial scarcity may prove to be the biggest artificial intelligence of all.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;p&gt;Chinese artificial intelligence startup DeepSeek made waves across the global AI community Tuesday with the quiet release of its most ambitious model yet — a 685-billion parameter system that challenges the dominance of American AI giants while reshaping the competitive landscape through open-source accessibility.&lt;/p&gt;&lt;p&gt;The Hangzhou-based company, backed by High-Flyer Capital Management, uploaded DeepSeek V3.1 to Hugging Face without fanfare, a characteristically understated approach that belies the model’s potential impact. Within hours, early performance tests revealed benchmark scores that rival proprietary systems from OpenAI and Anthropic, while the model’s open-source license ensures global access unconstrained by geopolitical tensions.&lt;/p&gt;&lt;p&gt;The release of DeepSeek V3.1 represents more than just another incremental improvement in AI capabilities. It signals a fundamental shift in how the world’s most advanced artificial intelligence systems might be developed, distributed, and controlled — with potentially profound implications for the ongoing technological competition between the United States and China.&lt;/p&gt;&lt;p&gt;Within hours of its Hugging Face debut, DeepSeek V3.1 began climbing popularity rankings, drawing praise from researchers worldwide who downloaded and tested its capabilities. The model achieved a 71.6% score on the prestigious Aider coding benchmark, establishing itself as one of the top-performing models available and directly challenging the dominance of American AI giants.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Deepseek V3.1 is already 4th trending on HF with a silent release without model card ??? &lt;/p&gt;&lt;p&gt;The power of 80,000 followers on @huggingface (first org with 100k when?)! pic.twitter.com/OjeBfWQ7St&lt;/p&gt;— clem ? (@ClementDelangue) August 19, 2025&lt;/blockquote&gt; 



&lt;h2 class="wp-block-heading" id="h-how-deepseek-v3-1-delivers-breakthrough-performance"&gt;How DeepSeek V3.1 delivers breakthrough performance&lt;/h2&gt;



&lt;p&gt;DeepSeek V3.1 delivers remarkable engineering achievements that redefine expectations for AI model performance. The system processes up to 128,000 tokens of context — roughly equivalent to a 400-page book — while maintaining response speeds that dwarf slower reasoning-based competitors. The model supports multiple precision formats, from standard BF16 to experimental FP8, allowing developers to optimize performance for their specific hardware constraints.&lt;/p&gt;



&lt;p&gt;The real breakthrough lies in what DeepSeek calls its “hybrid architecture.” Unlike previous attempts at combining different AI capabilities, which often resulted in systems that performed poorly at everything, V3.1 seamlessly integrates chat, reasoning, and coding functions into a single, coherent model.&lt;/p&gt;



&lt;p&gt;“Deepseek v3.1 scores 71.6% on aider – non-reasoning SOTA,” tweeted AI researcher Andrew Christianson, adding that it is “1% more than Claude Opus 4 while being 68 times cheaper.”  The achievement places DeepSeek in rarified company, matching performance levels previously reserved for the most expensive proprietary systems.&lt;/p&gt;



&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;"1% more than Claude Opus 4 while being 68 times cheaper." pic.twitter.com/vKb6wWwjXq&lt;/p&gt;— Andrew I. Christianson (@ai_christianson) August 19, 2025&lt;/blockquote&gt; 



&lt;p&gt;Community analysis revealed sophisticated technical innovations hidden beneath the surface. Researcher “Rookie“, who is also a moderator of the subreddits r/DeepSeek &amp;amp; r/LocalLLaMA, claims they discovered four new special tokens embedded in the model’s architecture: search capabilities that allow real-time web integration and thinking tokens that enable internal reasoning processes. These additions suggest DeepSeek has solved fundamental challenges that have plagued other hybrid systems.&lt;/p&gt;



&lt;p&gt;The model’s efficiency proves equally impressive. At roughly $1.01 per complete coding task, DeepSeek V3.1 delivers results comparable to systems costing nearly $70 per equivalent workload. For enterprise users managing thousands of daily AI interactions, such cost differences translate into millions of dollars in potential savings.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-strategic-timing-reveals-calculated-challenge-to-american-ai-dominance"&gt;Strategic timing reveals calculated challenge to American AI dominance&lt;/h2&gt;



&lt;p&gt;DeepSeek timed its release with surgical precision. The V3.1 launch comes just weeks after OpenAI unveiled GPT-5 and Anthropic launched Claude 4, both positioned as frontier models representing the cutting edge of artificial intelligence capability. By matching their performance while maintaining open source accessibility, DeepSeek directly challenges the fundamental business models underlying American AI leadership.&lt;/p&gt;



&lt;p&gt;The strategic implications extend far beyond technical specifications. While American companies maintain strict control over their most advanced systems, requiring expensive API access and imposing usage restrictions, DeepSeek makes comparable capabilities freely available for download, modification, and deployment anywhere in the world.&lt;/p&gt;



&lt;p&gt;This philosophical divide reflects broader differences in how the two superpowers approach technological development. American firms like OpenAI and Anthropic view their models as valuable intellectual property requiring protection and monetization. Chinese companies increasingly treat advanced AI as a public good that accelerates innovation through widespread access.&lt;/p&gt;



&lt;p&gt;“DeepSeek quietly removed the R1 tag. Now every entry point defaults to V3.1—128k context, unified responses, consistent style,” observed journalist Poe Zhao. “Looks less like multiple public models, more like a strategic consolidation. A Chinese answer to the fragmentation risk in the LLM race.”&lt;/p&gt;



&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;DeepSeek quietly removed the R1 tag. Now every entry point defaults to V3.1—128k context, unified responses, consistent style. Looks less like multiple public models, more like a strategic consolidation. A Chinese answer to the fragmentation risk in the LLM race. pic.twitter.com/hbS6NjaYAw&lt;/p&gt;— Poe Zhao (@poezhao0605) August 19, 2025&lt;/blockquote&gt; 



&lt;p&gt;The consolidation strategy suggests DeepSeek has learned from earlier mistakes, both its own and those of competitors. Previous hybrid models, including initial versions from Chinese rival Qwen, suffered from performance degradation when attempting to combine different capabilities. DeepSeek appears to have cracked that code.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-open-source-strategy-disrupts-traditional-ai-economics"&gt;How open source strategy disrupts traditional AI economics&lt;/h2&gt;



&lt;p&gt;DeepSeek’s approach fundamentally challenges assumptions about how frontier AI systems should be developed and distributed. Traditional venture capital-backed approaches require massive investments in computing infrastructure, research talent, and regulatory compliance — costs that must eventually be recouped through premium pricing.&lt;/p&gt;



&lt;p&gt;DeepSeek’s open source strategy turns this model upside down. By making advanced capabilities freely available, the company accelerates adoption while potentially undermining competitors’ ability to maintain high margins on similar capabilities. The approach mirrors earlier disruptions in software, where open source alternatives eventually displaced proprietary solutions across entire industries.&lt;/p&gt;



&lt;p&gt;Enterprise decision makers face both exciting opportunities and complex challenges. Organizations can now download, customize, and deploy frontier-level AI capabilities without ongoing licensing fees or usage restrictions. The model’s 700GB size requires substantial computational resources, but cloud providers will likely offer hosted versions that eliminate infrastructure barriers.&lt;/p&gt;



&lt;p&gt;“That’s almost the same score as R1 0528 (71.4% with $4.8), but quicker and cheaper, right?” noted one Reddit user analyzing benchmark results. “R1 0528 quality but instant instead of having to wait minutes for a response.”&lt;/p&gt;



&lt;p&gt;The speed advantage could prove particularly valuable for interactive applications where users expect immediate responses. Previous reasoning models, while capable, often required minutes to process complex queries — making them unsuitable for real-time use cases.&lt;/p&gt;



&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;DeepSeek-V3-0324&lt;/p&gt;&lt;p&gt;write a p5.js program that shows a ball bouncing inside a spinning hexagon. The ball should be affected by gravity and friction, and it must bounce off the rotating walls realistically https://t.co/yT2Pfd0wPt pic.twitter.com/AUG6Tkmpau&lt;/p&gt;— AK (@_akhaliq) March 25, 2025&lt;/blockquote&gt; 







&lt;p&gt;The international response to DeepSeek V3.1 reveals how quickly technical excellence transcends geopolitical boundaries. Developers from around the world began downloading, testing, and praising the model’s capabilities within hours of release, regardless of its Chinese origins.&lt;/p&gt;



&lt;p&gt;“Open Source AI is at its peak right now… just look at the current Hugging Face trending list,” tweeted Hugging Face head of product Victor Mustar, noting that Chinese models increasingly dominate the platform’s most popular downloads. The trend suggests that technical merit, rather than national origin, drives adoption decisions among developers.&lt;/p&gt;



&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Open Source AI is at its peak right now… just look at the current Hugging Face trending list:&lt;/p&gt;&lt;p&gt;? Qwen/Qwen-Image-Edit&lt;br /&gt;? google/gemma-3-270m&lt;br /&gt;? tencent/Hunyuan-GameCraft-1.0&lt;br /&gt;? openai/gpt-oss-20b&lt;br /&gt;? zai-org/GLM-4.5V&lt;br /&gt;? deepseek-ai/DeepSeek-V3.1-Base&lt;br /&gt;? google/gemma-3-270m-it… pic.twitter.com/57zuEbOqmK&lt;/p&gt;— Victor M (@victormustar) August 19, 2025&lt;/blockquote&gt; 



&lt;p&gt;Community analysis proceeded at breakneck pace, with researchers reverse-engineering architectural details and performance characteristics within hours of release. AI developer Teortaxes, a long-term DeepSeek observer, noted the company’s apparent strategy: “I’ve long been saying that they hate maintaining separate model lines and will collapse everything into a single product and artifact as soon as possible. This may be it.”&lt;/p&gt;



&lt;p&gt;The rapid community embrace reflects broader shifts in how AI development occurs. Rather than relying solely on corporate research labs, the field increasingly benefits from distributed innovation across global communities of researchers, developers, and enthusiasts.&lt;/p&gt;



&lt;p&gt;Such collaborative development accelerates innovation while making it more difficult for any single company or country to maintain permanent technological advantages. As Chinese models gain recognition for technical excellence, the traditional dominance of American AI companies faces unprecedented challenges.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-deepseek-s-success-means-for-the-future-of-ai-competition"&gt;What DeepSeek’s success means for the future of AI competition&lt;/h2&gt;



&lt;p&gt;DeepSeek’s achievement demonstrates that frontier AI capabilities no longer require the massive resources and proprietary approaches that have characterized American AI development. Smaller, more focused teams can achieve comparable results through different strategies, fundamentally altering the competitive landscape.&lt;/p&gt;



&lt;p&gt;This democratization of AI development could reshape global technology leadership. Countries and companies previously locked out of frontier AI development due to resource constraints can now access, modify, and build upon cutting-edge capabilities. The shift could accelerate AI adoption worldwide while reducing dependence on American technology platforms.&lt;/p&gt;



&lt;p&gt;American AI companies face an existential challenge. If open source alternatives can match proprietary performance while offering greater flexibility and lower costs, the traditional advantages of closed development disappear. Companies will need to demonstrate substantial superior value to justify premium pricing.&lt;/p&gt;



&lt;p&gt;The competition may ultimately benefit global innovation by forcing all participants to advance capabilities more rapidly. However, it also raises fundamental questions about sustainable business models in an industry where marginal costs approach zero and competitive advantages prove ephemeral.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-new-paradigm-when-artificial-intelligence-becomes-truly-artificial"&gt;The new paradigm: when artificial intelligence becomes truly artificial&lt;/h2&gt;



&lt;p&gt;DeepSeek V3.1‘s emergence signals more than technological progress — it represents the moment when artificial intelligence began living up to its name. For too long, the world’s most advanced AI systems remained artificially scarce, locked behind corporate paywalls and geographic restrictions that had little to do with the technology’s inherent capabilities.&lt;/p&gt;



&lt;p&gt;DeepSeek’s demonstration that frontier performance can coexist with open access reveals the artificial barriers that once defined AI competition are crumbling. The democratization isn’t just about making powerful tools available — it’s about exposing that the scarcity was always manufactured, not inevitable.&lt;/p&gt;



&lt;p&gt;The irony proves unmistakable: in seeking to make their intelligence artificial, DeepSeek has made the entire industry’s gatekeeping look artificial instead. As one community observer noted about the company’s roadmap, even more dramatic breakthroughs may be forthcoming. If V3.1 represents merely a stepping stone to V4, the current disruption may pale in comparison to what lies ahead.&lt;/p&gt;



&lt;p&gt;The global AI race has fundamentally changed. What began as a competition over who could build the most powerful systems has evolved into a contest over who can make those systems most accessible. In that race, artificial scarcity may prove to be the biggest artificial intelligence of all.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/deepseek-v3-1-just-dropped-and-it-might-be-the-most-powerful-open-ai-yet/</guid><pubDate>Tue, 19 Aug 2025 21:13:15 +0000</pubDate></item><item><title>In Xcode 26, Apple shows first signs of offering ChatGPT alternatives (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/08/in-xcode-26-apple-shows-first-signs-of-offering-chatgpt-alternatives/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Claude support in Xcode heralds bigger moves across the ecosystem.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The Claude 4 logo." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/05/Claude-4-hero-640x360.jpg" width="640" /&gt;
                  &lt;img alt="The Claude 4 logo." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/05/Claude-4-hero-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The Claude 4 logo, created by Anthropic.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Anthropic

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The latest Xcode beta contains clear signs that Apple plans to bring Anthropic's Claude and Opus large language models into the integrated development environment (IDE), expanding on features already available using Apple's own models or OpenAI's ChatGPT.&lt;/p&gt;
&lt;p&gt;Apple enthusiast publication 9to5Mac "found multiple references to built-in support for Anthropic accounts," including in the "Intelligence" menu, where users can currently log into ChatGPT or enter an API key for higher message limits.&lt;/p&gt;
&lt;p&gt;Apple introduced a suite of features meant to compete with GitHub Copilot in Xcode at WWDC24, but first focused on its own models and a more limited set of use cases. That expanded quite a bit at this year's developer conference, and users can converse about codebases, discuss changes, or ask for suggestions using ChatGPT. They are initially given a limited set of messages, but this can be greatly increased by logging into a ChatGPT account or entering an API key.&lt;/p&gt;
&lt;p&gt;This summer, Apple said it would be possible to use Anthropic's models with an API key, too, but made no mention of support for Anthropic accounts, which are generally more cost-effective than using the API for most users.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Now, with 9to5Mac's discovery, it appears that Xcode 26 will ultimately allow users to log in to use Anthropic's models as well.&lt;/p&gt;
&lt;p&gt;Claude has proven to be one of the most popular models for developers, thanks in part to a wide context window and models more fine-tuned for the task, as Anthropic has a B2B, developer-oriented strategy compared to OpenAI's everything-for-everybody strategy. The release of GPT-5 poses a major challenge for Anthropic, though, as it both significantly improves ChatGPT's coding capabilities while also coming at a much lower cost. Anthropic is likely to answer that with future model updates that aim for greater efficiency.&lt;/p&gt;
&lt;p&gt;This news is also relevant for the wider Apple ecosystem, not just developers, as it's the first clear example of Apple working on support for a third-party model besides those offered by OpenAI. The company's executives have often said they planned to do that in the future in Xcode and in Siri, but until now, we haven't seen much beyond statements of intent.&lt;/p&gt;
&lt;p&gt;Xcode 26 is expected to launch alongside the new version of macOS later this year. It's unclear whether this Anthropic account support will come with the initial release or an update further down the line in this annual cycle.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Claude support in Xcode heralds bigger moves across the ecosystem.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The Claude 4 logo." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/05/Claude-4-hero-640x360.jpg" width="640" /&gt;
                  &lt;img alt="The Claude 4 logo." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/05/Claude-4-hero-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The Claude 4 logo, created by Anthropic.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Anthropic

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The latest Xcode beta contains clear signs that Apple plans to bring Anthropic's Claude and Opus large language models into the integrated development environment (IDE), expanding on features already available using Apple's own models or OpenAI's ChatGPT.&lt;/p&gt;
&lt;p&gt;Apple enthusiast publication 9to5Mac "found multiple references to built-in support for Anthropic accounts," including in the "Intelligence" menu, where users can currently log into ChatGPT or enter an API key for higher message limits.&lt;/p&gt;
&lt;p&gt;Apple introduced a suite of features meant to compete with GitHub Copilot in Xcode at WWDC24, but first focused on its own models and a more limited set of use cases. That expanded quite a bit at this year's developer conference, and users can converse about codebases, discuss changes, or ask for suggestions using ChatGPT. They are initially given a limited set of messages, but this can be greatly increased by logging into a ChatGPT account or entering an API key.&lt;/p&gt;
&lt;p&gt;This summer, Apple said it would be possible to use Anthropic's models with an API key, too, but made no mention of support for Anthropic accounts, which are generally more cost-effective than using the API for most users.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Now, with 9to5Mac's discovery, it appears that Xcode 26 will ultimately allow users to log in to use Anthropic's models as well.&lt;/p&gt;
&lt;p&gt;Claude has proven to be one of the most popular models for developers, thanks in part to a wide context window and models more fine-tuned for the task, as Anthropic has a B2B, developer-oriented strategy compared to OpenAI's everything-for-everybody strategy. The release of GPT-5 poses a major challenge for Anthropic, though, as it both significantly improves ChatGPT's coding capabilities while also coming at a much lower cost. Anthropic is likely to answer that with future model updates that aim for greater efficiency.&lt;/p&gt;
&lt;p&gt;This news is also relevant for the wider Apple ecosystem, not just developers, as it's the first clear example of Apple working on support for a third-party model besides those offered by OpenAI. The company's executives have often said they planned to do that in the future in Xcode and in Siri, but until now, we haven't seen much beyond statements of intent.&lt;/p&gt;
&lt;p&gt;Xcode 26 is expected to launch alongside the new version of macOS later this year. It's unclear whether this Anthropic account support will come with the initial release or an update further down the line in this annual cycle.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/08/in-xcode-26-apple-shows-first-signs-of-offering-chatgpt-alternatives/</guid><pubDate>Tue, 19 Aug 2025 22:08:55 +0000</pubDate></item><item><title>[NEW] LLMs generate ‘fluent nonsense’ when reasoning outside their training zone (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/llms-generate-fluent-nonsense-when-reasoning-outside-their-training-zone/</link><description>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;A new study from Arizona State University researchers suggests that the celebrated “Chain-of-Thought” (CoT) reasoning in Large Language Models (LLMs) may be more of a “brittle mirage” than genuine intelligence. The research builds on a growing body of work questioning the depth of LLM reasoning, but it takes a unique “data distribution” lens to test where and why CoT breaks down systematically.&lt;/p&gt;&lt;p&gt;Crucially for application builders, the paper goes beyond critique to offer clear, practical guidance on how to account for these limitations when developing LLM-powered applications, from testing strategies to the role of fine-tuning.&lt;/p&gt;&lt;p&gt;CoT prompting, which asks an LLM to “think step by step,” has shown impressive results on complex tasks, leading to the perception that models are engaging in human-like inferential processes. However, a closer inspection often reveals logical inconsistencies that challenge this view.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Various studies show that LLMs frequently rely on surface-level semantics and clues rather than logical procedures. The models generate plausible-sounding logic by repeating token patterns they have seen during training. Still, this approach often fails on tasks that deviate from familiar templates or when irrelevant information is introduced.&amp;nbsp;&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Despite these observations, the researchers of the new study argue that “a systematic understanding of why and when CoT reasoning fails is still a mystery,” which their study aims to address. Previous work has already shown that LLMs struggle to generalize their reasoning abilities. As the paper notes, “theoretical and empirical evidence shows that CoT generalizes well only when test inputs share latent structures with training data; otherwise, performance declines sharply.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-new-lens-on-llm-reasoning"&gt;A new lens on LLM reasoning&lt;/h2&gt;



&lt;p&gt;The ASU researchers propose a new lens to view this problem: CoT isn’t an act of reasoning but a sophisticated form of pattern matching, fundamentally bound by the statistical patterns in its training data. They posit that “CoT’s success stems not from a model’s inherent reasoning capacity, but from its ability to generalize conditionally to out-of-distribution (OOD) test cases that are structurally similar to in-distribution exemplars.” In other words, an LLM is good at applying old patterns to new data that looks similar, but not at solving truly novel problems.&lt;/p&gt;


&lt;div class="wp-block-image"&gt;
&lt;figure class="aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3015798" height="600" src="https://venturebeat.com/wp-content/uploads/2025/08/image_531b9b.png?w=679" width="679" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;The data distribution lens Source: GitHub&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;


&lt;p&gt;To test this hypothesis, they dissected CoT’s capabilities across three dimensions of “distributional shift” (changes between the training data and the test data). First, they tested “task generalization” to see if a model could apply a learned reasoning process to a new type of task. Second, they examined “length generalization” to determine if it could handle reasoning chains that are significantly longer or shorter than those it was trained on. Finally, they assessed “format generalization” to measure how sensitive the model is to minor changes in the prompt’s wording or structure.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;For their analysis, they developed a framework called DataAlchemy to train smaller LLMs from scratch in a controlled environment, allowing them to precisely measure how performance degrades when pushed beyond the training data.&lt;/p&gt;



&lt;p&gt;“The data distribution lens and controlled environment are both central to what we were trying to convey,” Chengshuai Zhao, doctoral student at ASU and co-author of the paper, told VentureBeat. “We hope to create a space where the public, researchers, and developers can freely explore and probe the nature of LLMs and advance the boundaries of human knowledge.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-mirage-confirmed"&gt;The mirage confirmed&lt;/h2&gt;



&lt;p&gt;Based on their findings, the researchers conclude that CoT reasoning is a “sophisticated form of structured pattern matching, fundamentally bounded by the data distribution seen during training.” When tested even slightly outside this distribution, performance collapses. What looks like structured reasoning is more of a mirage, “emerging from memorized or interpolated patterns in the training data rather than logical inference.”&lt;/p&gt;



&lt;p&gt;The breakdown was consistent across all three dimensions. On new tasks, models failed to generalize and instead replicated the closest patterns they had seen during training. When faced with reasoning chains of different lengths, they struggled, often trying to artificially add or remove steps to match the length of their training examples. Finally, their performance proved highly sensitive to superficial changes in the prompt, especially variations in core elements and instructions.&lt;/p&gt;


&lt;div class="wp-block-image"&gt;
&lt;figure class="aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3015799" height="564" src="https://venturebeat.com/wp-content/uploads/2025/08/image_d09e6e.png" width="750" /&gt;&lt;/figure&gt;&lt;/div&gt;


&lt;p&gt;Interestingly, the researchers found that these failures could be quickly fixed. By fine-tuning the models on a very small sample of the new, unseen data through supervised fine-tuning (SFT), performance on that specific type of problem increased rapidly. However, this quick fix further supports the pattern-matching theory, suggesting the model isn’t learning to reason more abstractly but is instead just memorizing a new pattern to overcome a specific weakness.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-takeaways-for-the-enterprise"&gt;Takeaways for the enterprise&lt;/h2&gt;



&lt;p&gt;The researchers offer a direct warning to practitioners, highlighting “the risk of relying on CoT as a plug-and-play solution for reasoning tasks and caution against equating CoT-style output with human thinking.” They provide three key pieces of advice for developers building applications with LLMs.&lt;/p&gt;



&lt;p&gt;1)&lt;strong&gt;Guard against over-reliance and false confidence.&lt;/strong&gt; CoT should not be treated as a reliable module for reasoning in high-stakes fields like finance or legal analysis. LLMs can produce “fluent nonsense” (plausible but logically flawed reasoning) that is more deceptive than an outright incorrect answer. The authors stress that “sufficient auditing from domain experts is indispensable.”&lt;/p&gt;



&lt;p&gt;“The advance of science should remain human-centered—machines can assist, but discovery still thrives on humanity and curiosity,” Zhao said.&lt;/p&gt;



&lt;p&gt;2) P&lt;strong&gt;rioritize out-of-distribution (OOD) testing.&lt;/strong&gt; Standard validation, where test data mirrors training data, is not enough to measure true robustness. Developers must implement rigorous testing that systematically probes for failures across task, length, and format variations.&lt;/p&gt;



&lt;p&gt;3)&lt;strong&gt;Recognize fine-tuning as a patch, not a panacea.&lt;/strong&gt; While supervised fine-tuning (SFT) can quickly “patch” a model’s performance on a specific new data distribution, it does not create true generalization. It simply expands the model’s “in-distribution bubble” slightly. Relying on SFT to fix every OOD failure is an unsustainable strategy that fails to address the model’s core lack of abstract reasoning.&lt;/p&gt;



&lt;p&gt;While CoT isn’t a form of human cognition, this limitation can be managed. Most enterprise applications involve a relatively narrow and predictable set of tasks. The paper’s findings provide a blueprint for ensuring reliability within these domains. Developers can build rigorous evaluation suites that systematically test model performance against the specific task, length, and format variations their application will encounter. This allows them to map out the boundaries of a model’s “in-distribution” comfort zone and identify where it aligns with their specific needs.&lt;/p&gt;



&lt;p&gt;This targeted testing transforms fine-tuning from a reactive “patch” into a proactive strategy for alignment. When evaluations reveal a specific weakness, developers can create small, targeted SFT datasets to address it. Instead of trying to achieve broad, general reasoning, this approach uses SFT surgically to ensure the model’s pattern-matching capabilities are precisely aligned with the contours of a specific enterprise task. Ultimately, the study offers a practical lens for moving beyond hope and engineering LLM applications to achieve predictable success.&lt;/p&gt;




&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;A new study from Arizona State University researchers suggests that the celebrated “Chain-of-Thought” (CoT) reasoning in Large Language Models (LLMs) may be more of a “brittle mirage” than genuine intelligence. The research builds on a growing body of work questioning the depth of LLM reasoning, but it takes a unique “data distribution” lens to test where and why CoT breaks down systematically.&lt;/p&gt;&lt;p&gt;Crucially for application builders, the paper goes beyond critique to offer clear, practical guidance on how to account for these limitations when developing LLM-powered applications, from testing strategies to the role of fine-tuning.&lt;/p&gt;&lt;p&gt;CoT prompting, which asks an LLM to “think step by step,” has shown impressive results on complex tasks, leading to the perception that models are engaging in human-like inferential processes. However, a closer inspection often reveals logical inconsistencies that challenge this view.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Various studies show that LLMs frequently rely on surface-level semantics and clues rather than logical procedures. The models generate plausible-sounding logic by repeating token patterns they have seen during training. Still, this approach often fails on tasks that deviate from familiar templates or when irrelevant information is introduced.&amp;nbsp;&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Despite these observations, the researchers of the new study argue that “a systematic understanding of why and when CoT reasoning fails is still a mystery,” which their study aims to address. Previous work has already shown that LLMs struggle to generalize their reasoning abilities. As the paper notes, “theoretical and empirical evidence shows that CoT generalizes well only when test inputs share latent structures with training data; otherwise, performance declines sharply.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-new-lens-on-llm-reasoning"&gt;A new lens on LLM reasoning&lt;/h2&gt;



&lt;p&gt;The ASU researchers propose a new lens to view this problem: CoT isn’t an act of reasoning but a sophisticated form of pattern matching, fundamentally bound by the statistical patterns in its training data. They posit that “CoT’s success stems not from a model’s inherent reasoning capacity, but from its ability to generalize conditionally to out-of-distribution (OOD) test cases that are structurally similar to in-distribution exemplars.” In other words, an LLM is good at applying old patterns to new data that looks similar, but not at solving truly novel problems.&lt;/p&gt;


&lt;div class="wp-block-image"&gt;
&lt;figure class="aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3015798" height="600" src="https://venturebeat.com/wp-content/uploads/2025/08/image_531b9b.png?w=679" width="679" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;The data distribution lens Source: GitHub&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;


&lt;p&gt;To test this hypothesis, they dissected CoT’s capabilities across three dimensions of “distributional shift” (changes between the training data and the test data). First, they tested “task generalization” to see if a model could apply a learned reasoning process to a new type of task. Second, they examined “length generalization” to determine if it could handle reasoning chains that are significantly longer or shorter than those it was trained on. Finally, they assessed “format generalization” to measure how sensitive the model is to minor changes in the prompt’s wording or structure.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;For their analysis, they developed a framework called DataAlchemy to train smaller LLMs from scratch in a controlled environment, allowing them to precisely measure how performance degrades when pushed beyond the training data.&lt;/p&gt;



&lt;p&gt;“The data distribution lens and controlled environment are both central to what we were trying to convey,” Chengshuai Zhao, doctoral student at ASU and co-author of the paper, told VentureBeat. “We hope to create a space where the public, researchers, and developers can freely explore and probe the nature of LLMs and advance the boundaries of human knowledge.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-mirage-confirmed"&gt;The mirage confirmed&lt;/h2&gt;



&lt;p&gt;Based on their findings, the researchers conclude that CoT reasoning is a “sophisticated form of structured pattern matching, fundamentally bounded by the data distribution seen during training.” When tested even slightly outside this distribution, performance collapses. What looks like structured reasoning is more of a mirage, “emerging from memorized or interpolated patterns in the training data rather than logical inference.”&lt;/p&gt;



&lt;p&gt;The breakdown was consistent across all three dimensions. On new tasks, models failed to generalize and instead replicated the closest patterns they had seen during training. When faced with reasoning chains of different lengths, they struggled, often trying to artificially add or remove steps to match the length of their training examples. Finally, their performance proved highly sensitive to superficial changes in the prompt, especially variations in core elements and instructions.&lt;/p&gt;


&lt;div class="wp-block-image"&gt;
&lt;figure class="aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3015799" height="564" src="https://venturebeat.com/wp-content/uploads/2025/08/image_d09e6e.png" width="750" /&gt;&lt;/figure&gt;&lt;/div&gt;


&lt;p&gt;Interestingly, the researchers found that these failures could be quickly fixed. By fine-tuning the models on a very small sample of the new, unseen data through supervised fine-tuning (SFT), performance on that specific type of problem increased rapidly. However, this quick fix further supports the pattern-matching theory, suggesting the model isn’t learning to reason more abstractly but is instead just memorizing a new pattern to overcome a specific weakness.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-takeaways-for-the-enterprise"&gt;Takeaways for the enterprise&lt;/h2&gt;



&lt;p&gt;The researchers offer a direct warning to practitioners, highlighting “the risk of relying on CoT as a plug-and-play solution for reasoning tasks and caution against equating CoT-style output with human thinking.” They provide three key pieces of advice for developers building applications with LLMs.&lt;/p&gt;



&lt;p&gt;1)&lt;strong&gt;Guard against over-reliance and false confidence.&lt;/strong&gt; CoT should not be treated as a reliable module for reasoning in high-stakes fields like finance or legal analysis. LLMs can produce “fluent nonsense” (plausible but logically flawed reasoning) that is more deceptive than an outright incorrect answer. The authors stress that “sufficient auditing from domain experts is indispensable.”&lt;/p&gt;



&lt;p&gt;“The advance of science should remain human-centered—machines can assist, but discovery still thrives on humanity and curiosity,” Zhao said.&lt;/p&gt;



&lt;p&gt;2) P&lt;strong&gt;rioritize out-of-distribution (OOD) testing.&lt;/strong&gt; Standard validation, where test data mirrors training data, is not enough to measure true robustness. Developers must implement rigorous testing that systematically probes for failures across task, length, and format variations.&lt;/p&gt;



&lt;p&gt;3)&lt;strong&gt;Recognize fine-tuning as a patch, not a panacea.&lt;/strong&gt; While supervised fine-tuning (SFT) can quickly “patch” a model’s performance on a specific new data distribution, it does not create true generalization. It simply expands the model’s “in-distribution bubble” slightly. Relying on SFT to fix every OOD failure is an unsustainable strategy that fails to address the model’s core lack of abstract reasoning.&lt;/p&gt;



&lt;p&gt;While CoT isn’t a form of human cognition, this limitation can be managed. Most enterprise applications involve a relatively narrow and predictable set of tasks. The paper’s findings provide a blueprint for ensuring reliability within these domains. Developers can build rigorous evaluation suites that systematically test model performance against the specific task, length, and format variations their application will encounter. This allows them to map out the boundaries of a model’s “in-distribution” comfort zone and identify where it aligns with their specific needs.&lt;/p&gt;



&lt;p&gt;This targeted testing transforms fine-tuning from a reactive “patch” into a proactive strategy for alignment. When evaluations reveal a specific weakness, developers can create small, targeted SFT datasets to address it. Instead of trying to achieve broad, general reasoning, this approach uses SFT surgically to ensure the model’s pattern-matching capabilities are precisely aligned with the contours of a specific enterprise task. Ultimately, the study offers a practical lens for moving beyond hope and engineering LLM applications to achieve predictable success.&lt;/p&gt;




&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/llms-generate-fluent-nonsense-when-reasoning-outside-their-training-zone/</guid><pubDate>Tue, 19 Aug 2025 22:12:37 +0000</pubDate></item><item><title>[NEW] Stop benchmarking in the lab: Inclusion Arena shows how LLMs perform in production (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/stop-benchmarking-in-the-lab-inclusion-arena-shows-how-llms-perform-in-production/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Benchmark testing models have become essential for enterprises, allowing them to choose the type of performance that resonates with their needs. But not all benchmarks are built the same and many test models are based on static datasets or testing environments.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Researchers from Inclusion AI, which is affiliated with Alibaba’s Ant Group, proposed a new model leaderboard and benchmark that focuses more on a model’s performance in real-life scenarios. They argue that LLMs need a leaderboard that takes into account how people use them and how much people prefer their answers compared to the static knowledge capabilities models have.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In a paper, the researchers laid out the foundation for Inclusion Arena, which ranks models based on user preferences.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“To address these gaps, we propose Inclusion Arena, a live leaderboard that bridges real-world AI-powered applications with state-of-the-art LLMs and MLLMs. Unlike crowdsourced platforms, our system randomly triggers model battles during multi-turn human-AI dialogues in real-world apps,” the paper said.&amp;nbsp;&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Inclusion Arena stands out among other model leaderboards, such as MMLU and OpenLLM, due to its real-life aspect and its unique method of ranking models. It employs the Bradley-Terry modeling method, similar to the one used by Chatbot Arena.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Inclusion Arena works by integrating the benchmark into AI applications to gather datasets and conduct human evaluations. The researchers admit that “the number of initially integrated AI-powered applications is limited, but we aim to build an open alliance to expand the ecosystem.”&lt;/p&gt;



&lt;p&gt;By now, most people are familiar with the leaderboards and benchmarks touting the performance of each new LLM released by companies like OpenAI, Google or Anthropic. VentureBeat is no stranger to these leaderboards since some models, like xAI’s Grok 3, show their might by topping the Chatbot Arena leaderboard. The Inclusion AI researchers argue that their new leaderboard “ensures evaluations reflect practical usage scenarios,” so enterprises have better information around models they plan to choose.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-using-the-bradley-terry-method-nbsp"&gt;Using the Bradley-Terry method&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;Inclusion Arena draws inspiration from Chatbot Arena, utilizing the Bradley-Terry method, while Chatbot Arena also employs the Elo ranking method concurrently.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Most leaderboards rely on the Elo method to set rankings and performance. Elo refers to the Elo rating in chess, which determines the relative skill of players. Both Elo and Bradley-Terry are probabilistic frameworks, but the researchers said Bradley-Terry produces more stable ratings.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“The Bradley-Terry model provides a robust framework for inferring latent abilities from pairwise comparison outcomes,” the paper said. “However, in practical scenarios, particularly with a large and growing number of models, the prospect of exhaustive pairwise comparisons becomes computationally prohibitive and resource-intensive. This highlights a critical need for intelligent battle strategies that maximize information gain within a limited budget.”&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXeheO7IrzPh_RQkQizcPu9rJDt_pqV8vrSRu4qzRlwDxga-ysJNkQeFvXykW94llJH-KX98z-eghjpNm1sYTt2BnnIdYO_rah1EgU8fU5kP7KSTErUHarDOHCGyqyEzkASVYyhqHQ?key=hYz6EIiNSeTxoY_8bQrQGg" /&gt;&lt;/figure&gt;



&lt;p&gt;To make ranking more efficient in the face of a large number of LLMs, Inclusion Arena has two other components: the placement match mechanism and proximity sampling. The placement match mechanism estimates an initial ranking for new models registered for the leaderboard. Proximity sampling then limits those comparisons to models within the same trust region.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-it-works"&gt;How it works&lt;/h2&gt;



&lt;p&gt;So how does it work?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Inclusion Arena’s framework integrates into AI-powered applications. Currently, there are two apps available on Inclusion Arena: the character chat app Joyland and the education communication app T-Box. When people use the apps, the prompts are sent to multiple LLMs behind the scenes for responses. The users then choose which answer they like best, though they don’t know which model generated the response.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The framework considers user preferences to generate pairs of models for comparison. The Bradley-Terry algorithm is then used to calculate a score for each model, which then leads to the final leaderboard.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Inclusion AI capped its experiment at data up to July 2025, comprising 501,003 pairwise comparisons.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;According to the initial experiments with Inclusion Arena, the most performant model is Anthropic’s Claude 3.7 Sonnet, DeepSeek v3-0324, Claude 3.5 Sonnet, DeepSeek v3 and Qwen Max-0125.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXf01Lk1tRUhP30jgeqpASZrdTwLeWtMZHb5WBlGxnEJUYMHIvk1SFN6X70dMomMz4TIYTsEySKUSHIwtGAVXNehUbud7xfTlpTEGtLuKFwmocSZJAtJzx47-1aERRokh-sQ7FjNJA?key=hYz6EIiNSeTxoY_8bQrQGg" /&gt;&lt;/figure&gt;



&lt;p&gt;Of course, this was data from two apps with more than 46,611 active users, according to the paper. The researchers said they can create a more robust and precise leaderboard with more data.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-more-leaderboards-more-choices"&gt;More leaderboards, more choices&lt;/h2&gt;



&lt;p&gt;The increasing number of models being released makes it more challenging for enterprises to select which LLMs to begin evaluating. Leaderboards and benchmarks guide technical decision makers to models that could provide the best performance for their needs. Of course, organizations should then conduct internal evaluations to ensure the LLMs are effective for their applications.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It also provides an idea of the broader LLM landscape, highlighting which models are becoming competitive compared to their peers. Recent benchmarks such as RewardBench 2 from the Allen Institute for AI attempt to align models with real-life use cases for enterprises.&amp;nbsp;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Benchmark testing models have become essential for enterprises, allowing them to choose the type of performance that resonates with their needs. But not all benchmarks are built the same and many test models are based on static datasets or testing environments.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Researchers from Inclusion AI, which is affiliated with Alibaba’s Ant Group, proposed a new model leaderboard and benchmark that focuses more on a model’s performance in real-life scenarios. They argue that LLMs need a leaderboard that takes into account how people use them and how much people prefer their answers compared to the static knowledge capabilities models have.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In a paper, the researchers laid out the foundation for Inclusion Arena, which ranks models based on user preferences.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“To address these gaps, we propose Inclusion Arena, a live leaderboard that bridges real-world AI-powered applications with state-of-the-art LLMs and MLLMs. Unlike crowdsourced platforms, our system randomly triggers model battles during multi-turn human-AI dialogues in real-world apps,” the paper said.&amp;nbsp;&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Inclusion Arena stands out among other model leaderboards, such as MMLU and OpenLLM, due to its real-life aspect and its unique method of ranking models. It employs the Bradley-Terry modeling method, similar to the one used by Chatbot Arena.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Inclusion Arena works by integrating the benchmark into AI applications to gather datasets and conduct human evaluations. The researchers admit that “the number of initially integrated AI-powered applications is limited, but we aim to build an open alliance to expand the ecosystem.”&lt;/p&gt;



&lt;p&gt;By now, most people are familiar with the leaderboards and benchmarks touting the performance of each new LLM released by companies like OpenAI, Google or Anthropic. VentureBeat is no stranger to these leaderboards since some models, like xAI’s Grok 3, show their might by topping the Chatbot Arena leaderboard. The Inclusion AI researchers argue that their new leaderboard “ensures evaluations reflect practical usage scenarios,” so enterprises have better information around models they plan to choose.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-using-the-bradley-terry-method-nbsp"&gt;Using the Bradley-Terry method&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;Inclusion Arena draws inspiration from Chatbot Arena, utilizing the Bradley-Terry method, while Chatbot Arena also employs the Elo ranking method concurrently.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Most leaderboards rely on the Elo method to set rankings and performance. Elo refers to the Elo rating in chess, which determines the relative skill of players. Both Elo and Bradley-Terry are probabilistic frameworks, but the researchers said Bradley-Terry produces more stable ratings.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“The Bradley-Terry model provides a robust framework for inferring latent abilities from pairwise comparison outcomes,” the paper said. “However, in practical scenarios, particularly with a large and growing number of models, the prospect of exhaustive pairwise comparisons becomes computationally prohibitive and resource-intensive. This highlights a critical need for intelligent battle strategies that maximize information gain within a limited budget.”&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXeheO7IrzPh_RQkQizcPu9rJDt_pqV8vrSRu4qzRlwDxga-ysJNkQeFvXykW94llJH-KX98z-eghjpNm1sYTt2BnnIdYO_rah1EgU8fU5kP7KSTErUHarDOHCGyqyEzkASVYyhqHQ?key=hYz6EIiNSeTxoY_8bQrQGg" /&gt;&lt;/figure&gt;



&lt;p&gt;To make ranking more efficient in the face of a large number of LLMs, Inclusion Arena has two other components: the placement match mechanism and proximity sampling. The placement match mechanism estimates an initial ranking for new models registered for the leaderboard. Proximity sampling then limits those comparisons to models within the same trust region.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-it-works"&gt;How it works&lt;/h2&gt;



&lt;p&gt;So how does it work?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Inclusion Arena’s framework integrates into AI-powered applications. Currently, there are two apps available on Inclusion Arena: the character chat app Joyland and the education communication app T-Box. When people use the apps, the prompts are sent to multiple LLMs behind the scenes for responses. The users then choose which answer they like best, though they don’t know which model generated the response.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The framework considers user preferences to generate pairs of models for comparison. The Bradley-Terry algorithm is then used to calculate a score for each model, which then leads to the final leaderboard.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Inclusion AI capped its experiment at data up to July 2025, comprising 501,003 pairwise comparisons.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;According to the initial experiments with Inclusion Arena, the most performant model is Anthropic’s Claude 3.7 Sonnet, DeepSeek v3-0324, Claude 3.5 Sonnet, DeepSeek v3 and Qwen Max-0125.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXf01Lk1tRUhP30jgeqpASZrdTwLeWtMZHb5WBlGxnEJUYMHIvk1SFN6X70dMomMz4TIYTsEySKUSHIwtGAVXNehUbud7xfTlpTEGtLuKFwmocSZJAtJzx47-1aERRokh-sQ7FjNJA?key=hYz6EIiNSeTxoY_8bQrQGg" /&gt;&lt;/figure&gt;



&lt;p&gt;Of course, this was data from two apps with more than 46,611 active users, according to the paper. The researchers said they can create a more robust and precise leaderboard with more data.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-more-leaderboards-more-choices"&gt;More leaderboards, more choices&lt;/h2&gt;



&lt;p&gt;The increasing number of models being released makes it more challenging for enterprises to select which LLMs to begin evaluating. Leaderboards and benchmarks guide technical decision makers to models that could provide the best performance for their needs. Of course, organizations should then conduct internal evaluations to ensure the LLMs are effective for their applications.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It also provides an idea of the broader LLM landscape, highlighting which models are becoming competitive compared to their peers. Recent benchmarks such as RewardBench 2 from the Allen Institute for AI attempt to align models with real-life use cases for enterprises.&amp;nbsp;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/stop-benchmarking-in-the-lab-inclusion-arena-shows-how-llms-perform-in-production/</guid><pubDate>Tue, 19 Aug 2025 23:07:40 +0000</pubDate></item></channel></rss>