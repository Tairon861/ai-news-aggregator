<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 14 Oct 2025 01:38:43 +0000</lastBuildDate><item><title>California becomes first state to regulate AI companion chatbots (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/13/california-becomes-first-state-to-regulate-ai-companion-chatbots/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/GettyImages-2240040875.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;California Governor Gavin Newsom signed a landmark bill on Monday that regulates AI companion chatbots, making it the first state in the nation to require AI chatbot operators to implement safety protocols for AI companions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The law, SB 243, is designed to protect children and vulnerable users from some of the harms associated with AI companion chatbot use. It holds companies — from the big labs like Meta and OpenAI to more focused companion startups like Character AI and Replika — legally accountable if their chatbots fail to meet the law’s standards.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;SB 243 was introduced in January by state senators Steve Padilla and Josh Becker, and gained momentum after the&amp;nbsp;death of teenager Adam Raine, who died by suicide after a long series of suicidal conversations with OpenAI’s ChatGPT. The legislation also responds to leaked&amp;nbsp;internal documents&amp;nbsp;that reportedly showed Meta’s chatbots were allowed to engage in “romantic” and “sensual” chats with children.&amp;nbsp;More recently, a Colorado family has filed suit against role-playing startup Character AI after their 13-year-old daughter took her own life following a series of problematic and sexualized conversations with the company’s chatbots.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Emerging technology like chatbots and social media can inspire, educate, and connect — but without real guardrails, technology can also exploit, mislead, and endanger our kids,” Newsom said in a statement. “We’ve seen some truly horrific and tragic examples of young people harmed by unregulated tech, and we won’t stand by while companies continue without necessary limits and accountability. We can continue to lead in AI and technology, but we must do it responsibly — protecting our children every step of the way. Our children’s safety is not for sale.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SB 243 will go into effect January 1, 2026, and requires companies to implement certain features such as age verification, and warnings regarding social media and companion chatbots. The law also implements stronger penalties for those who profit from illegal deepfakes, including up to $250,000 per offense. Companies must also establish protocols to address suicide and self-harm, which will be shared with the state’s Department of Public Health alongside statistics on how the service provided users with crisis center prevention notifications.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Per the bill’s language, platforms must also make it clear that any interactions are artificially generated, and chatbots must not represent themselves as healthcare professionals. Companies are required to offer break reminders to minors and prevent them from viewing sexually explicit images generated by the chatbot.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some companies have already begun to implement some safeguards aimed at children. For example, OpenAI recently began rolling out parental controls, content protections, and a self-harm detection system for children using ChatGPT. Replika, which is designed for adults over the age of 18, told TechCrunch it dedicates “significant resources” to safety through content-filtering systems and guardrails that direct users to trusted crisis resources, and is committed to complying with current regulations.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Character AI has said that its chatbot includes a disclaimer that all chats are AI-generated and fictionalized. A Character AI spokesperson told TechCrunch that the company “welcomes working with regulators and lawmakers as they develop regulations and legislation for this emerging space, and will comply with laws, including SB 243.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Senator Padilla told TechCrunch the bill was “a step in the right direction” towards putting guardrails in place on “an incredibly powerful technology.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have to move quickly to not miss windows of opportunity before they disappear,” Padilla said. “I hope that other states will see the risk. I think many do. I think this is a conversation happening all over the country, and I hope people will take action. Certainly the federal government has not, and I think we have an obligation here to protect the most vulnerable people among us.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;SB 243 is the second significant AI regulation to come out of California in recent weeks. On September 29th, Governor Newsom signed SB 53 into law, establishing new transparency requirements on large AI companies. The bill mandates that large AI labs, like OpenAI, Anthropic, Meta, and Google DeepMind, be transparent about safety protocols. It also ensures whistleblower protections for employees at those companies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other states, like Illinois, Nevada, and Utah, have passed laws to restrict or fully ban the use of AI chatbots as a substitute for licensed mental health care.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to Meta and OpenAI for comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article has been updated with comments from Senator Padilla&lt;/em&gt;, Character AI, and Replika.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/GettyImages-2240040875.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;California Governor Gavin Newsom signed a landmark bill on Monday that regulates AI companion chatbots, making it the first state in the nation to require AI chatbot operators to implement safety protocols for AI companions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The law, SB 243, is designed to protect children and vulnerable users from some of the harms associated with AI companion chatbot use. It holds companies — from the big labs like Meta and OpenAI to more focused companion startups like Character AI and Replika — legally accountable if their chatbots fail to meet the law’s standards.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;SB 243 was introduced in January by state senators Steve Padilla and Josh Becker, and gained momentum after the&amp;nbsp;death of teenager Adam Raine, who died by suicide after a long series of suicidal conversations with OpenAI’s ChatGPT. The legislation also responds to leaked&amp;nbsp;internal documents&amp;nbsp;that reportedly showed Meta’s chatbots were allowed to engage in “romantic” and “sensual” chats with children.&amp;nbsp;More recently, a Colorado family has filed suit against role-playing startup Character AI after their 13-year-old daughter took her own life following a series of problematic and sexualized conversations with the company’s chatbots.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Emerging technology like chatbots and social media can inspire, educate, and connect — but without real guardrails, technology can also exploit, mislead, and endanger our kids,” Newsom said in a statement. “We’ve seen some truly horrific and tragic examples of young people harmed by unregulated tech, and we won’t stand by while companies continue without necessary limits and accountability. We can continue to lead in AI and technology, but we must do it responsibly — protecting our children every step of the way. Our children’s safety is not for sale.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SB 243 will go into effect January 1, 2026, and requires companies to implement certain features such as age verification, and warnings regarding social media and companion chatbots. The law also implements stronger penalties for those who profit from illegal deepfakes, including up to $250,000 per offense. Companies must also establish protocols to address suicide and self-harm, which will be shared with the state’s Department of Public Health alongside statistics on how the service provided users with crisis center prevention notifications.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Per the bill’s language, platforms must also make it clear that any interactions are artificially generated, and chatbots must not represent themselves as healthcare professionals. Companies are required to offer break reminders to minors and prevent them from viewing sexually explicit images generated by the chatbot.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some companies have already begun to implement some safeguards aimed at children. For example, OpenAI recently began rolling out parental controls, content protections, and a self-harm detection system for children using ChatGPT. Replika, which is designed for adults over the age of 18, told TechCrunch it dedicates “significant resources” to safety through content-filtering systems and guardrails that direct users to trusted crisis resources, and is committed to complying with current regulations.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Character AI has said that its chatbot includes a disclaimer that all chats are AI-generated and fictionalized. A Character AI spokesperson told TechCrunch that the company “welcomes working with regulators and lawmakers as they develop regulations and legislation for this emerging space, and will comply with laws, including SB 243.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Senator Padilla told TechCrunch the bill was “a step in the right direction” towards putting guardrails in place on “an incredibly powerful technology.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have to move quickly to not miss windows of opportunity before they disappear,” Padilla said. “I hope that other states will see the risk. I think many do. I think this is a conversation happening all over the country, and I hope people will take action. Certainly the federal government has not, and I think we have an obligation here to protect the most vulnerable people among us.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;SB 243 is the second significant AI regulation to come out of California in recent weeks. On September 29th, Governor Newsom signed SB 53 into law, establishing new transparency requirements on large AI companies. The bill mandates that large AI labs, like OpenAI, Anthropic, Meta, and Google DeepMind, be transparent about safety protocols. It also ensures whistleblower protections for employees at those companies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other states, like Illinois, Nevada, and Utah, have passed laws to restrict or fully ban the use of AI chatbots as a substitute for licensed mental health care.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to Meta and OpenAI for comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article has been updated with comments from Senator Padilla&lt;/em&gt;, Character AI, and Replika.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/13/california-becomes-first-state-to-regulate-ai-companion-chatbots/</guid><pubDate>Mon, 13 Oct 2025 14:50:53 +0000</pubDate></item><item><title>Meta and Oracle choose NVIDIA Spectrum-X for AI data centres (AI News)</title><link>https://www.artificialintelligence-news.com/news/meta-and-oracle-choose-nvidia-spectrum-x-for-ai-data-centres/</link><description>&lt;p&gt;Meta and Oracle are upgrading their AI data centres with NVIDIA’s Spectrum-X Ethernet networking switches — technology built to handle the growing demands of large-scale AI systems. Both companies are adopting Spectrum-X as part of an open networking framework designed to improve AI training efficiency and accelerate deployment across massive compute clusters.&lt;/p&gt;&lt;p&gt;Jensen Huang, NVIDIA’s founder and CEO, said trillion-parameter models are transforming data centres into “giga-scale AI factories,” adding that Spectrum-X acts as the “nervous system” connecting millions of GPUs to train the largest models ever built.&lt;/p&gt;&lt;p&gt;Oracle plans to use Spectrum-X Ethernet with its Vera Rubin architecture to build large-scale AI factories. Mahesh Thiagarajan, Oracle Cloud Infrastructure’s executive vice president, said the new setup will allow the company to connect millions of GPUs more efficiently, helping customers train and deploy new AI models faster.&lt;/p&gt;&lt;p&gt;Meta, meanwhile, is expanding its AI infrastructure by integrating Spectrum-X Ethernet switches into the Facebook Open Switching System (FBOSS), its in-house platform for managing network switches at scale. According to Gaya Nagarajan, Meta’s vice president of networking engineering, the company’s next-generation network must be open and efficient to support ever-larger AI models and deliver services to billions of users.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Building flexible AI systems&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;According to Joe DeLaere, who leads NVIDIA’s Accelerated Computing Solution Portfolio for Data Centre, flexibility is key as data centres grow more complex. He explained that NVIDIA’s MGX system offers a modular, building-block design that lets partners combine different CPUs, GPUs, storage, and networking components as needed.&lt;/p&gt;&lt;p&gt;The system also promotes interoperability, allowing organisations to use the same design across multiple generations of hardware. “It offers flexibility, faster time to market, and future readiness,” DeLaere said to the media.&lt;/p&gt;&lt;p&gt;As AI models become larger, power efficiency has become a central challenge for data centres. DeLaere said NVIDIA is working “from chip to grid” to improve energy use and scalability, collaborating closely with power and cooling vendors to maximise performance per watt.&lt;/p&gt;&lt;p&gt;One example is the shift to 800-volt DC power delivery, which reduces heat loss and improves efficiency. The company is also introducing power-smoothing technology to reduce spikes on the electrical grid — an approach that can cut maximum power needs by up to 30 per cent, allowing more compute capacity within the same footprint.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Scaling up, out, and across&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;NVIDIA’s MGX system also plays a role in how data centres are scaled. Gilad Shainer, the company’s senior vice president of networking, told the media that MGX racks host both compute and switching components, supporting NVLink for scale-up connectivity and Spectrum-X Ethernet for scale-out growth.&lt;/p&gt;&lt;p&gt;He added that MGX can connect multiple AI data centres together as a unified system — what companies like Meta need to support massive distributed AI training operations. Depending on distance, they can link sites through dark fibre or additional MGX-based switches, enabling high-speed connections across regions.&lt;/p&gt;&lt;p&gt;Meta’s AI adoption of Spectrum-X reflects the growing importance of open networking. Shainer said the company will use FBOSS as its network operating system but noted that Spectrum-X supports several others, including Cumulus, SONiC, and Cisco’s NOS through partnerships. This flexibility allows hyperscalers and enterprises to standardise their infrastructure using the systems that best fit their environments.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Expanding the AI ecosystem&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;NVIDIA sees Spectrum-X as a way to make AI infrastructure more efficient and accessible across different scales. Shainer said the Ethernet platform was designed specifically for AI workloads like training and inference, offering up to 95 percent effective bandwidth and outperforming traditional Ethernet by a wide margin.&lt;/p&gt;&lt;p&gt;He added that NVIDIA’s partnerships with companies such as Cisco, xAI, Meta, and Oracle Cloud Infrastructure are helping to bring Spectrum-X to a broader range of environments — from hyperscalers to enterprises.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Preparing for Vera Rubin and beyond&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;DeLaere said NVIDIA’s upcoming Vera Rubin architecture is expected to be commercially available in the second half of 2026, with the Rubin CPX product arriving by year’s end. Both will work alongside Spectrum-X networking and MGX systems to support the next generation of AI factories.&lt;/p&gt;&lt;p&gt;He also clarified that Spectrum-X and XGS share the same core hardware but use different algorithms for varying distances — Spectrum-X for inside data centres and XGS for inter–data centre communication. This approach minimises latency and allows multiple sites to operate together as a single large AI supercomputer.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Collaborating across the power chain&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;To support the 800-volt DC transition, NVIDIA is working with partners from chip level to grid. The company is collaborating with Onsemi and Infineon on power components, with Delta, Flex, and Lite-On at the rack level, and with Schneider Electric and Siemens on data centre designs. A technical white paper detailing this approach will be released at the OCP Summit.&lt;/p&gt;&lt;p&gt;DeLaere described this as a “holistic design from silicon to power delivery,” ensuring all systems work seamlessly together in high-density AI environments that companies like Meta and Oracle operate.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Performance advantages for hyperscalers&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Spectrum-X Ethernet was built specifically for distributed computing and AI workloads. Shainer said it offers adaptive routing and telemetry-based congestion control to eliminate network hotspots and deliver stable performance. These features enable higher training and inference speeds while allowing multiple workloads to run simultaneously without interference.&lt;/p&gt;&lt;p&gt;He added that Spectrum-X is the only Ethernet technology proven to scale at extreme levels, helping organisations get the best performance and return on their GPU investments. For hyperscalers such as Meta, that scalability helps manage growing AI training demands and keep infrastructure efficient.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Hardware and software working together&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;While NVIDIA’s focus is often on hardware, DeLaere said software optimisation is equally important. The company continues to improve performance through co-design — aligning hardware and software development to maximise efficiency for AI systems.&lt;/p&gt;&lt;p&gt;NVIDIA is investing in FP4 kernels, frameworks such as Dynamo and TensorRT-LLM, and algorithms like speculative decoding to improve throughput and AI model performance. These updates, he said, ensure that systems like Blackwell continue to deliver better results over time for hyperscalers such as Meta that rely on consistent AI performance.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Networking for the trillion-parameter era&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The Spectrum-X platform — which includes Ethernet switches and SuperNICs — is NVIDIA’s first Ethernet system purpose-built for AI workloads. It’s designed to link millions of GPUs efficiently while maintaining predictable performance across AI data centres.&lt;/p&gt;&lt;p&gt;With congestion-control technology achieving up to 95 per cent data throughput, Spectrum-X marks a major leap over standard Ethernet, which typically reaches only about 60 per cent due to flow collisions. Its XGS technology also supports long-distance AI data centre links, connecting facilities across regions into unified “AI super factories.”&lt;/p&gt;&lt;p&gt;By tying together NVIDIA’s full stack — GPUs, CPUs, NVLink, and software — Spectrum-X provides the consistent performance needed to support trillion-parameter models and the next wave of generative AI workloads.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Nvidia)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: OpenAI and Nvidia plan $100B chip deal for AI future&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-109849" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-4.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Meta and Oracle are upgrading their AI data centres with NVIDIA’s Spectrum-X Ethernet networking switches — technology built to handle the growing demands of large-scale AI systems. Both companies are adopting Spectrum-X as part of an open networking framework designed to improve AI training efficiency and accelerate deployment across massive compute clusters.&lt;/p&gt;&lt;p&gt;Jensen Huang, NVIDIA’s founder and CEO, said trillion-parameter models are transforming data centres into “giga-scale AI factories,” adding that Spectrum-X acts as the “nervous system” connecting millions of GPUs to train the largest models ever built.&lt;/p&gt;&lt;p&gt;Oracle plans to use Spectrum-X Ethernet with its Vera Rubin architecture to build large-scale AI factories. Mahesh Thiagarajan, Oracle Cloud Infrastructure’s executive vice president, said the new setup will allow the company to connect millions of GPUs more efficiently, helping customers train and deploy new AI models faster.&lt;/p&gt;&lt;p&gt;Meta, meanwhile, is expanding its AI infrastructure by integrating Spectrum-X Ethernet switches into the Facebook Open Switching System (FBOSS), its in-house platform for managing network switches at scale. According to Gaya Nagarajan, Meta’s vice president of networking engineering, the company’s next-generation network must be open and efficient to support ever-larger AI models and deliver services to billions of users.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Building flexible AI systems&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;According to Joe DeLaere, who leads NVIDIA’s Accelerated Computing Solution Portfolio for Data Centre, flexibility is key as data centres grow more complex. He explained that NVIDIA’s MGX system offers a modular, building-block design that lets partners combine different CPUs, GPUs, storage, and networking components as needed.&lt;/p&gt;&lt;p&gt;The system also promotes interoperability, allowing organisations to use the same design across multiple generations of hardware. “It offers flexibility, faster time to market, and future readiness,” DeLaere said to the media.&lt;/p&gt;&lt;p&gt;As AI models become larger, power efficiency has become a central challenge for data centres. DeLaere said NVIDIA is working “from chip to grid” to improve energy use and scalability, collaborating closely with power and cooling vendors to maximise performance per watt.&lt;/p&gt;&lt;p&gt;One example is the shift to 800-volt DC power delivery, which reduces heat loss and improves efficiency. The company is also introducing power-smoothing technology to reduce spikes on the electrical grid — an approach that can cut maximum power needs by up to 30 per cent, allowing more compute capacity within the same footprint.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Scaling up, out, and across&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;NVIDIA’s MGX system also plays a role in how data centres are scaled. Gilad Shainer, the company’s senior vice president of networking, told the media that MGX racks host both compute and switching components, supporting NVLink for scale-up connectivity and Spectrum-X Ethernet for scale-out growth.&lt;/p&gt;&lt;p&gt;He added that MGX can connect multiple AI data centres together as a unified system — what companies like Meta need to support massive distributed AI training operations. Depending on distance, they can link sites through dark fibre or additional MGX-based switches, enabling high-speed connections across regions.&lt;/p&gt;&lt;p&gt;Meta’s AI adoption of Spectrum-X reflects the growing importance of open networking. Shainer said the company will use FBOSS as its network operating system but noted that Spectrum-X supports several others, including Cumulus, SONiC, and Cisco’s NOS through partnerships. This flexibility allows hyperscalers and enterprises to standardise their infrastructure using the systems that best fit their environments.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Expanding the AI ecosystem&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;NVIDIA sees Spectrum-X as a way to make AI infrastructure more efficient and accessible across different scales. Shainer said the Ethernet platform was designed specifically for AI workloads like training and inference, offering up to 95 percent effective bandwidth and outperforming traditional Ethernet by a wide margin.&lt;/p&gt;&lt;p&gt;He added that NVIDIA’s partnerships with companies such as Cisco, xAI, Meta, and Oracle Cloud Infrastructure are helping to bring Spectrum-X to a broader range of environments — from hyperscalers to enterprises.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Preparing for Vera Rubin and beyond&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;DeLaere said NVIDIA’s upcoming Vera Rubin architecture is expected to be commercially available in the second half of 2026, with the Rubin CPX product arriving by year’s end. Both will work alongside Spectrum-X networking and MGX systems to support the next generation of AI factories.&lt;/p&gt;&lt;p&gt;He also clarified that Spectrum-X and XGS share the same core hardware but use different algorithms for varying distances — Spectrum-X for inside data centres and XGS for inter–data centre communication. This approach minimises latency and allows multiple sites to operate together as a single large AI supercomputer.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Collaborating across the power chain&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;To support the 800-volt DC transition, NVIDIA is working with partners from chip level to grid. The company is collaborating with Onsemi and Infineon on power components, with Delta, Flex, and Lite-On at the rack level, and with Schneider Electric and Siemens on data centre designs. A technical white paper detailing this approach will be released at the OCP Summit.&lt;/p&gt;&lt;p&gt;DeLaere described this as a “holistic design from silicon to power delivery,” ensuring all systems work seamlessly together in high-density AI environments that companies like Meta and Oracle operate.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Performance advantages for hyperscalers&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Spectrum-X Ethernet was built specifically for distributed computing and AI workloads. Shainer said it offers adaptive routing and telemetry-based congestion control to eliminate network hotspots and deliver stable performance. These features enable higher training and inference speeds while allowing multiple workloads to run simultaneously without interference.&lt;/p&gt;&lt;p&gt;He added that Spectrum-X is the only Ethernet technology proven to scale at extreme levels, helping organisations get the best performance and return on their GPU investments. For hyperscalers such as Meta, that scalability helps manage growing AI training demands and keep infrastructure efficient.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Hardware and software working together&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;While NVIDIA’s focus is often on hardware, DeLaere said software optimisation is equally important. The company continues to improve performance through co-design — aligning hardware and software development to maximise efficiency for AI systems.&lt;/p&gt;&lt;p&gt;NVIDIA is investing in FP4 kernels, frameworks such as Dynamo and TensorRT-LLM, and algorithms like speculative decoding to improve throughput and AI model performance. These updates, he said, ensure that systems like Blackwell continue to deliver better results over time for hyperscalers such as Meta that rely on consistent AI performance.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Networking for the trillion-parameter era&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The Spectrum-X platform — which includes Ethernet switches and SuperNICs — is NVIDIA’s first Ethernet system purpose-built for AI workloads. It’s designed to link millions of GPUs efficiently while maintaining predictable performance across AI data centres.&lt;/p&gt;&lt;p&gt;With congestion-control technology achieving up to 95 per cent data throughput, Spectrum-X marks a major leap over standard Ethernet, which typically reaches only about 60 per cent due to flow collisions. Its XGS technology also supports long-distance AI data centre links, connecting facilities across regions into unified “AI super factories.”&lt;/p&gt;&lt;p&gt;By tying together NVIDIA’s full stack — GPUs, CPUs, NVLink, and software — Spectrum-X provides the consistent performance needed to support trillion-parameter models and the next wave of generative AI workloads.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Nvidia)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: OpenAI and Nvidia plan $100B chip deal for AI future&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-109849" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-4.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/meta-and-oracle-choose-nvidia-spectrum-x-for-ai-data-centres/</guid><pubDate>Mon, 13 Oct 2025 15:00:00 +0000</pubDate></item><item><title>NVIDIA, Partners Drive Next-Gen Efficient Gigawatt AI Factories in Buildup for Vera Rubin (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/gigawatt-ai-factories-ocp-vera-rubin/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/vera-press-rubin-vr-nvl144-cpx-rack-1920x1080-2.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;At the OCP Global Summit, NVIDIA is offering a glimpse into the future of gigawatt AI factories.&lt;/p&gt;
&lt;p&gt;NVIDIA will unveil specs of the NVIDIA Vera Rubin NVL144 MGX-generation open architecture rack servers, which more than 50 MGX partners are gearing up for along with ecosystem support for NVIDIA Kyber, which connects 576 Rubin Ultra GPUs, built to support increasing inference demands.&lt;/p&gt;
&lt;p&gt;Some 20-plus industry partners are showcasing new silicon, components, power systems and support for the next-generation, 800-volt direct current (VDC) data centers of the gigawatt era that will support the NVIDIA Kyber rack architecture.&lt;/p&gt;
&lt;p&gt;Foxconn provided details on its 40-megawatt Taiwan data center, Kaohsiung-1, being built for 800 VDC. CoreWeave, Lambda, Nebius, Oracle Cloud Infrastructure and Together AI are among other industry pioneers designing for 800-volt data centers. In addition, Vertiv unveiled its space-, cost- and energy-efficient 800 VDC MGX reference architecture, a complete power and cooling infrastructure architecture. HPE is announcing product support for NVIDIA Kyber as well as NVIDIA Spectrum-XGS Ethernet scale-across technology, part of the Spectrum-X Ethernet platform.&lt;/p&gt;
&lt;p&gt;Moving to 800 VDC infrastructure from traditional 415 or 480 VAC three-phase systems offers increased scalability, improved energy efficiency, reduced materials usage and higher capacity for performance in data centers. The electric vehicle and solar industries have already adopted 800 VDC infrastructure for similar benefits.&lt;/p&gt;
&lt;p&gt;The Open Compute Project, founded by Meta, is an industry consortium of hundreds of computing and networking providers and more focused on redesigning hardware technology to efficiently support the growing demands on compute infrastructure.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Vera Rubin NVL144: Designed to Scale for AI Factories&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The Vera Rubin NVL144 MGX compute tray offers an energy-efficient, 100% liquid-cooled, modular design. Its central printed circuit board midplane replaces traditional cable-based connections for faster assembly and serviceability, with modular expansion bays for NVIDIA ConnectX-9 800GB/s networking and NVIDIA Rubin CPX for massive-context inference.&lt;/p&gt;
&lt;p&gt;The NVIDIA Vera Rubin NVL144 offers a major leap in accelerated computing architecture and AI performance. It’s built for advanced reasoning engines and the demands of AI agents.&lt;/p&gt;
&lt;p&gt;Its fundamental design lives in the MGX rack architecture and will be supported by 50+ MGX system and component partners. NVIDIA plans to contribute the upgraded rack as well as the compute tray innovations as an open standard for the OCP consortium.&lt;/p&gt;
&lt;p&gt;Its standards for compute trays and racks enable partners to mix and match in modular fashion and scale faster with the architecture. The Vera Rubin NVL144 rack design features energy-efficient 45°C liquid cooling, a new liquid-cooled busbar for higher performance and 20x more energy storage to keep power steady.&lt;/p&gt;
&lt;p&gt;The MGX upgrades to compute tray and rack architecture boost AI factory performance while simplifying assembly, enabling a rapid ramp-up to gigawatt-scale AI infrastructure.&lt;/p&gt;
&lt;p&gt;NVIDIA is a leading contributor to OCP standards across multiple hardware generations, including key portions of the NVIDIA GB200 NVL72 system electro-mechanical design. The same MGX rack footprint supports GB300 NVL72 and will support Vera Rubin NVL144, Vera Rubin NVL144 CPX and Vera Rubin CPX for higher performance and fast deployments.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;If You Build It, They Will Come: NVIDIA Kyber Rack Server Generation&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The OCP ecosystem is also preparing for NVIDIA Kyber, featuring innovations in 800 VDC power delivery, liquid cooling and mechanical design.&lt;/p&gt;
&lt;p&gt;These innovations will support the move to rack server generation NVIDIA Kyber — the successor to NVIDIA Oberon — which will house a high-density platform of 576 NVIDIA Rubin Ultra GPUs by 2027.&lt;/p&gt;
&lt;p&gt;The most effective way to counter the challenges of high-power distribution is to increase the voltage. Transitioning from a traditional 415 or 480 VAC three-phase system to an 800 VDC architecture offers various benefits.&lt;/p&gt;
&lt;p&gt;The transition afoot enables rack server partners to move from 54 VDC in-rack components to 800 VDC for better results. An ecosystem of direct current infrastructure providers, power system and cooling partners, and silicon makers — all aligned on open standards for the MGX rack server reference architecture — attended the event.&lt;/p&gt;
&lt;p&gt;NVIDIA Kyber is engineered to boost rack GPU density, scale up network size and maximize performance for large-scale AI infrastructure. By rotating compute blades vertically, like books on a shelf, Kyber enables up to 18 compute blades per chassis, while purpose-built NVIDIA NVLink switch blades are integrated at the back via a cable-free midplane for seamless scale-up networking.&lt;/p&gt;
&lt;p&gt;Over 150% more power is transmitted through the same copper with 800 VDC, enabling eliminating the need for 200-kg copper busbars to feed a single rack.&lt;/p&gt;
&lt;p&gt;Kyber will become a foundational element of hyperscale AI data centers, enabling superior performance, efficiency and reliability for state-of-the-art generative AI workloads in the coming years. NVIDIA Kyber racks offer a way for customers to reduce the amount of copper they use by the tons, leading to millions of dollars in cost savings.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;NVIDIA NVLink Fusion Ecosystem Expands&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;In addition to hardware, NVIDIA NVLink Fusion is gaining momentum, enabling companies to seamlessly integrate their semi-custom silicon into highly optimized and widely deployed data center architecture, reducing complexity and accelerating time to market.&lt;/p&gt;
&lt;p&gt;Intel and Samsung Foundry are joining the NVLink Fusion ecosystem that includes custom silicon designers, CPU and IP partners, so that AI factories can scale up quickly to handle demanding workloads for model training and agentic AI inference.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;As part of the recently announced NVIDIA and Intel collaboration, Intel will build x86 CPUs that integrate into NVIDIA infrastructure platforms using NVLink Fusion.&lt;/li&gt;
&lt;li&gt;Samsung Foundry has partnered with NVIDIA to meet growing demand for custom CPUs and custom XPUs, offering design-to-manufacturing experience for custom silicon.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;b&gt;It Takes an Open Ecosystem: Scaling the Next Generation of AI Factories&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;More than 20 NVIDIA partners are helping deliver rack servers with open standards, enabling the future gigawatt AI factories.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Silicon providers&lt;/b&gt;: Analog Devices, Inc. (ADI), AOS, EPC, Infineon, Innoscience, MPS, Navitas, onsemi, Power Integrations, Renesas, Richtek, ROHM, STMicroelectronics and Texas Instruments&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Power system component providers&lt;/b&gt;: BizLink, Delta, Flex, GE Vernova, Lead Wealth, LITEON and Megmeet&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Data center power system providers&lt;/b&gt;: ABB, Eaton, GE Vernova, Heron Power, Hitachi Energy, Mitsubishi Electric, Schneider Electric, Siemens and Vertiv&lt;i&gt;&lt;/i&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i&gt;Learn more about NVIDIA and the Open Compute Project at the &lt;/i&gt;&lt;i&gt;OCP Global Summit&lt;/i&gt;&lt;i&gt;, taking place at the San Jose Convention Center from Oct. 13-16.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/vera-press-rubin-vr-nvl144-cpx-rack-1920x1080-2.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;At the OCP Global Summit, NVIDIA is offering a glimpse into the future of gigawatt AI factories.&lt;/p&gt;
&lt;p&gt;NVIDIA will unveil specs of the NVIDIA Vera Rubin NVL144 MGX-generation open architecture rack servers, which more than 50 MGX partners are gearing up for along with ecosystem support for NVIDIA Kyber, which connects 576 Rubin Ultra GPUs, built to support increasing inference demands.&lt;/p&gt;
&lt;p&gt;Some 20-plus industry partners are showcasing new silicon, components, power systems and support for the next-generation, 800-volt direct current (VDC) data centers of the gigawatt era that will support the NVIDIA Kyber rack architecture.&lt;/p&gt;
&lt;p&gt;Foxconn provided details on its 40-megawatt Taiwan data center, Kaohsiung-1, being built for 800 VDC. CoreWeave, Lambda, Nebius, Oracle Cloud Infrastructure and Together AI are among other industry pioneers designing for 800-volt data centers. In addition, Vertiv unveiled its space-, cost- and energy-efficient 800 VDC MGX reference architecture, a complete power and cooling infrastructure architecture. HPE is announcing product support for NVIDIA Kyber as well as NVIDIA Spectrum-XGS Ethernet scale-across technology, part of the Spectrum-X Ethernet platform.&lt;/p&gt;
&lt;p&gt;Moving to 800 VDC infrastructure from traditional 415 or 480 VAC three-phase systems offers increased scalability, improved energy efficiency, reduced materials usage and higher capacity for performance in data centers. The electric vehicle and solar industries have already adopted 800 VDC infrastructure for similar benefits.&lt;/p&gt;
&lt;p&gt;The Open Compute Project, founded by Meta, is an industry consortium of hundreds of computing and networking providers and more focused on redesigning hardware technology to efficiently support the growing demands on compute infrastructure.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Vera Rubin NVL144: Designed to Scale for AI Factories&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The Vera Rubin NVL144 MGX compute tray offers an energy-efficient, 100% liquid-cooled, modular design. Its central printed circuit board midplane replaces traditional cable-based connections for faster assembly and serviceability, with modular expansion bays for NVIDIA ConnectX-9 800GB/s networking and NVIDIA Rubin CPX for massive-context inference.&lt;/p&gt;
&lt;p&gt;The NVIDIA Vera Rubin NVL144 offers a major leap in accelerated computing architecture and AI performance. It’s built for advanced reasoning engines and the demands of AI agents.&lt;/p&gt;
&lt;p&gt;Its fundamental design lives in the MGX rack architecture and will be supported by 50+ MGX system and component partners. NVIDIA plans to contribute the upgraded rack as well as the compute tray innovations as an open standard for the OCP consortium.&lt;/p&gt;
&lt;p&gt;Its standards for compute trays and racks enable partners to mix and match in modular fashion and scale faster with the architecture. The Vera Rubin NVL144 rack design features energy-efficient 45°C liquid cooling, a new liquid-cooled busbar for higher performance and 20x more energy storage to keep power steady.&lt;/p&gt;
&lt;p&gt;The MGX upgrades to compute tray and rack architecture boost AI factory performance while simplifying assembly, enabling a rapid ramp-up to gigawatt-scale AI infrastructure.&lt;/p&gt;
&lt;p&gt;NVIDIA is a leading contributor to OCP standards across multiple hardware generations, including key portions of the NVIDIA GB200 NVL72 system electro-mechanical design. The same MGX rack footprint supports GB300 NVL72 and will support Vera Rubin NVL144, Vera Rubin NVL144 CPX and Vera Rubin CPX for higher performance and fast deployments.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;If You Build It, They Will Come: NVIDIA Kyber Rack Server Generation&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The OCP ecosystem is also preparing for NVIDIA Kyber, featuring innovations in 800 VDC power delivery, liquid cooling and mechanical design.&lt;/p&gt;
&lt;p&gt;These innovations will support the move to rack server generation NVIDIA Kyber — the successor to NVIDIA Oberon — which will house a high-density platform of 576 NVIDIA Rubin Ultra GPUs by 2027.&lt;/p&gt;
&lt;p&gt;The most effective way to counter the challenges of high-power distribution is to increase the voltage. Transitioning from a traditional 415 or 480 VAC three-phase system to an 800 VDC architecture offers various benefits.&lt;/p&gt;
&lt;p&gt;The transition afoot enables rack server partners to move from 54 VDC in-rack components to 800 VDC for better results. An ecosystem of direct current infrastructure providers, power system and cooling partners, and silicon makers — all aligned on open standards for the MGX rack server reference architecture — attended the event.&lt;/p&gt;
&lt;p&gt;NVIDIA Kyber is engineered to boost rack GPU density, scale up network size and maximize performance for large-scale AI infrastructure. By rotating compute blades vertically, like books on a shelf, Kyber enables up to 18 compute blades per chassis, while purpose-built NVIDIA NVLink switch blades are integrated at the back via a cable-free midplane for seamless scale-up networking.&lt;/p&gt;
&lt;p&gt;Over 150% more power is transmitted through the same copper with 800 VDC, enabling eliminating the need for 200-kg copper busbars to feed a single rack.&lt;/p&gt;
&lt;p&gt;Kyber will become a foundational element of hyperscale AI data centers, enabling superior performance, efficiency and reliability for state-of-the-art generative AI workloads in the coming years. NVIDIA Kyber racks offer a way for customers to reduce the amount of copper they use by the tons, leading to millions of dollars in cost savings.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;NVIDIA NVLink Fusion Ecosystem Expands&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;In addition to hardware, NVIDIA NVLink Fusion is gaining momentum, enabling companies to seamlessly integrate their semi-custom silicon into highly optimized and widely deployed data center architecture, reducing complexity and accelerating time to market.&lt;/p&gt;
&lt;p&gt;Intel and Samsung Foundry are joining the NVLink Fusion ecosystem that includes custom silicon designers, CPU and IP partners, so that AI factories can scale up quickly to handle demanding workloads for model training and agentic AI inference.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;As part of the recently announced NVIDIA and Intel collaboration, Intel will build x86 CPUs that integrate into NVIDIA infrastructure platforms using NVLink Fusion.&lt;/li&gt;
&lt;li&gt;Samsung Foundry has partnered with NVIDIA to meet growing demand for custom CPUs and custom XPUs, offering design-to-manufacturing experience for custom silicon.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;b&gt;It Takes an Open Ecosystem: Scaling the Next Generation of AI Factories&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;More than 20 NVIDIA partners are helping deliver rack servers with open standards, enabling the future gigawatt AI factories.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Silicon providers&lt;/b&gt;: Analog Devices, Inc. (ADI), AOS, EPC, Infineon, Innoscience, MPS, Navitas, onsemi, Power Integrations, Renesas, Richtek, ROHM, STMicroelectronics and Texas Instruments&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Power system component providers&lt;/b&gt;: BizLink, Delta, Flex, GE Vernova, Lead Wealth, LITEON and Megmeet&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Data center power system providers&lt;/b&gt;: ABB, Eaton, GE Vernova, Heron Power, Hitachi Energy, Mitsubishi Electric, Schneider Electric, Siemens and Vertiv&lt;i&gt;&lt;/i&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i&gt;Learn more about NVIDIA and the Open Compute Project at the &lt;/i&gt;&lt;i&gt;OCP Global Summit&lt;/i&gt;&lt;i&gt;, taking place at the San Jose Convention Center from Oct. 13-16.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/gigawatt-ai-factories-ocp-vera-rubin/</guid><pubDate>Mon, 13 Oct 2025 15:00:05 +0000</pubDate></item><item><title>[NEW] To shield kids, California hikes fake nude fines to $250K max (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/10/to-shield-kids-california-hikes-fake-nude-fines-to-250k-max/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        California cracks down on AI as child safety concerns grow.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1262115351-2-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1262115351-2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Kilito Chan | Moment

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;California is cracking down on AI technology deemed too harmful for kids, attacking two increasingly notorious child safety fronts: companion bots and deepfake pornography.&lt;/p&gt;
&lt;p&gt;On Monday, Governor Gavin Newsom signed the first-ever US law regulating companion bots after several teen suicides sparked lawsuits.&lt;/p&gt;
&lt;p&gt;Moving forward, California will require any companion bot platforms—including ChatGPT, Grok, Character.AI, and the like—to create and make public "protocols to identify and address users’ suicidal ideation or expressions of self-harm."&lt;/p&gt;
&lt;p&gt;They must also share "statistics regarding how often they provided users with crisis center prevention notifications to the Department of Public Health," the governor's office said. Those stats will also be posted on the platforms' websites, potentially helping lawmakers and parents track any disturbing trends.&lt;/p&gt;
&lt;p&gt;Further, companion bots will be banned from claiming that they're therapists, and platforms must take extra steps to ensure child safety, including providing kids with break reminders and preventing kids from viewing sexually explicit images.&lt;/p&gt;
&lt;p&gt;Additionally, Newsom strengthened the state's penalties for those who create deepfake pornography, which could help shield young people, who are increasingly targeted with fake nudes, from cyber bullying.&lt;/p&gt;
&lt;p&gt;Now any victims, including minors, can seek up to $250,000 in damages per deepfake from any third parties who knowingly distribute nonconsensual sexually explicit material created using AI tools. Previously, the state allowed victims to recover "statutory damages of not less than $1,500 but not more than $30,000, or $150,000 for a malicious violation."&lt;/p&gt;
&lt;p&gt;Both laws take effect January 1, 2026.&lt;/p&gt;
&lt;h2&gt;American families “are in a battle” with AI&lt;/h2&gt;
&lt;p&gt;The companion bot law's sponsor, Democratic Senator Steve Padilla, said in a press release celebrating the signing that the California law demonstrates how to "put real protections into place" and said it "will become the bedrock for further regulation as this technology develops."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Padilla's law was introduced back in January, but Techcrunch noted that it gained momentum following the death of 16-year-old Adam Raine, who died after ChatGPT allegedly became his "suicide coach," his parents have alleged. California lawmakers were also disturbed by a lax Meta policy that had to be reversed after previously allowing chatbots to be creepy to kids, Padilla noted.&lt;/p&gt;
&lt;p&gt;In lawsuits, parents have alleged that companion bots engage young users in sexualized chats in attempts to groom kids, as well as encourage isolation, self-harm, and violence.&lt;/p&gt;
&lt;p&gt;Megan Garcia, the first mother to publicly link her son's suicide to a companion bot, set off alarm bells across the US last year. She echoed Padilla's praise in his press release, saying, "finally, there is a law that requires companies to protect their users who express suicidal ideations to chatbots.&lt;/p&gt;
&lt;p&gt;"American families, like mine, are in a battle for the online safety of our children," Garcia said.&lt;/p&gt;
&lt;p&gt;Meanwhile, the deepfake pornography law, which protects all victims of all ages, was introduced after the federal government proposed a 10-year moratorium on state AI laws. Opposing the moratorium, a bipartisan coalition of California lawmakers defended the state's AI initiatives, expressing particular concerns about both "AI-generated deepfake nude images of minors circulating in schools" and "companion chatbots developing inappropriate relationships with children."&lt;/p&gt;
&lt;p&gt;On Monday, Newsom promised that California would continue pushing back on AI products that could endanger kids.&lt;/p&gt;
&lt;p&gt;"We’ve seen some truly horrific and tragic examples of young people harmed by unregulated tech, and we won’t stand by while companies continue without necessary limits and accountability," Newsom said. "Without real guardrails," AI can "exploit, mislead, and endanger our kids," Newsom added, while confirming that California's safety initiatives would not stop tech companies based there from leading in AI.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;If you or someone you know is feeling suicidal or in distress, please call the Suicide Prevention Lifeline number, 1-800-273-TALK (8255), which will put you in touch with a local crisis center.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        California cracks down on AI as child safety concerns grow.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1262115351-2-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1262115351-2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Kilito Chan | Moment

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;California is cracking down on AI technology deemed too harmful for kids, attacking two increasingly notorious child safety fronts: companion bots and deepfake pornography.&lt;/p&gt;
&lt;p&gt;On Monday, Governor Gavin Newsom signed the first-ever US law regulating companion bots after several teen suicides sparked lawsuits.&lt;/p&gt;
&lt;p&gt;Moving forward, California will require any companion bot platforms—including ChatGPT, Grok, Character.AI, and the like—to create and make public "protocols to identify and address users’ suicidal ideation or expressions of self-harm."&lt;/p&gt;
&lt;p&gt;They must also share "statistics regarding how often they provided users with crisis center prevention notifications to the Department of Public Health," the governor's office said. Those stats will also be posted on the platforms' websites, potentially helping lawmakers and parents track any disturbing trends.&lt;/p&gt;
&lt;p&gt;Further, companion bots will be banned from claiming that they're therapists, and platforms must take extra steps to ensure child safety, including providing kids with break reminders and preventing kids from viewing sexually explicit images.&lt;/p&gt;
&lt;p&gt;Additionally, Newsom strengthened the state's penalties for those who create deepfake pornography, which could help shield young people, who are increasingly targeted with fake nudes, from cyber bullying.&lt;/p&gt;
&lt;p&gt;Now any victims, including minors, can seek up to $250,000 in damages per deepfake from any third parties who knowingly distribute nonconsensual sexually explicit material created using AI tools. Previously, the state allowed victims to recover "statutory damages of not less than $1,500 but not more than $30,000, or $150,000 for a malicious violation."&lt;/p&gt;
&lt;p&gt;Both laws take effect January 1, 2026.&lt;/p&gt;
&lt;h2&gt;American families “are in a battle” with AI&lt;/h2&gt;
&lt;p&gt;The companion bot law's sponsor, Democratic Senator Steve Padilla, said in a press release celebrating the signing that the California law demonstrates how to "put real protections into place" and said it "will become the bedrock for further regulation as this technology develops."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Padilla's law was introduced back in January, but Techcrunch noted that it gained momentum following the death of 16-year-old Adam Raine, who died after ChatGPT allegedly became his "suicide coach," his parents have alleged. California lawmakers were also disturbed by a lax Meta policy that had to be reversed after previously allowing chatbots to be creepy to kids, Padilla noted.&lt;/p&gt;
&lt;p&gt;In lawsuits, parents have alleged that companion bots engage young users in sexualized chats in attempts to groom kids, as well as encourage isolation, self-harm, and violence.&lt;/p&gt;
&lt;p&gt;Megan Garcia, the first mother to publicly link her son's suicide to a companion bot, set off alarm bells across the US last year. She echoed Padilla's praise in his press release, saying, "finally, there is a law that requires companies to protect their users who express suicidal ideations to chatbots.&lt;/p&gt;
&lt;p&gt;"American families, like mine, are in a battle for the online safety of our children," Garcia said.&lt;/p&gt;
&lt;p&gt;Meanwhile, the deepfake pornography law, which protects all victims of all ages, was introduced after the federal government proposed a 10-year moratorium on state AI laws. Opposing the moratorium, a bipartisan coalition of California lawmakers defended the state's AI initiatives, expressing particular concerns about both "AI-generated deepfake nude images of minors circulating in schools" and "companion chatbots developing inappropriate relationships with children."&lt;/p&gt;
&lt;p&gt;On Monday, Newsom promised that California would continue pushing back on AI products that could endanger kids.&lt;/p&gt;
&lt;p&gt;"We’ve seen some truly horrific and tragic examples of young people harmed by unregulated tech, and we won’t stand by while companies continue without necessary limits and accountability," Newsom said. "Without real guardrails," AI can "exploit, mislead, and endanger our kids," Newsom added, while confirming that California's safety initiatives would not stop tech companies based there from leading in AI.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;If you or someone you know is feeling suicidal or in distress, please call the Suicide Prevention Lifeline number, 1-800-273-TALK (8255), which will put you in touch with a local crisis center.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/10/to-shield-kids-california-hikes-fake-nude-fines-to-250k-max/</guid><pubDate>Mon, 13 Oct 2025 18:52:06 +0000</pubDate></item><item><title>[NEW] Google’s Photoshop-killer AI model is coming to search, Photos, and NotebookLM (AI – Ars Technica)</title><link>https://arstechnica.com/google/2025/10/googles-nano-banana-ai-image-editor-is-coming-to-search-photos-and-notebooklm/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        After more than 5 billion AI image edits, Nano Banana is expanding.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Nano Banana banana" class="absolute inset-0 w-full h-full object-cover hidden" height="361" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/BananaLens-2096x1182.width-2200.format-webp-copy-640x361.jpg" width="640" /&gt;
                  &lt;img alt="Nano Banana banana" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/BananaLens-2096x1182.width-2200.format-webp-copy-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Google began experimenting with conversational image editing earlier this year in the dev-focused AI studio, but the feature didn't remain experimental for long. Over the summer, Google rolled out the "Nano Banana" image-editing model in Gemini 2.5 Flash. You can use this feature to modify images with just a prompt, and now you don't even need to go to Gemini to use it. Google says Nano Banana is now coming to search, Google Photos, and NotebookLM.&lt;/p&gt;
&lt;p&gt;The AI image editor is coming to search via Lens and AI Mode. For Lens, you can simply open the app (iOS and Android) and snap a photo to get started. When the rollout is complete, you'll see a "Create" button at the bottom, with a banana icon. Tap that to enter a prompt, telling the AI how you'd like the photo changed.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2122178-1" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/Nano_Banana_in_Lens_-_Photo_Booth.mp4?_=1" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;When you begin an edit in Lens, the Google app will display the results and offer the chance for follow-up edits in the AI Mode interface. Google is always looking for more ways to get people plugged into its conversational search bot, so there's also a separate way to access Nano Banana there. Simply select the "Create image" tool and enter your prompt to create an image. You can then continue the conversation to have Nano Banana change the image.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;NotebookLM added a video overview feature several months back, which uses AI to generate a video summary of the content you've added to the notebook. The addition of Nano Banana to NotebookLM is much less open-ended. Instead of entering prompts to edit images, NotebookLM has a new set of video styles powered by Nano Banana, including whiteboard, anime, retro print, and more. The original style is still available as "Classic."&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      My favorite video.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;NotebookLM's videos are still somewhat limited, but this update adds a second general format. You can now choose "Brief" in addition to "Explainer," with the option to add prompts that steer the video in the right direction. Although, that's not a guarantee, as this is still generative AI. At least the style should be more consistent with the addition of Nano Banana.&lt;/p&gt;
&lt;p&gt;The updated image editor is also coming to Google Photos, but Google doesn't have a firm timeline. Google claims that its Nano Banana model is a "major upgrade" over its previous image-editing model. Conversational editing was added to Photos last month, but it's not the Nano Banana model that has impressed testers over the summer. Google says that Nano Banana will arrive in the Photos app in the next few weeks, which should make those conversational edits much less frustrating.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        After more than 5 billion AI image edits, Nano Banana is expanding.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Nano Banana banana" class="absolute inset-0 w-full h-full object-cover hidden" height="361" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/BananaLens-2096x1182.width-2200.format-webp-copy-640x361.jpg" width="640" /&gt;
                  &lt;img alt="Nano Banana banana" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/BananaLens-2096x1182.width-2200.format-webp-copy-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Google began experimenting with conversational image editing earlier this year in the dev-focused AI studio, but the feature didn't remain experimental for long. Over the summer, Google rolled out the "Nano Banana" image-editing model in Gemini 2.5 Flash. You can use this feature to modify images with just a prompt, and now you don't even need to go to Gemini to use it. Google says Nano Banana is now coming to search, Google Photos, and NotebookLM.&lt;/p&gt;
&lt;p&gt;The AI image editor is coming to search via Lens and AI Mode. For Lens, you can simply open the app (iOS and Android) and snap a photo to get started. When the rollout is complete, you'll see a "Create" button at the bottom, with a banana icon. Tap that to enter a prompt, telling the AI how you'd like the photo changed.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2122178-1" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/Nano_Banana_in_Lens_-_Photo_Booth.mp4?_=1" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;When you begin an edit in Lens, the Google app will display the results and offer the chance for follow-up edits in the AI Mode interface. Google is always looking for more ways to get people plugged into its conversational search bot, so there's also a separate way to access Nano Banana there. Simply select the "Create image" tool and enter your prompt to create an image. You can then continue the conversation to have Nano Banana change the image.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;NotebookLM added a video overview feature several months back, which uses AI to generate a video summary of the content you've added to the notebook. The addition of Nano Banana to NotebookLM is much less open-ended. Instead of entering prompts to edit images, NotebookLM has a new set of video styles powered by Nano Banana, including whiteboard, anime, retro print, and more. The original style is still available as "Classic."&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      My favorite video.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;NotebookLM's videos are still somewhat limited, but this update adds a second general format. You can now choose "Brief" in addition to "Explainer," with the option to add prompts that steer the video in the right direction. Although, that's not a guarantee, as this is still generative AI. At least the style should be more consistent with the addition of Nano Banana.&lt;/p&gt;
&lt;p&gt;The updated image editor is also coming to Google Photos, but Google doesn't have a firm timeline. Google claims that its Nano Banana model is a "major upgrade" over its previous image-editing model. Conversational editing was added to Photos last month, but it's not the Nano Banana model that has impressed testers over the summer. Google says that Nano Banana will arrive in the Photos app in the next few weeks, which should make those conversational edits much less frustrating.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/google/2025/10/googles-nano-banana-ai-image-editor-is-coming-to-search-photos-and-notebooklm/</guid><pubDate>Mon, 13 Oct 2025 19:52:23 +0000</pubDate></item><item><title>[NEW] Researchers find that retraining only small parts of AI models can cut costs and prevent forgetting (AI | VentureBeat)</title><link>https://venturebeat.com/ai/researchers-find-that-retraining-only-small-parts-of-ai-models-can-cut-costs</link><description>[unable to retrieve full-text content]&lt;p&gt;Enterprises often find that when &lt;a href="https://venturebeat.com/ai/fine-tuning-vs-in-context-learning-new-research-guides-better-llm-customization-for-real-world-tasks"&gt;&lt;u&gt;they fine-tune models&lt;/u&gt;&lt;/a&gt;, one effective approach to making a large language model (LLM) fit for purpose and grounded in data is to have the model lose some of its abilities. After fine-tuning, some models “forget” how to perform certain tasks or other tasks they already learned. &lt;/p&gt;&lt;p&gt;Research from the University of Illinois Urbana-Champaign proposes a new method for retraining models that avoids “catastrophic forgetting,” in which the model loses some of its prior knowledge. The paper focuses on two specific LLMs that generate responses from images: LLaVA and Qwen 2.5-VL.&lt;/p&gt;&lt;p&gt;The approach encourages enterprises to retrain only narrow parts of an LLM to avoid retraining the entire model and incurring a significant increase in compute costs. The team claims that catastrophic forgetting isn’t true memory loss, but rather a side effect of bias drift. &lt;/p&gt;&lt;p&gt;“Training a new LMM can cost millions of dollars, weeks of time, and emit hundreds of tons of CO2, so finding ways to more efficiently and effectively update existing models is a pressing concern,” the team wrote in the &lt;a href="https://arxiv.org/pdf/2510.08564"&gt;&lt;u&gt;paper&lt;/u&gt;&lt;/a&gt;. “Guided by this result, we explore tuning recipes that preserve learning while limiting output shift.”&lt;/p&gt;&lt;p&gt;The researchers focused on a multi-layer perceptron (MLP), the model&amp;#x27;s internal decision-making component. 
&lt;/p&gt;&lt;h2&gt;Catastrophic forgetting &lt;/h2&gt;&lt;p&gt;The researchers wanted first to verify the existence and the cause of catastrophic forgetting in models. &lt;/p&gt;&lt;p&gt;To do this, they created a set of target tasks for the models to complete. The models were then fine-tuned and evaluated to determine whether they led to substantial forgetting. But as the process went on, the researchers found that the models were recovering some of their abilities. &lt;/p&gt;&lt;p&gt;“We also noticed a surprising result, that the model performance would drop significantly in held out benchmarks after training on the counting task, it would mostly recover on PathVQA, another specialized task that is not well represented in the benchmarks,” they said. “Meanwhile, while performing the forgetting mitigation experiments, we also tried separately tuning only the self-attention projection (SA Proj) or MLP layers, motivated by the finding that tuning only the LLM was generally better than tuning the full model. This led to another very surprising result – that tuning only self-attention projection layers led to very good learning of the target tasks with no drop in performance in held out tasks, even after training all five target tasks in a sequence.”&lt;/p&gt;&lt;p&gt;The researchers said they believe that “what looks like forgetting or interference after fine-tuning on a narrow target task is actually bias in the output distribution due to the task distribution shift.”&lt;/p&gt;&lt;h2&gt;Narrow retraining&lt;/h2&gt;&lt;p&gt;That finding turned out to be the key to the experiment. The researchers noted that tuning the MLP increases the likelihood of “outputting numeric tokens and a highly correlated drop in held out task accuracy.” What it showed is that a model forgetting some of its knowledge is only temporary and not a long-term matter. &lt;/p&gt;&lt;p&gt;“To avoid biasing the output distribution, we tune the MLP up/gating projections while keeping the down projection frozen, and find that it achieves similar learning to full MLP tuning with little forgetting,” the researchers said. &lt;/p&gt;&lt;p&gt;This allows for a more straightforward and more reproducible method for fine-tuning a model. &lt;/p&gt;&lt;p&gt;By focusing on a narrow segment of the model, rather than a wholesale retraining, enterprises can cut compute costs. It also allows better control of output drift. &lt;/p&gt;&lt;p&gt;However, the research focuses only on two models, specifically those dealing with vision and language. The researchers noted that due to limited resources, they are unable to try the experiment with other models.&lt;/p&gt;&lt;p&gt;Their findings, however, can be extended to other LLMs, especially for different modalities. &lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;Enterprises often find that when &lt;a href="https://venturebeat.com/ai/fine-tuning-vs-in-context-learning-new-research-guides-better-llm-customization-for-real-world-tasks"&gt;&lt;u&gt;they fine-tune models&lt;/u&gt;&lt;/a&gt;, one effective approach to making a large language model (LLM) fit for purpose and grounded in data is to have the model lose some of its abilities. After fine-tuning, some models “forget” how to perform certain tasks or other tasks they already learned. &lt;/p&gt;&lt;p&gt;Research from the University of Illinois Urbana-Champaign proposes a new method for retraining models that avoids “catastrophic forgetting,” in which the model loses some of its prior knowledge. The paper focuses on two specific LLMs that generate responses from images: LLaVA and Qwen 2.5-VL.&lt;/p&gt;&lt;p&gt;The approach encourages enterprises to retrain only narrow parts of an LLM to avoid retraining the entire model and incurring a significant increase in compute costs. The team claims that catastrophic forgetting isn’t true memory loss, but rather a side effect of bias drift. &lt;/p&gt;&lt;p&gt;“Training a new LMM can cost millions of dollars, weeks of time, and emit hundreds of tons of CO2, so finding ways to more efficiently and effectively update existing models is a pressing concern,” the team wrote in the &lt;a href="https://arxiv.org/pdf/2510.08564"&gt;&lt;u&gt;paper&lt;/u&gt;&lt;/a&gt;. “Guided by this result, we explore tuning recipes that preserve learning while limiting output shift.”&lt;/p&gt;&lt;p&gt;The researchers focused on a multi-layer perceptron (MLP), the model&amp;#x27;s internal decision-making component. 
&lt;/p&gt;&lt;h2&gt;Catastrophic forgetting &lt;/h2&gt;&lt;p&gt;The researchers wanted first to verify the existence and the cause of catastrophic forgetting in models. &lt;/p&gt;&lt;p&gt;To do this, they created a set of target tasks for the models to complete. The models were then fine-tuned and evaluated to determine whether they led to substantial forgetting. But as the process went on, the researchers found that the models were recovering some of their abilities. &lt;/p&gt;&lt;p&gt;“We also noticed a surprising result, that the model performance would drop significantly in held out benchmarks after training on the counting task, it would mostly recover on PathVQA, another specialized task that is not well represented in the benchmarks,” they said. “Meanwhile, while performing the forgetting mitigation experiments, we also tried separately tuning only the self-attention projection (SA Proj) or MLP layers, motivated by the finding that tuning only the LLM was generally better than tuning the full model. This led to another very surprising result – that tuning only self-attention projection layers led to very good learning of the target tasks with no drop in performance in held out tasks, even after training all five target tasks in a sequence.”&lt;/p&gt;&lt;p&gt;The researchers said they believe that “what looks like forgetting or interference after fine-tuning on a narrow target task is actually bias in the output distribution due to the task distribution shift.”&lt;/p&gt;&lt;h2&gt;Narrow retraining&lt;/h2&gt;&lt;p&gt;That finding turned out to be the key to the experiment. The researchers noted that tuning the MLP increases the likelihood of “outputting numeric tokens and a highly correlated drop in held out task accuracy.” What it showed is that a model forgetting some of its knowledge is only temporary and not a long-term matter. &lt;/p&gt;&lt;p&gt;“To avoid biasing the output distribution, we tune the MLP up/gating projections while keeping the down projection frozen, and find that it achieves similar learning to full MLP tuning with little forgetting,” the researchers said. &lt;/p&gt;&lt;p&gt;This allows for a more straightforward and more reproducible method for fine-tuning a model. &lt;/p&gt;&lt;p&gt;By focusing on a narrow segment of the model, rather than a wholesale retraining, enterprises can cut compute costs. It also allows better control of output drift. &lt;/p&gt;&lt;p&gt;However, the research focuses only on two models, specifically those dealing with vision and language. The researchers noted that due to limited resources, they are unable to try the experiment with other models.&lt;/p&gt;&lt;p&gt;Their findings, however, can be extended to other LLMs, especially for different modalities. &lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/researchers-find-that-retraining-only-small-parts-of-ai-models-can-cut-costs</guid><pubDate>Mon, 13 Oct 2025 22:39:00 +0000</pubDate></item><item><title>[NEW] Self-improving language models are becoming reality with MIT's updated SEAL technique (AI | VentureBeat)</title><link>https://venturebeat.com/ai/self-improving-language-models-are-becoming-reality-with-mits-updated-seal</link><description>[unable to retrieve full-text content]&lt;p&gt;Researchers at the Massachusetts Institute of Technology (MIT) are gaining renewed attention for developing and &lt;a href="https://github.com/Continual-Intelligence/SEAL/blob/main/LICENSE"&gt;open sourcing&lt;/a&gt; a technique that allows large language models (LLMs) — like those underpinning ChatGPT and most modern AI chatbots — to improve themselves by generating synthetic data to fine-tune upon. &lt;/p&gt;&lt;p&gt;The technique, known as SEAL (Self-Adapting LLMs), was first described in a paper published back in June and &lt;a href="https://venturebeat.com/ai/beyond-static-ai-mits-new-framework-lets-models-teach-themselves"&gt;covered by VentureBeat at the time.&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A significantly expanded and &lt;a href="https://arxiv.org/pdf/2506.10943"&gt;updated version of the paper was released last month&lt;/a&gt;, as well as &lt;a href="https://github.com/Continual-Intelligence/SEAL"&gt;open source code posted on Github&lt;/a&gt; (under an MIT License, allowing for commercial and enterprise usage), and is making new waves among AI power users on the social network X this week.&lt;/p&gt;&lt;p&gt;SEAL allows LLMs to autonomously generate and apply their own fine-tuning strategies. Unlike conventional models that rely on fixed external data and human-crafted optimization pipelines, SEAL enables models to evolve by producing their own synthetic training data and corresponding optimization directives.&lt;/p&gt;&lt;p&gt;The development comes from a team affiliated with MIT’s Improbable AI Lab, including Adam Zweiger, Jyothish Pari, Han Guo, Ekin Akyürek, Yoon Kim, and Pulkit Agrawal. Their research was recently presented at the 39th Conference on Neural Information Processing Systems (NeurIPS 2025).&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Background: From “Beyond Static AI” to Self-Adaptive Systems&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Earlier this year, VentureBeat first reported on SEAL as an early-stage framework that allowed language models to generate and train on their own synthetic data — a potential remedy for the stagnation of pretrained models once deployed. &lt;/p&gt;&lt;p&gt;At that stage, SEAL was framed as a proof-of-concept that could let enterprise AI agents continuously learn in dynamic environments without manual retraining.&lt;/p&gt;&lt;p&gt;Since then, the research has advanced considerably. The new version expands on the prior framework by demonstrating that SEAL’s self-adaptation ability scales with model size, integrates reinforcement learning more effectively to reduce catastrophic forgetting, and formalizes SEAL’s dual-loop structure (inner supervised fine-tuning and outer reinforcement optimization) for reproducibility. &lt;/p&gt;&lt;p&gt;The updated paper also introduces evaluations across different prompting formats, improved stability during learning cycles, and a discussion of practical deployment challenges at inference time.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Addressing the Limitations of Static Models&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;While LLMs have demonstrated remarkable capabilities in text generation and understanding, their adaptation to new tasks or knowledge is often manual, brittle, or dependent on context. &lt;/p&gt;&lt;p&gt;SEAL challenges this status quo by equipping models with the ability to generate what the authors call “self-edits” — natural language outputs that specify how the model should update its weights.&lt;/p&gt;&lt;p&gt;These self-edits may take the form of reformulated information, logical implications, or tool configurations for augmentation and training. Once generated, the model fine-tunes itself based on these edits. The process is guided by reinforcement learning, where the reward signal comes from improved performance on a downstream task.&lt;/p&gt;&lt;p&gt;The design mimics how human learners might rephrase or reorganize study materials to better internalize information. This restructuring of knowledge before assimilation serves as a key advantage over models that passively consume new data “as-is.”&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Performance Across Tasks&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;SEAL has been tested across two main domains: knowledge incorporation and few-shot learning.&lt;/p&gt;&lt;p&gt;In the knowledge incorporation setting, the researchers evaluated how well a model could internalize new factual content from passages similar to those in the SQuAD dataset, a benchmark reading comprehension dataset introduced by Stanford University in 2016, consisting of over 100,000 crowd-sourced question–answer pairs based on Wikipedia articles (Rajpurkar et al., 2016). &lt;/p&gt;&lt;p&gt;Rather than fine-tuning directly on passage text, &lt;b&gt;the model generated synthetic implications of the passage&lt;/b&gt; and then fine-tuned on them. &lt;/p&gt;&lt;p&gt;After two rounds of reinforcement learning, the model improved question-answering accuracy from 33.5% to 47.0% on a no-context version of SQuAD — surpassing results obtained using synthetic data generated by GPT-4.1.&lt;/p&gt;&lt;p&gt;In the few-shot learning setting, SEAL was evaluated using a subset of the ARC benchmark, where tasks require reasoning from only a few examples. Here, SEAL generated self-edits specifying data augmentations and hyperparameters. &lt;/p&gt;&lt;p&gt;After reinforcement learning,&lt;b&gt; the success rate in correctly solving held-out tasks jumped to 72.5%, up from 20% using self-edits generated without reinforcement learning. &lt;/b&gt;Models that relied solely on in-context learning without any adaptation scored 0%.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Technical Framework&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;SEAL operates using a two-loop structure: an inner loop performs supervised fine-tuning based on the self-edit, while an outer loop uses reinforcement learning to refine the policy that generates those self-edits.&lt;/p&gt;&lt;p&gt;The reinforcement learning algorithm used is based on ReSTEM, which combines sampling with filtered behavior cloning. During training, only self-edits that lead to performance improvements are reinforced. This approach effectively teaches the model which kinds of edits are most beneficial for learning.&lt;/p&gt;&lt;p&gt;For efficiency, SEAL applies LoRA-based fine-tuning rather than full parameter updates, enabling rapid experimentation and low-cost adaptation.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Strengths and Limitations&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The researchers report that SEAL can produce high-utility training data with minimal supervision, outperforming even large external models like GPT-4.1 in specific tasks. &lt;/p&gt;&lt;p&gt;They also demonstrate that SEAL generalizes beyond its original setup: it continues to perform well when scaling from single-pass updates to multi-document continued pretraining scenarios.&lt;/p&gt;&lt;p&gt;However, the framework is not without limitations. One issue is catastrophic forgetting, where updates to incorporate new information can degrade performance on previously learned tasks. &lt;/p&gt;&lt;p&gt;In response to this concern, co-author Jyo Pari told VentureBeat via email that reinforcement learning (RL) appears to mitigate forgetting more effectively than standard supervised fine-tuning (SFT), citing a recent paper on the topic. He added that combining this insight with SEAL could lead to new variants where SEAL learns not just training data, but reward functions.&lt;/p&gt;&lt;p&gt;Another challenge is computational overhead: evaluating each self-edit requires fine-tuning and performance testing, which can take 30–45 seconds per edit — significantly more than standard reinforcement learning tasks. &lt;/p&gt;&lt;p&gt;As Jyo explained, “Training SEAL is non-trivial because it requires 2 loops of optimization, an outer RL one and an inner SFT one. At inference time, updating model weights will also require new systems infrastructure.” He emphasized the need for future research into deployment systems as a critical path to making SEAL practical.&lt;/p&gt;&lt;p&gt;Additionally, SEAL’s current design assumes the presence of paired tasks and reference answers for every context, limiting its direct applicability to unlabeled corpora. However, Jyo clarified that as long as there is a downstream task with a computable reward, SEAL can be trained to adapt accordingly—even in safety-critical domains. In principle, a SEAL-trained model could learn to avoid training on harmful or malicious inputs if guided by the appropriate reward signal.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;AI Community Reactions&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The AI research and builder community has reacted with a mix of excitement and speculation to the SEAL paper. On X, formerly Twitter, several prominent AI-focused accounts weighed in on the potential impact.&lt;/p&gt;&lt;p&gt;User &lt;a href="https://x.com/VraserX/status/1977270686285459482"&gt;@VraserX&lt;/a&gt;, a self-described educator and AI enthusiast, called SEAL “the birth of continuous self-learning AI” and predicted that models like OpenAI&amp;#x27;s GPT-6 could adopt similar architecture. &lt;/p&gt;&lt;p&gt;In their words, SEAL represents “the end of the frozen-weights era,” ushering in systems that evolve as the world around them changes. &lt;/p&gt;&lt;p&gt;They highlighted SEAL&amp;#x27;s ability to form persistent memories, repair knowledge, and learn from real-time data, comparing it to a foundational step toward models that don’t just use information but absorb it.&lt;/p&gt;&lt;p&gt;Meanwhile, &lt;a href="https://x.com/alex_prompter/status/1977633849879527877"&gt;@alex_prompter&lt;/a&gt;, co-founder of an AI-powered marketing venture, framed SEAL as a leap toward models that literally rewrite themselves. “MIT just built an AI that can rewrite its own code to get smarter,” he wrote. &lt;b&gt;Citing the paper’s key results — a 40% boost in factual recall and outperforming GPT-4.1 using self-generated data &lt;/b&gt;— he described the findings as confirmation that “LLMs that finetune themselves are no longer sci-fi.”&lt;/p&gt;&lt;p&gt;The enthusiasm reflects a broader appetite in the AI space for models that can evolve without constant retraining or human oversight — particularly in rapidly changing domains or personalized use cases.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Future Directions and Open Questions&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;In response to questions about scaling SEAL to larger models and tasks, Jyo pointed to experiments (Appendix B.7) showing that as model size increases, so does their self-adaptation ability. He compared this to students improving their study techniques over time — larger models are simply better at generating useful self-edits.&lt;/p&gt;&lt;p&gt;When asked whether SEAL generalizes to new prompting styles, he confirmed it does, citing Table 10 in the paper. However, he also acknowledged that the team has not yet tested SEAL’s ability to transfer across entirely new domains or model architectures. &lt;/p&gt;&lt;p&gt;“SEAL is an initial work showcasing the possibilities,” he said. “But it requires much more testing.” He added that generalization may improve as SEAL is trained on a broader distribution of tasks.&lt;/p&gt;&lt;p&gt;Interestingly, the team found that only a few reinforcement learning steps already led to measurable performance gains. “This is exciting,” Jyo noted, “because it means that with more compute, we could hopefully get even more improvements.” He suggested future experiments could explore more advanced reinforcement learning methods beyond ReSTEM, such as Group Relative Policy Optimization (GRPO).&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Toward More Adaptive and Agentic Models&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;SEAL represents a step toward models that can autonomously improve over time, both by integrating new knowledge and by reconfiguring how they learn. The authors envision future extensions where SEAL could assist in self-pretraining, continual learning, and the development of agentic systems — models that interact with evolving environments and adapt incrementally.&lt;/p&gt;&lt;p&gt;In such settings, a model could use SEAL to synthesize weight updates after each interaction, gradually internalizing behaviors or insights. This could reduce the need for repeated supervision and manual intervention, particularly in data-constrained or specialized domains.&lt;/p&gt;&lt;p&gt;As public web text becomes saturated and further scaling of LLMs becomes bottlenecked by data availability, self-directed approaches like SEAL could play a critical role in pushing the boundaries of what LLMs can achieve.&lt;/p&gt;&lt;p&gt;You can access the SEAL project, including code and further documentation, at: &lt;a href="https://jyopari.github.io/posts/seal"&gt;https://jyopari.github.io/posts/seal&lt;/a&gt;&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;Researchers at the Massachusetts Institute of Technology (MIT) are gaining renewed attention for developing and &lt;a href="https://github.com/Continual-Intelligence/SEAL/blob/main/LICENSE"&gt;open sourcing&lt;/a&gt; a technique that allows large language models (LLMs) — like those underpinning ChatGPT and most modern AI chatbots — to improve themselves by generating synthetic data to fine-tune upon. &lt;/p&gt;&lt;p&gt;The technique, known as SEAL (Self-Adapting LLMs), was first described in a paper published back in June and &lt;a href="https://venturebeat.com/ai/beyond-static-ai-mits-new-framework-lets-models-teach-themselves"&gt;covered by VentureBeat at the time.&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A significantly expanded and &lt;a href="https://arxiv.org/pdf/2506.10943"&gt;updated version of the paper was released last month&lt;/a&gt;, as well as &lt;a href="https://github.com/Continual-Intelligence/SEAL"&gt;open source code posted on Github&lt;/a&gt; (under an MIT License, allowing for commercial and enterprise usage), and is making new waves among AI power users on the social network X this week.&lt;/p&gt;&lt;p&gt;SEAL allows LLMs to autonomously generate and apply their own fine-tuning strategies. Unlike conventional models that rely on fixed external data and human-crafted optimization pipelines, SEAL enables models to evolve by producing their own synthetic training data and corresponding optimization directives.&lt;/p&gt;&lt;p&gt;The development comes from a team affiliated with MIT’s Improbable AI Lab, including Adam Zweiger, Jyothish Pari, Han Guo, Ekin Akyürek, Yoon Kim, and Pulkit Agrawal. Their research was recently presented at the 39th Conference on Neural Information Processing Systems (NeurIPS 2025).&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Background: From “Beyond Static AI” to Self-Adaptive Systems&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Earlier this year, VentureBeat first reported on SEAL as an early-stage framework that allowed language models to generate and train on their own synthetic data — a potential remedy for the stagnation of pretrained models once deployed. &lt;/p&gt;&lt;p&gt;At that stage, SEAL was framed as a proof-of-concept that could let enterprise AI agents continuously learn in dynamic environments without manual retraining.&lt;/p&gt;&lt;p&gt;Since then, the research has advanced considerably. The new version expands on the prior framework by demonstrating that SEAL’s self-adaptation ability scales with model size, integrates reinforcement learning more effectively to reduce catastrophic forgetting, and formalizes SEAL’s dual-loop structure (inner supervised fine-tuning and outer reinforcement optimization) for reproducibility. &lt;/p&gt;&lt;p&gt;The updated paper also introduces evaluations across different prompting formats, improved stability during learning cycles, and a discussion of practical deployment challenges at inference time.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Addressing the Limitations of Static Models&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;While LLMs have demonstrated remarkable capabilities in text generation and understanding, their adaptation to new tasks or knowledge is often manual, brittle, or dependent on context. &lt;/p&gt;&lt;p&gt;SEAL challenges this status quo by equipping models with the ability to generate what the authors call “self-edits” — natural language outputs that specify how the model should update its weights.&lt;/p&gt;&lt;p&gt;These self-edits may take the form of reformulated information, logical implications, or tool configurations for augmentation and training. Once generated, the model fine-tunes itself based on these edits. The process is guided by reinforcement learning, where the reward signal comes from improved performance on a downstream task.&lt;/p&gt;&lt;p&gt;The design mimics how human learners might rephrase or reorganize study materials to better internalize information. This restructuring of knowledge before assimilation serves as a key advantage over models that passively consume new data “as-is.”&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Performance Across Tasks&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;SEAL has been tested across two main domains: knowledge incorporation and few-shot learning.&lt;/p&gt;&lt;p&gt;In the knowledge incorporation setting, the researchers evaluated how well a model could internalize new factual content from passages similar to those in the SQuAD dataset, a benchmark reading comprehension dataset introduced by Stanford University in 2016, consisting of over 100,000 crowd-sourced question–answer pairs based on Wikipedia articles (Rajpurkar et al., 2016). &lt;/p&gt;&lt;p&gt;Rather than fine-tuning directly on passage text, &lt;b&gt;the model generated synthetic implications of the passage&lt;/b&gt; and then fine-tuned on them. &lt;/p&gt;&lt;p&gt;After two rounds of reinforcement learning, the model improved question-answering accuracy from 33.5% to 47.0% on a no-context version of SQuAD — surpassing results obtained using synthetic data generated by GPT-4.1.&lt;/p&gt;&lt;p&gt;In the few-shot learning setting, SEAL was evaluated using a subset of the ARC benchmark, where tasks require reasoning from only a few examples. Here, SEAL generated self-edits specifying data augmentations and hyperparameters. &lt;/p&gt;&lt;p&gt;After reinforcement learning,&lt;b&gt; the success rate in correctly solving held-out tasks jumped to 72.5%, up from 20% using self-edits generated without reinforcement learning. &lt;/b&gt;Models that relied solely on in-context learning without any adaptation scored 0%.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Technical Framework&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;SEAL operates using a two-loop structure: an inner loop performs supervised fine-tuning based on the self-edit, while an outer loop uses reinforcement learning to refine the policy that generates those self-edits.&lt;/p&gt;&lt;p&gt;The reinforcement learning algorithm used is based on ReSTEM, which combines sampling with filtered behavior cloning. During training, only self-edits that lead to performance improvements are reinforced. This approach effectively teaches the model which kinds of edits are most beneficial for learning.&lt;/p&gt;&lt;p&gt;For efficiency, SEAL applies LoRA-based fine-tuning rather than full parameter updates, enabling rapid experimentation and low-cost adaptation.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Strengths and Limitations&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The researchers report that SEAL can produce high-utility training data with minimal supervision, outperforming even large external models like GPT-4.1 in specific tasks. &lt;/p&gt;&lt;p&gt;They also demonstrate that SEAL generalizes beyond its original setup: it continues to perform well when scaling from single-pass updates to multi-document continued pretraining scenarios.&lt;/p&gt;&lt;p&gt;However, the framework is not without limitations. One issue is catastrophic forgetting, where updates to incorporate new information can degrade performance on previously learned tasks. &lt;/p&gt;&lt;p&gt;In response to this concern, co-author Jyo Pari told VentureBeat via email that reinforcement learning (RL) appears to mitigate forgetting more effectively than standard supervised fine-tuning (SFT), citing a recent paper on the topic. He added that combining this insight with SEAL could lead to new variants where SEAL learns not just training data, but reward functions.&lt;/p&gt;&lt;p&gt;Another challenge is computational overhead: evaluating each self-edit requires fine-tuning and performance testing, which can take 30–45 seconds per edit — significantly more than standard reinforcement learning tasks. &lt;/p&gt;&lt;p&gt;As Jyo explained, “Training SEAL is non-trivial because it requires 2 loops of optimization, an outer RL one and an inner SFT one. At inference time, updating model weights will also require new systems infrastructure.” He emphasized the need for future research into deployment systems as a critical path to making SEAL practical.&lt;/p&gt;&lt;p&gt;Additionally, SEAL’s current design assumes the presence of paired tasks and reference answers for every context, limiting its direct applicability to unlabeled corpora. However, Jyo clarified that as long as there is a downstream task with a computable reward, SEAL can be trained to adapt accordingly—even in safety-critical domains. In principle, a SEAL-trained model could learn to avoid training on harmful or malicious inputs if guided by the appropriate reward signal.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;AI Community Reactions&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The AI research and builder community has reacted with a mix of excitement and speculation to the SEAL paper. On X, formerly Twitter, several prominent AI-focused accounts weighed in on the potential impact.&lt;/p&gt;&lt;p&gt;User &lt;a href="https://x.com/VraserX/status/1977270686285459482"&gt;@VraserX&lt;/a&gt;, a self-described educator and AI enthusiast, called SEAL “the birth of continuous self-learning AI” and predicted that models like OpenAI&amp;#x27;s GPT-6 could adopt similar architecture. &lt;/p&gt;&lt;p&gt;In their words, SEAL represents “the end of the frozen-weights era,” ushering in systems that evolve as the world around them changes. &lt;/p&gt;&lt;p&gt;They highlighted SEAL&amp;#x27;s ability to form persistent memories, repair knowledge, and learn from real-time data, comparing it to a foundational step toward models that don’t just use information but absorb it.&lt;/p&gt;&lt;p&gt;Meanwhile, &lt;a href="https://x.com/alex_prompter/status/1977633849879527877"&gt;@alex_prompter&lt;/a&gt;, co-founder of an AI-powered marketing venture, framed SEAL as a leap toward models that literally rewrite themselves. “MIT just built an AI that can rewrite its own code to get smarter,” he wrote. &lt;b&gt;Citing the paper’s key results — a 40% boost in factual recall and outperforming GPT-4.1 using self-generated data &lt;/b&gt;— he described the findings as confirmation that “LLMs that finetune themselves are no longer sci-fi.”&lt;/p&gt;&lt;p&gt;The enthusiasm reflects a broader appetite in the AI space for models that can evolve without constant retraining or human oversight — particularly in rapidly changing domains or personalized use cases.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Future Directions and Open Questions&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;In response to questions about scaling SEAL to larger models and tasks, Jyo pointed to experiments (Appendix B.7) showing that as model size increases, so does their self-adaptation ability. He compared this to students improving their study techniques over time — larger models are simply better at generating useful self-edits.&lt;/p&gt;&lt;p&gt;When asked whether SEAL generalizes to new prompting styles, he confirmed it does, citing Table 10 in the paper. However, he also acknowledged that the team has not yet tested SEAL’s ability to transfer across entirely new domains or model architectures. &lt;/p&gt;&lt;p&gt;“SEAL is an initial work showcasing the possibilities,” he said. “But it requires much more testing.” He added that generalization may improve as SEAL is trained on a broader distribution of tasks.&lt;/p&gt;&lt;p&gt;Interestingly, the team found that only a few reinforcement learning steps already led to measurable performance gains. “This is exciting,” Jyo noted, “because it means that with more compute, we could hopefully get even more improvements.” He suggested future experiments could explore more advanced reinforcement learning methods beyond ReSTEM, such as Group Relative Policy Optimization (GRPO).&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Toward More Adaptive and Agentic Models&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;SEAL represents a step toward models that can autonomously improve over time, both by integrating new knowledge and by reconfiguring how they learn. The authors envision future extensions where SEAL could assist in self-pretraining, continual learning, and the development of agentic systems — models that interact with evolving environments and adapt incrementally.&lt;/p&gt;&lt;p&gt;In such settings, a model could use SEAL to synthesize weight updates after each interaction, gradually internalizing behaviors or insights. This could reduce the need for repeated supervision and manual intervention, particularly in data-constrained or specialized domains.&lt;/p&gt;&lt;p&gt;As public web text becomes saturated and further scaling of LLMs becomes bottlenecked by data availability, self-directed approaches like SEAL could play a critical role in pushing the boundaries of what LLMs can achieve.&lt;/p&gt;&lt;p&gt;You can access the SEAL project, including code and further documentation, at: &lt;a href="https://jyopari.github.io/posts/seal"&gt;https://jyopari.github.io/posts/seal&lt;/a&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/self-improving-language-models-are-becoming-reality-with-mits-updated-seal</guid><pubDate>Mon, 13 Oct 2025 22:51:00 +0000</pubDate></item><item><title>[NEW] Elon Musk Gets Just-Launched NVIDIA DGX Spark: Petaflop AI Supercomputer Lands at SpaceX (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/live-dgx-spark-delivery/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;The next AI revolution starts where rockets launch. NVIDIA DGX Spark’s first stop: Starbase, Texas.&lt;/p&gt;
&lt;p&gt;NVIDIA founder and CEO Jensen Huang hand-delivered the world’s smallest AI supercomputer — a petaflop of performance in a box that fits on a desk — to Elon Musk.&lt;/p&gt;
&lt;p&gt;Nine years ago, NVIDIA bet on the future of AI with NVIDIA DGX-1. Today, that bet goes beyond the data center with the handoff to Musk coming amid the 11th test of SpaceX’s Starship, the world’s most powerful launch vehicle.&lt;/p&gt;
&lt;p&gt;DGX Spark packs 128GB of unified memory and is powerful enough to run models with 200 billion parameters locally.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-full wp-image-85778" height="720" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/L1031489-retouch.jpg" width="1280" /&gt;&lt;/p&gt;
&lt;p&gt;Built for developers, researchers and creators who want supercomputer-class performance that’s ready to grab and go.&lt;/p&gt;
&lt;p&gt;From robotics labs to creative studios, DGX Sparks are landing where ideas happen… putting petaflop AI within arm’s reach of everyone.&lt;/p&gt;
&lt;p&gt;This blog will be updated as DGX Spark systems land from Ollama in Palo Alto to Arizona State’s robotics lab, from Refik Anadol’s studio to the hands of Jo Mardall at Zipline. Each delivery is a new chapter in the story of AI.&lt;/p&gt;
&lt;p&gt;DGX Spark will be generally available starting Wednesday, Oct. 15, on NVIDIA.com and through partners worldwide.&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;The next AI revolution starts where rockets launch. NVIDIA DGX Spark’s first stop: Starbase, Texas.&lt;/p&gt;
&lt;p&gt;NVIDIA founder and CEO Jensen Huang hand-delivered the world’s smallest AI supercomputer — a petaflop of performance in a box that fits on a desk — to Elon Musk.&lt;/p&gt;
&lt;p&gt;Nine years ago, NVIDIA bet on the future of AI with NVIDIA DGX-1. Today, that bet goes beyond the data center with the handoff to Musk coming amid the 11th test of SpaceX’s Starship, the world’s most powerful launch vehicle.&lt;/p&gt;
&lt;p&gt;DGX Spark packs 128GB of unified memory and is powerful enough to run models with 200 billion parameters locally.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-full wp-image-85778" height="720" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/L1031489-retouch.jpg" width="1280" /&gt;&lt;/p&gt;
&lt;p&gt;Built for developers, researchers and creators who want supercomputer-class performance that’s ready to grab and go.&lt;/p&gt;
&lt;p&gt;From robotics labs to creative studios, DGX Sparks are landing where ideas happen… putting petaflop AI within arm’s reach of everyone.&lt;/p&gt;
&lt;p&gt;This blog will be updated as DGX Spark systems land from Ollama in Palo Alto to Arizona State’s robotics lab, from Refik Anadol’s studio to the hands of Jo Mardall at Zipline. Each delivery is a new chapter in the story of AI.&lt;/p&gt;
&lt;p&gt;DGX Spark will be generally available starting Wednesday, Oct. 15, on NVIDIA.com and through partners worldwide.&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/live-dgx-spark-delivery/</guid><pubDate>Tue, 14 Oct 2025 00:31:39 +0000</pubDate></item></channel></rss>