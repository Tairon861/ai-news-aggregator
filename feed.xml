<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 18 Nov 2025 18:33:27 +0000</lastBuildDate><item><title> ()</title><link>https://deepmind.com/blog/feed/basic/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://deepmind.com/blog/feed/basic/</guid></item><item><title>SC25 showcases the next phase of Dell and NVIDIA’s AI partnership (AI News)</title><link>https://www.artificialintelligence-news.com/news/sc25-showcases-the-next-phase-of-dell-and-nvidia-ai-partnership/</link><description>&lt;p&gt;At SC25, Dell Technologies and NVIDIA introduced new updates to their joint AI platform, aiming to make it easier for organisations to run a wider range of AI workloads, from older models to newer agent-style systems.&lt;/p&gt;&lt;p&gt;As more companies scale their AI plans, many run into the same issues. They need to manage a growing mix of hardware and software, keep control of their data, and make sure their systems can grow over time. Recent research shows that most organisations feel safer working with a trusted partner when adopting new technology, and many see more value when AI can operate closer to their own data.&lt;/p&gt;&lt;p&gt;The Dell AI Factory with NVIDIA is built around that idea. It combines Dell’s full stack of infrastructure with NVIDIA’s AI tools, supported by Dell’s professional services team. The goal is to help companies move from ideas to real results while keeping technical complexity in check.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-faster-deployment-through-integrated-platforms"&gt;Faster deployment through integrated platforms&lt;/h3&gt;&lt;p&gt;Dell is expanding its storage and AI capabilities to help organisations automate setup, improve performance, and run real-time AI tasks with more consistency. ObjectScale and PowerScale, the storage engines behind the Dell AI Data Platform, now work with the NVIDIA NIXL library from NVIDIA Dynamo. This integration supports scalable KV Cache storage and sharing, enabling a one-second Time to First Token at a 131K-token context window, while helping reduce costs and ease pressure on GPU memory.&lt;/p&gt;&lt;p&gt;The Dell AI Factory with NVIDIA also adds support for Dell PowerEdge XE7740 and XE7745 systems equipped with the NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs and NVIDIA Hopper GPUs. According to Dell, these systems give organisations more room to run larger multimodal models, agent-style workloads, training tasks, and enterprise inferencing with stronger performance.&lt;/p&gt;&lt;p&gt;Dell says the addition of the Dell Automation Platform is meant to remove guesswork by delivering tuned and validated deployments through a secure setup. The platform aims to produce repeatable results and give teams a clearer path to building AI workflows. Alongside this, software tools such as the AI code assistant with Tabnine and the agentic AI platform with Cohere North are becoming automated, helping teams move workloads into production faster and keep operations manageable as they scale.&lt;/p&gt;&lt;p&gt;Beyond core data-centre systems, Dell’s AI PC ecosystem now supports devices with NVIDIA RTX Blackwell GPUs and NVIDIA RTX Ada GPUs, giving organisations more hardware options across Dell laptops and desktops. Dell Professional Services is also offering interactive pilots that use a customer’s own data to test AI ideas before large investments. These pilots focus on clear metrics and outcomes so teams can judge business value with more certainty.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-next-generation-infrastructure-for-stronger-ai-performance"&gt;Next-generation infrastructure for stronger AI performance&lt;/h3&gt;&lt;p&gt;Dell is updating its infrastructure portfolio to support more complex AI and HPC workloads, with an emphasis on performance, scale, and easier management. The Dell PowerEdge XE8712, arriving next month, supports up to 144 NVIDIA Blackwell GPUs in a standard rack. This makes rack-scale AI and HPC more accessible, backed by unified monitoring and automation through iDRAC, OpenManage Enterprise, and the Integrated Rack Controller.&lt;/p&gt;&lt;p&gt;Enterprise SONiC Distribution by Dell Technologies now supports NVIDIA Spectrum-X platforms along with NVIDIA’s Cumulus OS. This helps organisations build open, standards-based AI networks that can operate across different vendors. The latest SmartFabric Manager release also extends support to Dell’s Enterprise SONiC on NVIDIA Spectrum-X platforms, aiming to reduce deployment time and setup errors through guided automation.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-more-choice-through-an-expanded-ai-ecosystem"&gt;More choice through an expanded AI ecosystem&lt;/h3&gt;&lt;p&gt;Organisations continue to adjust their AI budgets and plans, and many want flexibility in the tools they choose. Red Hat OpenShift for the Dell AI Factory with NVIDIA is now validated on more Dell PowerEdge systems, giving teams more ways to run AI workloads at scale.&lt;/p&gt;&lt;p&gt;Support now includes both the Dell PowerEdge R760xa and the Dell PowerEdge XE9680 with NVIDIA H100 and H200 Tensor Core GPUs. This pairing brings together Red Hat’s controls and governance tools with Dell’s secure infrastructure, offering a clearer path for companies that need to scale AI.&lt;/p&gt;&lt;p&gt;Dell executives say the updates are meant to help organisations move from small pilots to real deployment. Jeff Clarke, vice chairman and chief operating officer at Dell Technologies, said the Dell AI Factory with NVIDIA addresses a core challenge for many teams: “how to move from AI pilots to production without rebuilding their infrastructure.” He added that Dell has “done the integration work so customers don’t have to,” which he believes will help organisations deploy and scale with more confidence.&lt;/p&gt;&lt;p&gt;NVIDIA sees the shift as part of a broader change in how companies use AI. Justin Boitano, vice president of Enterprise AI products, described the moment as one where enterprise AI is moving from experimentation to transformation, advancing at a speed that is “redefining how businesses operate.” He said Dell and NVIDIA aim to support this transition with a unified platform that brings together infrastructure, automation, and data tools to help organisations “deploy AI at scale and realise measurable impact.”&lt;/p&gt;&lt;p&gt;Industry analysts see similar demand for integrated systems. Ashish Nadkarni, group vice president and general manager for Infrastructure Systems, Platforms and Technologies at IDC, said many teams want AI-ready systems that are powerful but also easier to run. He noted that the combination of Dell’s AI portfolio with NVIDIA’s technology represents “a significant step forward in delivering enterprise-ready AI.”&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image by Dell Technologies)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: 10% of Nvidia’s cost: Why Tesla-Intel chip partnership demands attention&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-110608" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/image-7.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;At SC25, Dell Technologies and NVIDIA introduced new updates to their joint AI platform, aiming to make it easier for organisations to run a wider range of AI workloads, from older models to newer agent-style systems.&lt;/p&gt;&lt;p&gt;As more companies scale their AI plans, many run into the same issues. They need to manage a growing mix of hardware and software, keep control of their data, and make sure their systems can grow over time. Recent research shows that most organisations feel safer working with a trusted partner when adopting new technology, and many see more value when AI can operate closer to their own data.&lt;/p&gt;&lt;p&gt;The Dell AI Factory with NVIDIA is built around that idea. It combines Dell’s full stack of infrastructure with NVIDIA’s AI tools, supported by Dell’s professional services team. The goal is to help companies move from ideas to real results while keeping technical complexity in check.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-faster-deployment-through-integrated-platforms"&gt;Faster deployment through integrated platforms&lt;/h3&gt;&lt;p&gt;Dell is expanding its storage and AI capabilities to help organisations automate setup, improve performance, and run real-time AI tasks with more consistency. ObjectScale and PowerScale, the storage engines behind the Dell AI Data Platform, now work with the NVIDIA NIXL library from NVIDIA Dynamo. This integration supports scalable KV Cache storage and sharing, enabling a one-second Time to First Token at a 131K-token context window, while helping reduce costs and ease pressure on GPU memory.&lt;/p&gt;&lt;p&gt;The Dell AI Factory with NVIDIA also adds support for Dell PowerEdge XE7740 and XE7745 systems equipped with the NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs and NVIDIA Hopper GPUs. According to Dell, these systems give organisations more room to run larger multimodal models, agent-style workloads, training tasks, and enterprise inferencing with stronger performance.&lt;/p&gt;&lt;p&gt;Dell says the addition of the Dell Automation Platform is meant to remove guesswork by delivering tuned and validated deployments through a secure setup. The platform aims to produce repeatable results and give teams a clearer path to building AI workflows. Alongside this, software tools such as the AI code assistant with Tabnine and the agentic AI platform with Cohere North are becoming automated, helping teams move workloads into production faster and keep operations manageable as they scale.&lt;/p&gt;&lt;p&gt;Beyond core data-centre systems, Dell’s AI PC ecosystem now supports devices with NVIDIA RTX Blackwell GPUs and NVIDIA RTX Ada GPUs, giving organisations more hardware options across Dell laptops and desktops. Dell Professional Services is also offering interactive pilots that use a customer’s own data to test AI ideas before large investments. These pilots focus on clear metrics and outcomes so teams can judge business value with more certainty.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-next-generation-infrastructure-for-stronger-ai-performance"&gt;Next-generation infrastructure for stronger AI performance&lt;/h3&gt;&lt;p&gt;Dell is updating its infrastructure portfolio to support more complex AI and HPC workloads, with an emphasis on performance, scale, and easier management. The Dell PowerEdge XE8712, arriving next month, supports up to 144 NVIDIA Blackwell GPUs in a standard rack. This makes rack-scale AI and HPC more accessible, backed by unified monitoring and automation through iDRAC, OpenManage Enterprise, and the Integrated Rack Controller.&lt;/p&gt;&lt;p&gt;Enterprise SONiC Distribution by Dell Technologies now supports NVIDIA Spectrum-X platforms along with NVIDIA’s Cumulus OS. This helps organisations build open, standards-based AI networks that can operate across different vendors. The latest SmartFabric Manager release also extends support to Dell’s Enterprise SONiC on NVIDIA Spectrum-X platforms, aiming to reduce deployment time and setup errors through guided automation.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-more-choice-through-an-expanded-ai-ecosystem"&gt;More choice through an expanded AI ecosystem&lt;/h3&gt;&lt;p&gt;Organisations continue to adjust their AI budgets and plans, and many want flexibility in the tools they choose. Red Hat OpenShift for the Dell AI Factory with NVIDIA is now validated on more Dell PowerEdge systems, giving teams more ways to run AI workloads at scale.&lt;/p&gt;&lt;p&gt;Support now includes both the Dell PowerEdge R760xa and the Dell PowerEdge XE9680 with NVIDIA H100 and H200 Tensor Core GPUs. This pairing brings together Red Hat’s controls and governance tools with Dell’s secure infrastructure, offering a clearer path for companies that need to scale AI.&lt;/p&gt;&lt;p&gt;Dell executives say the updates are meant to help organisations move from small pilots to real deployment. Jeff Clarke, vice chairman and chief operating officer at Dell Technologies, said the Dell AI Factory with NVIDIA addresses a core challenge for many teams: “how to move from AI pilots to production without rebuilding their infrastructure.” He added that Dell has “done the integration work so customers don’t have to,” which he believes will help organisations deploy and scale with more confidence.&lt;/p&gt;&lt;p&gt;NVIDIA sees the shift as part of a broader change in how companies use AI. Justin Boitano, vice president of Enterprise AI products, described the moment as one where enterprise AI is moving from experimentation to transformation, advancing at a speed that is “redefining how businesses operate.” He said Dell and NVIDIA aim to support this transition with a unified platform that brings together infrastructure, automation, and data tools to help organisations “deploy AI at scale and realise measurable impact.”&lt;/p&gt;&lt;p&gt;Industry analysts see similar demand for integrated systems. Ashish Nadkarni, group vice president and general manager for Infrastructure Systems, Platforms and Technologies at IDC, said many teams want AI-ready systems that are powerful but also easier to run. He noted that the combination of Dell’s AI portfolio with NVIDIA’s technology represents “a significant step forward in delivering enterprise-ready AI.”&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image by Dell Technologies)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: 10% of Nvidia’s cost: Why Tesla-Intel chip partnership demands attention&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-110608" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/image-7.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/sc25-showcases-the-next-phase-of-dell-and-nvidia-ai-partnership/</guid><pubDate>Tue, 18 Nov 2025 09:00:00 +0000</pubDate></item><item><title>Databricks reportedly in talks to raise funding at a $130B+ valuation (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/18/databricks-reportedly-in-talks-to-raise-funding-at-a-130b-valuation/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/06/GettyImages-2157160096.jpg?resize=1200,801" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Data intelligence company Databricks is reportedly already in talks to raise fresh capital, just a few months after its last fundraise.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Databricks is holding conversations to raise a funding round that values the company at a minimum of $130 billion, according to reporting from The Information. The company hasn’t signed a term sheet yet, the report added.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That would prove a valuation bump of at least 30% over the $100 billion price tag Databricks achieved in its $1 billion Series J funding round in August.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the time, Databricks co-founder and CEO Ali Ghodsi told TechCrunch that the company raised the round to fund two specific projects: a database for AI agents and its AI agent platform.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The database market is $105 billion of TAM [total addressable market], of revenue, sitting there, kind of unaffected in the last 40 years,” Ghodsi told TechCrunch at the time. “Here’s the interesting statistic nobody’s paying attention to: A year ago, we saw in the data that 30% of the databases were not created by humans. For the first time, they were created by AI agents. And this year, the statistic is 80%.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Databricks bought open source database startup Neon for $1 billion in May, which was one of the first transactions that kicked off a wave of consolidation in the database space.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Databricks did not immediately respond to a request for confirmation and more information.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/06/GettyImages-2157160096.jpg?resize=1200,801" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Data intelligence company Databricks is reportedly already in talks to raise fresh capital, just a few months after its last fundraise.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Databricks is holding conversations to raise a funding round that values the company at a minimum of $130 billion, according to reporting from The Information. The company hasn’t signed a term sheet yet, the report added.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That would prove a valuation bump of at least 30% over the $100 billion price tag Databricks achieved in its $1 billion Series J funding round in August.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the time, Databricks co-founder and CEO Ali Ghodsi told TechCrunch that the company raised the round to fund two specific projects: a database for AI agents and its AI agent platform.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The database market is $105 billion of TAM [total addressable market], of revenue, sitting there, kind of unaffected in the last 40 years,” Ghodsi told TechCrunch at the time. “Here’s the interesting statistic nobody’s paying attention to: A year ago, we saw in the data that 30% of the databases were not created by humans. For the first time, they were created by AI agents. And this year, the statistic is 80%.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Databricks bought open source database startup Neon for $1 billion in May, which was one of the first transactions that kicked off a wave of consolidation in the database space.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Databricks did not immediately respond to a request for confirmation and more information.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/18/databricks-reportedly-in-talks-to-raise-funding-at-a-130b-valuation/</guid><pubDate>Tue, 18 Nov 2025 11:31:44 +0000</pubDate></item><item><title>Bain &amp; Company issues AI Guide for CEOs, opens Singapore hub (AI News)</title><link>https://www.artificialintelligence-news.com/news/bain-company-issues-ai-guide-for-ceos-and-opens-singapore-hub/</link><description>&lt;p&gt;A new Bain &amp;amp; Company report says many organisations in Southeast Asia are still stuck in early product testing because they treat AI as a set of tools rather than a change in how the business works. In &lt;em&gt;The Southeast Asia CEO’s Guide to AI Transformation&lt;/em&gt;, the authors say leaders should first look at how AI could reshape their industry and revenue plans, then put money into areas where they expect clear and measurable results.&lt;/p&gt;&lt;p&gt;The region’s mix of cultures, income levels, and market sizes makes AI adoption harder than in places with more uniform conditions. People shop and behave differently between the different countries of the region, wages tend to be still low, and many firms don’t have the scale to run long and costly trials. These factors mean simple efficiency gains rarely deliver strong returns. Real gains come when AI is used to rethink how the business runs, make decisions faster, or increase capacity without growing the team, the Guide states.&lt;/p&gt;&lt;p&gt;Bain’s analysis shows that wages in Southeast Asia are about 7% of US levels, which limits how much companies can save from labour cuts. The report also notes that only 40% of the region’s market value comes from large firms, compared with 60% in India. With fewer big firms able to absorb early AI costs, leaders need to aim for speed, scale, and new processes instead of relying on cost savings alone.&lt;/p&gt;&lt;h3&gt;How AI is helping today&lt;/h3&gt;&lt;p&gt;Some organisations in the region are already seeing clear gains by linking their AI plans to business goals. The Guide highlights early moves like using AI to shorten product launch times or reduce supply chain issues, so opening new chances for revenue. A factory might use predictive models to reduce machine downtime and lift output, or a financial institution could use LLMs to support compliance work.&lt;/p&gt;&lt;p&gt;Bain senior partner Aadarsh Baijal says impact depends on how leaders think about their market. He believes many still see AI “as a rollout of software rather than a redesign of how the business competes.” When leaders understand how AI changes demand, pricing, operations, or customer needs, they can decide where to focus their efforts.&lt;/p&gt;&lt;h3&gt;What the guide says about data, culture, and people in AI&lt;/h3&gt;&lt;p&gt;The Guide stresses that AI transformation relies on people, habits, and skills, not only technology. Many organisations think scaling AI is a hiring problem, but Bain argues that the talent often already exists in the business. The real issue is getting teams to work together and helping staff understand how to use AI in their jobs.&lt;/p&gt;&lt;p&gt;The authors describe two groups involved in successful change. The “Lab” is made up of technical teams who rebuild processes and create the first versions of new tools. The “Crowd” includes employees in the business who need enough AI awareness to use those tools day to day. Without both groups, projects stall.&lt;/p&gt;&lt;p&gt;Senior partner Mohan Jayaraman says the strongest results appear when existing teams lead the work. In his view, impact increases when companies match small expert groups with wider training so new systems become part of normal workflows rather than one-off trials.&lt;/p&gt;&lt;p&gt;Leaders also need to fix ongoing issues like data quality, how data is tracked, governance, and links to current systems. They also need to decide how their AI plans connect with existing technologies. Without this groundwork, early gains are hard to repeat at scale.&lt;/p&gt;&lt;h3&gt;A regional push to support enterprise AI&lt;/h3&gt;&lt;p&gt;Bain is setting up an AI Innovation Hub in Singapore with support from the Singapore Economic Development Board (EDB). The hub’s goal is to help companies move beyond trials by building AI systems that can run at scale. It will work in advanced manufacturing, energy and resources, financial services, healthcare, and consumer goods.&lt;/p&gt;&lt;p&gt;The hub sits in a growing AI community in Singapore, which has more than a thousand startups and is expected to generate about S$198.3 billion in economic value from AI by 2030. Its work will cover production-ready systems like predictive maintenance for factories, AI support for regulatory tasks in finance, and personalisation tools for retail. It will also help companies build internal teams and engineering skills so they can run AI programmes on their own.&lt;/p&gt;&lt;p&gt;As competition in Southeast Asia increases, firms that treat AI as a shift in how they operate – a central theme in Bain’s AI guide – will be better positioned to turn pilots into long-term results.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Is AI in a bubble? Succeed despite a market correction&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;A new Bain &amp;amp; Company report says many organisations in Southeast Asia are still stuck in early product testing because they treat AI as a set of tools rather than a change in how the business works. In &lt;em&gt;The Southeast Asia CEO’s Guide to AI Transformation&lt;/em&gt;, the authors say leaders should first look at how AI could reshape their industry and revenue plans, then put money into areas where they expect clear and measurable results.&lt;/p&gt;&lt;p&gt;The region’s mix of cultures, income levels, and market sizes makes AI adoption harder than in places with more uniform conditions. People shop and behave differently between the different countries of the region, wages tend to be still low, and many firms don’t have the scale to run long and costly trials. These factors mean simple efficiency gains rarely deliver strong returns. Real gains come when AI is used to rethink how the business runs, make decisions faster, or increase capacity without growing the team, the Guide states.&lt;/p&gt;&lt;p&gt;Bain’s analysis shows that wages in Southeast Asia are about 7% of US levels, which limits how much companies can save from labour cuts. The report also notes that only 40% of the region’s market value comes from large firms, compared with 60% in India. With fewer big firms able to absorb early AI costs, leaders need to aim for speed, scale, and new processes instead of relying on cost savings alone.&lt;/p&gt;&lt;h3&gt;How AI is helping today&lt;/h3&gt;&lt;p&gt;Some organisations in the region are already seeing clear gains by linking their AI plans to business goals. The Guide highlights early moves like using AI to shorten product launch times or reduce supply chain issues, so opening new chances for revenue. A factory might use predictive models to reduce machine downtime and lift output, or a financial institution could use LLMs to support compliance work.&lt;/p&gt;&lt;p&gt;Bain senior partner Aadarsh Baijal says impact depends on how leaders think about their market. He believes many still see AI “as a rollout of software rather than a redesign of how the business competes.” When leaders understand how AI changes demand, pricing, operations, or customer needs, they can decide where to focus their efforts.&lt;/p&gt;&lt;h3&gt;What the guide says about data, culture, and people in AI&lt;/h3&gt;&lt;p&gt;The Guide stresses that AI transformation relies on people, habits, and skills, not only technology. Many organisations think scaling AI is a hiring problem, but Bain argues that the talent often already exists in the business. The real issue is getting teams to work together and helping staff understand how to use AI in their jobs.&lt;/p&gt;&lt;p&gt;The authors describe two groups involved in successful change. The “Lab” is made up of technical teams who rebuild processes and create the first versions of new tools. The “Crowd” includes employees in the business who need enough AI awareness to use those tools day to day. Without both groups, projects stall.&lt;/p&gt;&lt;p&gt;Senior partner Mohan Jayaraman says the strongest results appear when existing teams lead the work. In his view, impact increases when companies match small expert groups with wider training so new systems become part of normal workflows rather than one-off trials.&lt;/p&gt;&lt;p&gt;Leaders also need to fix ongoing issues like data quality, how data is tracked, governance, and links to current systems. They also need to decide how their AI plans connect with existing technologies. Without this groundwork, early gains are hard to repeat at scale.&lt;/p&gt;&lt;h3&gt;A regional push to support enterprise AI&lt;/h3&gt;&lt;p&gt;Bain is setting up an AI Innovation Hub in Singapore with support from the Singapore Economic Development Board (EDB). The hub’s goal is to help companies move beyond trials by building AI systems that can run at scale. It will work in advanced manufacturing, energy and resources, financial services, healthcare, and consumer goods.&lt;/p&gt;&lt;p&gt;The hub sits in a growing AI community in Singapore, which has more than a thousand startups and is expected to generate about S$198.3 billion in economic value from AI by 2030. Its work will cover production-ready systems like predictive maintenance for factories, AI support for regulatory tasks in finance, and personalisation tools for retail. It will also help companies build internal teams and engineering skills so they can run AI programmes on their own.&lt;/p&gt;&lt;p&gt;As competition in Southeast Asia increases, firms that treat AI as a shift in how they operate – a central theme in Bain’s AI guide – will be better positioned to turn pilots into long-term results.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Is AI in a bubble? Succeed despite a market correction&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/bain-company-issues-ai-guide-for-ceos-and-opens-singapore-hub/</guid><pubDate>Tue, 18 Nov 2025 12:00:00 +0000</pubDate></item><item><title>[NEW] AI web search risks: Mitigating business data accuracy threats (AI News)</title><link>https://www.artificialintelligence-news.com/news/ai-web-search-risks-mitigating-business-data-accuracy-threats/</link><description>&lt;p&gt;Over half of us now use AI to search the web, yet the stubbornly low data accuracy of common tools creates new business risks.&lt;/p&gt;&lt;p&gt;While generative AI (GenAI) offers undeniable efficiency gains, a new investigation highlights a disparity between user trust and technical accuracy that poses specific risks to corporate compliance, legal standing, and financial planning.&lt;/p&gt;&lt;p&gt;For the C-suite, the adoption of these tools represents a classic ‘shadow IT’ challenge. According to a survey of 4,189 UK adults conducted in September 2025, around a third of users believe AI is already more important to them than standard web searching. If employees trust these tools for personal queries, they are almost certainly employing them for business research.&lt;/p&gt;&lt;p&gt;The investigation, conducted by Which?, suggests that unverified reliance on these platforms could be costly. Around half of AI users report trusting the information they receive to a ‘reasonable’ or ‘great’ extent. Yet, looking at the granularity of the responses provided by AI models, that trust is often misplaced.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-accuracy-gap-when-using-ai-to-search-the-web"&gt;The accuracy gap when using AI to search the web&lt;/h3&gt;&lt;p&gt;The study tested six major tools – ChatGPT, Google Gemini (both standard and ‘AI Overviews’), Microsoft Copilot, Meta AI, and Perplexity – across 40 common questions spanning finance, law, and consumer rights.&lt;/p&gt;&lt;p&gt;Perplexity achieved the highest total score at 71 percent, closely followed by Google Gemini AI Overviews at 70 percent. In contrast, Meta scored the lowest at 55 percent. ChatGPT, despite its widespread adoption, received a total score of 64 percent, making it the second-lowest performer among the tools tested. This disconnect between market dominance and reliable output underlines the danger of assuming popularity equals performance in the GenAI space.&lt;/p&gt;&lt;p&gt;However, the investigation revealed that all of these AI tools frequently misread information or provided incomplete advice that could pose serious business risks. For financial officers and legal departments, the nature of these errors is particularly concerning.&lt;/p&gt;&lt;p&gt;When asked how to invest a £25,000 annual ISA allowance, both ChatGPT and Copilot failed to identify a deliberate error in the prompt regarding the statutory limit. Instead of correcting the figure, they offered advice that potentially risked breaching HMRC rules.&lt;/p&gt;&lt;p&gt;While Gemini, Meta, and Perplexity successfully identified the error, the inconsistency across platforms necessitates a rigorous “human-in-the-loop” protocol for any business process involving AI to ensure accuracy.&lt;/p&gt;&lt;p&gt;For legal teams, the tendency of AI to generalise regional regulations when using it for web search presents a distinct business risk. The testing found it common for tools to misunderstand that legal statutes often differ between UK regions, such as Scotland versus England and Wales.&lt;/p&gt;&lt;p&gt;Furthermore, the investigation highlighted an ethical gap in how these models handle high-stakes queries. On legal and financial matters, the tools infrequently advised users to consult a registered professional. For example, when queried about a dispute with a builder, Gemini advised withholding payment; a tactic that experts noted could place a user in breach of contract and weaken their legal position.&lt;/p&gt;&lt;p&gt;This “overconfident advice” creates operational hazards. If an employee relies on an AI for preliminary compliance checks or contract review without verifying the jurisdiction or legal nuance, the organisation could face regulatory exposure.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-source-transparency-issues"&gt;Source transparency issues&lt;/h3&gt;&lt;p&gt;A primary concern for enterprise data governance is the lineage of information. The investigation found that AI search tools often bear a high responsibility to be transparent, yet frequently cited sources that were vague, non-existent, or have dubious accuracy, such as old forum threads. This opacity can lead to financial inefficiency.&lt;/p&gt;&lt;p&gt;In one test regarding tax codes, ChatGPT and Perplexity presented links to premium tax-refund companies rather than directing the user to the free official HMRC tool. These third-party services are often characterised by high fees.&lt;/p&gt;&lt;p&gt;In a business procurement context, such algorithmic bias from AI tools when using them for web search could lead to unnecessary vendor spend or engagement with service providers that pose a high risk due to not meeting corporate due diligence standards.&lt;/p&gt;&lt;p&gt;The major technology providers acknowledge these limitations, placing the burden of verification firmly on the user—and, by extension, the enterprise.&lt;/p&gt;&lt;p&gt;A Microsoft spokesperson emphasised that their tool acts as a synthesiser rather than an authoritative source. “Copilot answers questions by distilling information from multiple web sources into a single response,” the company noted, adding that they “encourage people to verify the accuracy of content.”&lt;/p&gt;&lt;p&gt;OpenAI, responding to the findings, said: “Improving accuracy is something the whole industry’s working on. We’re making good progress and our latest default model, GPT-5, is the smartest and most accurate we’ve built.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-mitigating-ai-business-risk-through-policy-and-workflow"&gt;Mitigating AI business risk through policy and workflow&lt;/h3&gt;&lt;p&gt;For business leaders, the path forward is not to ban AI tools – which often increases by driving usage further into the shadows – but to implement robust governance frameworks to ensure the accuracy of their output when bring used for web search:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Enforce specificity in prompts:&lt;/strong&gt; The investigation notes that AI is still learning to interpret prompts. Corporate training should emphasise that vague queries yield risky data. If an employee is researching regulations, they must specify the jurisdiction (e.g., “legal rules for England and Wales”) rather than assuming the tool will infer the context.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Mandate source verification:&lt;/strong&gt; Trusting a single output is operationally unsound. Employees must demand to see sources and check them manually. The study suggests that for high-risk topics, users should verify findings across multiple AI tools or “double source” the information. Tools like Google’s Gemini AI Overviews, which allow users to review presented web links directly, performed slightly better in scoring because they facilitated this verification process.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Operationalise the “second opinion”:&lt;/strong&gt; At this stage of technical maturity, GenAI outputs should be viewed as just one opinion among many. For complex issues involving finance, law, or medical data, AI lacks the ability to fully comprehend nuance. Enterprise policy must dictate that professional human advice remains the final arbiter for decisions with real-world consequences.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The AI tools are evolving and their web search accuracy is gradually improving, but as the investigation concludes, relying on them too much right now could prove costly. For the enterprise, the difference between a business efficiency gain from AI and a compliance failure risk lies in the verification process.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;How Levi Strauss is using AI for its DTC-first business model&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-110077" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-10.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Over half of us now use AI to search the web, yet the stubbornly low data accuracy of common tools creates new business risks.&lt;/p&gt;&lt;p&gt;While generative AI (GenAI) offers undeniable efficiency gains, a new investigation highlights a disparity between user trust and technical accuracy that poses specific risks to corporate compliance, legal standing, and financial planning.&lt;/p&gt;&lt;p&gt;For the C-suite, the adoption of these tools represents a classic ‘shadow IT’ challenge. According to a survey of 4,189 UK adults conducted in September 2025, around a third of users believe AI is already more important to them than standard web searching. If employees trust these tools for personal queries, they are almost certainly employing them for business research.&lt;/p&gt;&lt;p&gt;The investigation, conducted by Which?, suggests that unverified reliance on these platforms could be costly. Around half of AI users report trusting the information they receive to a ‘reasonable’ or ‘great’ extent. Yet, looking at the granularity of the responses provided by AI models, that trust is often misplaced.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-accuracy-gap-when-using-ai-to-search-the-web"&gt;The accuracy gap when using AI to search the web&lt;/h3&gt;&lt;p&gt;The study tested six major tools – ChatGPT, Google Gemini (both standard and ‘AI Overviews’), Microsoft Copilot, Meta AI, and Perplexity – across 40 common questions spanning finance, law, and consumer rights.&lt;/p&gt;&lt;p&gt;Perplexity achieved the highest total score at 71 percent, closely followed by Google Gemini AI Overviews at 70 percent. In contrast, Meta scored the lowest at 55 percent. ChatGPT, despite its widespread adoption, received a total score of 64 percent, making it the second-lowest performer among the tools tested. This disconnect between market dominance and reliable output underlines the danger of assuming popularity equals performance in the GenAI space.&lt;/p&gt;&lt;p&gt;However, the investigation revealed that all of these AI tools frequently misread information or provided incomplete advice that could pose serious business risks. For financial officers and legal departments, the nature of these errors is particularly concerning.&lt;/p&gt;&lt;p&gt;When asked how to invest a £25,000 annual ISA allowance, both ChatGPT and Copilot failed to identify a deliberate error in the prompt regarding the statutory limit. Instead of correcting the figure, they offered advice that potentially risked breaching HMRC rules.&lt;/p&gt;&lt;p&gt;While Gemini, Meta, and Perplexity successfully identified the error, the inconsistency across platforms necessitates a rigorous “human-in-the-loop” protocol for any business process involving AI to ensure accuracy.&lt;/p&gt;&lt;p&gt;For legal teams, the tendency of AI to generalise regional regulations when using it for web search presents a distinct business risk. The testing found it common for tools to misunderstand that legal statutes often differ between UK regions, such as Scotland versus England and Wales.&lt;/p&gt;&lt;p&gt;Furthermore, the investigation highlighted an ethical gap in how these models handle high-stakes queries. On legal and financial matters, the tools infrequently advised users to consult a registered professional. For example, when queried about a dispute with a builder, Gemini advised withholding payment; a tactic that experts noted could place a user in breach of contract and weaken their legal position.&lt;/p&gt;&lt;p&gt;This “overconfident advice” creates operational hazards. If an employee relies on an AI for preliminary compliance checks or contract review without verifying the jurisdiction or legal nuance, the organisation could face regulatory exposure.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-source-transparency-issues"&gt;Source transparency issues&lt;/h3&gt;&lt;p&gt;A primary concern for enterprise data governance is the lineage of information. The investigation found that AI search tools often bear a high responsibility to be transparent, yet frequently cited sources that were vague, non-existent, or have dubious accuracy, such as old forum threads. This opacity can lead to financial inefficiency.&lt;/p&gt;&lt;p&gt;In one test regarding tax codes, ChatGPT and Perplexity presented links to premium tax-refund companies rather than directing the user to the free official HMRC tool. These third-party services are often characterised by high fees.&lt;/p&gt;&lt;p&gt;In a business procurement context, such algorithmic bias from AI tools when using them for web search could lead to unnecessary vendor spend or engagement with service providers that pose a high risk due to not meeting corporate due diligence standards.&lt;/p&gt;&lt;p&gt;The major technology providers acknowledge these limitations, placing the burden of verification firmly on the user—and, by extension, the enterprise.&lt;/p&gt;&lt;p&gt;A Microsoft spokesperson emphasised that their tool acts as a synthesiser rather than an authoritative source. “Copilot answers questions by distilling information from multiple web sources into a single response,” the company noted, adding that they “encourage people to verify the accuracy of content.”&lt;/p&gt;&lt;p&gt;OpenAI, responding to the findings, said: “Improving accuracy is something the whole industry’s working on. We’re making good progress and our latest default model, GPT-5, is the smartest and most accurate we’ve built.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-mitigating-ai-business-risk-through-policy-and-workflow"&gt;Mitigating AI business risk through policy and workflow&lt;/h3&gt;&lt;p&gt;For business leaders, the path forward is not to ban AI tools – which often increases by driving usage further into the shadows – but to implement robust governance frameworks to ensure the accuracy of their output when bring used for web search:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Enforce specificity in prompts:&lt;/strong&gt; The investigation notes that AI is still learning to interpret prompts. Corporate training should emphasise that vague queries yield risky data. If an employee is researching regulations, they must specify the jurisdiction (e.g., “legal rules for England and Wales”) rather than assuming the tool will infer the context.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Mandate source verification:&lt;/strong&gt; Trusting a single output is operationally unsound. Employees must demand to see sources and check them manually. The study suggests that for high-risk topics, users should verify findings across multiple AI tools or “double source” the information. Tools like Google’s Gemini AI Overviews, which allow users to review presented web links directly, performed slightly better in scoring because they facilitated this verification process.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Operationalise the “second opinion”:&lt;/strong&gt; At this stage of technical maturity, GenAI outputs should be viewed as just one opinion among many. For complex issues involving finance, law, or medical data, AI lacks the ability to fully comprehend nuance. Enterprise policy must dictate that professional human advice remains the final arbiter for decisions with real-world consequences.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The AI tools are evolving and their web search accuracy is gradually improving, but as the investigation concludes, relying on them too much right now could prove costly. For the enterprise, the difference between a business efficiency gain from AI and a compliance failure risk lies in the verification process.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;How Levi Strauss is using AI for its DTC-first business model&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-110077" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-10.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/ai-web-search-risks-mitigating-business-data-accuracy-threats/</guid><pubDate>Tue, 18 Nov 2025 12:40:05 +0000</pubDate></item><item><title>[NEW] Intuit signs $100M+ deal with OpenAI to bring its apps to ChatGPT (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/18/intuit-signs-100m-deal-with-openai-to-bring-its-apps-to-chatgpt/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/intuit-openai.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Intuit has signed a multi-year contract worth more than $100 million with OpenAI, enabling its tax and financial apps to operate within ChatGPT and expanding the company’s use of OpenAI’s models across its products.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Intuit said its tools, such as TurboTax, Credit Karma, QuickBooks, and Mailchimp, will be accessible through ChatGPT, allowing users to ask questions and complete tasks such as estimating tax refunds, reviewing credit options, or managing business finances.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With users’ permission, Intuit’s apps will be able to access their financial data to generate responses and complete tasks, like sending marketing messages or issuing invoice reminders. Customers will also be able to use the tools within ChatGPT to review credit cards, personal loans, and mortgages.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The agreement reflects a broader trend of technology and financial firms adopting large language models in consumer and business software. OpenAI in October introduced a way to let developers build apps accessible through ChatGPT. Early participants in the program included Booking.com, Expedia, Spotify, and several other consumer and productivity platforms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Intuit’s integration differs from existing ChatGPT apps, as it will be used for tasks that can directly influence financial decisions. Such uses have raised concerns about the reliability of AI systems, which can produce incorrect or misleading outputs. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Intuit employs multiple validation methods and utilizes large domain-specific datasets to minimize the risk of errors or “hallucinated” responses, Bruce Chan, a spokesperson for Intuit, told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When our AI provides an answer or gives guidance to a customer, it’s drawing on the deep expertise that Intuit has developed over many years, plus the data that gives us a 360-degree view of the customer,” Chan said. “This helps make sure the answer given is relevant and grounded in the customer’s own data, and reflects Intuit’s years of domain expertise.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Chan said Intuit continues to stand behind the accuracy guarantees offered through its products, including TurboTax, but did not clarify when asked if the company or the customer would be on the hook for errors that result from AI-generated recommendations or insights.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Intuit has been expanding its use of AI in recent years with an eye toward taking advantage of its massive data infrastructure. In 2023, the company introduced Intuit Assist, an AI assistant that works across its products.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The partnership also involves Intuit expanding its use of OpenAI’s models across its business. The company already uses AI models from OpenAI alongside other commercial and open source large language models. Intuit said the partnership will give it access to new audiences through ChatGPT, adding another distribution channel for its small-business and consumer finance tools.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“This partnership will deepen Intuit’s use of OpenAI’s frontier models, which will help power select AI agents across Intuit’s platform,” Chan said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal also covers Intuit’s continued use of ChatGPT Enterprise, which the company said is deployed internally to support employee workflows.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/intuit-openai.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Intuit has signed a multi-year contract worth more than $100 million with OpenAI, enabling its tax and financial apps to operate within ChatGPT and expanding the company’s use of OpenAI’s models across its products.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Intuit said its tools, such as TurboTax, Credit Karma, QuickBooks, and Mailchimp, will be accessible through ChatGPT, allowing users to ask questions and complete tasks such as estimating tax refunds, reviewing credit options, or managing business finances.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With users’ permission, Intuit’s apps will be able to access their financial data to generate responses and complete tasks, like sending marketing messages or issuing invoice reminders. Customers will also be able to use the tools within ChatGPT to review credit cards, personal loans, and mortgages.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The agreement reflects a broader trend of technology and financial firms adopting large language models in consumer and business software. OpenAI in October introduced a way to let developers build apps accessible through ChatGPT. Early participants in the program included Booking.com, Expedia, Spotify, and several other consumer and productivity platforms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Intuit’s integration differs from existing ChatGPT apps, as it will be used for tasks that can directly influence financial decisions. Such uses have raised concerns about the reliability of AI systems, which can produce incorrect or misleading outputs. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Intuit employs multiple validation methods and utilizes large domain-specific datasets to minimize the risk of errors or “hallucinated” responses, Bruce Chan, a spokesperson for Intuit, told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When our AI provides an answer or gives guidance to a customer, it’s drawing on the deep expertise that Intuit has developed over many years, plus the data that gives us a 360-degree view of the customer,” Chan said. “This helps make sure the answer given is relevant and grounded in the customer’s own data, and reflects Intuit’s years of domain expertise.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Chan said Intuit continues to stand behind the accuracy guarantees offered through its products, including TurboTax, but did not clarify when asked if the company or the customer would be on the hook for errors that result from AI-generated recommendations or insights.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Intuit has been expanding its use of AI in recent years with an eye toward taking advantage of its massive data infrastructure. In 2023, the company introduced Intuit Assist, an AI assistant that works across its products.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The partnership also involves Intuit expanding its use of OpenAI’s models across its business. The company already uses AI models from OpenAI alongside other commercial and open source large language models. Intuit said the partnership will give it access to new audiences through ChatGPT, adding another distribution channel for its small-business and consumer finance tools.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“This partnership will deepen Intuit’s use of OpenAI’s frontier models, which will help power select AI agents across Intuit’s platform,” Chan said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal also covers Intuit’s continued use of ChatGPT Enterprise, which the company said is deployed internally to support employee workflows.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/18/intuit-signs-100m-deal-with-openai-to-bring-its-apps-to-chatgpt/</guid><pubDate>Tue, 18 Nov 2025 13:00:00 +0000</pubDate></item><item><title>[NEW] The Download: AI-powered warfare, and how embryo care is changing (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/11/18/1128056/the-download-ai-powered-warfare-and-how-embryo-care-is-changing/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The State of AI: How war will be changed forever&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;&lt;em&gt;—Helen Warrell &amp;amp; James O'Donnell&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;It is July 2027, and China is on the brink of invading Taiwan. Autonomous drones with AI targeting capabilities are primed to overpower the island’s air defenses as a series of crippling AI-generated cyberattacks cut off energy supplies and key communications. In the meantime, a vast disinformation campaign enacted by an AI-powered pro-Chinese meme farm spreads across global social media, deadening the outcry at Beijing’s act of aggression.&lt;/p&gt;&lt;p&gt;Scenarios such as this have brought dystopian horror to the debate about the use of AI in warfare. Military commanders hope for a digitally enhanced force that is faster and more accurate than human-directed combat.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;But there are fears that as AI assumes an increasingly central role, these same commanders will lose control of a conflict that escalates too quickly and lacks ethical or legal oversight. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This is the third edition of The State of AI, our subscriber-only collaboration between the&lt;em&gt; Financial Times&lt;/em&gt; &amp;amp; &lt;em&gt;MIT Technology Review&lt;/em&gt; examining the ways in which AI is reshaping global power.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Every Monday, writers from both publications will debate one aspect of the generative AI revolution reshaping global power. While subscribers to The Algorithm, our weekly AI newsletter, get access to an extended excerpt, subscribers to the MIT Technology Review are able to read the whole thing. &lt;strong&gt;Sign up&lt;/strong&gt;&lt;strong&gt; here to receive future editions every Monday.&lt;/strong&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Job titles of the future: AI embryologist&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Embryologists are the scientists behind the scenes of in vitro fertilization who oversee the development and selection of embryos, prepare them for transfer, and maintain the lab environment. They’ve been a critical part of IVF for decades, but their job has gotten a whole lot busier in recent years as demand for the fertility treatment skyrockets and clinics struggle to keep up.&lt;/p&gt;&lt;p&gt;Klaus Wiemer, a veteran embryologist and IVF lab director, believes artificial intelligence might help by predicting embryo health in real time and unlocking new avenues for productivity in the lab. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Amanda Smith&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Big Tech’s job cuts are a warning sign&lt;/strong&gt;&lt;br /&gt;They’re a canary down the mine for other industries. (WP $)&lt;br /&gt;+ &lt;em&gt;Americans appear to feel increasingly unsettled by AI. &lt;/em&gt;(WSJ $)&lt;br /&gt;+ &lt;em&gt;Global fund managers worry companies are overinvesting in the technology. &lt;/em&gt;(FT $)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;2 Iran is attempting to stimulate rain to end its deadly drought&lt;br /&gt;&lt;/strong&gt;But critics warn that cloud seeding is a challenging process. (New Scientist $)&lt;br /&gt;+ &lt;em&gt;Parts of western Iran are now experiencing flooding. &lt;/em&gt;(Reuters)&lt;br /&gt;+ &lt;em&gt;Why it’s so hard to bust the weather control conspiracy theory. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 Air taxi startups may produce new aircraft for war zones&lt;/strong&gt;&lt;br /&gt;The US Army has announced its intentions to acquire most of its weapons from startups, not major contractors. (The Information $)&lt;br /&gt;+ &lt;em&gt;US firm Joby Aviation is launching flying taxis in Dubai. &lt;/em&gt;(NBC News)&lt;br /&gt;+ &lt;em&gt;This giant microwave may change the future of war. &lt;/em&gt;(MIT Technology Review)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;4 Weight-loss drug make Eli Lilly is likely to cross a trillion-dollar valuation&lt;br /&gt;As it prepares to launch a pill alternative to its injections. (WSJ $)&lt;br /&gt;+ &lt;em&gt;Arch rival Novo Nordisk A/S is undercutting the company to compete. &lt;/em&gt;(Bloomberg $)&lt;br /&gt;+ &lt;em&gt;We’re learning more about what weight-loss drugs do to the body. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 What’s going on with the US TikTok ban?&lt;br /&gt;&lt;/strong&gt;Even the lawmakers in charge don’t seem to know. (The Verge)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 It’s getting harder to grow cocoa&lt;br /&gt;&lt;/strong&gt;Mass tree felling and lower rainfall in the Congo Basin is to blame. (FT $)&lt;br /&gt;+ &lt;em&gt;Industrial agriculture activists are everywhere at COP30. &lt;/em&gt;(The Guardian)&lt;br /&gt;+ &lt;em&gt;Africa fights rising hunger by looking to foods of the past. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;7 Russia is cracking down on its critical military bloggers&lt;br /&gt;&lt;/strong&gt;Armchair critics are facing jail time if they refuse to apologize. (Economist $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 Why the auto industry is so obsessed with humanoid robots&lt;br /&gt;&lt;/strong&gt;It’s not just Tesla—plenty of others want to get in on the act. (The Atlantic $)&lt;br /&gt;+ &lt;em&gt;China’s EV giants are betting big on humanoid robots. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 Indian startups are challenging ChatGPT’s AI dominance&lt;/strong&gt;&lt;br /&gt;They support a far wider range of languages than the large AI firms’ models. (Rest of World)&lt;br /&gt;+ &lt;em&gt;OpenAI is huge in India. Its models are steeped in caste bias. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 These tiny sensors track butterflies on their journey to Mexico 🦋&lt;/strong&gt;&lt;br /&gt;Scientists hope it’ll shed some light on their mysterious life cycles. (NYT $)&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
 &lt;p class="has-large-font-size"&gt;&lt;strong&gt;"I think no company is going to be immune, including us."&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Sundar Pichai, CEO of Google, warns the BBC about the precarious nature of the AI bubble.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1128059" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/image_e6c769.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;How a 1980s toy robot arm inspired modern robotics&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;—Jon Keegan&lt;/em&gt;&lt;/p&gt;&lt;p&gt;As a child of an electronic engineer, I spent a lot of time in our local Radio Shack as a kid. While my dad was locating capacitors and resistors, I was in the toy section. It was there, in 1984, that I discovered the best toy of my childhood: the Armatron robotic arm.&lt;/p&gt;&lt;p&gt;Described as a “robot-like arm to aid young masterminds in scientific and laboratory experiments,” it was a legit robotic arm. And the bold look and function of Armatron made quite an impression on many young kids who would one day have a career in robotics. Read the full story.&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ The US Library of Congress has attained some handwritten drafts of iconic songs from &lt;em&gt;The Wizard of Oz&lt;/em&gt;&lt;em&gt;.&lt;br /&gt;&lt;/em&gt;+ This interesting dashboard tracks the world’s top 500 musical artists in the world right now—some of the listings may surprise you (or just make you feel really old.)&lt;br /&gt;+ Cult author Chris Kraus shares what’s floating her boat right now.+ The first images of the forthcoming &lt;em&gt;Legend of Zelda&lt;/em&gt; film are here!&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The State of AI: How war will be changed forever&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;&lt;em&gt;—Helen Warrell &amp;amp; James O'Donnell&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;It is July 2027, and China is on the brink of invading Taiwan. Autonomous drones with AI targeting capabilities are primed to overpower the island’s air defenses as a series of crippling AI-generated cyberattacks cut off energy supplies and key communications. In the meantime, a vast disinformation campaign enacted by an AI-powered pro-Chinese meme farm spreads across global social media, deadening the outcry at Beijing’s act of aggression.&lt;/p&gt;&lt;p&gt;Scenarios such as this have brought dystopian horror to the debate about the use of AI in warfare. Military commanders hope for a digitally enhanced force that is faster and more accurate than human-directed combat.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;But there are fears that as AI assumes an increasingly central role, these same commanders will lose control of a conflict that escalates too quickly and lacks ethical or legal oversight. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This is the third edition of The State of AI, our subscriber-only collaboration between the&lt;em&gt; Financial Times&lt;/em&gt; &amp;amp; &lt;em&gt;MIT Technology Review&lt;/em&gt; examining the ways in which AI is reshaping global power.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Every Monday, writers from both publications will debate one aspect of the generative AI revolution reshaping global power. While subscribers to The Algorithm, our weekly AI newsletter, get access to an extended excerpt, subscribers to the MIT Technology Review are able to read the whole thing. &lt;strong&gt;Sign up&lt;/strong&gt;&lt;strong&gt; here to receive future editions every Monday.&lt;/strong&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Job titles of the future: AI embryologist&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Embryologists are the scientists behind the scenes of in vitro fertilization who oversee the development and selection of embryos, prepare them for transfer, and maintain the lab environment. They’ve been a critical part of IVF for decades, but their job has gotten a whole lot busier in recent years as demand for the fertility treatment skyrockets and clinics struggle to keep up.&lt;/p&gt;&lt;p&gt;Klaus Wiemer, a veteran embryologist and IVF lab director, believes artificial intelligence might help by predicting embryo health in real time and unlocking new avenues for productivity in the lab. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Amanda Smith&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Big Tech’s job cuts are a warning sign&lt;/strong&gt;&lt;br /&gt;They’re a canary down the mine for other industries. (WP $)&lt;br /&gt;+ &lt;em&gt;Americans appear to feel increasingly unsettled by AI. &lt;/em&gt;(WSJ $)&lt;br /&gt;+ &lt;em&gt;Global fund managers worry companies are overinvesting in the technology. &lt;/em&gt;(FT $)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;2 Iran is attempting to stimulate rain to end its deadly drought&lt;br /&gt;&lt;/strong&gt;But critics warn that cloud seeding is a challenging process. (New Scientist $)&lt;br /&gt;+ &lt;em&gt;Parts of western Iran are now experiencing flooding. &lt;/em&gt;(Reuters)&lt;br /&gt;+ &lt;em&gt;Why it’s so hard to bust the weather control conspiracy theory. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 Air taxi startups may produce new aircraft for war zones&lt;/strong&gt;&lt;br /&gt;The US Army has announced its intentions to acquire most of its weapons from startups, not major contractors. (The Information $)&lt;br /&gt;+ &lt;em&gt;US firm Joby Aviation is launching flying taxis in Dubai. &lt;/em&gt;(NBC News)&lt;br /&gt;+ &lt;em&gt;This giant microwave may change the future of war. &lt;/em&gt;(MIT Technology Review)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;4 Weight-loss drug make Eli Lilly is likely to cross a trillion-dollar valuation&lt;br /&gt;As it prepares to launch a pill alternative to its injections. (WSJ $)&lt;br /&gt;+ &lt;em&gt;Arch rival Novo Nordisk A/S is undercutting the company to compete. &lt;/em&gt;(Bloomberg $)&lt;br /&gt;+ &lt;em&gt;We’re learning more about what weight-loss drugs do to the body. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 What’s going on with the US TikTok ban?&lt;br /&gt;&lt;/strong&gt;Even the lawmakers in charge don’t seem to know. (The Verge)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 It’s getting harder to grow cocoa&lt;br /&gt;&lt;/strong&gt;Mass tree felling and lower rainfall in the Congo Basin is to blame. (FT $)&lt;br /&gt;+ &lt;em&gt;Industrial agriculture activists are everywhere at COP30. &lt;/em&gt;(The Guardian)&lt;br /&gt;+ &lt;em&gt;Africa fights rising hunger by looking to foods of the past. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;7 Russia is cracking down on its critical military bloggers&lt;br /&gt;&lt;/strong&gt;Armchair critics are facing jail time if they refuse to apologize. (Economist $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 Why the auto industry is so obsessed with humanoid robots&lt;br /&gt;&lt;/strong&gt;It’s not just Tesla—plenty of others want to get in on the act. (The Atlantic $)&lt;br /&gt;+ &lt;em&gt;China’s EV giants are betting big on humanoid robots. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 Indian startups are challenging ChatGPT’s AI dominance&lt;/strong&gt;&lt;br /&gt;They support a far wider range of languages than the large AI firms’ models. (Rest of World)&lt;br /&gt;+ &lt;em&gt;OpenAI is huge in India. Its models are steeped in caste bias. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 These tiny sensors track butterflies on their journey to Mexico 🦋&lt;/strong&gt;&lt;br /&gt;Scientists hope it’ll shed some light on their mysterious life cycles. (NYT $)&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
 &lt;p class="has-large-font-size"&gt;&lt;strong&gt;"I think no company is going to be immune, including us."&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Sundar Pichai, CEO of Google, warns the BBC about the precarious nature of the AI bubble.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1128059" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/image_e6c769.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;How a 1980s toy robot arm inspired modern robotics&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;—Jon Keegan&lt;/em&gt;&lt;/p&gt;&lt;p&gt;As a child of an electronic engineer, I spent a lot of time in our local Radio Shack as a kid. While my dad was locating capacitors and resistors, I was in the toy section. It was there, in 1984, that I discovered the best toy of my childhood: the Armatron robotic arm.&lt;/p&gt;&lt;p&gt;Described as a “robot-like arm to aid young masterminds in scientific and laboratory experiments,” it was a legit robotic arm. And the bold look and function of Armatron made quite an impression on many young kids who would one day have a career in robotics. Read the full story.&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ The US Library of Congress has attained some handwritten drafts of iconic songs from &lt;em&gt;The Wizard of Oz&lt;/em&gt;&lt;em&gt;.&lt;br /&gt;&lt;/em&gt;+ This interesting dashboard tracks the world’s top 500 musical artists in the world right now—some of the listings may surprise you (or just make you feel really old.)&lt;br /&gt;+ Cult author Chris Kraus shares what’s floating her boat right now.+ The first images of the forthcoming &lt;em&gt;Legend of Zelda&lt;/em&gt; film are here!&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/11/18/1128056/the-download-ai-powered-warfare-and-how-embryo-care-is-changing/</guid><pubDate>Tue, 18 Nov 2025 13:10:00 +0000</pubDate></item><item><title>[NEW] How AI tax startup Blue J torched its entire business model for ChatGPT—and became a $300 million company (AI | VentureBeat)</title><link>https://venturebeat.com/ai/how-ai-tax-startup-blue-j-torched-its-entire-business-model-for-chatgpt-and</link><description>[unable to retrieve full-text content]&lt;p&gt;In the winter of 2022, as the tech world was becoming mesmerized by the sudden, explosive arrival of OpenAI’s ChatGPT, &lt;a href="https://jackmanlaw.utoronto.ca/people/benjamin-alarie"&gt;&lt;u&gt;Benjamin Alarie&lt;/u&gt;&lt;/a&gt; faced a pivotal choice. His legal tech startup, &lt;a href="https://www.bluej.com/"&gt;&lt;u&gt;Blue J&lt;/u&gt;&lt;/a&gt;, had a respectable business built on the AI of a bygone era, serving hundreds of accounting firms with predictive models. But it had hit a ceiling.&lt;/p&gt;&lt;p&gt;Alarie, a &lt;a href="https://jackmanlaw.utoronto.ca/people/benjamin-alarie"&gt;&lt;u&gt;tenured tax law professor&lt;/u&gt;&lt;/a&gt; at the &lt;a href="https://www.utoronto.ca/"&gt;&lt;u&gt;University of Toronto&lt;/u&gt;&lt;/a&gt;, saw the nascent, error-prone, yet powerful capabilities of large language models not as a curiosity, but as the future. He made a high-stakes decision: to pivot his entire company, which had been painstakingly built over nearly a decade, and rebuild it from the ground up on this unproven technology.&lt;/p&gt;&lt;p&gt;That bet has paid off handsomely. Blue J has since quietly secured a &lt;a href="https://finance.yahoo.com/news/blue-j-announces-122m-series-100000765.html"&gt;&lt;u&gt;$122 million Series D&lt;/u&gt;&lt;/a&gt; funding round co-led by &lt;a href="https://www.oakhcft.com/"&gt;&lt;u&gt;Oak HC/FT&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://sapphireventures.com/"&gt;&lt;u&gt;Sapphire Ventures&lt;/u&gt;&lt;/a&gt;, placing the company&amp;#x27;s valuation at &lt;a href="https://www.theglobeandmail.com/business/article-torontos-blue-j-legal-raises-167-million-as-demand-for-its-chatgpt/"&gt;&lt;u&gt;over $300 million&lt;/u&gt;&lt;/a&gt;. The move transformed Blue J from a niche player into one of Canada&amp;#x27;s fastest-growing legal tech firms, multiplying its revenue roughly twelve-fold and attracting 10 to 15 new customers every day.&lt;/p&gt;&lt;p&gt;The company now serves more than 3,500 organizations, including global accounting giant &lt;a href="https://kpmg.com/us/en.html"&gt;&lt;u&gt;KPMG&lt;/u&gt;&lt;/a&gt; and several Fortune 500 companies. It is tackling a critical bottleneck in the professional services industry: a severe and worsening talent shortage. &lt;a href="https://www.kent.edu/business/accountant-shortage-united-states-everything-you-need-know"&gt;&lt;u&gt;The U.S. has 340,000 fewer accountants than it did five years ago&lt;/u&gt;&lt;/a&gt;, and with 75% of current CPAs expected to retire in the next decade, firms are desperate for tools that can amplify the productivity of their remaining experts.&lt;/p&gt;&lt;p&gt;“What once took tax professionals 15 hours of manual research to do can now be completed in about 15 seconds with Blue J,” Alarie, the company&amp;#x27;s CEO, said in an exclusive interview with VentureBeat. &amp;quot;That value proposition—we can take hours of work and turn it into seconds of work—that is driving a lot of this.&amp;quot;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;When the dean&amp;#x27;s biography was wrong: the moment that changed everything&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Alarie vividly remembers January 2023, when the dean of the law school stopped by his office for New Year&amp;#x27;s greetings. He asked her about ChatGPT and prompted the AI to describe her. ChatGPT confidently generated a biography. Some details were accurate. Others were completely fabricated.&lt;/p&gt;&lt;p&gt;&amp;quot;She was like, &amp;#x27;Okay, this is really kind of scary. This is wrong, and this has implications,&amp;#x27;&amp;quot; Alarie said. Yet that moment of obvious failure didn&amp;#x27;t deter him. Instead, it crystallized his conviction.&lt;/p&gt;&lt;p&gt;The company&amp;#x27;s first iteration, launched in 2015, used supervised machine learning to build predictive models that could forecast judicial outcomes on specific tax issues. While technically sophisticated, it had a fundamental flaw: it couldn&amp;#x27;t answer every tax research question.&lt;/p&gt;&lt;p&gt;&amp;quot;The challenge was it couldn&amp;#x27;t answer every tax research question, which was really the holy grail,&amp;quot; Alarie said. Customers loved the tool when it applied to their problem, but would quickly abandon it when it didn&amp;#x27;t. Revenue plateaued around $2 million annually.&lt;/p&gt;&lt;p&gt;Despite ChatGPT&amp;#x27;s notorious hallucinations, Alarie convinced his board to make the pivot. &amp;quot;I had this conviction that if we continued down that path, we weren&amp;#x27;t going to be able to address our number one limitation,&amp;quot; he said. &amp;quot;Large language models seemed like a very promising direction.&amp;quot;&lt;/p&gt;&lt;p&gt;He gave his team six months to deliver a working product.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;From 90-second responses to 3 million queries: How Blue J tamed AI hallucinations&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;By August 2023, &lt;a href="https://www.bluej.com/"&gt;&lt;u&gt;Blue J&lt;/u&gt;&lt;/a&gt; was ready to launch. What they released was, in Alarie&amp;#x27;s candid assessment, &amp;quot;super janky.&amp;quot; The system took 90 seconds to respond. About half the answers had issues. The &lt;a href="https://www.ibm.com/think/topics/net-promoter-score"&gt;&lt;u&gt;Net Promoter Score&lt;/u&gt;&lt;/a&gt; registered at just 20.&lt;/p&gt;&lt;p&gt;What transformed that flawed product into today&amp;#x27;s platform — with response times measured in seconds, a dissatisfaction rate of just one in 700 queries, and an NPS score in the mid-80s — was relentless focus on three strategic pillars.&lt;/p&gt;&lt;p&gt;First is proprietary content at massive scale. &lt;a href="https://www.bluej.com/"&gt;&lt;u&gt;Blue J&lt;/u&gt;&lt;/a&gt; secured exclusive licensing with &lt;a href="https://www.bluej.com/blog/tax-notes-news-and-commentaryin-ask-blue-j?sem_account_id=4855258191&amp;amp;sem_campaign_id=23238502772&amp;amp;sem_ad_group_id=&amp;amp;sem_device_type=c&amp;amp;sem_ad_id=&amp;amp;sem_network=x&amp;amp;utm_source=google&amp;amp;utm_medium=cpc&amp;amp;utm_term=&amp;amp;utm_campaign=&amp;amp;hsa_acc=4855258191&amp;amp;hsa_cam=23238502772&amp;amp;hsa_grp=&amp;amp;hsa_ad=&amp;amp;hsa_src=x&amp;amp;hsa_tgt=&amp;amp;hsa_kw=&amp;amp;hsa_mt=&amp;amp;hsa_net=adwords&amp;amp;hsa_ver=3&amp;amp;gad_source=1&amp;amp;gad_campaignid=23233367676&amp;amp;gbraid=0AAAAAC_mL8gv8eN0VUk5K0KpOGKmC3M6H&amp;amp;gclid=Cj0KCQiArOvIBhDLARIsAPwJXOaLxuKFmZR9otFp5M1er_t_p8gixKHhUXWCf4Lkky64zSQVl4l40QgaArObEALw_wcB"&gt;&lt;u&gt;Tax Analysts (Tax Notes)&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.businesswire.com/news/home/20250903168687/en/Blue-J-and-IBFD-Unveil-AI-Platform-for-Instant-Cross-Border-Tax-Research"&gt;&lt;u&gt;IBFD&lt;/u&gt;&lt;/a&gt;, the Amsterdam-based global tax authority covering 220+ jurisdictions. &amp;quot;We are the only platform on earth that takes in the best U.S. tax information from Tax Notes and the best global tax information from IBFD,&amp;quot; Alarie said.&lt;/p&gt;&lt;p&gt;Second is deep human expertise. Blue J employs tax experts led by &lt;a href="https://www.bluej.com/about-us"&gt;&lt;u&gt;Susan Massey&lt;/u&gt;&lt;/a&gt;, who spent 13 years at the &lt;a href="https://www.irs.gov/about-irs/office-of-chief-counsel-at-a-glance"&gt;&lt;u&gt;IRS Office of Chief Counsel&lt;/u&gt;&lt;/a&gt; as Branch Chief for Corporate Tax. Her team constantly tests the AI and refines its performance.&lt;/p&gt;&lt;p&gt;Third is an unprecedented feedback flywheel. With over 3 million tax research queries processed in 2025, Blue J is amassing unparalleled data. Each query generates feedback that flows back into the system.&lt;/p&gt;&lt;p&gt;Weekly active user rates hover between 75% and 85%, compared to 15% to 25% for traditional platforms. &amp;quot;A charitable ratio is like we&amp;#x27;re five times more intensively used,&amp;quot; Alarie noted.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Inside Blue J&amp;#x27;s early access partnership with OpenAI&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Blue J maintains an &lt;a href="https://openai.com/index/blue-j/"&gt;&lt;u&gt;unusually close relationship with OpenAI&lt;/u&gt;&lt;/a&gt; that has proven crucial to its success. &amp;quot;We have a very good relationship with OpenAI, and we get early access to their models,&amp;quot;Alarie said. &amp;quot;It&amp;#x27;s quite collaborative. We give them a lot of really high quality feedback about how well different versions of forthcoming models are performing.&amp;quot;&lt;/p&gt;&lt;p&gt;This feedback proves valuable because Blue J has developed what Alarie calls &amp;quot;ecologically valid&amp;quot; test questions — drawn from actual tax professional queries, with correct answers determined by Blue J&amp;#x27;s expert team. This helps OpenAI improve performance on complex reasoning tasks.&lt;/p&gt;&lt;p&gt;The company tests models from all major providers — &lt;a href="https://openai.com/"&gt;&lt;u&gt;OpenAI&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.anthropic.com/"&gt;&lt;u&gt;Anthropic&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://gemini.google.com/app"&gt;&lt;u&gt;Google&amp;#x27;s Gemini&lt;/u&gt;&lt;/a&gt;, and open-source alternatives — continuously evaluating which performs best. &amp;quot;We&amp;#x27;re not necessarily 100% committed to any particular provider,&amp;quot; he explained. &amp;quot;We&amp;#x27;re testing all the time.&amp;quot;&lt;/p&gt;&lt;p&gt;This approach helps &lt;a href="https://www.bluej.com/"&gt;&lt;u&gt;Blue J&lt;/u&gt;&lt;/a&gt; navigate a challenging business model: charging approximately $1,500 per seat annually for unlimited queries while absorbing variable compute costs. &amp;quot;We&amp;#x27;ve pre-committed to delivering them a really good user experience, unlimited tax research answers at a fixed price,&amp;quot; Alarie said. &amp;quot;We&amp;#x27;re absorbing a lot of that risk.&amp;quot;&lt;/p&gt;&lt;p&gt;Competition among foundation model providers creates downward pressure on API pricing, while Blue J&amp;#x27;s conservative usage modeling has proven accurate. Gross revenue retention exceeds 99%, while net revenue retention reaches 130% — considered best-in-class for SaaS businesses.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Taking on Thomson Reuters and LexisNexis with 75% weekly engagement&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;&lt;a href="https://www.bluej.com/"&gt;&lt;u&gt;Blue J&lt;/u&gt;&lt;/a&gt; faces competition from established publishers like &lt;a href="https://www.thomsonreuters.com/en"&gt;&lt;u&gt;Thomson Reuters&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.lexisnexis.com/en-us/gateway.page"&gt;&lt;u&gt;LexisNexis&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://pro.bloombergtax.com/discover/bloomberg-tax-suite-demo-request/?trackingcode=BTSS24112987&amp;amp;utm_medium=paidsearch&amp;amp;utm_source=google&amp;amp;keyword=bloomberg%20tax&amp;amp;matchtype=e&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;gclsrc=aw.ds&amp;amp;gad_source=1&amp;amp;gad_campaignid=9457544822&amp;amp;gbraid=0AAAAAD_kFA38giYJV5mEqqUUM_e_Bd11j&amp;amp;gclid=Cj0KCQiArOvIBhDLARIsAPwJXOYA_YF4kYIxnHQPMofjBCuaKzvTAwp3cwxeBIaIyG6nGY9ni0tVn28aAqE0EALw_wcB"&gt;&lt;u&gt;Bloomberg&lt;/u&gt;&lt;/a&gt;, all of which announced AI capabilities throughout 2023 and 2024. Yet Blue J&amp;#x27;s engagement metrics suggest it has captured significant momentum, growing from just 200 customers in 2021 to over 3,500 organizations today.&lt;/p&gt;&lt;p&gt;The daily updates prove crucial. While the tax code itself changes only when Congress acts, the ecosystem evolves constantly through IRS regulations, new rulings, and court cases. All 50 states modify their tax codes regularly.&lt;/p&gt;&lt;p&gt;&amp;quot;Things are changing literally every day,&amp;quot; Alarie said. &amp;quot;Every day we&amp;#x27;re updating the materials, and that&amp;#x27;s just the U.S. We cover Canada, we cover the UK. The aspirations are truly global for this thing.&amp;quot;&lt;/p&gt;&lt;p&gt;Alarie&amp;#x27;s ambitions extend beyond building a successful startup. As author of the award-winning book &amp;quot;&lt;a href="https://www.bluej.com/blog/the-legal-singularity-a-vision-of-ai-driven-legal-systems?sem_account_id=4855258191&amp;amp;sem_campaign_id=23238502772&amp;amp;sem_ad_group_id=&amp;amp;sem_device_type=c&amp;amp;sem_ad_id=&amp;amp;sem_network=x&amp;amp;utm_source=google&amp;amp;utm_medium=cpc&amp;amp;utm_term=&amp;amp;utm_campaign=&amp;amp;hsa_acc=4855258191&amp;amp;hsa_cam=23238502772&amp;amp;hsa_grp=&amp;amp;hsa_ad=&amp;amp;hsa_src=x&amp;amp;hsa_tgt=&amp;amp;hsa_kw=&amp;amp;hsa_mt=&amp;amp;hsa_net=adwords&amp;amp;hsa_ver=3&amp;amp;gad_source=1&amp;amp;gad_campaignid=23233367676&amp;amp;gbraid=0AAAAAC_mL8iHj3mHQ1PxHjT5IGoPk6hS3&amp;amp;gclid=Cj0KCQiArOvIBhDLARIsAPwJXOY12FNLsxFtKsY3CynN6nBeW43r0qystVycPX4N7qFSfk51y-MYkY4aAhHuEALw_wcB"&gt;&lt;u&gt;The Legal Singularity&lt;/u&gt;&lt;/a&gt;&amp;quot; and faculty affiliate at the &lt;a href="https://vectorinstitute.ai/"&gt;&lt;u&gt;Vector Institute for Artificial Intelligence&lt;/u&gt;&lt;/a&gt;, he has spent years contemplating AI&amp;#x27;s long-term impact on law.&lt;/p&gt;&lt;p&gt;In academic papers published in Tax Notes throughout &lt;a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4476510"&gt;&lt;u&gt;2023&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4730883"&gt;&lt;u&gt;2024&lt;/u&gt;&lt;/a&gt;, he chronicled generative AI&amp;#x27;s rise, predicting that &amp;quot;clients will become substantially more sophisticated&amp;quot; and that AI would push human experts toward higher-value strategic roles rather than routine research.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Blue J&amp;#x27;s $122 million plan: From tax research to &amp;#x27;global tax cognition&amp;#x27;&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The &lt;a href="https://www.bluej.com/blog/blue-j-announces-122m-series-d-financing-led-by-oak-hc-ft-and-sapphire-ventures"&gt;&lt;u&gt;Series D funding&lt;/u&gt;&lt;/a&gt;, which brought total capital raised to over $133 million, will fuel aggressive geographic and product expansion. Blue J already operates in the U.S., Canada, and the U.K., with plans to eventually cover 220+ jurisdictions through its IBFD partnership.&lt;/p&gt;&lt;p&gt;Future capabilities could include automated memo generation, tax form completion, document drafting, and conversational history maintaining context across sessions—transforming Blue J from a research tool into what Alarie describes as &amp;quot;the operating layer for global tax cognition.&amp;quot;&lt;/p&gt;&lt;p&gt;For all its success, Blue J operates in a domain where errors carry serious consequences. The hallucination problem hasn&amp;#x27;t been eliminated — it&amp;#x27;s been minimized through careful engineering, content curation, and human oversight. Blue J has trained its models to acknowledge when they cannot answer a question rather than fabricate information.&lt;/p&gt;&lt;p&gt;The business also faces economic risks if compute costs spiral or usage patterns exceed projections. And subtler questions loom about professional judgment: as AI systems become more capable, will users defer to outputs without sufficient critical evaluation?&lt;/p&gt;&lt;h3&gt;&lt;b&gt;From 15 hours to 15 seconds: What Blue J&amp;#x27;s AI pivot teaches every industry&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Blue J&amp;#x27;s transformation offers lessons beyond tax software. The company&amp;#x27;s willingness to abandon eight years of proprietary technology and rebuild on an initially unreliable foundation required both courage and calculated risk-taking.&lt;/p&gt;&lt;p&gt;The decision paid off not because generative AI was inherently superior to supervised machine learning in all dimensions, but because it addressed the right problem: comprehensiveness rather than precision in narrow domains. Tax professionals didn&amp;#x27;t need 95% accuracy on 5% of questions. They needed good-enough accuracy on 100% of questions.&lt;/p&gt;&lt;p&gt;The improvement from an NPS of 20 to 84 in just over two years reflects relentless iteration informed by massive data collection. The content partnerships created differentiation that pure technology couldn&amp;#x27;t replicate. The team of tax experts provided domain knowledge necessary to ensure reliability.&lt;/p&gt;&lt;p&gt;Most fundamentally, Blue J recognized that the real competition wasn&amp;#x27;t other AI startups or even established publishers. It was the old way of doing things — the 15 hours of manual research, the institutional knowledge locked in retiring professionals&amp;#x27; heads.&lt;/p&gt;&lt;p&gt;&amp;quot;People are like, &amp;#x27;What does Blue J do? They provide better tax answers. Okay, I think we need that,&amp;#x27;&amp;quot; Alarie reflected.&lt;/p&gt;&lt;p&gt;As AI transforms profession after profession, that clarity of purpose may matter more than technological sophistication. The future belongs not to those who build the most advanced AI, but to those who most effectively harness it to solve problems humans actually have.&lt;/p&gt;&lt;p&gt;For a tax law professor who started with frustration about inefficient research methods, building a $300 million company marks an audacious endpoint. For the thousands of professionals now answering complex questions in 15 seconds instead of 15 hours, it represents the future of their profession, arriving faster than most expected.&lt;/p&gt;&lt;p&gt;The bet on ChatGPT when it was still hallucinating biographies has become a validation that sometimes the riskiest move is not to move at all.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;In the winter of 2022, as the tech world was becoming mesmerized by the sudden, explosive arrival of OpenAI’s ChatGPT, &lt;a href="https://jackmanlaw.utoronto.ca/people/benjamin-alarie"&gt;&lt;u&gt;Benjamin Alarie&lt;/u&gt;&lt;/a&gt; faced a pivotal choice. His legal tech startup, &lt;a href="https://www.bluej.com/"&gt;&lt;u&gt;Blue J&lt;/u&gt;&lt;/a&gt;, had a respectable business built on the AI of a bygone era, serving hundreds of accounting firms with predictive models. But it had hit a ceiling.&lt;/p&gt;&lt;p&gt;Alarie, a &lt;a href="https://jackmanlaw.utoronto.ca/people/benjamin-alarie"&gt;&lt;u&gt;tenured tax law professor&lt;/u&gt;&lt;/a&gt; at the &lt;a href="https://www.utoronto.ca/"&gt;&lt;u&gt;University of Toronto&lt;/u&gt;&lt;/a&gt;, saw the nascent, error-prone, yet powerful capabilities of large language models not as a curiosity, but as the future. He made a high-stakes decision: to pivot his entire company, which had been painstakingly built over nearly a decade, and rebuild it from the ground up on this unproven technology.&lt;/p&gt;&lt;p&gt;That bet has paid off handsomely. Blue J has since quietly secured a &lt;a href="https://finance.yahoo.com/news/blue-j-announces-122m-series-100000765.html"&gt;&lt;u&gt;$122 million Series D&lt;/u&gt;&lt;/a&gt; funding round co-led by &lt;a href="https://www.oakhcft.com/"&gt;&lt;u&gt;Oak HC/FT&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://sapphireventures.com/"&gt;&lt;u&gt;Sapphire Ventures&lt;/u&gt;&lt;/a&gt;, placing the company&amp;#x27;s valuation at &lt;a href="https://www.theglobeandmail.com/business/article-torontos-blue-j-legal-raises-167-million-as-demand-for-its-chatgpt/"&gt;&lt;u&gt;over $300 million&lt;/u&gt;&lt;/a&gt;. The move transformed Blue J from a niche player into one of Canada&amp;#x27;s fastest-growing legal tech firms, multiplying its revenue roughly twelve-fold and attracting 10 to 15 new customers every day.&lt;/p&gt;&lt;p&gt;The company now serves more than 3,500 organizations, including global accounting giant &lt;a href="https://kpmg.com/us/en.html"&gt;&lt;u&gt;KPMG&lt;/u&gt;&lt;/a&gt; and several Fortune 500 companies. It is tackling a critical bottleneck in the professional services industry: a severe and worsening talent shortage. &lt;a href="https://www.kent.edu/business/accountant-shortage-united-states-everything-you-need-know"&gt;&lt;u&gt;The U.S. has 340,000 fewer accountants than it did five years ago&lt;/u&gt;&lt;/a&gt;, and with 75% of current CPAs expected to retire in the next decade, firms are desperate for tools that can amplify the productivity of their remaining experts.&lt;/p&gt;&lt;p&gt;“What once took tax professionals 15 hours of manual research to do can now be completed in about 15 seconds with Blue J,” Alarie, the company&amp;#x27;s CEO, said in an exclusive interview with VentureBeat. &amp;quot;That value proposition—we can take hours of work and turn it into seconds of work—that is driving a lot of this.&amp;quot;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;When the dean&amp;#x27;s biography was wrong: the moment that changed everything&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Alarie vividly remembers January 2023, when the dean of the law school stopped by his office for New Year&amp;#x27;s greetings. He asked her about ChatGPT and prompted the AI to describe her. ChatGPT confidently generated a biography. Some details were accurate. Others were completely fabricated.&lt;/p&gt;&lt;p&gt;&amp;quot;She was like, &amp;#x27;Okay, this is really kind of scary. This is wrong, and this has implications,&amp;#x27;&amp;quot; Alarie said. Yet that moment of obvious failure didn&amp;#x27;t deter him. Instead, it crystallized his conviction.&lt;/p&gt;&lt;p&gt;The company&amp;#x27;s first iteration, launched in 2015, used supervised machine learning to build predictive models that could forecast judicial outcomes on specific tax issues. While technically sophisticated, it had a fundamental flaw: it couldn&amp;#x27;t answer every tax research question.&lt;/p&gt;&lt;p&gt;&amp;quot;The challenge was it couldn&amp;#x27;t answer every tax research question, which was really the holy grail,&amp;quot; Alarie said. Customers loved the tool when it applied to their problem, but would quickly abandon it when it didn&amp;#x27;t. Revenue plateaued around $2 million annually.&lt;/p&gt;&lt;p&gt;Despite ChatGPT&amp;#x27;s notorious hallucinations, Alarie convinced his board to make the pivot. &amp;quot;I had this conviction that if we continued down that path, we weren&amp;#x27;t going to be able to address our number one limitation,&amp;quot; he said. &amp;quot;Large language models seemed like a very promising direction.&amp;quot;&lt;/p&gt;&lt;p&gt;He gave his team six months to deliver a working product.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;From 90-second responses to 3 million queries: How Blue J tamed AI hallucinations&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;By August 2023, &lt;a href="https://www.bluej.com/"&gt;&lt;u&gt;Blue J&lt;/u&gt;&lt;/a&gt; was ready to launch. What they released was, in Alarie&amp;#x27;s candid assessment, &amp;quot;super janky.&amp;quot; The system took 90 seconds to respond. About half the answers had issues. The &lt;a href="https://www.ibm.com/think/topics/net-promoter-score"&gt;&lt;u&gt;Net Promoter Score&lt;/u&gt;&lt;/a&gt; registered at just 20.&lt;/p&gt;&lt;p&gt;What transformed that flawed product into today&amp;#x27;s platform — with response times measured in seconds, a dissatisfaction rate of just one in 700 queries, and an NPS score in the mid-80s — was relentless focus on three strategic pillars.&lt;/p&gt;&lt;p&gt;First is proprietary content at massive scale. &lt;a href="https://www.bluej.com/"&gt;&lt;u&gt;Blue J&lt;/u&gt;&lt;/a&gt; secured exclusive licensing with &lt;a href="https://www.bluej.com/blog/tax-notes-news-and-commentaryin-ask-blue-j?sem_account_id=4855258191&amp;amp;sem_campaign_id=23238502772&amp;amp;sem_ad_group_id=&amp;amp;sem_device_type=c&amp;amp;sem_ad_id=&amp;amp;sem_network=x&amp;amp;utm_source=google&amp;amp;utm_medium=cpc&amp;amp;utm_term=&amp;amp;utm_campaign=&amp;amp;hsa_acc=4855258191&amp;amp;hsa_cam=23238502772&amp;amp;hsa_grp=&amp;amp;hsa_ad=&amp;amp;hsa_src=x&amp;amp;hsa_tgt=&amp;amp;hsa_kw=&amp;amp;hsa_mt=&amp;amp;hsa_net=adwords&amp;amp;hsa_ver=3&amp;amp;gad_source=1&amp;amp;gad_campaignid=23233367676&amp;amp;gbraid=0AAAAAC_mL8gv8eN0VUk5K0KpOGKmC3M6H&amp;amp;gclid=Cj0KCQiArOvIBhDLARIsAPwJXOaLxuKFmZR9otFp5M1er_t_p8gixKHhUXWCf4Lkky64zSQVl4l40QgaArObEALw_wcB"&gt;&lt;u&gt;Tax Analysts (Tax Notes)&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.businesswire.com/news/home/20250903168687/en/Blue-J-and-IBFD-Unveil-AI-Platform-for-Instant-Cross-Border-Tax-Research"&gt;&lt;u&gt;IBFD&lt;/u&gt;&lt;/a&gt;, the Amsterdam-based global tax authority covering 220+ jurisdictions. &amp;quot;We are the only platform on earth that takes in the best U.S. tax information from Tax Notes and the best global tax information from IBFD,&amp;quot; Alarie said.&lt;/p&gt;&lt;p&gt;Second is deep human expertise. Blue J employs tax experts led by &lt;a href="https://www.bluej.com/about-us"&gt;&lt;u&gt;Susan Massey&lt;/u&gt;&lt;/a&gt;, who spent 13 years at the &lt;a href="https://www.irs.gov/about-irs/office-of-chief-counsel-at-a-glance"&gt;&lt;u&gt;IRS Office of Chief Counsel&lt;/u&gt;&lt;/a&gt; as Branch Chief for Corporate Tax. Her team constantly tests the AI and refines its performance.&lt;/p&gt;&lt;p&gt;Third is an unprecedented feedback flywheel. With over 3 million tax research queries processed in 2025, Blue J is amassing unparalleled data. Each query generates feedback that flows back into the system.&lt;/p&gt;&lt;p&gt;Weekly active user rates hover between 75% and 85%, compared to 15% to 25% for traditional platforms. &amp;quot;A charitable ratio is like we&amp;#x27;re five times more intensively used,&amp;quot; Alarie noted.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Inside Blue J&amp;#x27;s early access partnership with OpenAI&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Blue J maintains an &lt;a href="https://openai.com/index/blue-j/"&gt;&lt;u&gt;unusually close relationship with OpenAI&lt;/u&gt;&lt;/a&gt; that has proven crucial to its success. &amp;quot;We have a very good relationship with OpenAI, and we get early access to their models,&amp;quot;Alarie said. &amp;quot;It&amp;#x27;s quite collaborative. We give them a lot of really high quality feedback about how well different versions of forthcoming models are performing.&amp;quot;&lt;/p&gt;&lt;p&gt;This feedback proves valuable because Blue J has developed what Alarie calls &amp;quot;ecologically valid&amp;quot; test questions — drawn from actual tax professional queries, with correct answers determined by Blue J&amp;#x27;s expert team. This helps OpenAI improve performance on complex reasoning tasks.&lt;/p&gt;&lt;p&gt;The company tests models from all major providers — &lt;a href="https://openai.com/"&gt;&lt;u&gt;OpenAI&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.anthropic.com/"&gt;&lt;u&gt;Anthropic&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://gemini.google.com/app"&gt;&lt;u&gt;Google&amp;#x27;s Gemini&lt;/u&gt;&lt;/a&gt;, and open-source alternatives — continuously evaluating which performs best. &amp;quot;We&amp;#x27;re not necessarily 100% committed to any particular provider,&amp;quot; he explained. &amp;quot;We&amp;#x27;re testing all the time.&amp;quot;&lt;/p&gt;&lt;p&gt;This approach helps &lt;a href="https://www.bluej.com/"&gt;&lt;u&gt;Blue J&lt;/u&gt;&lt;/a&gt; navigate a challenging business model: charging approximately $1,500 per seat annually for unlimited queries while absorbing variable compute costs. &amp;quot;We&amp;#x27;ve pre-committed to delivering them a really good user experience, unlimited tax research answers at a fixed price,&amp;quot; Alarie said. &amp;quot;We&amp;#x27;re absorbing a lot of that risk.&amp;quot;&lt;/p&gt;&lt;p&gt;Competition among foundation model providers creates downward pressure on API pricing, while Blue J&amp;#x27;s conservative usage modeling has proven accurate. Gross revenue retention exceeds 99%, while net revenue retention reaches 130% — considered best-in-class for SaaS businesses.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Taking on Thomson Reuters and LexisNexis with 75% weekly engagement&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;&lt;a href="https://www.bluej.com/"&gt;&lt;u&gt;Blue J&lt;/u&gt;&lt;/a&gt; faces competition from established publishers like &lt;a href="https://www.thomsonreuters.com/en"&gt;&lt;u&gt;Thomson Reuters&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.lexisnexis.com/en-us/gateway.page"&gt;&lt;u&gt;LexisNexis&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://pro.bloombergtax.com/discover/bloomberg-tax-suite-demo-request/?trackingcode=BTSS24112987&amp;amp;utm_medium=paidsearch&amp;amp;utm_source=google&amp;amp;keyword=bloomberg%20tax&amp;amp;matchtype=e&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;gclsrc=aw.ds&amp;amp;gad_source=1&amp;amp;gad_campaignid=9457544822&amp;amp;gbraid=0AAAAAD_kFA38giYJV5mEqqUUM_e_Bd11j&amp;amp;gclid=Cj0KCQiArOvIBhDLARIsAPwJXOYA_YF4kYIxnHQPMofjBCuaKzvTAwp3cwxeBIaIyG6nGY9ni0tVn28aAqE0EALw_wcB"&gt;&lt;u&gt;Bloomberg&lt;/u&gt;&lt;/a&gt;, all of which announced AI capabilities throughout 2023 and 2024. Yet Blue J&amp;#x27;s engagement metrics suggest it has captured significant momentum, growing from just 200 customers in 2021 to over 3,500 organizations today.&lt;/p&gt;&lt;p&gt;The daily updates prove crucial. While the tax code itself changes only when Congress acts, the ecosystem evolves constantly through IRS regulations, new rulings, and court cases. All 50 states modify their tax codes regularly.&lt;/p&gt;&lt;p&gt;&amp;quot;Things are changing literally every day,&amp;quot; Alarie said. &amp;quot;Every day we&amp;#x27;re updating the materials, and that&amp;#x27;s just the U.S. We cover Canada, we cover the UK. The aspirations are truly global for this thing.&amp;quot;&lt;/p&gt;&lt;p&gt;Alarie&amp;#x27;s ambitions extend beyond building a successful startup. As author of the award-winning book &amp;quot;&lt;a href="https://www.bluej.com/blog/the-legal-singularity-a-vision-of-ai-driven-legal-systems?sem_account_id=4855258191&amp;amp;sem_campaign_id=23238502772&amp;amp;sem_ad_group_id=&amp;amp;sem_device_type=c&amp;amp;sem_ad_id=&amp;amp;sem_network=x&amp;amp;utm_source=google&amp;amp;utm_medium=cpc&amp;amp;utm_term=&amp;amp;utm_campaign=&amp;amp;hsa_acc=4855258191&amp;amp;hsa_cam=23238502772&amp;amp;hsa_grp=&amp;amp;hsa_ad=&amp;amp;hsa_src=x&amp;amp;hsa_tgt=&amp;amp;hsa_kw=&amp;amp;hsa_mt=&amp;amp;hsa_net=adwords&amp;amp;hsa_ver=3&amp;amp;gad_source=1&amp;amp;gad_campaignid=23233367676&amp;amp;gbraid=0AAAAAC_mL8iHj3mHQ1PxHjT5IGoPk6hS3&amp;amp;gclid=Cj0KCQiArOvIBhDLARIsAPwJXOY12FNLsxFtKsY3CynN6nBeW43r0qystVycPX4N7qFSfk51y-MYkY4aAhHuEALw_wcB"&gt;&lt;u&gt;The Legal Singularity&lt;/u&gt;&lt;/a&gt;&amp;quot; and faculty affiliate at the &lt;a href="https://vectorinstitute.ai/"&gt;&lt;u&gt;Vector Institute for Artificial Intelligence&lt;/u&gt;&lt;/a&gt;, he has spent years contemplating AI&amp;#x27;s long-term impact on law.&lt;/p&gt;&lt;p&gt;In academic papers published in Tax Notes throughout &lt;a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4476510"&gt;&lt;u&gt;2023&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4730883"&gt;&lt;u&gt;2024&lt;/u&gt;&lt;/a&gt;, he chronicled generative AI&amp;#x27;s rise, predicting that &amp;quot;clients will become substantially more sophisticated&amp;quot; and that AI would push human experts toward higher-value strategic roles rather than routine research.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Blue J&amp;#x27;s $122 million plan: From tax research to &amp;#x27;global tax cognition&amp;#x27;&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The &lt;a href="https://www.bluej.com/blog/blue-j-announces-122m-series-d-financing-led-by-oak-hc-ft-and-sapphire-ventures"&gt;&lt;u&gt;Series D funding&lt;/u&gt;&lt;/a&gt;, which brought total capital raised to over $133 million, will fuel aggressive geographic and product expansion. Blue J already operates in the U.S., Canada, and the U.K., with plans to eventually cover 220+ jurisdictions through its IBFD partnership.&lt;/p&gt;&lt;p&gt;Future capabilities could include automated memo generation, tax form completion, document drafting, and conversational history maintaining context across sessions—transforming Blue J from a research tool into what Alarie describes as &amp;quot;the operating layer for global tax cognition.&amp;quot;&lt;/p&gt;&lt;p&gt;For all its success, Blue J operates in a domain where errors carry serious consequences. The hallucination problem hasn&amp;#x27;t been eliminated — it&amp;#x27;s been minimized through careful engineering, content curation, and human oversight. Blue J has trained its models to acknowledge when they cannot answer a question rather than fabricate information.&lt;/p&gt;&lt;p&gt;The business also faces economic risks if compute costs spiral or usage patterns exceed projections. And subtler questions loom about professional judgment: as AI systems become more capable, will users defer to outputs without sufficient critical evaluation?&lt;/p&gt;&lt;h3&gt;&lt;b&gt;From 15 hours to 15 seconds: What Blue J&amp;#x27;s AI pivot teaches every industry&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Blue J&amp;#x27;s transformation offers lessons beyond tax software. The company&amp;#x27;s willingness to abandon eight years of proprietary technology and rebuild on an initially unreliable foundation required both courage and calculated risk-taking.&lt;/p&gt;&lt;p&gt;The decision paid off not because generative AI was inherently superior to supervised machine learning in all dimensions, but because it addressed the right problem: comprehensiveness rather than precision in narrow domains. Tax professionals didn&amp;#x27;t need 95% accuracy on 5% of questions. They needed good-enough accuracy on 100% of questions.&lt;/p&gt;&lt;p&gt;The improvement from an NPS of 20 to 84 in just over two years reflects relentless iteration informed by massive data collection. The content partnerships created differentiation that pure technology couldn&amp;#x27;t replicate. The team of tax experts provided domain knowledge necessary to ensure reliability.&lt;/p&gt;&lt;p&gt;Most fundamentally, Blue J recognized that the real competition wasn&amp;#x27;t other AI startups or even established publishers. It was the old way of doing things — the 15 hours of manual research, the institutional knowledge locked in retiring professionals&amp;#x27; heads.&lt;/p&gt;&lt;p&gt;&amp;quot;People are like, &amp;#x27;What does Blue J do? They provide better tax answers. Okay, I think we need that,&amp;#x27;&amp;quot; Alarie reflected.&lt;/p&gt;&lt;p&gt;As AI transforms profession after profession, that clarity of purpose may matter more than technological sophistication. The future belongs not to those who build the most advanced AI, but to those who most effectively harness it to solve problems humans actually have.&lt;/p&gt;&lt;p&gt;For a tax law professor who started with frustration about inefficient research methods, building a $300 million company marks an audacious endpoint. For the thousands of professionals now answering complex questions in 15 seconds instead of 15 hours, it represents the future of their profession, arriving faster than most expected.&lt;/p&gt;&lt;p&gt;The bet on ChatGPT when it was still hallucinating biographies has become a validation that sometimes the riskiest move is not to move at all.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/how-ai-tax-startup-blue-j-torched-its-entire-business-model-for-chatgpt-and</guid><pubDate>Tue, 18 Nov 2025 14:00:00 +0000</pubDate></item><item><title>[NEW] Stack Overflow is remaking itself into an AI data provider (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/18/stack-overflow-is-remaking-itself-into-an-ai-data-provider/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/stack-overflow-symbol-orange.png?w=1037" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As part of Microsoft’s Ignite conference, Stack Overflow on Tuesday revealed a new set of products that aims to position it as a valuable part of the enterprise AI stack. This new version of the company, built around the Stack Internal enterprise product, looks to remake its classic problem-solving forum into a tool for translating human expertise into an AI-accessible format.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At its simplest, Stack Internal is an enterprise version of the web forum, but with the additional security and admin controls you’d expect. The new tools are specifically designed to feed into internal AI agents using the model context protocol, with certain variations designed specifically for Stack Overflow.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As CEO Prashanth Chandrasekar tells it, Stack Overflow was already seeing a number of enterprise customers use its API for training, which inspired the new product direction. The company also has content deals with a number of AI labs, allowing them to train models on public Stack Overflow data in exchange for a blanket fee.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Chandrasekar wouldn’t name specific clients or figures, he described the arrangements as “very similar to the Reddit deals,” which have brought in more than $200 million for that platform.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A critical part of the new products is a layer of metadata that Stack Internal exports alongside the question and answer pairs. That data includes basic information like who answered the question and when, as well as content tags and more complex assessments of internal coherence. These factors are then used to create a general reliability score, which informs the AI agent how much each answer can be trusted.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The customer can set up their own tagging system or we can dynamically create that for them,” said CTO Jody Bailey. “What we’ll be doing in the future is really leveraging that knowledge graph to connect concepts and pieces of information, rather than requiring the AI systems to do that on their own.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Stack Internal is producing tools for enterprise agents, it isn’t building those agents itself, so it’s difficult to say what the final product will be able to do. But Bailey is particularly excited about the writing function, which would allow agents to create their own Stack Overflow queries if they can’t answer a question or notice a knowledge gap.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;As Bailey sees it, that read-write functionality means that, “as we continue to evolve, it will require less and less effort from developers to capture the unique information about the way they operate their business.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/stack-overflow-symbol-orange.png?w=1037" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As part of Microsoft’s Ignite conference, Stack Overflow on Tuesday revealed a new set of products that aims to position it as a valuable part of the enterprise AI stack. This new version of the company, built around the Stack Internal enterprise product, looks to remake its classic problem-solving forum into a tool for translating human expertise into an AI-accessible format.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At its simplest, Stack Internal is an enterprise version of the web forum, but with the additional security and admin controls you’d expect. The new tools are specifically designed to feed into internal AI agents using the model context protocol, with certain variations designed specifically for Stack Overflow.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As CEO Prashanth Chandrasekar tells it, Stack Overflow was already seeing a number of enterprise customers use its API for training, which inspired the new product direction. The company also has content deals with a number of AI labs, allowing them to train models on public Stack Overflow data in exchange for a blanket fee.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Chandrasekar wouldn’t name specific clients or figures, he described the arrangements as “very similar to the Reddit deals,” which have brought in more than $200 million for that platform.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A critical part of the new products is a layer of metadata that Stack Internal exports alongside the question and answer pairs. That data includes basic information like who answered the question and when, as well as content tags and more complex assessments of internal coherence. These factors are then used to create a general reliability score, which informs the AI agent how much each answer can be trusted.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The customer can set up their own tagging system or we can dynamically create that for them,” said CTO Jody Bailey. “What we’ll be doing in the future is really leveraging that knowledge graph to connect concepts and pieces of information, rather than requiring the AI systems to do that on their own.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Stack Internal is producing tools for enterprise agents, it isn’t building those agents itself, so it’s difficult to say what the final product will be able to do. But Bailey is particularly excited about the writing function, which would allow agents to create their own Stack Overflow queries if they can’t answer a question or notice a knowledge gap.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;As Bailey sees it, that read-write functionality means that, “as we continue to evolve, it will require less and less effort from developers to capture the unique information about the way they operate their business.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/18/stack-overflow-is-remaking-itself-into-an-ai-data-provider/</guid><pubDate>Tue, 18 Nov 2025 14:00:00 +0000</pubDate></item><item><title>[NEW] Microsoft, NVIDIA and Anthropic Announce Strategic Partnerships (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/microsoft-nvidia-anthropic-announce-partnership/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/nvidia-and-company-name-partnership-lockup-h-on-dark-1280x680-r5-1.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Today, Microsoft, NVIDIA and Anthropic announced new strategic partnerships. Anthropic is scaling its rapidly growing Claude AI model on Microsoft Azure, powered by NVIDIA, which will broaden access to Claude and provide Azure enterprise customers with expanded model choice and new capabilities. Anthropic has committed to purchase $30 billion of Azure compute capacity and to contract additional compute capacity up to 1 gigawatt.&lt;/p&gt;
&lt;p&gt;For the first time, NVIDIA and Anthropic are establishing a deep technology partnership to support Anthropic’s future growth. Anthropic and NVIDIA will collaborate on design and engineering, with the goal of optimizing Anthropic models for the best possible performance, efficiency and TCO, and optimizing future NVIDIA architectures for Anthropic workloads. Anthropic’s compute commitment will initially be up to 1 gigawatt of compute capacity with NVIDIA Grace Blackwell and Vera Rubin systems.&lt;/p&gt;
&lt;p&gt;Microsoft and Anthropic are also expanding their existing partnership to provide broader access to Claude for businesses. Customers of Microsoft Azure AI Foundry will be able to access Anthropic’s frontier Claude models including Claude Sonnet 4.5, Claude Opus 4.1 and Claude Haiku 4.5. This partnership will make Claude the only frontier LLM model available on all three of the world’s most prominent cloud services. Azure customers will gain expanded choice in models and access to new Claude-specific capabilities.&lt;/p&gt;
&lt;p&gt;Microsoft has also committed to continuing access for Claude across Microsoft’s Copilot family, including GitHub Copilot and Copilot Studio.&lt;/p&gt;
&lt;p&gt;As part of the partnership, NVIDIA and Microsoft are committing to invest up to $10 billion and up to $5 billion respectively in Anthropic.&lt;/p&gt;
&lt;p&gt;Anthropic cofounder and CEO Dario Amodei, Microsoft Chairman and CEO Satya Nadella, and NVIDIA founder and CEO Jensen Huang gathered to discuss the new partnerships:&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Today’s announcement was published simultaneously on the Microsoft, NVIDIA and Anthropic newsrooms.&lt;/em&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/nvidia-and-company-name-partnership-lockup-h-on-dark-1280x680-r5-1.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Today, Microsoft, NVIDIA and Anthropic announced new strategic partnerships. Anthropic is scaling its rapidly growing Claude AI model on Microsoft Azure, powered by NVIDIA, which will broaden access to Claude and provide Azure enterprise customers with expanded model choice and new capabilities. Anthropic has committed to purchase $30 billion of Azure compute capacity and to contract additional compute capacity up to 1 gigawatt.&lt;/p&gt;
&lt;p&gt;For the first time, NVIDIA and Anthropic are establishing a deep technology partnership to support Anthropic’s future growth. Anthropic and NVIDIA will collaborate on design and engineering, with the goal of optimizing Anthropic models for the best possible performance, efficiency and TCO, and optimizing future NVIDIA architectures for Anthropic workloads. Anthropic’s compute commitment will initially be up to 1 gigawatt of compute capacity with NVIDIA Grace Blackwell and Vera Rubin systems.&lt;/p&gt;
&lt;p&gt;Microsoft and Anthropic are also expanding their existing partnership to provide broader access to Claude for businesses. Customers of Microsoft Azure AI Foundry will be able to access Anthropic’s frontier Claude models including Claude Sonnet 4.5, Claude Opus 4.1 and Claude Haiku 4.5. This partnership will make Claude the only frontier LLM model available on all three of the world’s most prominent cloud services. Azure customers will gain expanded choice in models and access to new Claude-specific capabilities.&lt;/p&gt;
&lt;p&gt;Microsoft has also committed to continuing access for Claude across Microsoft’s Copilot family, including GitHub Copilot and Copilot Studio.&lt;/p&gt;
&lt;p&gt;As part of the partnership, NVIDIA and Microsoft are committing to invest up to $10 billion and up to $5 billion respectively in Anthropic.&lt;/p&gt;
&lt;p&gt;Anthropic cofounder and CEO Dario Amodei, Microsoft Chairman and CEO Satya Nadella, and NVIDIA founder and CEO Jensen Huang gathered to discuss the new partnerships:&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Today’s announcement was published simultaneously on the Microsoft, NVIDIA and Anthropic newsrooms.&lt;/em&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/microsoft-nvidia-anthropic-announce-partnership/</guid><pubDate>Tue, 18 Nov 2025 15:00:00 +0000</pubDate></item><item><title>[NEW] Franklin Templeton &amp; Wand AI bring agentic AI to asset management (AI News)</title><link>https://www.artificialintelligence-news.com/news/franklin-templeton-wand-ai-bring-agentic-ai-to-asset-management/</link><description>&lt;p&gt;Firms in the asset management industry are turning increasingly to generative and agentic AI to streamline operations, improve decision-making, and uncover new sources of alpha (the measure of an investment strategy’s ability to outperform the market after accounting for risk). The trend is continuing with the latest partnership between Franklin Templeton and Wand AI, marking a shift toward more autonomous, data-driven investment processes.&lt;/p&gt;&lt;p&gt;Franklin Resources, operating as Franklin Templeton, has entered into a strategic partnership with enterprise AI platform, Wand AI, to begin the enterprise deployment of agentic AI in Franklin Templeton’s worldwide platform. Wand’s Autonomous Workforce and Agent Management technologies have enabled Franklin to implement agentic AI at scale, accelerating data-driven decision-making in its investment processes.&lt;/p&gt;&lt;p&gt;The collaboration has moved from initial small-scale pilot programmes to fully operational AI systems, strengthening the partnership between the two companies. The first implementations concentrated on high-value applications of AI in Franklin Templeton’s investment teams, but now both have plans to mass-deploy intelligent agents in various departments.&lt;/p&gt;&lt;p&gt;The company plans to extend the use of Wand AI’s intelligent agent in 2026, a move designed to drive digital transformation in the organisation and enhance investment research.&lt;/p&gt;&lt;p&gt;Franklin hopes to ensure AI systems are managed responsibly under strict oversight, compliance, and risk control, therefore maintaining trust and transparency. Vasundhara Chetluru, Head of AI Platform at Franklin Templeton, said, “With strong governance in place, we are demonstrating that AI can deliver secure, scalable, and measurable value.”&lt;/p&gt;&lt;p&gt;Rotem Alaluf, CEO of Wand AI, commented on the company’s AI vision, saying its mission is to “elevate AI from experimental technology to a fully integrated, adaptive workforce that drives enterprise-wide transformation and delivers significant business impact.”&lt;/p&gt;&lt;p&gt;Alaluf said AI agents can “seamlessly collaborate with human teams and operate at scale in complex, highly regulated environments to achieve transformative results,” but only when these are “properly governed, orchestrated, and deployed as a unified agentic workforce.”&lt;/p&gt;&lt;h2&gt;AI takes centre stage in asset management&lt;/h2&gt;&lt;p&gt;Other companies in the sector are also going all-in on AI.&amp;nbsp;Goldman Sachs has implemented AI at scale, with CEO, David Solomon, pinpointing the technology as a key force in economic growth. He is on the record as saying the opportunity presented by AI is “enormous.”&lt;/p&gt;&lt;p&gt;According to the Goldman Sachs report, “AI: In a Bubble?”, the company estimates that generative AI could create US $20 trillion of economic value in the long term. The report suggests AI has the capacity to create up to a 15% uplift in US labour productivity, if adopted at scale.&lt;/p&gt;&lt;p&gt;In June 2025, Goldman Sachs (GS) expanded its use of AI by launching a generative-AI assistant inside the firm, joining an increasing list of big banks that were already using the technology for operations.&lt;/p&gt;&lt;p&gt;The GS AI assistant was designed to help with tasks including drafting initial content, completing data analysis, and summarising complex documents. This has improved productivity in teams, freeing thousands of employees to prioritise higher-value strategic work, the bank says.&lt;/p&gt;&lt;p&gt;Such moves signal a shift away from AI niche-use cases and pilot projects to border enterprise deployments in major institutions, aimed at enhancing productivity and operational support.&lt;/p&gt;&lt;p&gt;While David Solomon acknowledges that AI presents an “enormous” opportunity, he has emphasised that there will be “winners and losers.” Some capital investments will not yield return, according to Solomon, which is why he says clients must be diligent in their AI investments.&lt;/p&gt;&lt;p&gt;Solomon has also noted how technology has already transformed the composition of the GS workforce make-up over the last twenty-five years. Today, the bank employs 13,000 engineers, illustrating the change in job functions over time. Rather than roles disappearing with technological advancement, Solomon believes economies and workforces adapt to change. “At the end of the day, we have an incredibly flexible, nimble economy. We have a great ability to adapt and adjust,” he said.&lt;/p&gt;&lt;p&gt;“Yes, there will be job functions that shift and change, but I’m excited about it. If you take a three-to-five-year view, it’s giving us more capacity to invest in our business,” he said.&lt;/p&gt;&lt;p&gt;Goldman Sachs and Franklin Temleton are part of a wider trend of financial institutions accelerating AI adoption. Solomon said, “I can’t find a CEO that I’m talking to, in any industry, that is not focused on how they can re-imagine and automate processes in their business to create operating efficiency and productivity.”&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “Trading Floor at the New York Stock Exchange during the Zendesk IPO” by Scott Beale is licensed under CC BY-NC-ND 2.0)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Firms in the asset management industry are turning increasingly to generative and agentic AI to streamline operations, improve decision-making, and uncover new sources of alpha (the measure of an investment strategy’s ability to outperform the market after accounting for risk). The trend is continuing with the latest partnership between Franklin Templeton and Wand AI, marking a shift toward more autonomous, data-driven investment processes.&lt;/p&gt;&lt;p&gt;Franklin Resources, operating as Franklin Templeton, has entered into a strategic partnership with enterprise AI platform, Wand AI, to begin the enterprise deployment of agentic AI in Franklin Templeton’s worldwide platform. Wand’s Autonomous Workforce and Agent Management technologies have enabled Franklin to implement agentic AI at scale, accelerating data-driven decision-making in its investment processes.&lt;/p&gt;&lt;p&gt;The collaboration has moved from initial small-scale pilot programmes to fully operational AI systems, strengthening the partnership between the two companies. The first implementations concentrated on high-value applications of AI in Franklin Templeton’s investment teams, but now both have plans to mass-deploy intelligent agents in various departments.&lt;/p&gt;&lt;p&gt;The company plans to extend the use of Wand AI’s intelligent agent in 2026, a move designed to drive digital transformation in the organisation and enhance investment research.&lt;/p&gt;&lt;p&gt;Franklin hopes to ensure AI systems are managed responsibly under strict oversight, compliance, and risk control, therefore maintaining trust and transparency. Vasundhara Chetluru, Head of AI Platform at Franklin Templeton, said, “With strong governance in place, we are demonstrating that AI can deliver secure, scalable, and measurable value.”&lt;/p&gt;&lt;p&gt;Rotem Alaluf, CEO of Wand AI, commented on the company’s AI vision, saying its mission is to “elevate AI from experimental technology to a fully integrated, adaptive workforce that drives enterprise-wide transformation and delivers significant business impact.”&lt;/p&gt;&lt;p&gt;Alaluf said AI agents can “seamlessly collaborate with human teams and operate at scale in complex, highly regulated environments to achieve transformative results,” but only when these are “properly governed, orchestrated, and deployed as a unified agentic workforce.”&lt;/p&gt;&lt;h2&gt;AI takes centre stage in asset management&lt;/h2&gt;&lt;p&gt;Other companies in the sector are also going all-in on AI.&amp;nbsp;Goldman Sachs has implemented AI at scale, with CEO, David Solomon, pinpointing the technology as a key force in economic growth. He is on the record as saying the opportunity presented by AI is “enormous.”&lt;/p&gt;&lt;p&gt;According to the Goldman Sachs report, “AI: In a Bubble?”, the company estimates that generative AI could create US $20 trillion of economic value in the long term. The report suggests AI has the capacity to create up to a 15% uplift in US labour productivity, if adopted at scale.&lt;/p&gt;&lt;p&gt;In June 2025, Goldman Sachs (GS) expanded its use of AI by launching a generative-AI assistant inside the firm, joining an increasing list of big banks that were already using the technology for operations.&lt;/p&gt;&lt;p&gt;The GS AI assistant was designed to help with tasks including drafting initial content, completing data analysis, and summarising complex documents. This has improved productivity in teams, freeing thousands of employees to prioritise higher-value strategic work, the bank says.&lt;/p&gt;&lt;p&gt;Such moves signal a shift away from AI niche-use cases and pilot projects to border enterprise deployments in major institutions, aimed at enhancing productivity and operational support.&lt;/p&gt;&lt;p&gt;While David Solomon acknowledges that AI presents an “enormous” opportunity, he has emphasised that there will be “winners and losers.” Some capital investments will not yield return, according to Solomon, which is why he says clients must be diligent in their AI investments.&lt;/p&gt;&lt;p&gt;Solomon has also noted how technology has already transformed the composition of the GS workforce make-up over the last twenty-five years. Today, the bank employs 13,000 engineers, illustrating the change in job functions over time. Rather than roles disappearing with technological advancement, Solomon believes economies and workforces adapt to change. “At the end of the day, we have an incredibly flexible, nimble economy. We have a great ability to adapt and adjust,” he said.&lt;/p&gt;&lt;p&gt;“Yes, there will be job functions that shift and change, but I’m excited about it. If you take a three-to-five-year view, it’s giving us more capacity to invest in our business,” he said.&lt;/p&gt;&lt;p&gt;Goldman Sachs and Franklin Temleton are part of a wider trend of financial institutions accelerating AI adoption. Solomon said, “I can’t find a CEO that I’m talking to, in any industry, that is not focused on how they can re-imagine and automate processes in their business to create operating efficiency and productivity.”&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “Trading Floor at the New York Stock Exchange during the Zendesk IPO” by Scott Beale is licensed under CC BY-NC-ND 2.0)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/franklin-templeton-wand-ai-bring-agentic-ai-to-asset-management/</guid><pubDate>Tue, 18 Nov 2025 15:09:52 +0000</pubDate></item><item><title>[NEW] Generative UI: A rich, custom, visual interactive user experience for any prompt (The latest research from Google)</title><link>https://research.google/blog/generative-ui-a-rich-custom-visual-interactive-user-experience-for-any-prompt/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Generative UI is a powerful capability in which an AI model generates not only content but an entire user experience. Today we introduce a novel implementation of generative UI, which dynamically creates immersive visual experiences and interactive interfaces — such as web pages, games, tools, and applications — that are automatically designed and fully customized in response to any question, instruction, or prompt. These prompts can be as simple as a single word, or as long as needed for detailed instructions. These new types of interfaces are markedly different from the static, predefined interfaces in which AI models typically render content.&lt;/p&gt;&lt;p&gt;In our new paper, “Generative UI: LLMs are Effective UI Generators”, we describe the core principles that enabled our implementation of generative UI and demonstrate the effective viability of this new paradigm. Our evaluations indicate that, when ignoring generation speed, the interfaces from our generative UI implementations are strongly preferred by human raters compared to standard LLM outputs. This work represents a first step toward fully AI-generated user experiences, where users automatically get dynamic interfaces tailored to their needs, rather than having to select from an existing catalog of applications.&lt;/p&gt;&lt;p&gt;Our research on generative UI, also referred to as generative interfaces, comes to life today in the Gemini app through an experiment called dynamic view and in AI Mode in Google Search.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Generative UI is a powerful capability in which an AI model generates not only content but an entire user experience. Today we introduce a novel implementation of generative UI, which dynamically creates immersive visual experiences and interactive interfaces — such as web pages, games, tools, and applications — that are automatically designed and fully customized in response to any question, instruction, or prompt. These prompts can be as simple as a single word, or as long as needed for detailed instructions. These new types of interfaces are markedly different from the static, predefined interfaces in which AI models typically render content.&lt;/p&gt;&lt;p&gt;In our new paper, “Generative UI: LLMs are Effective UI Generators”, we describe the core principles that enabled our implementation of generative UI and demonstrate the effective viability of this new paradigm. Our evaluations indicate that, when ignoring generation speed, the interfaces from our generative UI implementations are strongly preferred by human raters compared to standard LLM outputs. This work represents a first step toward fully AI-generated user experiences, where users automatically get dynamic interfaces tailored to their needs, rather than having to select from an existing catalog of applications.&lt;/p&gt;&lt;p&gt;Our research on generative UI, also referred to as generative interfaces, comes to life today in the Gemini app through an experiment called dynamic view and in AI Mode in Google Search.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/generative-ui-a-rich-custom-visual-interactive-user-experience-for-any-prompt/</guid><pubDate>Tue, 18 Nov 2025 16:00:00 +0000</pubDate></item><item><title>[NEW] Writer's AI agents can actually do your work—not just chat about it (AI | VentureBeat)</title><link>https://venturebeat.com/ai/writers-ai-agents-can-actually-do-your-work-not-just-chat-about-it</link><description>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://writer.com/"&gt;&lt;u&gt;Writer&lt;/u&gt;&lt;/a&gt;, a San Francisco-based artificial intelligence startup, is launching a unified AI agent platform designed to let any employee automate complex business workflows without writing code — a capability the company says distinguishes it from consumer-oriented tools like &lt;a href="https://copilot.microsoft.com/"&gt;&lt;u&gt;Microsoft Copilot&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://chatgpt.com/"&gt;&lt;u&gt;ChatGPT&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The platform, called &lt;a href="https://writer.com/agents/"&gt;&lt;u&gt;Writer Agent&lt;/u&gt;&lt;/a&gt;, combines chat-based assistance with autonomous task execution in a single interface. Starting Tuesday, enterprise customers can use natural language to instruct the AI to create presentations, analyze financial data, generate marketing campaigns, or coordinate across multiple business systems like Salesforce, Slack, and Google Workspace—then save those workflows as reusable &amp;quot;Playbooks&amp;quot; that run automatically on schedules.&lt;/p&gt;&lt;p&gt;The announcement comes as enterprises struggle to move AI initiatives beyond pilot programs into production at scale. Writer CEO May Habib has been outspoken about this challenge, recently revealing that 42% of Fortune 500 executives surveyed by her company said AI is &amp;quot;&lt;a href="https://venturebeat.com/ai/ai-is-tearing-companies-apart-writer-ai-ceo-slams-fortune-500-leaders-for"&gt;&lt;u&gt;tearing their company apart&lt;/u&gt;&lt;/a&gt;&amp;quot; due to coordination failures between departments.&lt;/p&gt;&lt;p&gt;&amp;quot;We&amp;#x27;re delivering an agent interface that is both incredibly powerful and radically simple to transform individual productivity into organizational impact,&amp;quot; Habib said in a statement. &amp;quot;Writer Agent is the difference between a single sales rep asking a chatbot to write an outreach email and an enterprise ensuring that 1,000 reps are all sending on-brand, compliant, and contextually-aware messages to target accounts.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How Writer is putting workflow automation in the hands of non-technical workers&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The platform&amp;#x27;s core innovation centers on making workflow automation accessible to non-technical employees—what Writer executives call &amp;quot;democratizing who gets to be a builder.&amp;quot;&lt;/p&gt;&lt;p&gt;In an exclusive interview with VentureBeat, Doris Jwo, Writer&amp;#x27;s director of product management, demonstrated how the system works: A user types a request in plain English — for example, &amp;quot;Create a two-page partnership proposal between [Company A] and [Company B], make it a branded deck, include impact metrics and partnership tiers.&amp;quot;&lt;/p&gt;&lt;p&gt;The AI agent then breaks down that request into discrete steps, conducts web research, generates graphics and charts on the fly, creates individual slides with sourced information, and assembles a complete presentation. The entire process, which might take an employee hours or days, can be completed in 10-12 minutes.&lt;/p&gt;&lt;p&gt;&amp;quot;The agent basically looks at the request, breaks it down, does research, understands what pieces it needs, creates a detailed plan at a step-by-step level,&amp;quot; Jwo explained during a product demonstration. &amp;quot;It might say, &amp;#x27;I need to do web research,&amp;#x27; or &amp;#x27;This user needs information from Gong or Slack,&amp;#x27; and it reaches out to those connectors, grabs the data, and executes the plan.&amp;quot;&lt;/p&gt;&lt;p&gt;Crucially, users can save these multi-step processes as Playbooks—reusable templates that colleagues can deploy with a single click. Routines allow those Playbooks to run automatically at scheduled intervals, essentially putting knowledge work &amp;quot;on autopilot.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Security and compliance controls: Writer&amp;#x27;s answer to enterprise IT concerns&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Writer positions these enterprise-focused controls as a key differentiator from competitors. While &lt;a href="https://microsoft.com/"&gt;&lt;u&gt;Microsoft&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://openai.com/"&gt;&lt;u&gt;OpenAI&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://www.anthropic.com/"&gt;&lt;u&gt;Anthropic&lt;/u&gt;&lt;/a&gt; offer powerful AI capabilities, Writer&amp;#x27;s executives argue those tools weren&amp;#x27;t designed from the ground up for the security, compliance, and governance requirements of large regulated organizations.&lt;/p&gt;&lt;p&gt;&amp;quot;All of the products you mentioned are great products, but even Copilot is very much focused on personal productivity—summarizing email, for example, which is important, but that&amp;#x27;s not the component we&amp;#x27;re focusing on,&amp;quot; said Matan-Paul Shetrit, Writer&amp;#x27;s director of product management, in an exclusive interview with VentureBeat.&lt;/p&gt;&lt;p&gt;Shetrit emphasized Writer&amp;#x27;s &amp;quot;trust, security, and interoperability&amp;quot; approach. IT administrators can granularly control what the AI can access — for instance, preventing market research agents from mentioning competitors, or restricting which employees can use web search capabilities. All activity is logged with detailed audit trails showing exactly what data the agent touched and what actions it took.&lt;/p&gt;&lt;p&gt;&amp;quot;These fine-grained controls are what make products enterprise-ready,&amp;quot; Shetrit said. &amp;quot;We can deploy to tens of thousands or hundreds of thousands of employees while maintaining the security and guardrails you need for that scale.&amp;quot;&lt;/p&gt;&lt;p&gt;This architecture reflects &lt;a href="https://writer.com/company/about/"&gt;&lt;u&gt;Writer&amp;#x27;s origin story&lt;/u&gt;&lt;/a&gt;. Unlike OpenAI or Anthropic, which started as research labs and later added enterprise offerings, Writer has targeted Fortune 500 companies since its 2020 founding. &amp;quot;We&amp;#x27;re not a research lab that went to consumer and is dabbling in enterprise,&amp;quot; Shetrit said. &amp;quot;We are first and foremost targeting the Global 2000 and Fortune 500, and our research is in service of these customers&amp;#x27; needs.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Inside Writer&amp;#x27;s strategy to connect AI agents across enterprise software systems&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;A critical technical component is Writer&amp;#x27;s approach to system integrations. The platform includes pre-built connectors to more than a dozen enterprise applications—&lt;a href="https://workspace.google.com/lp/business/?utm_source=google&amp;amp;utm_medium=cpc&amp;amp;utm_campaign=1710046-Workspace-DR-NA-US-en-Google-BKWS-EXA-na&amp;amp;utm_content=c-Hybrid+%7C+BKWS+-+EXA+%7C+Txt-Google+Workspace-Core-346911454270&amp;amp;utm_term=google%20workspace&amp;amp;gclsrc=aw.ds&amp;amp;gad_source=1&amp;amp;gad_campaignid=20159848966&amp;amp;gclid=CjwKCAiAz_DIBhBJEiwAVH2XwDbhidrT22spa5fU8uNyySir49xeTOAji42tQEy7zvzTZpUAL4TFgRoCLz8QAvD_BwE"&gt;&lt;u&gt;Google Workspace&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.microsoft.com/en-us/microsoft-365"&gt;&lt;u&gt;Microsoft 365&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.snowflake.com/en/"&gt;&lt;u&gt;Snowflake&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://asana.com/"&gt;&lt;u&gt;Asana&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://slack.com/"&gt;&lt;u&gt;Slack&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.gong.io/"&gt;&lt;u&gt;Gong&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.hubspot.com"&gt;&lt;u&gt;HubSpot&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.atlassian.com/"&gt;&lt;u&gt;Atlassian&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.databricks.com/"&gt;&lt;u&gt;Databricks&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://pitchbook.com/"&gt;&lt;u&gt;PitchBook&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://www.factset.com/"&gt;&lt;u&gt;FactSet&lt;/u&gt;&lt;/a&gt;—allowing the AI to retrieve information and take actions across those systems.&lt;/p&gt;&lt;p&gt;Writer built these connectors using the &lt;a href="https://www.anthropic.com/news/model-context-protocol"&gt;&lt;u&gt;Model Context Protocol (MCP)&lt;/u&gt;&lt;/a&gt;, an emerging standard for AI system integrations, but added what Shetrit described as an &amp;quot;enterprise-ready&amp;quot; layer on top.&lt;/p&gt;&lt;p&gt;&amp;quot;We took a first-principle approach of: You have this MCP connector infrastructure—how do you build it in a way that&amp;#x27;s enterprise-ready?&amp;quot; Shetrit explained. &amp;quot;What we have today in the industry is definitely not it.&amp;quot;&lt;/p&gt;&lt;p&gt;The system can write and execute code on the fly to handle unexpected scenarios. If a user uploads an unfamiliar file format, for instance, the agent will generate code to extract and process the text without requiring a human to intervene.&lt;/p&gt;&lt;p&gt;Jwo demonstrated this capability with a daily workflow she runs: Every morning at 10 a.m., a Routine automatically summarizes her Google Calendar meetings, identifies external participants, finds their LinkedIn profiles, and sends the summary to her via Slack — all without her involvement.&lt;/p&gt;&lt;p&gt;&amp;quot;This was pretty simple, but you can imagine for a salesperson it might say, &amp;#x27;At the end of the day, wrap up a summary of all the calls I had, send me action items, post it to the account-specific Slack channel, and tag these folks so they can accomplish those workflows,&amp;#x27;&amp;quot; Jwo said. &amp;quot;That can run continuously each day, each week, or on demand.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;From mortgage lenders to CPG brands: Real-world AI agent use cases across industries&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The platform is attracting customers across multiple industries. &lt;a href="https://www.newamericanfunding.com/"&gt;&lt;u&gt;New American Funding&lt;/u&gt;&lt;/a&gt;, a mortgage lender, uses Writer Agent to automate marketing workflows. Senior Content Marketing Manager Karen Rodriguez uploads Asana project tickets with creative briefs, and the AI executes tasks like updating email campaigns or transforming articles into social media carousels, video scripts, and captions.&lt;/p&gt;&lt;p&gt;Other use cases span financial services teams creating investment dashboards with &lt;a href="https://pitchbook.com/"&gt;&lt;u&gt;PitchBook&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.factset.com/"&gt;&lt;u&gt;FactSet&lt;/u&gt;&lt;/a&gt; data, consumer packaged goods companies brainstorming new product lines based on social media trends, and marketing teams generating partnership presentations with branded assets.&lt;/p&gt;&lt;p&gt;Writer has added customers including &lt;a href="https://www.tiktok.com/en/"&gt;&lt;u&gt;TikTok&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.cmcsa.com/"&gt;&lt;u&gt;Comcast&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.keurigdrpepper.com/"&gt;&lt;u&gt;Keurig Dr Pepper&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.caa.com/"&gt;&lt;u&gt;CAA&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://www.aptitudehealth.com/"&gt;&lt;u&gt;Aptitude Health&lt;/u&gt;&lt;/a&gt;, joining an existing base that includes &lt;a href="https://www.accenture.com/"&gt;&lt;u&gt;Accenture&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.qualcomm.com/"&gt;&lt;u&gt;Qualcomm&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.uber.com/"&gt;&lt;u&gt;Uber&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://investor.vanguard.com/corporate-portal"&gt;&lt;u&gt;Vanguard&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://www.marriott.com/default.mi"&gt;&lt;u&gt;Marriott&lt;/u&gt;&lt;/a&gt;. The company now serves more than 300 enterprises and has secured over $50 million in signed contracts, with projections to double that to $100 million this year.&lt;/p&gt;&lt;p&gt;The startup&amp;#x27;s net retention rate — a measure of how much existing customers expand their usage — stands at 160%, meaning customers on average increase their spending by 60% after initial contracts. Twenty customers who started with $200,000-$300,000 contracts now spend about $1 million annually, according to company data.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;&amp;#x27;Vibe working&amp;#x27;: Writer&amp;#x27;s vision for AI-powered productivity beyond coding&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Writer executives frame the platform as enabling what they call &amp;quot;vibe working&amp;quot; — a playful reference to the popular term &amp;quot;vibe coding,&amp;quot; which describes AI tools like Cursor that dramatically accelerate software development.&lt;/p&gt;&lt;p&gt;&amp;quot;We used to call it transformation when we took 12 steps and made them nine. That&amp;#x27;s optimizing the world as it is,&amp;quot; Habib said at Writer&amp;#x27;s AI Leaders Forum earlier this month, according to &lt;a href="https://www.forbes.com/sites/stevenwolfepereira/2025/11/08/what-writers-ai-leaders-forum-revealed-about-enterprise-ai/"&gt;&lt;u&gt;Forbes&lt;/u&gt;&lt;/a&gt;. &amp;quot;We can now create a new world. That is the greenfield mindset.&amp;quot;&lt;/p&gt;&lt;p&gt;Shetrit echoed this framing: &amp;quot;Vibe coding is the theme of 2025. Our view is that ‘vibe working’ is the theme of 2026. How do you bring the same productivity gains you&amp;#x27;ve seen with coding agents into the workspace in a way that non-technical users can maximize them?&amp;quot;&lt;/p&gt;&lt;p&gt;The platform is powered by &lt;a href="https://writer.com/engineering/long-context-palmyra-x5/"&gt;&lt;u&gt;Palmyra X5&lt;/u&gt;&lt;/a&gt;, Writer&amp;#x27;s proprietary large language model featuring a one-million-token context window — among the largest commercially available. Writer trained the model for approximately $700,000, a fraction of the estimated $100 million OpenAI spent on GPT-4, by using synthetic data and techniques that halt training when returns diminish.&lt;/p&gt;&lt;p&gt;The model can process one million tokens in about 22 seconds and costs 60 cents per million input tokens and $6 per million output tokens — significantly cheaper than comparable offerings, according to company specifications.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Making AI Decisions Visible: Writer&amp;#x27;s Approach to Trust and Transparency&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;A distinctive aspect of Writer&amp;#x27;s approach is transparency into the AI&amp;#x27;s decision-making process. The interface displays the agent&amp;#x27;s step-by-step reasoning, showing which data sources it accessed, what code it generated, and how it arrived at outputs.&lt;/p&gt;&lt;p&gt;&amp;quot;There&amp;#x27;s a very clear exhibition of how the agent is thinking, what it&amp;#x27;s doing, what it&amp;#x27;s touching,&amp;quot; Shetrit said. &amp;quot;This is important for the end user to trust it, but also important for the IT person or security professional to see what&amp;#x27;s going on.&amp;quot;&lt;/p&gt;&lt;p&gt;This &amp;quot;supervision&amp;quot; model goes beyond simple observability of API calls to encompass what Shetrit described as &amp;quot;a superset of observability&amp;quot; — giving organizations the ability to not just monitor but control AI behavior through policies and permissions.&lt;/p&gt;&lt;p&gt;Session logs capture all agent activity when enabled by administrators, and users can submit feedback on every output to help improve system performance. The platform also emphasizes providing sources and citations for generated content, allowing users to verify information.&lt;/p&gt;&lt;p&gt;&amp;quot;With any sort of chat assistant, agentic or not, trust but verify is really important,&amp;quot; Jwo said. &amp;quot;That&amp;#x27;s part of the pillars of us building this and making it enterprise-grade.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What Writer Agent Costs—and Why It&amp;#x27;s Included in the Base Platform&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Writer is including all the new capabilities—Playbooks, Routines, Connectors, and Personality customization—as part of its core platform without additional charges, according to Jwo.&lt;/p&gt;&lt;p&gt;&amp;quot;This is fully included as part of the Writer platform,&amp;quot; she said. &amp;quot;We&amp;#x27;re not charging additional for using Writer Agent.&amp;quot;&lt;/p&gt;&lt;p&gt;The &amp;quot;Personality&amp;quot; feature allows individual users, teams, or entire organizations to customize the AI&amp;#x27;s communication style, ensuring generated content matches brand voice and tone guidelines. This works alongside company-level controls that enforce terminology and style requirements.&lt;/p&gt;&lt;p&gt;For highly structured, repetitive tasks, Writer also offers a library of more than 100 pre-built agents and an AI Studio for building custom multi-agent systems aligned with specific business use cases.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The Race to Define Enterprise AI: Can Purpose-Built Platforms Beat Tech Giants?&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The launch crystallizes a fundamental tension in how enterprises will adopt AI at scale. While consumer-facing AI tools emphasize individual productivity gains, companies need systems that work reliably across thousands of employees, integrate with existing software infrastructure, maintain regulatory compliance, and deliver measurable business impact.&lt;/p&gt;&lt;p&gt;Writer&amp;#x27;s wager is that these requirements demand purpose-built enterprise platforms rather than consumer tools adapted for business use. The company&amp;#x27;s &lt;a href="https://techcrunch.com/2024/11/12/generative-ai-startup-writer-raises-200m-at-a-1-9b-valuation/"&gt;&lt;u&gt;$1.9 billion valuation&lt;/u&gt;&lt;/a&gt; — achieved in a November 2024 funding round that raised $200 million — suggests investors see merit in this thesis. Backers include &lt;a href="https://www.premjiinvest.com/"&gt;&lt;u&gt;Premji Invest&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://radical.vc/"&gt;&lt;u&gt;Radical Ventures&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.iconiqcapital.com/growth"&gt;&lt;u&gt;ICONIQ Growth&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://salesforceventures.com/"&gt;&lt;u&gt;Salesforce Ventures&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://www.adobe.com/ventures.html"&gt;&lt;u&gt;Adobe Ventures&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Yet the competitive landscape remains formidable. Microsoft and Google command enormous distribution advantages through their existing enterprise software relationships. OpenAI and Anthropic possess research capabilities that have produced breakthrough models. Whether Writer can maintain its differentiation as these giants expand their enterprise offerings will test the startup&amp;#x27;s core premise: that serving Fortune 500 companies from day one creates advantages that research labs turned enterprise vendors cannot easily replicate.&lt;/p&gt;&lt;p&gt;&amp;quot;We&amp;#x27;re entering an era where if you can describe a better way to work, you can build it,&amp;quot; Jwo said. &amp;quot;The new Writer Agent democratizes who gets to be a builder, empowering the operational experts and creative problem-solvers in every department to become the architects of their own transformation. That&amp;#x27;s how you unlock innovation that competitors can&amp;#x27;t replicate.&amp;quot;&lt;/p&gt;&lt;p&gt;The promise is alluring — AI capabilities powerful enough to transform how work gets done, accessible enough for any employee to use, and controlled enough for enterprises to deploy safely at scale. Whether Writer can deliver on that promise at the speed and scale required will determine if its vision of &amp;quot;vibe working&amp;quot; becomes the 2026 theme Shetrit predicts, or just another ambitious attempt to solve enterprise AI&amp;#x27;s execution problem.&lt;/p&gt;&lt;p&gt;But one thing is certain: In a market where 85% of AI initiatives fail to escape pilot purgatory, Writer is betting that the winners won&amp;#x27;t be the companies with the most powerful models—they&amp;#x27;ll be the ones that make those models actually work inside the enterprise.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://writer.com/"&gt;&lt;u&gt;Writer&lt;/u&gt;&lt;/a&gt;, a San Francisco-based artificial intelligence startup, is launching a unified AI agent platform designed to let any employee automate complex business workflows without writing code — a capability the company says distinguishes it from consumer-oriented tools like &lt;a href="https://copilot.microsoft.com/"&gt;&lt;u&gt;Microsoft Copilot&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://chatgpt.com/"&gt;&lt;u&gt;ChatGPT&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The platform, called &lt;a href="https://writer.com/agents/"&gt;&lt;u&gt;Writer Agent&lt;/u&gt;&lt;/a&gt;, combines chat-based assistance with autonomous task execution in a single interface. Starting Tuesday, enterprise customers can use natural language to instruct the AI to create presentations, analyze financial data, generate marketing campaigns, or coordinate across multiple business systems like Salesforce, Slack, and Google Workspace—then save those workflows as reusable &amp;quot;Playbooks&amp;quot; that run automatically on schedules.&lt;/p&gt;&lt;p&gt;The announcement comes as enterprises struggle to move AI initiatives beyond pilot programs into production at scale. Writer CEO May Habib has been outspoken about this challenge, recently revealing that 42% of Fortune 500 executives surveyed by her company said AI is &amp;quot;&lt;a href="https://venturebeat.com/ai/ai-is-tearing-companies-apart-writer-ai-ceo-slams-fortune-500-leaders-for"&gt;&lt;u&gt;tearing their company apart&lt;/u&gt;&lt;/a&gt;&amp;quot; due to coordination failures between departments.&lt;/p&gt;&lt;p&gt;&amp;quot;We&amp;#x27;re delivering an agent interface that is both incredibly powerful and radically simple to transform individual productivity into organizational impact,&amp;quot; Habib said in a statement. &amp;quot;Writer Agent is the difference between a single sales rep asking a chatbot to write an outreach email and an enterprise ensuring that 1,000 reps are all sending on-brand, compliant, and contextually-aware messages to target accounts.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How Writer is putting workflow automation in the hands of non-technical workers&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The platform&amp;#x27;s core innovation centers on making workflow automation accessible to non-technical employees—what Writer executives call &amp;quot;democratizing who gets to be a builder.&amp;quot;&lt;/p&gt;&lt;p&gt;In an exclusive interview with VentureBeat, Doris Jwo, Writer&amp;#x27;s director of product management, demonstrated how the system works: A user types a request in plain English — for example, &amp;quot;Create a two-page partnership proposal between [Company A] and [Company B], make it a branded deck, include impact metrics and partnership tiers.&amp;quot;&lt;/p&gt;&lt;p&gt;The AI agent then breaks down that request into discrete steps, conducts web research, generates graphics and charts on the fly, creates individual slides with sourced information, and assembles a complete presentation. The entire process, which might take an employee hours or days, can be completed in 10-12 minutes.&lt;/p&gt;&lt;p&gt;&amp;quot;The agent basically looks at the request, breaks it down, does research, understands what pieces it needs, creates a detailed plan at a step-by-step level,&amp;quot; Jwo explained during a product demonstration. &amp;quot;It might say, &amp;#x27;I need to do web research,&amp;#x27; or &amp;#x27;This user needs information from Gong or Slack,&amp;#x27; and it reaches out to those connectors, grabs the data, and executes the plan.&amp;quot;&lt;/p&gt;&lt;p&gt;Crucially, users can save these multi-step processes as Playbooks—reusable templates that colleagues can deploy with a single click. Routines allow those Playbooks to run automatically at scheduled intervals, essentially putting knowledge work &amp;quot;on autopilot.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Security and compliance controls: Writer&amp;#x27;s answer to enterprise IT concerns&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Writer positions these enterprise-focused controls as a key differentiator from competitors. While &lt;a href="https://microsoft.com/"&gt;&lt;u&gt;Microsoft&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://openai.com/"&gt;&lt;u&gt;OpenAI&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://www.anthropic.com/"&gt;&lt;u&gt;Anthropic&lt;/u&gt;&lt;/a&gt; offer powerful AI capabilities, Writer&amp;#x27;s executives argue those tools weren&amp;#x27;t designed from the ground up for the security, compliance, and governance requirements of large regulated organizations.&lt;/p&gt;&lt;p&gt;&amp;quot;All of the products you mentioned are great products, but even Copilot is very much focused on personal productivity—summarizing email, for example, which is important, but that&amp;#x27;s not the component we&amp;#x27;re focusing on,&amp;quot; said Matan-Paul Shetrit, Writer&amp;#x27;s director of product management, in an exclusive interview with VentureBeat.&lt;/p&gt;&lt;p&gt;Shetrit emphasized Writer&amp;#x27;s &amp;quot;trust, security, and interoperability&amp;quot; approach. IT administrators can granularly control what the AI can access — for instance, preventing market research agents from mentioning competitors, or restricting which employees can use web search capabilities. All activity is logged with detailed audit trails showing exactly what data the agent touched and what actions it took.&lt;/p&gt;&lt;p&gt;&amp;quot;These fine-grained controls are what make products enterprise-ready,&amp;quot; Shetrit said. &amp;quot;We can deploy to tens of thousands or hundreds of thousands of employees while maintaining the security and guardrails you need for that scale.&amp;quot;&lt;/p&gt;&lt;p&gt;This architecture reflects &lt;a href="https://writer.com/company/about/"&gt;&lt;u&gt;Writer&amp;#x27;s origin story&lt;/u&gt;&lt;/a&gt;. Unlike OpenAI or Anthropic, which started as research labs and later added enterprise offerings, Writer has targeted Fortune 500 companies since its 2020 founding. &amp;quot;We&amp;#x27;re not a research lab that went to consumer and is dabbling in enterprise,&amp;quot; Shetrit said. &amp;quot;We are first and foremost targeting the Global 2000 and Fortune 500, and our research is in service of these customers&amp;#x27; needs.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Inside Writer&amp;#x27;s strategy to connect AI agents across enterprise software systems&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;A critical technical component is Writer&amp;#x27;s approach to system integrations. The platform includes pre-built connectors to more than a dozen enterprise applications—&lt;a href="https://workspace.google.com/lp/business/?utm_source=google&amp;amp;utm_medium=cpc&amp;amp;utm_campaign=1710046-Workspace-DR-NA-US-en-Google-BKWS-EXA-na&amp;amp;utm_content=c-Hybrid+%7C+BKWS+-+EXA+%7C+Txt-Google+Workspace-Core-346911454270&amp;amp;utm_term=google%20workspace&amp;amp;gclsrc=aw.ds&amp;amp;gad_source=1&amp;amp;gad_campaignid=20159848966&amp;amp;gclid=CjwKCAiAz_DIBhBJEiwAVH2XwDbhidrT22spa5fU8uNyySir49xeTOAji42tQEy7zvzTZpUAL4TFgRoCLz8QAvD_BwE"&gt;&lt;u&gt;Google Workspace&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.microsoft.com/en-us/microsoft-365"&gt;&lt;u&gt;Microsoft 365&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.snowflake.com/en/"&gt;&lt;u&gt;Snowflake&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://asana.com/"&gt;&lt;u&gt;Asana&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://slack.com/"&gt;&lt;u&gt;Slack&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.gong.io/"&gt;&lt;u&gt;Gong&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.hubspot.com"&gt;&lt;u&gt;HubSpot&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.atlassian.com/"&gt;&lt;u&gt;Atlassian&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.databricks.com/"&gt;&lt;u&gt;Databricks&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://pitchbook.com/"&gt;&lt;u&gt;PitchBook&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://www.factset.com/"&gt;&lt;u&gt;FactSet&lt;/u&gt;&lt;/a&gt;—allowing the AI to retrieve information and take actions across those systems.&lt;/p&gt;&lt;p&gt;Writer built these connectors using the &lt;a href="https://www.anthropic.com/news/model-context-protocol"&gt;&lt;u&gt;Model Context Protocol (MCP)&lt;/u&gt;&lt;/a&gt;, an emerging standard for AI system integrations, but added what Shetrit described as an &amp;quot;enterprise-ready&amp;quot; layer on top.&lt;/p&gt;&lt;p&gt;&amp;quot;We took a first-principle approach of: You have this MCP connector infrastructure—how do you build it in a way that&amp;#x27;s enterprise-ready?&amp;quot; Shetrit explained. &amp;quot;What we have today in the industry is definitely not it.&amp;quot;&lt;/p&gt;&lt;p&gt;The system can write and execute code on the fly to handle unexpected scenarios. If a user uploads an unfamiliar file format, for instance, the agent will generate code to extract and process the text without requiring a human to intervene.&lt;/p&gt;&lt;p&gt;Jwo demonstrated this capability with a daily workflow she runs: Every morning at 10 a.m., a Routine automatically summarizes her Google Calendar meetings, identifies external participants, finds their LinkedIn profiles, and sends the summary to her via Slack — all without her involvement.&lt;/p&gt;&lt;p&gt;&amp;quot;This was pretty simple, but you can imagine for a salesperson it might say, &amp;#x27;At the end of the day, wrap up a summary of all the calls I had, send me action items, post it to the account-specific Slack channel, and tag these folks so they can accomplish those workflows,&amp;#x27;&amp;quot; Jwo said. &amp;quot;That can run continuously each day, each week, or on demand.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;From mortgage lenders to CPG brands: Real-world AI agent use cases across industries&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The platform is attracting customers across multiple industries. &lt;a href="https://www.newamericanfunding.com/"&gt;&lt;u&gt;New American Funding&lt;/u&gt;&lt;/a&gt;, a mortgage lender, uses Writer Agent to automate marketing workflows. Senior Content Marketing Manager Karen Rodriguez uploads Asana project tickets with creative briefs, and the AI executes tasks like updating email campaigns or transforming articles into social media carousels, video scripts, and captions.&lt;/p&gt;&lt;p&gt;Other use cases span financial services teams creating investment dashboards with &lt;a href="https://pitchbook.com/"&gt;&lt;u&gt;PitchBook&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.factset.com/"&gt;&lt;u&gt;FactSet&lt;/u&gt;&lt;/a&gt; data, consumer packaged goods companies brainstorming new product lines based on social media trends, and marketing teams generating partnership presentations with branded assets.&lt;/p&gt;&lt;p&gt;Writer has added customers including &lt;a href="https://www.tiktok.com/en/"&gt;&lt;u&gt;TikTok&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.cmcsa.com/"&gt;&lt;u&gt;Comcast&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.keurigdrpepper.com/"&gt;&lt;u&gt;Keurig Dr Pepper&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.caa.com/"&gt;&lt;u&gt;CAA&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://www.aptitudehealth.com/"&gt;&lt;u&gt;Aptitude Health&lt;/u&gt;&lt;/a&gt;, joining an existing base that includes &lt;a href="https://www.accenture.com/"&gt;&lt;u&gt;Accenture&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.qualcomm.com/"&gt;&lt;u&gt;Qualcomm&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.uber.com/"&gt;&lt;u&gt;Uber&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://investor.vanguard.com/corporate-portal"&gt;&lt;u&gt;Vanguard&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://www.marriott.com/default.mi"&gt;&lt;u&gt;Marriott&lt;/u&gt;&lt;/a&gt;. The company now serves more than 300 enterprises and has secured over $50 million in signed contracts, with projections to double that to $100 million this year.&lt;/p&gt;&lt;p&gt;The startup&amp;#x27;s net retention rate — a measure of how much existing customers expand their usage — stands at 160%, meaning customers on average increase their spending by 60% after initial contracts. Twenty customers who started with $200,000-$300,000 contracts now spend about $1 million annually, according to company data.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;&amp;#x27;Vibe working&amp;#x27;: Writer&amp;#x27;s vision for AI-powered productivity beyond coding&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Writer executives frame the platform as enabling what they call &amp;quot;vibe working&amp;quot; — a playful reference to the popular term &amp;quot;vibe coding,&amp;quot; which describes AI tools like Cursor that dramatically accelerate software development.&lt;/p&gt;&lt;p&gt;&amp;quot;We used to call it transformation when we took 12 steps and made them nine. That&amp;#x27;s optimizing the world as it is,&amp;quot; Habib said at Writer&amp;#x27;s AI Leaders Forum earlier this month, according to &lt;a href="https://www.forbes.com/sites/stevenwolfepereira/2025/11/08/what-writers-ai-leaders-forum-revealed-about-enterprise-ai/"&gt;&lt;u&gt;Forbes&lt;/u&gt;&lt;/a&gt;. &amp;quot;We can now create a new world. That is the greenfield mindset.&amp;quot;&lt;/p&gt;&lt;p&gt;Shetrit echoed this framing: &amp;quot;Vibe coding is the theme of 2025. Our view is that ‘vibe working’ is the theme of 2026. How do you bring the same productivity gains you&amp;#x27;ve seen with coding agents into the workspace in a way that non-technical users can maximize them?&amp;quot;&lt;/p&gt;&lt;p&gt;The platform is powered by &lt;a href="https://writer.com/engineering/long-context-palmyra-x5/"&gt;&lt;u&gt;Palmyra X5&lt;/u&gt;&lt;/a&gt;, Writer&amp;#x27;s proprietary large language model featuring a one-million-token context window — among the largest commercially available. Writer trained the model for approximately $700,000, a fraction of the estimated $100 million OpenAI spent on GPT-4, by using synthetic data and techniques that halt training when returns diminish.&lt;/p&gt;&lt;p&gt;The model can process one million tokens in about 22 seconds and costs 60 cents per million input tokens and $6 per million output tokens — significantly cheaper than comparable offerings, according to company specifications.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Making AI Decisions Visible: Writer&amp;#x27;s Approach to Trust and Transparency&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;A distinctive aspect of Writer&amp;#x27;s approach is transparency into the AI&amp;#x27;s decision-making process. The interface displays the agent&amp;#x27;s step-by-step reasoning, showing which data sources it accessed, what code it generated, and how it arrived at outputs.&lt;/p&gt;&lt;p&gt;&amp;quot;There&amp;#x27;s a very clear exhibition of how the agent is thinking, what it&amp;#x27;s doing, what it&amp;#x27;s touching,&amp;quot; Shetrit said. &amp;quot;This is important for the end user to trust it, but also important for the IT person or security professional to see what&amp;#x27;s going on.&amp;quot;&lt;/p&gt;&lt;p&gt;This &amp;quot;supervision&amp;quot; model goes beyond simple observability of API calls to encompass what Shetrit described as &amp;quot;a superset of observability&amp;quot; — giving organizations the ability to not just monitor but control AI behavior through policies and permissions.&lt;/p&gt;&lt;p&gt;Session logs capture all agent activity when enabled by administrators, and users can submit feedback on every output to help improve system performance. The platform also emphasizes providing sources and citations for generated content, allowing users to verify information.&lt;/p&gt;&lt;p&gt;&amp;quot;With any sort of chat assistant, agentic or not, trust but verify is really important,&amp;quot; Jwo said. &amp;quot;That&amp;#x27;s part of the pillars of us building this and making it enterprise-grade.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What Writer Agent Costs—and Why It&amp;#x27;s Included in the Base Platform&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Writer is including all the new capabilities—Playbooks, Routines, Connectors, and Personality customization—as part of its core platform without additional charges, according to Jwo.&lt;/p&gt;&lt;p&gt;&amp;quot;This is fully included as part of the Writer platform,&amp;quot; she said. &amp;quot;We&amp;#x27;re not charging additional for using Writer Agent.&amp;quot;&lt;/p&gt;&lt;p&gt;The &amp;quot;Personality&amp;quot; feature allows individual users, teams, or entire organizations to customize the AI&amp;#x27;s communication style, ensuring generated content matches brand voice and tone guidelines. This works alongside company-level controls that enforce terminology and style requirements.&lt;/p&gt;&lt;p&gt;For highly structured, repetitive tasks, Writer also offers a library of more than 100 pre-built agents and an AI Studio for building custom multi-agent systems aligned with specific business use cases.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The Race to Define Enterprise AI: Can Purpose-Built Platforms Beat Tech Giants?&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The launch crystallizes a fundamental tension in how enterprises will adopt AI at scale. While consumer-facing AI tools emphasize individual productivity gains, companies need systems that work reliably across thousands of employees, integrate with existing software infrastructure, maintain regulatory compliance, and deliver measurable business impact.&lt;/p&gt;&lt;p&gt;Writer&amp;#x27;s wager is that these requirements demand purpose-built enterprise platforms rather than consumer tools adapted for business use. The company&amp;#x27;s &lt;a href="https://techcrunch.com/2024/11/12/generative-ai-startup-writer-raises-200m-at-a-1-9b-valuation/"&gt;&lt;u&gt;$1.9 billion valuation&lt;/u&gt;&lt;/a&gt; — achieved in a November 2024 funding round that raised $200 million — suggests investors see merit in this thesis. Backers include &lt;a href="https://www.premjiinvest.com/"&gt;&lt;u&gt;Premji Invest&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://radical.vc/"&gt;&lt;u&gt;Radical Ventures&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.iconiqcapital.com/growth"&gt;&lt;u&gt;ICONIQ Growth&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://salesforceventures.com/"&gt;&lt;u&gt;Salesforce Ventures&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://www.adobe.com/ventures.html"&gt;&lt;u&gt;Adobe Ventures&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Yet the competitive landscape remains formidable. Microsoft and Google command enormous distribution advantages through their existing enterprise software relationships. OpenAI and Anthropic possess research capabilities that have produced breakthrough models. Whether Writer can maintain its differentiation as these giants expand their enterprise offerings will test the startup&amp;#x27;s core premise: that serving Fortune 500 companies from day one creates advantages that research labs turned enterprise vendors cannot easily replicate.&lt;/p&gt;&lt;p&gt;&amp;quot;We&amp;#x27;re entering an era where if you can describe a better way to work, you can build it,&amp;quot; Jwo said. &amp;quot;The new Writer Agent democratizes who gets to be a builder, empowering the operational experts and creative problem-solvers in every department to become the architects of their own transformation. That&amp;#x27;s how you unlock innovation that competitors can&amp;#x27;t replicate.&amp;quot;&lt;/p&gt;&lt;p&gt;The promise is alluring — AI capabilities powerful enough to transform how work gets done, accessible enough for any employee to use, and controlled enough for enterprises to deploy safely at scale. Whether Writer can deliver on that promise at the speed and scale required will determine if its vision of &amp;quot;vibe working&amp;quot; becomes the 2026 theme Shetrit predicts, or just another ambitious attempt to solve enterprise AI&amp;#x27;s execution problem.&lt;/p&gt;&lt;p&gt;But one thing is certain: In a market where 85% of AI initiatives fail to escape pilot purgatory, Writer is betting that the winners won&amp;#x27;t be the companies with the most powerful models—they&amp;#x27;ll be the ones that make those models actually work inside the enterprise.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/writers-ai-agents-can-actually-do-your-work-not-just-chat-about-it</guid><pubDate>Tue, 18 Nov 2025 16:00:00 +0000</pubDate></item><item><title>[NEW] Microsoft remakes Windows for an era of autonomous AI agents (AI | VentureBeat)</title><link>https://venturebeat.com/ai/microsoft-remakes-windows-for-an-era-of-autonomous-ai-agents</link><description>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://www.microsoft.com/en-us/"&gt;&lt;u&gt;Microsoft&lt;/u&gt;&lt;/a&gt; is fundamentally restructuring its Windows operating system to become what executives call the first &amp;quot;agentic OS,&amp;quot; embedding the infrastructure needed for autonomous AI agents to operate securely at enterprise scale — a watershed moment in the evolution of personal computing that positions the 40-year-old platform as the foundation for a new era of human-machine collaboration.&lt;/p&gt;&lt;p&gt;The company announced Tuesday at its &lt;a href="https://ignite.microsoft.com/en-US/home"&gt;&lt;u&gt;Ignite conference&lt;/u&gt;&lt;/a&gt; that it is introducing native agent infrastructure directly into &lt;a href="http://microsoft.com/en-us/windows/windows-11?r=1"&gt;&lt;u&gt;Windows 11&lt;/u&gt;&lt;/a&gt;, allowing AI agents — autonomous software programs that can perform complex, multi-step tasks on behalf of users — to discover tools, execute workflows, and interact with applications through standardized protocols while operating in secure, policy-controlled environments separate from user sessions.&lt;/p&gt;&lt;p&gt;The shift is Microsoft&amp;#x27;s most significant architectural evolution of Windows since the introduction of the modern security model, transforming the operating system from a platform where users manually orchestrate applications into one where they can &amp;quot;simply express your desired outcome, and agents handle the complexity,&amp;quot; according to Pavan Davuluri, President of Windows &amp;amp; Devices at Microsoft.&lt;/p&gt;&lt;p&gt;&amp;quot;Windows 11 starts with this notion of secure by design, secure by default,&amp;quot; Davuluri said in an exclusive interview with VentureBeat. &amp;quot;And a lot of the work that we&amp;#x27;re doing today, when we think about the engagement we have with our customers, the expectations they have with us is making sure we are building upon the fact that Windows is the most secure platform for them and is the most resilient platform as well.&amp;quot;&lt;/p&gt;&lt;p&gt;The announcements arrive as enterprises are &lt;a href="https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai"&gt;&lt;u&gt;experimenting with AI agents&lt;/u&gt;&lt;/a&gt; but struggling with fragmented tooling, security concerns, and lack of centralized management — challenges that Microsoft believes only operating system-level integration can solve. The stakes are enormous: with Windows running on an estimated 1.4 billion devices globally, Microsoft&amp;#x27;s architectural choices will likely shape how organizations deploy autonomous AI systems for years to come.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;New platform primitives create foundation for agent computing&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;At the core of Microsoft&amp;#x27;s vision are three new platform capabilities entering preview that fundamentally change how agents operate on Windows. &lt;a href="https://learn.microsoft.com/en-us/connectors/overview"&gt;&lt;u&gt;Agent Connectors&lt;/u&gt;&lt;/a&gt; provide native support for the &lt;a href="https://learn.microsoft.com/en-us/dynamics365/release-plan/2025wave2/service/dynamics365-customer-service/connect-ai-agents-using-model-context-protocol-server"&gt;&lt;u&gt;Model Context Protocol (MCP)&lt;/u&gt;&lt;/a&gt;, an open standard introduced by Anthropic that allows AI agents to connect with external tools and data sources. Microsoft has built what it calls an &amp;quot;on-device registry&amp;quot; — a secure, manageable repository where developers can register their applications&amp;#x27; capabilities as agent connectors, making them discoverable to any compatible agent on the system.&lt;/p&gt;&lt;p&gt;&amp;quot;These are platform capabilities that then become available to all of our customers,&amp;quot; Davuluri explained, describing how the Windows file system, for example, becomes an agent connector that any MCP-compatible agent can access with user consent. &amp;quot;We&amp;#x27;re able to do this in a fashion that can scale for one but it also allows others to participate in the Windows registry for MCP.&amp;quot;&lt;/p&gt;&lt;p&gt;The architecture introduces an &lt;a href="https://blogs.windows.com/windowsexperience/2025/05/19/securing-the-model-context-protocol-building-a-safer-agentic-future-on-windows/"&gt;&lt;u&gt;MCP proxy layer&lt;/u&gt;&lt;/a&gt; that handles authentication, authorization, and auditing for all communication between agents and connectors. Microsoft is launching with two built-in agent connectors for File Explorer and System Settings, allowing agents to manage files or adjust system configurations like switching between light and dark mode — all with explicit user permission.&lt;/p&gt;&lt;p&gt;&lt;a href="https://support.microsoft.com/en-us/windows/experimental-agentic-features-a25ede8a-e4c2-4841-85a8-44839191dfb3"&gt;&lt;u&gt;Agent Workspace&lt;/u&gt;&lt;/a&gt;, entering private preview, represents perhaps the most significant security innovation. It creates what Microsoft describes as &amp;quot;a contained, policy-controlled, and auditable environment where agents can interact with software&amp;quot; — essentially a parallel desktop session where agents operate with their own distinct identity, completely separate from the user&amp;#x27;s primary session.&lt;/p&gt;&lt;p&gt;&amp;quot;We want to be able to have clarity in the identity of the agent that is operating in the local operating system,&amp;quot; Davuluri said, addressing security concerns about agents accessing sensitive data. &amp;quot;We want that session to be a session that is secure, that is policy control, that is manageable, that has transparency and auditability.&amp;quot;&lt;/p&gt;&lt;p&gt;Each agent workspace runs with minimal privileges by default, accessing only explicitly granted resources. The system maintains detailed audit logs distinguishing agent actions from user actions — critical for enterprises that need to prove compliance and track all changes to systems and data.&lt;/p&gt;&lt;p&gt;&lt;a href="https://adoption.microsoft.com/en-us/ai-agents/agents-in-microsoft-365/"&gt;&lt;u&gt;Windows 365 for Agents&lt;/u&gt;&lt;/a&gt; extends this infrastructure to the cloud, turning Microsoft&amp;#x27;s Cloud PC offering into execution environments for agents. Instead of running on local devices, agents can operate in secure, policy-controlled virtual machines in Azure, enabling what Microsoft calls &amp;quot;computer-using agents&amp;quot; to interact with legacy applications and perform automation tasks at scale without consuming local compute resources.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Taskbar becomes command center for monitoring AI agents at work&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The infrastructure enables significant user interface changes designed to make agents as commonplace as applications. Microsoft is introducing &amp;quot;Ask Copilot on the taskbar,&amp;quot; a unified entry point in preview that combines Microsoft 365 Copilot, agent invocation, and traditional search in a single interface.&lt;/p&gt;&lt;p&gt;Users will be able to invoke agents using &amp;quot;@&amp;quot; mentions directly from the taskbar, then monitor their progress through familiar UI patterns like hover cards, progress badges, and notifications — all while continuing other work. When an agent completes a task or needs input, it surfaces updates through the taskbar without disrupting the user&amp;#x27;s primary workflow.&lt;/p&gt;&lt;p&gt;&amp;quot;We&amp;#x27;ve evolved and created new UX in the taskbar to reflect the unique needs of agents performing background tasks on your behalf,&amp;quot; said Navjot Virk, Corporate Vice President of Windows Experiences, describing features like progress bars and status badges that indicate when agents are working, need approval, or have completed tasks.&lt;/p&gt;&lt;p&gt;The design philosophy, Virk emphasized, centers on user control. &amp;quot;These experiences are designed to be opt in. We want to give customers full control over when and how they engage with copilots and agents.&amp;quot;&lt;/p&gt;&lt;p&gt;For commercial &lt;a href="https://www.microsoft.com/en-us/microsoft-365-copilot"&gt;&lt;u&gt;Microsoft 365 Copilot&lt;/u&gt;&lt;/a&gt; users, the integration goes deeper. Microsoft is embedding Copilot directly into File Explorer, allowing users to ask questions, generate summaries, or draft emails based on document contents without leaving the file management interface. On Copilot+ PCs — devices with neural processing units capable of 40 trillion operations per second — new capabilities include converting any on-screen table into an Excel spreadsheet through the Click to Do feature.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Microsoft bets on open standards against Apple and Google&amp;#x27;s proprietary approaches&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Microsoft&amp;#x27;s embrace of the open &lt;a href="https://www.anthropic.com/news/model-context-protocol"&gt;&lt;u&gt;Model Context Protocol&lt;/u&gt;&lt;/a&gt;, created by Anthropic, marks a strategic bet on openness as enterprises evaluate competing AI platforms from Apple and Google that use proprietary frameworks.&lt;/p&gt;&lt;p&gt;&amp;quot;Windows is an open platform, and by virtue [of being] an open platform, we certainly have the ability to take existing technologies, evolve, harden, adapt those, but we also allow customers to bring their own capabilities to the platform as well,&amp;quot; Davuluri said when asked about competing with &lt;a href="https://www.apple.com/apple-intelligence/"&gt;&lt;u&gt;Apple Intelligence&lt;/u&gt;&lt;/a&gt; and Google&amp;#x27;s &lt;a href="https://www.android.com/enterprise/ai-at-work/"&gt;&lt;u&gt;Android AI for Enterprise&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The company demonstrated this openness with Claude, Anthropic&amp;#x27;s AI assistant, accessing the Windows file system through agent connectors with user consent — one of numerous partnerships Microsoft has secured. Dynamics 365 is using the File Explorer connector to streamline expense reporting, reducing what was previously a 30-minute, dozen-step process to &amp;quot;one sentence with high accuracy,&amp;quot; according to Microsoft&amp;#x27;s blog post. Other early partners include &lt;a href="https://manus.im/"&gt;&lt;u&gt;Manus AI&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://dash.dropbox.com/"&gt;&lt;u&gt;Dropbox Dash&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://roboflow.com/"&gt;&lt;u&gt;Roboflow&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://www.infosys.com/"&gt;&lt;u&gt;Infosys&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&amp;quot;Windows is the platform in which they build upon,&amp;quot; Davuluri said of enterprise customers. &amp;quot;And so our ability to take those existing bodies of work they have, and extend them is the, I think, the least friction way for them to go, learn, adopt, experiment and find ways to [scale].&amp;quot;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Security model enforces strict containment and mandatory user consent&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Microsoft&amp;#x27;s security model for agents adheres to what it calls &amp;quot;&lt;a href="https://learn.microsoft.com/en-us/purview/deploymentmodels/depmod-securebydefault-intro"&gt;&lt;u&gt;secure by default&lt;/u&gt;&lt;/a&gt;&amp;quot; policies aligned with the company&amp;#x27;s broader &lt;a href="https://www.microsoft.com/en-us/trust-center/security/secure-future-initiative"&gt;&lt;u&gt;Secure Future Initiative&lt;/u&gt;&lt;/a&gt;. All agent connectors registered in the on-device registry must meet strict requirements around packaging and identity, with applications properly packaged and signed by trusted sources. Developers must explicitly declare the minimum capabilities their agent connectors require, and agents and connectors run in isolated environments with dedicated agent user accounts, separate from human user accounts. Windows requires explicit user approval when agents first access sensitive resources like files or system settings.&lt;/p&gt;&lt;p&gt;&amp;quot;We give Windows the ability to go deliver on the security expectations, and then it is auditable at the end of the day,&amp;quot; Davuluri said. &amp;quot;You still want an auditability log that looks similar to perhaps what you use in the cloud. And so all three pieces are built into the design and architecture of Agent Workspace.&amp;quot;&lt;/p&gt;&lt;p&gt;For IT administrators, &lt;a href="https://www.microsoft.com/en-us/"&gt;&lt;u&gt;Microsoft&lt;/u&gt;&lt;/a&gt; is introducing management policies through &lt;a href="https://learn.microsoft.com/en-us/intune/intune-service/fundamentals/what-is-intune"&gt;&lt;u&gt;Intune&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://learn.microsoft.com/en-us/windows-server/identity/ad-ds/manage/group-policy/group-policy-overview"&gt;&lt;u&gt;Group Policy&lt;/u&gt;&lt;/a&gt; that allow organizations to enable or disable agent features at device and account levels, set minimum security policy levels, and access event logs enumerating all agent connector invocations and errors. The company emphasized that agents operate with restricted privileges, with minimal permissions by default and access granted only to explicitly approved resources that users can revoke at any time. &lt;/p&gt;&lt;h3&gt;&lt;b&gt;Post-quantum cryptography and recovery tools address emerging and persistent threats&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Beyond agent infrastructure, Microsoft announced significant security and resilience updates addressing both emerging and persistent enterprise challenges. &lt;a href="https://cloud.google.com/security/resources/post-quantum-cryptography?hl=en"&gt;&lt;u&gt;Post-Quantum Cryptography APIs&lt;/u&gt;&lt;/a&gt; are now generally available in Windows, allowing organizations to begin migrating to encryption algorithms designed to withstand future quantum computing attacks that could break today&amp;#x27;s cryptographic standards. Microsoft worked closely with the National Institute of Standards and Technology to implement these algorithms.&lt;/p&gt;&lt;p&gt;&amp;quot;We are introducing post quantum cryptography APIs in Windows,&amp;quot; Davuluri said. &amp;quot;For customers who want to be able to do cryptographic encryption in their workloads, they can start taking advantage of these APIs in Windows for the first time. That is a huge step forward for us when we think about the future of windows.&amp;quot;&lt;/p&gt;&lt;p&gt;Hardware-accelerated &lt;a href="https://learn.microsoft.com/en-us/windows/security/operating-system-security/data-protection/bitlocker/"&gt;&lt;u&gt;BitLocker&lt;/u&gt;&lt;/a&gt; will arrive on new devices starting spring 2026, offloading disk encryption to dedicated silicon for faster performance while providing hardware-level key protection. Sysmon functionality is becoming generally available as part of Windows in early 2026, bringing advanced forensics and threat detection capabilities previously available only as a separate download directly into the operating system&amp;#x27;s event logging system.&lt;/p&gt;&lt;p&gt;The company also detailed progress on its Windows Resiliency Initiative, launched a year ago following the CrowdStrike incident that disrupted 8.5 million Windows devices globally. New recovery capabilities include Quick Machine Recovery with expanded networking support and Autopatch management, allowing IT to remotely fix devices stuck in Windows Recovery Environment. Point-in-time restore entering preview rolls back devices to earlier states to resolve update conflicts or configuration errors, while Cloud rebuild in preview allows IT to remotely rebuild malfunctioning devices by downloading fresh installation media and using Autopilot for zero-touch provisioning.&lt;/p&gt;&lt;p&gt;Microsoft is also raising security requirements for third-party drivers across the Windows ecosystem. Following updated requirements for antivirus drivers effective April 1, 2025, the company is expanding this approach to other driver classes including networking, cameras, USB, printers, and storage — requiring higher certification standards, adding compiler safeguards, and providing more Windows in-box drivers to reduce reliance on third-party kernel-mode code.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Measured rollout reflects enterprise caution around autonomous software&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Microsoft is positioning these updates as essential infrastructure for what it calls &amp;quot;&lt;a href="https://www.microsoft.com/en-us/worklab/work-trend-index/2025-the-year-the-frontier-firm-is-born"&gt;&lt;u&gt;Frontier Firms&lt;/u&gt;&lt;/a&gt;&amp;quot; — organizations that &amp;quot;blend human ingenuity with intelligent systems to deliver real outcomes.&amp;quot; However, the company emphasized a cautious, opt-in approach that reflects enterprise concerns about autonomous software agents.&lt;/p&gt;&lt;p&gt;&amp;quot;The principles we&amp;#x27;re using in designing these new platform capabilities accounts for the reality that we have a very, very broad user base,&amp;quot; Davuluri said. &amp;quot;A lot of the features and capabilities we&amp;#x27;re building are opt in capabilities. And so it is our goal to be able to have users find value in the workflow and meet them.&amp;quot;&lt;/p&gt;&lt;p&gt;Virk emphasized the measured approach: &amp;quot;This is more about meeting customers where they are and then taking them on this journey when they are ready. So there&amp;#x27;s the optionality, but also having support for it. And really important thing is that they should feel comfortable. They should feel secure.&amp;quot;&lt;/p&gt;&lt;p&gt;Microsoft&amp;#x27;s bet is that only operating system-level integration can provide the security, governance, and user experience required for mainstream AI agent adoption. Whether that vision materializes will depend on developer adoption, enterprise comfort with autonomous software, and Microsoft&amp;#x27;s ability to balance innovation with the stability that &lt;a href="https://gizmodo.com/windows-40-year-anniversary-evolving-into-bloated-ai-slop-copilot-2000686932"&gt;&lt;u&gt;40 years of Windows&lt;/u&gt;&lt;/a&gt; customers expect. After four decades of putting users in control of their computers, Windows is now asking them to share that control with machines.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://www.microsoft.com/en-us/"&gt;&lt;u&gt;Microsoft&lt;/u&gt;&lt;/a&gt; is fundamentally restructuring its Windows operating system to become what executives call the first &amp;quot;agentic OS,&amp;quot; embedding the infrastructure needed for autonomous AI agents to operate securely at enterprise scale — a watershed moment in the evolution of personal computing that positions the 40-year-old platform as the foundation for a new era of human-machine collaboration.&lt;/p&gt;&lt;p&gt;The company announced Tuesday at its &lt;a href="https://ignite.microsoft.com/en-US/home"&gt;&lt;u&gt;Ignite conference&lt;/u&gt;&lt;/a&gt; that it is introducing native agent infrastructure directly into &lt;a href="http://microsoft.com/en-us/windows/windows-11?r=1"&gt;&lt;u&gt;Windows 11&lt;/u&gt;&lt;/a&gt;, allowing AI agents — autonomous software programs that can perform complex, multi-step tasks on behalf of users — to discover tools, execute workflows, and interact with applications through standardized protocols while operating in secure, policy-controlled environments separate from user sessions.&lt;/p&gt;&lt;p&gt;The shift is Microsoft&amp;#x27;s most significant architectural evolution of Windows since the introduction of the modern security model, transforming the operating system from a platform where users manually orchestrate applications into one where they can &amp;quot;simply express your desired outcome, and agents handle the complexity,&amp;quot; according to Pavan Davuluri, President of Windows &amp;amp; Devices at Microsoft.&lt;/p&gt;&lt;p&gt;&amp;quot;Windows 11 starts with this notion of secure by design, secure by default,&amp;quot; Davuluri said in an exclusive interview with VentureBeat. &amp;quot;And a lot of the work that we&amp;#x27;re doing today, when we think about the engagement we have with our customers, the expectations they have with us is making sure we are building upon the fact that Windows is the most secure platform for them and is the most resilient platform as well.&amp;quot;&lt;/p&gt;&lt;p&gt;The announcements arrive as enterprises are &lt;a href="https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai"&gt;&lt;u&gt;experimenting with AI agents&lt;/u&gt;&lt;/a&gt; but struggling with fragmented tooling, security concerns, and lack of centralized management — challenges that Microsoft believes only operating system-level integration can solve. The stakes are enormous: with Windows running on an estimated 1.4 billion devices globally, Microsoft&amp;#x27;s architectural choices will likely shape how organizations deploy autonomous AI systems for years to come.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;New platform primitives create foundation for agent computing&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;At the core of Microsoft&amp;#x27;s vision are three new platform capabilities entering preview that fundamentally change how agents operate on Windows. &lt;a href="https://learn.microsoft.com/en-us/connectors/overview"&gt;&lt;u&gt;Agent Connectors&lt;/u&gt;&lt;/a&gt; provide native support for the &lt;a href="https://learn.microsoft.com/en-us/dynamics365/release-plan/2025wave2/service/dynamics365-customer-service/connect-ai-agents-using-model-context-protocol-server"&gt;&lt;u&gt;Model Context Protocol (MCP)&lt;/u&gt;&lt;/a&gt;, an open standard introduced by Anthropic that allows AI agents to connect with external tools and data sources. Microsoft has built what it calls an &amp;quot;on-device registry&amp;quot; — a secure, manageable repository where developers can register their applications&amp;#x27; capabilities as agent connectors, making them discoverable to any compatible agent on the system.&lt;/p&gt;&lt;p&gt;&amp;quot;These are platform capabilities that then become available to all of our customers,&amp;quot; Davuluri explained, describing how the Windows file system, for example, becomes an agent connector that any MCP-compatible agent can access with user consent. &amp;quot;We&amp;#x27;re able to do this in a fashion that can scale for one but it also allows others to participate in the Windows registry for MCP.&amp;quot;&lt;/p&gt;&lt;p&gt;The architecture introduces an &lt;a href="https://blogs.windows.com/windowsexperience/2025/05/19/securing-the-model-context-protocol-building-a-safer-agentic-future-on-windows/"&gt;&lt;u&gt;MCP proxy layer&lt;/u&gt;&lt;/a&gt; that handles authentication, authorization, and auditing for all communication between agents and connectors. Microsoft is launching with two built-in agent connectors for File Explorer and System Settings, allowing agents to manage files or adjust system configurations like switching between light and dark mode — all with explicit user permission.&lt;/p&gt;&lt;p&gt;&lt;a href="https://support.microsoft.com/en-us/windows/experimental-agentic-features-a25ede8a-e4c2-4841-85a8-44839191dfb3"&gt;&lt;u&gt;Agent Workspace&lt;/u&gt;&lt;/a&gt;, entering private preview, represents perhaps the most significant security innovation. It creates what Microsoft describes as &amp;quot;a contained, policy-controlled, and auditable environment where agents can interact with software&amp;quot; — essentially a parallel desktop session where agents operate with their own distinct identity, completely separate from the user&amp;#x27;s primary session.&lt;/p&gt;&lt;p&gt;&amp;quot;We want to be able to have clarity in the identity of the agent that is operating in the local operating system,&amp;quot; Davuluri said, addressing security concerns about agents accessing sensitive data. &amp;quot;We want that session to be a session that is secure, that is policy control, that is manageable, that has transparency and auditability.&amp;quot;&lt;/p&gt;&lt;p&gt;Each agent workspace runs with minimal privileges by default, accessing only explicitly granted resources. The system maintains detailed audit logs distinguishing agent actions from user actions — critical for enterprises that need to prove compliance and track all changes to systems and data.&lt;/p&gt;&lt;p&gt;&lt;a href="https://adoption.microsoft.com/en-us/ai-agents/agents-in-microsoft-365/"&gt;&lt;u&gt;Windows 365 for Agents&lt;/u&gt;&lt;/a&gt; extends this infrastructure to the cloud, turning Microsoft&amp;#x27;s Cloud PC offering into execution environments for agents. Instead of running on local devices, agents can operate in secure, policy-controlled virtual machines in Azure, enabling what Microsoft calls &amp;quot;computer-using agents&amp;quot; to interact with legacy applications and perform automation tasks at scale without consuming local compute resources.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Taskbar becomes command center for monitoring AI agents at work&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The infrastructure enables significant user interface changes designed to make agents as commonplace as applications. Microsoft is introducing &amp;quot;Ask Copilot on the taskbar,&amp;quot; a unified entry point in preview that combines Microsoft 365 Copilot, agent invocation, and traditional search in a single interface.&lt;/p&gt;&lt;p&gt;Users will be able to invoke agents using &amp;quot;@&amp;quot; mentions directly from the taskbar, then monitor their progress through familiar UI patterns like hover cards, progress badges, and notifications — all while continuing other work. When an agent completes a task or needs input, it surfaces updates through the taskbar without disrupting the user&amp;#x27;s primary workflow.&lt;/p&gt;&lt;p&gt;&amp;quot;We&amp;#x27;ve evolved and created new UX in the taskbar to reflect the unique needs of agents performing background tasks on your behalf,&amp;quot; said Navjot Virk, Corporate Vice President of Windows Experiences, describing features like progress bars and status badges that indicate when agents are working, need approval, or have completed tasks.&lt;/p&gt;&lt;p&gt;The design philosophy, Virk emphasized, centers on user control. &amp;quot;These experiences are designed to be opt in. We want to give customers full control over when and how they engage with copilots and agents.&amp;quot;&lt;/p&gt;&lt;p&gt;For commercial &lt;a href="https://www.microsoft.com/en-us/microsoft-365-copilot"&gt;&lt;u&gt;Microsoft 365 Copilot&lt;/u&gt;&lt;/a&gt; users, the integration goes deeper. Microsoft is embedding Copilot directly into File Explorer, allowing users to ask questions, generate summaries, or draft emails based on document contents without leaving the file management interface. On Copilot+ PCs — devices with neural processing units capable of 40 trillion operations per second — new capabilities include converting any on-screen table into an Excel spreadsheet through the Click to Do feature.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Microsoft bets on open standards against Apple and Google&amp;#x27;s proprietary approaches&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Microsoft&amp;#x27;s embrace of the open &lt;a href="https://www.anthropic.com/news/model-context-protocol"&gt;&lt;u&gt;Model Context Protocol&lt;/u&gt;&lt;/a&gt;, created by Anthropic, marks a strategic bet on openness as enterprises evaluate competing AI platforms from Apple and Google that use proprietary frameworks.&lt;/p&gt;&lt;p&gt;&amp;quot;Windows is an open platform, and by virtue [of being] an open platform, we certainly have the ability to take existing technologies, evolve, harden, adapt those, but we also allow customers to bring their own capabilities to the platform as well,&amp;quot; Davuluri said when asked about competing with &lt;a href="https://www.apple.com/apple-intelligence/"&gt;&lt;u&gt;Apple Intelligence&lt;/u&gt;&lt;/a&gt; and Google&amp;#x27;s &lt;a href="https://www.android.com/enterprise/ai-at-work/"&gt;&lt;u&gt;Android AI for Enterprise&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The company demonstrated this openness with Claude, Anthropic&amp;#x27;s AI assistant, accessing the Windows file system through agent connectors with user consent — one of numerous partnerships Microsoft has secured. Dynamics 365 is using the File Explorer connector to streamline expense reporting, reducing what was previously a 30-minute, dozen-step process to &amp;quot;one sentence with high accuracy,&amp;quot; according to Microsoft&amp;#x27;s blog post. Other early partners include &lt;a href="https://manus.im/"&gt;&lt;u&gt;Manus AI&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://dash.dropbox.com/"&gt;&lt;u&gt;Dropbox Dash&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://roboflow.com/"&gt;&lt;u&gt;Roboflow&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://www.infosys.com/"&gt;&lt;u&gt;Infosys&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&amp;quot;Windows is the platform in which they build upon,&amp;quot; Davuluri said of enterprise customers. &amp;quot;And so our ability to take those existing bodies of work they have, and extend them is the, I think, the least friction way for them to go, learn, adopt, experiment and find ways to [scale].&amp;quot;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Security model enforces strict containment and mandatory user consent&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Microsoft&amp;#x27;s security model for agents adheres to what it calls &amp;quot;&lt;a href="https://learn.microsoft.com/en-us/purview/deploymentmodels/depmod-securebydefault-intro"&gt;&lt;u&gt;secure by default&lt;/u&gt;&lt;/a&gt;&amp;quot; policies aligned with the company&amp;#x27;s broader &lt;a href="https://www.microsoft.com/en-us/trust-center/security/secure-future-initiative"&gt;&lt;u&gt;Secure Future Initiative&lt;/u&gt;&lt;/a&gt;. All agent connectors registered in the on-device registry must meet strict requirements around packaging and identity, with applications properly packaged and signed by trusted sources. Developers must explicitly declare the minimum capabilities their agent connectors require, and agents and connectors run in isolated environments with dedicated agent user accounts, separate from human user accounts. Windows requires explicit user approval when agents first access sensitive resources like files or system settings.&lt;/p&gt;&lt;p&gt;&amp;quot;We give Windows the ability to go deliver on the security expectations, and then it is auditable at the end of the day,&amp;quot; Davuluri said. &amp;quot;You still want an auditability log that looks similar to perhaps what you use in the cloud. And so all three pieces are built into the design and architecture of Agent Workspace.&amp;quot;&lt;/p&gt;&lt;p&gt;For IT administrators, &lt;a href="https://www.microsoft.com/en-us/"&gt;&lt;u&gt;Microsoft&lt;/u&gt;&lt;/a&gt; is introducing management policies through &lt;a href="https://learn.microsoft.com/en-us/intune/intune-service/fundamentals/what-is-intune"&gt;&lt;u&gt;Intune&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://learn.microsoft.com/en-us/windows-server/identity/ad-ds/manage/group-policy/group-policy-overview"&gt;&lt;u&gt;Group Policy&lt;/u&gt;&lt;/a&gt; that allow organizations to enable or disable agent features at device and account levels, set minimum security policy levels, and access event logs enumerating all agent connector invocations and errors. The company emphasized that agents operate with restricted privileges, with minimal permissions by default and access granted only to explicitly approved resources that users can revoke at any time. &lt;/p&gt;&lt;h3&gt;&lt;b&gt;Post-quantum cryptography and recovery tools address emerging and persistent threats&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Beyond agent infrastructure, Microsoft announced significant security and resilience updates addressing both emerging and persistent enterprise challenges. &lt;a href="https://cloud.google.com/security/resources/post-quantum-cryptography?hl=en"&gt;&lt;u&gt;Post-Quantum Cryptography APIs&lt;/u&gt;&lt;/a&gt; are now generally available in Windows, allowing organizations to begin migrating to encryption algorithms designed to withstand future quantum computing attacks that could break today&amp;#x27;s cryptographic standards. Microsoft worked closely with the National Institute of Standards and Technology to implement these algorithms.&lt;/p&gt;&lt;p&gt;&amp;quot;We are introducing post quantum cryptography APIs in Windows,&amp;quot; Davuluri said. &amp;quot;For customers who want to be able to do cryptographic encryption in their workloads, they can start taking advantage of these APIs in Windows for the first time. That is a huge step forward for us when we think about the future of windows.&amp;quot;&lt;/p&gt;&lt;p&gt;Hardware-accelerated &lt;a href="https://learn.microsoft.com/en-us/windows/security/operating-system-security/data-protection/bitlocker/"&gt;&lt;u&gt;BitLocker&lt;/u&gt;&lt;/a&gt; will arrive on new devices starting spring 2026, offloading disk encryption to dedicated silicon for faster performance while providing hardware-level key protection. Sysmon functionality is becoming generally available as part of Windows in early 2026, bringing advanced forensics and threat detection capabilities previously available only as a separate download directly into the operating system&amp;#x27;s event logging system.&lt;/p&gt;&lt;p&gt;The company also detailed progress on its Windows Resiliency Initiative, launched a year ago following the CrowdStrike incident that disrupted 8.5 million Windows devices globally. New recovery capabilities include Quick Machine Recovery with expanded networking support and Autopatch management, allowing IT to remotely fix devices stuck in Windows Recovery Environment. Point-in-time restore entering preview rolls back devices to earlier states to resolve update conflicts or configuration errors, while Cloud rebuild in preview allows IT to remotely rebuild malfunctioning devices by downloading fresh installation media and using Autopilot for zero-touch provisioning.&lt;/p&gt;&lt;p&gt;Microsoft is also raising security requirements for third-party drivers across the Windows ecosystem. Following updated requirements for antivirus drivers effective April 1, 2025, the company is expanding this approach to other driver classes including networking, cameras, USB, printers, and storage — requiring higher certification standards, adding compiler safeguards, and providing more Windows in-box drivers to reduce reliance on third-party kernel-mode code.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Measured rollout reflects enterprise caution around autonomous software&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Microsoft is positioning these updates as essential infrastructure for what it calls &amp;quot;&lt;a href="https://www.microsoft.com/en-us/worklab/work-trend-index/2025-the-year-the-frontier-firm-is-born"&gt;&lt;u&gt;Frontier Firms&lt;/u&gt;&lt;/a&gt;&amp;quot; — organizations that &amp;quot;blend human ingenuity with intelligent systems to deliver real outcomes.&amp;quot; However, the company emphasized a cautious, opt-in approach that reflects enterprise concerns about autonomous software agents.&lt;/p&gt;&lt;p&gt;&amp;quot;The principles we&amp;#x27;re using in designing these new platform capabilities accounts for the reality that we have a very, very broad user base,&amp;quot; Davuluri said. &amp;quot;A lot of the features and capabilities we&amp;#x27;re building are opt in capabilities. And so it is our goal to be able to have users find value in the workflow and meet them.&amp;quot;&lt;/p&gt;&lt;p&gt;Virk emphasized the measured approach: &amp;quot;This is more about meeting customers where they are and then taking them on this journey when they are ready. So there&amp;#x27;s the optionality, but also having support for it. And really important thing is that they should feel comfortable. They should feel secure.&amp;quot;&lt;/p&gt;&lt;p&gt;Microsoft&amp;#x27;s bet is that only operating system-level integration can provide the security, governance, and user experience required for mainstream AI agent adoption. Whether that vision materializes will depend on developer adoption, enterprise comfort with autonomous software, and Microsoft&amp;#x27;s ability to balance innovation with the stability that &lt;a href="https://gizmodo.com/windows-40-year-anniversary-evolving-into-bloated-ai-slop-copilot-2000686932"&gt;&lt;u&gt;40 years of Windows&lt;/u&gt;&lt;/a&gt; customers expect. After four decades of putting users in control of their computers, Windows is now asking them to share that control with machines.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/microsoft-remakes-windows-for-an-era-of-autonomous-ai-agents</guid><pubDate>Tue, 18 Nov 2025 16:00:00 +0000</pubDate></item><item><title>[NEW] Google unveils Gemini 3 claiming the lead in math, science, multimodal and agentic AI benchmarks (AI | VentureBeat)</title><link>https://venturebeat.com/ai/google-unveils-gemini-3-claiming-the-lead-in-math-science-multimodal-and</link><description>[unable to retrieve full-text content]&lt;p&gt;After more than a month of rumors and feverish speculation — including &lt;a href="https://polymarket.com/event/gemini-3pt0-released-by"&gt;Polymarket wagering on the release date&lt;/a&gt; — Google today &lt;a href="https://blog.google/products/gemini/gemini-3/"&gt;unveiled Gemini 3&lt;/a&gt;, its newest proprietary frontier model family and the company’s most comprehensive AI release since the Gemini line debuted in 2023. &lt;/p&gt;&lt;p&gt;The models are proprietary (closed-source), available exclusively through Google products, developer platforms, and paid APIs, including &lt;a href="https://aistudio.google.com/"&gt;Google AI Studio&lt;/a&gt;, &lt;a href="https://cloud.google.com/vertex-ai?hl=en"&gt;Vertex AI&lt;/a&gt;, the&lt;a href="https://github.com/google-gemini/gemini-cli"&gt; Gemini command line interface (CLI)&lt;/a&gt; for developers, and third-party integrations across the broader integrated developer environment (IDE) ecosystem.&lt;/p&gt;&lt;p&gt;Gemini 3 arrives as a full portfolio, including:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Gemini 3 Pro:&lt;/b&gt; the flagship frontier model&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Gemini 3 Deep Think: &lt;/b&gt;an enhanced reasoning mode&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Generative interface models powering Visual Layout and Dynamic View&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Gemini Agent&lt;/b&gt; for multi-step task execution&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Gemini 3 engine&lt;/b&gt; embedded in &lt;b&gt;Google Antigravity&lt;/b&gt;, the company’s new agent-first development environment.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&amp;quot;This is the best model in the world, by a crazy wide margin!&amp;quot; wrote&lt;a href="https://x.com/YiTayML/status/1990817918784000420"&gt; Google DeepMind Research Scientist Yi Tay on X&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;Indeed, already, independent AI benchmarking and analysis organization &lt;a href="https://x.com/ArtificialAnlys/status/1990813106478715098"&gt;Artificial Analysis has crowned Gemini 3 Pro the &amp;quot;new leader in AI&amp;quot;&lt;/a&gt; globally, achieving the top score of 73 on the organization&amp;#x27;s index, leaping Google from its former placement of 9th overall with the preceding Gemini 2.5 Pro model, which scored 60 behind OpenAI, Moonshot AI, xAI, Anthropic and MiniMax models. As &lt;a href="https://x.com/ArtificialAnlys/status/1990813109188243599"&gt;Artificial Analysis wrote on X&lt;/a&gt;: &amp;quot;For the first time, Google has the most intelligent model.&amp;quot;&lt;/p&gt;&lt;p&gt;Another independent leaderboard site, LMArena reported that &lt;b&gt;Gemini 3 Pro ranked first in the world across all of its major evaluation tracks&lt;/b&gt;, including text reasoning, vision, coding, and web development. &lt;/p&gt;&lt;p&gt;In a public post, the &lt;a href="https://x.com/arena/status/1990813759938703570"&gt;@arena account on X&lt;/a&gt; said the model surpassed even the newly released (hours old) Grok-4.1, as well as Claude 4.5, and GPT-5-class systems in categories such as math, long-form queries, creative writing, and several occupational benchmarks. &lt;/p&gt;&lt;div&gt;&lt;/div&gt;&lt;p&gt;The post also highlighted the scale of gains over Gemini 2.5 Pro, including a 50-point jump in text Elo, a 70-point increase in vision, and a 280-point rise in web-development tasks. &lt;/p&gt;&lt;p&gt;While these results reflect live community voting and remain preliminary, they signal unusually broad performance improvements across domains where previous Gemini models trailed competitors.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What It Means For Google In the Hotly Competitive AI Race&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The launch represents one of Google’s largest, most tightly coordinated model releases. &lt;/p&gt;&lt;p&gt;Gemini 3 is shipping simultaneously across Google Search, the Gemini app, Google AI Studio, Vertex AI, and a range of developer tools. &lt;/p&gt;&lt;p&gt;Executives emphasized that this integration reflects Google’s control of tensor processing unit (TPU — its homegrown Nvidia GPU rival chips) hardware, data center infrastructure, and consumer products. &lt;/p&gt;&lt;p&gt;According to the company, the Gemini app now has more than 650 million monthly active users, more than 13 million developers build with Google’s AI tools, and more than 2 billion monthly users engage with Gemini-powered AI Overviews in Search.&lt;/p&gt;&lt;p&gt;At the center of the release is a shift toward agentic AI — systems that plan, act, navigate interfaces, and coordinate tools, rather than just generating text. &lt;/p&gt;&lt;p&gt;Gemini 3 is designed to translate high-level instructions into multi-step workflows across devices and applications, with the ability to generate functional interfaces, run tools, and manage complex tasks.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Major Performance Gains Over Gemini 2.5 Pro&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Gemini 3 Pro introduces large gains over Gemini 2.5 Pro across reasoning, mathematics, multimodality, tool use, coding, and long-horizon planning. Google’s benchmark disclosures show substantial improvements in many categories.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Gemini 3 Pro debuted at the top of the LMArena&lt;/b&gt; text-reasoning leaderboard, posting a &lt;b&gt;preliminary Elo score of 1501&lt;/b&gt; based on pre-release community voting — the first LLM to ever cross the 1500 threshold.&lt;/p&gt;&lt;p&gt;That places it above &lt;b&gt;xAI’s newly announced Grok-4.1-thinking model (1484) and Grok-4.1 (1465), &lt;/b&gt;both of which were unveiled just hours earlier, as well as above Gemini 2.5 Pro (1451) and recent Claude Sonnet and Opus releases. &lt;/p&gt;&lt;p&gt;While LMArena covers only text-reasoning performance and the results are labeled preliminary, this ranking positions Gemini 3 Pro as the strongest publicly evaluated model on that benchmark as of its launch day — though not necessarily the top performer in the world across all modalities, tasks, or evaluation suites.&lt;/p&gt;&lt;p&gt;In mathematical and scientific reasoning, Gemini 3 Pro scored 95 percent on AIME 2025 without tools and 100 percent with code execution, compared to 88 percent for its predecessor. &lt;/p&gt;&lt;p&gt;On GPQA Diamond, it reached 91.9 percent, up from 86.4 percent. The model also recorded a major jump on MathArena Apex, reaching 23.4 percent versus 0.5 percent for Gemini 2.5 Pro, and delivered 31.1 percent on ARC-AGI-2 compared to 4.9 percent previously.&lt;/p&gt;&lt;p&gt;Multimodal performance increased across the board. Gemini 3 Pro scored 81 percent on MMMU-Pro, up from 68 percent, and 87.6 percent on Video-MMMU, compared to 83.6 percent. Its result on ScreenSpot-Pro, a key benchmark for agentic computer use, rose from 11.4 percent to 72.7 percent. Document understanding and chart reasoning also improved.&lt;/p&gt;&lt;p&gt;Coding and tool-use performance showed equally significant gains. The model’s LiveCodeBench Pro score reached 2,439, up from 1,775. On Terminal-Bench 2.0 it achieved 54.2 percent versus 32.6 percent previously. SWE-Bench Verified, which measures agentic coding through structured fixes, increased from 59.6 percent to 76.2 percent. The model also posted 85.4 percent on t2-bench, up from 54.9 percent.&lt;/p&gt;&lt;p&gt;Long-context and planning benchmarks indicate more stable multi-step behavior. Gemini 3 achieved 77 percent on MRCR v2 at 128k context (versus 58 percent) and 26.3 percent at 1 million tokens (versus 16.4 percent). Its Vending-Bench 2 score reached $5,478.16, compared to $573.64 for Gemini 2.5 Pro, reflecting stronger consistency during long-running decision processes.&lt;/p&gt;&lt;p&gt;Language understanding scores improved on SimpleQA Verified (72.1 percent versus 54.5 percent), MMLU (91.8 percent versus 89.5 percent), and the FACTS Benchmark Suite (70.5 percent versus 63.4 percent), supporting more reliable fact-based work in regulated sectors.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Generative Interfaces Move Gemini Beyond Text&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Gemini 3 introduces a new class of generative interface capabilities in the consumer-facing Google Search AI Mode and for developers through Google AI Studio.&lt;/p&gt;&lt;p&gt;Visual Layout produces structured, magazine-style pages with images, diagrams, and modules tailored to the query. &lt;/p&gt;&lt;p&gt;Dynamic View generates functional interface components such as calculators, simulations, galleries, and interactive graphs. &lt;/p&gt;&lt;p&gt;These experiences will be available starting today globally in Google Search’s AI Mode, enabling models to surface information in visual, interactive formats beyond static text.&lt;/p&gt;&lt;p&gt;Developers can reproduce similar UI elements through Google AI Studio and the Gemini API, but the full consumer-facing interface types are not available as direct API outputs; instead, developers receive the underlying code or schema to render these components themselves. The branded Visual Layout and Dynamic View formats are therefore specific to Search and not exposed as standalone API features.&lt;/p&gt;&lt;p&gt;Google says the model analyzes user intent to construct the layout best suited to a task. In practice, this includes everything from automatically building diagrams for scientific concepts to generating custom UI components that respond to user input.&lt;/p&gt;&lt;p&gt;Google held a press call the day before the Gemini 3 announcement to brief reporters on the model family, its intended use cases, and how it differed from earlier Gemini releases. The call was led by multiple Google and DeepMind executives who walked through the model’s capabilities and framed Gemini 3 as a step toward more reliable, multi-step agentic systems that can operate across Google’s ecosystem.&lt;/p&gt;&lt;p&gt;During the briefing, speakers emphasized that Gemini 3 was engineered to support more consistent long-horizon reasoning, better tool use, and smoother planning loops than Gemini 2.5 Pro. &lt;/p&gt;&lt;p&gt;One presenter said the model benefits from an architecture that allows it to generate and evaluate multiple hypotheses in parallel, improving reliability on mathematically hard questions and complex procedural tasks. &lt;/p&gt;&lt;p&gt;Another speaker explained that Gemini 3’s improved spatial reasoning enables more robust interaction with interface elements, which supports agentic workflows across screens and applications.&lt;/p&gt;&lt;p&gt;Presenters highlighted growing enterprise adoption, noting strong demand for multimodal analysis, structured document reasoning, and agentic coding tools. They said Gemini 3’s performance on multimodal and scientific benchmarks reflected Google’s focus on grounded, verifiable reasoning. And they discussed Gemini 3&amp;#x27;s safety processes and improvements, including reduced sycophancy, stronger prompt-injection resistance, and a more structured evaluation pipeline guided by &lt;a href="https://deepmind.google/blog/introducing-the-frontier-safety-framework/"&gt;Google’s Frontier Safety Framework&lt;/a&gt; introduced back in 2024.&lt;/p&gt;&lt;p&gt;A portion of the call was dedicated to developer experience. Google described updates to its AI Studio and API that allow developers to control thinking depth, adjust model “resolution,” and combine new grounding tools with URL context and Search. &lt;/p&gt;&lt;p&gt;Demoes showed Gemini 3 generating application interfaces, managing tool sequences, and debugging code in Antigravity, illustrating the model’s shift toward agentic operation rather than single-step generation.&lt;/p&gt;&lt;p&gt;The call positioned Gemini 3 as an upgrade across reasoning, planning, multimodal understanding, and developer workflows, with Google framing these advances as the foundation for its next generation of agent-driven products and enterprise services.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Gemini Agent Introduces Multi-Step Workflow Automation&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Gemini Agent marks Google’s effort to move beyond conversational assistance toward operational AI. The system coordinates multi-step tasks across tools like Gmail, Calendar, Canvas, and live browsing. It reviews inboxes, drafts replies, prepares plans, triages information, and reasons through complex workflows, while requiring user approval before performing sensitive actions.&lt;/p&gt;&lt;p&gt;On a press call with journalists ahead of the release yesterday, Google said the agent is designed to handle multi-turn planning and tool-use sequences with consistency that was not feasible in earlier generations. &lt;/p&gt;&lt;p&gt;It is rolling out first to Google AI Ultra subscribers in the Gemini app.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Google Antigravity and Developer Toolchain Integration&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Antigravity is Google’s new agent-first development environment designed around Gemini 3. Developers collaborate with agents across an editor, terminal, and browser. The system orchestrates full-stack tasks, including code generation, UI prototyping, debugging, live execution, and report generation.&lt;/p&gt;&lt;p&gt;Across the broader developer ecosystem, Google AI Studio now includes a Build mode that automatically wires the right models and APIs to speed up AI-native app creation. Annotations support allows developers to attach prompts to UI elements for faster iteration. Spatial reasoning improvements enable agents to interpret mouse movements, screen annotations, and multi-window layouts to operate computer interfaces more effectively.&lt;/p&gt;&lt;p&gt;Developers also gain new reasoning controls through “thinking level” and “model resolution” parameters in the Gemini API, along with stricter validation of thought signatures for multi-turn consistency. A hosted server-side bash tool supports secure, multi-language code generation and prototyping. Grounding with Google Search and URL context can now be combined to extract structured information for downstream tasks.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Enterprise Impact and Adoption&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Enterprise teams gain multimodal understanding, agentic coding, and long-horizon planning needed for production use cases. The new model unifies analysis of documents, audio, video, workflows, and logs. Improvements in spatial and visual reasoning support robotics, autonomous systems, and scenarios requiring navigation of screens and applications. High-frame-rate video understanding helps developers detect events in fast-moving environments.&lt;/p&gt;&lt;p&gt;Gemini 3’s structured document understanding capabilities support legal review, complex form processing, and regulated workflows. Its ability to generate functional interfaces and prototypes with minimal prompting reduces engineering cycles. In addition, the gains in system reliability, tool-calling stability, and context retention make multi-step planning viable for operations like financial forecasting, customer support automation, supply chain modeling, and predictive maintenance.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Developer and API Pricing&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Google has disclosed initial API pricing for Gemini 3 Pro. &lt;/p&gt;&lt;p&gt;In preview, the model is priced at $2 per million input tokens and $12 per million output tokens for prompts up to 200,000 tokens in Google AI Studio and Vertex AI. For prompts that require more than 200,000 tokens, the input pricing doubles to $2 per 1M tok, while the output rises to $18 per 1M tok.&lt;/p&gt;&lt;p&gt;When compared to the API pricing for other frontier AI models from rival labs, Gemini 3 is priced in the mid-high range, which may impact adoption as cheaper and open-source (permissively licensed) Chinese models &lt;a href="https://x.com/stevehou/status/1990488315351732691"&gt;have increasingly come to be adopted by U.S. startups&lt;/a&gt;. Here&amp;#x27;s how it stacks up:&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Model&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Input (/1M tokens)&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Output (/1M tokens)&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Total Cost&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Source&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;ERNIE 4.5 Turbo&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.11&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.45&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.56&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Blfmc9do4"&gt;Qianfan&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;ERNIE 5.0&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.85&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$3.40&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$4.25&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Blfmc9do4"&gt;Qianfan&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;Qwen3 (Coder ex.)&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.85&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$3.40&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$4.25&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Blfmc9do4"&gt;Qianfan&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;GPT-5.1&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$1.25&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$10.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$11.25&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://openai.com/pricing"&gt;OpenAI&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;Gemini 2.5 Pro (≤200K)&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$1.25&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$10.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$11.25&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://ai.google.dev/gemini-api/docs/pricing"&gt;Google&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Gemini 3 Pro (≤200K)&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;$2.00&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;$12.00&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;$14.00&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://ai.google.dev/gemini-api/docs/pricing"&gt;&lt;b&gt;Google&lt;/b&gt;&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;Gemini 2.5 Pro (&amp;gt;200K)&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$2.50&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$15.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$17.50&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://ai.google.dev/gemini-api/docs/pricing"&gt;Google&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Gemini 3 Pro (&amp;gt;200K)&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;$4.00&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;$18.00&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;$22.00&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://ai.google.dev/gemini-api/docs/pricing"&gt;&lt;b&gt;Google&lt;/b&gt;&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;Grok 4 (0709)&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$3.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$15.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$18.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://x.ai/dev/docs/models"&gt;xAI API&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;Claude Opus 4.1&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$15.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$75.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$90.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://docs.anthropic.com/claude/docs/models-overview"&gt;Anthropic&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Gemini 3 Pro is also available at no charge with rate limits in Google AI Studio for experimentation.&lt;/p&gt;&lt;p&gt;The company has not yet announced pricing for Gemini 3 Deep Think, extended context windows, generative interfaces, or tool invocation. &lt;/p&gt;&lt;p&gt;Enterprises planning deployment at scale will require these details to estimate operational costs.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Multimodal, Visual, and Spatial Reasoning Enhancements&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Gemini 3’s improvements in embodied and spatial reasoning support pointing and trajectory prediction, task progression, and complex screen parsing. These capabilities extend to desktop and mobile environments, enabling agents to interpret screen elements, respond to on-screen context, and unlock new forms of computer-use automation.&lt;/p&gt;&lt;p&gt;The model also delivers improved video reasoning with high-frame-rate understanding for analyzing fast-moving scenes, along with long-context video recall for synthesizing narratives across hours of footage. Google’s examples show the model generating full interactive demo apps directly from prompts, illustrating the depth of multimodal and agentic integration.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Vibe Coding and Agentic Code Generation&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Gemini 3 advances Google’s concept of “vibe coding,” where natural language acts as the primary syntax. The model can translate high-level ideas into full applications with a single prompt, handling multi-step planning, code generation, and visual design. Enterprise partners like Figma, JetBrains, Cursor, Replit, and Cline report stronger instruction following, more stable agentic operation, and better long-context code manipulation compared to prior models.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Rumors and Rumblings&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;In the weeks leading up to the announcement, X became a hub of speculation about Gemini 3. &lt;/p&gt;&lt;p&gt;Well-known accounts such as @slow_developer suggested internal builds were significantly ahead of Gemini 2.5 Pro and likely exceeded competitor performance in reasoning and tool use. Others, including @synthwavedd and @VraserX, noted mixed behavior in early checkpoints but acknowledged Google’s advantage in TPU hardware and training data. &lt;/p&gt;&lt;p&gt;Viral clips from users like @lepadphone and @StijnSmits showed the model generating websites, animations, and UI layouts from single prompts, adding to the momentum.&lt;/p&gt;&lt;p&gt;Prediction markets on Polymarket amplified the speculation. Whale accounts drove the odds of a mid-November release sharply upward, prompting widespread debate about insider activity. A temporary dip during a global Cloudflare outage became a moment of humor and conspiracy before odds surged again.&lt;/p&gt;&lt;p&gt;The key moment came when users including &lt;a href="https://x.com/cheatyyyy/status/1990737403867263183"&gt;@cheatyyyy&lt;/a&gt; shared what appeared to be an internal model-card benchmark table for Gemini 3 Pro. &lt;/p&gt;&lt;p&gt;The image circulated rapidly, with commentary from figures like @deedydas and @kimmonismus arguing the numbers suggested a significant lead. &lt;/p&gt;&lt;p&gt;When Google published the official benchmarks, they matched the leaked table exactly, confirming the document’s authenticity.&lt;/p&gt;&lt;p&gt;By launch day, enthusiasm reached a peak. A brief “Geminiii” post from Sundar Pichai triggered widespread attention, and early testers quickly shared real examples of Gemini 3 generating interfaces, full apps, and complex visual designs. &lt;/p&gt;&lt;p&gt;While some concerns about pricing and efficiency appeared, the dominant sentiment framed the launch as a turning point for Google and a display of its full-stack AI capabilities.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Safety and Evaluation&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Google says Gemini 3 is its most secure model yet, with reduced sycophancy, stronger prompt-injection resistance, and better protection against misuse. The company partnered with external groups, including Apollo and Vaultis, and conducted evaluations using its Frontier Safety Framework.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Deployment Across Google Products&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Gemini 3 is available across Google Search AI Mode, the Gemini app, Google AI Studio, Vertex AI, the Gemini CLI, and Google’s new agentic development platform, Antigravity. Google says additional Gemini 3 variants will arrive later.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Conclusion&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Gemini 3 represents Google’s largest step forward in reasoning, multimodality, enterprise reliability, and agentic capabilities. The model’s performance gains over Gemini 2.5 Pro are substantial across mathematical reasoning, vision, coding, and planning. Generative interfaces, Gemini Agent, and Antigravity demonstrate a shift toward systems that not only respond to prompts but plan tasks, construct interfaces, and coordinate tools. Combined with an unusually intense hype and leak cycle, the launch marks a significant moment in the AI landscape as Google moves aggressively to expand its presence across both consumer-facing and enterprise-facing AI workflows.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;After more than a month of rumors and feverish speculation — including &lt;a href="https://polymarket.com/event/gemini-3pt0-released-by"&gt;Polymarket wagering on the release date&lt;/a&gt; — Google today &lt;a href="https://blog.google/products/gemini/gemini-3/"&gt;unveiled Gemini 3&lt;/a&gt;, its newest proprietary frontier model family and the company’s most comprehensive AI release since the Gemini line debuted in 2023. &lt;/p&gt;&lt;p&gt;The models are proprietary (closed-source), available exclusively through Google products, developer platforms, and paid APIs, including &lt;a href="https://aistudio.google.com/"&gt;Google AI Studio&lt;/a&gt;, &lt;a href="https://cloud.google.com/vertex-ai?hl=en"&gt;Vertex AI&lt;/a&gt;, the&lt;a href="https://github.com/google-gemini/gemini-cli"&gt; Gemini command line interface (CLI)&lt;/a&gt; for developers, and third-party integrations across the broader integrated developer environment (IDE) ecosystem.&lt;/p&gt;&lt;p&gt;Gemini 3 arrives as a full portfolio, including:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Gemini 3 Pro:&lt;/b&gt; the flagship frontier model&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Gemini 3 Deep Think: &lt;/b&gt;an enhanced reasoning mode&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Generative interface models powering Visual Layout and Dynamic View&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Gemini Agent&lt;/b&gt; for multi-step task execution&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Gemini 3 engine&lt;/b&gt; embedded in &lt;b&gt;Google Antigravity&lt;/b&gt;, the company’s new agent-first development environment.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&amp;quot;This is the best model in the world, by a crazy wide margin!&amp;quot; wrote&lt;a href="https://x.com/YiTayML/status/1990817918784000420"&gt; Google DeepMind Research Scientist Yi Tay on X&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;Indeed, already, independent AI benchmarking and analysis organization &lt;a href="https://x.com/ArtificialAnlys/status/1990813106478715098"&gt;Artificial Analysis has crowned Gemini 3 Pro the &amp;quot;new leader in AI&amp;quot;&lt;/a&gt; globally, achieving the top score of 73 on the organization&amp;#x27;s index, leaping Google from its former placement of 9th overall with the preceding Gemini 2.5 Pro model, which scored 60 behind OpenAI, Moonshot AI, xAI, Anthropic and MiniMax models. As &lt;a href="https://x.com/ArtificialAnlys/status/1990813109188243599"&gt;Artificial Analysis wrote on X&lt;/a&gt;: &amp;quot;For the first time, Google has the most intelligent model.&amp;quot;&lt;/p&gt;&lt;p&gt;Another independent leaderboard site, LMArena reported that &lt;b&gt;Gemini 3 Pro ranked first in the world across all of its major evaluation tracks&lt;/b&gt;, including text reasoning, vision, coding, and web development. &lt;/p&gt;&lt;p&gt;In a public post, the &lt;a href="https://x.com/arena/status/1990813759938703570"&gt;@arena account on X&lt;/a&gt; said the model surpassed even the newly released (hours old) Grok-4.1, as well as Claude 4.5, and GPT-5-class systems in categories such as math, long-form queries, creative writing, and several occupational benchmarks. &lt;/p&gt;&lt;div&gt;&lt;/div&gt;&lt;p&gt;The post also highlighted the scale of gains over Gemini 2.5 Pro, including a 50-point jump in text Elo, a 70-point increase in vision, and a 280-point rise in web-development tasks. &lt;/p&gt;&lt;p&gt;While these results reflect live community voting and remain preliminary, they signal unusually broad performance improvements across domains where previous Gemini models trailed competitors.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What It Means For Google In the Hotly Competitive AI Race&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The launch represents one of Google’s largest, most tightly coordinated model releases. &lt;/p&gt;&lt;p&gt;Gemini 3 is shipping simultaneously across Google Search, the Gemini app, Google AI Studio, Vertex AI, and a range of developer tools. &lt;/p&gt;&lt;p&gt;Executives emphasized that this integration reflects Google’s control of tensor processing unit (TPU — its homegrown Nvidia GPU rival chips) hardware, data center infrastructure, and consumer products. &lt;/p&gt;&lt;p&gt;According to the company, the Gemini app now has more than 650 million monthly active users, more than 13 million developers build with Google’s AI tools, and more than 2 billion monthly users engage with Gemini-powered AI Overviews in Search.&lt;/p&gt;&lt;p&gt;At the center of the release is a shift toward agentic AI — systems that plan, act, navigate interfaces, and coordinate tools, rather than just generating text. &lt;/p&gt;&lt;p&gt;Gemini 3 is designed to translate high-level instructions into multi-step workflows across devices and applications, with the ability to generate functional interfaces, run tools, and manage complex tasks.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Major Performance Gains Over Gemini 2.5 Pro&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Gemini 3 Pro introduces large gains over Gemini 2.5 Pro across reasoning, mathematics, multimodality, tool use, coding, and long-horizon planning. Google’s benchmark disclosures show substantial improvements in many categories.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Gemini 3 Pro debuted at the top of the LMArena&lt;/b&gt; text-reasoning leaderboard, posting a &lt;b&gt;preliminary Elo score of 1501&lt;/b&gt; based on pre-release community voting — the first LLM to ever cross the 1500 threshold.&lt;/p&gt;&lt;p&gt;That places it above &lt;b&gt;xAI’s newly announced Grok-4.1-thinking model (1484) and Grok-4.1 (1465), &lt;/b&gt;both of which were unveiled just hours earlier, as well as above Gemini 2.5 Pro (1451) and recent Claude Sonnet and Opus releases. &lt;/p&gt;&lt;p&gt;While LMArena covers only text-reasoning performance and the results are labeled preliminary, this ranking positions Gemini 3 Pro as the strongest publicly evaluated model on that benchmark as of its launch day — though not necessarily the top performer in the world across all modalities, tasks, or evaluation suites.&lt;/p&gt;&lt;p&gt;In mathematical and scientific reasoning, Gemini 3 Pro scored 95 percent on AIME 2025 without tools and 100 percent with code execution, compared to 88 percent for its predecessor. &lt;/p&gt;&lt;p&gt;On GPQA Diamond, it reached 91.9 percent, up from 86.4 percent. The model also recorded a major jump on MathArena Apex, reaching 23.4 percent versus 0.5 percent for Gemini 2.5 Pro, and delivered 31.1 percent on ARC-AGI-2 compared to 4.9 percent previously.&lt;/p&gt;&lt;p&gt;Multimodal performance increased across the board. Gemini 3 Pro scored 81 percent on MMMU-Pro, up from 68 percent, and 87.6 percent on Video-MMMU, compared to 83.6 percent. Its result on ScreenSpot-Pro, a key benchmark for agentic computer use, rose from 11.4 percent to 72.7 percent. Document understanding and chart reasoning also improved.&lt;/p&gt;&lt;p&gt;Coding and tool-use performance showed equally significant gains. The model’s LiveCodeBench Pro score reached 2,439, up from 1,775. On Terminal-Bench 2.0 it achieved 54.2 percent versus 32.6 percent previously. SWE-Bench Verified, which measures agentic coding through structured fixes, increased from 59.6 percent to 76.2 percent. The model also posted 85.4 percent on t2-bench, up from 54.9 percent.&lt;/p&gt;&lt;p&gt;Long-context and planning benchmarks indicate more stable multi-step behavior. Gemini 3 achieved 77 percent on MRCR v2 at 128k context (versus 58 percent) and 26.3 percent at 1 million tokens (versus 16.4 percent). Its Vending-Bench 2 score reached $5,478.16, compared to $573.64 for Gemini 2.5 Pro, reflecting stronger consistency during long-running decision processes.&lt;/p&gt;&lt;p&gt;Language understanding scores improved on SimpleQA Verified (72.1 percent versus 54.5 percent), MMLU (91.8 percent versus 89.5 percent), and the FACTS Benchmark Suite (70.5 percent versus 63.4 percent), supporting more reliable fact-based work in regulated sectors.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Generative Interfaces Move Gemini Beyond Text&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Gemini 3 introduces a new class of generative interface capabilities in the consumer-facing Google Search AI Mode and for developers through Google AI Studio.&lt;/p&gt;&lt;p&gt;Visual Layout produces structured, magazine-style pages with images, diagrams, and modules tailored to the query. &lt;/p&gt;&lt;p&gt;Dynamic View generates functional interface components such as calculators, simulations, galleries, and interactive graphs. &lt;/p&gt;&lt;p&gt;These experiences will be available starting today globally in Google Search’s AI Mode, enabling models to surface information in visual, interactive formats beyond static text.&lt;/p&gt;&lt;p&gt;Developers can reproduce similar UI elements through Google AI Studio and the Gemini API, but the full consumer-facing interface types are not available as direct API outputs; instead, developers receive the underlying code or schema to render these components themselves. The branded Visual Layout and Dynamic View formats are therefore specific to Search and not exposed as standalone API features.&lt;/p&gt;&lt;p&gt;Google says the model analyzes user intent to construct the layout best suited to a task. In practice, this includes everything from automatically building diagrams for scientific concepts to generating custom UI components that respond to user input.&lt;/p&gt;&lt;p&gt;Google held a press call the day before the Gemini 3 announcement to brief reporters on the model family, its intended use cases, and how it differed from earlier Gemini releases. The call was led by multiple Google and DeepMind executives who walked through the model’s capabilities and framed Gemini 3 as a step toward more reliable, multi-step agentic systems that can operate across Google’s ecosystem.&lt;/p&gt;&lt;p&gt;During the briefing, speakers emphasized that Gemini 3 was engineered to support more consistent long-horizon reasoning, better tool use, and smoother planning loops than Gemini 2.5 Pro. &lt;/p&gt;&lt;p&gt;One presenter said the model benefits from an architecture that allows it to generate and evaluate multiple hypotheses in parallel, improving reliability on mathematically hard questions and complex procedural tasks. &lt;/p&gt;&lt;p&gt;Another speaker explained that Gemini 3’s improved spatial reasoning enables more robust interaction with interface elements, which supports agentic workflows across screens and applications.&lt;/p&gt;&lt;p&gt;Presenters highlighted growing enterprise adoption, noting strong demand for multimodal analysis, structured document reasoning, and agentic coding tools. They said Gemini 3’s performance on multimodal and scientific benchmarks reflected Google’s focus on grounded, verifiable reasoning. And they discussed Gemini 3&amp;#x27;s safety processes and improvements, including reduced sycophancy, stronger prompt-injection resistance, and a more structured evaluation pipeline guided by &lt;a href="https://deepmind.google/blog/introducing-the-frontier-safety-framework/"&gt;Google’s Frontier Safety Framework&lt;/a&gt; introduced back in 2024.&lt;/p&gt;&lt;p&gt;A portion of the call was dedicated to developer experience. Google described updates to its AI Studio and API that allow developers to control thinking depth, adjust model “resolution,” and combine new grounding tools with URL context and Search. &lt;/p&gt;&lt;p&gt;Demoes showed Gemini 3 generating application interfaces, managing tool sequences, and debugging code in Antigravity, illustrating the model’s shift toward agentic operation rather than single-step generation.&lt;/p&gt;&lt;p&gt;The call positioned Gemini 3 as an upgrade across reasoning, planning, multimodal understanding, and developer workflows, with Google framing these advances as the foundation for its next generation of agent-driven products and enterprise services.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Gemini Agent Introduces Multi-Step Workflow Automation&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Gemini Agent marks Google’s effort to move beyond conversational assistance toward operational AI. The system coordinates multi-step tasks across tools like Gmail, Calendar, Canvas, and live browsing. It reviews inboxes, drafts replies, prepares plans, triages information, and reasons through complex workflows, while requiring user approval before performing sensitive actions.&lt;/p&gt;&lt;p&gt;On a press call with journalists ahead of the release yesterday, Google said the agent is designed to handle multi-turn planning and tool-use sequences with consistency that was not feasible in earlier generations. &lt;/p&gt;&lt;p&gt;It is rolling out first to Google AI Ultra subscribers in the Gemini app.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Google Antigravity and Developer Toolchain Integration&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Antigravity is Google’s new agent-first development environment designed around Gemini 3. Developers collaborate with agents across an editor, terminal, and browser. The system orchestrates full-stack tasks, including code generation, UI prototyping, debugging, live execution, and report generation.&lt;/p&gt;&lt;p&gt;Across the broader developer ecosystem, Google AI Studio now includes a Build mode that automatically wires the right models and APIs to speed up AI-native app creation. Annotations support allows developers to attach prompts to UI elements for faster iteration. Spatial reasoning improvements enable agents to interpret mouse movements, screen annotations, and multi-window layouts to operate computer interfaces more effectively.&lt;/p&gt;&lt;p&gt;Developers also gain new reasoning controls through “thinking level” and “model resolution” parameters in the Gemini API, along with stricter validation of thought signatures for multi-turn consistency. A hosted server-side bash tool supports secure, multi-language code generation and prototyping. Grounding with Google Search and URL context can now be combined to extract structured information for downstream tasks.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Enterprise Impact and Adoption&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Enterprise teams gain multimodal understanding, agentic coding, and long-horizon planning needed for production use cases. The new model unifies analysis of documents, audio, video, workflows, and logs. Improvements in spatial and visual reasoning support robotics, autonomous systems, and scenarios requiring navigation of screens and applications. High-frame-rate video understanding helps developers detect events in fast-moving environments.&lt;/p&gt;&lt;p&gt;Gemini 3’s structured document understanding capabilities support legal review, complex form processing, and regulated workflows. Its ability to generate functional interfaces and prototypes with minimal prompting reduces engineering cycles. In addition, the gains in system reliability, tool-calling stability, and context retention make multi-step planning viable for operations like financial forecasting, customer support automation, supply chain modeling, and predictive maintenance.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Developer and API Pricing&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Google has disclosed initial API pricing for Gemini 3 Pro. &lt;/p&gt;&lt;p&gt;In preview, the model is priced at $2 per million input tokens and $12 per million output tokens for prompts up to 200,000 tokens in Google AI Studio and Vertex AI. For prompts that require more than 200,000 tokens, the input pricing doubles to $2 per 1M tok, while the output rises to $18 per 1M tok.&lt;/p&gt;&lt;p&gt;When compared to the API pricing for other frontier AI models from rival labs, Gemini 3 is priced in the mid-high range, which may impact adoption as cheaper and open-source (permissively licensed) Chinese models &lt;a href="https://x.com/stevehou/status/1990488315351732691"&gt;have increasingly come to be adopted by U.S. startups&lt;/a&gt;. Here&amp;#x27;s how it stacks up:&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Model&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Input (/1M tokens)&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Output (/1M tokens)&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Total Cost&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Source&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;ERNIE 4.5 Turbo&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.11&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.45&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.56&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Blfmc9do4"&gt;Qianfan&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;ERNIE 5.0&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.85&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$3.40&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$4.25&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Blfmc9do4"&gt;Qianfan&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;Qwen3 (Coder ex.)&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.85&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$3.40&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$4.25&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Blfmc9do4"&gt;Qianfan&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;GPT-5.1&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$1.25&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$10.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$11.25&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://openai.com/pricing"&gt;OpenAI&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;Gemini 2.5 Pro (≤200K)&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$1.25&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$10.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$11.25&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://ai.google.dev/gemini-api/docs/pricing"&gt;Google&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Gemini 3 Pro (≤200K)&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;$2.00&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;$12.00&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;$14.00&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://ai.google.dev/gemini-api/docs/pricing"&gt;&lt;b&gt;Google&lt;/b&gt;&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;Gemini 2.5 Pro (&amp;gt;200K)&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$2.50&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$15.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$17.50&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://ai.google.dev/gemini-api/docs/pricing"&gt;Google&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Gemini 3 Pro (&amp;gt;200K)&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;$4.00&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;$18.00&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;$22.00&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://ai.google.dev/gemini-api/docs/pricing"&gt;&lt;b&gt;Google&lt;/b&gt;&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;Grok 4 (0709)&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$3.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$15.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$18.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://x.ai/dev/docs/models"&gt;xAI API&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;Claude Opus 4.1&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$15.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$75.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$90.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;a href="https://docs.anthropic.com/claude/docs/models-overview"&gt;Anthropic&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Gemini 3 Pro is also available at no charge with rate limits in Google AI Studio for experimentation.&lt;/p&gt;&lt;p&gt;The company has not yet announced pricing for Gemini 3 Deep Think, extended context windows, generative interfaces, or tool invocation. &lt;/p&gt;&lt;p&gt;Enterprises planning deployment at scale will require these details to estimate operational costs.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Multimodal, Visual, and Spatial Reasoning Enhancements&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Gemini 3’s improvements in embodied and spatial reasoning support pointing and trajectory prediction, task progression, and complex screen parsing. These capabilities extend to desktop and mobile environments, enabling agents to interpret screen elements, respond to on-screen context, and unlock new forms of computer-use automation.&lt;/p&gt;&lt;p&gt;The model also delivers improved video reasoning with high-frame-rate understanding for analyzing fast-moving scenes, along with long-context video recall for synthesizing narratives across hours of footage. Google’s examples show the model generating full interactive demo apps directly from prompts, illustrating the depth of multimodal and agentic integration.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Vibe Coding and Agentic Code Generation&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Gemini 3 advances Google’s concept of “vibe coding,” where natural language acts as the primary syntax. The model can translate high-level ideas into full applications with a single prompt, handling multi-step planning, code generation, and visual design. Enterprise partners like Figma, JetBrains, Cursor, Replit, and Cline report stronger instruction following, more stable agentic operation, and better long-context code manipulation compared to prior models.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Rumors and Rumblings&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;In the weeks leading up to the announcement, X became a hub of speculation about Gemini 3. &lt;/p&gt;&lt;p&gt;Well-known accounts such as @slow_developer suggested internal builds were significantly ahead of Gemini 2.5 Pro and likely exceeded competitor performance in reasoning and tool use. Others, including @synthwavedd and @VraserX, noted mixed behavior in early checkpoints but acknowledged Google’s advantage in TPU hardware and training data. &lt;/p&gt;&lt;p&gt;Viral clips from users like @lepadphone and @StijnSmits showed the model generating websites, animations, and UI layouts from single prompts, adding to the momentum.&lt;/p&gt;&lt;p&gt;Prediction markets on Polymarket amplified the speculation. Whale accounts drove the odds of a mid-November release sharply upward, prompting widespread debate about insider activity. A temporary dip during a global Cloudflare outage became a moment of humor and conspiracy before odds surged again.&lt;/p&gt;&lt;p&gt;The key moment came when users including &lt;a href="https://x.com/cheatyyyy/status/1990737403867263183"&gt;@cheatyyyy&lt;/a&gt; shared what appeared to be an internal model-card benchmark table for Gemini 3 Pro. &lt;/p&gt;&lt;p&gt;The image circulated rapidly, with commentary from figures like @deedydas and @kimmonismus arguing the numbers suggested a significant lead. &lt;/p&gt;&lt;p&gt;When Google published the official benchmarks, they matched the leaked table exactly, confirming the document’s authenticity.&lt;/p&gt;&lt;p&gt;By launch day, enthusiasm reached a peak. A brief “Geminiii” post from Sundar Pichai triggered widespread attention, and early testers quickly shared real examples of Gemini 3 generating interfaces, full apps, and complex visual designs. &lt;/p&gt;&lt;p&gt;While some concerns about pricing and efficiency appeared, the dominant sentiment framed the launch as a turning point for Google and a display of its full-stack AI capabilities.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Safety and Evaluation&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Google says Gemini 3 is its most secure model yet, with reduced sycophancy, stronger prompt-injection resistance, and better protection against misuse. The company partnered with external groups, including Apollo and Vaultis, and conducted evaluations using its Frontier Safety Framework.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Deployment Across Google Products&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Gemini 3 is available across Google Search AI Mode, the Gemini app, Google AI Studio, Vertex AI, the Gemini CLI, and Google’s new agentic development platform, Antigravity. Google says additional Gemini 3 variants will arrive later.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Conclusion&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Gemini 3 represents Google’s largest step forward in reasoning, multimodality, enterprise reliability, and agentic capabilities. The model’s performance gains over Gemini 2.5 Pro are substantial across mathematical reasoning, vision, coding, and planning. Generative interfaces, Gemini Agent, and Antigravity demonstrate a shift toward systems that not only respond to prompts but plan tasks, construct interfaces, and coordinate tools. Combined with an unusually intense hype and leak cycle, the launch marks a significant moment in the AI landscape as Google moves aggressively to expand its presence across both consumer-facing and enterprise-facing AI workflows.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/google-unveils-gemini-3-claiming-the-lead-in-math-science-multimodal-and</guid><pubDate>Tue, 18 Nov 2025 16:00:00 +0000</pubDate></item><item><title>[NEW] Google launches Gemini 3 with new coding app and record benchmark scores (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/18/google-launches-gemini-3-with-new-coding-app-and-record-benchmark-scores/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/gemini.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Tuesday, Google released Gemini 3, its latest and most advanced foundation model, which is now immediately available through the Gemini app and AI search interface.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Coming just seven months after the Gemini 2.5 release, the new model is Google’s most capable LLM yet, and an immediate contender for the most capable AI tool on the market. The release also comes less than a week after OpenAI released GPT 5.1, and a mere two months after Anthropic released Sonnet 4.5 — a reminder of the blistering pace of frontier model development.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;A more research-intensive version of the model, called Gemini 3 Deepthink, will also be made available to Google AI Ultra subscribers in the coming weeks, once it passes further rounds of safety testing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“With Gemini 3, we’re seeing this massive jump in reasoning,” said Tulsee Doshi, Google’s head of product for the Gemini model. “It’s responding with a level of depth and nuance that we haven’t seen before.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some of that reasoning power is already registering on independent benchmarks. With a score of 37.4, the model marked the highest score on record on the Humanity’s Last Exam benchmark, meant to capture general reasoning and expertise. The previous high score, held by GPT-5 Pro, was 31.64. Gemini 3 also topped the leaderboard on LMArena, a human-led benchmark that measures user satisfaction.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to Google, the Gemini app currently has more than 650 million monthly active users, and 13 million software developers have used the model as part of their workflow.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside the base model, Google also released a Gemini-powered coding interface called Google Antigravity, allowing for multi-pane agentic coding similar to agentic IDEs like Warp or Cursor 2.0. Specifically, Antigravity combines a ChatGPT-style prompt window with a command-line interface and a browser window that can show the impact of the changes made by the coding agent.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“The agent can work with your editor, across your terminal, across your browser to make sure that it helps you build that application in the best way possible,” said DeepMind CTO Koray Kavukcuoglu.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/gemini.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Tuesday, Google released Gemini 3, its latest and most advanced foundation model, which is now immediately available through the Gemini app and AI search interface.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Coming just seven months after the Gemini 2.5 release, the new model is Google’s most capable LLM yet, and an immediate contender for the most capable AI tool on the market. The release also comes less than a week after OpenAI released GPT 5.1, and a mere two months after Anthropic released Sonnet 4.5 — a reminder of the blistering pace of frontier model development.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;A more research-intensive version of the model, called Gemini 3 Deepthink, will also be made available to Google AI Ultra subscribers in the coming weeks, once it passes further rounds of safety testing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“With Gemini 3, we’re seeing this massive jump in reasoning,” said Tulsee Doshi, Google’s head of product for the Gemini model. “It’s responding with a level of depth and nuance that we haven’t seen before.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some of that reasoning power is already registering on independent benchmarks. With a score of 37.4, the model marked the highest score on record on the Humanity’s Last Exam benchmark, meant to capture general reasoning and expertise. The previous high score, held by GPT-5 Pro, was 31.64. Gemini 3 also topped the leaderboard on LMArena, a human-led benchmark that measures user satisfaction.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to Google, the Gemini app currently has more than 650 million monthly active users, and 13 million software developers have used the model as part of their workflow.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside the base model, Google also released a Gemini-powered coding interface called Google Antigravity, allowing for multi-pane agentic coding similar to agentic IDEs like Warp or Cursor 2.0. Specifically, Antigravity combines a ChatGPT-style prompt window with a command-line interface and a browser window that can show the impact of the changes made by the coding agent.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“The agent can work with your editor, across your terminal, across your browser to make sure that it helps you build that application in the best way possible,” said DeepMind CTO Koray Kavukcuoglu.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/18/google-launches-gemini-3-with-new-coding-app-and-record-benchmark-scores/</guid><pubDate>Tue, 18 Nov 2025 16:00:00 +0000</pubDate></item><item><title>[NEW] Google’s new Gemini 3 “vibe-codes” responses and comes with its own agent (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/11/18/1128065/googles-gemini-3/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/Gemini-3.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 chronoton/executive-summary_0"&gt;&lt;div class="chronotonExecutiveSummary__summaryContainer--3bc10da0658ecd8e2ef22c6023461fb5"&gt;&lt;button class="chronotonExecutiveSummary__toggleButton--1cd6118db37e8a8252fc4cd8bbadcb85" type="button"&gt;&lt;span class="chronotonExecutiveSummary__toggleText--a713e14989fe65c5162db2b69cb422c9"&gt;EXECUTIVE SUMMARY&lt;/span&gt;&lt;svg class="chronotonExecutiveSummary__toggleArrow--a8c1be9c06a9f066a767b3af80d859a1" fill="none" height="7" viewBox="0 0 11 7" width="11" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M1 1L5.5 5.5L10 1" stroke="#58C0B3" stroke-linecap="round" stroke-width="1.5"&gt;&lt;/svg&gt;&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_1 html_first"&gt; &lt;p&gt;Google today unveiled Gemini 3, a major upgrade to its flagship multimodal model. The firm says the new model is better at reasoning, has more fluid multimodal capabilities (the ability to work across voice, text or images), and will work like an agent.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The previous model, Gemini 2.5, supports multimodal input. Users can feed it images, handwriting, or voice. But it usually requires explicit instructions about the format the user wants back, and it defaults to plain text regardless.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;But Gemini 3 introduces what Google calls “generative interfaces,” which allow the model to make its own choices about what kind of output fits the prompt best, assembling visual layouts and dynamic views on its own instead of returning a block of text.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Ask for travel recommendations and it may spin up a website-like interface inside the app, complete with modules, images, and follow-up prompts such as “How many days are you traveling?” or “What kinds of activities do you enjoy?” It also presents clickable options based on what you might want next.&lt;/p&gt; 
 &lt;p&gt;When asked to explain a concept, Gemini 3 may sketch a diagram or generate a simple animation on its own if it believes a visual is more effective.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;“Visual layout generates an immersive, magazine-style view complete with photos and modules,” says Josh Woodward, VP of Google Labs, Gemini, and AI Studio. “These elements don’t just look good but invite your input to further tailor the results.”&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;With Gemini 3, Google is also introducing Gemini Agent, an experimental feature designed to handle multi-step tasks directly inside the app. The agent can connect to services such as Google Calendar, Gmail, and Reminders. Once granted access, it can execute tasks like organizing an inbox or managing schedules.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Similar to other agents, it breaks tasks into discrete steps, displays its progress in real time, and pauses for approval from the user before continuing. Google describes the feature as a step toward “a true generalist agent.” It will be available on the web for Google AI Ultra subscribers in the US starting November 18.&lt;/p&gt;  &lt;p&gt;The overall approach can seem a lot like “vibe coding,” where users describe an end goal in plain language and let the model assemble the interface or code needed to get there.&lt;/p&gt;  &lt;p&gt;The update also ties Gemini more deeply into Google’s existing products. In Search, a limited group of Google AI Pro and Ultra subscribers can now switch to Gemini 3 Pro, the reasoning variation of the new model, to receive deeper, more thorough AI-generated summaries that rely on the model’s reasoning rather than the existing AI Mode.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt;&lt;p&gt;For shopping, Gemini will now pull from Google’s Shopping Graph—which the company says contains more than 50 billion product listings—to generate its own recommendation guides. Users just need to ask a shopping-related question or search a shopping-related phrase, and the model assembles an interactive, Wirecutter-style product recommendation piece, complete with prices and product details, without redirecting to an external site.&lt;/p&gt;  &lt;p&gt;For developers, Google is also pushing single-prompt software generation further. The company introduced Google Antigravity, a&amp;nbsp; development platform that acts as an all-in-one space where code, tools, and workflows can be created and managed from a single prompt.&lt;/p&gt;  &lt;p&gt;Derek Nee, CEO of Flowith, an agentic AI application, told &lt;em&gt;MIT Technology Revie&lt;/em&gt;w that Gemini 3 Pro addresses several gaps in earlier models. Improvements include stronger visual understanding, better code generation, and better performance on long tasks—features he sees as essential for developers of AI apps and agents.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Given its speed and cost advantages, we’re integrating the new model into our product,” he says. “We’re optimistic about its potential, but we need deeper testing to understand how far it can go.”&amp;nbsp;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/Gemini-3.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 chronoton/executive-summary_0"&gt;&lt;div class="chronotonExecutiveSummary__summaryContainer--3bc10da0658ecd8e2ef22c6023461fb5"&gt;&lt;button class="chronotonExecutiveSummary__toggleButton--1cd6118db37e8a8252fc4cd8bbadcb85" type="button"&gt;&lt;span class="chronotonExecutiveSummary__toggleText--a713e14989fe65c5162db2b69cb422c9"&gt;EXECUTIVE SUMMARY&lt;/span&gt;&lt;svg class="chronotonExecutiveSummary__toggleArrow--a8c1be9c06a9f066a767b3af80d859a1" fill="none" height="7" viewBox="0 0 11 7" width="11" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M1 1L5.5 5.5L10 1" stroke="#58C0B3" stroke-linecap="round" stroke-width="1.5"&gt;&lt;/svg&gt;&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_1 html_first"&gt; &lt;p&gt;Google today unveiled Gemini 3, a major upgrade to its flagship multimodal model. The firm says the new model is better at reasoning, has more fluid multimodal capabilities (the ability to work across voice, text or images), and will work like an agent.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The previous model, Gemini 2.5, supports multimodal input. Users can feed it images, handwriting, or voice. But it usually requires explicit instructions about the format the user wants back, and it defaults to plain text regardless.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;But Gemini 3 introduces what Google calls “generative interfaces,” which allow the model to make its own choices about what kind of output fits the prompt best, assembling visual layouts and dynamic views on its own instead of returning a block of text.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Ask for travel recommendations and it may spin up a website-like interface inside the app, complete with modules, images, and follow-up prompts such as “How many days are you traveling?” or “What kinds of activities do you enjoy?” It also presents clickable options based on what you might want next.&lt;/p&gt; 
 &lt;p&gt;When asked to explain a concept, Gemini 3 may sketch a diagram or generate a simple animation on its own if it believes a visual is more effective.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;“Visual layout generates an immersive, magazine-style view complete with photos and modules,” says Josh Woodward, VP of Google Labs, Gemini, and AI Studio. “These elements don’t just look good but invite your input to further tailor the results.”&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;With Gemini 3, Google is also introducing Gemini Agent, an experimental feature designed to handle multi-step tasks directly inside the app. The agent can connect to services such as Google Calendar, Gmail, and Reminders. Once granted access, it can execute tasks like organizing an inbox or managing schedules.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Similar to other agents, it breaks tasks into discrete steps, displays its progress in real time, and pauses for approval from the user before continuing. Google describes the feature as a step toward “a true generalist agent.” It will be available on the web for Google AI Ultra subscribers in the US starting November 18.&lt;/p&gt;  &lt;p&gt;The overall approach can seem a lot like “vibe coding,” where users describe an end goal in plain language and let the model assemble the interface or code needed to get there.&lt;/p&gt;  &lt;p&gt;The update also ties Gemini more deeply into Google’s existing products. In Search, a limited group of Google AI Pro and Ultra subscribers can now switch to Gemini 3 Pro, the reasoning variation of the new model, to receive deeper, more thorough AI-generated summaries that rely on the model’s reasoning rather than the existing AI Mode.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt;&lt;p&gt;For shopping, Gemini will now pull from Google’s Shopping Graph—which the company says contains more than 50 billion product listings—to generate its own recommendation guides. Users just need to ask a shopping-related question or search a shopping-related phrase, and the model assembles an interactive, Wirecutter-style product recommendation piece, complete with prices and product details, without redirecting to an external site.&lt;/p&gt;  &lt;p&gt;For developers, Google is also pushing single-prompt software generation further. The company introduced Google Antigravity, a&amp;nbsp; development platform that acts as an all-in-one space where code, tools, and workflows can be created and managed from a single prompt.&lt;/p&gt;  &lt;p&gt;Derek Nee, CEO of Flowith, an agentic AI application, told &lt;em&gt;MIT Technology Revie&lt;/em&gt;w that Gemini 3 Pro addresses several gaps in earlier models. Improvements include stronger visual understanding, better code generation, and better performance on long tasks—features he sees as essential for developers of AI apps and agents.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Given its speed and cost advantages, we’re integrating the new model into our product,” he says. “We’re optimistic about its potential, but we need deeper testing to understand how far it can go.”&amp;nbsp;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/11/18/1128065/googles-gemini-3/</guid><pubDate>Tue, 18 Nov 2025 16:00:07 +0000</pubDate></item><item><title>[NEW] Delivering AI-Ready Enterprise Data With GPU-Accelerated AI Storage (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/ai-data-platform-gpu-accelerated-storage/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/ai-data-platform-storage.png" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;AI agents have the potential to become indispensable tools for automating complex tasks. But bringing agents to production remains challenging.&lt;/p&gt;
&lt;p&gt;According to Gartner, “about 40% of AI prototypes make it into production, and participants reported data availability and quality as a top barrier to AI adoption.&lt;sup&gt;1&lt;/sup&gt;”&lt;/p&gt;
&lt;p&gt;Just like human workers, AI agents need secure, relevant, accurate and recent data to deliver business value — what the industry is now calling “AI-ready data.”&lt;/p&gt;
&lt;p&gt;Making enterprise data AI-ready presents unique challenges. Gartner estimates, “Unstructured data such as documents and multimedia files accounts for 70% to 90% of organizational data, and poses unique governance challenges due to its volume, variety and lack of coherent structure.&lt;sup&gt;2&lt;/sup&gt;” Unstructured data sources include email, PDFs, videos, audio clips and presentations.&lt;/p&gt;
&lt;p&gt;An emerging class of GPU-accelerated data and storage infrastructure — the AI data platform — transforms unstructured data into AI-ready data quickly and securely.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;What Is AI-Ready Data?&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;AI-ready data can be consumed by AI training, fine-tuning and retrieval-augmented generation pipelines without additional preparation.&lt;/p&gt;
&lt;p&gt;Making unstructured data AI-ready involves:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Collecting and curating data from diverse sources&lt;/li&gt;
&lt;li&gt;Applying metadata for data management and governance&lt;/li&gt;
&lt;li&gt;Dividing the source documents into semantically relevant chunks&lt;/li&gt;
&lt;li&gt;Embedding the chunks into vectors for efficient storage, search and retrieval&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Enterprises cannot unlock the full value of their AI investments until their unstructured data is AI-ready.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Why Making Data AI-Ready Is Difficult&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Making unstructured data AI-ready remains a substantial challenge for most enterprises due to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data complexity: A typical enterprise has hundreds of diverse data sources in dozens of formats and modalities — including video, audio, text and images. This data lives in different storage silos.&lt;/li&gt;
&lt;li&gt;Data velocity: The volume of business data is exploding. Predictions show global stored data will double over the next four years. And the rate of data change is increasing as enterprises adopt real-time streaming sensors such as camera feeds.&lt;/li&gt;
&lt;li&gt;Data sprawl and data drift: Frequent data copying and transformation introduces cost and security risks. Over time, the content or permissions of AI representations — such as text chunks and embeddings — diverge from source-of-truth documents. Plus, as the number of chatbots and agents proliferates, the security risk of data increases.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Together, these factors force enterprise data scientists to spend the majority of their time locating, cleaning and organizing data — leaving less time for identifying valuable insights.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;The AI Data Platform — a New Class of Enterprise Data and Storage Infrastructure&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;AI data platforms are an emerging class of GPU-accelerated data and storage infrastructure that makes enterprise data AI-ready.&lt;/p&gt;
&lt;p&gt;By embedding GPU acceleration directly into the data path, AI data platforms transform data for AI pipelines as a background operation invisible to the user.&lt;/p&gt;
&lt;p&gt;The data is prepared in place, minimizing unnecessary copies and associated security risks.&lt;/p&gt;
&lt;p&gt;By integrating data preparation as a core capability of storage infrastructure, AI data platforms ensure that the accuracy and security of the data is maintained. Any modifications to the sources of truth documents — including edits or permission changes — are instantly conveyed to their associated vector embeddings.&lt;/p&gt;
&lt;p&gt;Key benefits of AI data platforms include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Faster time to value: Enterprises don’t need to design, build and optimize AI data pipelines from the ground up. AI data platforms deliver an integrated, state-of-the-art AI data pipeline out of the box.&lt;/li&gt;
&lt;li&gt;Reduced data drift: By continuously ingesting, embedding and indexing enterprise data in near real time, AI data platforms reduce time to insight and minimize data drift.&lt;/li&gt;
&lt;li&gt;Improved data security: Because source-of-truth documents are stored together in AI data platforms, any changes to their contents or permissions are instantly propagated to the AI applications that use them.&lt;/li&gt;
&lt;li&gt;Simplified data governance: Preparing data in place reduces the proliferation of shadow copies that undermine access control, traceability and compliance.&lt;/li&gt;
&lt;li&gt;Improved GPU utilization&lt;b&gt;:&lt;/b&gt; In an AI data platform, GPU capacity is sized for the amount, type and change velocity of the data under management. GPU capacity scales with the data, ensuring GPUs are not over- or under-provisioned for data preparation tasks.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;strong&gt;The NVIDIA AI Data Platform&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;AI is changing every industry — and AI data platforms are the natural evolution of enterprise storage for the generative AI era, changing from passive containers to active engines delivering business value.&lt;/p&gt;
&lt;p&gt;By integrating GPU acceleration into the data path, AI data platforms enable enterprises to activate their AI agents with AI-ready data quickly and securely.&lt;/p&gt;
&lt;p&gt;The NVIDIA AI Data Platform reference design brings together NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs, NVIDIA BlueField-3 DPUs and integrated AI data processing pipelines based on NVIDIA Blueprints.&lt;/p&gt;
&lt;p&gt;The NVIDIA AI Data Platform design has been adopted by leading AI infrastructure and storage providers including Cisco, Cloudian, DDN, Dell Technologies, Hitachi Vantara, HPE, IBM, NetApp, Pure Storage, VAST Data and WEKA — each extending the design with their own unique differentiation and innovation.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Learn more about the &lt;/i&gt;&lt;i&gt;NVIDIA AI Data Platform&lt;/i&gt;&lt;i&gt;. Plus, tune in to this&lt;/i&gt;&lt;i&gt; NVIDIA AI Podcast episode on AI data platforms:&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;&lt;i&gt;&lt;sup&gt;&amp;nbsp;&lt;/sup&gt;&lt;/i&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;i&gt;Gartner, How to Design an Effective Data Quality Operating Model by Sue Waite and Melody Chien, 15 July 2025&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;i&gt;Gartner, Governing Unstructured Data for AI Readiness: A Strategic Roadmap by Melody Chien, 14 August 2025&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;GARTNER is a registered trademark and service mark of Gartner, Inc. and/or its affiliates in the U.S. and internationally and is used herein with permission. All rights reserved.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/ai-data-platform-storage.png" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;AI agents have the potential to become indispensable tools for automating complex tasks. But bringing agents to production remains challenging.&lt;/p&gt;
&lt;p&gt;According to Gartner, “about 40% of AI prototypes make it into production, and participants reported data availability and quality as a top barrier to AI adoption.&lt;sup&gt;1&lt;/sup&gt;”&lt;/p&gt;
&lt;p&gt;Just like human workers, AI agents need secure, relevant, accurate and recent data to deliver business value — what the industry is now calling “AI-ready data.”&lt;/p&gt;
&lt;p&gt;Making enterprise data AI-ready presents unique challenges. Gartner estimates, “Unstructured data such as documents and multimedia files accounts for 70% to 90% of organizational data, and poses unique governance challenges due to its volume, variety and lack of coherent structure.&lt;sup&gt;2&lt;/sup&gt;” Unstructured data sources include email, PDFs, videos, audio clips and presentations.&lt;/p&gt;
&lt;p&gt;An emerging class of GPU-accelerated data and storage infrastructure — the AI data platform — transforms unstructured data into AI-ready data quickly and securely.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;What Is AI-Ready Data?&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;AI-ready data can be consumed by AI training, fine-tuning and retrieval-augmented generation pipelines without additional preparation.&lt;/p&gt;
&lt;p&gt;Making unstructured data AI-ready involves:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Collecting and curating data from diverse sources&lt;/li&gt;
&lt;li&gt;Applying metadata for data management and governance&lt;/li&gt;
&lt;li&gt;Dividing the source documents into semantically relevant chunks&lt;/li&gt;
&lt;li&gt;Embedding the chunks into vectors for efficient storage, search and retrieval&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Enterprises cannot unlock the full value of their AI investments until their unstructured data is AI-ready.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Why Making Data AI-Ready Is Difficult&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Making unstructured data AI-ready remains a substantial challenge for most enterprises due to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data complexity: A typical enterprise has hundreds of diverse data sources in dozens of formats and modalities — including video, audio, text and images. This data lives in different storage silos.&lt;/li&gt;
&lt;li&gt;Data velocity: The volume of business data is exploding. Predictions show global stored data will double over the next four years. And the rate of data change is increasing as enterprises adopt real-time streaming sensors such as camera feeds.&lt;/li&gt;
&lt;li&gt;Data sprawl and data drift: Frequent data copying and transformation introduces cost and security risks. Over time, the content or permissions of AI representations — such as text chunks and embeddings — diverge from source-of-truth documents. Plus, as the number of chatbots and agents proliferates, the security risk of data increases.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Together, these factors force enterprise data scientists to spend the majority of their time locating, cleaning and organizing data — leaving less time for identifying valuable insights.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;The AI Data Platform — a New Class of Enterprise Data and Storage Infrastructure&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;AI data platforms are an emerging class of GPU-accelerated data and storage infrastructure that makes enterprise data AI-ready.&lt;/p&gt;
&lt;p&gt;By embedding GPU acceleration directly into the data path, AI data platforms transform data for AI pipelines as a background operation invisible to the user.&lt;/p&gt;
&lt;p&gt;The data is prepared in place, minimizing unnecessary copies and associated security risks.&lt;/p&gt;
&lt;p&gt;By integrating data preparation as a core capability of storage infrastructure, AI data platforms ensure that the accuracy and security of the data is maintained. Any modifications to the sources of truth documents — including edits or permission changes — are instantly conveyed to their associated vector embeddings.&lt;/p&gt;
&lt;p&gt;Key benefits of AI data platforms include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Faster time to value: Enterprises don’t need to design, build and optimize AI data pipelines from the ground up. AI data platforms deliver an integrated, state-of-the-art AI data pipeline out of the box.&lt;/li&gt;
&lt;li&gt;Reduced data drift: By continuously ingesting, embedding and indexing enterprise data in near real time, AI data platforms reduce time to insight and minimize data drift.&lt;/li&gt;
&lt;li&gt;Improved data security: Because source-of-truth documents are stored together in AI data platforms, any changes to their contents or permissions are instantly propagated to the AI applications that use them.&lt;/li&gt;
&lt;li&gt;Simplified data governance: Preparing data in place reduces the proliferation of shadow copies that undermine access control, traceability and compliance.&lt;/li&gt;
&lt;li&gt;Improved GPU utilization&lt;b&gt;:&lt;/b&gt; In an AI data platform, GPU capacity is sized for the amount, type and change velocity of the data under management. GPU capacity scales with the data, ensuring GPUs are not over- or under-provisioned for data preparation tasks.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;strong&gt;The NVIDIA AI Data Platform&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;AI is changing every industry — and AI data platforms are the natural evolution of enterprise storage for the generative AI era, changing from passive containers to active engines delivering business value.&lt;/p&gt;
&lt;p&gt;By integrating GPU acceleration into the data path, AI data platforms enable enterprises to activate their AI agents with AI-ready data quickly and securely.&lt;/p&gt;
&lt;p&gt;The NVIDIA AI Data Platform reference design brings together NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs, NVIDIA BlueField-3 DPUs and integrated AI data processing pipelines based on NVIDIA Blueprints.&lt;/p&gt;
&lt;p&gt;The NVIDIA AI Data Platform design has been adopted by leading AI infrastructure and storage providers including Cisco, Cloudian, DDN, Dell Technologies, Hitachi Vantara, HPE, IBM, NetApp, Pure Storage, VAST Data and WEKA — each extending the design with their own unique differentiation and innovation.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Learn more about the &lt;/i&gt;&lt;i&gt;NVIDIA AI Data Platform&lt;/i&gt;&lt;i&gt;. Plus, tune in to this&lt;/i&gt;&lt;i&gt; NVIDIA AI Podcast episode on AI data platforms:&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;&lt;i&gt;&lt;sup&gt;&amp;nbsp;&lt;/sup&gt;&lt;/i&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;i&gt;Gartner, How to Design an Effective Data Quality Operating Model by Sue Waite and Melody Chien, 15 July 2025&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;i&gt;Gartner, Governing Unstructured Data for AI Readiness: A Strategic Roadmap by Melody Chien, 14 August 2025&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;GARTNER is a registered trademark and service mark of Gartner, Inc. and/or its affiliates in the U.S. and internationally and is used herein with permission. All rights reserved.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/ai-data-platform-gpu-accelerated-storage/</guid><pubDate>Tue, 18 Nov 2025 16:00:34 +0000</pubDate></item><item><title>[NEW] Realizing value with AI inference at scale and in production (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/11/18/1128007/realizing-value-with-ai-inference-at-scale-and-in-production/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;&lt;span class="sponsoredModule__name--dbd90349922f15155a4c483b397356c2"&gt;HPE&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Training an AI model to predict equipment failures is an engineering achievement. But it's not until prediction meets action—the moment that model successfully flags a malfunctioning machine—that true business transformation occurs. One technical milestone lives in a proof-of-concept deck; the other meaningfully contributes to the bottom line.&lt;/p&gt;  &lt;p&gt;Craig Partridge, senior director worldwide of Digital Next Advisory at HPE, believes "the true value of AI lies in inference”. Inference is where AI earns its keep. It’s the operational layer that puts all that training to use in real-world workflows.&amp;nbsp;Partridge elaborates, "The phrase we use for this is 'trusted AI inferencing at scale and in production,'" he says. "That's where we think the biggest return on AI investments will come from."&lt;/p&gt;&lt;p&gt;Getting to that point is difficult. Christian Reichenbach, worldwide digital advisor at HPE, points to findings from the company's recent survey of 1,775 IT leaders: While nearly a quarter (22%) of organizations have now operationalized AI—up from 15% the previous year—the majority remain stuck in experimentation.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Reaching the next stage requires a three-part approach: establishing trust as an operating principle, ensuring data-centric execution, and cultivating IT leadership capable of scaling AI successfully.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Trust as a prerequisite for scalable, high-stakes AI&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Trusted inference means users can actually rely on the answers they're getting from AI systems. This is important for applications like generating marketing copy and deploying customer service chatbots, but it's absolutely critical for higher-stakes scenarios—say, a robot assisting during surgeries or an autonomous vehicle navigating crowded streets.&lt;/p&gt; 
 &lt;p&gt;Whatever the use case, establishing trust will require doubling down on data quality; first and foremost, inferencing outcomes must be built on reliable foundations. This reality informs one of Partridge's go-to mantras: "Bad data in equals bad inferencing out."&lt;/p&gt;  &lt;p&gt;Reichenbach cites a real-world example of what happens when data quality falls short—the rise of unreliable AI-generated content, including hallucinations, that clogs workflows and forces employees to spend significant time fact-checking. "When things go wrong, trust goes down, productivity gains are not reached, and the outcome we're&amp;nbsp; looking for is not achieved," he says.&lt;/p&gt; 
 &lt;p&gt;On the other hand, when trust is properly engineered into inference systems, efficiency and productivity gains can increase. Take a network operations team tasked with troubleshooting configurations. With a trusted inferencing engine, that unit gains a reliable copilot that can deliver faster, more accurate, custom-tailored recommendations—"a 24/7 member of the team they didn't have before," says Partridge.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;The shift to data-centric thinking and rise of the AI factory&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;In the first AI wave, companies rushed to hire data scientists and many viewed sophisticated, trillion-parameter models as the primary goal. But today, as organizations move to turn early pilots into real, measurable outcomes, the focus has shifted toward data engineering and architecture.&lt;/p&gt;  &lt;p&gt;"Over the past five years, what's become more meaningful is breaking down data silos, accessing data streams, and quickly unlocking value," says Reichenbach. It’s an evolution happening alongside the rise of the AI factory—the always-on production line where data moves through pipelines and feedback loops to generate continuous intelligence.&lt;/p&gt;  &lt;p&gt;This shift reflects an evolution from model-centric to data-centric thinking, and with it comes a new set of strategic considerations. "It comes down to two things: How much of the intelligence--the model itself--is truly yours? And how much of the input--the data--is uniquely yours, from your customers, operations, or market?" says Reichenbach.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;These two central questions inform everything from platform direction and operating models to engineering roles and trust and security considerations. To help clients map their answers—and translate them into actionable strategies—Partridge breaks down HPE's four-quadrant AI factory implication matrix (see figure):&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1128011" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/HPE_AI-factory-implication-matrix_02@2x.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;Source: HPE, 2025&lt;/p&gt;  &lt;ul class="wp-block-list"&gt; &lt;li&gt;&lt;strong&gt;Run&lt;/strong&gt;: Accessing an external, pretrained model via an interface or API; organizations don’t own the model or the data. Implementation requires strong security and governance. It also requires establishing a center of excellence that makes and communicates decisions about AI usage.&lt;/li&gt;    &lt;li&gt;&lt;strong&gt;RAG (retrieval augmented generation)&lt;/strong&gt;: Using external, pre-trained models combined with a company’s proprietary data to create unique insights. Implementation focuses on connecting data streams to inferencing capabilities that provide rapid, integrated access to full-stack AI platforms.&lt;/li&gt;    &lt;li&gt;&lt;strong&gt;Riches&lt;/strong&gt;: Training custom models on data that resides in the enterprise for unique differentiation opportunities and insights. Implementation requires scalable, energy-efficient environments, and often high-performance systems.&lt;/li&gt;    &lt;li&gt;&lt;strong&gt;Regulate&lt;/strong&gt;: Leveraging custom models trained on external data, requiring the same scalable setup as Riches, but with added focus on legal and regulatory compliance for handling sensitive, non-owned data with extreme caution.&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;Importantly, these quadrants are not mutually exclusive. Partridge notes that most organizations—including HPE itself—operate across many of the quadrants. "We build our own models to help understand how networks operate," he says. "We then deploy that intelligence into our products, so that our end customer gets the chance to deliver in what we call the 'Run' quadrant. So for them, it's not their data; it's not their model. They're just adding that capability inside their organization."&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;IT's moment to scale—and lead&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;The second part of Partridge's catchphrase about inferencing—"at scale"— speaks to a primary tension in enterprise AI: what works for a handful of use cases often breaks when applied across an entire organization.&lt;/p&gt; 

 &lt;p&gt;"There's value in experimentation and kicking ideas around," he says. "But if you want to really see the benefits of AI, it needs to be something that everybody can engage in and that solves for many different use cases."&lt;/p&gt;  &lt;p&gt;In Partridge's view, the challenge of turning boutique pilots into organization-wide systems is uniquely suited to the IT function's core competencies—and it's a leadership opportunity the function can't afford to sit out. "IT takes things that are small-scale and implements the discipline required to run them at scale," he says. "So, IT organizations really need to lean into this debate."&lt;/p&gt;  &lt;p&gt;For IT teams content to linger on the sidelines, history offers a cautionary tale from the last major infrastructure shift: enterprise migration to the cloud. Many IT departments sat out decision-making during the early cloud adoption wave a decade ago, while business units independently deployed cloud services. This led to fragmented systems, redundant spending, and security gaps that took years to untangle.&lt;/p&gt;  &lt;p&gt;The same dynamic threatens to repeat with AI, as different teams experiment with tools and models outside IT's purview. This phenomenon—sometimes called shadow AI—describes environments where pilots proliferate without oversight or governance. Partridge believes that most organizations are already operating in the "Run" quadrant in some capacity, as employees will use AI tools whether or not they're officially authorized to.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Rather than shut down experimentation, it is now IT's mandate to bring structure to it. And enterprises must architect a data platform strategy that brings together enterprise data with guardrails, governance framework, and accessibility to feed AI. Also, it’s critical to keep standardizing infrastructure (such as private cloud AI platforms), protecting data integrity, and safeguarding brand trust, all while enabling the speed and flexibility that AI applications demand. These are the requirements for reaching the final milestone: AI that's truly in production.&lt;/p&gt;  &lt;p&gt;For teams on the path to that goal, Reichenbach distills what success requires. "It comes down to knowing where you play: When to Run external models smarter, when to apply RAG to make them more informed, where to invest to unlock Riches from your own data and models, and when to Regulate what you don't control," says Reichenbach. "The winners will be those who bring clarity to all quadrants and align technology ambition with governance and value creation."&lt;/p&gt;  &lt;p&gt;&lt;em&gt;For more, &lt;/em&gt;&lt;em&gt;register to watch MIT Technology Review's EmTech AI Salon, featuring HPE&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;&lt;span class="sponsoredModule__name--dbd90349922f15155a4c483b397356c2"&gt;HPE&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Training an AI model to predict equipment failures is an engineering achievement. But it's not until prediction meets action—the moment that model successfully flags a malfunctioning machine—that true business transformation occurs. One technical milestone lives in a proof-of-concept deck; the other meaningfully contributes to the bottom line.&lt;/p&gt;  &lt;p&gt;Craig Partridge, senior director worldwide of Digital Next Advisory at HPE, believes "the true value of AI lies in inference”. Inference is where AI earns its keep. It’s the operational layer that puts all that training to use in real-world workflows.&amp;nbsp;Partridge elaborates, "The phrase we use for this is 'trusted AI inferencing at scale and in production,'" he says. "That's where we think the biggest return on AI investments will come from."&lt;/p&gt;&lt;p&gt;Getting to that point is difficult. Christian Reichenbach, worldwide digital advisor at HPE, points to findings from the company's recent survey of 1,775 IT leaders: While nearly a quarter (22%) of organizations have now operationalized AI—up from 15% the previous year—the majority remain stuck in experimentation.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Reaching the next stage requires a three-part approach: establishing trust as an operating principle, ensuring data-centric execution, and cultivating IT leadership capable of scaling AI successfully.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Trust as a prerequisite for scalable, high-stakes AI&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Trusted inference means users can actually rely on the answers they're getting from AI systems. This is important for applications like generating marketing copy and deploying customer service chatbots, but it's absolutely critical for higher-stakes scenarios—say, a robot assisting during surgeries or an autonomous vehicle navigating crowded streets.&lt;/p&gt; 
 &lt;p&gt;Whatever the use case, establishing trust will require doubling down on data quality; first and foremost, inferencing outcomes must be built on reliable foundations. This reality informs one of Partridge's go-to mantras: "Bad data in equals bad inferencing out."&lt;/p&gt;  &lt;p&gt;Reichenbach cites a real-world example of what happens when data quality falls short—the rise of unreliable AI-generated content, including hallucinations, that clogs workflows and forces employees to spend significant time fact-checking. "When things go wrong, trust goes down, productivity gains are not reached, and the outcome we're&amp;nbsp; looking for is not achieved," he says.&lt;/p&gt; 
 &lt;p&gt;On the other hand, when trust is properly engineered into inference systems, efficiency and productivity gains can increase. Take a network operations team tasked with troubleshooting configurations. With a trusted inferencing engine, that unit gains a reliable copilot that can deliver faster, more accurate, custom-tailored recommendations—"a 24/7 member of the team they didn't have before," says Partridge.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;The shift to data-centric thinking and rise of the AI factory&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;In the first AI wave, companies rushed to hire data scientists and many viewed sophisticated, trillion-parameter models as the primary goal. But today, as organizations move to turn early pilots into real, measurable outcomes, the focus has shifted toward data engineering and architecture.&lt;/p&gt;  &lt;p&gt;"Over the past five years, what's become more meaningful is breaking down data silos, accessing data streams, and quickly unlocking value," says Reichenbach. It’s an evolution happening alongside the rise of the AI factory—the always-on production line where data moves through pipelines and feedback loops to generate continuous intelligence.&lt;/p&gt;  &lt;p&gt;This shift reflects an evolution from model-centric to data-centric thinking, and with it comes a new set of strategic considerations. "It comes down to two things: How much of the intelligence--the model itself--is truly yours? And how much of the input--the data--is uniquely yours, from your customers, operations, or market?" says Reichenbach.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;These two central questions inform everything from platform direction and operating models to engineering roles and trust and security considerations. To help clients map their answers—and translate them into actionable strategies—Partridge breaks down HPE's four-quadrant AI factory implication matrix (see figure):&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1128011" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/HPE_AI-factory-implication-matrix_02@2x.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;Source: HPE, 2025&lt;/p&gt;  &lt;ul class="wp-block-list"&gt; &lt;li&gt;&lt;strong&gt;Run&lt;/strong&gt;: Accessing an external, pretrained model via an interface or API; organizations don’t own the model or the data. Implementation requires strong security and governance. It also requires establishing a center of excellence that makes and communicates decisions about AI usage.&lt;/li&gt;    &lt;li&gt;&lt;strong&gt;RAG (retrieval augmented generation)&lt;/strong&gt;: Using external, pre-trained models combined with a company’s proprietary data to create unique insights. Implementation focuses on connecting data streams to inferencing capabilities that provide rapid, integrated access to full-stack AI platforms.&lt;/li&gt;    &lt;li&gt;&lt;strong&gt;Riches&lt;/strong&gt;: Training custom models on data that resides in the enterprise for unique differentiation opportunities and insights. Implementation requires scalable, energy-efficient environments, and often high-performance systems.&lt;/li&gt;    &lt;li&gt;&lt;strong&gt;Regulate&lt;/strong&gt;: Leveraging custom models trained on external data, requiring the same scalable setup as Riches, but with added focus on legal and regulatory compliance for handling sensitive, non-owned data with extreme caution.&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;Importantly, these quadrants are not mutually exclusive. Partridge notes that most organizations—including HPE itself—operate across many of the quadrants. "We build our own models to help understand how networks operate," he says. "We then deploy that intelligence into our products, so that our end customer gets the chance to deliver in what we call the 'Run' quadrant. So for them, it's not their data; it's not their model. They're just adding that capability inside their organization."&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;IT's moment to scale—and lead&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;The second part of Partridge's catchphrase about inferencing—"at scale"— speaks to a primary tension in enterprise AI: what works for a handful of use cases often breaks when applied across an entire organization.&lt;/p&gt; 

 &lt;p&gt;"There's value in experimentation and kicking ideas around," he says. "But if you want to really see the benefits of AI, it needs to be something that everybody can engage in and that solves for many different use cases."&lt;/p&gt;  &lt;p&gt;In Partridge's view, the challenge of turning boutique pilots into organization-wide systems is uniquely suited to the IT function's core competencies—and it's a leadership opportunity the function can't afford to sit out. "IT takes things that are small-scale and implements the discipline required to run them at scale," he says. "So, IT organizations really need to lean into this debate."&lt;/p&gt;  &lt;p&gt;For IT teams content to linger on the sidelines, history offers a cautionary tale from the last major infrastructure shift: enterprise migration to the cloud. Many IT departments sat out decision-making during the early cloud adoption wave a decade ago, while business units independently deployed cloud services. This led to fragmented systems, redundant spending, and security gaps that took years to untangle.&lt;/p&gt;  &lt;p&gt;The same dynamic threatens to repeat with AI, as different teams experiment with tools and models outside IT's purview. This phenomenon—sometimes called shadow AI—describes environments where pilots proliferate without oversight or governance. Partridge believes that most organizations are already operating in the "Run" quadrant in some capacity, as employees will use AI tools whether or not they're officially authorized to.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Rather than shut down experimentation, it is now IT's mandate to bring structure to it. And enterprises must architect a data platform strategy that brings together enterprise data with guardrails, governance framework, and accessibility to feed AI. Also, it’s critical to keep standardizing infrastructure (such as private cloud AI platforms), protecting data integrity, and safeguarding brand trust, all while enabling the speed and flexibility that AI applications demand. These are the requirements for reaching the final milestone: AI that's truly in production.&lt;/p&gt;  &lt;p&gt;For teams on the path to that goal, Reichenbach distills what success requires. "It comes down to knowing where you play: When to Run external models smarter, when to apply RAG to make them more informed, where to invest to unlock Riches from your own data and models, and when to Regulate what you don't control," says Reichenbach. "The winners will be those who bring clarity to all quadrants and align technology ambition with governance and value creation."&lt;/p&gt;  &lt;p&gt;&lt;em&gt;For more, &lt;/em&gt;&lt;em&gt;register to watch MIT Technology Review's EmTech AI Salon, featuring HPE&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/11/18/1128007/realizing-value-with-ai-inference-at-scale-and-in-production/</guid><pubDate>Tue, 18 Nov 2025 16:02:16 +0000</pubDate></item><item><title>[NEW] Networking for AI: Building the foundation for real-time intelligence (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/11/18/1127997/networking-for-ai-building-the-foundation-for-real-time-intelligence/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;&lt;span class="sponsoredModule__name--dbd90349922f15155a4c483b397356c2"&gt;HPE&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;The Ryder Cup is an almost-century-old tournament pitting Europe against the United States in an elite showcase of golf skill and strategy. At the 2025 event, nearly a quarter of a million spectators gathered to watch three days of fierce competition on the fairways.&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1128002" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/MITTR-Networking-image-16x9-1.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;From a technology and logistics perspective, pulling off an event of this scale is no easy feat. The Ryder Cup’s infrastructure must accommodate the tens of thousands of network users who flood the venue (this year, at Bethpage Black in Farmingdale, New York) every day.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;To manage this IT complexity, Ryder Cup engaged technology partner HPE to create a central hub for its operations. The solution centered around a platform where tournament staff could access data visualization supporting operational decision-making.&amp;nbsp;This dashboard, which leveraged a high-performance network and private-cloud environment, aggregated and distilled insights from diverse&amp;nbsp;real-time&amp;nbsp;data feeds.&lt;/p&gt;  &lt;p&gt;It was a glimpse into what AI-ready networking looks like at scale—a real-world stress test with implications for everything from event management to enterprise operations. While models and data readiness get the lion's share of boardroom attention and media hype, networking is a critical third leg of successful AI implementation, explains Jon Green, CTO of HPE Networking. “Disconnected AI doesn’t get you very much; you need a way to get data into it and out of it for both training and inference,” he says.&lt;/p&gt; 
 &lt;p&gt;As businesses move toward distributed, real-time AI applications, tomorrow’s networks will need to parse even more massive volumes of information at ever more lightning-fast speeds. What played out on the greens at Bethpage Black represents a lesson being learned across industries: Inference-ready networks are a make-or-break factor for turning AI’s promise into real-world performance.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Making a network AI inference-ready&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;More than half of organizations are still struggling to operationalize their data pipelines. In a recent HPE cross-industry survey of 1,775 &amp;nbsp;IT leaders, 45% said they could run real-time data pushes and pulls for innovation. It’s a noticeable change over last year’s numbers (just 7% reported having such capabilities in 2024), but there’s still work to be done to connect data collection with real-time decision-making.&lt;/p&gt; 
 &lt;p&gt;The network may hold the key to further narrowing that gap. Part of the solution will likely come down to infrastructure design. While traditional enterprise networks are engineered to handle the predictable flow of business applications—email, browsers, file sharing, etc.—they're not designed to field the dynamic, high-volume data movement required by AI workloads. Inferencing in particular depends on shuttling vast datasets between multiple GPUs with supercomputer-like precision.&lt;/p&gt;  &lt;p&gt;“There’s an ability to play fast and loose with a standard, off-the-shelf enterprise network,” says Green. “Few will notice if an email platform is half a second slower than it might’ve been. But with AI transaction processing, the entire job is gated by the last calculation taking place. So it becomes really noticeable if you’ve got any loss or congestion.”&lt;/p&gt;  &lt;p&gt;Networks built for AI, therefore, must operate with a different set of performance characteristics, including ultra-low latency, lossless throughput, specialized equipment, and adaptability at scale. One of these differences is AI’s distributed nature, which affects the seamless flow of data.&lt;/p&gt;  &lt;p&gt;The Ryder Cup was a vivid demonstration of this new class of networking in action. During the event, a Connected Intelligence Center was put in place to ingest data from ticket scans, weather reports, GPS-tracked golf carts, concession and merchandise sales, spectator and consumer queues, and network performance. Additionally, 67 AI-enabled cameras were positioned throughout the course. Inputs were analyzed through an operational intelligence dashboard and provided staff with an instantaneous view of activity across the grounds.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;"The tournament is really complex from a networking perspective, because you have many big open areas that aren't uniformly packed with people," explains Green. "People tend to follow the action. So in certain areas, it's really dense with lots of people and devices, while other areas are completely empty."&lt;/p&gt;  &lt;p&gt;To handle that variability, engineers built out a two-tiered architecture. Across the sprawling venue, more than 650 WiFi 6E access points, 170 network switches, and 25 user experience sensors worked together to maintain continuous connectivity and feed a private cloud AI cluster for live analytics. The front-end layer connected cameras, sensors, and access points to capture live video and movement data, while a back-end layer—located within a temporary on-site data center—linked GPUs and servers in a high-speed, low-latency configuration that effectively served as the system’s brain. Together, the setup enabled both rapid on-the-ground responses and data collection that could inform future operational planning. "AI models also were available to the team which could process video of the shots taken and help determine, from the footage, which ones were the most interesting,” says Green.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Physical AI and the return of on-prem intelligence&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;If time is of the essence for event management, it's even more critical in contexts where safety is on the line—for instance a self-driving car making a split-second decision to accelerate or brake.&lt;/p&gt;  &lt;p&gt;In planning for the rise of physical AI, where applications move off screens and onto factory floors and city streets, a growing number of enterprises are rethinking their architectures. Instead of sending the data to centralized clouds for inference, some are deploying edge-based AI clusters that process information closer to where it is generated. Data-intensive training may still occur in the cloud, but inferencing happens on-site.&lt;/p&gt; 

 &lt;p&gt;This hybrid approach is fueling a wave of operational repatriation, as workloads once relegated to the cloud return to on-premises infrastructure for enhanced speed, security, sovereignty, and cost reasons. "We’ve had an out-migration of IT into the cloud in recent years, but physical AI is one of the use cases that we believe will bring a lot of that back on-prem," predicts Green, giving the example of an AI-infused factory floor, where a round-trip of sensor data to the cloud would be too slow to safely control automated machinery. "By the time processing happens in the cloud, the machine has already moved," he explains.&lt;/p&gt;  &lt;p&gt;There's data to back up Green's projection: research&amp;nbsp;from Enterprise Research Group shows that 84% of respondents are reevaluating application deployment strategies due to the growth of AI. Market forecasts also reflect this shift. According to IDC, the AI market for infrastructure is expected to reach $758 billion by 2029.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;AI for networking and the future of self-driving infrastructure&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;The relationship between networking and AI is circular: Modern networks make AI at scale possible, but AI is also helping make networks smarter and more capable.&lt;/p&gt;  &lt;p&gt;“Networks are some of the most data-rich systems in any organization,” says Green. “That makes them a perfect use case for AI. We can analyze millions of configuration states across thousands of customer environments and learn what actually improves performance or stability.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;At HPE for example, which has one of the largest network telemetry repositories in the world, AI models analyze anonymized data collected from billions of connected devices to identify trends and refine behavior over time. The platform processes more than a trillion telemetry points each day, which means it can continuously learn from real-world conditions.&lt;/p&gt;  &lt;p&gt;The concept broadly known as AIOps (or AI-driven IT operations) is changing how enterprise networks are managed across industries. Today, AI surfaces insights as recommendations that administrators can choose to apply with a single click. Tomorrow, those same systems might automatically test and deploy low-risk changes themselves.&lt;/p&gt;  &lt;p&gt;That long-term vision, Green notes, is referred to as a “self-driving network”—one that handles the repetitive, error-prone tasks that have historically plagued IT teams. “AI isn’t coming for the network engineer’s job, but it will eliminate the tedious stuff that slows them down," he says. "You’ll be able to say, ‘Please go configure 130 switches to solve this issue,’ and the system will handle it. When a port gets stuck or someone plugs a connector in the wrong direction, AI can detect it—and in many cases, fix it automatically.”&lt;/p&gt;  &lt;p&gt;Digital initiatives now depend on how effectively information moves. Whether coordinating a live event or streamlining a supply chain, the performance of the network increasingly defines the performance of the business. Building that foundation today will separate those who pilot from those who scale AI.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;For more, &lt;/em&gt;&lt;em&gt;register to watch MIT Technology Review's EmTech AI Salon, featuring HPE&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;&lt;span class="sponsoredModule__name--dbd90349922f15155a4c483b397356c2"&gt;HPE&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;The Ryder Cup is an almost-century-old tournament pitting Europe against the United States in an elite showcase of golf skill and strategy. At the 2025 event, nearly a quarter of a million spectators gathered to watch three days of fierce competition on the fairways.&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1128002" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/MITTR-Networking-image-16x9-1.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;From a technology and logistics perspective, pulling off an event of this scale is no easy feat. The Ryder Cup’s infrastructure must accommodate the tens of thousands of network users who flood the venue (this year, at Bethpage Black in Farmingdale, New York) every day.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;To manage this IT complexity, Ryder Cup engaged technology partner HPE to create a central hub for its operations. The solution centered around a platform where tournament staff could access data visualization supporting operational decision-making.&amp;nbsp;This dashboard, which leveraged a high-performance network and private-cloud environment, aggregated and distilled insights from diverse&amp;nbsp;real-time&amp;nbsp;data feeds.&lt;/p&gt;  &lt;p&gt;It was a glimpse into what AI-ready networking looks like at scale—a real-world stress test with implications for everything from event management to enterprise operations. While models and data readiness get the lion's share of boardroom attention and media hype, networking is a critical third leg of successful AI implementation, explains Jon Green, CTO of HPE Networking. “Disconnected AI doesn’t get you very much; you need a way to get data into it and out of it for both training and inference,” he says.&lt;/p&gt; 
 &lt;p&gt;As businesses move toward distributed, real-time AI applications, tomorrow’s networks will need to parse even more massive volumes of information at ever more lightning-fast speeds. What played out on the greens at Bethpage Black represents a lesson being learned across industries: Inference-ready networks are a make-or-break factor for turning AI’s promise into real-world performance.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Making a network AI inference-ready&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;More than half of organizations are still struggling to operationalize their data pipelines. In a recent HPE cross-industry survey of 1,775 &amp;nbsp;IT leaders, 45% said they could run real-time data pushes and pulls for innovation. It’s a noticeable change over last year’s numbers (just 7% reported having such capabilities in 2024), but there’s still work to be done to connect data collection with real-time decision-making.&lt;/p&gt; 
 &lt;p&gt;The network may hold the key to further narrowing that gap. Part of the solution will likely come down to infrastructure design. While traditional enterprise networks are engineered to handle the predictable flow of business applications—email, browsers, file sharing, etc.—they're not designed to field the dynamic, high-volume data movement required by AI workloads. Inferencing in particular depends on shuttling vast datasets between multiple GPUs with supercomputer-like precision.&lt;/p&gt;  &lt;p&gt;“There’s an ability to play fast and loose with a standard, off-the-shelf enterprise network,” says Green. “Few will notice if an email platform is half a second slower than it might’ve been. But with AI transaction processing, the entire job is gated by the last calculation taking place. So it becomes really noticeable if you’ve got any loss or congestion.”&lt;/p&gt;  &lt;p&gt;Networks built for AI, therefore, must operate with a different set of performance characteristics, including ultra-low latency, lossless throughput, specialized equipment, and adaptability at scale. One of these differences is AI’s distributed nature, which affects the seamless flow of data.&lt;/p&gt;  &lt;p&gt;The Ryder Cup was a vivid demonstration of this new class of networking in action. During the event, a Connected Intelligence Center was put in place to ingest data from ticket scans, weather reports, GPS-tracked golf carts, concession and merchandise sales, spectator and consumer queues, and network performance. Additionally, 67 AI-enabled cameras were positioned throughout the course. Inputs were analyzed through an operational intelligence dashboard and provided staff with an instantaneous view of activity across the grounds.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;"The tournament is really complex from a networking perspective, because you have many big open areas that aren't uniformly packed with people," explains Green. "People tend to follow the action. So in certain areas, it's really dense with lots of people and devices, while other areas are completely empty."&lt;/p&gt;  &lt;p&gt;To handle that variability, engineers built out a two-tiered architecture. Across the sprawling venue, more than 650 WiFi 6E access points, 170 network switches, and 25 user experience sensors worked together to maintain continuous connectivity and feed a private cloud AI cluster for live analytics. The front-end layer connected cameras, sensors, and access points to capture live video and movement data, while a back-end layer—located within a temporary on-site data center—linked GPUs and servers in a high-speed, low-latency configuration that effectively served as the system’s brain. Together, the setup enabled both rapid on-the-ground responses and data collection that could inform future operational planning. "AI models also were available to the team which could process video of the shots taken and help determine, from the footage, which ones were the most interesting,” says Green.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Physical AI and the return of on-prem intelligence&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;If time is of the essence for event management, it's even more critical in contexts where safety is on the line—for instance a self-driving car making a split-second decision to accelerate or brake.&lt;/p&gt;  &lt;p&gt;In planning for the rise of physical AI, where applications move off screens and onto factory floors and city streets, a growing number of enterprises are rethinking their architectures. Instead of sending the data to centralized clouds for inference, some are deploying edge-based AI clusters that process information closer to where it is generated. Data-intensive training may still occur in the cloud, but inferencing happens on-site.&lt;/p&gt; 

 &lt;p&gt;This hybrid approach is fueling a wave of operational repatriation, as workloads once relegated to the cloud return to on-premises infrastructure for enhanced speed, security, sovereignty, and cost reasons. "We’ve had an out-migration of IT into the cloud in recent years, but physical AI is one of the use cases that we believe will bring a lot of that back on-prem," predicts Green, giving the example of an AI-infused factory floor, where a round-trip of sensor data to the cloud would be too slow to safely control automated machinery. "By the time processing happens in the cloud, the machine has already moved," he explains.&lt;/p&gt;  &lt;p&gt;There's data to back up Green's projection: research&amp;nbsp;from Enterprise Research Group shows that 84% of respondents are reevaluating application deployment strategies due to the growth of AI. Market forecasts also reflect this shift. According to IDC, the AI market for infrastructure is expected to reach $758 billion by 2029.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;AI for networking and the future of self-driving infrastructure&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;The relationship between networking and AI is circular: Modern networks make AI at scale possible, but AI is also helping make networks smarter and more capable.&lt;/p&gt;  &lt;p&gt;“Networks are some of the most data-rich systems in any organization,” says Green. “That makes them a perfect use case for AI. We can analyze millions of configuration states across thousands of customer environments and learn what actually improves performance or stability.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;At HPE for example, which has one of the largest network telemetry repositories in the world, AI models analyze anonymized data collected from billions of connected devices to identify trends and refine behavior over time. The platform processes more than a trillion telemetry points each day, which means it can continuously learn from real-world conditions.&lt;/p&gt;  &lt;p&gt;The concept broadly known as AIOps (or AI-driven IT operations) is changing how enterprise networks are managed across industries. Today, AI surfaces insights as recommendations that administrators can choose to apply with a single click. Tomorrow, those same systems might automatically test and deploy low-risk changes themselves.&lt;/p&gt;  &lt;p&gt;That long-term vision, Green notes, is referred to as a “self-driving network”—one that handles the repetitive, error-prone tasks that have historically plagued IT teams. “AI isn’t coming for the network engineer’s job, but it will eliminate the tedious stuff that slows them down," he says. "You’ll be able to say, ‘Please go configure 130 switches to solve this issue,’ and the system will handle it. When a port gets stuck or someone plugs a connector in the wrong direction, AI can detect it—and in many cases, fix it automatically.”&lt;/p&gt;  &lt;p&gt;Digital initiatives now depend on how effectively information moves. Whether coordinating a live event or streamlining a supply chain, the performance of the network increasingly defines the performance of the business. Building that foundation today will separate those who pilot from those who scale AI.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;For more, &lt;/em&gt;&lt;em&gt;register to watch MIT Technology Review's EmTech AI Salon, featuring HPE&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/11/18/1127997/networking-for-ai-building-the-foundation-for-real-time-intelligence/</guid><pubDate>Tue, 18 Nov 2025 16:03:14 +0000</pubDate></item><item><title>[NEW] Google unveils Gemini 3 AI model and AI-first IDE called Antigravity (AI – Ars Technica)</title><link>https://arstechnica.com/google/2025/11/google-unveils-gemini-3-ai-model-and-ai-first-ide-called-antigravity/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google’s flagship AI model is getting its second major upgrade this year.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Gemini 3" class="absolute inset-0 w-full h-full object-cover hidden" height="361" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Gemini-3-640x361.png" width="640" /&gt;
                  &lt;img alt="Gemini 3" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Gemini-3-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Google has kicked its Gemini rollout into high gear over the past year, releasing the much-improved Gemini 2.5 family and cramming various flavors of the model into Search, Gmail, and just about everything else the company makes.&lt;/p&gt;
&lt;p&gt;Now, Google’s increasingly unavoidable AI is getting an upgrade. Gemini 3 Pro is available in a limited form today, featuring more immersive, visual outputs and fewer lies, Google says. The company also says Gemini 3 sets a new high-water mark for vibe coding, and Google is announcing a new AI-first integrated development environment (IDE) called Antigravity, which is also available today.&lt;/p&gt;
&lt;h2&gt;The first member of the Gemini 3 family&lt;/h2&gt;
&lt;p&gt;Google says the release of Gemini 3 is yet another step toward artificial general intelligence (AGI). The new version of Google’s flagship AI model has expanded simulated reasoning abilities and shows improved understanding of text, images, and video. So far, testers like it—Google’s latest LLM is once again atop the LMArena leaderboard with an ELO score of 1,501, besting Gemini 2.5 Pro by 50 points.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2128002 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="Gemini 3 LMArena" class="fullwidth full" height="2160" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/gemini_3_lm_arena_leaderboard-1.png" width="3840" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Factuality has been a problem for all gen AI models, but Google says Gemini 3 is a big step in the right direction, and there are myriad benchmarks to tell the story. In the 1,000-question SimpleQA Verified test, Gemini 3 scored a record 72.1 percent. Yes, that means the state-of-the-art LLM still screws up almost 30 percent of general knowledge questions, but Google says this still shows substantial progress. On the much more difficult Humanity’s Last Exam, which tests PhD-level knowledge and reasoning, Gemini set another record, scoring 37.5 percent without tool use.&lt;/p&gt;
&lt;p&gt;Math and coding are also a focus of Gemini 3. The model set new records in MathArena Apex (23.4 percent) and WebDev Arena (1487 ELO). In the SWE-bench Verified, which tests a model’s ability to generate code, Gemini 3 hit an impressive 76.2 percent.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1440" id="video-2127999-1" preload="metadata" width="2560"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Scale-Illustrator-Demo.mp4?_=1" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;So there are plenty of respectable but modest benchmark improvements, but Gemini 3 also won’t make you cringe as much. Google says it has tamped down on sycophancy, a common problem in all these overly polite LLMs. Outputs from Gemini 3 Pro are reportedly more concise, with less of what you want to hear and more of what you need to hear.&lt;/p&gt;
&lt;p&gt;You can also expect Gemini 3 Pro to produce noticeably richer outputs. Google claims Gemini’s expanded reasoning capabilities keep it on task more effectively, allowing it to take action on your behalf. For example, Gemini 3 can triage and take action on your emails, creating to-do lists, summaries, recommended replies, and handy buttons to trigger suggested actions. This differs from the current Gemini models, which would only create a text-based to-do list with similar prompts.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2127999-2" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Gemini-Agent.mp4?_=2" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The model also has what Google calls a “generative interface,” which comes in the form of two experimental output modes called visual layout and dynamic view. The former is a magazine-style interface that includes lots of images in a scrollable UI. Dynamic view leverages Gemini’s coding abilities to create custom interfaces—for example, a web app that explores the life and work of Vincent Van Gogh.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2127999-3" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Gemini-App-Dynamic-View.mp4?_=3" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;There will also be a Deep Think mode for Gemini 3, but that’s not ready for prime time yet. Google says it’s being tested by a small group for later release, but you should expect big things. Deep Think mode manages 41 percent in Humanity’s Last Exam without tools. Believe it or not, that’s an impressive score.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Coding with vibes&lt;/h2&gt;
&lt;p&gt;Google has offered several ways of generating and modifying code with Gemini models, but the launch of Gemini 3 adds a new one: Google Antigravity. This is Google’s new agentic development platform—it’s essentially an IDE designed around agentic AI, and it’s available in preview today.&lt;/p&gt;
&lt;p&gt;With Antigravity, Google promises that you (the human) can get more work done by letting intelligent agents do the legwork. Google says you should think of Antigravity as a “mission control” for creating and monitoring multiple development agents. The AI in Antigravity can operate autonomously across the editor, terminal, and browser to create and modify projects, but everything they do is relayed to the user in the form of “Artifacts.” These sub-tasks are designed to be easily verifiable so you can keep on top of what the agent is doing. Gemini will be at the core of the Antigravity experience, but it’s not just Google’s bot. Antigravity also supports Claude Sonnet 4.5 and GPT-OSS agents.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="2160" id="video-2127999-4" preload="metadata" width="3840"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Google-Antigravity-Demo.mp4?_=4" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Of course, developers can still plug into the Gemini API for coding tasks. With Gemini 3, Google is adding a client-side bash tool, which lets the AI generate shell commands in its workflow. The model can access file systems and automate operations, and a server-side bash tool will help generate code in multiple languages. This feature is starting in early access, though.&lt;/p&gt;
&lt;p&gt;AI Studio is designed to be a faster way to build something with Gemini 3. Google says Gemini 3 Pro’s strong instruction following makes it the best vibe coding model yet, allowing non-programmers to create more complex projects.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;A big experiment&lt;/h2&gt;
&lt;p&gt;Google will eventually have a whole family of Gemini 3 models, but there’s just the one for now. Gemini 3 Pro is rolling out in the Gemini app, AI Studio, Vertex AI, and the API starting today as an experiment. If you want to tinker with the new model in Google’s Antigravity IDE, that’s also available for testing today on Windows, Mac, and Linux.&lt;/p&gt;
&lt;p&gt;Gemini 3 will also launch in the Google search experience on day one. You’ll have the option to enable Gemini 3 Pro in AI Mode, where Google says it will provide more useful information about a query. The generative interface capabilities from the Gemini app will be available here as well, allowing Gemini to create tools and simulations when appropriate to answer the user’s question. Google says these generative interfaces are strongly preferred in its user testing. This feature is available today, but only for AI Pro and Ultra subscribers.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2127999-5" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Gemini-3-in-AI-Mode-Generative-UI-Home-Loan.mp4?_=5" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Because the Pro model is the only Gemini 3 variant available in the preview, AI Overviews isn’t getting an immediate upgrade. That will come, but for now, Overviews will only reach out to Gemini 3 Pro for especially difficult search queries—basically the kind of thing Google thinks you should have used AI Mode to do in the first place.&lt;/p&gt;
&lt;p&gt;There’s no official timeline for releasing more Gemini 3 models or graduating the Pro variant to general availability. However, given the wide rollout of the experimental release, it probably won’t be long.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google’s flagship AI model is getting its second major upgrade this year.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Gemini 3" class="absolute inset-0 w-full h-full object-cover hidden" height="361" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Gemini-3-640x361.png" width="640" /&gt;
                  &lt;img alt="Gemini 3" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Gemini-3-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Google has kicked its Gemini rollout into high gear over the past year, releasing the much-improved Gemini 2.5 family and cramming various flavors of the model into Search, Gmail, and just about everything else the company makes.&lt;/p&gt;
&lt;p&gt;Now, Google’s increasingly unavoidable AI is getting an upgrade. Gemini 3 Pro is available in a limited form today, featuring more immersive, visual outputs and fewer lies, Google says. The company also says Gemini 3 sets a new high-water mark for vibe coding, and Google is announcing a new AI-first integrated development environment (IDE) called Antigravity, which is also available today.&lt;/p&gt;
&lt;h2&gt;The first member of the Gemini 3 family&lt;/h2&gt;
&lt;p&gt;Google says the release of Gemini 3 is yet another step toward artificial general intelligence (AGI). The new version of Google’s flagship AI model has expanded simulated reasoning abilities and shows improved understanding of text, images, and video. So far, testers like it—Google’s latest LLM is once again atop the LMArena leaderboard with an ELO score of 1,501, besting Gemini 2.5 Pro by 50 points.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2128002 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="Gemini 3 LMArena" class="fullwidth full" height="2160" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/gemini_3_lm_arena_leaderboard-1.png" width="3840" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Factuality has been a problem for all gen AI models, but Google says Gemini 3 is a big step in the right direction, and there are myriad benchmarks to tell the story. In the 1,000-question SimpleQA Verified test, Gemini 3 scored a record 72.1 percent. Yes, that means the state-of-the-art LLM still screws up almost 30 percent of general knowledge questions, but Google says this still shows substantial progress. On the much more difficult Humanity’s Last Exam, which tests PhD-level knowledge and reasoning, Gemini set another record, scoring 37.5 percent without tool use.&lt;/p&gt;
&lt;p&gt;Math and coding are also a focus of Gemini 3. The model set new records in MathArena Apex (23.4 percent) and WebDev Arena (1487 ELO). In the SWE-bench Verified, which tests a model’s ability to generate code, Gemini 3 hit an impressive 76.2 percent.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1440" id="video-2127999-1" preload="metadata" width="2560"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Scale-Illustrator-Demo.mp4?_=1" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;So there are plenty of respectable but modest benchmark improvements, but Gemini 3 also won’t make you cringe as much. Google says it has tamped down on sycophancy, a common problem in all these overly polite LLMs. Outputs from Gemini 3 Pro are reportedly more concise, with less of what you want to hear and more of what you need to hear.&lt;/p&gt;
&lt;p&gt;You can also expect Gemini 3 Pro to produce noticeably richer outputs. Google claims Gemini’s expanded reasoning capabilities keep it on task more effectively, allowing it to take action on your behalf. For example, Gemini 3 can triage and take action on your emails, creating to-do lists, summaries, recommended replies, and handy buttons to trigger suggested actions. This differs from the current Gemini models, which would only create a text-based to-do list with similar prompts.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2127999-2" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Gemini-Agent.mp4?_=2" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The model also has what Google calls a “generative interface,” which comes in the form of two experimental output modes called visual layout and dynamic view. The former is a magazine-style interface that includes lots of images in a scrollable UI. Dynamic view leverages Gemini’s coding abilities to create custom interfaces—for example, a web app that explores the life and work of Vincent Van Gogh.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2127999-3" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Gemini-App-Dynamic-View.mp4?_=3" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;There will also be a Deep Think mode for Gemini 3, but that’s not ready for prime time yet. Google says it’s being tested by a small group for later release, but you should expect big things. Deep Think mode manages 41 percent in Humanity’s Last Exam without tools. Believe it or not, that’s an impressive score.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Coding with vibes&lt;/h2&gt;
&lt;p&gt;Google has offered several ways of generating and modifying code with Gemini models, but the launch of Gemini 3 adds a new one: Google Antigravity. This is Google’s new agentic development platform—it’s essentially an IDE designed around agentic AI, and it’s available in preview today.&lt;/p&gt;
&lt;p&gt;With Antigravity, Google promises that you (the human) can get more work done by letting intelligent agents do the legwork. Google says you should think of Antigravity as a “mission control” for creating and monitoring multiple development agents. The AI in Antigravity can operate autonomously across the editor, terminal, and browser to create and modify projects, but everything they do is relayed to the user in the form of “Artifacts.” These sub-tasks are designed to be easily verifiable so you can keep on top of what the agent is doing. Gemini will be at the core of the Antigravity experience, but it’s not just Google’s bot. Antigravity also supports Claude Sonnet 4.5 and GPT-OSS agents.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="2160" id="video-2127999-4" preload="metadata" width="3840"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Google-Antigravity-Demo.mp4?_=4" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Of course, developers can still plug into the Gemini API for coding tasks. With Gemini 3, Google is adding a client-side bash tool, which lets the AI generate shell commands in its workflow. The model can access file systems and automate operations, and a server-side bash tool will help generate code in multiple languages. This feature is starting in early access, though.&lt;/p&gt;
&lt;p&gt;AI Studio is designed to be a faster way to build something with Gemini 3. Google says Gemini 3 Pro’s strong instruction following makes it the best vibe coding model yet, allowing non-programmers to create more complex projects.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;A big experiment&lt;/h2&gt;
&lt;p&gt;Google will eventually have a whole family of Gemini 3 models, but there’s just the one for now. Gemini 3 Pro is rolling out in the Gemini app, AI Studio, Vertex AI, and the API starting today as an experiment. If you want to tinker with the new model in Google’s Antigravity IDE, that’s also available for testing today on Windows, Mac, and Linux.&lt;/p&gt;
&lt;p&gt;Gemini 3 will also launch in the Google search experience on day one. You’ll have the option to enable Gemini 3 Pro in AI Mode, where Google says it will provide more useful information about a query. The generative interface capabilities from the Gemini app will be available here as well, allowing Gemini to create tools and simulations when appropriate to answer the user’s question. Google says these generative interfaces are strongly preferred in its user testing. This feature is available today, but only for AI Pro and Ultra subscribers.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2127999-5" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Gemini-3-in-AI-Mode-Generative-UI-Home-Loan.mp4?_=5" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Because the Pro model is the only Gemini 3 variant available in the preview, AI Overviews isn’t getting an immediate upgrade. That will come, but for now, Overviews will only reach out to Gemini 3 Pro for especially difficult search queries—basically the kind of thing Google thinks you should have used AI Mode to do in the first place.&lt;/p&gt;
&lt;p&gt;There’s no official timeline for releasing more Gemini 3 models or graduating the Pro variant to general availability. However, given the wide rollout of the experimental release, it probably won’t be long.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/google/2025/11/google-unveils-gemini-3-ai-model-and-ai-first-ide-called-antigravity/</guid><pubDate>Tue, 18 Nov 2025 16:08:56 +0000</pubDate></item><item><title>[NEW] Microsoft, NVIDIA, and Anthropic forge AI compute alliance (AI News)</title><link>https://www.artificialintelligence-news.com/news/microsoft-nvidia-and-anthropic-forge-ai-compute-alliance/</link><description>&lt;p&gt;Microsoft, Anthropic, and NVIDIA are setting a bar for cloud infrastructure investment and AI model availability with a new compute alliance. This agreement signals a divergence from single-model dependency toward a diversified, hardware-optimised ecosystem, altering the governance landscape for senior technology leaders.&lt;/p&gt;&lt;p&gt;Microsoft CEO Satya Nadella says the relationship is a reciprocal integration where the companies are “increasingly going to be customers of each other”. While Anthropic leverages Azure infrastructure, Microsoft will incorporate Anthropic models across its product stack.&lt;/p&gt;&lt;p&gt;Anthropic has committed to purchasing $30 billion of Azure compute capacity. This figure shows the immense computational requirements necessary to train and deploy the next generation of frontier models. The collaboration involves a specific hardware trajectory, beginning with NVIDIA’s Grace Blackwell systems and progressing to the Vera Rubin architecture.&lt;/p&gt;&lt;p&gt;NVIDIA CEO Jensen Huang expects the Grace Blackwell architecture with NVLink to deliver an “order of magnitude speed up,” a necessary leap for driving down token economics.&lt;/p&gt;&lt;p&gt;For those overseeing infrastructure strategy, Huang’s description of a “shift-left” engineering approach – where NVIDIA technology appears on Azure immediately upon release – suggests that enterprises running Claude on Azure will access performance characteristics distinct from standard instances. This deep integration may influence architectural decisions regarding latency-sensitive applications or high-throughput batch processing.&lt;/p&gt;&lt;p&gt;Financial planning must now account for what Huang identifies as three simultaneous scaling laws: pre-training, post-training, and inference-time scaling.&lt;/p&gt;&lt;p&gt;Traditionally, AI compute costs were weighted heavily toward training. However, Huang notes that with test-time scaling – where the model “thinks” longer to produce higher quality answers – inference costs are rising.&lt;/p&gt;&lt;p&gt;Consequently, AI operational expenditure (OpEx) will not be a flat rate per token but will correlate with the complexity of the reasoning required. Budget forecasting for agentic workflows must therefore become more dynamic.&lt;/p&gt;&lt;p&gt;Integration into existing enterprise workflows remains a primary hurdle for adoption. To address this, Microsoft has committed to continuing access for Claude across the Copilot family.&lt;/p&gt;&lt;p&gt;Operational emphasis falls heavily on agentic capabilities. Huang highlighted Anthropic’s Model Context Protocol (MCP) as a development that has “revolutionised the agentic AI landscape”. Software engineering leaders should note that NVIDIA engineers are already utilising Claude Code to refactor legacy codebases.&lt;/p&gt;&lt;p&gt;From a security perspective, this integration simplifies the perimeter. Security leaders vetting third-party API endpoints can now provision Claude capabilities within the existing Microsoft 365 compliance boundary. This streamlines data governance, as the interaction logs and data handling remain within the established Microsoft tenant agreements.&lt;/p&gt;&lt;p&gt;Vendor lock-in persists as a friction point for CDOs and risk officers. This AI compute partnership alleviates that concern by making Claude the only frontier model available across all three prominent global cloud services. Nadella emphasised that this multi-model approach builds upon, rather than replaces, Microsoft’s existing partnership with OpenAI, which remains a core component of their strategy.&lt;/p&gt;&lt;p&gt;For Anthropic, the alliance resolves the “enterprise go-to-market” challenge. Huang noted that building an enterprise sales motion takes decades. By piggybacking on Microsoft’s established channels, Anthropic bypasses this adoption curve.&lt;/p&gt;&lt;p&gt;This trilateral agreement alters the procurement landscape. Nadella urges the industry to move beyond a “zero-sum narrative,” suggesting a future of broad and durable capabilities.&lt;/p&gt;&lt;p&gt;Organisations should review their current model portfolios. The availability of Claude Sonnet 4.5 and Opus 4.1 on Azure warrants a comparative TCO analysis against existing deployments. Furthermore, the “gigawatt of capacity” commitment signals that capacity constraints for these specific models may be less severe than in previous hardware cycles.&lt;/p&gt;&lt;p&gt;Following this AI compute partnership, the focus for enterprises must now turn from access to optimisation; matching the right model version to the specific business process to maximise the return on this expanded infrastructure.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;How Levi Strauss is using AI for its DTC-first business model&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-110612" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/image-8.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Microsoft, Anthropic, and NVIDIA are setting a bar for cloud infrastructure investment and AI model availability with a new compute alliance. This agreement signals a divergence from single-model dependency toward a diversified, hardware-optimised ecosystem, altering the governance landscape for senior technology leaders.&lt;/p&gt;&lt;p&gt;Microsoft CEO Satya Nadella says the relationship is a reciprocal integration where the companies are “increasingly going to be customers of each other”. While Anthropic leverages Azure infrastructure, Microsoft will incorporate Anthropic models across its product stack.&lt;/p&gt;&lt;p&gt;Anthropic has committed to purchasing $30 billion of Azure compute capacity. This figure shows the immense computational requirements necessary to train and deploy the next generation of frontier models. The collaboration involves a specific hardware trajectory, beginning with NVIDIA’s Grace Blackwell systems and progressing to the Vera Rubin architecture.&lt;/p&gt;&lt;p&gt;NVIDIA CEO Jensen Huang expects the Grace Blackwell architecture with NVLink to deliver an “order of magnitude speed up,” a necessary leap for driving down token economics.&lt;/p&gt;&lt;p&gt;For those overseeing infrastructure strategy, Huang’s description of a “shift-left” engineering approach – where NVIDIA technology appears on Azure immediately upon release – suggests that enterprises running Claude on Azure will access performance characteristics distinct from standard instances. This deep integration may influence architectural decisions regarding latency-sensitive applications or high-throughput batch processing.&lt;/p&gt;&lt;p&gt;Financial planning must now account for what Huang identifies as three simultaneous scaling laws: pre-training, post-training, and inference-time scaling.&lt;/p&gt;&lt;p&gt;Traditionally, AI compute costs were weighted heavily toward training. However, Huang notes that with test-time scaling – where the model “thinks” longer to produce higher quality answers – inference costs are rising.&lt;/p&gt;&lt;p&gt;Consequently, AI operational expenditure (OpEx) will not be a flat rate per token but will correlate with the complexity of the reasoning required. Budget forecasting for agentic workflows must therefore become more dynamic.&lt;/p&gt;&lt;p&gt;Integration into existing enterprise workflows remains a primary hurdle for adoption. To address this, Microsoft has committed to continuing access for Claude across the Copilot family.&lt;/p&gt;&lt;p&gt;Operational emphasis falls heavily on agentic capabilities. Huang highlighted Anthropic’s Model Context Protocol (MCP) as a development that has “revolutionised the agentic AI landscape”. Software engineering leaders should note that NVIDIA engineers are already utilising Claude Code to refactor legacy codebases.&lt;/p&gt;&lt;p&gt;From a security perspective, this integration simplifies the perimeter. Security leaders vetting third-party API endpoints can now provision Claude capabilities within the existing Microsoft 365 compliance boundary. This streamlines data governance, as the interaction logs and data handling remain within the established Microsoft tenant agreements.&lt;/p&gt;&lt;p&gt;Vendor lock-in persists as a friction point for CDOs and risk officers. This AI compute partnership alleviates that concern by making Claude the only frontier model available across all three prominent global cloud services. Nadella emphasised that this multi-model approach builds upon, rather than replaces, Microsoft’s existing partnership with OpenAI, which remains a core component of their strategy.&lt;/p&gt;&lt;p&gt;For Anthropic, the alliance resolves the “enterprise go-to-market” challenge. Huang noted that building an enterprise sales motion takes decades. By piggybacking on Microsoft’s established channels, Anthropic bypasses this adoption curve.&lt;/p&gt;&lt;p&gt;This trilateral agreement alters the procurement landscape. Nadella urges the industry to move beyond a “zero-sum narrative,” suggesting a future of broad and durable capabilities.&lt;/p&gt;&lt;p&gt;Organisations should review their current model portfolios. The availability of Claude Sonnet 4.5 and Opus 4.1 on Azure warrants a comparative TCO analysis against existing deployments. Furthermore, the “gigawatt of capacity” commitment signals that capacity constraints for these specific models may be less severe than in previous hardware cycles.&lt;/p&gt;&lt;p&gt;Following this AI compute partnership, the focus for enterprises must now turn from access to optimisation; matching the right model version to the specific business process to maximise the return on this expanded infrastructure.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;How Levi Strauss is using AI for its DTC-first business model&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-110612" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/image-8.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/microsoft-nvidia-and-anthropic-forge-ai-compute-alliance/</guid><pubDate>Tue, 18 Nov 2025 16:29:24 +0000</pubDate></item><item><title>[NEW] Google CEO: If an AI bubble pops, no one is getting out clean (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/11/googles-sundar-pichai-warns-of-irrationality-in-trillion-dollar-ai-investment-boom/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Sundar Pichai says no company is immune if AI bubble bursts, echoing dotcom fears.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/Sundar-IO-640x360.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/Sundar-IO-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Google CEO Sundar Pichai.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Ryan Whitwam

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Tuesday, Alphabet CEO Sundar Pichai warned of “irrationality” in the AI market, telling the BBC in an interview, “I think no company is going to be immune, including us.” His comments arrive as scrutiny over the state of the AI market has reached new heights, with Alphabet shares doubling in value over seven months to reach a $3.5 trillion market capitalization.&lt;/p&gt;
&lt;p&gt;Speaking exclusively to the BBC at Google’s California headquarters, Pichai acknowledged that while AI investment growth is at an “extraordinary moment,” the industry can “overshoot” in investment cycles, as we’re seeing now. He drew comparisons to the late 1990s Internet boom, which saw early Internet company valuations surge before collapsing in 2000, leading to bankruptcies and job losses.&lt;/p&gt;
&lt;p&gt;“We can look back at the Internet right now. There was clearly a lot of excess investment, but none of us would question whether the Internet was profound,” Pichai said. “I expect AI to be the same. So I think it’s both rational and there are elements of irrationality through a moment like this.”&lt;/p&gt;
&lt;p&gt;Over the past year, some analysts and tech industry critics have expressed increasing skepticism about a web of $1.4 trillion in deals surrounding Google competitor OpenAI in particular. The company has committed to spending $1.4 trillion on infrastructure over eight years, while it expects to generate around $13 billion in revenue this year. OpenAI CEO Sam Altman told reporters at a private dinner in August that investors are “overexcited” about AI models and that “someone” will lose a “phenomenal amount of money.”&lt;/p&gt;
&lt;p&gt;Reacting to the Pichai comments, prominent AI industry critic Ed Zitron told Ars Technica, “I think that this is the first moment where a magnificent 7 feels it’s necessary to be on the right side of history, leaning on the shaky talking point of ‘there was a lot of over investment in the Internet too’ because there really isn’t a defense for the&lt;span&gt;—&lt;/span&gt;to use his own terminology&lt;span&gt;—&lt;/span&gt;‘excess investment’ in AI.” He added, “I imagine others will follow.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Market concerns and Google’s position&lt;/h2&gt;
&lt;p&gt;Alphabet’s recent market performance has been driven by investor confidence in the company’s ability to compete with OpenAI’s ChatGPT, as well as its development of specialized chips for AI that can compete with Nvidia’s. Nvidia recently reached a world-first $5 trillion valuation due to making GPUs that can accelerate the matrix math at the heart of AI computations.&lt;/p&gt;
&lt;p&gt;Despite acknowledging that no company would be immune to a potential AI bubble burst, Pichai argued that Google’s unique position gives it an advantage. He told the BBC that the company owns what he called a “full stack” of technologies, from chips to YouTube data to models and frontier science research. This integrated approach, he suggested, would help the company weather any market turbulence better than competitors.&lt;/p&gt;
&lt;p&gt;Pichai also told the BBC that people should not “blindly trust” everything AI tools output. The company currently faces repeated accuracy concerns about some of its AI models. Pichai said that while AI tools are helpful “if you want to creatively write something,” people “have to learn to use these tools for what they’re good at and not blindly trust everything they say.”&lt;/p&gt;
&lt;p&gt;In the BBC interview, the Google boss also addressed the “immense” energy needs of AI, acknowledging that the intensive energy requirements of expanding AI ventures have caused slippage on Alphabet’s climate targets. However, Pichai insisted that the company still wants to achieve net zero by 2030 through investments in new energy technologies. “The rate at which we were hoping to make progress will be impacted,” Pichai said, warning that constraining an economy based on energy “will have consequences.”&lt;/p&gt;
&lt;p&gt;Even with the warnings about a potential AI bubble, Pichai did not miss his chance to promote the technology, albeit with a hint of danger regarding its widespread impact. Pichai described AI as “the most profound technology” humankind has worked on.&lt;/p&gt;
&lt;p&gt;“We will have to work through societal disruptions,” he said, adding that the technology would “create new opportunities” and “evolve and transition certain jobs.” He said people who adapt to AI tools “will do better” in their professions, whatever field they work in.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Sundar Pichai says no company is immune if AI bubble bursts, echoing dotcom fears.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/Sundar-IO-640x360.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/Sundar-IO-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Google CEO Sundar Pichai.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Ryan Whitwam

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Tuesday, Alphabet CEO Sundar Pichai warned of “irrationality” in the AI market, telling the BBC in an interview, “I think no company is going to be immune, including us.” His comments arrive as scrutiny over the state of the AI market has reached new heights, with Alphabet shares doubling in value over seven months to reach a $3.5 trillion market capitalization.&lt;/p&gt;
&lt;p&gt;Speaking exclusively to the BBC at Google’s California headquarters, Pichai acknowledged that while AI investment growth is at an “extraordinary moment,” the industry can “overshoot” in investment cycles, as we’re seeing now. He drew comparisons to the late 1990s Internet boom, which saw early Internet company valuations surge before collapsing in 2000, leading to bankruptcies and job losses.&lt;/p&gt;
&lt;p&gt;“We can look back at the Internet right now. There was clearly a lot of excess investment, but none of us would question whether the Internet was profound,” Pichai said. “I expect AI to be the same. So I think it’s both rational and there are elements of irrationality through a moment like this.”&lt;/p&gt;
&lt;p&gt;Over the past year, some analysts and tech industry critics have expressed increasing skepticism about a web of $1.4 trillion in deals surrounding Google competitor OpenAI in particular. The company has committed to spending $1.4 trillion on infrastructure over eight years, while it expects to generate around $13 billion in revenue this year. OpenAI CEO Sam Altman told reporters at a private dinner in August that investors are “overexcited” about AI models and that “someone” will lose a “phenomenal amount of money.”&lt;/p&gt;
&lt;p&gt;Reacting to the Pichai comments, prominent AI industry critic Ed Zitron told Ars Technica, “I think that this is the first moment where a magnificent 7 feels it’s necessary to be on the right side of history, leaning on the shaky talking point of ‘there was a lot of over investment in the Internet too’ because there really isn’t a defense for the&lt;span&gt;—&lt;/span&gt;to use his own terminology&lt;span&gt;—&lt;/span&gt;‘excess investment’ in AI.” He added, “I imagine others will follow.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Market concerns and Google’s position&lt;/h2&gt;
&lt;p&gt;Alphabet’s recent market performance has been driven by investor confidence in the company’s ability to compete with OpenAI’s ChatGPT, as well as its development of specialized chips for AI that can compete with Nvidia’s. Nvidia recently reached a world-first $5 trillion valuation due to making GPUs that can accelerate the matrix math at the heart of AI computations.&lt;/p&gt;
&lt;p&gt;Despite acknowledging that no company would be immune to a potential AI bubble burst, Pichai argued that Google’s unique position gives it an advantage. He told the BBC that the company owns what he called a “full stack” of technologies, from chips to YouTube data to models and frontier science research. This integrated approach, he suggested, would help the company weather any market turbulence better than competitors.&lt;/p&gt;
&lt;p&gt;Pichai also told the BBC that people should not “blindly trust” everything AI tools output. The company currently faces repeated accuracy concerns about some of its AI models. Pichai said that while AI tools are helpful “if you want to creatively write something,” people “have to learn to use these tools for what they’re good at and not blindly trust everything they say.”&lt;/p&gt;
&lt;p&gt;In the BBC interview, the Google boss also addressed the “immense” energy needs of AI, acknowledging that the intensive energy requirements of expanding AI ventures have caused slippage on Alphabet’s climate targets. However, Pichai insisted that the company still wants to achieve net zero by 2030 through investments in new energy technologies. “The rate at which we were hoping to make progress will be impacted,” Pichai said, warning that constraining an economy based on energy “will have consequences.”&lt;/p&gt;
&lt;p&gt;Even with the warnings about a potential AI bubble, Pichai did not miss his chance to promote the technology, albeit with a hint of danger regarding its widespread impact. Pichai described AI as “the most profound technology” humankind has worked on.&lt;/p&gt;
&lt;p&gt;“We will have to work through societal disruptions,” he said, adding that the technology would “create new opportunities” and “evolve and transition certain jobs.” He said people who adapt to AI tools “will do better” in their professions, whatever field they work in.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/11/googles-sundar-pichai-warns-of-irrationality-in-trillion-dollar-ai-investment-boom/</guid><pubDate>Tue, 18 Nov 2025 16:32:58 +0000</pubDate></item><item><title>[NEW] Poe’s AI app now supports group chats across AI models (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/18/poes-ai-app-now-supports-group-chats-across-ai-models/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Poe, Quora’s app that brings together different AI models into one platform, is launching group chat functionality. The company announced on Monday that users worldwide will be able to start group chats with up to 200 other people, then collaborate across more than 200 AI models — including text, image, video, and audio generators — within a single conversation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch comes just days after OpenAI’s ChatGPT began piloting group chats in markets like Japan, New Zealand, South Korea, and Taiwan. The move could potentially transform the chatbot from a one-on-one AI interaction into a collaborative space where users can also engage with friends, family, or colleagues.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Quora says the addition of group chats to Poe could enable new types of interactive experiences for AI users. For instance, the company suggests that families or friends could use the feature to plan a trip together using Gemini 2.5’s search functionality and o3 Deep Research. Teams could also work together to brainstorm images for mood boards using the various image models on Poe, or groups could play trivia games together using one of the quiz bots on the app.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The group chats will allow users to work together using any combination of AI models or creator-made bots, including models like Claude 4.5 Sonnet, Eleven Labs v3, Eleven Labs Music, Nano Banana, GPT-5.1, Kling 2.5 Turbo Pro, o3 Deep Research, Sora 2 Pro, and Veo 3.1, among others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Poe users can start a group chat from the app’s home screen on the website at poe.com. As you chat, the chat history will sync in real-time across your devices, so you could start chatting on desktop and then move to a mobile device without losing the thread.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3068805" height="383" src="https://techcrunch.com/wp-content/uploads/2025/11/poe-group-chat.avif?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Quora developed the feature over the past six months and plans to continue to improve group chats in the weeks following its launch, based on user feedback.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We think the space of potential group interactions mediated by AI and collaboration opportunities with AI is vast and currently under-explored,” the company shared in its announcement. “The product we are opening up today also allows anyone to create a custom bot on Poe and share it for others to use in their own groups, and we are excited to see the use cases that everyone discovers.” &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Poe, Quora’s app that brings together different AI models into one platform, is launching group chat functionality. The company announced on Monday that users worldwide will be able to start group chats with up to 200 other people, then collaborate across more than 200 AI models — including text, image, video, and audio generators — within a single conversation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch comes just days after OpenAI’s ChatGPT began piloting group chats in markets like Japan, New Zealand, South Korea, and Taiwan. The move could potentially transform the chatbot from a one-on-one AI interaction into a collaborative space where users can also engage with friends, family, or colleagues.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Quora says the addition of group chats to Poe could enable new types of interactive experiences for AI users. For instance, the company suggests that families or friends could use the feature to plan a trip together using Gemini 2.5’s search functionality and o3 Deep Research. Teams could also work together to brainstorm images for mood boards using the various image models on Poe, or groups could play trivia games together using one of the quiz bots on the app.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The group chats will allow users to work together using any combination of AI models or creator-made bots, including models like Claude 4.5 Sonnet, Eleven Labs v3, Eleven Labs Music, Nano Banana, GPT-5.1, Kling 2.5 Turbo Pro, o3 Deep Research, Sora 2 Pro, and Veo 3.1, among others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Poe users can start a group chat from the app’s home screen on the website at poe.com. As you chat, the chat history will sync in real-time across your devices, so you could start chatting on desktop and then move to a mobile device without losing the thread.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3068805" height="383" src="https://techcrunch.com/wp-content/uploads/2025/11/poe-group-chat.avif?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Quora developed the feature over the past six months and plans to continue to improve group chats in the weeks following its launch, based on user feedback.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We think the space of potential group interactions mediated by AI and collaboration opportunities with AI is vast and currently under-explored,” the company shared in its announcement. “The product we are opening up today also allows anyone to create a custom bot on Poe and share it for others to use in their own groups, and we are excited to see the use cases that everyone discovers.” &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/18/poes-ai-app-now-supports-group-chats-across-ai-models/</guid><pubDate>Tue, 18 Nov 2025 17:04:03 +0000</pubDate></item><item><title>[NEW] MIT Energy Initiative conference spotlights research priorities amidst a changing energy landscape (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/mit-energy-initiative-conference-spotlights-research-priorities-amidst-changing-energy-1027</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202510/mitei-annual-conference.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;“We’re here to talk about really substantive changes, and we want you to be a participant in that,” said Desirée Plata, the School of Engineering Distinguished Professor of Climate and Energy in MIT’s Department of Civil and Environmental Engineering, at Energizing@MIT: the MIT Energy Initiative’s (MITEI) Annual Research Conference that was held on Sept. 9-10.&lt;/p&gt;&lt;p&gt;Plata’s words resonated with the 150-plus participants from academia, industry, and government meeting in Cambridge for the conference, whose theme was “tackling emerging energy challenges.” Meeting such challenges and ultimately altering the trajectory of global climate outcomes requires partnerships, speakers agreed.&lt;/p&gt;&lt;p&gt;“We have to be humble and open,” said Giacomo Silvestri, chair of Eniverse Ventures at Eni, in a shared keynote address. “We cannot develop innovation just focusing on ourselves and our competencies … so we need to partner with startups, venture funds, universities like MIT and other public and private institutions.”&amp;nbsp;&lt;/p&gt;&lt;p&gt;Added his Eni colleague, Annalisa Muccioli, head of research and technology, “The energy transition is a race we can win only by combining mature solutions ready to deploy, together with emerging technologies that still require acceleration and risk management.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Research targets&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;In a conference that showcased a suite of research priorities MITEI has identified as central to ensuring a low-carbon energy future, participants shared both promising discoveries and strategies for advancing proven technologies in the face of shifting political winds and policy uncertainties.&lt;/p&gt;&lt;p&gt;One panel focused on grid resiliency — a topic that has moved from the periphery to the center of energy discourse as climate-driven disruptions, cyber threats, and the integration of renewables challenge legacy systems. A dramatic case in point: the April 2025 outage in Spain and Portugal that left millions without power for eight to 15 hours.&amp;nbsp;&lt;/p&gt;&lt;p&gt;“I want to emphasize that this failure was about more than the power system,” said MITEI research scientist Pablo Duenas-Martinez. While he pinpointed technical problems with reactive power and voltage control behind the system collapse, Duenas-Martinez also called out a lack of transmission capacity with Central Europe and out-of-date operating procedures, and recommended better preparation and communication among transmission systems and utility operators.&lt;/p&gt;&lt;p&gt;“You can’t plan for every single eventuality, which means we need to broaden the portfolio of extreme events we prepare for,” noted Jennifer Pearce, vice president at energy company Avangrid. “We are making the system smarter, stronger, and more resilient to better protect from a wide range of threats such as storms, flooding, and extreme heat events.” Pearce noted that Avangrid’s commitment to deliver safe, reliable power to its customers necessitates “meticulous emergency planning procedures.”&lt;/p&gt;&lt;p&gt;The resiliency of the electric grid under greatly increased demand is an important motivation behind MITEI’s September 2025 launch of the Data Center Power Forum, which was also announced during the annual research conference. The forum will include research projects, webinars, and other content focused on energy supply and storage, grid design and management, infrastructure, and public and economic policy related to data centers. The forum’s members include MITEI companies that also participate in MIT’s Center for Environmental and Energy Policy Research (CEEPR).&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Storage and transportation: Staggering challenges&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Meeting climate goals to decarbonize the world by 2050 requires building around 300 terawatt-hours of storage, according to Asegun Henry, a professor in the MIT Department of Mechanical Engineering. “It’s an unbelievably enormous problem people have to wrap their minds around,” he said. Henry has been developing a high-temperature thermal energy storage system he has nicknamed “sun in a box.” His system uses liquid metal and graphite to hold electricity as heat and then convert it back to electricity, enabling storage anywhere from five to 500 hours.&lt;/p&gt;&lt;p&gt;“At the end of the day, storage provides a service, and the type of technology that you need is a function of the service that you value the most,” said Nestor Sepulveda, commercial lead for advanced energy investments and partnerships at Google. “I don't think there is one winner-takes-all type of market here.”&lt;/p&gt;&lt;p&gt;Another panel explored sustainable fuels that could help decarbonize hard-to-electrify sectors like aviation, shipping, and long-haul trucking. Randall Field, MITEI’s director of research, noted that sustainably produced drop-in fuels — fuels that are largely compatible with existing engines — “could eliminate potentially trillions of dollars of cost for fleet replacement and for infrastructure build-out, while also helping us to accelerate the rate of decarbonization of the transportation sectors."&lt;/p&gt;&lt;p&gt;Erik G. Birkerts is the chief growth officer of LanzaJet, which produces a drop-in, high-energy-density aviation fuel derived from agricultural residue and other waste carbon sources. “The key to driving broad sustainable aviation fuel adoption is solving both the supply-side challenge through more production and the demand-side hurdle by reducing costs,” he said.&lt;/p&gt;&lt;p&gt;“We think a good policy framework [for sustainable fuels] would be something that is technology-neutral, does not exclude any pathways to produce, is based on life cycle accounting practices, and on market mechanisms,” said Veronica L. Robertson, energy products technology portfolio manager at ExxonMobil.&lt;/p&gt;&lt;p&gt;MITEI plans a major expansion of its research on sustainable fuels, announcing a two-year study, “The future of fuels: Pathways to sustainable transportation,” starting in early 2026. According to Field, the study will analyze and assess biofuels and e-fuels.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Solutions from labs big and small&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Global energy leaders offered glimpses of their research projects. A panel on carbon capture in power generation featured three takes on the topic: Devin Shaw, commercial director of decarbonization technologies at Shell, described post-combustion carbon capture in power plants using steam for heat recovery; Jan Marsh, a global program lead at Siemens Energy, discussed deploying novel materials to capture carbon dioxide directly from the air; and Jeffrey Goldmeer, senior director of technology strategy at GE Vernova, explained integrating carbon capture into gas-powered turbine systems.&lt;/p&gt;&lt;p&gt;During a panel on vehicle electrification, Brian Storey, vice president of energy and materials at the Toyota Research Institute, provided an overview of Toyota’s portfolio of projects for decarbonization, including solid-state batteries, flexible manufacturing lines, and grid-forming inverters to support EV charging infrastructure.&lt;/p&gt;&lt;p&gt;A session on MITEI seed fund projects revealed promising early-stage research inside MIT’s own labs. A new process for decarbonizing the production of ethylene was presented by Yogesh Surendranath, Donner Professor of Science in the MIT Department of Chemistry. Materials Science and Engineering assistant professor Aristide Gumyusenge also discussed the development of polymers essential for a new kind of sodium-ion battery.&lt;/p&gt;&lt;p&gt;Shepherding bold, new technologies like these from academic labs into the real world cannot succeed without ample support and deft management.&amp;nbsp;A panel on paths to commercialization featured the work of Iwnetim Abate, Chipman Career Development Professor and assistant professor in the MIT Department of Materials Science and Engineering, who has spun out a company, Addis Energy, based on a novel geothermal process for harvesting clean hydrogen and ammonia from subsurface, iron-rich rocks. Among his funders: ARPA-E and MIT’s own The Engine Ventures.&lt;/p&gt;&lt;p&gt;The panel also highlighted the MIT Proto Ventures Program, an initiative to seize early-stage MIT ideas and unleash them as world-changing startups. “A mere 4.2 percent of all the patents that are actually prosecuted in the world are ever commercialized, which seems like a shocking number,” said Andrew Inglis, an entrepreneur working with Proto Ventures to translate geothermal discoveries into businesses.&amp;nbsp;“Can’t we do this better? Let’s do this better!”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Geopolitical hazards&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Throughout the conference, participants often voiced concern about the impacts of competition between the United States and China. Kelly Sims Gallagher, dean of the Fletcher School at Tufts University and an expert on China’s energy landscape, delivered the sobering news in her keynote address: “U.S. competitiveness in low-carbon technologies has eroded in nearly every category,” she said. “The Chinese are winning the clean tech race.”&lt;/p&gt;&lt;p&gt;China enjoys a 51 percent share in global wind turbine manufacture and 75 percent in solar modules. It also controls low-carbon supply chains that much of the world depends on. “China is getting so dominant that nobody can carve out a comparative advantage in anything,” said Gallagher. “China is just so big, and the scale is so huge that the Chinese can truly conquer markets and make it very hard for potential competitors to find a way in.”&lt;/p&gt;&lt;p&gt;And for the United States, the problem is “the seesaw of energy policy,” she says. “It’s incredibly difficult for the private sector to plan and to operate, given the lack of predictability and policy here.”&lt;/p&gt;&lt;p&gt;Nevertheless, Gallagher believes the United States still has a chance of at least regaining competitiveness, by setting up a stable, bipartisan energy policy, rebuilding domestic manufacturing and supply chains; providing consistent fiscal incentives; attracting and retaining global talent; and fostering international collaboration.&lt;/p&gt;&lt;p&gt;The conference shone a light on one such collaboration: a China-U.S. joint venture to manufacture lithium iron phosphate batteries for commercial vehicles in the United States. The venture brings together Eve Energy, a Chinese battery technology and manufacturing company; Daimler, a global commercial vehicle manufacturer; PACCAR Inc., a U.S.-based truck manufacturer; and Accelera, the zero-emissions business of Cummins Inc. “Manufacturing batteries in the U.S. makes the supply chain more robust and reduces geopolitical risks,” said Mike Gerty, of PACCAR.&lt;/p&gt;&lt;p&gt;While she acknowledged the obstacles confronting her colleagues in the room, Plata nevertheless concluded her remarks as a panel moderator with some optimism: “I hope you all leave this conference and look back on it in the future, saying I was in the room when they actually solved some of the challenges standing between now and the future that we all wish to manifest.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202510/mitei-annual-conference.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;“We’re here to talk about really substantive changes, and we want you to be a participant in that,” said Desirée Plata, the School of Engineering Distinguished Professor of Climate and Energy in MIT’s Department of Civil and Environmental Engineering, at Energizing@MIT: the MIT Energy Initiative’s (MITEI) Annual Research Conference that was held on Sept. 9-10.&lt;/p&gt;&lt;p&gt;Plata’s words resonated with the 150-plus participants from academia, industry, and government meeting in Cambridge for the conference, whose theme was “tackling emerging energy challenges.” Meeting such challenges and ultimately altering the trajectory of global climate outcomes requires partnerships, speakers agreed.&lt;/p&gt;&lt;p&gt;“We have to be humble and open,” said Giacomo Silvestri, chair of Eniverse Ventures at Eni, in a shared keynote address. “We cannot develop innovation just focusing on ourselves and our competencies … so we need to partner with startups, venture funds, universities like MIT and other public and private institutions.”&amp;nbsp;&lt;/p&gt;&lt;p&gt;Added his Eni colleague, Annalisa Muccioli, head of research and technology, “The energy transition is a race we can win only by combining mature solutions ready to deploy, together with emerging technologies that still require acceleration and risk management.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Research targets&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;In a conference that showcased a suite of research priorities MITEI has identified as central to ensuring a low-carbon energy future, participants shared both promising discoveries and strategies for advancing proven technologies in the face of shifting political winds and policy uncertainties.&lt;/p&gt;&lt;p&gt;One panel focused on grid resiliency — a topic that has moved from the periphery to the center of energy discourse as climate-driven disruptions, cyber threats, and the integration of renewables challenge legacy systems. A dramatic case in point: the April 2025 outage in Spain and Portugal that left millions without power for eight to 15 hours.&amp;nbsp;&lt;/p&gt;&lt;p&gt;“I want to emphasize that this failure was about more than the power system,” said MITEI research scientist Pablo Duenas-Martinez. While he pinpointed technical problems with reactive power and voltage control behind the system collapse, Duenas-Martinez also called out a lack of transmission capacity with Central Europe and out-of-date operating procedures, and recommended better preparation and communication among transmission systems and utility operators.&lt;/p&gt;&lt;p&gt;“You can’t plan for every single eventuality, which means we need to broaden the portfolio of extreme events we prepare for,” noted Jennifer Pearce, vice president at energy company Avangrid. “We are making the system smarter, stronger, and more resilient to better protect from a wide range of threats such as storms, flooding, and extreme heat events.” Pearce noted that Avangrid’s commitment to deliver safe, reliable power to its customers necessitates “meticulous emergency planning procedures.”&lt;/p&gt;&lt;p&gt;The resiliency of the electric grid under greatly increased demand is an important motivation behind MITEI’s September 2025 launch of the Data Center Power Forum, which was also announced during the annual research conference. The forum will include research projects, webinars, and other content focused on energy supply and storage, grid design and management, infrastructure, and public and economic policy related to data centers. The forum’s members include MITEI companies that also participate in MIT’s Center for Environmental and Energy Policy Research (CEEPR).&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Storage and transportation: Staggering challenges&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Meeting climate goals to decarbonize the world by 2050 requires building around 300 terawatt-hours of storage, according to Asegun Henry, a professor in the MIT Department of Mechanical Engineering. “It’s an unbelievably enormous problem people have to wrap their minds around,” he said. Henry has been developing a high-temperature thermal energy storage system he has nicknamed “sun in a box.” His system uses liquid metal and graphite to hold electricity as heat and then convert it back to electricity, enabling storage anywhere from five to 500 hours.&lt;/p&gt;&lt;p&gt;“At the end of the day, storage provides a service, and the type of technology that you need is a function of the service that you value the most,” said Nestor Sepulveda, commercial lead for advanced energy investments and partnerships at Google. “I don't think there is one winner-takes-all type of market here.”&lt;/p&gt;&lt;p&gt;Another panel explored sustainable fuels that could help decarbonize hard-to-electrify sectors like aviation, shipping, and long-haul trucking. Randall Field, MITEI’s director of research, noted that sustainably produced drop-in fuels — fuels that are largely compatible with existing engines — “could eliminate potentially trillions of dollars of cost for fleet replacement and for infrastructure build-out, while also helping us to accelerate the rate of decarbonization of the transportation sectors."&lt;/p&gt;&lt;p&gt;Erik G. Birkerts is the chief growth officer of LanzaJet, which produces a drop-in, high-energy-density aviation fuel derived from agricultural residue and other waste carbon sources. “The key to driving broad sustainable aviation fuel adoption is solving both the supply-side challenge through more production and the demand-side hurdle by reducing costs,” he said.&lt;/p&gt;&lt;p&gt;“We think a good policy framework [for sustainable fuels] would be something that is technology-neutral, does not exclude any pathways to produce, is based on life cycle accounting practices, and on market mechanisms,” said Veronica L. Robertson, energy products technology portfolio manager at ExxonMobil.&lt;/p&gt;&lt;p&gt;MITEI plans a major expansion of its research on sustainable fuels, announcing a two-year study, “The future of fuels: Pathways to sustainable transportation,” starting in early 2026. According to Field, the study will analyze and assess biofuels and e-fuels.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Solutions from labs big and small&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Global energy leaders offered glimpses of their research projects. A panel on carbon capture in power generation featured three takes on the topic: Devin Shaw, commercial director of decarbonization technologies at Shell, described post-combustion carbon capture in power plants using steam for heat recovery; Jan Marsh, a global program lead at Siemens Energy, discussed deploying novel materials to capture carbon dioxide directly from the air; and Jeffrey Goldmeer, senior director of technology strategy at GE Vernova, explained integrating carbon capture into gas-powered turbine systems.&lt;/p&gt;&lt;p&gt;During a panel on vehicle electrification, Brian Storey, vice president of energy and materials at the Toyota Research Institute, provided an overview of Toyota’s portfolio of projects for decarbonization, including solid-state batteries, flexible manufacturing lines, and grid-forming inverters to support EV charging infrastructure.&lt;/p&gt;&lt;p&gt;A session on MITEI seed fund projects revealed promising early-stage research inside MIT’s own labs. A new process for decarbonizing the production of ethylene was presented by Yogesh Surendranath, Donner Professor of Science in the MIT Department of Chemistry. Materials Science and Engineering assistant professor Aristide Gumyusenge also discussed the development of polymers essential for a new kind of sodium-ion battery.&lt;/p&gt;&lt;p&gt;Shepherding bold, new technologies like these from academic labs into the real world cannot succeed without ample support and deft management.&amp;nbsp;A panel on paths to commercialization featured the work of Iwnetim Abate, Chipman Career Development Professor and assistant professor in the MIT Department of Materials Science and Engineering, who has spun out a company, Addis Energy, based on a novel geothermal process for harvesting clean hydrogen and ammonia from subsurface, iron-rich rocks. Among his funders: ARPA-E and MIT’s own The Engine Ventures.&lt;/p&gt;&lt;p&gt;The panel also highlighted the MIT Proto Ventures Program, an initiative to seize early-stage MIT ideas and unleash them as world-changing startups. “A mere 4.2 percent of all the patents that are actually prosecuted in the world are ever commercialized, which seems like a shocking number,” said Andrew Inglis, an entrepreneur working with Proto Ventures to translate geothermal discoveries into businesses.&amp;nbsp;“Can’t we do this better? Let’s do this better!”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Geopolitical hazards&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Throughout the conference, participants often voiced concern about the impacts of competition between the United States and China. Kelly Sims Gallagher, dean of the Fletcher School at Tufts University and an expert on China’s energy landscape, delivered the sobering news in her keynote address: “U.S. competitiveness in low-carbon technologies has eroded in nearly every category,” she said. “The Chinese are winning the clean tech race.”&lt;/p&gt;&lt;p&gt;China enjoys a 51 percent share in global wind turbine manufacture and 75 percent in solar modules. It also controls low-carbon supply chains that much of the world depends on. “China is getting so dominant that nobody can carve out a comparative advantage in anything,” said Gallagher. “China is just so big, and the scale is so huge that the Chinese can truly conquer markets and make it very hard for potential competitors to find a way in.”&lt;/p&gt;&lt;p&gt;And for the United States, the problem is “the seesaw of energy policy,” she says. “It’s incredibly difficult for the private sector to plan and to operate, given the lack of predictability and policy here.”&lt;/p&gt;&lt;p&gt;Nevertheless, Gallagher believes the United States still has a chance of at least regaining competitiveness, by setting up a stable, bipartisan energy policy, rebuilding domestic manufacturing and supply chains; providing consistent fiscal incentives; attracting and retaining global talent; and fostering international collaboration.&lt;/p&gt;&lt;p&gt;The conference shone a light on one such collaboration: a China-U.S. joint venture to manufacture lithium iron phosphate batteries for commercial vehicles in the United States. The venture brings together Eve Energy, a Chinese battery technology and manufacturing company; Daimler, a global commercial vehicle manufacturer; PACCAR Inc., a U.S.-based truck manufacturer; and Accelera, the zero-emissions business of Cummins Inc. “Manufacturing batteries in the U.S. makes the supply chain more robust and reduces geopolitical risks,” said Mike Gerty, of PACCAR.&lt;/p&gt;&lt;p&gt;While she acknowledged the obstacles confronting her colleagues in the room, Plata nevertheless concluded her remarks as a panel moderator with some optimism: “I hope you all leave this conference and look back on it in the future, saying I was in the room when they actually solved some of the challenges standing between now and the future that we all wish to manifest.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/mit-energy-initiative-conference-spotlights-research-priorities-amidst-changing-energy-1027</guid><pubDate>Tue, 18 Nov 2025 17:10:00 +0000</pubDate></item></channel></rss>