<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 26 Jul 2025 01:53:41 +0000</lastBuildDate><item><title> ()</title><link>https://www.wired.com/feed/category/artificial-intelligence/rss</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://www.wired.com/feed/category/artificial-intelligence/rss</guid></item><item><title>Tesla is reportedly behind on its pledge to build 5,000 Optimus bots this year (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/25/tesla-is-reportedly-behind-on-its-pledge-to-build-5000-optimus-bots-this-year/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/musk-promises-2024.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Tesla is well behind the pace needed to meet its earlier stated goal of producing at least 5,000 Optimus humanoid robots this year, The Information reports. Nearly eight months into 2025, and the number of bots Tesla has produced is only in the hundreds, according to two sources. That means Tesla will either need to step it up or push back the deadline.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The news comes after Tesla reported a 12% decline in overall revenue in the second quarter due to falling EV sales, less cash from regulatory credits, and a decline in solar and energy storage sales.&amp;nbsp;During the Q2 earnings call earlier this week, Musk said that Tesla would start production on its latest Optimus 3 design by early next year.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We will scale Optimus production as fast as possible and try to get to a million units a year as quickly as possible,” Musk said. “We think we can get there in less than five years. That’s a reasonable aspiration.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Recall that Musk has made bold claims like this before. During Tesla’s 2019 Autonomy Day, Musk said the company would have a fleet of a million robotaxis on the road by 2020. Two years later, he said Tesla would mass-produce robotaxis by 2024. Neither of those projections has yet come to pass.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/musk-promises-2024.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Tesla is well behind the pace needed to meet its earlier stated goal of producing at least 5,000 Optimus humanoid robots this year, The Information reports. Nearly eight months into 2025, and the number of bots Tesla has produced is only in the hundreds, according to two sources. That means Tesla will either need to step it up or push back the deadline.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The news comes after Tesla reported a 12% decline in overall revenue in the second quarter due to falling EV sales, less cash from regulatory credits, and a decline in solar and energy storage sales.&amp;nbsp;During the Q2 earnings call earlier this week, Musk said that Tesla would start production on its latest Optimus 3 design by early next year.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We will scale Optimus production as fast as possible and try to get to a million units a year as quickly as possible,” Musk said. “We think we can get there in less than five years. That’s a reasonable aspiration.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Recall that Musk has made bold claims like this before. During Tesla’s 2019 Autonomy Day, Musk said the company would have a fleet of a million robotaxis on the road by 2020. Two years later, he said Tesla would mass-produce robotaxis by 2024. Neither of those projections has yet come to pass.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/25/tesla-is-reportedly-behind-on-its-pledge-to-build-5000-optimus-bots-this-year/</guid><pubDate>Fri, 25 Jul 2025 14:14:19 +0000</pubDate></item><item><title>Should Silicon Valley celebrate Trump’s AI plans? (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/podcast/should-silicon-valley-celebrate-trumps-ai-plans/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2224983065-e1753313001258.jpg?w=836" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;The big AI companies seem to be in a celebratory mood after President Donald Trump unveiled his AI Action Plan — not surprising, perhaps, since the plan was shaped by Trump’s Silicon Valley allies.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Today on TechCrunch’s Equity podcast, hosts Kirsten Korosec, Max Zeff, and Anthony Ha look at how the Trump administration plans to reshape the AI landscape, making it harder for environmental regulators to block data center construction, for state governments to oversee AI development and safety, and for tech companies to develop what conservatives see as “woke” AI.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear more about this week’s startup and tech news, including:&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Equity will be back for you next week, so don’t miss it!&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Subscribe to us on&lt;/em&gt;&lt;em&gt;&amp;nbsp;Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt;&amp;nbsp;Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt;&amp;nbsp;Spotify&lt;/em&gt;&lt;em&gt;&amp;nbsp;and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt;&amp;nbsp;X&lt;/em&gt;&lt;em&gt;&amp;nbsp;and&lt;/em&gt;&lt;em&gt;&amp;nbsp;Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2224983065-e1753313001258.jpg?w=836" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;The big AI companies seem to be in a celebratory mood after President Donald Trump unveiled his AI Action Plan — not surprising, perhaps, since the plan was shaped by Trump’s Silicon Valley allies.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Today on TechCrunch’s Equity podcast, hosts Kirsten Korosec, Max Zeff, and Anthony Ha look at how the Trump administration plans to reshape the AI landscape, making it harder for environmental regulators to block data center construction, for state governments to oversee AI development and safety, and for tech companies to develop what conservatives see as “woke” AI.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear more about this week’s startup and tech news, including:&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Equity will be back for you next week, so don’t miss it!&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Subscribe to us on&lt;/em&gt;&lt;em&gt;&amp;nbsp;Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt;&amp;nbsp;Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt;&amp;nbsp;Spotify&lt;/em&gt;&lt;em&gt;&amp;nbsp;and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt;&amp;nbsp;X&lt;/em&gt;&lt;em&gt;&amp;nbsp;and&lt;/em&gt;&lt;em&gt;&amp;nbsp;Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/podcast/should-silicon-valley-celebrate-trumps-ai-plans/</guid><pubDate>Fri, 25 Jul 2025 15:21:24 +0000</pubDate></item><item><title>[NEW] It’s Qwen’s summer: new open source Qwen3-235B-A22B-Thinking-2507 tops OpenAI, Gemini reasoning models on key benchmarks (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/its-qwens-summer-new-open-source-qwen3-235b-a22b-thinking-2507-tops-openai-gemini-reasoning-models-on-key-benchmarks/</link><description>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;If the AI industry had an equivalent to the recording industry’s “song of the summer” — a hit that catches on in the warmer months here in the Northern Hemisphere and is heard playing everywhere — the clear honoree for that title would go to Alibaba’s Qwen Team.&lt;/p&gt;&lt;p&gt;Over just the past week, the frontier model AI research division of the Chinese e-commerce behemoth has released not one, not two, not three, but four (!!) new open source generative AI models that offer record-setting benchmarks, besting even some leading proprietary options.&lt;/p&gt;&lt;p&gt;Last night, Qwen Team capped it off with the release of &lt;strong&gt;Qwen3-235B-A22B-Thinking-2507&lt;/strong&gt;, it’s updated reasoning large language model (LLM), which takes longer to respond than a non-reasoning or “instruct” LLM, engaging in “chains-of-thought” or self-reflection and self-checking that hopefully result in more correct and comprehensive responses on more difficult tasks. &lt;/p&gt;&lt;p&gt;Indeed, the new Qwen3-Thinking-2507, as we’ll call it for short, now leads or closely trails top-performing models across several major benchmarks. &lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;As AI influencer and news aggregator Andrew Curran wrote on X: “Qwen’s strongest reasoning model has arrived, and it is at the frontier.”&lt;/p&gt;



&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3014682" height="450" src="https://venturebeat.com/wp-content/uploads/2025/07/GwshKhhagAA7pbb-1.jpg?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;In the &lt;strong&gt;AIME25&lt;/strong&gt; benchmark—designed to evaluate problem-solving ability in mathematical and logical contexts — &lt;strong&gt;Qwen3-Thinking-2507 leads all reported models&lt;/strong&gt; with a score of &lt;strong&gt;92.3&lt;/strong&gt;, narrowly surpassing both OpenAI’s o4-mini (&lt;strong&gt;92.7&lt;/strong&gt;) and Gemini-2.5 Pro (&lt;strong&gt;88.0&lt;/strong&gt;). &lt;/p&gt;



&lt;p&gt;The model also shows a commanding performance on &lt;strong&gt;LiveCodeBench v6&lt;/strong&gt;, &lt;strong&gt;scoring 74.1, ahead of Google Gemini-2.5 Pro (72.5), OpenAI o4-mini (71.8)&lt;/strong&gt;, and significantly outperforming its earlier version, which posted &lt;strong&gt;55.7&lt;/strong&gt;.&lt;/p&gt;



&lt;p&gt;In &lt;strong&gt;GPQA&lt;/strong&gt;, a benchmark for graduate-level multiple-choice questions, the model achieves &lt;strong&gt;81.1&lt;/strong&gt;, nearly matching Deepseek-R1-0528 (&lt;strong&gt;81.0&lt;/strong&gt;) and trailing Gemini-2.5 Pro’s top mark of &lt;strong&gt;86.4&lt;/strong&gt;. &lt;/p&gt;



&lt;p&gt;On &lt;strong&gt;Arena-Hard v2&lt;/strong&gt;, which evaluates alignment and subjective preference through win rates, Qwen3-Thinking-2507 scores &lt;strong&gt;79.7&lt;/strong&gt;, placing it ahead of all competitors.&lt;/p&gt;



&lt;p&gt;The results show that this model not only surpasses its predecessor in every major category but also sets a new standard for what open-source, reasoning-focused models can achieve.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-shift-away-from-hybrid-reasoning"&gt;A shift away from ‘hybrid reasoning’&lt;/h2&gt;



&lt;p&gt;The release of Qwen3-Thinking-2507 reflects a broader strategic shift by Alibaba’s Qwen team: moving away from hybrid reasoning models that required users to manually toggle between “thinking” and “non-thinking” modes. &lt;/p&gt;



&lt;p&gt;Instead, the team is now training separate models for reasoning and instruction tasks. This separation allows each model to be optimized for its intended purpose—resulting in improved consistency, clarity, and benchmark performance. The new Qwen3-Thinking model fully embodies this design philosophy.&lt;/p&gt;



&lt;p&gt;Alongside it, Qwen launched &lt;strong&gt;Qwen3-Coder-480B-A35B-Instruct&lt;/strong&gt;, a 480B-parameter model built for complex coding workflows. It supports 1 million token context windows and outperforms GPT-4.1 and Gemini 2.5 Pro on SWE-bench Verified.&lt;/p&gt;



&lt;p&gt;Also announced was &lt;strong&gt;Qwen3-MT&lt;/strong&gt;, a multilingual translation model trained on trillions of tokens across 92+ languages. It supports domain adaptation, terminology control, and inference from just $0.50 per million tokens.&lt;/p&gt;



&lt;p&gt;Earlier in the week, the team released &lt;strong&gt;Qwen3-235B-A22B-Instruct-2507&lt;/strong&gt;, a non-reasoning model that surpassed Claude Opus 4 on several benchmarks and introduced a lightweight FP8 variant for more efficient inference on constrained hardware.&lt;/p&gt;



&lt;p&gt;All models are licensed under Apache 2.0 and are available through Hugging Face, ModelScope, and the Qwen API.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-licensing-apache-2-0-and-its-enterprise-advantage"&gt;Licensing: Apache 2.0 and its enterprise advantage&lt;/h2&gt;



&lt;p&gt;Qwen3-235B-A22B-Thinking-2507 is released under the &lt;strong&gt;Apache 2.0 license&lt;/strong&gt;, a highly permissive and commercially friendly license that allows enterprises to download, modify, self-host, fine-tune, and integrate the model into proprietary systems without restriction.&lt;/p&gt;



&lt;p&gt;This stands in contrast to proprietary models or research-only open releases, which often require API access, impose usage limits, or prohibit commercial deployment. For compliance-conscious organizations and teams looking to control cost, latency, and data privacy, Apache 2.0 licensing enables full flexibility and ownership.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-availability-and-pricing"&gt;Availability and pricing&lt;/h2&gt;



&lt;p&gt;Qwen3-235B-A22B-Thinking-2507 is available now for free download on Hugging Face and ModelScope. &lt;/p&gt;



&lt;p&gt;For those enterprises who don’t want to or don’t have the resources and capability to host the model inference on their own hardware or virtual private cloud through Alibaba Cloud’s API, vLLM, and SGLang.&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Input price:&lt;/strong&gt; $0.70 per million tokens&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Output price:&lt;/strong&gt; $8.40 per million tokens&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Free tier:&lt;/strong&gt; 1 million tokens, valid for 180 days&lt;/li&gt;
&lt;/ul&gt;







&lt;p&gt;The model is compatible with agentic frameworks via &lt;strong&gt;Qwen-Agent&lt;/strong&gt;, and supports advanced deployment via OpenAI-compatible APIs. &lt;/p&gt;



&lt;p&gt;It can also be run locally using transformer frameworks or integrated into dev stacks through Node.js, CLI tools, or structured prompting interfaces.&lt;/p&gt;



&lt;p&gt;Sampling settings for best performance include &lt;strong&gt;temperature=0.6&lt;/strong&gt;, &lt;strong&gt;top_p=0.95&lt;/strong&gt;, and &lt;strong&gt;max output length of 81,920 tokens&lt;/strong&gt; for complex tasks.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-enterprise-applications-and-future-outlook"&gt;Enterprise applications and future outlook&lt;/h2&gt;



&lt;p&gt;With its strong benchmark performance, long-context capability, and permissive licensing, Qwen3-Thinking-2507 is particularly well suited for use in enterprise AI systems involving reasoning, planning, and decision support.&lt;/p&gt;



&lt;p&gt;The broader Qwen3 ecosystem — including coding, instruction, and translation models—further extends the appeal to technical teams and business units looking to incorporate AI across verticals like engineering, localization, customer support, and research.&lt;/p&gt;



&lt;p&gt;The Qwen team’s decision to release specialized models for distinct use cases, backed by technical transparency and community support, signals a deliberate shift toward building &lt;strong&gt;open, performant, and production-ready AI infrastructure&lt;/strong&gt;.&lt;/p&gt;



&lt;p&gt;As more enterprises seek alternatives to API-gated, black-box models, Alibaba’s Qwen series increasingly positions itself as a viable open-source foundation for intelligent systems—offering both control and capability at scale.&lt;/p&gt;




&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;If the AI industry had an equivalent to the recording industry’s “song of the summer” — a hit that catches on in the warmer months here in the Northern Hemisphere and is heard playing everywhere — the clear honoree for that title would go to Alibaba’s Qwen Team.&lt;/p&gt;&lt;p&gt;Over just the past week, the frontier model AI research division of the Chinese e-commerce behemoth has released not one, not two, not three, but four (!!) new open source generative AI models that offer record-setting benchmarks, besting even some leading proprietary options.&lt;/p&gt;&lt;p&gt;Last night, Qwen Team capped it off with the release of &lt;strong&gt;Qwen3-235B-A22B-Thinking-2507&lt;/strong&gt;, it’s updated reasoning large language model (LLM), which takes longer to respond than a non-reasoning or “instruct” LLM, engaging in “chains-of-thought” or self-reflection and self-checking that hopefully result in more correct and comprehensive responses on more difficult tasks. &lt;/p&gt;&lt;p&gt;Indeed, the new Qwen3-Thinking-2507, as we’ll call it for short, now leads or closely trails top-performing models across several major benchmarks. &lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;As AI influencer and news aggregator Andrew Curran wrote on X: “Qwen’s strongest reasoning model has arrived, and it is at the frontier.”&lt;/p&gt;



&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3014682" height="450" src="https://venturebeat.com/wp-content/uploads/2025/07/GwshKhhagAA7pbb-1.jpg?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;In the &lt;strong&gt;AIME25&lt;/strong&gt; benchmark—designed to evaluate problem-solving ability in mathematical and logical contexts — &lt;strong&gt;Qwen3-Thinking-2507 leads all reported models&lt;/strong&gt; with a score of &lt;strong&gt;92.3&lt;/strong&gt;, narrowly surpassing both OpenAI’s o4-mini (&lt;strong&gt;92.7&lt;/strong&gt;) and Gemini-2.5 Pro (&lt;strong&gt;88.0&lt;/strong&gt;). &lt;/p&gt;



&lt;p&gt;The model also shows a commanding performance on &lt;strong&gt;LiveCodeBench v6&lt;/strong&gt;, &lt;strong&gt;scoring 74.1, ahead of Google Gemini-2.5 Pro (72.5), OpenAI o4-mini (71.8)&lt;/strong&gt;, and significantly outperforming its earlier version, which posted &lt;strong&gt;55.7&lt;/strong&gt;.&lt;/p&gt;



&lt;p&gt;In &lt;strong&gt;GPQA&lt;/strong&gt;, a benchmark for graduate-level multiple-choice questions, the model achieves &lt;strong&gt;81.1&lt;/strong&gt;, nearly matching Deepseek-R1-0528 (&lt;strong&gt;81.0&lt;/strong&gt;) and trailing Gemini-2.5 Pro’s top mark of &lt;strong&gt;86.4&lt;/strong&gt;. &lt;/p&gt;



&lt;p&gt;On &lt;strong&gt;Arena-Hard v2&lt;/strong&gt;, which evaluates alignment and subjective preference through win rates, Qwen3-Thinking-2507 scores &lt;strong&gt;79.7&lt;/strong&gt;, placing it ahead of all competitors.&lt;/p&gt;



&lt;p&gt;The results show that this model not only surpasses its predecessor in every major category but also sets a new standard for what open-source, reasoning-focused models can achieve.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-shift-away-from-hybrid-reasoning"&gt;A shift away from ‘hybrid reasoning’&lt;/h2&gt;



&lt;p&gt;The release of Qwen3-Thinking-2507 reflects a broader strategic shift by Alibaba’s Qwen team: moving away from hybrid reasoning models that required users to manually toggle between “thinking” and “non-thinking” modes. &lt;/p&gt;



&lt;p&gt;Instead, the team is now training separate models for reasoning and instruction tasks. This separation allows each model to be optimized for its intended purpose—resulting in improved consistency, clarity, and benchmark performance. The new Qwen3-Thinking model fully embodies this design philosophy.&lt;/p&gt;



&lt;p&gt;Alongside it, Qwen launched &lt;strong&gt;Qwen3-Coder-480B-A35B-Instruct&lt;/strong&gt;, a 480B-parameter model built for complex coding workflows. It supports 1 million token context windows and outperforms GPT-4.1 and Gemini 2.5 Pro on SWE-bench Verified.&lt;/p&gt;



&lt;p&gt;Also announced was &lt;strong&gt;Qwen3-MT&lt;/strong&gt;, a multilingual translation model trained on trillions of tokens across 92+ languages. It supports domain adaptation, terminology control, and inference from just $0.50 per million tokens.&lt;/p&gt;



&lt;p&gt;Earlier in the week, the team released &lt;strong&gt;Qwen3-235B-A22B-Instruct-2507&lt;/strong&gt;, a non-reasoning model that surpassed Claude Opus 4 on several benchmarks and introduced a lightweight FP8 variant for more efficient inference on constrained hardware.&lt;/p&gt;



&lt;p&gt;All models are licensed under Apache 2.0 and are available through Hugging Face, ModelScope, and the Qwen API.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-licensing-apache-2-0-and-its-enterprise-advantage"&gt;Licensing: Apache 2.0 and its enterprise advantage&lt;/h2&gt;



&lt;p&gt;Qwen3-235B-A22B-Thinking-2507 is released under the &lt;strong&gt;Apache 2.0 license&lt;/strong&gt;, a highly permissive and commercially friendly license that allows enterprises to download, modify, self-host, fine-tune, and integrate the model into proprietary systems without restriction.&lt;/p&gt;



&lt;p&gt;This stands in contrast to proprietary models or research-only open releases, which often require API access, impose usage limits, or prohibit commercial deployment. For compliance-conscious organizations and teams looking to control cost, latency, and data privacy, Apache 2.0 licensing enables full flexibility and ownership.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-availability-and-pricing"&gt;Availability and pricing&lt;/h2&gt;



&lt;p&gt;Qwen3-235B-A22B-Thinking-2507 is available now for free download on Hugging Face and ModelScope. &lt;/p&gt;



&lt;p&gt;For those enterprises who don’t want to or don’t have the resources and capability to host the model inference on their own hardware or virtual private cloud through Alibaba Cloud’s API, vLLM, and SGLang.&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Input price:&lt;/strong&gt; $0.70 per million tokens&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Output price:&lt;/strong&gt; $8.40 per million tokens&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Free tier:&lt;/strong&gt; 1 million tokens, valid for 180 days&lt;/li&gt;
&lt;/ul&gt;







&lt;p&gt;The model is compatible with agentic frameworks via &lt;strong&gt;Qwen-Agent&lt;/strong&gt;, and supports advanced deployment via OpenAI-compatible APIs. &lt;/p&gt;



&lt;p&gt;It can also be run locally using transformer frameworks or integrated into dev stacks through Node.js, CLI tools, or structured prompting interfaces.&lt;/p&gt;



&lt;p&gt;Sampling settings for best performance include &lt;strong&gt;temperature=0.6&lt;/strong&gt;, &lt;strong&gt;top_p=0.95&lt;/strong&gt;, and &lt;strong&gt;max output length of 81,920 tokens&lt;/strong&gt; for complex tasks.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-enterprise-applications-and-future-outlook"&gt;Enterprise applications and future outlook&lt;/h2&gt;



&lt;p&gt;With its strong benchmark performance, long-context capability, and permissive licensing, Qwen3-Thinking-2507 is particularly well suited for use in enterprise AI systems involving reasoning, planning, and decision support.&lt;/p&gt;



&lt;p&gt;The broader Qwen3 ecosystem — including coding, instruction, and translation models—further extends the appeal to technical teams and business units looking to incorporate AI across verticals like engineering, localization, customer support, and research.&lt;/p&gt;



&lt;p&gt;The Qwen team’s decision to release specialized models for distinct use cases, backed by technical transparency and community support, signals a deliberate shift toward building &lt;strong&gt;open, performant, and production-ready AI infrastructure&lt;/strong&gt;.&lt;/p&gt;



&lt;p&gt;As more enterprises seek alternatives to API-gated, black-box models, Alibaba’s Qwen series increasingly positions itself as a viable open-source foundation for intelligent systems—offering both control and capability at scale.&lt;/p&gt;




&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/its-qwens-summer-new-open-source-qwen3-235b-a22b-thinking-2507-tops-openai-gemini-reasoning-models-on-key-benchmarks/</guid><pubDate>Fri, 25 Jul 2025 15:47:28 +0000</pubDate></item><item><title>A timeline of the US semiconductor market in 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/25/a-timeline-of-the-u-s-semiconductor-market-in-2025/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/GettyImages-1366897838.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;It’s been a tumultuous year for the U.S. semiconductor industry.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The semiconductor industry plays a sizable role in the “AI race” that the U.S. seems determined to win, which is why this context is worth paying attention to: from Intel’s appointment of Lip-Bu Tan to CEO — who wasted no time getting to work trying to revitalize the legacy company — to Joe Biden proposing sweeping new AI chip export rules on his way out of office that never came to fruition. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Here’s a look at what’s happened so far in 2025. &lt;/p&gt;

&lt;h2 class="wp-block-heading"&gt;July&lt;/h2&gt;

&lt;h3 class="wp-block-heading"&gt;Intel continues to look for efficiency&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;July 24:&lt;/strong&gt; Intel announced that it was pulling back on some of its manufacturing operations. The company will no longer pursue its previously announced projects in Germany and Poland and is consolidating its test operations. Intel also announced it plans to end this year with around 75,000 employees.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-trump-s-ai-action-plan"&gt;Trump’s AI Action Plan&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;July 23:&lt;/strong&gt; The Trump administration unveiled its much-anticipated AI Action Plan alongside multiple related executive orders. While the plan includes a lot regarding the need for U.S. chip export controls, and for the U.S. to coordinate with its allies on this effort, it doesn’t provide any concrete information on what these restrictions would look like.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Groundbreaking UAE AI deal reportedly on hold&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;July 17:&lt;/strong&gt; The Trump administration helped foster a groundbreaking deal in May that resulted in a commitment from the United Arab Emirates to buy billions of dollars’ worth of AI chips from Nvidia. But now that deal is reportedly on hold as the U.S. works through national security concerns and fears that those chips could be smuggled from the Middle East to China.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Nvidia is a bargaining chip&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;July 16:&lt;/strong&gt; A day after semiconductor firms like Nvidia and AMD got the green light to resume selling certain AI chips to China, we found out why. U.S. Commerce Security Howard Lutnick said the plans to allow U.S. companies to start selling AI chips in China is tied to ongoing trade discussions between the U.S. and China regarding rare earth elements.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h3 class="wp-block-heading" id="h-u-s-chips-head-back-to-china"&gt;U.S. chips head back to China&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;July 14:&lt;/strong&gt; Nvidia said it was filing an application to restart sales of H20 AI chips in China, confirming rumors from a few weeks prior. The company also announced that it would be selling a new chip, the RTX Pro, which was designed specifically for the Chinese market.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Malaysia fights chip smuggling&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;July 14:&lt;/strong&gt; Malaysia announced that it was launching trade permits for U.S.-made AI chips. Under this new restriction, any individual or business would need to give the Malaysian government 30 days notice before exporting any U.S. AI chips.&lt;/p&gt;

&lt;h2 class="wp-block-heading"&gt;June&lt;/h2&gt;

&lt;h3 class="wp-block-heading"&gt;Intel appoints new leadership&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;June 18: &lt;/strong&gt;Intel announced four new leadership appointments that Intel says will help it move toward its goal of becoming an engineering-first company again. Intel announced a new chief revenue officer in addition to multiple high-profile engineering hires.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Intel to begin layoffs&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;June 17: &lt;/strong&gt;Intel will begin to lay off a significant chunk of its Intel Foundry staff in July. The company plans to eliminate at least 15%, and up to 20%, of workers in that business unit. These layoffs aren’t a shock: It was rumored back in April, and Intel’s CEO Lip-Bu Tan has said he wants to flatten the organization.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Nvidia won’t report on China&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;June 13: &lt;/strong&gt;Nvidia isn’t counting on the U.S. backing off of its AI chip export restrictions anytime soon. After the company took a financial hit from the newly imposed licensing requirements on its H20 AI chips, Nvidia CEO Jensen Huang said the company will no longer include the Chinese market in future revenue and profit forecasts.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;AMD acquires the team behind Untether AI&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;June 6: &lt;/strong&gt;AMD makes another acquisition —&amp;nbsp;this time focused on talent. The company acqui-hired the team behind Untether AI, which develops AI inference chips, as the semiconductor giant continues to round out its AI offerings.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;AMD is coming for Nvidia’s AI hardware dominance&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;June 4: &lt;/strong&gt;AMD continued its shopping spree. The company acquired AI software optimization startup Brium, which helps companies retrofit AI software to work with different AI hardware. With a lot of AI software being designed with Nvidia hardware in mind, this acquisition isn’t surprising.&lt;/p&gt;

&lt;h2 class="wp-block-heading"&gt;May&lt;/h2&gt;

&lt;h3 class="wp-block-heading"&gt;Nvidia lays out the impact of chip export restrictions&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;May 28: &lt;/strong&gt;Nvidia reported that U.S. licensing requirements on its H20 AI chips cost the company $4.5 billion in charges during Q1. The company expects these requirements to result in an $8 billion hit to Nvidia’s revenue in Q2.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;AMD acquires Enosemi&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;May 28:&lt;/strong&gt; AMD kicks off its acquisition spree. The semiconductor company announced that it acquired Enosemi, a silicon photonics startup. Enosemi’s tech, which uses light photons to transmit data, is becoming an increasing area of interest for semiconductor companies.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Tensions start to flare between China and the U.S.&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;May 21: &lt;/strong&gt;China’s Commerce Secretary didn’t like the U.S.’s guidance, issued on May 13, that warned U.S. companies that using Huawei’s AI chips “anywhere in the world” was a U.S. chip export violation. The commerce secretary issued a statement that threatened legal action against anyone caught enforcing that export restriction.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Intel may be starting to offload its non-core units&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;May 20: &lt;/strong&gt;Intel CEO Lip-Bu Tan seemingly got right to work on his plan to spin out Intel’s non-core business units. The semiconductor giant is reportedly looking to offload its networking and edge units, which makes chips for telecom equipment, and was responsible for $5.4 billion of the company’s 2024 revenue.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;The Biden administration’s AI Diffusion rule is officially dead&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;May 13:&lt;/strong&gt; Just days before the Biden administration’s Artificial Intelligence Diffusion Rule was set to go into place, the U.S. Department of Commerce formally rescinded it. The DOC said that it plans to issue new guidance in the future, and in the meantime companies should remember that using Huawei’s Ascend AI chips anywhere in the world is a violation of U.S. export rules.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-a-last-minute-reversal"&gt;A last-minute reversal&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;May 7:&lt;/strong&gt; Just a week before the “Framework for Artificial Intelligence Diffusion” was set to go into place, the Trump administration plans on taking a different path. According to multiple media outlets, including Axios and Bloomberg, the administration won’t enforce the restrictions when they were supposed to start on May 15 and is instead working on its own framework.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-april"&gt;April&lt;/h2&gt;

&lt;h3 class="wp-block-heading" id="h-anthropic-doubles-down-on-its-support-of-chip-export-restrictions"&gt;Anthropic doubles down on its support of chip export restrictions&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;April 30:&amp;nbsp;&lt;/strong&gt;Anthropic doubled down on its support for restricting U.S.-made chip exports, including some tweaks to the Framework for Artificial Intelligence Diffusion, like imposing further restrictions on Tier 2 countries and dedicating resources to enforcement.&amp;nbsp;An Nvidia spokesperson shot back, saying, “American firms should focus on innovation and rise to the challenge, rather than tell tall tales that large, heavy, and sensitive electronics are somehow smuggled in ‘baby bumps’ or ‘alongside live lobsters.’”&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-planned-layoffs-at-intel"&gt;Planned layoffs at Intel&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;April 22:&amp;nbsp;&lt;/strong&gt;Ahead of its Q1 earnings call, Intel said it was planning to lay off more than 21,000 employees. The layoffs were meant to streamline management, something CEO Lip-Bu Tan has long said Intel needed to do, and help rebuild the company’s engineering focus.&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-the-trump-administration-further-restricts-chip-exports"&gt;The Trump administration further restricts chip exports&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;April 15:&amp;nbsp;&lt;/strong&gt;Nvidia’s H20 AI chip got hit with an export licensing requirement, the company disclosed in an SEC filing. The company added it expects $5.5 billion in charges related to this new requirement in the first quarter of its 2026 fiscal year. The H20 is the most advanced AI chip Nvidia can still export to China in some form or fashion. TSMC and Intel reported similar expenses the same week.&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-nvidia-appears-to-talk-its-way-out-of-further-chip-exports"&gt;Nvidia appears to talk its way out of further chip exports&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;April 9:&amp;nbsp;&lt;/strong&gt;Nvidia’s CEO Jensen Huang was spotted attending dinner at Donald Trump’s Mar-a-Lago resort, according to reports. At the time, NPR reported Huang may have been able to spare Nvidia’s H20 AI chips from export restrictions upon agreeing to invest in AI data centers in the U.S.&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-an-alleged-agreement-between-intel-and-tsmc"&gt;An alleged agreement between Intel and TSMC&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;April 3:&amp;nbsp;&lt;/strong&gt;Intel and TSMC allegedly reached a tentative agreement to launch a joint chipmaking venture. This joint venture would operate Intel’s chipmaking facilities, and TSMC would have a 20% stake in the new venture. Both companies declined to comment or confirm. If this deal doesn’t come to fruition, this is likely a decent preview of potential deals in this industry to come.&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-intel-spins-off-noncore-assets-announces-new-initiative"&gt;Intel spins off noncore assets, announces new initiative&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;April 1:&amp;nbsp;&lt;/strong&gt;CEO Lip-Bu Tan got to work right away. Just weeks after he joined Intel, the company announced that it was going to spin off noncore assets so it could focus. He also said the company would launch new products, including custom semiconductors for customers.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-march"&gt;March&lt;/h2&gt;

&lt;h3 class="wp-block-heading" id="h-intel-names-a-new-ceo-nbsp"&gt;Intel names a new CEO&amp;nbsp;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;March 12:&amp;nbsp;&lt;/strong&gt; Intel announced that industry veteran, and former board member, Lip-Bu Tan would return to the company as CEO on March 18. At the time of his appointment, Tan said Intel would be an “engineering-focused company” under his leadership.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-february"&gt;February&lt;/h2&gt;

&lt;h3 class="wp-block-heading" id="h-intel-s-ohio-chip-plant-gets-delayed-again"&gt;Intel’s Ohio chip plant gets delayed again&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;February 28:&amp;nbsp;&lt;/strong&gt;Intel was supposed to start operating its first chip fabrication plant in Ohio this year. Instead, the company slowed down construction on the plant for the second time in February. Now the $28 billion semiconductor project won’t wrap up construction until 2030 and may not even open until 2031.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-senators-call-for-more-chip-export-restrictions"&gt;Senators call for more chip export restrictions&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;February 3:&amp;nbsp;&lt;/strong&gt;U.S. senators, including Elizabeth Warren (D-Mass) and Josh Hawley (R-Mo), wrote a letter to Commerce Secretary Nominee-Designate Howard Lutnick urging the Trump administration to further restrict AI chip exports. The letter specifically referred to Nvidia’s H20 AI chips, which were used in the training of DeepSeek’s R1 “reasoning” model.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-january-nbsp"&gt;January&amp;nbsp;&lt;/h2&gt;

&lt;h3 class="wp-block-heading" id="h-deepseek-releases-its-open-reasoning-model"&gt;DeepSeek releases its open “reasoning” model&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;January 27:&amp;nbsp;&lt;/strong&gt;Chinese AI startup DeepSeek caused quite the stir in Silicon Valley when it released the open version of its R1 “reasoning” model. While this isn’t semiconductor news specifically, the sheer alarm in the AI and semiconductor industries DeepSeek’s release caused continues to have ripple effects on the chip industry.&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-joe-biden-s-executive-order-on-chip-exports"&gt;Joe Biden’s executive order on chip exports&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;January 13:&amp;nbsp;&lt;/strong&gt;With just a week left in office, former president Joe Biden proposed sweeping new export restrictions on U.S.-made AI chips. This order created a three-tier structure that determined how many U.S. chips can be exported to each country. Under this proposal, Tier 1 countries faced no restrictions; Tier 2 countries had a chip purchase limit for the first time; and Tier 3 countries got additional restrictions.&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-anthropic-s-dario-amodei-weighs-in-on-chip-export-restrictions"&gt;Anthropic’s Dario Amodei weighs in on chip export restrictions&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;January 6:&lt;/strong&gt;&amp;nbsp;Anthropic co-founder and CEO Dario Amodei co-wrote an op-ed in The Wall Street Journal endorsing existing AI chip export controls and pointing to them as a reason why China’s AI market was behind the U.S.’. He also called on incoming president Donald Trump to impose further restrictions and to close loopholes that have allowed AI companies in China to still get their hands on these chips.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story originally published May 9, 2025, and is regularly updated with new information.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/GettyImages-1366897838.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;It’s been a tumultuous year for the U.S. semiconductor industry.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The semiconductor industry plays a sizable role in the “AI race” that the U.S. seems determined to win, which is why this context is worth paying attention to: from Intel’s appointment of Lip-Bu Tan to CEO — who wasted no time getting to work trying to revitalize the legacy company — to Joe Biden proposing sweeping new AI chip export rules on his way out of office that never came to fruition. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Here’s a look at what’s happened so far in 2025. &lt;/p&gt;

&lt;h2 class="wp-block-heading"&gt;July&lt;/h2&gt;

&lt;h3 class="wp-block-heading"&gt;Intel continues to look for efficiency&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;July 24:&lt;/strong&gt; Intel announced that it was pulling back on some of its manufacturing operations. The company will no longer pursue its previously announced projects in Germany and Poland and is consolidating its test operations. Intel also announced it plans to end this year with around 75,000 employees.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-trump-s-ai-action-plan"&gt;Trump’s AI Action Plan&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;July 23:&lt;/strong&gt; The Trump administration unveiled its much-anticipated AI Action Plan alongside multiple related executive orders. While the plan includes a lot regarding the need for U.S. chip export controls, and for the U.S. to coordinate with its allies on this effort, it doesn’t provide any concrete information on what these restrictions would look like.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Groundbreaking UAE AI deal reportedly on hold&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;July 17:&lt;/strong&gt; The Trump administration helped foster a groundbreaking deal in May that resulted in a commitment from the United Arab Emirates to buy billions of dollars’ worth of AI chips from Nvidia. But now that deal is reportedly on hold as the U.S. works through national security concerns and fears that those chips could be smuggled from the Middle East to China.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Nvidia is a bargaining chip&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;July 16:&lt;/strong&gt; A day after semiconductor firms like Nvidia and AMD got the green light to resume selling certain AI chips to China, we found out why. U.S. Commerce Security Howard Lutnick said the plans to allow U.S. companies to start selling AI chips in China is tied to ongoing trade discussions between the U.S. and China regarding rare earth elements.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h3 class="wp-block-heading" id="h-u-s-chips-head-back-to-china"&gt;U.S. chips head back to China&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;July 14:&lt;/strong&gt; Nvidia said it was filing an application to restart sales of H20 AI chips in China, confirming rumors from a few weeks prior. The company also announced that it would be selling a new chip, the RTX Pro, which was designed specifically for the Chinese market.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Malaysia fights chip smuggling&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;July 14:&lt;/strong&gt; Malaysia announced that it was launching trade permits for U.S.-made AI chips. Under this new restriction, any individual or business would need to give the Malaysian government 30 days notice before exporting any U.S. AI chips.&lt;/p&gt;

&lt;h2 class="wp-block-heading"&gt;June&lt;/h2&gt;

&lt;h3 class="wp-block-heading"&gt;Intel appoints new leadership&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;June 18: &lt;/strong&gt;Intel announced four new leadership appointments that Intel says will help it move toward its goal of becoming an engineering-first company again. Intel announced a new chief revenue officer in addition to multiple high-profile engineering hires.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Intel to begin layoffs&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;June 17: &lt;/strong&gt;Intel will begin to lay off a significant chunk of its Intel Foundry staff in July. The company plans to eliminate at least 15%, and up to 20%, of workers in that business unit. These layoffs aren’t a shock: It was rumored back in April, and Intel’s CEO Lip-Bu Tan has said he wants to flatten the organization.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Nvidia won’t report on China&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;June 13: &lt;/strong&gt;Nvidia isn’t counting on the U.S. backing off of its AI chip export restrictions anytime soon. After the company took a financial hit from the newly imposed licensing requirements on its H20 AI chips, Nvidia CEO Jensen Huang said the company will no longer include the Chinese market in future revenue and profit forecasts.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;AMD acquires the team behind Untether AI&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;June 6: &lt;/strong&gt;AMD makes another acquisition —&amp;nbsp;this time focused on talent. The company acqui-hired the team behind Untether AI, which develops AI inference chips, as the semiconductor giant continues to round out its AI offerings.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;AMD is coming for Nvidia’s AI hardware dominance&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;June 4: &lt;/strong&gt;AMD continued its shopping spree. The company acquired AI software optimization startup Brium, which helps companies retrofit AI software to work with different AI hardware. With a lot of AI software being designed with Nvidia hardware in mind, this acquisition isn’t surprising.&lt;/p&gt;

&lt;h2 class="wp-block-heading"&gt;May&lt;/h2&gt;

&lt;h3 class="wp-block-heading"&gt;Nvidia lays out the impact of chip export restrictions&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;May 28: &lt;/strong&gt;Nvidia reported that U.S. licensing requirements on its H20 AI chips cost the company $4.5 billion in charges during Q1. The company expects these requirements to result in an $8 billion hit to Nvidia’s revenue in Q2.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;AMD acquires Enosemi&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;May 28:&lt;/strong&gt; AMD kicks off its acquisition spree. The semiconductor company announced that it acquired Enosemi, a silicon photonics startup. Enosemi’s tech, which uses light photons to transmit data, is becoming an increasing area of interest for semiconductor companies.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Tensions start to flare between China and the U.S.&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;May 21: &lt;/strong&gt;China’s Commerce Secretary didn’t like the U.S.’s guidance, issued on May 13, that warned U.S. companies that using Huawei’s AI chips “anywhere in the world” was a U.S. chip export violation. The commerce secretary issued a statement that threatened legal action against anyone caught enforcing that export restriction.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Intel may be starting to offload its non-core units&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;May 20: &lt;/strong&gt;Intel CEO Lip-Bu Tan seemingly got right to work on his plan to spin out Intel’s non-core business units. The semiconductor giant is reportedly looking to offload its networking and edge units, which makes chips for telecom equipment, and was responsible for $5.4 billion of the company’s 2024 revenue.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;The Biden administration’s AI Diffusion rule is officially dead&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;May 13:&lt;/strong&gt; Just days before the Biden administration’s Artificial Intelligence Diffusion Rule was set to go into place, the U.S. Department of Commerce formally rescinded it. The DOC said that it plans to issue new guidance in the future, and in the meantime companies should remember that using Huawei’s Ascend AI chips anywhere in the world is a violation of U.S. export rules.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-a-last-minute-reversal"&gt;A last-minute reversal&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;May 7:&lt;/strong&gt; Just a week before the “Framework for Artificial Intelligence Diffusion” was set to go into place, the Trump administration plans on taking a different path. According to multiple media outlets, including Axios and Bloomberg, the administration won’t enforce the restrictions when they were supposed to start on May 15 and is instead working on its own framework.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-april"&gt;April&lt;/h2&gt;

&lt;h3 class="wp-block-heading" id="h-anthropic-doubles-down-on-its-support-of-chip-export-restrictions"&gt;Anthropic doubles down on its support of chip export restrictions&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;April 30:&amp;nbsp;&lt;/strong&gt;Anthropic doubled down on its support for restricting U.S.-made chip exports, including some tweaks to the Framework for Artificial Intelligence Diffusion, like imposing further restrictions on Tier 2 countries and dedicating resources to enforcement.&amp;nbsp;An Nvidia spokesperson shot back, saying, “American firms should focus on innovation and rise to the challenge, rather than tell tall tales that large, heavy, and sensitive electronics are somehow smuggled in ‘baby bumps’ or ‘alongside live lobsters.’”&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-planned-layoffs-at-intel"&gt;Planned layoffs at Intel&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;April 22:&amp;nbsp;&lt;/strong&gt;Ahead of its Q1 earnings call, Intel said it was planning to lay off more than 21,000 employees. The layoffs were meant to streamline management, something CEO Lip-Bu Tan has long said Intel needed to do, and help rebuild the company’s engineering focus.&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-the-trump-administration-further-restricts-chip-exports"&gt;The Trump administration further restricts chip exports&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;April 15:&amp;nbsp;&lt;/strong&gt;Nvidia’s H20 AI chip got hit with an export licensing requirement, the company disclosed in an SEC filing. The company added it expects $5.5 billion in charges related to this new requirement in the first quarter of its 2026 fiscal year. The H20 is the most advanced AI chip Nvidia can still export to China in some form or fashion. TSMC and Intel reported similar expenses the same week.&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-nvidia-appears-to-talk-its-way-out-of-further-chip-exports"&gt;Nvidia appears to talk its way out of further chip exports&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;April 9:&amp;nbsp;&lt;/strong&gt;Nvidia’s CEO Jensen Huang was spotted attending dinner at Donald Trump’s Mar-a-Lago resort, according to reports. At the time, NPR reported Huang may have been able to spare Nvidia’s H20 AI chips from export restrictions upon agreeing to invest in AI data centers in the U.S.&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-an-alleged-agreement-between-intel-and-tsmc"&gt;An alleged agreement between Intel and TSMC&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;April 3:&amp;nbsp;&lt;/strong&gt;Intel and TSMC allegedly reached a tentative agreement to launch a joint chipmaking venture. This joint venture would operate Intel’s chipmaking facilities, and TSMC would have a 20% stake in the new venture. Both companies declined to comment or confirm. If this deal doesn’t come to fruition, this is likely a decent preview of potential deals in this industry to come.&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-intel-spins-off-noncore-assets-announces-new-initiative"&gt;Intel spins off noncore assets, announces new initiative&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;April 1:&amp;nbsp;&lt;/strong&gt;CEO Lip-Bu Tan got to work right away. Just weeks after he joined Intel, the company announced that it was going to spin off noncore assets so it could focus. He also said the company would launch new products, including custom semiconductors for customers.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-march"&gt;March&lt;/h2&gt;

&lt;h3 class="wp-block-heading" id="h-intel-names-a-new-ceo-nbsp"&gt;Intel names a new CEO&amp;nbsp;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;March 12:&amp;nbsp;&lt;/strong&gt; Intel announced that industry veteran, and former board member, Lip-Bu Tan would return to the company as CEO on March 18. At the time of his appointment, Tan said Intel would be an “engineering-focused company” under his leadership.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-february"&gt;February&lt;/h2&gt;

&lt;h3 class="wp-block-heading" id="h-intel-s-ohio-chip-plant-gets-delayed-again"&gt;Intel’s Ohio chip plant gets delayed again&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;February 28:&amp;nbsp;&lt;/strong&gt;Intel was supposed to start operating its first chip fabrication plant in Ohio this year. Instead, the company slowed down construction on the plant for the second time in February. Now the $28 billion semiconductor project won’t wrap up construction until 2030 and may not even open until 2031.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-senators-call-for-more-chip-export-restrictions"&gt;Senators call for more chip export restrictions&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;February 3:&amp;nbsp;&lt;/strong&gt;U.S. senators, including Elizabeth Warren (D-Mass) and Josh Hawley (R-Mo), wrote a letter to Commerce Secretary Nominee-Designate Howard Lutnick urging the Trump administration to further restrict AI chip exports. The letter specifically referred to Nvidia’s H20 AI chips, which were used in the training of DeepSeek’s R1 “reasoning” model.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-january-nbsp"&gt;January&amp;nbsp;&lt;/h2&gt;

&lt;h3 class="wp-block-heading" id="h-deepseek-releases-its-open-reasoning-model"&gt;DeepSeek releases its open “reasoning” model&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;January 27:&amp;nbsp;&lt;/strong&gt;Chinese AI startup DeepSeek caused quite the stir in Silicon Valley when it released the open version of its R1 “reasoning” model. While this isn’t semiconductor news specifically, the sheer alarm in the AI and semiconductor industries DeepSeek’s release caused continues to have ripple effects on the chip industry.&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-joe-biden-s-executive-order-on-chip-exports"&gt;Joe Biden’s executive order on chip exports&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;January 13:&amp;nbsp;&lt;/strong&gt;With just a week left in office, former president Joe Biden proposed sweeping new export restrictions on U.S.-made AI chips. This order created a three-tier structure that determined how many U.S. chips can be exported to each country. Under this proposal, Tier 1 countries faced no restrictions; Tier 2 countries had a chip purchase limit for the first time; and Tier 3 countries got additional restrictions.&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-anthropic-s-dario-amodei-weighs-in-on-chip-export-restrictions"&gt;Anthropic’s Dario Amodei weighs in on chip export restrictions&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;January 6:&lt;/strong&gt;&amp;nbsp;Anthropic co-founder and CEO Dario Amodei co-wrote an op-ed in The Wall Street Journal endorsing existing AI chip export controls and pointing to them as a reason why China’s AI market was behind the U.S.’. He also called on incoming president Donald Trump to impose further restrictions and to close loopholes that have allowed AI companies in China to still get their hands on these chips.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story originally published May 9, 2025, and is regularly updated with new information.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/25/a-timeline-of-the-u-s-semiconductor-market-in-2025/</guid><pubDate>Fri, 25 Jul 2025 17:01:24 +0000</pubDate></item><item><title>Mistral’s new “environmental audit” shows how much AI is hurting the planet (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/07/mistrals-new-environmental-audit-shows-how-much-ai-is-hurting-the-planet/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Individual prompts don't cost much, but billions together can have aggregate impact.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1318519629-640x360.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1318519629-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A view of the future brought on by too many power-hungry AI servers?

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Despite concerns over the environmental impacts of AI models, it's surprisingly hard to find precise, reliable data on the CO&lt;sub&gt;2&lt;/sub&gt; emissions and water use for many major large language models. French model-maker Mistral is seeking to fix that this week, releasing details from what it calls a first-of-its-kind environmental audit "to quantify the environmental impacts of our LLMs."&lt;/p&gt;
&lt;p&gt;The results, which are broadly in line with estimates from previous scholarly work, suggest the environmental harm of any single AI query is relatively small compared to many other common Internet tasks. But with billions of AI prompts taxing GPUs every year, even those small individual impacts can lead to significant environmental effects in aggregate.&lt;/p&gt;
&lt;h2&gt;Is AI really destroying the planet?&lt;/h2&gt;
&lt;p&gt;To generate a life-cycle analysis of its "Large 2" model after just under 18 months of existence, Mistral partnered with sustainability consultancy Carbone 4 and the French Agency for Ecological Transition. Following the French government's Frugal AI guidelines for measuring overall environmental impact, Mistral says its peer-reviewed study looked at three categories: greenhouse gas (i.e., CO&lt;sub&gt;2&lt;/sub&gt;) emissions, water consumption, and materials consumption (i.e., "the depletion of non-renewable resources," mostly through wear and tear on AI server GPUs). Mistral's audit found that the vast majority of CO&lt;sub&gt;2&lt;/sub&gt; emissions and water consumption (85.5 percent and 91 percent, respectively) occurred during model training and inference, rather than from sources like data center construction and energy used by end-user equipment.&lt;/p&gt;
&lt;p&gt;Through its audit, Mistral found that the marginal "inference time" environmental impact of a single average prompt (generating 400 tokens' worth of text, or about a page's worth) was relatively minimal: just 1.14 grams of CO&lt;sub&gt;2&lt;/sub&gt; emitted and 45 milliliters of water consumed. Through its first 18 months of operation, though, the combination of model training and running millions (if not billions) of those prompts led to a significant aggregate impact: 20.4 ktons of CO&lt;sub&gt;2&lt;/sub&gt; emissions (comparable to 4,500 average internal combustion-engine passenger vehicles operating for a year, according to the Environmental Protection Agency) and the evaporation of 281,000 cubic meters of water (enough to fill about 112 Olympic-sized swimming pools).&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2108405 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="1540" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/mistralco2.jpg" width="1841" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The marginal impact of a single Mistral LLM query compared to some other common activities.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Mistral

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Comparing Mistral's environmental impact numbers to those of other common Internet tasks helps put the AI's environmental impact in context. Mistral points out, for instance, that the incremental CO&lt;sub&gt;2&lt;/sub&gt; emissions from one of its average LLM queries are equivalent to those of watching 10 seconds of a streaming show in the US (or 55 seconds of the same show in France, where the energy grid is notably cleaner). It's also equivalent to sitting on a Zoom call for anywhere from four to 27 seconds, according to numbers from the Mozilla Foundation. And spending 10 minutes writing an email that's read fully by one of its 100 recipients emits as much CO&lt;sub&gt;2&lt;/sub&gt; as 22.8 Mistral prompts, according to numbers from Carbon Literacy.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Directly comparing the social and environmental "value" of all of these activities isn't easy and depends heavily on how much value you place on the output of AI tools in general. However, the level of social taboo, personal guilt, and overall online griping associated with these different tasks might not align with their similar environmental footprints. That's worth keeping in mind the next time you hear someone warn that AI energy use in particular is destroying the planet.&lt;/p&gt;
&lt;h2&gt;A call for more data&lt;/h2&gt;
&lt;p&gt;Mistral's numbers are broadly comparable to other studies that have sought to estimate AI's environmental impact. A study from researchers at the University of California, Riverside, for instance, estimated the average US AI data center used for OpenAI's GPT-3 consumed nearly 17 ml of water per LLM prompt. And a 2024 study published in the journal Nature estimated an average of 2.2g of CO&lt;sub&gt;2&lt;/sub&gt; emissions per query for ChatGPT (across training and inference time).&lt;/p&gt;
&lt;p&gt;Compared to those previous third-party estimates, the fact that Mistral provided information directly for this latest study definitely lends some additional weight to its reported numbers. Still, Mistral writes that its data represents "a first approximation" of the model's total environmental impact, with important estimates used for the life-cycle impact of GPUs, for instance. Hugging Face AI &amp;amp; Climate Lead Sasha Luccioni also notes that the information Mistral has released lacks important methodological details and information on the model's total energy use (rather than the estimated emissions from that energy use).&lt;/p&gt;
&lt;p&gt;Still, Luccioni calls the report "a great first step in terms of environmental impact assessment of AI models," which she hopes other AI companies will be inspired to emulate. Mistral is also urging other model makers to be more transparent about their environmental impact, saying that such comparative results "could enable the creation of a scoring system, helping buyers and users identify the least carbon-, water- and material-intensive models."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Individual prompts don't cost much, but billions together can have aggregate impact.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1318519629-640x360.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1318519629-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A view of the future brought on by too many power-hungry AI servers?

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Despite concerns over the environmental impacts of AI models, it's surprisingly hard to find precise, reliable data on the CO&lt;sub&gt;2&lt;/sub&gt; emissions and water use for many major large language models. French model-maker Mistral is seeking to fix that this week, releasing details from what it calls a first-of-its-kind environmental audit "to quantify the environmental impacts of our LLMs."&lt;/p&gt;
&lt;p&gt;The results, which are broadly in line with estimates from previous scholarly work, suggest the environmental harm of any single AI query is relatively small compared to many other common Internet tasks. But with billions of AI prompts taxing GPUs every year, even those small individual impacts can lead to significant environmental effects in aggregate.&lt;/p&gt;
&lt;h2&gt;Is AI really destroying the planet?&lt;/h2&gt;
&lt;p&gt;To generate a life-cycle analysis of its "Large 2" model after just under 18 months of existence, Mistral partnered with sustainability consultancy Carbone 4 and the French Agency for Ecological Transition. Following the French government's Frugal AI guidelines for measuring overall environmental impact, Mistral says its peer-reviewed study looked at three categories: greenhouse gas (i.e., CO&lt;sub&gt;2&lt;/sub&gt;) emissions, water consumption, and materials consumption (i.e., "the depletion of non-renewable resources," mostly through wear and tear on AI server GPUs). Mistral's audit found that the vast majority of CO&lt;sub&gt;2&lt;/sub&gt; emissions and water consumption (85.5 percent and 91 percent, respectively) occurred during model training and inference, rather than from sources like data center construction and energy used by end-user equipment.&lt;/p&gt;
&lt;p&gt;Through its audit, Mistral found that the marginal "inference time" environmental impact of a single average prompt (generating 400 tokens' worth of text, or about a page's worth) was relatively minimal: just 1.14 grams of CO&lt;sub&gt;2&lt;/sub&gt; emitted and 45 milliliters of water consumed. Through its first 18 months of operation, though, the combination of model training and running millions (if not billions) of those prompts led to a significant aggregate impact: 20.4 ktons of CO&lt;sub&gt;2&lt;/sub&gt; emissions (comparable to 4,500 average internal combustion-engine passenger vehicles operating for a year, according to the Environmental Protection Agency) and the evaporation of 281,000 cubic meters of water (enough to fill about 112 Olympic-sized swimming pools).&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2108405 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="1540" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/mistralco2.jpg" width="1841" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The marginal impact of a single Mistral LLM query compared to some other common activities.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Mistral

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Comparing Mistral's environmental impact numbers to those of other common Internet tasks helps put the AI's environmental impact in context. Mistral points out, for instance, that the incremental CO&lt;sub&gt;2&lt;/sub&gt; emissions from one of its average LLM queries are equivalent to those of watching 10 seconds of a streaming show in the US (or 55 seconds of the same show in France, where the energy grid is notably cleaner). It's also equivalent to sitting on a Zoom call for anywhere from four to 27 seconds, according to numbers from the Mozilla Foundation. And spending 10 minutes writing an email that's read fully by one of its 100 recipients emits as much CO&lt;sub&gt;2&lt;/sub&gt; as 22.8 Mistral prompts, according to numbers from Carbon Literacy.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Directly comparing the social and environmental "value" of all of these activities isn't easy and depends heavily on how much value you place on the output of AI tools in general. However, the level of social taboo, personal guilt, and overall online griping associated with these different tasks might not align with their similar environmental footprints. That's worth keeping in mind the next time you hear someone warn that AI energy use in particular is destroying the planet.&lt;/p&gt;
&lt;h2&gt;A call for more data&lt;/h2&gt;
&lt;p&gt;Mistral's numbers are broadly comparable to other studies that have sought to estimate AI's environmental impact. A study from researchers at the University of California, Riverside, for instance, estimated the average US AI data center used for OpenAI's GPT-3 consumed nearly 17 ml of water per LLM prompt. And a 2024 study published in the journal Nature estimated an average of 2.2g of CO&lt;sub&gt;2&lt;/sub&gt; emissions per query for ChatGPT (across training and inference time).&lt;/p&gt;
&lt;p&gt;Compared to those previous third-party estimates, the fact that Mistral provided information directly for this latest study definitely lends some additional weight to its reported numbers. Still, Mistral writes that its data represents "a first approximation" of the model's total environmental impact, with important estimates used for the life-cycle impact of GPUs, for instance. Hugging Face AI &amp;amp; Climate Lead Sasha Luccioni also notes that the information Mistral has released lacks important methodological details and information on the model's total energy use (rather than the estimated emissions from that energy use).&lt;/p&gt;
&lt;p&gt;Still, Luccioni calls the report "a great first step in terms of environmental impact assessment of AI models," which she hopes other AI companies will be inspired to emulate. Mistral is also urging other model makers to be more transparent about their environmental impact, saying that such comparative results "could enable the creation of a scoring system, helping buyers and users identify the least carbon-, water- and material-intensive models."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/07/mistrals-new-environmental-audit-shows-how-much-ai-is-hurting-the-planet/</guid><pubDate>Fri, 25 Jul 2025 17:11:50 +0000</pubDate></item><item><title>Sam Altman warns there’s no legal confidentiality when using ChatGPT as a therapist (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/25/sam-altman-warns-theres-no-legal-confidentiality-when-using-chatgpt-as-a-therapist/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/altman-on-theo-von.jpg?resize=1200,672" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT users may want to think twice before turning to their AI app for therapy or other kinds of emotional support. According to OpenAI CEO Sam Altman, the AI industry hasn’t yet figured out how to protect user privacy when it comes to these more sensitive conversations, because there’s no doctor-patient confidentiality when your doc is an AI. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The exec made these comments on a recent episode of Theo Von’s podcast, This Past Weekend w/ Theo Von.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In response to a question about how AI works with today’s legal system, Altman said one of the problems of not yet having a legal or policy framework for AI is that there’s no legal confidentiality for users’ conversations. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“People talk about the most personal sh** in their lives to ChatGPT,” Altman said. “People use it — young people, especially, use it — as a therapist, a life coach; having these relationship problems and [asking] ‘what should I do?’ And right now, if you talk to a therapist or a lawyer or a doctor about those problems, there’s legal privilege for it. There’s doctor-patient confidentiality, there’s legal confidentiality, whatever. And we haven’t figured that out yet for when you talk to ChatGPT.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This could create a privacy concern for users in the case of a lawsuit, Altman added, because OpenAI would be legally required to produce those conversations today. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think that’s very screwed up. I think we should have the same concept of privacy for your conversations with AI that we do with a therapist or whatever — and no one had to think about that even a year ago,” Altman said. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company understands that the lack of privacy could be a blocker to broader user adoption. In addition to AI’s demand for so much online data during the training period, it’s being asked to produce data from users’ chats in some legal contexts. Already, OpenAI has been fighting a court order in its lawsuit with The New York Times, which would require it to save the chats of hundreds of millions of ChatGPT users globally, excluding those from ChatGPT Enterprise customers.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In a statement on its website, OpenAI said it’s appealing this order, which it called “an overreach.” If the court could override OpenAI’s own decisions around data privacy, it could open the company to further demand for legal discovery or law enforcement purposes. Today’s tech companies are regularly subpoenaed for user data in order to aid in criminal prosecutions. But in more recent years, there have been additional concerns about digital data as laws began limiting access to previously established freedoms, like a woman’s right to choose.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When the Supreme Court overturned Roe v. Wade, for example, customers began switching to more private period-tracking apps or to Apple Health, which encrypted their records. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman asked the podcast host about his own ChatGPT usage, as well, given that Von said he didn’t talk to the AI chatbot much due to his own privacy concerns.  &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think it makes sense … to really want the privacy clarity before you use [ChatGPT] a lot — like the legal clarity,” Altman said.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/altman-on-theo-von.jpg?resize=1200,672" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT users may want to think twice before turning to their AI app for therapy or other kinds of emotional support. According to OpenAI CEO Sam Altman, the AI industry hasn’t yet figured out how to protect user privacy when it comes to these more sensitive conversations, because there’s no doctor-patient confidentiality when your doc is an AI. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The exec made these comments on a recent episode of Theo Von’s podcast, This Past Weekend w/ Theo Von.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In response to a question about how AI works with today’s legal system, Altman said one of the problems of not yet having a legal or policy framework for AI is that there’s no legal confidentiality for users’ conversations. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“People talk about the most personal sh** in their lives to ChatGPT,” Altman said. “People use it — young people, especially, use it — as a therapist, a life coach; having these relationship problems and [asking] ‘what should I do?’ And right now, if you talk to a therapist or a lawyer or a doctor about those problems, there’s legal privilege for it. There’s doctor-patient confidentiality, there’s legal confidentiality, whatever. And we haven’t figured that out yet for when you talk to ChatGPT.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This could create a privacy concern for users in the case of a lawsuit, Altman added, because OpenAI would be legally required to produce those conversations today. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think that’s very screwed up. I think we should have the same concept of privacy for your conversations with AI that we do with a therapist or whatever — and no one had to think about that even a year ago,” Altman said. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company understands that the lack of privacy could be a blocker to broader user adoption. In addition to AI’s demand for so much online data during the training period, it’s being asked to produce data from users’ chats in some legal contexts. Already, OpenAI has been fighting a court order in its lawsuit with The New York Times, which would require it to save the chats of hundreds of millions of ChatGPT users globally, excluding those from ChatGPT Enterprise customers.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In a statement on its website, OpenAI said it’s appealing this order, which it called “an overreach.” If the court could override OpenAI’s own decisions around data privacy, it could open the company to further demand for legal discovery or law enforcement purposes. Today’s tech companies are regularly subpoenaed for user data in order to aid in criminal prosecutions. But in more recent years, there have been additional concerns about digital data as laws began limiting access to previously established freedoms, like a woman’s right to choose.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When the Supreme Court overturned Roe v. Wade, for example, customers began switching to more private period-tracking apps or to Apple Health, which encrypted their records. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman asked the podcast host about his own ChatGPT usage, as well, given that Von said he didn’t talk to the AI chatbot much due to his own privacy concerns.  &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think it makes sense … to really want the privacy clarity before you use [ChatGPT] a lot — like the legal clarity,” Altman said.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/25/sam-altman-warns-theres-no-legal-confidentiality-when-using-chatgpt-as-a-therapist/</guid><pubDate>Fri, 25 Jul 2025 17:33:29 +0000</pubDate></item><item><title>Delta’s AI spying to “jack up” prices must be banned, lawmakers say (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/07/deltas-ai-spying-to-jack-up-prices-must-be-banned-lawmakers-say/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Lawmakers want to prevent companies from using AI to increase prices or lower wages.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="410" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2207302392-640x410.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2207302392-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Hongwei Jiang | iStock / Getty Images Plus

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;One week after Delta announced it is expanding a test using artificial intelligence to charge different prices based on customers' personal data—which critics fear could end cheap flights forever—Democratic lawmakers have moved to ban what they consider predatory surveillance pricing.&lt;/p&gt;
&lt;p&gt;In a press release, Reps. Greg Casar (D-Texas) and Rashida Tlaib (D-Mich.) announced the Stop AI Price Gouging and Wage Fixing Act. The law directly bans companies from using "surveillance-based" price or wage setting to increase their profit margins.&lt;/p&gt;
&lt;p&gt;If passed, the law would allow anyone to sue companies found unfairly using AI, lawmakers explained in what's called a "one-sheet." That could mean charging customers higher prices—based on "how desperate a customer is for a product and the maximum amount a customer is willing to pay"—or paying employees lower wages—based on "their financial status, personal associations, and demographics."&lt;/p&gt;
&lt;p&gt;Tlaib called companies using AI to "exploit" workers in "desperate" situations "appalling," with the one-sheet specifically shaming delivery services that lower drivers' wages based on their "pattern of taking orders" and health care companies that base nurses' pay on "an algorithmically-manipulated-bidding war, not the tasks they perform."&lt;/p&gt;
&lt;p&gt;The lawmakers also called out Delta among companies whose AI pricing plans, advocacy groups warn, stand to worsen the US "affordability crisis" that currently sees many Americans struggling to afford basic items, like groceries. Delta has confirmed it plans to "set 20 percent of prices using AI by the end of the year," lawmakers noted.&lt;/p&gt;
&lt;p&gt;Asked for comment on the bill, a Delta spokesperson confirmed the airline will be reaching out to Senators to explain its AI pricing. In a statement, Delta denied that its AI system used personalized data for individualized pricing. Instead, it apparently relies on AI to forecast demand for certain flights, adapt to emerging market conditions (like jet fuel costs), and factor in a wide variety of undisclosed variables, in addition to learning from pricing decisions. However, factors like customer purchasing behavior, customer demand, and competitive offers that perhaps that customer is known to be weighing also influence the AI's pricing, which lawmakers and critics may be interpreting as individualized pricing.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"There is no fare product Delta has ever used, is testing or plans to use that targets customers with individualized offers based on personal information or otherwise," Delta said. "A variety of market forces drive the dynamic pricing model that’s been used in the global industry for decades, with new tech simply streamlining this process. Delta always complies with regulations around pricing and disclosures."&lt;/p&gt;
&lt;p&gt;Other companies "engaging in surveillance-based price setting" include giants like Amazon and Kroger, as well as a ride-sharing app that has been "charging a customer more when their phone battery is low."&lt;/p&gt;
&lt;p&gt;Public Citizen, a progressive consumer rights group that endorsed the bill, condemned the practice in the press release, urging Congress to pass the law and draw "a clear line in the sand: companies can offer discounts and fair wages—but not by spying on people."&lt;/p&gt;
&lt;p&gt;"Surveillance-based price gouging and wage setting are exploitative practices that deepen inequality and strip consumers and workers of dignity," Public Citizen said.&lt;/p&gt;
&lt;h2&gt;AI pricing will cause “full-blown crisis”&lt;/h2&gt;
&lt;p&gt;In January, the Federal Trade Commission requested information from eight companies—including MasterCard, Revionics, Bloomreach, JPMorgan Chase, Task Software, PROS, Accenture, and McKinsey &amp;amp; Co—joining a "shadowy market" that provides AI pricing services. Those companies confirmed they've provided services to at least 250 companies "that sell goods or services ranging from grocery stores to apparel retailers," lawmakers noted.&lt;/p&gt;
&lt;p&gt;That inquiry led the FTC to conclude that "widespread adoption of this practice may fundamentally upend how consumers buy products and how companies compete."&lt;/p&gt;
&lt;p&gt;In the press release, the anti-monopoly watchdog, the American Economic Liberties Project, was counted among advocacy groups endorsing the Democrats' bill. Their senior legal counsel, Lee Hepner, pointed out that "grocery prices have risen 26 percent since the pandemic-era explosion of online shopping," and that's "dovetailing with new technology designed to squeeze every last penny from consumers."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Hepner pushed lawmakers to support the legislation banning AI surveillance pricing, suggesting that could help "restore fair, transparent, and predictable pricing." Otherwise, "there is no such thing as a good deal when every consumer is charged a different price," Hepner warned.&lt;/p&gt;
&lt;p&gt;For consumers and workers who may not even realize they've been subjected to AI spying, the law offers paths through their state, the FTC, and the Equal Employment Opportunity Commission to sue. Any violations could force companies to either pay back the difference in any unfair transactions that AI systems recommended or $3,000—whichever is higher. And willful violations could triple damages owed.&lt;/p&gt;
&lt;p&gt;"Giant corporations should not be allowed to jack up your prices or lower your wages using data they got spying on you," Casar said. "Whether you know it or not, you may already be getting ripped off by corporations using your personal data to charge you more. This problem is only going to get worse, and Congress should act before this becomes a full-blown crisis."&lt;/p&gt;
&lt;p&gt;It's unclear if the Democrats can win enough support from Republicans to pass the bill. Perhaps notably, Republican FTC commissioners voted against releasing the report outlining potential concerns with AI surveillance pricing and wage setting.&lt;/p&gt;
&lt;p&gt;In their dissent, commissioners Andrew Ferguson and Melissa Holyoak suggested the report was published prematurely, criticizing Biden's outgoing FTC for "nakedly" politicizing the agency and taking an "unprecedented" step in sharing preliminary summaries of findings.&lt;/p&gt;
&lt;p&gt;However, they did agree that when the final report is ready, the "American public and Congress will surely value what the Commission ultimately learns and shares as to whether and how consumers’ private data may be used to affect their pocketbooks, especially as the future of our nation’s privacy laws is being considered."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Lawmakers want to prevent companies from using AI to increase prices or lower wages.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="410" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2207302392-640x410.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2207302392-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Hongwei Jiang | iStock / Getty Images Plus

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;One week after Delta announced it is expanding a test using artificial intelligence to charge different prices based on customers' personal data—which critics fear could end cheap flights forever—Democratic lawmakers have moved to ban what they consider predatory surveillance pricing.&lt;/p&gt;
&lt;p&gt;In a press release, Reps. Greg Casar (D-Texas) and Rashida Tlaib (D-Mich.) announced the Stop AI Price Gouging and Wage Fixing Act. The law directly bans companies from using "surveillance-based" price or wage setting to increase their profit margins.&lt;/p&gt;
&lt;p&gt;If passed, the law would allow anyone to sue companies found unfairly using AI, lawmakers explained in what's called a "one-sheet." That could mean charging customers higher prices—based on "how desperate a customer is for a product and the maximum amount a customer is willing to pay"—or paying employees lower wages—based on "their financial status, personal associations, and demographics."&lt;/p&gt;
&lt;p&gt;Tlaib called companies using AI to "exploit" workers in "desperate" situations "appalling," with the one-sheet specifically shaming delivery services that lower drivers' wages based on their "pattern of taking orders" and health care companies that base nurses' pay on "an algorithmically-manipulated-bidding war, not the tasks they perform."&lt;/p&gt;
&lt;p&gt;The lawmakers also called out Delta among companies whose AI pricing plans, advocacy groups warn, stand to worsen the US "affordability crisis" that currently sees many Americans struggling to afford basic items, like groceries. Delta has confirmed it plans to "set 20 percent of prices using AI by the end of the year," lawmakers noted.&lt;/p&gt;
&lt;p&gt;Asked for comment on the bill, a Delta spokesperson confirmed the airline will be reaching out to Senators to explain its AI pricing. In a statement, Delta denied that its AI system used personalized data for individualized pricing. Instead, it apparently relies on AI to forecast demand for certain flights, adapt to emerging market conditions (like jet fuel costs), and factor in a wide variety of undisclosed variables, in addition to learning from pricing decisions. However, factors like customer purchasing behavior, customer demand, and competitive offers that perhaps that customer is known to be weighing also influence the AI's pricing, which lawmakers and critics may be interpreting as individualized pricing.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"There is no fare product Delta has ever used, is testing or plans to use that targets customers with individualized offers based on personal information or otherwise," Delta said. "A variety of market forces drive the dynamic pricing model that’s been used in the global industry for decades, with new tech simply streamlining this process. Delta always complies with regulations around pricing and disclosures."&lt;/p&gt;
&lt;p&gt;Other companies "engaging in surveillance-based price setting" include giants like Amazon and Kroger, as well as a ride-sharing app that has been "charging a customer more when their phone battery is low."&lt;/p&gt;
&lt;p&gt;Public Citizen, a progressive consumer rights group that endorsed the bill, condemned the practice in the press release, urging Congress to pass the law and draw "a clear line in the sand: companies can offer discounts and fair wages—but not by spying on people."&lt;/p&gt;
&lt;p&gt;"Surveillance-based price gouging and wage setting are exploitative practices that deepen inequality and strip consumers and workers of dignity," Public Citizen said.&lt;/p&gt;
&lt;h2&gt;AI pricing will cause “full-blown crisis”&lt;/h2&gt;
&lt;p&gt;In January, the Federal Trade Commission requested information from eight companies—including MasterCard, Revionics, Bloomreach, JPMorgan Chase, Task Software, PROS, Accenture, and McKinsey &amp;amp; Co—joining a "shadowy market" that provides AI pricing services. Those companies confirmed they've provided services to at least 250 companies "that sell goods or services ranging from grocery stores to apparel retailers," lawmakers noted.&lt;/p&gt;
&lt;p&gt;That inquiry led the FTC to conclude that "widespread adoption of this practice may fundamentally upend how consumers buy products and how companies compete."&lt;/p&gt;
&lt;p&gt;In the press release, the anti-monopoly watchdog, the American Economic Liberties Project, was counted among advocacy groups endorsing the Democrats' bill. Their senior legal counsel, Lee Hepner, pointed out that "grocery prices have risen 26 percent since the pandemic-era explosion of online shopping," and that's "dovetailing with new technology designed to squeeze every last penny from consumers."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Hepner pushed lawmakers to support the legislation banning AI surveillance pricing, suggesting that could help "restore fair, transparent, and predictable pricing." Otherwise, "there is no such thing as a good deal when every consumer is charged a different price," Hepner warned.&lt;/p&gt;
&lt;p&gt;For consumers and workers who may not even realize they've been subjected to AI spying, the law offers paths through their state, the FTC, and the Equal Employment Opportunity Commission to sue. Any violations could force companies to either pay back the difference in any unfair transactions that AI systems recommended or $3,000—whichever is higher. And willful violations could triple damages owed.&lt;/p&gt;
&lt;p&gt;"Giant corporations should not be allowed to jack up your prices or lower your wages using data they got spying on you," Casar said. "Whether you know it or not, you may already be getting ripped off by corporations using your personal data to charge you more. This problem is only going to get worse, and Congress should act before this becomes a full-blown crisis."&lt;/p&gt;
&lt;p&gt;It's unclear if the Democrats can win enough support from Republicans to pass the bill. Perhaps notably, Republican FTC commissioners voted against releasing the report outlining potential concerns with AI surveillance pricing and wage setting.&lt;/p&gt;
&lt;p&gt;In their dissent, commissioners Andrew Ferguson and Melissa Holyoak suggested the report was published prematurely, criticizing Biden's outgoing FTC for "nakedly" politicizing the agency and taking an "unprecedented" step in sharing preliminary summaries of findings.&lt;/p&gt;
&lt;p&gt;However, they did agree that when the final report is ready, the "American public and Congress will surely value what the Commission ultimately learns and shares as to whether and how consumers’ private data may be used to affect their pocketbooks, especially as the future of our nation’s privacy laws is being considered."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/07/deltas-ai-spying-to-jack-up-prices-must-be-banned-lawmakers-say/</guid><pubDate>Fri, 25 Jul 2025 18:13:52 +0000</pubDate></item><item><title>[NEW] OpenAI’s most capable AI model, GPT-5, may be coming in August (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/07/openais-most-capable-ai-model-gpt-5-may-be-coming-in-august/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Sources say new model combines o3 reasoning with general GPT capabilities.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The OpenAI logo over a tectonic shift in the background." class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/09/openai_tectonic_shift-300x169.jpg" width="300" /&gt;
                  &lt;img alt="The OpenAI logo over a tectonic shift in the background." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/09/openai_tectonic_shift-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards / OpenAI

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Thursday, The Verge reported that OpenAI is preparing to launch GPT-5 as early as August, according to sources familiar with the company's plans. The report comes five months after CEO Sam Altman first laid out a roadmap for the next-generation AI model that would unify the company's various AI capabilities. OpenAI CEO Sam Altman revealed in a post on X last week that the company plans to release GPT-5 "soon."&lt;/p&gt;
&lt;p&gt;According to The Verge's Tom Warren, Microsoft engineers began preparing server capacity for GPT-5 as early as late May, but testing and development challenges pushed the timeline back. During an appearance on Theo Von's podcast this week, Altman demonstrated the model's capabilities by having it answer a question he couldn't. "I put it in the model, this is GPT-5, and it answered it perfectly," Altman said, saying it gave him a "weird feeling" to see the AI model answer a question that he couldn't.&lt;/p&gt;
&lt;p&gt;GPT-5 has been a highly anticipated release since the launch of GPT-4 in March 2023. In fact, we first wrote about rumors of GPT-5's launch in March 2024, but it appears that GPT-5 did not materialize last year because the company saved the "GPT-5" name for a future release.&lt;/p&gt;
&lt;p&gt;The Verge reports that OpenAI plans to launch what is now called GPT-5 with "mini" and "nano" versions available through its API. The main version, which will combine a conventional large language model (LLM) and a simulated reasoning (SR) model, will be available through ChatGPT and OpenAI's API, while the nano version will reportedly only be accessible via the API.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;References to "gpt-5-reasoning-alpha-2025-07-13" have already been spotted on X, with code showing "reasoning_effort: high" in the model configuration. These sightings suggest the model has entered final testing phases, with testers getting their hands on the code and security experts doing red teaming on the model to test vulnerabilities.&lt;/p&gt;
&lt;h2&gt;Unifying OpenAI’s model lineup&lt;/h2&gt;
&lt;p&gt;The new model represents OpenAI's attempt to simplify its increasingly complex product lineup. As Altman explained in February, GPT-5 may integrate features from both the company's conventional GPT models and its reasoning-focused o-series models into a single system.&lt;/p&gt;
&lt;p&gt;"We're truly excited to not just make a net new great frontier model, we're also going to unify our two series," OpenAI's Head of Developer Experience Romain Huet said at a recent event. "The breakthrough of reasoning in the O-series and the breakthroughs in multi-modality in the GPT-series will be unified, and that will be GPT-5."&lt;/p&gt;
&lt;p&gt;According to The Information, GPT-5 is expected to be better at coding and more powerful overall, combining attributes of both traditional models and SR models such as o3.&lt;/p&gt;
&lt;p&gt;Before GPT-5 arrives, OpenAI still plans to release its first open-weights model since GPT-2 in 2019, which means others with the proper hardware will be able to download and run the AI model on their own machines. The Verge describes this model as "similar to o3 mini" with reasoning capabilities. However, Altman announced on July 11 that the open model needs additional safety testing, saying, "We are not yet sure how long it will take us."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Sources say new model combines o3 reasoning with general GPT capabilities.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The OpenAI logo over a tectonic shift in the background." class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/09/openai_tectonic_shift-300x169.jpg" width="300" /&gt;
                  &lt;img alt="The OpenAI logo over a tectonic shift in the background." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/09/openai_tectonic_shift-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards / OpenAI

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Thursday, The Verge reported that OpenAI is preparing to launch GPT-5 as early as August, according to sources familiar with the company's plans. The report comes five months after CEO Sam Altman first laid out a roadmap for the next-generation AI model that would unify the company's various AI capabilities. OpenAI CEO Sam Altman revealed in a post on X last week that the company plans to release GPT-5 "soon."&lt;/p&gt;
&lt;p&gt;According to The Verge's Tom Warren, Microsoft engineers began preparing server capacity for GPT-5 as early as late May, but testing and development challenges pushed the timeline back. During an appearance on Theo Von's podcast this week, Altman demonstrated the model's capabilities by having it answer a question he couldn't. "I put it in the model, this is GPT-5, and it answered it perfectly," Altman said, saying it gave him a "weird feeling" to see the AI model answer a question that he couldn't.&lt;/p&gt;
&lt;p&gt;GPT-5 has been a highly anticipated release since the launch of GPT-4 in March 2023. In fact, we first wrote about rumors of GPT-5's launch in March 2024, but it appears that GPT-5 did not materialize last year because the company saved the "GPT-5" name for a future release.&lt;/p&gt;
&lt;p&gt;The Verge reports that OpenAI plans to launch what is now called GPT-5 with "mini" and "nano" versions available through its API. The main version, which will combine a conventional large language model (LLM) and a simulated reasoning (SR) model, will be available through ChatGPT and OpenAI's API, while the nano version will reportedly only be accessible via the API.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;References to "gpt-5-reasoning-alpha-2025-07-13" have already been spotted on X, with code showing "reasoning_effort: high" in the model configuration. These sightings suggest the model has entered final testing phases, with testers getting their hands on the code and security experts doing red teaming on the model to test vulnerabilities.&lt;/p&gt;
&lt;h2&gt;Unifying OpenAI’s model lineup&lt;/h2&gt;
&lt;p&gt;The new model represents OpenAI's attempt to simplify its increasingly complex product lineup. As Altman explained in February, GPT-5 may integrate features from both the company's conventional GPT models and its reasoning-focused o-series models into a single system.&lt;/p&gt;
&lt;p&gt;"We're truly excited to not just make a net new great frontier model, we're also going to unify our two series," OpenAI's Head of Developer Experience Romain Huet said at a recent event. "The breakthrough of reasoning in the O-series and the breakthroughs in multi-modality in the GPT-series will be unified, and that will be GPT-5."&lt;/p&gt;
&lt;p&gt;According to The Information, GPT-5 is expected to be better at coding and more powerful overall, combining attributes of both traditional models and SR models such as o3.&lt;/p&gt;
&lt;p&gt;Before GPT-5 arrives, OpenAI still plans to release its first open-weights model since GPT-2 in 2019, which means others with the proper hardware will be able to download and run the AI model on their own machines. The Verge describes this model as "similar to o3 mini" with reasoning capabilities. However, Altman announced on July 11 that the open model needs additional safety testing, saying, "We are not yet sure how long it will take us."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/07/openais-most-capable-ai-model-gpt-5-may-be-coming-in-august/</guid><pubDate>Fri, 25 Jul 2025 19:59:37 +0000</pubDate></item><item><title>[NEW] CoSyn: The open-source tool that’s making GPT-4V-level vision AI accessible to everyone (AI News | VentureBeat)</title><link>https://venturebeat.com/business/cosyn-the-open-source-tool-thats-making-gpt-4v-level-vision-ai-accessible-to-everyone/</link><description>&lt;p&gt;Researchers at the University of Pennsylvania and the Allen Institute for Artificial Intelligence have developed a groundbreaking tool that allows open-source AI systems to match or surpass the visual understanding capabilities of proprietary models like GPT-4V and Gemini 1.5 Flash, potentially reshaping the competitive landscape between open and closed AI development.&lt;/p&gt;



&lt;p&gt;The tool, called CoSyn (Code-Guided Synthesis), addresses a critical bottleneck in AI development: the scarcity of high-quality training data for teaching machines to understand complex visual information like scientific charts, medical diagrams, and financial documents. Rather than scraping millions of images from the internet — a practice fraught with copyright and ethical concerns — CoSyn leverages the coding abilities of existing language models to generate synthetic training data.&lt;/p&gt;



&lt;p&gt;“We have, we lack of such data to train the model. We lack of data, like documents, charts with rich annotations to train a vision language model to do question answering over those images,” explained Yue Yang, a recent Penn Engineering Ph.D. graduate and co-first author of the research, during an exclusive interview with VentureBeat. “Those images actually are more challenging to annotate, compared to natural photos, like a picture of a dog of a cat of a house.”&lt;/p&gt;



&lt;p&gt;The breakthrough comes as enterprises increasingly seek AI systems capable of understanding and reasoning about complex visual information — capabilities essential for everything from automated document processing to AI agents that can navigate digital interfaces independently. The work was conducted during Yang’s internship with the PRIOR team at the Allen Institute for AI and supported by the Office of the Director of National Intelligence, Intelligence Advanced Research Projects Activity, and the Defense Advanced Research Projects Agency.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-synthetic-data-generation-solves-ai-s-biggest-training-challenge"&gt;How synthetic data generation solves AI’s biggest training challenge&lt;/h2&gt;



&lt;p&gt;The challenge of training AI to understand text-rich images has long plagued the field. Unlike natural photographs, scientific figures, charts, and documents require extensive annotation work that is both time-consuming and expensive. Traditional approaches have relied on harvesting images and their alt-text descriptions from the internet, but this method produces training data that is often superficial and legally problematic.&lt;/p&gt;



&lt;p&gt;CoSyn takes a fundamentally different approach by recognizing that most text-rich images are originally created through code — Python scripts generate charts, LaTeX renders mathematical equations, HTML creates web interfaces. The research team’s insight was to reverse this process: use language models’ proven coding abilities to generate the underlying code, then execute that code to create realistic synthetic images.&lt;/p&gt;



&lt;p&gt;“One intuition is actually those images like charts documents. We render them from programs from code, like we use Python to generate charts. We use, like latex or word to write our documents,” Yang said. “So how about we go through the reverse way, like we generated the code because the text only language model has been proved very good at writing code.”&lt;/p&gt;



&lt;p&gt;Chris Callison-Burch, a computer science professor at Penn who co-advised the research, described the approach in simpler terms: “This is like taking a student who’s great at writing and asking them to teach someone how to draw, just by describing what the drawing should look like. We’re essentially transferring the strengths of open-source AI from text to vision.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-cosyn-trained-models-outperform-gpt-4v-and-gemini-on-key-benchmarks"&gt;CoSyn-trained models outperform GPT-4V and Gemini on key benchmarks&lt;/h2&gt;



&lt;p&gt;The results are striking. Using their synthetic dataset of 400,000 images and 2.7 million instruction pairs, models trained with CoSyn achieved state-of-the-art performance among open-source systems and surpassed proprietary models on seven benchmark tests measuring text-rich image understanding.&lt;/p&gt;



&lt;p&gt;On average, their 7-billion parameter model scored 80.9% across the benchmark suite, outperforming the previous best open-source model (Llama 3.2 11B) by 3.9 percentage points. More remarkably, even their “zero-shot” model—trained without any examples from the evaluation datasets—outperformed most open and closed models, demonstrating the transferability of capabilities learned from synthetic data.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3014678" height="314" src="https://venturebeat.com/wp-content/uploads/2025/07/main_results.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;CoSyn-trained models outperformed GPT-4V and Gemini 1.5 Flash across seven text-rich image understanding benchmarks. (Credit: github.io/cosyn)&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;In one particularly compelling demonstration, the researchers created a new benchmark called NutritionQA, consisting of 100 questions about nutrition label photographs. Using just 7,000 synthetically generated nutrition labels for training, their model outperformed others trained on millions of real images. “Despite being trained on millions of images, we observe that open-source VLMs are not data-efficient and perform poorly on this novel task compared to GPT-4V,” the researchers wrote in their paper.&lt;/p&gt;



&lt;p&gt;Yang emphasized the significance: “Those big packs, they have so many resources to collecting data to run a lot of experiments, and I but I think open source models, we can give access to people, the model weights, the data we trained, or even the code, the training script, everything people can developers can build upon.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-real-companies-are-already-using-vision-ai-for-quality-control-and-automation"&gt;Real companies are already using vision AI for quality control and automation&lt;/h2&gt;



&lt;p&gt;The technology is already finding real-world applications across industries. Callison-Burch cited an example from one of his teaching assistants whose company uses vision-language models for cable installation quality assurance: “They have the workers on site who are doing the installation take photographs of the processes they’re doing it, and they use that to automatically validate that each step has been followed properly.”&lt;/p&gt;



&lt;p&gt;This type of specialized visual understanding could transform numerous enterprise workflows, from automated document processing in financial services to quality control in manufacturing. The ability to train models on specific visual tasks using synthetic data means companies can develop AI systems tailored to their particular needs without the massive data collection efforts traditionally required.&lt;/p&gt;



&lt;p&gt;For enterprise decision makers, the research suggests a shift in how to approach AI data strategies. “I think synthetic data is a very promising way to remove the effort for human annotation. It costs less money, and it will just automatically generate large scale data, and also can avoid some copyright issues,” Yang noted.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-persona-driven-approach-that-makes-ai-training-data-more-diverse"&gt;The persona-driven approach that makes AI training data more diverse&lt;/h2&gt;



&lt;p&gt;One of CoSyn’s key innovations is its approach to ensuring data diversity. To prevent the repetitive outputs common in AI-generated content, the system employs what the researchers call a “persona-driven mechanism.” Each time CoSyn generates a synthetic example, it pairs the request with a randomly sampled persona—a short description like “a sci-fi novelist constantly bouncing off ideas for new alien worlds” or “a chemistry teacher preparing lab materials.”&lt;/p&gt;



&lt;p&gt;“Every time we generate one syntax data, we will appear with a randomly sampled persona,” Yang explained. “This will diversify the content and styles of the examples we generated, because, like, if I provide the persona of like a PhD student, it will generate something more scientific or more about, something about academia.”&lt;/p&gt;



&lt;p&gt;This approach enables the system to generate content across nine different categories: charts, documents, math problems, tables, diagrams, vector graphics, music sheets, electrical circuits, and chemical structures. The researchers used 11 different rendering tools, from Python’s Matplotlib for charts to LaTeX for mathematical expressions, supported by 20 specialized generation pipelines.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-this-breakthrough-could-level-the-playing-field-between-open-source-and-big-tech"&gt;Why this breakthrough could level the playing field between open source and Big Tech&lt;/h2&gt;



&lt;p&gt;The implications for the broader AI industry are significant. Major technology companies like OpenAI and Google have invested billions in developing their proprietary vision-language capabilities, creating systems whose training methods and data sources remain trade secrets. CoSyn offers a path for open-source alternatives to compete without requiring similar resource investments.&lt;/p&gt;



&lt;p&gt;“Open source models still like, like behind those closed source models, but with all the efforts, all the resources from the open source community, everyone, like, we’ve had more efforts. We have more like energy, like from, from everyone. So I think finally we can catch up,” Yang said.&lt;/p&gt;



&lt;p&gt;The commitment to openness extends beyond just releasing the model. The complete CoSyn codebase, the 400,000-image dataset, and all training scripts are publicly available, enabling researchers and companies worldwide to build upon the work. “From the academia side, like a lot of research is built upon openness, like we need all access to the data, code, everything to discover new findings to support our claims in the papers,” Yang emphasized.&lt;/p&gt;



&lt;p&gt;This transparency addresses growing concerns about the black-box nature of proprietary AI systems. “If you only rely on the APIs for like open AI, this may not be reliable to prove your like scientific discoveries, because they may just. Something in the back end you never know,” Yang noted.&lt;/p&gt;







&lt;p&gt;Beyond static image understanding, CoSyn is pioneering capabilities crucial for the next generation of AI agents—systems that can autonomously navigate digital interfaces and perform complex tasks. The researchers developed synthetic “pointing data” that teaches models exactly where to click on screenshots, a fundamental requirement for web-based automation.&lt;/p&gt;



&lt;p&gt;Using 65,000 synthetic screenshots with click annotations, their model achieved state-of-the-art performance on ScreenSpot, a benchmark for click prediction, outperforming systems trained on 1.3 million real screenshots. “We only use like several 100k synthetic screenshot, we can outperform previous model on millions of screenshots,” Yang said.&lt;/p&gt;



&lt;p&gt;This capability is essential as the industry moves toward AI agents that can perform knowledge work autonomously. “There’s sort of like two prevailing models and how you might go about implementing agents,” Callison-Burch explained. One approach uses specialized APIs, while the other relies on agents that “literally just use web browsing capabilities in the same way that you and I do.”&lt;/p&gt;



&lt;p&gt;The vision-based approach, enabled by technologies like CoSyn, could prove more versatile: “You’re not just calling up software function, which is relatively straightforward, but you actually have to, like, take screenshots of the current state of the web browser. Reason about where to click, navigate your mouse to that location to click.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-synthetic-data-sidesteps-the-growing-copyright-crisis-in-ai-training"&gt;How synthetic data sidesteps the growing copyright crisis in AI training&lt;/h2&gt;



&lt;p&gt;The synthetic data approach also provides a potential solution to mounting legal challenges around AI training data. With ongoing litigation over whether training on copyrighted materials constitutes fair use, synthetic data generation offers an alternative path that sidesteps many intellectual property concerns.&lt;/p&gt;



&lt;p&gt;Callison-Burch, who testified before Congress on AI and copyright in 2023, sees synthetic data as complementary to, rather than replacing, real-world training data: “I don’t think that synthetic data eliminates the need for having wide amounts of diverse training data like that’s still a core element to training AI systems, but it does allow you to extend their capabilities in really remarkable ways.”&lt;/p&gt;



&lt;p&gt;The approach demonstrates how existing knowledge can be transferred to new applications without directly using copyrighted materials. “The underlying thing that we’re relying on here is a large language model. Can write code that’s something that it learned from its original data. We’re now applying that to a totally different application, which is creation of new training data that is unlike any of the data that it was trained on.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-current-limits-of-synthetic-data-and-what-comes-next"&gt;The current limits of synthetic data and what comes next&lt;/h2&gt;



&lt;p&gt;Despite its promise, synthetic data generation faces important limitations. “One limitation is it may inherit the biases from the model that generates such synthetic data,” Yang acknowledged. The system can also struggle with diversity: “If you prompt a large network to generate some data among different runs, it may generate similar data.”&lt;/p&gt;



&lt;p&gt;The current research focuses on text-rich images rather than natural photographs, limiting its immediate applicability to some domains. “What about some real photos like some other like natural images? It is hard to generate synthetic data for those two males, or even like medical images, chest X rays,” Yang noted, though she indicated ongoing efforts to extend the approach to medical imaging.&lt;/p&gt;



&lt;p&gt;Looking ahead, Yang expects synthetic data generation to become standard practice: “In the future, in two or three years, and even for nothing, editor has been a very important component to teach model different capabilities.” However, she emphasized that optimal results will likely require combining synthetic and real-world data: “Real world data will reflect some real world distributions. Single data can be large scale. Can be more controllable.”&lt;/p&gt;







&lt;p&gt;Early adoption signals suggest the technology is already influencing industry practices. “I heard like companies, like meta, some teams also, like all Amazon, they are trying to using our data to train their model,” Yang revealed during the interview.&lt;/p&gt;



&lt;p&gt;For startups and smaller companies, the cost advantages could be particularly significant. “For some startups, it is cheaper to host, their host open model on their server, rather than just calling the APIs, which is less controllable,” Yang noted.&lt;/p&gt;



&lt;p&gt;The research team’s decision to make everything open source reflects a broader philosophy about AI development. As Yang prepares to join the Allen Institute full-time after completing her Ph.D., the commitment to open science remains central to their mission. “Currently, those vision language models are quite brittle. It just needs the right data to get the right capabilities,” she said. “If you find the right data, you can improve models capability on it, and it will benefit the society.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-vision-for-ai-that-acts-not-just-describes"&gt;The vision for AI that acts, not just describes&lt;/h2&gt;



&lt;p&gt;As the research moves from academic laboratories to real-world applications, the implications extend far beyond improved benchmark scores. Yang and her colleagues are already looking toward applications that could transform how people with disabilities interact with technology, from AI that understands sign language for the hearing impaired to systems that can describe complex medical images for those with visual impairments.&lt;/p&gt;



&lt;p&gt;“I have an idea to let the model to know how to understand the sign language or those people with hearing difficulties,” Yang said, describing potential future applications. “If you find the right data, you can improve models capability on it, and it will benefit the society.”&lt;/p&gt;



&lt;p&gt;Callison-Burch sees even broader possibilities, particularly in robotics and scientific discovery: “Synthetic data opens up many possible applications that we don’t have naturally occurring data for. So one that Yang has also worked on at the Allen Institute is that. Ocean of creating simulated training data for robots.”&lt;/p&gt;



&lt;p&gt;The work represents more than just a technical achievement—it’s a demonstration that open-source AI development can compete with the well-funded efforts of major technology companies through innovative approaches to fundamental challenges. As Yang noted in reflecting on her decision to join the Allen Institute rather than accept higher-paying offers from companies like Meta: “I think it’s still a very early stage of those multimodal models, and there are not much resources, open resources, or knowledge to share to the community.”&lt;/p&gt;



&lt;p&gt;The message is clear: in the race to build AI that can truly see and understand the world, the advantage may not always go to those with the deepest pockets, but to those with the most creative solutions.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;p&gt;Researchers at the University of Pennsylvania and the Allen Institute for Artificial Intelligence have developed a groundbreaking tool that allows open-source AI systems to match or surpass the visual understanding capabilities of proprietary models like GPT-4V and Gemini 1.5 Flash, potentially reshaping the competitive landscape between open and closed AI development.&lt;/p&gt;



&lt;p&gt;The tool, called CoSyn (Code-Guided Synthesis), addresses a critical bottleneck in AI development: the scarcity of high-quality training data for teaching machines to understand complex visual information like scientific charts, medical diagrams, and financial documents. Rather than scraping millions of images from the internet — a practice fraught with copyright and ethical concerns — CoSyn leverages the coding abilities of existing language models to generate synthetic training data.&lt;/p&gt;



&lt;p&gt;“We have, we lack of such data to train the model. We lack of data, like documents, charts with rich annotations to train a vision language model to do question answering over those images,” explained Yue Yang, a recent Penn Engineering Ph.D. graduate and co-first author of the research, during an exclusive interview with VentureBeat. “Those images actually are more challenging to annotate, compared to natural photos, like a picture of a dog of a cat of a house.”&lt;/p&gt;



&lt;p&gt;The breakthrough comes as enterprises increasingly seek AI systems capable of understanding and reasoning about complex visual information — capabilities essential for everything from automated document processing to AI agents that can navigate digital interfaces independently. The work was conducted during Yang’s internship with the PRIOR team at the Allen Institute for AI and supported by the Office of the Director of National Intelligence, Intelligence Advanced Research Projects Activity, and the Defense Advanced Research Projects Agency.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-synthetic-data-generation-solves-ai-s-biggest-training-challenge"&gt;How synthetic data generation solves AI’s biggest training challenge&lt;/h2&gt;



&lt;p&gt;The challenge of training AI to understand text-rich images has long plagued the field. Unlike natural photographs, scientific figures, charts, and documents require extensive annotation work that is both time-consuming and expensive. Traditional approaches have relied on harvesting images and their alt-text descriptions from the internet, but this method produces training data that is often superficial and legally problematic.&lt;/p&gt;



&lt;p&gt;CoSyn takes a fundamentally different approach by recognizing that most text-rich images are originally created through code — Python scripts generate charts, LaTeX renders mathematical equations, HTML creates web interfaces. The research team’s insight was to reverse this process: use language models’ proven coding abilities to generate the underlying code, then execute that code to create realistic synthetic images.&lt;/p&gt;



&lt;p&gt;“One intuition is actually those images like charts documents. We render them from programs from code, like we use Python to generate charts. We use, like latex or word to write our documents,” Yang said. “So how about we go through the reverse way, like we generated the code because the text only language model has been proved very good at writing code.”&lt;/p&gt;



&lt;p&gt;Chris Callison-Burch, a computer science professor at Penn who co-advised the research, described the approach in simpler terms: “This is like taking a student who’s great at writing and asking them to teach someone how to draw, just by describing what the drawing should look like. We’re essentially transferring the strengths of open-source AI from text to vision.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-cosyn-trained-models-outperform-gpt-4v-and-gemini-on-key-benchmarks"&gt;CoSyn-trained models outperform GPT-4V and Gemini on key benchmarks&lt;/h2&gt;



&lt;p&gt;The results are striking. Using their synthetic dataset of 400,000 images and 2.7 million instruction pairs, models trained with CoSyn achieved state-of-the-art performance among open-source systems and surpassed proprietary models on seven benchmark tests measuring text-rich image understanding.&lt;/p&gt;



&lt;p&gt;On average, their 7-billion parameter model scored 80.9% across the benchmark suite, outperforming the previous best open-source model (Llama 3.2 11B) by 3.9 percentage points. More remarkably, even their “zero-shot” model—trained without any examples from the evaluation datasets—outperformed most open and closed models, demonstrating the transferability of capabilities learned from synthetic data.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3014678" height="314" src="https://venturebeat.com/wp-content/uploads/2025/07/main_results.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;CoSyn-trained models outperformed GPT-4V and Gemini 1.5 Flash across seven text-rich image understanding benchmarks. (Credit: github.io/cosyn)&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;In one particularly compelling demonstration, the researchers created a new benchmark called NutritionQA, consisting of 100 questions about nutrition label photographs. Using just 7,000 synthetically generated nutrition labels for training, their model outperformed others trained on millions of real images. “Despite being trained on millions of images, we observe that open-source VLMs are not data-efficient and perform poorly on this novel task compared to GPT-4V,” the researchers wrote in their paper.&lt;/p&gt;



&lt;p&gt;Yang emphasized the significance: “Those big packs, they have so many resources to collecting data to run a lot of experiments, and I but I think open source models, we can give access to people, the model weights, the data we trained, or even the code, the training script, everything people can developers can build upon.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-real-companies-are-already-using-vision-ai-for-quality-control-and-automation"&gt;Real companies are already using vision AI for quality control and automation&lt;/h2&gt;



&lt;p&gt;The technology is already finding real-world applications across industries. Callison-Burch cited an example from one of his teaching assistants whose company uses vision-language models for cable installation quality assurance: “They have the workers on site who are doing the installation take photographs of the processes they’re doing it, and they use that to automatically validate that each step has been followed properly.”&lt;/p&gt;



&lt;p&gt;This type of specialized visual understanding could transform numerous enterprise workflows, from automated document processing in financial services to quality control in manufacturing. The ability to train models on specific visual tasks using synthetic data means companies can develop AI systems tailored to their particular needs without the massive data collection efforts traditionally required.&lt;/p&gt;



&lt;p&gt;For enterprise decision makers, the research suggests a shift in how to approach AI data strategies. “I think synthetic data is a very promising way to remove the effort for human annotation. It costs less money, and it will just automatically generate large scale data, and also can avoid some copyright issues,” Yang noted.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-persona-driven-approach-that-makes-ai-training-data-more-diverse"&gt;The persona-driven approach that makes AI training data more diverse&lt;/h2&gt;



&lt;p&gt;One of CoSyn’s key innovations is its approach to ensuring data diversity. To prevent the repetitive outputs common in AI-generated content, the system employs what the researchers call a “persona-driven mechanism.” Each time CoSyn generates a synthetic example, it pairs the request with a randomly sampled persona—a short description like “a sci-fi novelist constantly bouncing off ideas for new alien worlds” or “a chemistry teacher preparing lab materials.”&lt;/p&gt;



&lt;p&gt;“Every time we generate one syntax data, we will appear with a randomly sampled persona,” Yang explained. “This will diversify the content and styles of the examples we generated, because, like, if I provide the persona of like a PhD student, it will generate something more scientific or more about, something about academia.”&lt;/p&gt;



&lt;p&gt;This approach enables the system to generate content across nine different categories: charts, documents, math problems, tables, diagrams, vector graphics, music sheets, electrical circuits, and chemical structures. The researchers used 11 different rendering tools, from Python’s Matplotlib for charts to LaTeX for mathematical expressions, supported by 20 specialized generation pipelines.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-this-breakthrough-could-level-the-playing-field-between-open-source-and-big-tech"&gt;Why this breakthrough could level the playing field between open source and Big Tech&lt;/h2&gt;



&lt;p&gt;The implications for the broader AI industry are significant. Major technology companies like OpenAI and Google have invested billions in developing their proprietary vision-language capabilities, creating systems whose training methods and data sources remain trade secrets. CoSyn offers a path for open-source alternatives to compete without requiring similar resource investments.&lt;/p&gt;



&lt;p&gt;“Open source models still like, like behind those closed source models, but with all the efforts, all the resources from the open source community, everyone, like, we’ve had more efforts. We have more like energy, like from, from everyone. So I think finally we can catch up,” Yang said.&lt;/p&gt;



&lt;p&gt;The commitment to openness extends beyond just releasing the model. The complete CoSyn codebase, the 400,000-image dataset, and all training scripts are publicly available, enabling researchers and companies worldwide to build upon the work. “From the academia side, like a lot of research is built upon openness, like we need all access to the data, code, everything to discover new findings to support our claims in the papers,” Yang emphasized.&lt;/p&gt;



&lt;p&gt;This transparency addresses growing concerns about the black-box nature of proprietary AI systems. “If you only rely on the APIs for like open AI, this may not be reliable to prove your like scientific discoveries, because they may just. Something in the back end you never know,” Yang noted.&lt;/p&gt;







&lt;p&gt;Beyond static image understanding, CoSyn is pioneering capabilities crucial for the next generation of AI agents—systems that can autonomously navigate digital interfaces and perform complex tasks. The researchers developed synthetic “pointing data” that teaches models exactly where to click on screenshots, a fundamental requirement for web-based automation.&lt;/p&gt;



&lt;p&gt;Using 65,000 synthetic screenshots with click annotations, their model achieved state-of-the-art performance on ScreenSpot, a benchmark for click prediction, outperforming systems trained on 1.3 million real screenshots. “We only use like several 100k synthetic screenshot, we can outperform previous model on millions of screenshots,” Yang said.&lt;/p&gt;



&lt;p&gt;This capability is essential as the industry moves toward AI agents that can perform knowledge work autonomously. “There’s sort of like two prevailing models and how you might go about implementing agents,” Callison-Burch explained. One approach uses specialized APIs, while the other relies on agents that “literally just use web browsing capabilities in the same way that you and I do.”&lt;/p&gt;



&lt;p&gt;The vision-based approach, enabled by technologies like CoSyn, could prove more versatile: “You’re not just calling up software function, which is relatively straightforward, but you actually have to, like, take screenshots of the current state of the web browser. Reason about where to click, navigate your mouse to that location to click.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-synthetic-data-sidesteps-the-growing-copyright-crisis-in-ai-training"&gt;How synthetic data sidesteps the growing copyright crisis in AI training&lt;/h2&gt;



&lt;p&gt;The synthetic data approach also provides a potential solution to mounting legal challenges around AI training data. With ongoing litigation over whether training on copyrighted materials constitutes fair use, synthetic data generation offers an alternative path that sidesteps many intellectual property concerns.&lt;/p&gt;



&lt;p&gt;Callison-Burch, who testified before Congress on AI and copyright in 2023, sees synthetic data as complementary to, rather than replacing, real-world training data: “I don’t think that synthetic data eliminates the need for having wide amounts of diverse training data like that’s still a core element to training AI systems, but it does allow you to extend their capabilities in really remarkable ways.”&lt;/p&gt;



&lt;p&gt;The approach demonstrates how existing knowledge can be transferred to new applications without directly using copyrighted materials. “The underlying thing that we’re relying on here is a large language model. Can write code that’s something that it learned from its original data. We’re now applying that to a totally different application, which is creation of new training data that is unlike any of the data that it was trained on.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-current-limits-of-synthetic-data-and-what-comes-next"&gt;The current limits of synthetic data and what comes next&lt;/h2&gt;



&lt;p&gt;Despite its promise, synthetic data generation faces important limitations. “One limitation is it may inherit the biases from the model that generates such synthetic data,” Yang acknowledged. The system can also struggle with diversity: “If you prompt a large network to generate some data among different runs, it may generate similar data.”&lt;/p&gt;



&lt;p&gt;The current research focuses on text-rich images rather than natural photographs, limiting its immediate applicability to some domains. “What about some real photos like some other like natural images? It is hard to generate synthetic data for those two males, or even like medical images, chest X rays,” Yang noted, though she indicated ongoing efforts to extend the approach to medical imaging.&lt;/p&gt;



&lt;p&gt;Looking ahead, Yang expects synthetic data generation to become standard practice: “In the future, in two or three years, and even for nothing, editor has been a very important component to teach model different capabilities.” However, she emphasized that optimal results will likely require combining synthetic and real-world data: “Real world data will reflect some real world distributions. Single data can be large scale. Can be more controllable.”&lt;/p&gt;







&lt;p&gt;Early adoption signals suggest the technology is already influencing industry practices. “I heard like companies, like meta, some teams also, like all Amazon, they are trying to using our data to train their model,” Yang revealed during the interview.&lt;/p&gt;



&lt;p&gt;For startups and smaller companies, the cost advantages could be particularly significant. “For some startups, it is cheaper to host, their host open model on their server, rather than just calling the APIs, which is less controllable,” Yang noted.&lt;/p&gt;



&lt;p&gt;The research team’s decision to make everything open source reflects a broader philosophy about AI development. As Yang prepares to join the Allen Institute full-time after completing her Ph.D., the commitment to open science remains central to their mission. “Currently, those vision language models are quite brittle. It just needs the right data to get the right capabilities,” she said. “If you find the right data, you can improve models capability on it, and it will benefit the society.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-vision-for-ai-that-acts-not-just-describes"&gt;The vision for AI that acts, not just describes&lt;/h2&gt;



&lt;p&gt;As the research moves from academic laboratories to real-world applications, the implications extend far beyond improved benchmark scores. Yang and her colleagues are already looking toward applications that could transform how people with disabilities interact with technology, from AI that understands sign language for the hearing impaired to systems that can describe complex medical images for those with visual impairments.&lt;/p&gt;



&lt;p&gt;“I have an idea to let the model to know how to understand the sign language or those people with hearing difficulties,” Yang said, describing potential future applications. “If you find the right data, you can improve models capability on it, and it will benefit the society.”&lt;/p&gt;



&lt;p&gt;Callison-Burch sees even broader possibilities, particularly in robotics and scientific discovery: “Synthetic data opens up many possible applications that we don’t have naturally occurring data for. So one that Yang has also worked on at the Allen Institute is that. Ocean of creating simulated training data for robots.”&lt;/p&gt;



&lt;p&gt;The work represents more than just a technical achievement—it’s a demonstration that open-source AI development can compete with the well-funded efforts of major technology companies through innovative approaches to fundamental challenges. As Yang noted in reflecting on her decision to join the Allen Institute rather than accept higher-paying offers from companies like Meta: “I think it’s still a very early stage of those multimodal models, and there are not much resources, open resources, or knowledge to share to the community.”&lt;/p&gt;



&lt;p&gt;The message is clear: in the race to build AI that can truly see and understand the world, the advantage may not always go to those with the deepest pockets, but to those with the most creative solutions.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/business/cosyn-the-open-source-tool-thats-making-gpt-4v-level-vision-ai-accessible-to-everyone/</guid><pubDate>Fri, 25 Jul 2025 20:05:12 +0000</pubDate></item><item><title>[NEW] AI referrals to top websites were up 357% year-over-year in June, reaching 1.13B (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/25/ai-referrals-to-top-websites-were-up-357-year-over-year-in-june-reaching-1-13b/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI referrals to websites still have a way to go to catch up to the traffic that Google Search provides, but they’re growing quickly. According to new data from market intelligence provider Similarweb, AI platforms in June generated over 1.13 billion referrals to the top 1,000 websites globally, a figure that’s up 357% since June 2024.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, Google Search still accounts for the majority of traffic to these sites, accounting for 191 billion referrals during the same period of June 2025. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;One particular category of interest these days is news and media. Online publishers are seeing traffic declines and are preparing for a day they’re calling “Google Zero,” when Google stops sending traffic to websites.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, The Wall Street Journal recently reported on data that showed how AI overviews were killing traffic to news sites. Plus, a Pew Research Center study out this week found that in a survey of 900 U.S. Google users, 18% of some 69,000 searches showed AI Overviews, which led to users clicking links 8% of the time. When there was no AI summary, users clicked links nearly twice as much, or 15% of the time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Similarweb found that June’s AI referrals to news and media websites were up 770% since June 2024. Some sites will naturally rank higher than others that are blocking access to AI platforms, as The New York Times does, as a result of its lawsuit with OpenAI over the use of its articles to train its models. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the news media category, Yahoo led with 2.3 million AI referrals in June 2025, followed by Yahoo Japan (1.9M), Reuters (1.8M), The Guardian (1.7M), India Times (1.2M), and Business Insider (1.0M). &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In terms of methodology, Similarweb counts AI referrals as web referrals to a domain from an AI platform like ChatGPT, Gemini, DeepSeek, Grok, Perplexity, Claude, and Liner. ChatGPT dominates here, accounting for more than 80% of the AI referrals to the top 1,000 domains. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s analysis also looked at other categories beyond news, like e-commerce, science and education, tech/search/social media, arts and entertainment, business, and others. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3031349" height="614" src="https://techcrunch.com/wp-content/uploads/2025/07/top-ai-referrals-june-2025.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Similarweb&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In e-commerce, Amazon was followed by Etsy and eBay when it came to those sites seeing the most referrals, at 4.5M, 2.0M, and 1.8M, respectively, during June. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Among the top tech and social sites, Google, not surprisingly, was at the top of the list, with 53.1 million referrals in June, followed by Reddit (11.1M), Facebook (11.0M), Github (7.4M), Microsoft (5.1M), Canva (5.0M), Instagram (4.7M), LinkedIn (4.4M), Bing (3.1M), and Pinterest (2.5M). &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The analysis excluded the OpenAI website because so many of its referrals were from ChatGPT, pointing to its services. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Across all other domains, the No. 1 site by AI referrals for each category included YouTube (31.2M), Research Gate (3.6M), Zillow (776.2K), Europa.eu (992.9K), Wikipedia (10.8M), NIH.gov (5.2M), Investing.com (1.2M), Home Depot (1.2M), Kayak (456.5K), and Zara (325.6K). &lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI referrals to websites still have a way to go to catch up to the traffic that Google Search provides, but they’re growing quickly. According to new data from market intelligence provider Similarweb, AI platforms in June generated over 1.13 billion referrals to the top 1,000 websites globally, a figure that’s up 357% since June 2024.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, Google Search still accounts for the majority of traffic to these sites, accounting for 191 billion referrals during the same period of June 2025. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;One particular category of interest these days is news and media. Online publishers are seeing traffic declines and are preparing for a day they’re calling “Google Zero,” when Google stops sending traffic to websites.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, The Wall Street Journal recently reported on data that showed how AI overviews were killing traffic to news sites. Plus, a Pew Research Center study out this week found that in a survey of 900 U.S. Google users, 18% of some 69,000 searches showed AI Overviews, which led to users clicking links 8% of the time. When there was no AI summary, users clicked links nearly twice as much, or 15% of the time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Similarweb found that June’s AI referrals to news and media websites were up 770% since June 2024. Some sites will naturally rank higher than others that are blocking access to AI platforms, as The New York Times does, as a result of its lawsuit with OpenAI over the use of its articles to train its models. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the news media category, Yahoo led with 2.3 million AI referrals in June 2025, followed by Yahoo Japan (1.9M), Reuters (1.8M), The Guardian (1.7M), India Times (1.2M), and Business Insider (1.0M). &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In terms of methodology, Similarweb counts AI referrals as web referrals to a domain from an AI platform like ChatGPT, Gemini, DeepSeek, Grok, Perplexity, Claude, and Liner. ChatGPT dominates here, accounting for more than 80% of the AI referrals to the top 1,000 domains. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s analysis also looked at other categories beyond news, like e-commerce, science and education, tech/search/social media, arts and entertainment, business, and others. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3031349" height="614" src="https://techcrunch.com/wp-content/uploads/2025/07/top-ai-referrals-june-2025.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Similarweb&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In e-commerce, Amazon was followed by Etsy and eBay when it came to those sites seeing the most referrals, at 4.5M, 2.0M, and 1.8M, respectively, during June. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Among the top tech and social sites, Google, not surprisingly, was at the top of the list, with 53.1 million referrals in June, followed by Reddit (11.1M), Facebook (11.0M), Github (7.4M), Microsoft (5.1M), Canva (5.0M), Instagram (4.7M), LinkedIn (4.4M), Bing (3.1M), and Pinterest (2.5M). &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The analysis excluded the OpenAI website because so many of its referrals were from ChatGPT, pointing to its services. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Across all other domains, the No. 1 site by AI referrals for each category included YouTube (31.2M), Research Gate (3.6M), Zillow (776.2K), Europa.eu (992.9K), Wikipedia (10.8M), NIH.gov (5.2M), Investing.com (1.2M), Home Depot (1.2M), Kayak (456.5K), and Zara (325.6K). &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/25/ai-referrals-to-top-websites-were-up-357-year-over-year-in-june-reaching-1-13b/</guid><pubDate>Fri, 25 Jul 2025 20:11:08 +0000</pubDate></item><item><title>[NEW] Meta names Shengjia Zhao as chief scientist of AI superintelligence unit (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/25/meta-names-shengjia-zhao-as-chief-scientist-of-ai-superintelligence-unit/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2173579488.jpg?resize=1200,799" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta CEO Mark Zuckerberg announced Friday that former OpenAI researcher Shengjia Zhao will lead research efforts at the company’s new AI unit, Meta Superintelligence Labs (MSL). Zhao contributed to several of OpenAI’s largest breakthroughs, including ChatGPT, GPT-4, and the company’s first AI reasoning model, o1.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I’m excited to share that Shengjia Zhao will be the Chief Scientist of Meta Superintelligence Labs,” Zuckerberg said in a post on Threads Friday. “Shengjia co-founded the new lab and has been our lead scientist from day one. Now that our recruiting is going well and our team is coming together, we have decided to formalize his leadership role.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Zhao will set a research agenda for MSL under the leadership of Alexandr Wang, the former CEO of Scale AI who was recently hired to lead the new unit.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;We are excited to announce that @shengjia_zhao will be the Chief Scientist of Meta Superintelligence Labs!&lt;/p&gt;&lt;p&gt;Shengjia is a brilliant scientist who most recently pioneered a new scaling paradigm in his research. He will lead our scientific direction for our team.&lt;/p&gt;&lt;p&gt;Let's go 🚀 pic.twitter.com/D93KQWIvFl&lt;/p&gt;— Alexandr Wang (@alexandr_wang) July 25, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Wang, who does not have a research background, was viewed as a somewhat unconventional choice to lead an AI lab. The addition of Zhao, who is a reputable research leader known for developing frontier AI models, rounds out the leadership team. To further fill out the unit, Meta has hired several high-level researchers from OpenAI, Google DeepMind, Safe Superintelligence, Apple, and Anthropic, as well as pulling researchers from Meta’s existing Fundamental AI Research (FAIR) lab and generative AI unit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zuckerberg notes in his post that Zhao has pioneered several breakthroughs, including a “new scaling paradigm.” The Meta CEO is likely referencing Zhao’s work on OpenAI’s reasoning model, o1, in which he is listed as a foundational contributor alongside OpenAI co-founder Ilya Sutskever. Meta currently doesn’t offer a competitor to o1, so AI reasoning models are a key area of focus for MSL.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Information reported in June that Zhao would be joining Meta Superintelligence Labs, alongside three other influential OpenAI researchers — Jiahui Yu, Shuchao Bi, and Hongyu Ren. Meta has also recruited&amp;nbsp;Trapit Bansal, another OpenAI researcher who worked on AI reasoning models with Zhao, as well as three employees from OpenAI’s Zurich office who worked on multimodality.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zuckerberg has gone to great lengths to set MSL up for success. The Meta CEO has been on a recruiting spree to staff up his AI superintelligence lab, which has entailed sending personal emails to researchers and inviting prospects to his Lake Tahoe estate. Meta has reportedly offered some researchers eight- and nine-figure compensation packages, some of which are “exploding offers” that expire in a matter of days.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Meta has also upped its investment in cloud computing infrastructure, which should help MSL conduct the massive training runs required to create competitive frontier AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;By 2026, Zhao and MSL’s researchers should have access to Meta’s 1 gigawatt cloud computing cluster, Prometheus, located in Ohio. Once online, Meta will be one of the first technology companies with an AI training cluster of Prometheus’ size — 1 gigawatt is enough energy to power more than 750,000 homes. That should help Meta conduct the massive training runs required to create frontier AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the addition of Zhao, Meta now has two chief AI scientists, including Yann LeCun, the leader of Meta’s FAIR lab. Unlike MSL, FAIR is designed to focus on long-term AI research — techniques that may be used five to 10 years from now. How exactly Meta’s three AI units will work together remains to be seen.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Nevertheless, Meta now seems to have a formidable AI leadership team to compete with OpenAI and Google.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2173579488.jpg?resize=1200,799" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta CEO Mark Zuckerberg announced Friday that former OpenAI researcher Shengjia Zhao will lead research efforts at the company’s new AI unit, Meta Superintelligence Labs (MSL). Zhao contributed to several of OpenAI’s largest breakthroughs, including ChatGPT, GPT-4, and the company’s first AI reasoning model, o1.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I’m excited to share that Shengjia Zhao will be the Chief Scientist of Meta Superintelligence Labs,” Zuckerberg said in a post on Threads Friday. “Shengjia co-founded the new lab and has been our lead scientist from day one. Now that our recruiting is going well and our team is coming together, we have decided to formalize his leadership role.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Zhao will set a research agenda for MSL under the leadership of Alexandr Wang, the former CEO of Scale AI who was recently hired to lead the new unit.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;We are excited to announce that @shengjia_zhao will be the Chief Scientist of Meta Superintelligence Labs!&lt;/p&gt;&lt;p&gt;Shengjia is a brilliant scientist who most recently pioneered a new scaling paradigm in his research. He will lead our scientific direction for our team.&lt;/p&gt;&lt;p&gt;Let's go 🚀 pic.twitter.com/D93KQWIvFl&lt;/p&gt;— Alexandr Wang (@alexandr_wang) July 25, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Wang, who does not have a research background, was viewed as a somewhat unconventional choice to lead an AI lab. The addition of Zhao, who is a reputable research leader known for developing frontier AI models, rounds out the leadership team. To further fill out the unit, Meta has hired several high-level researchers from OpenAI, Google DeepMind, Safe Superintelligence, Apple, and Anthropic, as well as pulling researchers from Meta’s existing Fundamental AI Research (FAIR) lab and generative AI unit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zuckerberg notes in his post that Zhao has pioneered several breakthroughs, including a “new scaling paradigm.” The Meta CEO is likely referencing Zhao’s work on OpenAI’s reasoning model, o1, in which he is listed as a foundational contributor alongside OpenAI co-founder Ilya Sutskever. Meta currently doesn’t offer a competitor to o1, so AI reasoning models are a key area of focus for MSL.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Information reported in June that Zhao would be joining Meta Superintelligence Labs, alongside three other influential OpenAI researchers — Jiahui Yu, Shuchao Bi, and Hongyu Ren. Meta has also recruited&amp;nbsp;Trapit Bansal, another OpenAI researcher who worked on AI reasoning models with Zhao, as well as three employees from OpenAI’s Zurich office who worked on multimodality.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zuckerberg has gone to great lengths to set MSL up for success. The Meta CEO has been on a recruiting spree to staff up his AI superintelligence lab, which has entailed sending personal emails to researchers and inviting prospects to his Lake Tahoe estate. Meta has reportedly offered some researchers eight- and nine-figure compensation packages, some of which are “exploding offers” that expire in a matter of days.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Meta has also upped its investment in cloud computing infrastructure, which should help MSL conduct the massive training runs required to create competitive frontier AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;By 2026, Zhao and MSL’s researchers should have access to Meta’s 1 gigawatt cloud computing cluster, Prometheus, located in Ohio. Once online, Meta will be one of the first technology companies with an AI training cluster of Prometheus’ size — 1 gigawatt is enough energy to power more than 750,000 homes. That should help Meta conduct the massive training runs required to create frontier AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the addition of Zhao, Meta now has two chief AI scientists, including Yann LeCun, the leader of Meta’s FAIR lab. Unlike MSL, FAIR is designed to focus on long-term AI research — techniques that may be used five to 10 years from now. How exactly Meta’s three AI units will work together remains to be seen.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Nevertheless, Meta now seems to have a formidable AI leadership team to compete with OpenAI and Google.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/25/meta-names-shengjia-zhao-as-chief-scientist-of-ai-superintelligence-unit/</guid><pubDate>Fri, 25 Jul 2025 20:58:37 +0000</pubDate></item><item><title>[NEW] New AI architecture delivers 100x faster reasoning than LLMs with just 1,000 training examples (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/new-ai-architecture-delivers-100x-faster-reasoning-than-llms-with-just-1000-training-examples/</link><description>&lt;p&gt;Singapore-based AI startup Sapient Intelligence has developed a new AI architecture that can match, and in some cases vastly outperform, large language models (LLMs) on complex reasoning tasks, all while being significantly smaller and more data-efficient.&lt;/p&gt;&lt;p&gt;The architecture, &lt;span&gt;known as the&amp;nbsp;Hierarchical Reasoning Model&amp;nbsp;(HRM), is inspired by how the human brain utilizes distinct&lt;/span&gt; systems for slow, deliberate planning and fast, intuitive computation. The model achieves impressive results with a fraction of the data and memory required by today’s LLMs. This efficiency could have important implications for real-world enterprise AI applications where data is scarce and computational resources are limited.&lt;/p&gt;&lt;p&gt;When faced with a complex problem, current LLMs largely rely on chain-of-thought (CoT) prompting, breaking down problems into intermediate text-based steps, essentially forcing the model to “think out loud” as it works toward a solution.&lt;/p&gt;&lt;p&gt;While CoT has improved the reasoning abilities of LLMs, it has fundamental limitations. In their paper, researchers at Sapient Intelligence argue that “CoT for reasoning is a crutch, not a satisfactory solution. It relies on brittle, human-defined decompositions where a single misstep or a misorder of the steps can derail the reasoning process entirely.”&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;This dependency on generating explicit language tethers the model’s reasoning to the token level, often requiring massive amounts of training data and producing long, slow responses. This approach also overlooks the type of “latent reasoning” that occurs internally, without being explicitly articulated in language.&lt;/p&gt;



&lt;p&gt;As the researchers note, “A more efficient approach is needed to minimize these data requirements.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-hierarchical-approach-inspired-by-the-brain"&gt;A hierarchical approach inspired by the brain&lt;/h2&gt;



&lt;p&gt;To move beyond CoT, the researchers explored “latent reasoning,” where instead of generating “thinking tokens,” the model reasons in its internal, abstract representation of the problem. This is more aligned with how humans think; as the paper states, “the brain sustains lengthy, coherent chains of reasoning with remarkable efficiency in a latent space, without constant translation back to language.”&lt;/p&gt;



&lt;p&gt;However, achieving this level of deep, internal reasoning in AI is challenging. Simply stacking more layers in a deep learning model often leads to a “vanishing gradient” problem, where learning signals weaken across layers, making training ineffective. An alternative, recurrent architectures that loop over computations can suffer from “early convergence,” where the model settles on a solution too quickly without fully exploring the problem.&lt;/p&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="hierarchical reasoning model" class="wp-image-3014691" height="508" src="https://venturebeat.com/wp-content/uploads/2025/07/image_9378b6.png" width="778" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;The Hierarchical Reasoning Model (HRM) is inspired by the structure of the brain Source: arXiv&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Seeking a better approach, the Sapient team turned to neuroscience for a solution. “The human brain provides a compelling blueprint for achieving the effective computational depth that contemporary artificial models lack,” the researchers write. “It organizes computation hierarchically across cortical regions operating at different timescales, enabling deep, multi-stage reasoning.”&lt;/p&gt;



&lt;p&gt;Inspired by this, they designed HRM with two coupled, recurrent modules: a high-level (H) module for slow, abstract planning, and a low-level (L) module for fast, detailed computations. This structure enables a process the team calls “hierarchical convergence.” Intuitively, the fast L-module addresses a portion of the problem, executing multiple steps until it reaches a stable, local solution. At that point, the slow H-module takes this result, updates its overall strategy, and gives the L-module a new, refined sub-problem to work on. This effectively resets the L-module, preventing it from getting stuck (early convergence) and allowing the entire system to perform a long sequence of reasoning steps with a lean model architecture that doesn’t suffer from vanishing gradients.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3014692" height="202" src="https://venturebeat.com/wp-content/uploads/2025/07/image_c096bf.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;HRM (left) smoothly converges on the solution across computation cycles and avoids early convergence (center, RNNs) and vanishing gradients (right, classic deep neural networks) Source: arXiv&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;According to the paper, “This process allows the HRM to perform a sequence of distinct, stable, nested computations, where the H-module directs the overall problem-solving strategy and the L-module executes the intensive search or refinement required for each step.” This nested-loop design allows the model to reason deeply in its latent space without needing long CoT prompts or huge amounts of data.&lt;/p&gt;



&lt;p&gt;A natural question is whether this “latent reasoning” comes at the cost of interpretability. Guan Wang, Founder and CEO of Sapient Intelligence, pushes back on this idea, explaining that the model’s internal processes can be decoded and visualized, similar to how CoT provides a window into a model’s thinking. He also points out that CoT itself can be misleading. “CoT does not genuinely reflect a model’s internal reasoning,” Wang told VentureBeat, referencing studies showing that models can sometimes yield correct answers with incorrect reasoning steps, and vice versa. “It remains essentially a black box.”&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3014693" height="130" src="https://venturebeat.com/wp-content/uploads/2025/07/image_fa955c.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Example of how HRM reasons over a maze problem across different compute cycles Source: arXiv&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-hrm-in-action"&gt;HRM in action&lt;/h2&gt;



&lt;p&gt;To test their model, the researchers pitted HRM against benchmarks that require extensive search and backtracking, such as the Abstraction and Reasoning Corpus (ARC-AGI), extremely difficult Sudoku puzzles and complex maze-solving tasks.&lt;/p&gt;



&lt;p&gt;The results show that HRM learns to solve problems that are intractable for even advanced LLMs. For instance, on the “Sudoku-Extreme” and “Maze-Hard” benchmarks, state-of-the-art CoT models failed completely, scoring 0% accuracy. In contrast, HRM achieved near-perfect accuracy after being trained on just 1,000 examples for each task.&lt;/p&gt;



&lt;p&gt;On the ARC-AGI benchmark, a test of abstract reasoning and generalization, the 27M-parameter HRM scored 40.3%. This surpasses leading CoT-based models like the much larger o3-mini-high (34.5%) and Claude 3.7 Sonnet (21.2%). This performance, achieved without a large pre-training corpus and with very limited data, highlights the power and efficiency of its architecture.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3014694" height="310" src="https://venturebeat.com/wp-content/uploads/2025/07/image_95e232.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;HRM outperforms large models on complex reasoning tasks Source: arXiv&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;While solving puzzles demonstrates the model’s power, the real-world implications lie in a different class of problems. According to Wang, developers should continue using LLMs for language-based or creative tasks, but for “complex or deterministic tasks,” an HRM-like architecture offers superior performance with fewer hallucinations. He points to “sequential problems requiring complex decision-making or long-term planning,” especially in latency-sensitive fields like embodied AI and robotics, or data-scarce domains like scientific exploration.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In these scenarios, HRM doesn’t just solve problems; it learns to solve them better. “In our Sudoku experiments at the master level… HRM needs progressively fewer steps as training advances—akin to a novice becoming an expert,” Wang explained.&lt;/p&gt;



&lt;p&gt;For the enterprise, this is where the architecture’s efficiency translates directly to the bottom line. Instead of the serial, token-by-token generation of CoT, HRM’s parallel processing allows for what Wang estimates could be a “100x speedup in task completion time.” This means lower inference latency and the ability to run powerful reasoning on edge devices.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The cost savings are also substantial. “Specialized reasoning engines such as HRM offer a more promising alternative for specific complex reasoning tasks compared to large, costly, and latency-intensive API-based models,” Wang said. To put the efficiency into perspective, he noted that training the model for professional-level Sudoku takes roughly two GPU hours, and for the complex ARC-AGI benchmark, between 50 and 200 GPU hours—a fraction of the resources needed for massive foundation models. This opens a path to solving specialized business problems, from logistics optimization to complex system diagnostics, where both data and budget are finite.&lt;/p&gt;



&lt;p&gt;Looking ahead, Sapient Intelligence is already working to evolve HRM from a specialized problem-solver into a more general-purpose reasoning module. “We are actively developing brain-inspired models built upon HRM,” Wang said, highlighting promising initial results in healthcare, climate forecasting, and robotics. He teased that these next-generation models will differ significantly from today’s text-based systems, notably through the inclusion of self-correcting capabilities.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The work suggests that for a class of problems that have stumped today’s AI giants, the path forward may not be bigger models, but smarter, more structured architectures inspired by the ultimate reasoning engine: the human brain.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;p&gt;Singapore-based AI startup Sapient Intelligence has developed a new AI architecture that can match, and in some cases vastly outperform, large language models (LLMs) on complex reasoning tasks, all while being significantly smaller and more data-efficient.&lt;/p&gt;&lt;p&gt;The architecture, &lt;span&gt;known as the&amp;nbsp;Hierarchical Reasoning Model&amp;nbsp;(HRM), is inspired by how the human brain utilizes distinct&lt;/span&gt; systems for slow, deliberate planning and fast, intuitive computation. The model achieves impressive results with a fraction of the data and memory required by today’s LLMs. This efficiency could have important implications for real-world enterprise AI applications where data is scarce and computational resources are limited.&lt;/p&gt;&lt;p&gt;When faced with a complex problem, current LLMs largely rely on chain-of-thought (CoT) prompting, breaking down problems into intermediate text-based steps, essentially forcing the model to “think out loud” as it works toward a solution.&lt;/p&gt;&lt;p&gt;While CoT has improved the reasoning abilities of LLMs, it has fundamental limitations. In their paper, researchers at Sapient Intelligence argue that “CoT for reasoning is a crutch, not a satisfactory solution. It relies on brittle, human-defined decompositions where a single misstep or a misorder of the steps can derail the reasoning process entirely.”&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;This dependency on generating explicit language tethers the model’s reasoning to the token level, often requiring massive amounts of training data and producing long, slow responses. This approach also overlooks the type of “latent reasoning” that occurs internally, without being explicitly articulated in language.&lt;/p&gt;



&lt;p&gt;As the researchers note, “A more efficient approach is needed to minimize these data requirements.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-hierarchical-approach-inspired-by-the-brain"&gt;A hierarchical approach inspired by the brain&lt;/h2&gt;



&lt;p&gt;To move beyond CoT, the researchers explored “latent reasoning,” where instead of generating “thinking tokens,” the model reasons in its internal, abstract representation of the problem. This is more aligned with how humans think; as the paper states, “the brain sustains lengthy, coherent chains of reasoning with remarkable efficiency in a latent space, without constant translation back to language.”&lt;/p&gt;



&lt;p&gt;However, achieving this level of deep, internal reasoning in AI is challenging. Simply stacking more layers in a deep learning model often leads to a “vanishing gradient” problem, where learning signals weaken across layers, making training ineffective. An alternative, recurrent architectures that loop over computations can suffer from “early convergence,” where the model settles on a solution too quickly without fully exploring the problem.&lt;/p&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="hierarchical reasoning model" class="wp-image-3014691" height="508" src="https://venturebeat.com/wp-content/uploads/2025/07/image_9378b6.png" width="778" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;The Hierarchical Reasoning Model (HRM) is inspired by the structure of the brain Source: arXiv&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Seeking a better approach, the Sapient team turned to neuroscience for a solution. “The human brain provides a compelling blueprint for achieving the effective computational depth that contemporary artificial models lack,” the researchers write. “It organizes computation hierarchically across cortical regions operating at different timescales, enabling deep, multi-stage reasoning.”&lt;/p&gt;



&lt;p&gt;Inspired by this, they designed HRM with two coupled, recurrent modules: a high-level (H) module for slow, abstract planning, and a low-level (L) module for fast, detailed computations. This structure enables a process the team calls “hierarchical convergence.” Intuitively, the fast L-module addresses a portion of the problem, executing multiple steps until it reaches a stable, local solution. At that point, the slow H-module takes this result, updates its overall strategy, and gives the L-module a new, refined sub-problem to work on. This effectively resets the L-module, preventing it from getting stuck (early convergence) and allowing the entire system to perform a long sequence of reasoning steps with a lean model architecture that doesn’t suffer from vanishing gradients.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3014692" height="202" src="https://venturebeat.com/wp-content/uploads/2025/07/image_c096bf.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;HRM (left) smoothly converges on the solution across computation cycles and avoids early convergence (center, RNNs) and vanishing gradients (right, classic deep neural networks) Source: arXiv&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;According to the paper, “This process allows the HRM to perform a sequence of distinct, stable, nested computations, where the H-module directs the overall problem-solving strategy and the L-module executes the intensive search or refinement required for each step.” This nested-loop design allows the model to reason deeply in its latent space without needing long CoT prompts or huge amounts of data.&lt;/p&gt;



&lt;p&gt;A natural question is whether this “latent reasoning” comes at the cost of interpretability. Guan Wang, Founder and CEO of Sapient Intelligence, pushes back on this idea, explaining that the model’s internal processes can be decoded and visualized, similar to how CoT provides a window into a model’s thinking. He also points out that CoT itself can be misleading. “CoT does not genuinely reflect a model’s internal reasoning,” Wang told VentureBeat, referencing studies showing that models can sometimes yield correct answers with incorrect reasoning steps, and vice versa. “It remains essentially a black box.”&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3014693" height="130" src="https://venturebeat.com/wp-content/uploads/2025/07/image_fa955c.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Example of how HRM reasons over a maze problem across different compute cycles Source: arXiv&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-hrm-in-action"&gt;HRM in action&lt;/h2&gt;



&lt;p&gt;To test their model, the researchers pitted HRM against benchmarks that require extensive search and backtracking, such as the Abstraction and Reasoning Corpus (ARC-AGI), extremely difficult Sudoku puzzles and complex maze-solving tasks.&lt;/p&gt;



&lt;p&gt;The results show that HRM learns to solve problems that are intractable for even advanced LLMs. For instance, on the “Sudoku-Extreme” and “Maze-Hard” benchmarks, state-of-the-art CoT models failed completely, scoring 0% accuracy. In contrast, HRM achieved near-perfect accuracy after being trained on just 1,000 examples for each task.&lt;/p&gt;



&lt;p&gt;On the ARC-AGI benchmark, a test of abstract reasoning and generalization, the 27M-parameter HRM scored 40.3%. This surpasses leading CoT-based models like the much larger o3-mini-high (34.5%) and Claude 3.7 Sonnet (21.2%). This performance, achieved without a large pre-training corpus and with very limited data, highlights the power and efficiency of its architecture.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3014694" height="310" src="https://venturebeat.com/wp-content/uploads/2025/07/image_95e232.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;HRM outperforms large models on complex reasoning tasks Source: arXiv&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;While solving puzzles demonstrates the model’s power, the real-world implications lie in a different class of problems. According to Wang, developers should continue using LLMs for language-based or creative tasks, but for “complex or deterministic tasks,” an HRM-like architecture offers superior performance with fewer hallucinations. He points to “sequential problems requiring complex decision-making or long-term planning,” especially in latency-sensitive fields like embodied AI and robotics, or data-scarce domains like scientific exploration.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In these scenarios, HRM doesn’t just solve problems; it learns to solve them better. “In our Sudoku experiments at the master level… HRM needs progressively fewer steps as training advances—akin to a novice becoming an expert,” Wang explained.&lt;/p&gt;



&lt;p&gt;For the enterprise, this is where the architecture’s efficiency translates directly to the bottom line. Instead of the serial, token-by-token generation of CoT, HRM’s parallel processing allows for what Wang estimates could be a “100x speedup in task completion time.” This means lower inference latency and the ability to run powerful reasoning on edge devices.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The cost savings are also substantial. “Specialized reasoning engines such as HRM offer a more promising alternative for specific complex reasoning tasks compared to large, costly, and latency-intensive API-based models,” Wang said. To put the efficiency into perspective, he noted that training the model for professional-level Sudoku takes roughly two GPU hours, and for the complex ARC-AGI benchmark, between 50 and 200 GPU hours—a fraction of the resources needed for massive foundation models. This opens a path to solving specialized business problems, from logistics optimization to complex system diagnostics, where both data and budget are finite.&lt;/p&gt;



&lt;p&gt;Looking ahead, Sapient Intelligence is already working to evolve HRM from a specialized problem-solver into a more general-purpose reasoning module. “We are actively developing brain-inspired models built upon HRM,” Wang said, highlighting promising initial results in healthcare, climate forecasting, and robotics. He teased that these next-generation models will differ significantly from today’s text-based systems, notably through the inclusion of self-correcting capabilities.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The work suggests that for a class of problems that have stumped today’s AI giants, the path forward may not be bigger models, but smarter, more structured architectures inspired by the ultimate reasoning engine: the human brain.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/new-ai-architecture-delivers-100x-faster-reasoning-than-llms-with-just-1000-training-examples/</guid><pubDate>Fri, 25 Jul 2025 23:27:42 +0000</pubDate></item><item><title>[NEW] Meta announces its Superintelligence Labs Chief Scientist: former OpenAI GPT-4 co-creator Shengjia Zhao (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/meta-announces-its-superintelligence-labs-chief-scientist-former-openai-gpt-4-co-creator-shengjia-zhao/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Meta has appointed &lt;strong&gt;Shengjia Zhao&lt;/strong&gt;, a former OpenAI researcher and co‑creator of GPT‑4, as the Chief Scientist of its newly created &lt;strong&gt;Meta Superintelligence Labs (MSL)&lt;/strong&gt;. &lt;/p&gt;



&lt;p&gt;The announcement was made Friday by Mark Zuckerberg on Threads, noting Zhao will lead the lab’s scientific agenda alongside him and Alexandr Wang, the former CEO of Scale AI who Meta recently brought onboard as Chief AI Officer.&lt;/p&gt;



&lt;p&gt;&lt;em&gt;“I am very excited to take up the role of chief scientist for meta super-intelligence labs. Looking forward to building asi [artificial superintelligence] and aligning it to empower people with the amazing team here. Let’s build!”&lt;/em&gt; Zhao wrote in his own Threads post.&lt;/p&gt;



&lt;p&gt;“Artificial superintelligence” is a nebulous term used in the AI industry to describe systems more powerful and capable than any today, beyond even the smartest humans, making them difficult to control. &lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;h2 class="wp-block-heading" id="h-zhao-s-strong-commercial-ai-background"&gt;Zhao’s strong commercial AI background&lt;/h2&gt;



&lt;p&gt;Zhao, who previously worked at OpenAI, played a key role in the development of foundational models like GPT-4 and GPT-4o, according to arXiv system cards and research papers listing him as a co-author. He’s also known for his academic work on generative models and fair representations, with widely cited papers in venues like NeurIPS, ICML, and ICLR.&lt;/p&gt;



&lt;p&gt;Zhao joins Meta amid a high-stakes hiring blitz across the AI industry. Over the past few months, Meta has poached researchers from OpenAI, Apple, Google, and Anthropic as part of a multibillion-dollar bet on superintelligence as CNN reported. &lt;/p&gt;



&lt;p&gt;Meta recently invested $14.3 billion in Scale AI, acquiring a 49% stake and bringing on Wang to lead the superintelligence effort. Former GitHub CEO Nat Friedman also joined the team. &lt;/p&gt;



&lt;p&gt;The company has reportedly offered compensation packages worth as much as &lt;strong&gt;$100 million to $300 million over four years&lt;/strong&gt; to lure top AI talent, according to multiple reports. One claim from a rival AI startup founder alleged Meta offered &lt;strong&gt;$1.25 billion over four years&lt;/strong&gt;—approximately &lt;strong&gt;$312 million per year&lt;/strong&gt;—to a single candidate who declined. &lt;/p&gt;



&lt;p&gt;Other insiders say Meta’s most senior AI scientists may be receiving &lt;strong&gt;$10 million+ per year&lt;/strong&gt;, while first-year comp for some new hires reportedly reached &lt;strong&gt;$100 million&lt;/strong&gt;.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-aspirations-of-leading-the-ai-frontier"&gt;Aspirations of leading the AI frontier&lt;/h2&gt;



&lt;p&gt;Zuckerberg has made no secret of his ambition to make Meta a leader in AI’s next frontier, repeatedly stating that the company plans to “invest hundreds of billions of dollars into compute to build superintelligence” using its own business-generated capital. &lt;/p&gt;



&lt;p&gt;He said the Llama 4 rollout underscored the importance of elite talent: “You can have hundreds of thousands of GPUs, but if you don’t have the right team developing the model, it doesn’t matter.”&lt;/p&gt;



&lt;p&gt;Meta’s fundamental AI research group (FAIR), still led by acclaimed scientist Yann LeCun, will remain separate from the new lab. &lt;/p&gt;



&lt;p&gt;The creation of Meta Superintelligence Labs signals a more product- and mission-focused arm of Meta’s AI efforts, centered on building and aligning ASI with human interests.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-making-up-for-the-mixed-reception-of-llama-4"&gt;Making up for the mixed reception of Llama 4&lt;/h2&gt;



&lt;p&gt;However, Meta’s push into superintelligence has come on the heels of a bumpy rollout of its latest open-source foundation models. &lt;/p&gt;



&lt;p&gt;The company released its Llama 4 model family in April 2025, positioning it as a leap forward in multimodal reasoning and long-context understanding. But the release has struggled to gain traction amid the rise of powerful Chinese open-source rivals like DeepSeek and Qwen. &lt;/p&gt;



&lt;p&gt;Meta faced public criticism from researchers and developers who cited poor real-world performance, confusion around benchmark results, and inconsistent quality across deployments. &lt;/p&gt;



&lt;p&gt;Some accused the company of “benchmark gamesmanship” and using unreleased optimized versions of Llama 4 to boost public perception—a claim Meta has denied. &lt;/p&gt;



&lt;p&gt;Internal sources blamed fast rollout timelines and bugs for the issues, but the episode has cast a shadow over Meta’s generative AI credibility just as it embarks on its most ambitious effort yet. &lt;/p&gt;



&lt;p&gt;Jim Fan, a former Stanford colleague of Zhao and now Nvidia’s Director of Robotics and Distinguished Scientist, offered his endorsement on X: “Shengjia is one of the brightest, humblest, and most passionate scientists I know. Very bullish on MSL!”&lt;/p&gt;



&lt;p&gt;The move underscores Meta’s strategy of spending aggressively now to secure a dominant position in what it views as the next foundational technology platform — one that could eclipse the mobile internet. As Zuckerberg sees it, ASI isn’t a moonshot — it’s the next frontier, and Meta intends to lead.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Meta has appointed &lt;strong&gt;Shengjia Zhao&lt;/strong&gt;, a former OpenAI researcher and co‑creator of GPT‑4, as the Chief Scientist of its newly created &lt;strong&gt;Meta Superintelligence Labs (MSL)&lt;/strong&gt;. &lt;/p&gt;



&lt;p&gt;The announcement was made Friday by Mark Zuckerberg on Threads, noting Zhao will lead the lab’s scientific agenda alongside him and Alexandr Wang, the former CEO of Scale AI who Meta recently brought onboard as Chief AI Officer.&lt;/p&gt;



&lt;p&gt;&lt;em&gt;“I am very excited to take up the role of chief scientist for meta super-intelligence labs. Looking forward to building asi [artificial superintelligence] and aligning it to empower people with the amazing team here. Let’s build!”&lt;/em&gt; Zhao wrote in his own Threads post.&lt;/p&gt;



&lt;p&gt;“Artificial superintelligence” is a nebulous term used in the AI industry to describe systems more powerful and capable than any today, beyond even the smartest humans, making them difficult to control. &lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;h2 class="wp-block-heading" id="h-zhao-s-strong-commercial-ai-background"&gt;Zhao’s strong commercial AI background&lt;/h2&gt;



&lt;p&gt;Zhao, who previously worked at OpenAI, played a key role in the development of foundational models like GPT-4 and GPT-4o, according to arXiv system cards and research papers listing him as a co-author. He’s also known for his academic work on generative models and fair representations, with widely cited papers in venues like NeurIPS, ICML, and ICLR.&lt;/p&gt;



&lt;p&gt;Zhao joins Meta amid a high-stakes hiring blitz across the AI industry. Over the past few months, Meta has poached researchers from OpenAI, Apple, Google, and Anthropic as part of a multibillion-dollar bet on superintelligence as CNN reported. &lt;/p&gt;



&lt;p&gt;Meta recently invested $14.3 billion in Scale AI, acquiring a 49% stake and bringing on Wang to lead the superintelligence effort. Former GitHub CEO Nat Friedman also joined the team. &lt;/p&gt;



&lt;p&gt;The company has reportedly offered compensation packages worth as much as &lt;strong&gt;$100 million to $300 million over four years&lt;/strong&gt; to lure top AI talent, according to multiple reports. One claim from a rival AI startup founder alleged Meta offered &lt;strong&gt;$1.25 billion over four years&lt;/strong&gt;—approximately &lt;strong&gt;$312 million per year&lt;/strong&gt;—to a single candidate who declined. &lt;/p&gt;



&lt;p&gt;Other insiders say Meta’s most senior AI scientists may be receiving &lt;strong&gt;$10 million+ per year&lt;/strong&gt;, while first-year comp for some new hires reportedly reached &lt;strong&gt;$100 million&lt;/strong&gt;.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-aspirations-of-leading-the-ai-frontier"&gt;Aspirations of leading the AI frontier&lt;/h2&gt;



&lt;p&gt;Zuckerberg has made no secret of his ambition to make Meta a leader in AI’s next frontier, repeatedly stating that the company plans to “invest hundreds of billions of dollars into compute to build superintelligence” using its own business-generated capital. &lt;/p&gt;



&lt;p&gt;He said the Llama 4 rollout underscored the importance of elite talent: “You can have hundreds of thousands of GPUs, but if you don’t have the right team developing the model, it doesn’t matter.”&lt;/p&gt;



&lt;p&gt;Meta’s fundamental AI research group (FAIR), still led by acclaimed scientist Yann LeCun, will remain separate from the new lab. &lt;/p&gt;



&lt;p&gt;The creation of Meta Superintelligence Labs signals a more product- and mission-focused arm of Meta’s AI efforts, centered on building and aligning ASI with human interests.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-making-up-for-the-mixed-reception-of-llama-4"&gt;Making up for the mixed reception of Llama 4&lt;/h2&gt;



&lt;p&gt;However, Meta’s push into superintelligence has come on the heels of a bumpy rollout of its latest open-source foundation models. &lt;/p&gt;



&lt;p&gt;The company released its Llama 4 model family in April 2025, positioning it as a leap forward in multimodal reasoning and long-context understanding. But the release has struggled to gain traction amid the rise of powerful Chinese open-source rivals like DeepSeek and Qwen. &lt;/p&gt;



&lt;p&gt;Meta faced public criticism from researchers and developers who cited poor real-world performance, confusion around benchmark results, and inconsistent quality across deployments. &lt;/p&gt;



&lt;p&gt;Some accused the company of “benchmark gamesmanship” and using unreleased optimized versions of Llama 4 to boost public perception—a claim Meta has denied. &lt;/p&gt;



&lt;p&gt;Internal sources blamed fast rollout timelines and bugs for the issues, but the episode has cast a shadow over Meta’s generative AI credibility just as it embarks on its most ambitious effort yet. &lt;/p&gt;



&lt;p&gt;Jim Fan, a former Stanford colleague of Zhao and now Nvidia’s Director of Robotics and Distinguished Scientist, offered his endorsement on X: “Shengjia is one of the brightest, humblest, and most passionate scientists I know. Very bullish on MSL!”&lt;/p&gt;



&lt;p&gt;The move underscores Meta’s strategy of spending aggressively now to secure a dominant position in what it views as the next foundational technology platform — one that could eclipse the mobile internet. As Zuckerberg sees it, ASI isn’t a moonshot — it’s the next frontier, and Meta intends to lead.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/meta-announces-its-superintelligence-labs-chief-scientist-former-openai-gpt-4-co-creator-shengjia-zhao/</guid><pubDate>Sat, 26 Jul 2025 00:58:24 +0000</pubDate></item></channel></rss>