<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 30 Aug 2025 06:27:45 +0000</lastBuildDate><item><title>With new in-house models, Microsoft lays the groundwork for independence from OpenAI (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/08/with-new-in-house-models-microsoft-lays-the-groundwork-for-independence-from-openai/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Microsoft is still deeply tied to OpenAI, but who knows what the future holds.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The Microsoft Copilot logo." class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2023/11/copilot_logo3-300x169.jpg" width="300" /&gt;
                  &lt;img alt="The Microsoft Copilot logo." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2023/11/copilot_logo3-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The Microsoft Copilot logo.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Microsoft

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Microsoft has introduced AI models that it trained internally and says it will begin using them in some products. This announcement may represent an effort to move away from dependence on OpenAI, despite Microsoft's substantial investment in that company. It comes more than a year after insider reports revealed that Microsoft was beginning work on its own foundational models.&lt;/p&gt;
&lt;p&gt;A post on the Microsoft AI blog describes two models. MAI-Voice-1 is a natural speech-generation model meant to deliver "high-fidelity, expressive audio across both single and multi-speaker scenarios." The idea is that voice will be one of the main ways users interact with AI tools in the future, though we haven't really seen that come to fruition so far.&lt;/p&gt;
&lt;p&gt;The second model is called MAI-1-preview, and it's a foundational large language model specifically trained to drive Copilot, Microsoft's AI chatbot tool. It was trained on around 15,000 Nvidia H100 GPUs, and runs inference on a single GPU. As reported last year, this model is significantly larger than the models seen in Microsoft's earlier experiments, which focused on smaller models meant to run locally, like Phi-3.&lt;/p&gt;
&lt;p&gt;To date, Copilot has primarily depended on OpenAI's models. Microsoft has invested enormous amounts of money in OpenAI, and it's unlikely the two companies will fully divorce any time soon. That said, there have been some tensions in recent months when their incentives or objectives have strayed out of alignment.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Since it's hard to predict where this is all going, it's likely to Microsoft's long-term advantage to develop its own models.&lt;/p&gt;
&lt;p&gt;It's also possible Microsoft has introduced these models to address use cases or queries that OpenAI isn't focused on. We're seeing a gradual shift in the AI landscape toward models that are more specialized for certain tasks, rather than general, all-purpose models that are meant to be all things to all people.&lt;/p&gt;
&lt;p&gt;These new models follow that somewhat, as Microsoft AI lead Mustafa Suleyman said in a podcast with The Verge that the goal here is "to create something that works extremely well for the consumer... my focus is on building models that really work for the consumer companion."&lt;/p&gt;
&lt;p&gt;As such, it makes sense that we're going to see these models rolling out in Copilot, which is Microsoft's consumer-oriented AI chatbot product. Of MAI-1-preview, the Microsoft AI blog post specifies, "this model is designed to provide powerful capabilities to consumers seeking to benefit from models that specialize in following instructions and providing helpful responses to everyday queries."&lt;/p&gt;
&lt;p&gt;So, yes, MAI-1-preview has a target audience in mind, but it's still a general-purpose model since Copilot is a general-purpose tool.&lt;/p&gt;
&lt;p&gt;MAI-Voice-1 is already being used in Microsoft's Copilot Daily and Podcasts features. There's also a Copilot Labs interface that you can visit right now to play around with it, giving it prompts or scripts and customizing what kind of voice or delivery you want to hear.&lt;/p&gt;
&lt;p&gt;MA1-1-preview is in public testing on LMArena&amp;nbsp;and will be rolled out to "certain text use cases within Copilot over the coming weeks."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Microsoft is still deeply tied to OpenAI, but who knows what the future holds.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The Microsoft Copilot logo." class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2023/11/copilot_logo3-300x169.jpg" width="300" /&gt;
                  &lt;img alt="The Microsoft Copilot logo." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2023/11/copilot_logo3-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The Microsoft Copilot logo.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Microsoft

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Microsoft has introduced AI models that it trained internally and says it will begin using them in some products. This announcement may represent an effort to move away from dependence on OpenAI, despite Microsoft's substantial investment in that company. It comes more than a year after insider reports revealed that Microsoft was beginning work on its own foundational models.&lt;/p&gt;
&lt;p&gt;A post on the Microsoft AI blog describes two models. MAI-Voice-1 is a natural speech-generation model meant to deliver "high-fidelity, expressive audio across both single and multi-speaker scenarios." The idea is that voice will be one of the main ways users interact with AI tools in the future, though we haven't really seen that come to fruition so far.&lt;/p&gt;
&lt;p&gt;The second model is called MAI-1-preview, and it's a foundational large language model specifically trained to drive Copilot, Microsoft's AI chatbot tool. It was trained on around 15,000 Nvidia H100 GPUs, and runs inference on a single GPU. As reported last year, this model is significantly larger than the models seen in Microsoft's earlier experiments, which focused on smaller models meant to run locally, like Phi-3.&lt;/p&gt;
&lt;p&gt;To date, Copilot has primarily depended on OpenAI's models. Microsoft has invested enormous amounts of money in OpenAI, and it's unlikely the two companies will fully divorce any time soon. That said, there have been some tensions in recent months when their incentives or objectives have strayed out of alignment.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Since it's hard to predict where this is all going, it's likely to Microsoft's long-term advantage to develop its own models.&lt;/p&gt;
&lt;p&gt;It's also possible Microsoft has introduced these models to address use cases or queries that OpenAI isn't focused on. We're seeing a gradual shift in the AI landscape toward models that are more specialized for certain tasks, rather than general, all-purpose models that are meant to be all things to all people.&lt;/p&gt;
&lt;p&gt;These new models follow that somewhat, as Microsoft AI lead Mustafa Suleyman said in a podcast with The Verge that the goal here is "to create something that works extremely well for the consumer... my focus is on building models that really work for the consumer companion."&lt;/p&gt;
&lt;p&gt;As such, it makes sense that we're going to see these models rolling out in Copilot, which is Microsoft's consumer-oriented AI chatbot product. Of MAI-1-preview, the Microsoft AI blog post specifies, "this model is designed to provide powerful capabilities to consumers seeking to benefit from models that specialize in following instructions and providing helpful responses to everyday queries."&lt;/p&gt;
&lt;p&gt;So, yes, MAI-1-preview has a target audience in mind, but it's still a general-purpose model since Copilot is a general-purpose tool.&lt;/p&gt;
&lt;p&gt;MAI-Voice-1 is already being used in Microsoft's Copilot Daily and Podcasts features. There's also a Copilot Labs interface that you can visit right now to play around with it, giving it prompts or scripts and customizing what kind of voice or delivery you want to hear.&lt;/p&gt;
&lt;p&gt;MA1-1-preview is in public testing on LMArena&amp;nbsp;and will be rolled out to "certain text use cases within Copilot over the coming weeks."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/08/with-new-in-house-models-microsoft-lays-the-groundwork-for-independence-from-openai/</guid><pubDate>Fri, 29 Aug 2025 19:49:54 +0000</pubDate></item><item><title>Spotlight on AI at TechCrunch Disrupt: Don’t miss these sessions backed by JetBrains and Greenfield (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/29/spotlight-on-ai-at-techcrunch-disrupt-dont-miss-these-sessions-backed-by-jetbrains-and-greenfield/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_Disrupt_General_Article_No-Anniversary-at-all_Headers_1920x1080.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;TechCrunch Disrupt isn’t just about showcasing the startups of tomorrow — it’s also about surfacing the boldest ideas shaping technology today. Thanks to the support of our partners JetBrains and Greenfield, the &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; program, happening October 27–29 at San Francisco’s Moscone West, brings two must-see sessions that put AI front and center.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-monday-october-27-builders-stage"&gt;Monday, October 27 — Builders Stage&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;1:40 p.m. – 2:10&lt;/strong&gt; &lt;strong&gt;p.m. PT&lt;/strong&gt;&lt;br /&gt;&lt;strong&gt;Who’s Defining AI’s Future in 2025? The AI Disruptors 60 Unveiled&lt;/strong&gt;&lt;br /&gt;Presented by Greenfield Partners&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;We’ve seen it with the internet, and again with mobile: moments when technology reshapes everything. Now it’s AI’s turn — and it’s moving faster than ever. Greenfield Partners is unveiling the AI Disruptors 60 right here at Disrupt 2025: a list of early- and growth-stage startups leading the charge in AI infrastructure, applications, and go-to-market innovation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This panel brings together top investors like Shay Grinfeld (Greenfield Partners) and founders, including Renen Hallak of VAST Data, for a candid discussion about how these companies are building the backbone of tomorrow’s AI economy. From scaling strategies to sector-defining breakthroughs, they’ll unpack what makes these startups stand out — and what’s coming next. Don’t miss the live reveal of the AI Disruptors 60 list, only at TC Disrupt.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-tuesday-october-28-ai-stage"&gt;Tuesday, October 28 — AI Stage&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;1:55 p.m. – 2:15 p.m. PT&lt;/strong&gt;&lt;br /&gt;&lt;strong&gt;Vibe coding? Cute. Now let’s get real and talk about AI built for developers&lt;/strong&gt;&lt;br /&gt;Presented by JetBrains&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI in software development often gets framed as a sprint — more speed, more output, more lines of code. But speed without quality doesn’t cut it in the real world. Join Kirill Skrygan, CEO of JetBrains, for an unfiltered look at how AI built &lt;em&gt;for developers&lt;/em&gt; is changing the industry. This session explores why code quality — not just velocity — will define the next generation of intelligent software and how developers can harness AI to deliver at scale, with reliability and precision.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-a-thank-you-to-our-partners"&gt;A thank-you to our partners&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;We’re grateful to JetBrains and Greenfield for supporting TechCrunch and making these conversations possible at Disrupt 2025. Their commitment to advancing the AI ecosystem helps us spotlight the people and companies rewriting what’s possible. Make sure these sessions are on your must-see list.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_Disrupt_General_Article_No-Anniversary-at-all_Headers_1920x1080.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;TechCrunch Disrupt isn’t just about showcasing the startups of tomorrow — it’s also about surfacing the boldest ideas shaping technology today. Thanks to the support of our partners JetBrains and Greenfield, the &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; program, happening October 27–29 at San Francisco’s Moscone West, brings two must-see sessions that put AI front and center.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-monday-october-27-builders-stage"&gt;Monday, October 27 — Builders Stage&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;1:40 p.m. – 2:10&lt;/strong&gt; &lt;strong&gt;p.m. PT&lt;/strong&gt;&lt;br /&gt;&lt;strong&gt;Who’s Defining AI’s Future in 2025? The AI Disruptors 60 Unveiled&lt;/strong&gt;&lt;br /&gt;Presented by Greenfield Partners&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;We’ve seen it with the internet, and again with mobile: moments when technology reshapes everything. Now it’s AI’s turn — and it’s moving faster than ever. Greenfield Partners is unveiling the AI Disruptors 60 right here at Disrupt 2025: a list of early- and growth-stage startups leading the charge in AI infrastructure, applications, and go-to-market innovation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This panel brings together top investors like Shay Grinfeld (Greenfield Partners) and founders, including Renen Hallak of VAST Data, for a candid discussion about how these companies are building the backbone of tomorrow’s AI economy. From scaling strategies to sector-defining breakthroughs, they’ll unpack what makes these startups stand out — and what’s coming next. Don’t miss the live reveal of the AI Disruptors 60 list, only at TC Disrupt.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-tuesday-october-28-ai-stage"&gt;Tuesday, October 28 — AI Stage&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;1:55 p.m. – 2:15 p.m. PT&lt;/strong&gt;&lt;br /&gt;&lt;strong&gt;Vibe coding? Cute. Now let’s get real and talk about AI built for developers&lt;/strong&gt;&lt;br /&gt;Presented by JetBrains&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI in software development often gets framed as a sprint — more speed, more output, more lines of code. But speed without quality doesn’t cut it in the real world. Join Kirill Skrygan, CEO of JetBrains, for an unfiltered look at how AI built &lt;em&gt;for developers&lt;/em&gt; is changing the industry. This session explores why code quality — not just velocity — will define the next generation of intelligent software and how developers can harness AI to deliver at scale, with reliability and precision.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-a-thank-you-to-our-partners"&gt;A thank-you to our partners&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;We’re grateful to JetBrains and Greenfield for supporting TechCrunch and making these conversations possible at Disrupt 2025. Their commitment to advancing the AI ecosystem helps us spotlight the people and companies rewriting what’s possible. Make sure these sessions are on your must-see list.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/29/spotlight-on-ai-at-techcrunch-disrupt-dont-miss-these-sessions-backed-by-jetbrains-and-greenfield/</guid><pubDate>Fri, 29 Aug 2025 21:05:00 +0000</pubDate></item><item><title>[NEW] How Sakana AI’s new evolutionary algorithm builds powerful AI models without expensive retraining (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/how-sakana-ais-new-evolutionary-algorithm-builds-powerful-ai-models-without-expensive-retraining/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;A new evolutionary technique from Japan-based AI lab Sakana AI enables developers to augment the capabilities of AI models without costly training and fine-tuning processes. The technique, called Model Merging of Natural Niches (M2N2), overcomes the limitations of other model merging methods and can even evolve new models entirely from scratch.&lt;/p&gt;



&lt;p&gt;M2N2 can be applied to different types of machine learning models, including large language models (LLMs) and text-to-image generators. For enterprises looking to build custom AI solutions, the approach offers a powerful and efficient way to create specialized models by combining the strengths of existing open-source variants.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-is-model-merging"&gt;What is model merging?&lt;/h2&gt;



&lt;p&gt;Model merging is a technique for integrating the knowledge of multiple specialized AI models into a single, more capable model. Instead of fine-tuning, which refines a single pre-trained model using new data, merging combines the parameters of several models simultaneously. This process can consolidate a wealth of knowledge into one asset without requiring expensive, gradient-based training or access to the original training data.&lt;/p&gt;



&lt;p&gt;For enterprise teams, this offers several practical advantages over traditional fine-tuning. In comments to VentureBeat, the paper’s authors said model merging is a gradient-free process that only requires forward passes, making it computationally cheaper than fine-tuning, which involves costly gradient updates. Merging also sidesteps the need for carefully balanced training data and mitigates the risk of “catastrophic forgetting,” where a model loses its original capabilities after learning a new task. The technique is especially powerful when the training data for specialist models isn’t available, as merging only requires the model weights themselves.&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Early approaches to model merging required significant manual effort, as developers adjusted coefficients through trial and error to find the optimal blend. More recently, evolutionary algorithms have helped automate this process by searching for the optimal combination of parameters. However, a significant manual step remains: developers must set fixed sets for mergeable parameters, such as layers. This restriction limits the search space and can prevent the discovery of more powerful combinations.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-m2n2-works"&gt;How M2N2 works&lt;/h2&gt;



&lt;p&gt;M2N2 addresses these limitations by drawing inspiration from evolutionary principles in nature. The algorithm has three key features that allow it to explore a wider range of possibilities and discover more effective model combinations.&lt;/p&gt;


&lt;div class="wp-block-image"&gt;
&lt;figure class="aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3016260" height="306" src="https://venturebeat.com/wp-content/uploads/2025/08/image_4efe91.png" width="478" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Model Merging of Natural Niches Source: arXiv&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;


&lt;p&gt;First, M2N2 eliminates fixed merging boundaries, such as blocks or layers. Instead of grouping parameters by pre-defined layers, it uses flexible “split points” and “mixing ration” to divide and combine models. This means that, for example, the algorithm might merge 30% of the parameters in one layer from Model A with 70% of the parameters from the same layer in Model B. The process starts with an “archive” of seed models. At each step, M2N2 selects two models from the archive, determines a mixing ratio and a split point, and merges them. If the resulting model performs well, it is added back to the archive, replacing a weaker one. This allows the algorithm to explore increasingly complex combinations over time. As the researchers note, “This gradual introduction of complexity ensures a wider range of possibilities while maintaining computational tractability.”&lt;/p&gt;



&lt;p&gt;Second, M2N2 manages the diversity of its model population through competition. To understand why diversity is crucial, the researchers offer a simple analogy: “Imagine merging two answer sheets for an exam… If both sheets have exactly the same answers, combining them does not make any improvement. But if each sheet has correct answers for different questions, merging them gives a much stronger result.” Model merging works the same way. The challenge, however, is defining what kind of diversity is valuable. Instead of relying on hand-crafted metrics, M2N2 simulates competition for limited resources. This nature-inspired approach naturally rewards models with unique skills, as they can “tap into uncontested resources” and solve problems others can’t. These niche specialists, the authors note, are the most valuable for merging.&lt;/p&gt;



&lt;p&gt;Third, M2N2 uses a heuristic called “attraction” to pair models for merging. Rather than simply combining the top-performing models as in other merging algorithms, it pairs them based on their complementary strengths. An “attraction score” identifies pairs where one model performs well on data points that the other finds challenging. This improves both the efficiency of the search and the quality of the final merged model.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-m2n2-in-action"&gt;M2N2 in action&lt;/h2&gt;



&lt;p&gt;The researchers tested M2N2 across three different domains, demonstrating its versatility and effectiveness.&lt;/p&gt;



&lt;p&gt;The first was a small-scale experiment evolving neural network–based image classifiers from scratch on the MNIST dataset. M2N2 achieved the highest test accuracy by a substantial margin compared to other methods. The results showed that its diversity-preservation mechanism was key, allowing it to maintain an archive of models with complementary strengths that facilitated effective merging while systematically discarding weaker solutions.&lt;/p&gt;



&lt;p&gt;Next, they applied M2N2 to LLMs, combining a math specialist model (WizardMath-7B) with an agentic specialist (AgentEvol-7B), both of which are based on the Llama 2 architecture. The goal was to create a single agent that excelled at both math problems (GSM8K dataset) and web-based tasks (WebShop dataset). The resulting model achieved strong performance on both benchmarks, showcasing M2N2’s ability to create powerful, multi-skilled models.&lt;/p&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-3016261" height="370" src="https://venturebeat.com/wp-content/uploads/2025/08/image_675535.png" width="790" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;A model merge with M2N2 combines the best of both seed models Source: arXiv&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Finally, the team merged diffusion-based image generation models. They combined a model trained on Japanese prompts (JSDXL) with three Stable Diffusion models primarily trained on English prompts. The objective was to create a model that combined the best image generation capabilities of each seed model while retaining the ability to understand Japanese. The merged model not only produced more photorealistic images with better semantic understanding but also developed an emergent bilingual ability. It could generate high-quality images from both English and Japanese prompts, even though it was optimized exclusively using Japanese captions.&lt;/p&gt;



&lt;p&gt;For enterprises that have already developed specialist models, the business case for merging is compelling. The authors point to new, hybrid capabilities that would be difficult to achieve otherwise. For example, merging an LLM fine-tuned for persuasive sales pitches with a vision model trained to interpret customer reactions could create a single agent that adapts its pitch in real-time based on live video feedback. This unlocks the combined intelligence of multiple models with the cost and latency of running just one.&lt;/p&gt;



&lt;p&gt;Looking ahead, the researchers see techniques like M2N2 as part of a broader trend toward “model fusion.” They envision a future where organizations maintain entire ecosystems of AI models that are continuously evolving and merging to adapt to new challenges.&lt;/p&gt;



&lt;p&gt;“Think of it like an evolving ecosystem where capabilities are combined as needed, rather than building one giant monolith from scratch,” the authors suggest.&lt;/p&gt;



&lt;p&gt;The researchers have released the code of M2N2 on GitHub.&lt;/p&gt;



&lt;p&gt;The biggest hurdle to this dynamic, self-improving AI ecosystem, the authors believe, is not technical but organizational. “In a world with a large ‘merged model’ made up of open-source, commercial, and custom components, ensuring privacy, security, and compliance will be a critical problem.” For businesses, the challenge will be figuring out which models can be safely and effectively absorbed into their evolving AI stack.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;A new evolutionary technique from Japan-based AI lab Sakana AI enables developers to augment the capabilities of AI models without costly training and fine-tuning processes. The technique, called Model Merging of Natural Niches (M2N2), overcomes the limitations of other model merging methods and can even evolve new models entirely from scratch.&lt;/p&gt;



&lt;p&gt;M2N2 can be applied to different types of machine learning models, including large language models (LLMs) and text-to-image generators. For enterprises looking to build custom AI solutions, the approach offers a powerful and efficient way to create specialized models by combining the strengths of existing open-source variants.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-is-model-merging"&gt;What is model merging?&lt;/h2&gt;



&lt;p&gt;Model merging is a technique for integrating the knowledge of multiple specialized AI models into a single, more capable model. Instead of fine-tuning, which refines a single pre-trained model using new data, merging combines the parameters of several models simultaneously. This process can consolidate a wealth of knowledge into one asset without requiring expensive, gradient-based training or access to the original training data.&lt;/p&gt;



&lt;p&gt;For enterprise teams, this offers several practical advantages over traditional fine-tuning. In comments to VentureBeat, the paper’s authors said model merging is a gradient-free process that only requires forward passes, making it computationally cheaper than fine-tuning, which involves costly gradient updates. Merging also sidesteps the need for carefully balanced training data and mitigates the risk of “catastrophic forgetting,” where a model loses its original capabilities after learning a new task. The technique is especially powerful when the training data for specialist models isn’t available, as merging only requires the model weights themselves.&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Early approaches to model merging required significant manual effort, as developers adjusted coefficients through trial and error to find the optimal blend. More recently, evolutionary algorithms have helped automate this process by searching for the optimal combination of parameters. However, a significant manual step remains: developers must set fixed sets for mergeable parameters, such as layers. This restriction limits the search space and can prevent the discovery of more powerful combinations.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-m2n2-works"&gt;How M2N2 works&lt;/h2&gt;



&lt;p&gt;M2N2 addresses these limitations by drawing inspiration from evolutionary principles in nature. The algorithm has three key features that allow it to explore a wider range of possibilities and discover more effective model combinations.&lt;/p&gt;


&lt;div class="wp-block-image"&gt;
&lt;figure class="aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3016260" height="306" src="https://venturebeat.com/wp-content/uploads/2025/08/image_4efe91.png" width="478" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Model Merging of Natural Niches Source: arXiv&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;


&lt;p&gt;First, M2N2 eliminates fixed merging boundaries, such as blocks or layers. Instead of grouping parameters by pre-defined layers, it uses flexible “split points” and “mixing ration” to divide and combine models. This means that, for example, the algorithm might merge 30% of the parameters in one layer from Model A with 70% of the parameters from the same layer in Model B. The process starts with an “archive” of seed models. At each step, M2N2 selects two models from the archive, determines a mixing ratio and a split point, and merges them. If the resulting model performs well, it is added back to the archive, replacing a weaker one. This allows the algorithm to explore increasingly complex combinations over time. As the researchers note, “This gradual introduction of complexity ensures a wider range of possibilities while maintaining computational tractability.”&lt;/p&gt;



&lt;p&gt;Second, M2N2 manages the diversity of its model population through competition. To understand why diversity is crucial, the researchers offer a simple analogy: “Imagine merging two answer sheets for an exam… If both sheets have exactly the same answers, combining them does not make any improvement. But if each sheet has correct answers for different questions, merging them gives a much stronger result.” Model merging works the same way. The challenge, however, is defining what kind of diversity is valuable. Instead of relying on hand-crafted metrics, M2N2 simulates competition for limited resources. This nature-inspired approach naturally rewards models with unique skills, as they can “tap into uncontested resources” and solve problems others can’t. These niche specialists, the authors note, are the most valuable for merging.&lt;/p&gt;



&lt;p&gt;Third, M2N2 uses a heuristic called “attraction” to pair models for merging. Rather than simply combining the top-performing models as in other merging algorithms, it pairs them based on their complementary strengths. An “attraction score” identifies pairs where one model performs well on data points that the other finds challenging. This improves both the efficiency of the search and the quality of the final merged model.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-m2n2-in-action"&gt;M2N2 in action&lt;/h2&gt;



&lt;p&gt;The researchers tested M2N2 across three different domains, demonstrating its versatility and effectiveness.&lt;/p&gt;



&lt;p&gt;The first was a small-scale experiment evolving neural network–based image classifiers from scratch on the MNIST dataset. M2N2 achieved the highest test accuracy by a substantial margin compared to other methods. The results showed that its diversity-preservation mechanism was key, allowing it to maintain an archive of models with complementary strengths that facilitated effective merging while systematically discarding weaker solutions.&lt;/p&gt;



&lt;p&gt;Next, they applied M2N2 to LLMs, combining a math specialist model (WizardMath-7B) with an agentic specialist (AgentEvol-7B), both of which are based on the Llama 2 architecture. The goal was to create a single agent that excelled at both math problems (GSM8K dataset) and web-based tasks (WebShop dataset). The resulting model achieved strong performance on both benchmarks, showcasing M2N2’s ability to create powerful, multi-skilled models.&lt;/p&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-3016261" height="370" src="https://venturebeat.com/wp-content/uploads/2025/08/image_675535.png" width="790" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;A model merge with M2N2 combines the best of both seed models Source: arXiv&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Finally, the team merged diffusion-based image generation models. They combined a model trained on Japanese prompts (JSDXL) with three Stable Diffusion models primarily trained on English prompts. The objective was to create a model that combined the best image generation capabilities of each seed model while retaining the ability to understand Japanese. The merged model not only produced more photorealistic images with better semantic understanding but also developed an emergent bilingual ability. It could generate high-quality images from both English and Japanese prompts, even though it was optimized exclusively using Japanese captions.&lt;/p&gt;



&lt;p&gt;For enterprises that have already developed specialist models, the business case for merging is compelling. The authors point to new, hybrid capabilities that would be difficult to achieve otherwise. For example, merging an LLM fine-tuned for persuasive sales pitches with a vision model trained to interpret customer reactions could create a single agent that adapts its pitch in real-time based on live video feedback. This unlocks the combined intelligence of multiple models with the cost and latency of running just one.&lt;/p&gt;



&lt;p&gt;Looking ahead, the researchers see techniques like M2N2 as part of a broader trend toward “model fusion.” They envision a future where organizations maintain entire ecosystems of AI models that are continuously evolving and merging to adapt to new challenges.&lt;/p&gt;



&lt;p&gt;“Think of it like an evolving ecosystem where capabilities are combined as needed, rather than building one giant monolith from scratch,” the authors suggest.&lt;/p&gt;



&lt;p&gt;The researchers have released the code of M2N2 on GitHub.&lt;/p&gt;



&lt;p&gt;The biggest hurdle to this dynamic, self-improving AI ecosystem, the authors believe, is not technical but organizational. “In a world with a large ‘merged model’ made up of open-source, commercial, and custom components, ensuring privacy, security, and compliance will be a critical problem.” For businesses, the challenge will be figuring out which models can be safely and effectively absorbed into their evolving AI stack.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/how-sakana-ais-new-evolutionary-algorithm-builds-powerful-ai-models-without-expensive-retraining/</guid><pubDate>Sat, 30 Aug 2025 00:14:14 +0000</pubDate></item><item><title>[NEW] Software commands 40% of cybersecurity budgets as gen AI attacks execute in milliseconds (AI News | VentureBeat)</title><link>https://venturebeat.com/security/software-is-40-of-security-budgets-as-cisos-shift-to-ai-defense/</link><description>&lt;p&gt;“With volatility now the norm, security and risk leaders need practical guidance on managing existing spending and new budgetary necessities,” states Forrester’s 2026 Budget Planning Guide, revealing a fundamental shift in how organizations allocate cybersecurity resources.&lt;/p&gt;&lt;p&gt;Software now commands 40% of cybersecurity spending, exceeding hardware at 15.8%, outsourcing at 15% and surpassing personnel costs at 29% by 11 percentage points while organizations defend against gen AI attacks executing in milliseconds versus a Mean Time to Identify (MTTI) of 181 days according to IBM’s latest Cost of a Data Breach Report.&lt;/p&gt;&lt;p&gt;Three converging threats are flipping cybersecurity on its head: what once protected organizations is now working against them. Generative AI (gen AI) is enabling attackers to craft 10,000 personalized phishing emails per minute using scraped LinkedIn profiles and corporate communications. NIST’s 2030 quantum deadline threatens retroactive decryption of $425 billion in currently protected data. Deepfake fraud that surged 3,000% in 2024 now bypasses biometric authentication in 97% of attempts, forcing security leaders to reimagine defensive architectures fundamentally.&lt;/p&gt;&lt;p&gt;Caption: Software now commands 40% of cybersecurity budgets in 2025, representing an 11 percentage point premium over personnel costs at 29%, as organizations layer security solutions to combat gen AI threats executing in milliseconds. Source: Forrester’s 2026 Budget Planning Guide&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;



&lt;p&gt;Enterprise security teams managing 75 or more tools lose $18 million annually to integration and overhead alone. The average detection time remains 277 days, while attacks execute within milliseconds.&lt;/p&gt;



&lt;p&gt;Gartner forecasts that interactive application security testing (IAST) tools will lose 80% of market share by 2026. Security Service Edge (SSE) platforms that promised streamlined convergence now add to the complexity they intended to solve. Meanwhile, standalone risk-rating products flood security operations centers with alerts that lack actionable context, leading analysts to spend 67% of their time on false positives, according to IDC’s Security Operations Study.&lt;/p&gt;



&lt;p&gt;The operational math doesn’t work. Analysts require 90 seconds to evaluate each alert, but they receive 11,000 alerts daily. Each additional security tool deployed reduces visibility by 12% and increases attacker dwell time by 23 days, as reported in Mandiant’s 2024 M-Trends Report. Complexity itself has become the enterprise’s greatest cybersecurity vulnerability.&lt;/p&gt;



&lt;p&gt;Platform vendors have been selling consolidation for years, capitalizing on the chaos and complexity that app and tool sprawl create. As George Kurtz, CEO of CrowdStrike, explained in a recent VentureBeat interview about competing with a platform in today’s mercurially changing market conditions: “The difference between a platform and platformization is execution. You need to deliver immediate value while building toward a unified vision that eliminates complexity.”&lt;/p&gt;



&lt;p&gt;CrowdStrike’s Charlotte AI automates alert triage and saves SOC teams over 40 hours every week by classifying millions of detections at 98% accuracy; that equals the output of five seasoned analysts and is fueled by Falcon Complete’s expert-labeled incident corpus.&lt;/p&gt;



&lt;p&gt;“We couldn’t have done this without our Falcon Complete team,” Elia Zaitsev, CTO at CrowdStrike, told VentureBeat in a recent interview. “They do triage as part of their workflow, manually handling millions of detections. That high-quality, human-annotated dataset is what made over 98% accuracy possible. We recognized that adversaries are increasingly leveraging AI to accelerate attacks. With Charlotte AI, we’re giving defenders an equal footing, amplifying their efficiency and ensuring they can keep pace with attackers in real time.”&lt;/p&gt;



&lt;p&gt;CrowdStrike, Microsoft’s Defender XDR with MDVM/Intune, Palo Alto Networks, Netskope, Tanium and Mondoo now bundle XDR, SIEM and auto-remediation, transforming SOCs from delayed forensics sessions to the ability to perform real-time threat neutralization.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-security-budgets-surge-10-as-gen-ai-attacks-outpace-human-defense"&gt;&lt;strong&gt;Security budgets surge 10% as gen AI attacks outpace human defense&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Forrester’s guide finds 55% of global security technology decision-makers expect significant budget increases in the next 12 months. 15% anticipate jumps exceeding 10% while 40% expect increases between 5% and 10%. This spending surge reflects an asymmetric battlefield where attackers deploy gen AI to simultaneously target thousands of employees with personalized campaigns crafted from real-time scraped data.&lt;/p&gt;



&lt;p&gt;Attackers are making the most of the advantages they’re getting from adversarial AI, with speed, stealth and highly personalized, target attacks becoming the most lethal. “For years, attackers have been utilizing AI to their advantage,” Mike Riemer, Field CISO at Ivanti, told VentureBeat. “However, 2025 will mark a turning point as defenders begin to harness the full potential of AI for cybersecurity purposes.”&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3016046" height="463" src="https://venturebeat.com/wp-content/uploads/2025/08/figure-2.jpg?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;Caption: 55% of security leaders expect budget increases above 5% in 2026, with Asia Pacific organizations leading at 22% expecting increases above 10% versus just 9% in North America. Source: Forrester’s 2026 Budget Planning Guide&lt;/p&gt;



&lt;p&gt;Regional spending disparities reveal threat landscape variations and how CISOs are responding to them. Asia Pacific organizations lead with 22% expecting budget increases above 10% versus just 9% in North America. Cloud security, on-premises technology and security awareness training top investment priorities globally.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-software-dominates-budgets-as-runtime-defenses-become-critical-in-2026"&gt;&lt;strong&gt;Software dominates budgets as runtime defenses become critical in 2026&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;VentureBeat continues to hear from security leaders about how crucial protecting the inference layer of AI model development is. Many consider it the new frontline of the future of cybersecurity. Inference layers are vulnerable to prompt injection, data exfiltration, or even direct model manipulation. These are all threats that demand millisecond-scale responses, not delayed forensic investigations.&lt;/p&gt;



&lt;p&gt;Forrester’s latest CISO spending guide underscores a profound shift in cybersecurity spending priorities, with cloud security leading all spending increases at 12%, closely followed by investments in on-premises security technology at 11%, and security awareness initiatives at 10%. These priorities reflect the urgency CISOs feel to strengthen defenses precisely at the critical moment of AI model inference.&lt;/p&gt;



&lt;p&gt;“At Reputation, security is baked into our core architecture and enforced rigorously at runtime,” Carter Rees, Vice President of Artificial Intelligence at Reputation, recently told VentureBeat. “The inference layer, the exact moment an AI model interacts with people, data, or tools, is where we apply our most stringent controls. Every interaction includes authenticated tenant and role contexts, verified in real-time by an AI security gateway.”&lt;/p&gt;



&lt;p&gt;Reputation’s multi-tiered approach has become a de facto gold standard, blending proactive and reactive defenses. “Real-time controls immediately take over,” Rees explained. “Our prompt firewall blocks unauthorized or off-topic inputs instantly, restricting tool and data access strictly to user permissions. Behavioral detectors proactively flag anomalies the moment they occur.”&lt;/p&gt;



&lt;p&gt;This rigorous runtime security approach extends equally into customer-facing systems. “For natural language interactions, our AI only pulls from explicitly customer-approved sources,” Rees noted. “Each generated response must transparently cite its sources. We verify citations match both tenant and context, routing for human review if they do not.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-quantum-computing-s-accelerating-risk"&gt;&lt;strong&gt;Quantum computing’s accelerating risk&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Quantum computing is quickly evolving from a theoretical concern into an immediate enterprise threat. Security leaders now face “harvest now, decrypt later” (HNDL) attacks, where adversaries store encrypted data for future quantum-enabled decryption. Widely used encryption methods like 2048-bit RSA risk compromise once quantum processors reach operational scale with tens of thousands of reliable qubits.&lt;/p&gt;



&lt;p&gt;The National Institute of Standards and Technology (NIST) finalized three critical Post-Quantum Cryptography (PQC) standards in August 2024, mandating encryption algorithm retirement by 2030 and full prohibition by 2035. Global agencies, including Australia’s Signals Directorate, require PQC implementation by 2030.&lt;/p&gt;



&lt;p&gt;Forrester urges organizations to prioritize PQC adoption for protecting sensitive data at rest, in transit, and in use. Security leaders should leverage cryptographic inventory and discovery tools, partnering with cryptoagility providers such as Entrust, IBM, Keyfactor, Palo Alto Networks, QuSecure, SandboxAQ, and Thales. Given quantum’s rapid progression, CISOs need to factor in how they’ll update encryption strategies to avoid obsolescence and vulnerability.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-explosion-of-identities-is-fueling-an-ai-driven-credential-crisis"&gt;&lt;strong&gt;Explosion of identities is fueling an AI-driven credential crisis&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Machine identities now outnumber human users by a staggering 45:1 ratio, fueling a credential crisis beyond human management. Forrester’s guide underscores scaling machine identity management as mission-critical to mitigating emerging threats. Gartner forecasts identity security spending to nearly double, reaching $47.1 billion by 2028.&lt;/p&gt;



&lt;p&gt;Traditional endpoint approaches aren’t capable of slowing down a growing onslaught of adversarial AI attacks. Ivanti’s Daren Goeson recently told VentureBeat: “As these endpoints multiply, so does their vulnerability. Combining AI with Unified Endpoint Management (UEM) is increasingly essential.” Ivanti’s AI-driven Vulnerability Risk Rating (VRR) illustrates this benefit, enabling organizations to patch vulnerabilities 85% faster by identifying threats traditional scoring methods overlook, making AI-driven credential intelligence enterprise security at scale.&lt;/p&gt;



&lt;p&gt;“Endpoint devices such as laptops, desktops, smartphones, and IoT devices are essential to modern business operations. However, as their numbers grow, so do the opportunities for attackers to exploit endpoints and their applications, ”Goeson explained. &amp;nbsp;“Factors like an expanded attack surface, insufficient security resources, unpatched vulnerabilities, and outdated software contribute to this rising risk. By adopting a comprehensive approach that combines UEM solutions with AI-powered tools, businesses significantly reduce their cyber risk and the impact of attacks,” Goeson advised VentureBeat during a recent interview.&lt;/p&gt;







&lt;p&gt;Forrester saves their immediate call to action in the guide for advising security leaders to begin divesting legacy security tools immediately, with a specific focus on interactive application security testing (IAST), standalone cybersecurity risk-rating (CRR) products, and fragmented Security Service Edge (SSE), SD-WAN, and Zero Trust Network Access (ZTNA) solutions.&lt;/p&gt;



&lt;p&gt;Instead, Forrester advises, security leaders need to prioritize more integrated platforms that enhance visibility and streamline management. Unified Secure Access Service Edge (SASE) solutions from Palo Alto Networks and Netskope now provide essential consolidation. At the same time, integrated Third-Party Risk Management (TPRM) and continuous monitoring platforms from UpGuard, Panorays and RiskRecon replace standalone CRR tools the consulting firm advises.&lt;/p&gt;



&lt;p&gt;Additionally, automated remediation powered by Microsoft’s MDVM with Intune, Tanium’s endpoint management, and DevOps-focused solutions like Mondoo has emerged as a critical capability for real-time threat neutralization.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-cisos-must-consolidate-security-at-ai-s-inference-edge-or-risk-losing-control"&gt;&lt;strong&gt;CISOs must consolidate security at AI’s inference edge or risk losing control&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Consolidating tools at inference’s edge is the future of cybersecurity, especially as AI threats intensify. “For CISOs, the playbook is crystal clear,” Rees concluded. “Consolidate controls decisively at the inference edge. Introduce robust behavioral anomaly detection. Strengthen Retrieval-Augmented Generation (RAG) systems with provenance checks and defined abstain paths. Above all, invest heavily in runtime defenses and support the specialized teams who operate them. Execute this playbook, and you achieve secure AI deployments at true scale.”&lt;/p&gt;




&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;p&gt;“With volatility now the norm, security and risk leaders need practical guidance on managing existing spending and new budgetary necessities,” states Forrester’s 2026 Budget Planning Guide, revealing a fundamental shift in how organizations allocate cybersecurity resources.&lt;/p&gt;&lt;p&gt;Software now commands 40% of cybersecurity spending, exceeding hardware at 15.8%, outsourcing at 15% and surpassing personnel costs at 29% by 11 percentage points while organizations defend against gen AI attacks executing in milliseconds versus a Mean Time to Identify (MTTI) of 181 days according to IBM’s latest Cost of a Data Breach Report.&lt;/p&gt;&lt;p&gt;Three converging threats are flipping cybersecurity on its head: what once protected organizations is now working against them. Generative AI (gen AI) is enabling attackers to craft 10,000 personalized phishing emails per minute using scraped LinkedIn profiles and corporate communications. NIST’s 2030 quantum deadline threatens retroactive decryption of $425 billion in currently protected data. Deepfake fraud that surged 3,000% in 2024 now bypasses biometric authentication in 97% of attempts, forcing security leaders to reimagine defensive architectures fundamentally.&lt;/p&gt;&lt;p&gt;Caption: Software now commands 40% of cybersecurity budgets in 2025, representing an 11 percentage point premium over personnel costs at 29%, as organizations layer security solutions to combat gen AI threats executing in milliseconds. Source: Forrester’s 2026 Budget Planning Guide&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;



&lt;p&gt;Enterprise security teams managing 75 or more tools lose $18 million annually to integration and overhead alone. The average detection time remains 277 days, while attacks execute within milliseconds.&lt;/p&gt;



&lt;p&gt;Gartner forecasts that interactive application security testing (IAST) tools will lose 80% of market share by 2026. Security Service Edge (SSE) platforms that promised streamlined convergence now add to the complexity they intended to solve. Meanwhile, standalone risk-rating products flood security operations centers with alerts that lack actionable context, leading analysts to spend 67% of their time on false positives, according to IDC’s Security Operations Study.&lt;/p&gt;



&lt;p&gt;The operational math doesn’t work. Analysts require 90 seconds to evaluate each alert, but they receive 11,000 alerts daily. Each additional security tool deployed reduces visibility by 12% and increases attacker dwell time by 23 days, as reported in Mandiant’s 2024 M-Trends Report. Complexity itself has become the enterprise’s greatest cybersecurity vulnerability.&lt;/p&gt;



&lt;p&gt;Platform vendors have been selling consolidation for years, capitalizing on the chaos and complexity that app and tool sprawl create. As George Kurtz, CEO of CrowdStrike, explained in a recent VentureBeat interview about competing with a platform in today’s mercurially changing market conditions: “The difference between a platform and platformization is execution. You need to deliver immediate value while building toward a unified vision that eliminates complexity.”&lt;/p&gt;



&lt;p&gt;CrowdStrike’s Charlotte AI automates alert triage and saves SOC teams over 40 hours every week by classifying millions of detections at 98% accuracy; that equals the output of five seasoned analysts and is fueled by Falcon Complete’s expert-labeled incident corpus.&lt;/p&gt;



&lt;p&gt;“We couldn’t have done this without our Falcon Complete team,” Elia Zaitsev, CTO at CrowdStrike, told VentureBeat in a recent interview. “They do triage as part of their workflow, manually handling millions of detections. That high-quality, human-annotated dataset is what made over 98% accuracy possible. We recognized that adversaries are increasingly leveraging AI to accelerate attacks. With Charlotte AI, we’re giving defenders an equal footing, amplifying their efficiency and ensuring they can keep pace with attackers in real time.”&lt;/p&gt;



&lt;p&gt;CrowdStrike, Microsoft’s Defender XDR with MDVM/Intune, Palo Alto Networks, Netskope, Tanium and Mondoo now bundle XDR, SIEM and auto-remediation, transforming SOCs from delayed forensics sessions to the ability to perform real-time threat neutralization.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-security-budgets-surge-10-as-gen-ai-attacks-outpace-human-defense"&gt;&lt;strong&gt;Security budgets surge 10% as gen AI attacks outpace human defense&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Forrester’s guide finds 55% of global security technology decision-makers expect significant budget increases in the next 12 months. 15% anticipate jumps exceeding 10% while 40% expect increases between 5% and 10%. This spending surge reflects an asymmetric battlefield where attackers deploy gen AI to simultaneously target thousands of employees with personalized campaigns crafted from real-time scraped data.&lt;/p&gt;



&lt;p&gt;Attackers are making the most of the advantages they’re getting from adversarial AI, with speed, stealth and highly personalized, target attacks becoming the most lethal. “For years, attackers have been utilizing AI to their advantage,” Mike Riemer, Field CISO at Ivanti, told VentureBeat. “However, 2025 will mark a turning point as defenders begin to harness the full potential of AI for cybersecurity purposes.”&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3016046" height="463" src="https://venturebeat.com/wp-content/uploads/2025/08/figure-2.jpg?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;Caption: 55% of security leaders expect budget increases above 5% in 2026, with Asia Pacific organizations leading at 22% expecting increases above 10% versus just 9% in North America. Source: Forrester’s 2026 Budget Planning Guide&lt;/p&gt;



&lt;p&gt;Regional spending disparities reveal threat landscape variations and how CISOs are responding to them. Asia Pacific organizations lead with 22% expecting budget increases above 10% versus just 9% in North America. Cloud security, on-premises technology and security awareness training top investment priorities globally.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-software-dominates-budgets-as-runtime-defenses-become-critical-in-2026"&gt;&lt;strong&gt;Software dominates budgets as runtime defenses become critical in 2026&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;VentureBeat continues to hear from security leaders about how crucial protecting the inference layer of AI model development is. Many consider it the new frontline of the future of cybersecurity. Inference layers are vulnerable to prompt injection, data exfiltration, or even direct model manipulation. These are all threats that demand millisecond-scale responses, not delayed forensic investigations.&lt;/p&gt;



&lt;p&gt;Forrester’s latest CISO spending guide underscores a profound shift in cybersecurity spending priorities, with cloud security leading all spending increases at 12%, closely followed by investments in on-premises security technology at 11%, and security awareness initiatives at 10%. These priorities reflect the urgency CISOs feel to strengthen defenses precisely at the critical moment of AI model inference.&lt;/p&gt;



&lt;p&gt;“At Reputation, security is baked into our core architecture and enforced rigorously at runtime,” Carter Rees, Vice President of Artificial Intelligence at Reputation, recently told VentureBeat. “The inference layer, the exact moment an AI model interacts with people, data, or tools, is where we apply our most stringent controls. Every interaction includes authenticated tenant and role contexts, verified in real-time by an AI security gateway.”&lt;/p&gt;



&lt;p&gt;Reputation’s multi-tiered approach has become a de facto gold standard, blending proactive and reactive defenses. “Real-time controls immediately take over,” Rees explained. “Our prompt firewall blocks unauthorized or off-topic inputs instantly, restricting tool and data access strictly to user permissions. Behavioral detectors proactively flag anomalies the moment they occur.”&lt;/p&gt;



&lt;p&gt;This rigorous runtime security approach extends equally into customer-facing systems. “For natural language interactions, our AI only pulls from explicitly customer-approved sources,” Rees noted. “Each generated response must transparently cite its sources. We verify citations match both tenant and context, routing for human review if they do not.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-quantum-computing-s-accelerating-risk"&gt;&lt;strong&gt;Quantum computing’s accelerating risk&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Quantum computing is quickly evolving from a theoretical concern into an immediate enterprise threat. Security leaders now face “harvest now, decrypt later” (HNDL) attacks, where adversaries store encrypted data for future quantum-enabled decryption. Widely used encryption methods like 2048-bit RSA risk compromise once quantum processors reach operational scale with tens of thousands of reliable qubits.&lt;/p&gt;



&lt;p&gt;The National Institute of Standards and Technology (NIST) finalized three critical Post-Quantum Cryptography (PQC) standards in August 2024, mandating encryption algorithm retirement by 2030 and full prohibition by 2035. Global agencies, including Australia’s Signals Directorate, require PQC implementation by 2030.&lt;/p&gt;



&lt;p&gt;Forrester urges organizations to prioritize PQC adoption for protecting sensitive data at rest, in transit, and in use. Security leaders should leverage cryptographic inventory and discovery tools, partnering with cryptoagility providers such as Entrust, IBM, Keyfactor, Palo Alto Networks, QuSecure, SandboxAQ, and Thales. Given quantum’s rapid progression, CISOs need to factor in how they’ll update encryption strategies to avoid obsolescence and vulnerability.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-explosion-of-identities-is-fueling-an-ai-driven-credential-crisis"&gt;&lt;strong&gt;Explosion of identities is fueling an AI-driven credential crisis&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Machine identities now outnumber human users by a staggering 45:1 ratio, fueling a credential crisis beyond human management. Forrester’s guide underscores scaling machine identity management as mission-critical to mitigating emerging threats. Gartner forecasts identity security spending to nearly double, reaching $47.1 billion by 2028.&lt;/p&gt;



&lt;p&gt;Traditional endpoint approaches aren’t capable of slowing down a growing onslaught of adversarial AI attacks. Ivanti’s Daren Goeson recently told VentureBeat: “As these endpoints multiply, so does their vulnerability. Combining AI with Unified Endpoint Management (UEM) is increasingly essential.” Ivanti’s AI-driven Vulnerability Risk Rating (VRR) illustrates this benefit, enabling organizations to patch vulnerabilities 85% faster by identifying threats traditional scoring methods overlook, making AI-driven credential intelligence enterprise security at scale.&lt;/p&gt;



&lt;p&gt;“Endpoint devices such as laptops, desktops, smartphones, and IoT devices are essential to modern business operations. However, as their numbers grow, so do the opportunities for attackers to exploit endpoints and their applications, ”Goeson explained. &amp;nbsp;“Factors like an expanded attack surface, insufficient security resources, unpatched vulnerabilities, and outdated software contribute to this rising risk. By adopting a comprehensive approach that combines UEM solutions with AI-powered tools, businesses significantly reduce their cyber risk and the impact of attacks,” Goeson advised VentureBeat during a recent interview.&lt;/p&gt;







&lt;p&gt;Forrester saves their immediate call to action in the guide for advising security leaders to begin divesting legacy security tools immediately, with a specific focus on interactive application security testing (IAST), standalone cybersecurity risk-rating (CRR) products, and fragmented Security Service Edge (SSE), SD-WAN, and Zero Trust Network Access (ZTNA) solutions.&lt;/p&gt;



&lt;p&gt;Instead, Forrester advises, security leaders need to prioritize more integrated platforms that enhance visibility and streamline management. Unified Secure Access Service Edge (SASE) solutions from Palo Alto Networks and Netskope now provide essential consolidation. At the same time, integrated Third-Party Risk Management (TPRM) and continuous monitoring platforms from UpGuard, Panorays and RiskRecon replace standalone CRR tools the consulting firm advises.&lt;/p&gt;



&lt;p&gt;Additionally, automated remediation powered by Microsoft’s MDVM with Intune, Tanium’s endpoint management, and DevOps-focused solutions like Mondoo has emerged as a critical capability for real-time threat neutralization.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-cisos-must-consolidate-security-at-ai-s-inference-edge-or-risk-losing-control"&gt;&lt;strong&gt;CISOs must consolidate security at AI’s inference edge or risk losing control&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Consolidating tools at inference’s edge is the future of cybersecurity, especially as AI threats intensify. “For CISOs, the playbook is crystal clear,” Rees concluded. “Consolidate controls decisively at the inference edge. Introduce robust behavioral anomaly detection. Strengthen Retrieval-Augmented Generation (RAG) systems with provenance checks and defined abstain paths. Above all, invest heavily in runtime defenses and support the specialized teams who operate them. Execute this playbook, and you achieve secure AI deployments at true scale.”&lt;/p&gt;




&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/security/software-is-40-of-security-budgets-as-cisos-shift-to-ai-defense/</guid><pubDate>Sat, 30 Aug 2025 01:06:26 +0000</pubDate></item><item><title>[NEW] Cracks are forming in Meta’s partnership with Scale AI (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/29/cracks-are-forming-in-metas-partnership-with-scale-ai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-1540568234.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;It’s only been since June that Meta invested $14.3 billion in the data-labeling vendor Scale AI, bringing on CEO Alexandr Wang and several of the startup’s top executives to run Meta Superintelligence Labs (MSL). But the relationship between the two companies is already showing signs of fraying.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At least one of the executives Wang brought over to help run MSL — Scale AI’s former Senior Vice President of GenAI Product and Operations, Ruben Mayer — has departed Meta after just two months with the company, two people familiar with the matter told TechCrunch.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Mayer spent roughly five years with Scale AI across two stints. In his short time at Meta, according to those sources, Mayer oversaw AI data operations teams but wasn’t part of the company’s TBD Labs — the core unit within Meta tasked with building AI superintelligence, where top AI researchers from OpenAI have landed.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, Mayer disputes some details about his role, telling TechCrunch that his initial position was “to help set up the lab, with whatever was needed” rather than data, and that he was “part of TBD Labs from day one” rather than being excluded from the core AI unit. Mayer also clarified that he “did not report directly to [Wang]” and was “very happy” with his Meta experience.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond the personnel changes, Meta’s relationship with Scale AI appears to be shifting. TBD Labs is working with third-party data labeling vendors other than Scale AI to train its upcoming AI models, according to five people familiar with the matter. Those third-party vendors include Mercor and Surge, two of Scale AI’s largest competitors, the people said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While AI labs commonly work with several data labeling vendors – Meta has been working with Mercor and Surge since before TBD Labs was spun up –&amp;nbsp; it’s rare for an AI lab to invest so heavily in one data vendor. That makes this situation especially notable: even with Meta’s multi-billion-dollar investment, several sources said that researchers in TBD Labs see Scale AI’s data as low quality and have expressed a preference to work with Surge and Mercor.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Scale AI initially built its business on a crowdsourcing model that used a large, low-cost workforce to handle simple data labeling, which is the process of tagging and annotating raw information to train AI models. But as AI models have grown more sophisticated, they now require highly-skilled domain experts—such as doctors, lawyers, and scientists—to generate and refine the high-quality data needed to improve their performance.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Although Scale AI has moved to attract these subject matter experts with its Outlier platform, competitors like Surge and Mercor have been growing quickly because their business models were built on a foundation of high-paid talent from the outset.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A Meta spokesperson disputed the fact that there are quality issues with Scale AI’s product. Surge and Mercor declined to comment. Asked about Meta’s deepening reliance on competing data providers, a Scale AI spokesperson directed TechCrunch to its initial announcement of Meta’s investment in the startup, which cites an expansion of the companies’ commercial relationship.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s deals with third-party data vendors likely mean the company is not putting all its eggs in Scale AI, even after investing billions in the startup. The same can’t be said for Scale AI, however. Not long after Meta announced its massive investment with Scale AI, OpenAI and Google said they would stop working with the data provider.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Shortly after losing those customers, Scale AI laid off 200 employees in its data labeling business in July, with the company’s new CEO, Jason Droege, blaming the changes in part on “shifts in market demand.” Droege said Scale AI would staff up in other parts of the business, including government sales — the company just landed a $99 million contract with the U.S. Army.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some speculated initially that Meta’s investment in Scale AI was really to lure Wang, a founder who has operated in the AI space since Scale AI was founded in 2016 and who appears to be helping Meta to attract top AI talent.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Aside from Wang, there’s an open question around how valuable Scale is to Meta.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One current MSL employee says that several of the Scale executives brought over to Meta are not working on the core TBD Labs team. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, Meta’s AI unit has become increasingly chaotic since bringing on Wang and a wave of top researchers, according to two former employees and one current MSL employee. New talent from OpenAI and Scale AI have expressed frustration with navigating the bureaucracy of a big company, while Meta’s previous GenAI team has seen its scope limited, they said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The tensions indicate that Meta’s largest AI investment to date may be off to a rocky start, despite that it was supposed to address the company’s AI development challenges. After the lackluster launch of Llama 4 in April, Meta CEO Mark Zuckerberg grew frustrated with the company’s AI team, one current and one former employee told TechCrunch.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In an effort to turn things around and catch up with OpenAI and Google, Zuckerberg rushed to strike deals and launched an aggressive campaign to recruit top AI talent.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond Wang, Zuckerberg has managed to pull in top AI researchers from OpenAI, Google DeepMind, and Anthropic. Meta has also acquired AI voice startups including Play AI and WaveForms AI, and announced a partnership with the AI image generation startup, Midjourney.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;To power its AI ambitions, Meta recently announced several massive data center buildouts across the U.S. One of the largest is a $50 billion data center in Louisiana called Hyperion, named after a titan in Greek mythology that fathered the God of Sun.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Wang, who’s not an AI researcher by background, was viewed as a somewhat unconventional choice to lead an AI lab. Zuckerberg reportedly held talks to bring in more traditional candidates to lead the effort, such as OpenAI’s chief research officer, Mark Chen, and tried to acquire the startups of Ilya Sutskever and Mira Murati. All of them declined.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some of the new AI researchers recently brought in from OpenAI have already left Meta, Wired previously reported. Meanwhile, many longtime members of Meta’s GenAI unit have departed in light of the changes.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;MSL AI researcher Rishabh Agarwal is among the latest, posting on X this week that he’d be leaving the company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The pitch from Mark and @alexandr_wang to build in the Superintelligence team was incredibly compelling,” said Agarwal. “But I ultimately choose to follow Mark’s own advice: ‘In a world that’s changing so fast, the biggest risk you can take is not taking any risk’.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Asked afterward about his time at Meta and what drove his decision to leave, Agarwal declined to comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Director of product management for generative AI, Chaya Nayak, and research engineer, Rohan Varma, have also announced their departure from Meta in recent weeks. The question now is whether Meta can stabilize its AI operations and retain the talent it needs for its future success. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;MSL has already started working on its next generation AI model. According to reports from Business Insider, it’s aiming to launch it by the end of this year.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Update: This story has been updated with comments from Mayer, who reached out to TechCrunch after publication.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-1540568234.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;It’s only been since June that Meta invested $14.3 billion in the data-labeling vendor Scale AI, bringing on CEO Alexandr Wang and several of the startup’s top executives to run Meta Superintelligence Labs (MSL). But the relationship between the two companies is already showing signs of fraying.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At least one of the executives Wang brought over to help run MSL — Scale AI’s former Senior Vice President of GenAI Product and Operations, Ruben Mayer — has departed Meta after just two months with the company, two people familiar with the matter told TechCrunch.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Mayer spent roughly five years with Scale AI across two stints. In his short time at Meta, according to those sources, Mayer oversaw AI data operations teams but wasn’t part of the company’s TBD Labs — the core unit within Meta tasked with building AI superintelligence, where top AI researchers from OpenAI have landed.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, Mayer disputes some details about his role, telling TechCrunch that his initial position was “to help set up the lab, with whatever was needed” rather than data, and that he was “part of TBD Labs from day one” rather than being excluded from the core AI unit. Mayer also clarified that he “did not report directly to [Wang]” and was “very happy” with his Meta experience.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond the personnel changes, Meta’s relationship with Scale AI appears to be shifting. TBD Labs is working with third-party data labeling vendors other than Scale AI to train its upcoming AI models, according to five people familiar with the matter. Those third-party vendors include Mercor and Surge, two of Scale AI’s largest competitors, the people said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While AI labs commonly work with several data labeling vendors – Meta has been working with Mercor and Surge since before TBD Labs was spun up –&amp;nbsp; it’s rare for an AI lab to invest so heavily in one data vendor. That makes this situation especially notable: even with Meta’s multi-billion-dollar investment, several sources said that researchers in TBD Labs see Scale AI’s data as low quality and have expressed a preference to work with Surge and Mercor.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Scale AI initially built its business on a crowdsourcing model that used a large, low-cost workforce to handle simple data labeling, which is the process of tagging and annotating raw information to train AI models. But as AI models have grown more sophisticated, they now require highly-skilled domain experts—such as doctors, lawyers, and scientists—to generate and refine the high-quality data needed to improve their performance.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Although Scale AI has moved to attract these subject matter experts with its Outlier platform, competitors like Surge and Mercor have been growing quickly because their business models were built on a foundation of high-paid talent from the outset.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A Meta spokesperson disputed the fact that there are quality issues with Scale AI’s product. Surge and Mercor declined to comment. Asked about Meta’s deepening reliance on competing data providers, a Scale AI spokesperson directed TechCrunch to its initial announcement of Meta’s investment in the startup, which cites an expansion of the companies’ commercial relationship.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s deals with third-party data vendors likely mean the company is not putting all its eggs in Scale AI, even after investing billions in the startup. The same can’t be said for Scale AI, however. Not long after Meta announced its massive investment with Scale AI, OpenAI and Google said they would stop working with the data provider.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Shortly after losing those customers, Scale AI laid off 200 employees in its data labeling business in July, with the company’s new CEO, Jason Droege, blaming the changes in part on “shifts in market demand.” Droege said Scale AI would staff up in other parts of the business, including government sales — the company just landed a $99 million contract with the U.S. Army.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some speculated initially that Meta’s investment in Scale AI was really to lure Wang, a founder who has operated in the AI space since Scale AI was founded in 2016 and who appears to be helping Meta to attract top AI talent.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Aside from Wang, there’s an open question around how valuable Scale is to Meta.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One current MSL employee says that several of the Scale executives brought over to Meta are not working on the core TBD Labs team. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, Meta’s AI unit has become increasingly chaotic since bringing on Wang and a wave of top researchers, according to two former employees and one current MSL employee. New talent from OpenAI and Scale AI have expressed frustration with navigating the bureaucracy of a big company, while Meta’s previous GenAI team has seen its scope limited, they said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The tensions indicate that Meta’s largest AI investment to date may be off to a rocky start, despite that it was supposed to address the company’s AI development challenges. After the lackluster launch of Llama 4 in April, Meta CEO Mark Zuckerberg grew frustrated with the company’s AI team, one current and one former employee told TechCrunch.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In an effort to turn things around and catch up with OpenAI and Google, Zuckerberg rushed to strike deals and launched an aggressive campaign to recruit top AI talent.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond Wang, Zuckerberg has managed to pull in top AI researchers from OpenAI, Google DeepMind, and Anthropic. Meta has also acquired AI voice startups including Play AI and WaveForms AI, and announced a partnership with the AI image generation startup, Midjourney.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;To power its AI ambitions, Meta recently announced several massive data center buildouts across the U.S. One of the largest is a $50 billion data center in Louisiana called Hyperion, named after a titan in Greek mythology that fathered the God of Sun.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Wang, who’s not an AI researcher by background, was viewed as a somewhat unconventional choice to lead an AI lab. Zuckerberg reportedly held talks to bring in more traditional candidates to lead the effort, such as OpenAI’s chief research officer, Mark Chen, and tried to acquire the startups of Ilya Sutskever and Mira Murati. All of them declined.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some of the new AI researchers recently brought in from OpenAI have already left Meta, Wired previously reported. Meanwhile, many longtime members of Meta’s GenAI unit have departed in light of the changes.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;MSL AI researcher Rishabh Agarwal is among the latest, posting on X this week that he’d be leaving the company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The pitch from Mark and @alexandr_wang to build in the Superintelligence team was incredibly compelling,” said Agarwal. “But I ultimately choose to follow Mark’s own advice: ‘In a world that’s changing so fast, the biggest risk you can take is not taking any risk’.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Asked afterward about his time at Meta and what drove his decision to leave, Agarwal declined to comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Director of product management for generative AI, Chaya Nayak, and research engineer, Rohan Varma, have also announced their departure from Meta in recent weeks. The question now is whether Meta can stabilize its AI operations and retain the talent it needs for its future success. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;MSL has already started working on its next generation AI model. According to reports from Business Insider, it’s aiming to launch it by the end of this year.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Update: This story has been updated with comments from Mayer, who reached out to TechCrunch after publication.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/29/cracks-are-forming-in-metas-partnership-with-scale-ai/</guid><pubDate>Sat, 30 Aug 2025 01:34:05 +0000</pubDate></item></channel></rss>