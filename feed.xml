<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 16 Sep 2025 01:36:32 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>Machine-learning tool gives doctors a more detailed 3D picture of fetal health (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/machine-learning-tool-gives-doctors-more-detailed-3d-picture-fetal-health-0915</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202508/MIT-csail-3d-fetus.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr" id="docs-internal-guid-9f9513be-7fff-adbc-e573-265de5f3d249"&gt;For pregnant women, ultrasounds are an informative (and sometimes necessary) procedure. They typically produce two-dimensional black-and-white scans of fetuses that can reveal key insights, including biological sex, approximate size, and abnormalities like heart issues or cleft lip. If your doctor wants a closer look, they may use magnetic resonance imaging (MRI), which uses magnetic fields to capture images that can be combined to create a 3D view of the fetus.&lt;/p&gt;&lt;p dir="ltr"&gt;MRIs aren’t a catch-all, though; the 3D scans are difficult for doctors to interpret well enough to diagnose problems because our visual system is not accustomed to processing 3D volumetric scans (in other words, a wrap-around look that also shows us the inner structures of a subject). Enter machine learning, which could help model a fetus’s development more clearly and accurately from data — although no such algorithm has been able to model their somewhat random movements and various body shapes.&lt;/p&gt;&lt;p dir="ltr"&gt;That is, until a new approach called “Fetal SMPL” from MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL), Boston Children’s Hospital (BCH), and Harvard Medical School presented clinicians with a more detailed picture of fetal health. It was adapted from “SMPL” (Skinned Multi-Person Linear model), a 3D model developed in computer graphics to capture adult body shapes and poses, as a way to represent fetal body shapes and poses accurately. Fetal SMPL was then trained on 20,000 MRI volumes to predict the location and size of a fetus and create sculpture-like 3D representations. Inside each model is a skeleton with 23 articulated joints called a “kinematic tree,” which the system uses to pose and move like the fetuses it saw during training.&lt;/p&gt;&lt;p&gt;The extensive, real-world scans that Fetal SMPL learned from helped it develop pinpoint accuracy. Imagine stepping into a stranger’s footprint while blindfolded, and not only does it fit perfectly, but you correctly guess what shoe they wore — similarly, the tool closely matched the position and size of fetuses in MRI frames it hadn’t seen before. Fetal SMPL was only misaligned by an average of about 3.1 millimeters, a gap smaller than a single grain of rice.&lt;/p&gt;&lt;p&gt;The approach could enable doctors to precisely measure things like the size of a baby’s head or abdomen and compare these metrics with healthy fetuses at the same age. Fetal SMPL has demonstrated its clinical potential in early tests, where it achieved accurate alignment results on a small group of real-world scans.&lt;/p&gt;&lt;p dir="ltr"&gt;“It can be challenging to estimate the shape and pose of a fetus because they’re crammed into the tight confines of the uterus,” says lead author, MIT PhD student, and CSAIL researcher Yingcheng Liu SM ’21. “Our approach overcomes this challenge using a system of interconnected bones under the surface of the 3D model, which represent the fetal body and its motions realistically. Then, it relies on a coordinate descent algorithm to make a prediction, essentially alternating between guessing pose and shape from tricky data until it finds a reliable estimate.”&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;In utero&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Fetal SMPL was tested on shape and pose accuracy against the closest baseline the researchers could find: a system that models infant growth called&amp;nbsp;“SMIL.” Since babies out of the womb are larger than fetuses, the team shrank those models by 75 percent to level the playing field.&lt;/p&gt;&lt;p&gt;The system outperformed this baseline on a dataset of fetal MRIs between the gestational ages of 24 and 37 weeks taken at Boston Children’s Hospital. Fetal SMPL was able to recreate real scans more precisely, as its models closely lined up with real MRIs.&lt;/p&gt;&lt;p dir="ltr"&gt;The method was efficient at lining up their models to images, only needing three iterations to arrive at a reasonable alignment. In an experiment that counted how many incorrect guesses Fetal SMPL had made before arriving at a final estimate, its accuracy plateaued from the fourth step onward.&lt;/p&gt;&lt;p&gt;The researchers have just begun testing their system in the real world, where it produced similarly accurate models in initial clinical tests. While these results are promising, the team notes that they’ll need to apply their results to larger populations, different gestational ages, and a variety of disease cases to better understand the system’s capabilities.&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;Only skin deep&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;Liu also notes that their system only helps analyze what doctors can see on the surface of a fetus, since only bone-like structures lie beneath the skin of the models. To better monitor babies’ internal health, such as liver, lung, and muscle development, the team intends to make their tool volumetric, modeling the fetus’s inner anatomy from scans. Such upgrades would make the models more human-like, but the current version of Fetal SMPL already presents a precise (and unique) upgrade to 3D fetal health analysis.&lt;/p&gt;&lt;p&gt;“This study introduces a method specifically designed for fetal MRI that effectively captures fetal movements, enhancing the assessment of fetal development and health,” says Kiho Im, Harvard Medical School associate professor of pediatrics and staff scientist in the Division of Newborn Medicine at BCH’s Fetal-Neonatal Neuroimaging and Developmental Science Center. Im, who was not involved with the paper, adds that this approach “will not only improve the diagnostic utility of fetal MRI, but also provide insights into the early functional development of the fetal brain in relation to body movements.”&lt;/p&gt;&lt;p dir="ltr"&gt;“This work reaches a pioneering milestone by extending parametric surface human body models for the earliest shapes of human life: fetuses,” says Sergi Pujades, an associate professor at University Grenoble Alpes, who wasn’t involved in the research. “It allows us to detangle the shape and motion of a human, which has already proven to be key in understanding how adult body shape relates to metabolic conditions and how infant motion relates to neurodevelopmental disorders. In addition, the fact that the fetal model stems from, and is compatible with, the adult (SMPL) and infant (SMIL) body models, will allow us to study human shape and pose evolution over long periods of time. This is an unprecedented opportunity to further quantify how human shape growth and motion are affected by different conditions.”&lt;/p&gt;&lt;p&gt;Liu wrote the paper with three CSAIL members: Peiqi Wang SM ’22, PhD ’25; MIT PhD student Sebastian Diaz; and senior author Polina Golland, the Sunlin and Priscilla Chou Professor of Electrical Engineering and Computer Science, a principal investigator in MIT CSAIL, and the leader of the Medical Vision Group. BCH assistant professor of pediatrics Esra Abaci Turk, Inria researcher Benjamin Billot, and Harvard Medical School professor of pediatrics and professor of radiology Patricia Ellen Grant are also authors on the paper. This work was supported, in part, by the National Institutes of Health and the MIT CSAIL-Wistron Program.&lt;/p&gt;&lt;p&gt;The researchers will present their work at the International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI) in September.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202508/MIT-csail-3d-fetus.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr" id="docs-internal-guid-9f9513be-7fff-adbc-e573-265de5f3d249"&gt;For pregnant women, ultrasounds are an informative (and sometimes necessary) procedure. They typically produce two-dimensional black-and-white scans of fetuses that can reveal key insights, including biological sex, approximate size, and abnormalities like heart issues or cleft lip. If your doctor wants a closer look, they may use magnetic resonance imaging (MRI), which uses magnetic fields to capture images that can be combined to create a 3D view of the fetus.&lt;/p&gt;&lt;p dir="ltr"&gt;MRIs aren’t a catch-all, though; the 3D scans are difficult for doctors to interpret well enough to diagnose problems because our visual system is not accustomed to processing 3D volumetric scans (in other words, a wrap-around look that also shows us the inner structures of a subject). Enter machine learning, which could help model a fetus’s development more clearly and accurately from data — although no such algorithm has been able to model their somewhat random movements and various body shapes.&lt;/p&gt;&lt;p dir="ltr"&gt;That is, until a new approach called “Fetal SMPL” from MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL), Boston Children’s Hospital (BCH), and Harvard Medical School presented clinicians with a more detailed picture of fetal health. It was adapted from “SMPL” (Skinned Multi-Person Linear model), a 3D model developed in computer graphics to capture adult body shapes and poses, as a way to represent fetal body shapes and poses accurately. Fetal SMPL was then trained on 20,000 MRI volumes to predict the location and size of a fetus and create sculpture-like 3D representations. Inside each model is a skeleton with 23 articulated joints called a “kinematic tree,” which the system uses to pose and move like the fetuses it saw during training.&lt;/p&gt;&lt;p&gt;The extensive, real-world scans that Fetal SMPL learned from helped it develop pinpoint accuracy. Imagine stepping into a stranger’s footprint while blindfolded, and not only does it fit perfectly, but you correctly guess what shoe they wore — similarly, the tool closely matched the position and size of fetuses in MRI frames it hadn’t seen before. Fetal SMPL was only misaligned by an average of about 3.1 millimeters, a gap smaller than a single grain of rice.&lt;/p&gt;&lt;p&gt;The approach could enable doctors to precisely measure things like the size of a baby’s head or abdomen and compare these metrics with healthy fetuses at the same age. Fetal SMPL has demonstrated its clinical potential in early tests, where it achieved accurate alignment results on a small group of real-world scans.&lt;/p&gt;&lt;p dir="ltr"&gt;“It can be challenging to estimate the shape and pose of a fetus because they’re crammed into the tight confines of the uterus,” says lead author, MIT PhD student, and CSAIL researcher Yingcheng Liu SM ’21. “Our approach overcomes this challenge using a system of interconnected bones under the surface of the 3D model, which represent the fetal body and its motions realistically. Then, it relies on a coordinate descent algorithm to make a prediction, essentially alternating between guessing pose and shape from tricky data until it finds a reliable estimate.”&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;In utero&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Fetal SMPL was tested on shape and pose accuracy against the closest baseline the researchers could find: a system that models infant growth called&amp;nbsp;“SMIL.” Since babies out of the womb are larger than fetuses, the team shrank those models by 75 percent to level the playing field.&lt;/p&gt;&lt;p&gt;The system outperformed this baseline on a dataset of fetal MRIs between the gestational ages of 24 and 37 weeks taken at Boston Children’s Hospital. Fetal SMPL was able to recreate real scans more precisely, as its models closely lined up with real MRIs.&lt;/p&gt;&lt;p dir="ltr"&gt;The method was efficient at lining up their models to images, only needing three iterations to arrive at a reasonable alignment. In an experiment that counted how many incorrect guesses Fetal SMPL had made before arriving at a final estimate, its accuracy plateaued from the fourth step onward.&lt;/p&gt;&lt;p&gt;The researchers have just begun testing their system in the real world, where it produced similarly accurate models in initial clinical tests. While these results are promising, the team notes that they’ll need to apply their results to larger populations, different gestational ages, and a variety of disease cases to better understand the system’s capabilities.&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;Only skin deep&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;Liu also notes that their system only helps analyze what doctors can see on the surface of a fetus, since only bone-like structures lie beneath the skin of the models. To better monitor babies’ internal health, such as liver, lung, and muscle development, the team intends to make their tool volumetric, modeling the fetus’s inner anatomy from scans. Such upgrades would make the models more human-like, but the current version of Fetal SMPL already presents a precise (and unique) upgrade to 3D fetal health analysis.&lt;/p&gt;&lt;p&gt;“This study introduces a method specifically designed for fetal MRI that effectively captures fetal movements, enhancing the assessment of fetal development and health,” says Kiho Im, Harvard Medical School associate professor of pediatrics and staff scientist in the Division of Newborn Medicine at BCH’s Fetal-Neonatal Neuroimaging and Developmental Science Center. Im, who was not involved with the paper, adds that this approach “will not only improve the diagnostic utility of fetal MRI, but also provide insights into the early functional development of the fetal brain in relation to body movements.”&lt;/p&gt;&lt;p dir="ltr"&gt;“This work reaches a pioneering milestone by extending parametric surface human body models for the earliest shapes of human life: fetuses,” says Sergi Pujades, an associate professor at University Grenoble Alpes, who wasn’t involved in the research. “It allows us to detangle the shape and motion of a human, which has already proven to be key in understanding how adult body shape relates to metabolic conditions and how infant motion relates to neurodevelopmental disorders. In addition, the fact that the fetal model stems from, and is compatible with, the adult (SMPL) and infant (SMIL) body models, will allow us to study human shape and pose evolution over long periods of time. This is an unprecedented opportunity to further quantify how human shape growth and motion are affected by different conditions.”&lt;/p&gt;&lt;p&gt;Liu wrote the paper with three CSAIL members: Peiqi Wang SM ’22, PhD ’25; MIT PhD student Sebastian Diaz; and senior author Polina Golland, the Sunlin and Priscilla Chou Professor of Electrical Engineering and Computer Science, a principal investigator in MIT CSAIL, and the leader of the Medical Vision Group. BCH assistant professor of pediatrics Esra Abaci Turk, Inria researcher Benjamin Billot, and Harvard Medical School professor of pediatrics and professor of radiology Patricia Ellen Grant are also authors on the paper. This work was supported, in part, by the National Institutes of Health and the MIT CSAIL-Wistron Program.&lt;/p&gt;&lt;p&gt;The researchers will present their work at the International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI) in September.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/machine-learning-tool-gives-doctors-more-detailed-3d-picture-fetal-health-0915</guid><pubDate>Mon, 15 Sep 2025 14:00:00 +0000</pubDate></item><item><title>Mythos AI and lomarlabs deploy sea-pilot AI assistance (AI News)</title><link>https://www.artificialintelligence-news.com/news/apas-radar-sea-trial-tests-ai-ocean-transport/</link><description>&lt;p&gt;American maritime technology company Mythos AI has completed the installation of its Advanced Pilot Assistance System (APAS) aboard the vessel CB Pacific, a chemical cargo ship owned by CB Tankers.&lt;/p&gt;&lt;p&gt;The APAS project is designed to manage navigation at sea. Unlike most traditional systems in this space that depend largely on machine vision, APAS uses a radar-first approach, in combination with other sensing technologies. It connects directly to a ship’s radar and streamlines data so it can be used to alert a ship’s human crew if necessary during a journey. APAS is designed to support mariners, reduce cognitive load, and improve situational awareness, yet keep human judgement at the centre of navigation.&lt;/p&gt;&lt;p&gt;Geoff Douglass, CEO of Mythos AI, said, “Our goal isn’t to replace the crew. It’s to equip them with next-generation capabilities. By integrating our proprietary radar perception, machine vision, and intelligent alerting with the vessel’s dynamics, APAS transforms complex situations into clear, actionable decisions, enhancing safety and operational resilience.”&lt;/p&gt;&lt;p&gt;The CB Pacific was chosen for testing due to its predictable routes and reliable Furuno radar. The trial follows the first installation of APAS on a Southern Devall towboat on the Mississippi River in August 2025, and will be a year-long experiment aiming to introduce next-gen bridge intelligence to commercial shipping.&lt;/p&gt;&lt;p&gt;“Partnering with lomarlabs and CB Tankers enables APAS to capture and retain the expertise of master mariners and the navigational norms of ports worldwide […] We are validating performance at scale and laying the groundwork for broader fleet-wide adoption,” Douglass said.&lt;/p&gt;&lt;p&gt;The APAS system’s year-long trial will help ensure it functions safely and effectively in real-world conditions, and will check it can follow international regulations compliant with the COLREG (Convention on the International Regulations for Preventing Collisions at Sea).&lt;/p&gt;&lt;p&gt;CB Tankers is part of the Lomar group of companies. Managing director of lomarlabs, Stylianos Papageorgiou, said progress in maritime AI only comes from operational testing. “Real innovation doesn’t happen in pitch decks. It happens in real-time operations, port calls, dry docks, and sea trials.”&lt;/p&gt;&lt;p&gt;With increased interest from the defence sector, the APAS project represents a step toward adoption of AI-driven navigation systems in commercial and strategic maritime operations.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “The M/T Carry on the Baltic Sea” by Mustang Joe is marked with CC0 1.0.)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;American maritime technology company Mythos AI has completed the installation of its Advanced Pilot Assistance System (APAS) aboard the vessel CB Pacific, a chemical cargo ship owned by CB Tankers.&lt;/p&gt;&lt;p&gt;The APAS project is designed to manage navigation at sea. Unlike most traditional systems in this space that depend largely on machine vision, APAS uses a radar-first approach, in combination with other sensing technologies. It connects directly to a ship’s radar and streamlines data so it can be used to alert a ship’s human crew if necessary during a journey. APAS is designed to support mariners, reduce cognitive load, and improve situational awareness, yet keep human judgement at the centre of navigation.&lt;/p&gt;&lt;p&gt;Geoff Douglass, CEO of Mythos AI, said, “Our goal isn’t to replace the crew. It’s to equip them with next-generation capabilities. By integrating our proprietary radar perception, machine vision, and intelligent alerting with the vessel’s dynamics, APAS transforms complex situations into clear, actionable decisions, enhancing safety and operational resilience.”&lt;/p&gt;&lt;p&gt;The CB Pacific was chosen for testing due to its predictable routes and reliable Furuno radar. The trial follows the first installation of APAS on a Southern Devall towboat on the Mississippi River in August 2025, and will be a year-long experiment aiming to introduce next-gen bridge intelligence to commercial shipping.&lt;/p&gt;&lt;p&gt;“Partnering with lomarlabs and CB Tankers enables APAS to capture and retain the expertise of master mariners and the navigational norms of ports worldwide […] We are validating performance at scale and laying the groundwork for broader fleet-wide adoption,” Douglass said.&lt;/p&gt;&lt;p&gt;The APAS system’s year-long trial will help ensure it functions safely and effectively in real-world conditions, and will check it can follow international regulations compliant with the COLREG (Convention on the International Regulations for Preventing Collisions at Sea).&lt;/p&gt;&lt;p&gt;CB Tankers is part of the Lomar group of companies. Managing director of lomarlabs, Stylianos Papageorgiou, said progress in maritime AI only comes from operational testing. “Real innovation doesn’t happen in pitch decks. It happens in real-time operations, port calls, dry docks, and sea trials.”&lt;/p&gt;&lt;p&gt;With increased interest from the defence sector, the APAS project represents a step toward adoption of AI-driven navigation systems in commercial and strategic maritime operations.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “The M/T Carry on the Baltic Sea” by Mustang Joe is marked with CC0 1.0.)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/apas-radar-sea-trial-tests-ai-ocean-transport/</guid><pubDate>Mon, 15 Sep 2025 14:05:48 +0000</pubDate></item><item><title>By popular demand: 10 extra exhibit tables open at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/15/by-popular-demand-10-extra-exhibit-tables-open-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Back by overwhelming demand, we’ve added 10 more exhibit tables to &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; — this will be the final release before they sell out. This is your last chance to showcase your company in front of 10,000+ founders, VCs, and tech innovators from October 27-29 at San Francisco’s Moscone West.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Disrupt isn’t just a tech conference — it’s a launchpad. Startups of all stages come here to meet their first investors, land their biggest partnerships, and spark ideas that take them to the next level. In 2025, that launchpad could be your exhibit table. &lt;strong&gt;Books yours here.&lt;/strong&gt;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Early Stage 2024 Fidelity exhibit" class="wp-image-2987335" height="453" src="https://techcrunch.com/wp-content/uploads/2025/03/Early-Stage-2024-Fidelity-exhibit.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Halo Creative&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-why-you-can-t-miss-this-opportunity"&gt;Why you can’t miss this opportunity&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Visibility where it counts:&lt;/strong&gt; No table = no chance to showcase your product to thousands of investors, partners, and press walking through the heart of one of the largest tech conferences of the year.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Access to key decision-makers:&lt;/strong&gt; Without passes, your team misses direct engagement with high-level founders, investors, and enterprise leaders.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Brand amplification:&lt;/strong&gt; Without placement, you miss exposure across TechCrunch channels before, during, and after the event.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Smart investment:&lt;/strong&gt; For just $10,000, you unlock unmatched reach, networking, and lead-generation tools. Skipping this means leaving serious value on the table.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-s-included-with-your-table"&gt;What’s included with your table&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;A 6’ x 30” branded exhibit table in the high-traffic Expo Hall for all three days.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;10 team passes (5 Attendee, 5 Expo+).&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Featured branding across TechCrunch channels.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Access to press coverage, lead-gen tools, and exclusive founder data.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Shoutouts during key event moments and closing ceremonies.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Direct access to traction, investor interest, and game-changing conversations.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-book-yours-before-your-competitor-does"&gt;Book yours before your competitor does&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;These 10 tables won’t last — act now to own the spotlight, leads, and momentum. &lt;strong&gt;Book your exhibit table now&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 no anniversary" class="wp-image-3040972" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_Disrupt_General_Article_No-Anniversary-at-all_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Back by overwhelming demand, we’ve added 10 more exhibit tables to &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; — this will be the final release before they sell out. This is your last chance to showcase your company in front of 10,000+ founders, VCs, and tech innovators from October 27-29 at San Francisco’s Moscone West.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Disrupt isn’t just a tech conference — it’s a launchpad. Startups of all stages come here to meet their first investors, land their biggest partnerships, and spark ideas that take them to the next level. In 2025, that launchpad could be your exhibit table. &lt;strong&gt;Books yours here.&lt;/strong&gt;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Early Stage 2024 Fidelity exhibit" class="wp-image-2987335" height="453" src="https://techcrunch.com/wp-content/uploads/2025/03/Early-Stage-2024-Fidelity-exhibit.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Halo Creative&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-why-you-can-t-miss-this-opportunity"&gt;Why you can’t miss this opportunity&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Visibility where it counts:&lt;/strong&gt; No table = no chance to showcase your product to thousands of investors, partners, and press walking through the heart of one of the largest tech conferences of the year.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Access to key decision-makers:&lt;/strong&gt; Without passes, your team misses direct engagement with high-level founders, investors, and enterprise leaders.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Brand amplification:&lt;/strong&gt; Without placement, you miss exposure across TechCrunch channels before, during, and after the event.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Smart investment:&lt;/strong&gt; For just $10,000, you unlock unmatched reach, networking, and lead-generation tools. Skipping this means leaving serious value on the table.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-s-included-with-your-table"&gt;What’s included with your table&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;A 6’ x 30” branded exhibit table in the high-traffic Expo Hall for all three days.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;10 team passes (5 Attendee, 5 Expo+).&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Featured branding across TechCrunch channels.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Access to press coverage, lead-gen tools, and exclusive founder data.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Shoutouts during key event moments and closing ceremonies.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Direct access to traction, investor interest, and game-changing conversations.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-book-yours-before-your-competitor-does"&gt;Book yours before your competitor does&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;These 10 tables won’t last — act now to own the spotlight, leads, and momentum. &lt;strong&gt;Book your exhibit table now&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 no anniversary" class="wp-image-3040972" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_Disrupt_General_Article_No-Anniversary-at-all_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/15/by-popular-demand-10-extra-exhibit-tables-open-at-techcrunch-disrupt-2025/</guid><pubDate>Mon, 15 Sep 2025 14:30:00 +0000</pubDate></item><item><title>Time’s running out to volunteer at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/15/times-running-out-to-volunteer-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Every year, &lt;strong&gt;TechCrunch Disrupt&lt;/strong&gt; runs on innovation — and the support of our incredible volunteers. If you’ve ever dreamed of a front-row seat to the startup world, this is your chance. But heads-up: &lt;strong&gt;volunteer applications close September 30&lt;/strong&gt;, and the clock is ticking.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-why-volunteer-because-access-is-everything"&gt;Why volunteer? Because access is everything&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Whether you’re a future founder, marketer, engineer, or event producer, volunteering at Disrupt offers a behind-the-scenes look at what it takes to run one of the most iconic startup conferences on the planet. You’ll gain experience, build your network, and score a &lt;strong&gt;free pass to the full event&lt;/strong&gt; — just for pitching in.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;TechCrunch Disrupt 2025 takes place October 27–29 at Moscone West in San Francisco, and we’re looking for motivated, curious, and energetic volunteers to help make it all happen.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Spots are filling quickly — &lt;strong&gt;sign up to volunteer now&lt;/strong&gt; before it’s too late.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 no anniversary" class="wp-image-3040972" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_Disrupt_General_Article_No-Anniversary-at-all_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Every year, &lt;strong&gt;TechCrunch Disrupt&lt;/strong&gt; runs on innovation — and the support of our incredible volunteers. If you’ve ever dreamed of a front-row seat to the startup world, this is your chance. But heads-up: &lt;strong&gt;volunteer applications close September 30&lt;/strong&gt;, and the clock is ticking.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-why-volunteer-because-access-is-everything"&gt;Why volunteer? Because access is everything&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Whether you’re a future founder, marketer, engineer, or event producer, volunteering at Disrupt offers a behind-the-scenes look at what it takes to run one of the most iconic startup conferences on the planet. You’ll gain experience, build your network, and score a &lt;strong&gt;free pass to the full event&lt;/strong&gt; — just for pitching in.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;TechCrunch Disrupt 2025 takes place October 27–29 at Moscone West in San Francisco, and we’re looking for motivated, curious, and energetic volunteers to help make it all happen.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Spots are filling quickly — &lt;strong&gt;sign up to volunteer now&lt;/strong&gt; before it’s too late.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 no anniversary" class="wp-image-3040972" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_Disrupt_General_Article_No-Anniversary-at-all_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/15/times-running-out-to-volunteer-at-techcrunch-disrupt-2025/</guid><pubDate>Mon, 15 Sep 2025 16:05:17 +0000</pubDate></item><item><title>China says Nvidia violated antitrust regulations (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/15/china-says-nvidia-violated-antitrust-regulations/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/GettyImages-2216028442.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Trade tensions between China and the U.S. regarding semiconductors just got even more strained.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Monday, China’s State Administration for Market Regulation ruled that semiconductor giant Nvidia was in violation of the country’s antitrust regulations, as first reported by Bloomberg. The ruling was in reference to Nvidia’s 2020 acquisition of Mellanox Technologies, a computer networking supplier, for $7 billion.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;An Nvidia spokesperson supplied the following statement: “We comply with the law in all respects. We will continue to cooperate with all relevant government agencies as they evaluate the impact of export controls on competition in the commercial markets.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;China didn’t announce any consequences tied to its findings and will continue to investigate. Still, the ruling is likely to cast a pall over ongoing tariff negotiations between the U.S. and China, currently taking place in Madrid. While these trade discussions aren’t specifically about semiconductors, the question of Chinese access to Nvidia chips is a major point of contention between the two regimes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The outgoing Biden administration announced its AI Diffusion Rule back in January that was meant to restrict U.S.-made AI chips to many countries, with further restrictions specifically for China and other adversaries.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the U.S. Department of Commerce formally repealed Biden’s AI rule in May, the future of AI chip exports to China remains in flux. The Trump administration slapped licensing agreements on chips heading to China in April. A few months later, in July, these companies were given the green light to start selling these chips again.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Just a few weeks after that the country struck a deal requiring companies selling chips to China to give the U.S. a 15% cut of the revenue made on those sales. China has discouraged firms from buying Nvidia chips and, as of a recent earnings call, none of the company’s chips have made it through the new export process.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/GettyImages-2216028442.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Trade tensions between China and the U.S. regarding semiconductors just got even more strained.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Monday, China’s State Administration for Market Regulation ruled that semiconductor giant Nvidia was in violation of the country’s antitrust regulations, as first reported by Bloomberg. The ruling was in reference to Nvidia’s 2020 acquisition of Mellanox Technologies, a computer networking supplier, for $7 billion.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;An Nvidia spokesperson supplied the following statement: “We comply with the law in all respects. We will continue to cooperate with all relevant government agencies as they evaluate the impact of export controls on competition in the commercial markets.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;China didn’t announce any consequences tied to its findings and will continue to investigate. Still, the ruling is likely to cast a pall over ongoing tariff negotiations between the U.S. and China, currently taking place in Madrid. While these trade discussions aren’t specifically about semiconductors, the question of Chinese access to Nvidia chips is a major point of contention between the two regimes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The outgoing Biden administration announced its AI Diffusion Rule back in January that was meant to restrict U.S.-made AI chips to many countries, with further restrictions specifically for China and other adversaries.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the U.S. Department of Commerce formally repealed Biden’s AI rule in May, the future of AI chip exports to China remains in flux. The Trump administration slapped licensing agreements on chips heading to China in April. A few months later, in July, these companies were given the green light to start selling these chips again.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Just a few weeks after that the country struck a deal requiring companies selling chips to China to give the U.S. a 15% cut of the revenue made on those sales. China has discouraged firms from buying Nvidia chips and, as of a recent earnings call, none of the company’s chips have made it through the new export process.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/15/china-says-nvidia-violated-antitrust-regulations/</guid><pubDate>Mon, 15 Sep 2025 16:44:02 +0000</pubDate></item><item><title>OpenAI upgrades Codex with a new version of GPT-5 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/15/openai-upgrades-codex-with-a-new-version-of-gpt-5/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI announced Monday that it’s releasing a new version of GPT-5 to its AI coding agent, Codex. The company says its new model, called GPT-5-Codex, spends its “thinking” time more dynamically than previous models and could spend anywhere from a few seconds to seven hours on a coding task. As a result, it performs better on agentic coding benchmarks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new model is now rolling out in Codex products — which can be accessed via a terminal, IDE, GitHub, or ChatGPT — to all ChatGPT Plus, Pro, Business, Edu, and Enterprise users. OpenAI says it plans to make the model available to API customers in the future.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The update is part of OpenAI’s effort to make Codex more competitive with other AI coding products, such as Claude Code, Anysphere’s Cursor, or Microsoft’s GitHub Copilot. The market for AI coding tools has become much more crowded in the last year as a result of intense user demand. Cursor surpassed $500 million in ARR earlier in 2025, and Windsurf, a similar code editor, was the subject of a chaotic acquisition attempt that saw its team split between Google and Cognition.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says that GPT-5-Codex outperforms GPT-5 on SWE-bench Verified, a benchmark measuring agentic coding abilities, as well as a benchmark measuring performance on code refactoring tasks from large, established repositories.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3045900" height="455" src="https://techcrunch.com/wp-content/uploads/2025/09/Screenshot-2025-09-15-at-9.50.01AM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;OpenAI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company also says it trained GPT-5-Codex for conducting code reviews and asked experience software engineers to evaluate the model’s review comments. The engineers reportedly found GPT-5-Codex to submit fewer incorrect comments, while adding more “high-impact comments.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a briefing, OpenAI’s Codex product lead Alexander Embiricos said that much of the increased performance was thanks to GPT-5-Codex’s dynamic “thinking abilities.” Users may be familiar with GPT-5’s router in ChatGPT, which directs queries to different models based on the complexity of a task. Embiricos said GPT-5-Codex works similarly but has no router under the hood and can adjust for how long to work on a task in real time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Embiricos says this is an advantage compared to a router, which decides how much computational power and time to use on a problem at the outset. Instead, GPT-5-Codex can decide five minutes into a problem that it needs to spend another hour. Embiricos said he’s seen the model take upward of seven hours in some cases.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI announced Monday that it’s releasing a new version of GPT-5 to its AI coding agent, Codex. The company says its new model, called GPT-5-Codex, spends its “thinking” time more dynamically than previous models and could spend anywhere from a few seconds to seven hours on a coding task. As a result, it performs better on agentic coding benchmarks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new model is now rolling out in Codex products — which can be accessed via a terminal, IDE, GitHub, or ChatGPT — to all ChatGPT Plus, Pro, Business, Edu, and Enterprise users. OpenAI says it plans to make the model available to API customers in the future.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The update is part of OpenAI’s effort to make Codex more competitive with other AI coding products, such as Claude Code, Anysphere’s Cursor, or Microsoft’s GitHub Copilot. The market for AI coding tools has become much more crowded in the last year as a result of intense user demand. Cursor surpassed $500 million in ARR earlier in 2025, and Windsurf, a similar code editor, was the subject of a chaotic acquisition attempt that saw its team split between Google and Cognition.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says that GPT-5-Codex outperforms GPT-5 on SWE-bench Verified, a benchmark measuring agentic coding abilities, as well as a benchmark measuring performance on code refactoring tasks from large, established repositories.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3045900" height="455" src="https://techcrunch.com/wp-content/uploads/2025/09/Screenshot-2025-09-15-at-9.50.01AM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;OpenAI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company also says it trained GPT-5-Codex for conducting code reviews and asked experience software engineers to evaluate the model’s review comments. The engineers reportedly found GPT-5-Codex to submit fewer incorrect comments, while adding more “high-impact comments.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a briefing, OpenAI’s Codex product lead Alexander Embiricos said that much of the increased performance was thanks to GPT-5-Codex’s dynamic “thinking abilities.” Users may be familiar with GPT-5’s router in ChatGPT, which directs queries to different models based on the complexity of a task. Embiricos said GPT-5-Codex works similarly but has no router under the hood and can adjust for how long to work on a task in real time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Embiricos says this is an advantage compared to a router, which decides how much computational power and time to use on a problem at the outset. Instead, GPT-5-Codex can decide five minutes into a problem that it needs to spend another hour. Embiricos said he’s seen the model take upward of seven hours in some cases.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/15/openai-upgrades-codex-with-a-new-version-of-gpt-5/</guid><pubDate>Mon, 15 Sep 2025 17:03:40 +0000</pubDate></item><item><title>Inside the shift at Disrupt: Building community and scaling in the AI era (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/15/on-stage-at-techcrunch-disrupt-2025-how-ai-is-forcing-late-stage-startups-to-rewire-gtm-or-be-left-behind/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;At &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, taking place October 27–29 in San Francisco, industry leaders will explore how founders can build lasting companies while navigating rapid shifts in AI, markets, and consumer behavior. Catch this dynamic panel on the &lt;strong&gt;Going Public Stage&lt;/strong&gt;, where three seasoned leaders will explore how AI is transforming go-to-market (GTM) strategies from the inside out.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Nirav Tolia, Jane Alexander, Vanessa Larco" class="wp-image-3029389" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/TC25_Tolia-Alexander-Larco-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-meet-the-speakers"&gt;Meet the speakers&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;&lt;strong&gt;Nirav Tolia&lt;/strong&gt;&lt;/strong&gt;, CEO, president, and co-founder of &lt;strong&gt; Nextdoor&lt;/strong&gt;, leads one of the most recognized community platforms in tech. He previously co-founded Epinions.com, served as COO at Shopping.com, and is non-executive chair at Hedosophia.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;&lt;strong&gt;Jane Alexander&lt;/strong&gt;&lt;/strong&gt;, partner at &lt;strong&gt;CapitalG&lt;/strong&gt;, brings more than 15 years of experience scaling GTM teams. She was previously CMO at Carta and held leadership roles at Salesforce and RelateIQ.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;&lt;strong&gt;Vanessa Larco&lt;/strong&gt;&lt;/strong&gt;, co-founder of Premise and former partner at NEA, combines product leadership and investing experience to help startups grow efficiently and strategically as AI reshapes market opportunities.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-unlock-insights-unlock-savings-for-disrupt-2025"&gt;Unlock insights, unlock savings for Disrupt 2025&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Buy your tickets now&lt;/strong&gt; to join this conversation — &lt;strong&gt;and more than 200 others&lt;/strong&gt; — at the premier gathering for startups and investors. Register now for TechCrunch Disrupt 2025 and save up to $668, available through September 26. Prices increase September 27.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;At &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, taking place October 27–29 in San Francisco, industry leaders will explore how founders can build lasting companies while navigating rapid shifts in AI, markets, and consumer behavior. Catch this dynamic panel on the &lt;strong&gt;Going Public Stage&lt;/strong&gt;, where three seasoned leaders will explore how AI is transforming go-to-market (GTM) strategies from the inside out.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Nirav Tolia, Jane Alexander, Vanessa Larco" class="wp-image-3029389" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/TC25_Tolia-Alexander-Larco-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-meet-the-speakers"&gt;Meet the speakers&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;&lt;strong&gt;Nirav Tolia&lt;/strong&gt;&lt;/strong&gt;, CEO, president, and co-founder of &lt;strong&gt; Nextdoor&lt;/strong&gt;, leads one of the most recognized community platforms in tech. He previously co-founded Epinions.com, served as COO at Shopping.com, and is non-executive chair at Hedosophia.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;&lt;strong&gt;Jane Alexander&lt;/strong&gt;&lt;/strong&gt;, partner at &lt;strong&gt;CapitalG&lt;/strong&gt;, brings more than 15 years of experience scaling GTM teams. She was previously CMO at Carta and held leadership roles at Salesforce and RelateIQ.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;&lt;strong&gt;Vanessa Larco&lt;/strong&gt;&lt;/strong&gt;, co-founder of Premise and former partner at NEA, combines product leadership and investing experience to help startups grow efficiently and strategically as AI reshapes market opportunities.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-unlock-insights-unlock-savings-for-disrupt-2025"&gt;Unlock insights, unlock savings for Disrupt 2025&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Buy your tickets now&lt;/strong&gt; to join this conversation — &lt;strong&gt;and more than 200 others&lt;/strong&gt; — at the premier gathering for startups and investors. Register now for TechCrunch Disrupt 2025 and save up to $668, available through September 26. Prices increase September 27.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/15/on-stage-at-techcrunch-disrupt-2025-how-ai-is-forcing-late-stage-startups-to-rewire-gtm-or-be-left-behind/</guid><pubDate>Mon, 15 Sep 2025 17:15:00 +0000</pubDate></item><item><title>[NEW] The 9 most sought-after startups from YC Demo Day (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/15/the-9-most-sought-after-startups-from-yc-demo-day/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/09/yc-2022-fall-1-e1662566861873.jpg?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Y Combinator hosted its Summer 2025 Demo Day last week, showcasing the latest batch of over 160 startups.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As with recent batches, the majority of startups presented AI-centric solutions. However, a clear evolution was evident. Instead of&amp;nbsp; “AI-powered” products, many companies are now building AI agents or the infrastructure and tools needed to develop them. For instance, this batch had a flurry of voice AI solutions and new businesses focused on helping others monetize the “AI economy” with ads and marketing tools.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;We spoke with a handful of YC-focused&amp;nbsp; investors to learn which startups they found most interesting and which generated the highest investment demand.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Below are the most frequently mentioned ones:&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;Stripe for AI startups&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;Many AI startups use complex pricing models that often blend a flat subscription fee per seat with usage-based charges, credits, and various add-on costs. Managing complex AI pricing on Stripe is a time-consuming, manual process. That’s why Autumn developed an open-source infrastructure that simplifies Stripe integration for AI startups. The company says its technology is already used by hundreds of AI apps and 40 YC startups. Given Stripe’s dominance in payments and the explosive growth of the AI market, could a specialized billing solution for AI be the next major fintech success story?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;Builds Vercel for AI agents&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;Just as Vercel helps developers deploy and host startups,&lt;strong&gt; &lt;/strong&gt;Dedalus Labs claims its platform automates the infrastructure for building AI agents, cutting hours of coding down to a few clicks. The company handles complex tasks like autoscaling and load balancing, which it says makes agent deployment fast and simple.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;crowdsource rankings of vibe coded designs&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;The ability of AI to rapidly generate a huge number of designs creates a new problem: figuring out which ones are actually good. Design Arena solves this by crowdsourcing rankings of AI-generated visuals, creating a feedback loop that forces AI models to improve. Large AI labs see value in training their models to generate better designs, as some of them are already Design Arena’s customers.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;Tech-enabled distributor for retailers in Southeast Asia&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;Getasap Asia was founded by Raghav Arora three years ago when he was just 14 years old. Since then, the startup that uses tech to deliver supplies to corner stores, restaurants and large supermarkets in Southeast Asia in under eight hours, has earned millions in revenue. Getasap Asia closed a round from General Catalyst, according to its website, and we are hearing that the startup’s valuation was among the highest in the whole batch.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;AI engineer that fixes bugs in production&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;Founded by a 20-year-old Pablo Hansen who last year earned a master’s degree in AI, Keystone is on a mission to reduce software breaks. The company’s AI finds and fixes bugs for clients like Lovable and has already turned down a seven-figure acquisition offer, Hansen said.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;AI matchmaker for female friends&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;While there isn’t a shortage of dating apps, RealRoots is tackling a different kind of loneliness. The company’s AI matchmaker, Lisa, interviews women and then organizes social experiences to connect them with compatible friends. While the AI part might be performative –&amp;nbsp; conversations with Lisa probably wouldn’t give RealRoots more insights about participants than written answers would – RealRoots may be on to something. Last month alone, the company generated $782,000 from 9,000 paying clients, its founders said.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;Automates insurance claims with AI&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;Solva’s AI automates the most routine tasks for insurance adjusters, from filling out complex claims to preventing improper payouts. Just ten weeks after launching, Solva has already amassed $245,000 in annual recurring revenue (ARR), a figure that has investors excited.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;counter-drone mini-missiles&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;With China reportedly amassing swarms of inexpensive drones, the U.S. military faces an urgent need for cost-effective counter-drone solutions. Perseus is developing just that: small missiles designed to shoot down drones at a fraction of the cost of existing systems. Multiple branches of the U.S. military have already invited the startup to demonstrate its solution, which could lead to hefty contracts.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does:&lt;/strong&gt; AI foreign language tutor&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;Apps like Duolingo have made language learning accessible and fun, but they often lack a key component of fluency: consistent conversation. Pingo solves this problem by allowing users to speak with its AI, which acts as a native speaker. The company’s unique approach is proving incredibly popular, with founders claiming it’s growing 70% monthly and earning $250,000 in monthly revenue.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/09/yc-2022-fall-1-e1662566861873.jpg?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Y Combinator hosted its Summer 2025 Demo Day last week, showcasing the latest batch of over 160 startups.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As with recent batches, the majority of startups presented AI-centric solutions. However, a clear evolution was evident. Instead of&amp;nbsp; “AI-powered” products, many companies are now building AI agents or the infrastructure and tools needed to develop them. For instance, this batch had a flurry of voice AI solutions and new businesses focused on helping others monetize the “AI economy” with ads and marketing tools.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;We spoke with a handful of YC-focused&amp;nbsp; investors to learn which startups they found most interesting and which generated the highest investment demand.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Below are the most frequently mentioned ones:&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;Stripe for AI startups&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;Many AI startups use complex pricing models that often blend a flat subscription fee per seat with usage-based charges, credits, and various add-on costs. Managing complex AI pricing on Stripe is a time-consuming, manual process. That’s why Autumn developed an open-source infrastructure that simplifies Stripe integration for AI startups. The company says its technology is already used by hundreds of AI apps and 40 YC startups. Given Stripe’s dominance in payments and the explosive growth of the AI market, could a specialized billing solution for AI be the next major fintech success story?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;Builds Vercel for AI agents&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;Just as Vercel helps developers deploy and host startups,&lt;strong&gt; &lt;/strong&gt;Dedalus Labs claims its platform automates the infrastructure for building AI agents, cutting hours of coding down to a few clicks. The company handles complex tasks like autoscaling and load balancing, which it says makes agent deployment fast and simple.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;crowdsource rankings of vibe coded designs&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;The ability of AI to rapidly generate a huge number of designs creates a new problem: figuring out which ones are actually good. Design Arena solves this by crowdsourcing rankings of AI-generated visuals, creating a feedback loop that forces AI models to improve. Large AI labs see value in training their models to generate better designs, as some of them are already Design Arena’s customers.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;Tech-enabled distributor for retailers in Southeast Asia&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;Getasap Asia was founded by Raghav Arora three years ago when he was just 14 years old. Since then, the startup that uses tech to deliver supplies to corner stores, restaurants and large supermarkets in Southeast Asia in under eight hours, has earned millions in revenue. Getasap Asia closed a round from General Catalyst, according to its website, and we are hearing that the startup’s valuation was among the highest in the whole batch.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;AI engineer that fixes bugs in production&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;Founded by a 20-year-old Pablo Hansen who last year earned a master’s degree in AI, Keystone is on a mission to reduce software breaks. The company’s AI finds and fixes bugs for clients like Lovable and has already turned down a seven-figure acquisition offer, Hansen said.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;AI matchmaker for female friends&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;While there isn’t a shortage of dating apps, RealRoots is tackling a different kind of loneliness. The company’s AI matchmaker, Lisa, interviews women and then organizes social experiences to connect them with compatible friends. While the AI part might be performative –&amp;nbsp; conversations with Lisa probably wouldn’t give RealRoots more insights about participants than written answers would – RealRoots may be on to something. Last month alone, the company generated $782,000 from 9,000 paying clients, its founders said.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;Automates insurance claims with AI&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;Solva’s AI automates the most routine tasks for insurance adjusters, from filling out complex claims to preventing improper payouts. Just ten weeks after launching, Solva has already amassed $245,000 in annual recurring revenue (ARR), a figure that has investors excited.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;counter-drone mini-missiles&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;With China reportedly amassing swarms of inexpensive drones, the U.S. military faces an urgent need for cost-effective counter-drone solutions. Perseus is developing just that: small missiles designed to shoot down drones at a fraction of the cost of existing systems. Multiple branches of the U.S. military have already invited the startup to demonstrate its solution, which could lead to hefty contracts.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does:&lt;/strong&gt; AI foreign language tutor&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;Apps like Duolingo have made language learning accessible and fun, but they often lack a key component of fluency: consistent conversation. Pingo solves this problem by allowing users to speak with its AI, which acts as a native speaker. The company’s unique approach is proving incredibly popular, with founders claiming it’s growing 70% monthly and earning $250,000 in monthly revenue.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/15/the-9-most-sought-after-startups-from-yc-demo-day/</guid><pubDate>Mon, 15 Sep 2025 20:11:51 +0000</pubDate></item><item><title>[NEW] What do people actually use ChatGPT for? OpenAI provides some numbers. (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/09/seven-things-we-learned-from-openais-first-study-on-chatgpt-usage/</link><description>&lt;article class="double-column h-entry post-2117130 post type-post status-publish format-standard has-post-thumbnail hentry category-ai tag-ai tag-chatgpt tag-demographics tag-measurement tag-openai tag-statistics tag-stats tag-users"&gt;
  
  &lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        New study breaks down what 700 million users do across 2.6 billion daily GPT messages.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-1397542920-1-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-1397542920-1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A live look at how OpenAI gathered its user data.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;As someone who writes about the AI industry relatively frequently for this site, there is one question that I find myself constantly asking and being asked in turn, in some form or another: What do you actually use large language models for?&lt;/p&gt;
&lt;p&gt;Today, OpenAI's Economic Research Team went a long way toward answering that question, on a population level, releasing a first-of-its-kind National Bureau of Economic Research working paper (in association with Harvard economist David Denning) detailing how people end up using ChatGPT across time and tasks. While other research has sought to estimate this kind of usage data using self-reported surveys, this is the first such paper with direct access to OpenAI's internal user data. As such, it gives us an unprecedented direct window into reliable usage stats for what is still the most popular application of LLMs by far.&lt;/p&gt;
&lt;p&gt;After digging through the dense 65-page paper, here are seven of the most interesting and/or surprising things we discovered about how people are using OpenAI today.&lt;/p&gt;
&lt;h2&gt;OpenAI is still growing at a rapid clip&lt;/h2&gt;
&lt;p&gt;We've known for a while that ChatGPT was popular, but this paper gives a direct look at just how big the LLM has been getting in recent months. Just measuring weekly active users on ChatGPT's consumer plans (i.e. Free, Plus, and Pro tiers), ChatGPT passed 100 million users in early 2024, climbed past 400 million users early this year, and currently can boast over 700 million users, or "nearly 10% of the world’s adult population," according to the company.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2117133 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="623" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph1.png" width="1084" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Line goes up... and faster than ever these days.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;OpenAI admits its measurements might be slightly off thanks to double-counting some logged-out users across multiple individual devices, as well as some logged-in users who maintain multiple accounts with different email addresses. And other reporting suggests only a small minority of those users are paying for the privilege of using ChatGPT just yet. Still, the vast number of people who are at least curious about trying OpenAI's LLM appears to still be on the steep upward part of its growth curve.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;All those new users are also leading to significant increases in just how many messages OpenAI processes daily, which has gone up from about 451 million in June 2024 to over 2.6 billion in June 2025 (averaged over a week near the end of the month). To give that number some context, Google announced in March that it averages 14 billion searches per day, and that's after decades as the undisputed leader in Internet search.&lt;/p&gt;
&lt;h2&gt;... but usage growth is plateauing among long-term users&lt;/h2&gt;
&lt;figure class="ars-wp-img-shortcode id-2117135 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="747" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph2.png" width="1084" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Newer users have driven almost all of the overall usage growth in ChatGPT in recent months.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;In addition to measuring overall user and usage growth, OpenAI's paper also breaks down total usage based on when its logged-in users first signed up for an account. These charts show just how much of ChatGPT's recent growth is reliant on new user acquisition, rather than older users increasing their daily usage.&lt;/p&gt;
&lt;p&gt;In terms of average daily message volume per individual long-term user, ChatGPT seems to have seen two distinct and sharp growth periods. The first runs roughly from September through December 2024, coinciding with the launch of the o1-preview and o1-mini models. Average per-user messaging on ChatGPT then largely plateaued until April, when the launch of the o3 and o4-mini models&amp;nbsp;caused another significant usage increase through June.&lt;/p&gt;
&lt;p&gt;Since June, though, per-user message rates for established ChatGPT users (those who signed up in the first quarter of 2025 or before) have been remarkably flat for three full months. The growth in overall usage during that last quarter has been entirely driven by newer users who have signed up since April, many of whom are still getting their feet wet with the LLM.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2117139 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="729" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph3.png" width="1072" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Average daily usage for long-term users has stopped growing in recent months, even as new users increase their ChatGPT message rates.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;We'll see if the recent tumultuous launch of the GPT-5 model leads to another significant increase in per-user message volume averages in the coming months. If it doesn't, then we may be seeing at least a temporary ceiling on how much use established ChatGPT users get out of the service in an average day.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;ChatGPT users are younger and were more male than the general population&lt;/h2&gt;
&lt;p&gt;While young people are generally more likely to embrace new technology, it's striking just how much of ChatGPT's user base is made up of our youngest demographic cohort. A full 46 percent of users who revealed their age in OpenAI's study sample were between the ages of 18 and 25. Add in the doubtless significant number of people under 18 using ChatGPT (who weren't included in the sample at all), and a decent majority of OpenAI's users probably aren't old enough to remember the 20th century firsthand.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2117140 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="492" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph4.png" width="1086" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      What started as mostly a boys' club has reached close to gender parity among ChatGPT users, based on gendered name analysis.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;OpenAI also estimated the likely gender split among a large sample of ChatGPT users by using Social Security data and the World Gender Name Registry's list of strongly masculine or feminine first names. When ChatGPT launched in late 2022, this analysis found roughly 80 percent of weekly active ChatGPT users were likely male. In late 2025, that ratio has flipped to a slight (52.4 percent) majority for likely female users.&lt;/p&gt;
&lt;h2&gt;People are using it for more than work&lt;/h2&gt;
&lt;p&gt;Despite all the talk about LLMs potentially revolutionizing the workplace, a significant majority of all ChatGPT use has nothing to do with business productivity, according to OpenAI. Non-work tasks (as identified by an LLM-based classifier) grew from about 53 percent of all ChatGPT messages in June of 2024 to 72.2 percent as of June 2025, according to the study.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2117142 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="776" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph5.png" width="1088" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      As time goes on, more and more ChatGPT usage is becoming non-work related.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Some of this might have to do with the exclusion of users in the Business, Enterprise, and Education subscription tiers from the data set. Still, the recent rise in non-work uses suggests that a lot of the newest ChatGPT users are doing so more for personal than for productivity reasons.&lt;/p&gt;
&lt;h2&gt;ChatGPT users need help with their writing&lt;/h2&gt;
&lt;p&gt;It's not that surprising that a lot of people use a large language model to help them with generating written words. But it's still striking the extent to which writing help is a major use of ChatGPT.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Across 1.1 million conversations dating from May 2024 to June 2025, a full 28 percent dealt with writing assistance in some form or another, OpenAI said. That rises to a whopping 42 percent for the subset of conversations tagged as work-related (by far the most popular work-related task), and a majority, 52 percent, of all work-related conversations from users with "management and business occupations."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2117145 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="675" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph8.png" width="1077" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A lot of ChatGPT use is people seeking help with their writing in some form.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;OpenAI is quick to point out, though, that many of these users aren't just relying on ChatGPT to generate emails or messages from whole cloth. The percent of all conversations studied involves users asking the LLM to "edit or critique" text, at 10.6 percent, vs. just 8 percent that deal with generating "personal writing or communication" from a prompt. Another 4.5 percent of all conversations deal with translating existing text to a new language, versus just 1.4 percent dealing with "writing fiction."&lt;/p&gt;
&lt;h2&gt;More people are using ChatGPT as an informational search engine&lt;/h2&gt;
&lt;p&gt;In June 2024, about 14 percent of all ChatGPT conversations were tagged as relating to "seeking information." By June 2025, that number had risen to 24.4 percent, slightly edging out writing-based prompts in the sample (which had fallen from roughly 35 percent of the 2024 sample).&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2117143 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="704" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph6.png" width="1072" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A growing number of ChatGPT conversations now deal with "seeking information" as you might do with a more traditional search engine.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;While recent GPT models seem to have gotten better about citing relevant sources to back up their information, OpenAI is no closer to solving the widespread confabulation problem that makes LLMs a dodgy tool for retrieving facts. Luckily, fewer people seem interested in using ChatGPT to seek information at work; that use case makes up just 13.5 percent of work-related ChatGPT conversations, well below the 40 percent that are writing-related.&lt;/p&gt;
&lt;h2&gt;A large number of workers are using ChatGPT to make decisions&lt;/h2&gt;
&lt;figure class="ars-wp-img-shortcode id-2117144 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="211" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph7.png" width="834" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Among work-related conversations, "making decisions and solving problems" is a relatively popular use for ChatGPT.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Getting help editing an email is one thing, but asking ChatGPT to help you make a business decision is another altogether. Across work-related conversations, OpenAI says a significant 14.9 percent dealt with "making decisions and solving problems." That's second only to "documenting and recording information" for work-related ChatGPT conversations among the dozens of "generalized work activity" categories classified by O*NET.&lt;/p&gt;
&lt;p&gt;This was true across all the different occupation types OpenAI looked at, which the company suggests means people are "using ChatGPT as an advisor or research assistant, not just a technology that performs job tasks directly."&lt;/p&gt;
&lt;h2&gt;And the rest...&lt;/h2&gt;
&lt;p&gt;Some other highly touted use cases for ChatGPT that represented a surprisingly small portion of the sampled conversations across OpenAI's study:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Multimedia (e.g., creating or retrieving an image): 6 percent&lt;/li&gt;
&lt;li&gt;Computer programming: 4.2 percent (though some of this use might be outsourced to the API)&lt;/li&gt;
&lt;li&gt;Creative ideation: 3.9 percent&lt;/li&gt;
&lt;li&gt;Mathematical calculation: 3 percent&lt;/li&gt;
&lt;li&gt;Relationships and personal reflection: 1.9 percent&lt;/li&gt;
&lt;li&gt;Game and roleplay: 0.4 percent&lt;/li&gt;
&lt;/ul&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
  &lt;/article&gt;&lt;article class="comment-pick"&gt;
          &lt;header&gt;
            &lt;span class="ars-avatar" style="color: #a7ffeb; background-color: #00796b;"&gt;&lt;span class="ars-avatar-letter"&gt;&lt;/span&gt;&lt;/span&gt;

            &lt;div class="text-base font-bold sm:text-xl"&gt;
              太鶏道
            &lt;/div&gt;
          &lt;/header&gt;

          &lt;div class="comments-pick-content"&gt;
            I use it quite a bit to assist with translation, and I can't ever see myself going back to things like Google Translate.  Google Translate has almost no ability to provide context, so the answers you get back with it are often suboptimal or even wrong.  It's a night and day difference for me.  However, as with other use cases, the LLM is most advantageous when you have a grasp on that language already, and can understand what the LLM spits out.
          &lt;/div&gt;

          &lt;div class="comments-pick-timestamp"&gt;
            
              &lt;time datetime="2025-09-15T20:52:11+00:00"&gt;September 15, 2025 at 8:52 pm&lt;/time&gt;
            
          &lt;/div&gt;
        &lt;/article&gt;</description><content:encoded>&lt;article class="double-column h-entry post-2117130 post type-post status-publish format-standard has-post-thumbnail hentry category-ai tag-ai tag-chatgpt tag-demographics tag-measurement tag-openai tag-statistics tag-stats tag-users"&gt;
  
  &lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        New study breaks down what 700 million users do across 2.6 billion daily GPT messages.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-1397542920-1-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-1397542920-1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A live look at how OpenAI gathered its user data.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;As someone who writes about the AI industry relatively frequently for this site, there is one question that I find myself constantly asking and being asked in turn, in some form or another: What do you actually use large language models for?&lt;/p&gt;
&lt;p&gt;Today, OpenAI's Economic Research Team went a long way toward answering that question, on a population level, releasing a first-of-its-kind National Bureau of Economic Research working paper (in association with Harvard economist David Denning) detailing how people end up using ChatGPT across time and tasks. While other research has sought to estimate this kind of usage data using self-reported surveys, this is the first such paper with direct access to OpenAI's internal user data. As such, it gives us an unprecedented direct window into reliable usage stats for what is still the most popular application of LLMs by far.&lt;/p&gt;
&lt;p&gt;After digging through the dense 65-page paper, here are seven of the most interesting and/or surprising things we discovered about how people are using OpenAI today.&lt;/p&gt;
&lt;h2&gt;OpenAI is still growing at a rapid clip&lt;/h2&gt;
&lt;p&gt;We've known for a while that ChatGPT was popular, but this paper gives a direct look at just how big the LLM has been getting in recent months. Just measuring weekly active users on ChatGPT's consumer plans (i.e. Free, Plus, and Pro tiers), ChatGPT passed 100 million users in early 2024, climbed past 400 million users early this year, and currently can boast over 700 million users, or "nearly 10% of the world’s adult population," according to the company.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2117133 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="623" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph1.png" width="1084" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Line goes up... and faster than ever these days.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;OpenAI admits its measurements might be slightly off thanks to double-counting some logged-out users across multiple individual devices, as well as some logged-in users who maintain multiple accounts with different email addresses. And other reporting suggests only a small minority of those users are paying for the privilege of using ChatGPT just yet. Still, the vast number of people who are at least curious about trying OpenAI's LLM appears to still be on the steep upward part of its growth curve.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;All those new users are also leading to significant increases in just how many messages OpenAI processes daily, which has gone up from about 451 million in June 2024 to over 2.6 billion in June 2025 (averaged over a week near the end of the month). To give that number some context, Google announced in March that it averages 14 billion searches per day, and that's after decades as the undisputed leader in Internet search.&lt;/p&gt;
&lt;h2&gt;... but usage growth is plateauing among long-term users&lt;/h2&gt;
&lt;figure class="ars-wp-img-shortcode id-2117135 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="747" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph2.png" width="1084" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Newer users have driven almost all of the overall usage growth in ChatGPT in recent months.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;In addition to measuring overall user and usage growth, OpenAI's paper also breaks down total usage based on when its logged-in users first signed up for an account. These charts show just how much of ChatGPT's recent growth is reliant on new user acquisition, rather than older users increasing their daily usage.&lt;/p&gt;
&lt;p&gt;In terms of average daily message volume per individual long-term user, ChatGPT seems to have seen two distinct and sharp growth periods. The first runs roughly from September through December 2024, coinciding with the launch of the o1-preview and o1-mini models. Average per-user messaging on ChatGPT then largely plateaued until April, when the launch of the o3 and o4-mini models&amp;nbsp;caused another significant usage increase through June.&lt;/p&gt;
&lt;p&gt;Since June, though, per-user message rates for established ChatGPT users (those who signed up in the first quarter of 2025 or before) have been remarkably flat for three full months. The growth in overall usage during that last quarter has been entirely driven by newer users who have signed up since April, many of whom are still getting their feet wet with the LLM.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2117139 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="729" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph3.png" width="1072" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Average daily usage for long-term users has stopped growing in recent months, even as new users increase their ChatGPT message rates.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;We'll see if the recent tumultuous launch of the GPT-5 model leads to another significant increase in per-user message volume averages in the coming months. If it doesn't, then we may be seeing at least a temporary ceiling on how much use established ChatGPT users get out of the service in an average day.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;ChatGPT users are younger and were more male than the general population&lt;/h2&gt;
&lt;p&gt;While young people are generally more likely to embrace new technology, it's striking just how much of ChatGPT's user base is made up of our youngest demographic cohort. A full 46 percent of users who revealed their age in OpenAI's study sample were between the ages of 18 and 25. Add in the doubtless significant number of people under 18 using ChatGPT (who weren't included in the sample at all), and a decent majority of OpenAI's users probably aren't old enough to remember the 20th century firsthand.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2117140 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="492" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph4.png" width="1086" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      What started as mostly a boys' club has reached close to gender parity among ChatGPT users, based on gendered name analysis.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;OpenAI also estimated the likely gender split among a large sample of ChatGPT users by using Social Security data and the World Gender Name Registry's list of strongly masculine or feminine first names. When ChatGPT launched in late 2022, this analysis found roughly 80 percent of weekly active ChatGPT users were likely male. In late 2025, that ratio has flipped to a slight (52.4 percent) majority for likely female users.&lt;/p&gt;
&lt;h2&gt;People are using it for more than work&lt;/h2&gt;
&lt;p&gt;Despite all the talk about LLMs potentially revolutionizing the workplace, a significant majority of all ChatGPT use has nothing to do with business productivity, according to OpenAI. Non-work tasks (as identified by an LLM-based classifier) grew from about 53 percent of all ChatGPT messages in June of 2024 to 72.2 percent as of June 2025, according to the study.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2117142 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="776" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph5.png" width="1088" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      As time goes on, more and more ChatGPT usage is becoming non-work related.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Some of this might have to do with the exclusion of users in the Business, Enterprise, and Education subscription tiers from the data set. Still, the recent rise in non-work uses suggests that a lot of the newest ChatGPT users are doing so more for personal than for productivity reasons.&lt;/p&gt;
&lt;h2&gt;ChatGPT users need help with their writing&lt;/h2&gt;
&lt;p&gt;It's not that surprising that a lot of people use a large language model to help them with generating written words. But it's still striking the extent to which writing help is a major use of ChatGPT.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Across 1.1 million conversations dating from May 2024 to June 2025, a full 28 percent dealt with writing assistance in some form or another, OpenAI said. That rises to a whopping 42 percent for the subset of conversations tagged as work-related (by far the most popular work-related task), and a majority, 52 percent, of all work-related conversations from users with "management and business occupations."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2117145 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="675" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph8.png" width="1077" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A lot of ChatGPT use is people seeking help with their writing in some form.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;OpenAI is quick to point out, though, that many of these users aren't just relying on ChatGPT to generate emails or messages from whole cloth. The percent of all conversations studied involves users asking the LLM to "edit or critique" text, at 10.6 percent, vs. just 8 percent that deal with generating "personal writing or communication" from a prompt. Another 4.5 percent of all conversations deal with translating existing text to a new language, versus just 1.4 percent dealing with "writing fiction."&lt;/p&gt;
&lt;h2&gt;More people are using ChatGPT as an informational search engine&lt;/h2&gt;
&lt;p&gt;In June 2024, about 14 percent of all ChatGPT conversations were tagged as relating to "seeking information." By June 2025, that number had risen to 24.4 percent, slightly edging out writing-based prompts in the sample (which had fallen from roughly 35 percent of the 2024 sample).&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2117143 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="704" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph6.png" width="1072" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A growing number of ChatGPT conversations now deal with "seeking information" as you might do with a more traditional search engine.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;While recent GPT models seem to have gotten better about citing relevant sources to back up their information, OpenAI is no closer to solving the widespread confabulation problem that makes LLMs a dodgy tool for retrieving facts. Luckily, fewer people seem interested in using ChatGPT to seek information at work; that use case makes up just 13.5 percent of work-related ChatGPT conversations, well below the 40 percent that are writing-related.&lt;/p&gt;
&lt;h2&gt;A large number of workers are using ChatGPT to make decisions&lt;/h2&gt;
&lt;figure class="ars-wp-img-shortcode id-2117144 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="211" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph7.png" width="834" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Among work-related conversations, "making decisions and solving problems" is a relatively popular use for ChatGPT.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Getting help editing an email is one thing, but asking ChatGPT to help you make a business decision is another altogether. Across work-related conversations, OpenAI says a significant 14.9 percent dealt with "making decisions and solving problems." That's second only to "documenting and recording information" for work-related ChatGPT conversations among the dozens of "generalized work activity" categories classified by O*NET.&lt;/p&gt;
&lt;p&gt;This was true across all the different occupation types OpenAI looked at, which the company suggests means people are "using ChatGPT as an advisor or research assistant, not just a technology that performs job tasks directly."&lt;/p&gt;
&lt;h2&gt;And the rest...&lt;/h2&gt;
&lt;p&gt;Some other highly touted use cases for ChatGPT that represented a surprisingly small portion of the sampled conversations across OpenAI's study:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Multimedia (e.g., creating or retrieving an image): 6 percent&lt;/li&gt;
&lt;li&gt;Computer programming: 4.2 percent (though some of this use might be outsourced to the API)&lt;/li&gt;
&lt;li&gt;Creative ideation: 3.9 percent&lt;/li&gt;
&lt;li&gt;Mathematical calculation: 3 percent&lt;/li&gt;
&lt;li&gt;Relationships and personal reflection: 1.9 percent&lt;/li&gt;
&lt;li&gt;Game and roleplay: 0.4 percent&lt;/li&gt;
&lt;/ul&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
  &lt;/article&gt;&lt;article class="comment-pick"&gt;
          &lt;header&gt;
            &lt;span class="ars-avatar" style="color: #a7ffeb; background-color: #00796b;"&gt;&lt;span class="ars-avatar-letter"&gt;&lt;/span&gt;&lt;/span&gt;

            &lt;div class="text-base font-bold sm:text-xl"&gt;
              太鶏道
            &lt;/div&gt;
          &lt;/header&gt;

          &lt;div class="comments-pick-content"&gt;
            I use it quite a bit to assist with translation, and I can't ever see myself going back to things like Google Translate.  Google Translate has almost no ability to provide context, so the answers you get back with it are often suboptimal or even wrong.  It's a night and day difference for me.  However, as with other use cases, the LLM is most advantageous when you have a grasp on that language already, and can understand what the LLM spits out.
          &lt;/div&gt;

          &lt;div class="comments-pick-timestamp"&gt;
            
              &lt;time datetime="2025-09-15T20:52:11+00:00"&gt;September 15, 2025 at 8:52 pm&lt;/time&gt;
            
          &lt;/div&gt;
        &lt;/article&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/09/seven-things-we-learned-from-openais-first-study-on-chatgpt-usage/</guid><pubDate>Mon, 15 Sep 2025 20:26:34 +0000</pubDate></item><item><title>[NEW] Google releases VaultGemma, its first privacy-preserving LLM (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/09/google-releases-vaultgemma-its-first-privacy-preserving-llm/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google Research shows that AI models can keep training data private.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/VaultGemma-640x360.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="450" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/VaultGemma.jpg" width="800" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The companies seeking to build larger AI models have been increasingly stymied by a lack of high-quality training data. As tech firms scour the web for more data to feed their models, they could increasingly rely on potentially sensitive user data. A team at Google Research is exploring new techniques to make the resulting large language models (LLMs) less likely to "memorize" any of that content.&lt;/p&gt;
&lt;p&gt;LLMs have non-deterministic outputs, meaning you can't exactly predict what they'll say. While the output varies even for identical inputs, models do sometimes regurgitate something from their training data—if trained with personal data, the output could be a violation of user privacy. In the event copyrighted data makes it into training data (either accidentally or on purpose), its appearance in outputs can cause a different kind of headache for devs. Differential privacy can prevent such memorization by introducing calibrated noise during the training phase.&lt;/p&gt;
&lt;p&gt;Adding differential privacy to a model comes with drawbacks in terms of accuracy and compute requirements. No one has bothered to figure out the degree to which that alters the scaling laws of AI models until now. The team worked from the assumption that model performance would be primarily affected by the noise-batch ratio, which compares the volume of randomized noise to the size of the original training data.&lt;/p&gt;
&lt;p&gt;By running experiments with varying model sizes and noise-batch ratios, the team established a basic understanding of differential privacy scaling laws, which is a balance between the compute budget, privacy budget, and data budget. In short, more noise leads to lower-quality outputs unless offset with a higher compute budget (FLOPs) or data budget (tokens). The paper details the scaling laws for private LLMs, which could help developers find an ideal noise-batch ratio to make a model more private.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Building VaultGemma&lt;/h2&gt;
&lt;p&gt;This work on differential privacy has led to a new open-weight Google model called VaultGemma. The model uses differential privacy to reduce the possibility of memorization, which could change how Google builds privacy into its future AI agents. For now, though, the company's first differential privacy model is an experiment.&lt;/p&gt;
&lt;p&gt;VaultGemma is based on the Gemma 2 foundational model, which is a generation behind Google's latest open model family. The team used the scaling laws derived from its initial testing to train VaultGemma with the optimal&amp;nbsp;differential privacy. This model isn't particularly large in the grand scheme, clocking in at just 1 billion parameters. However, Google Research says VaultGemma performs similarly to non-private models of a similar size.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2117184 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="VaultGemma tests" class="fullwidth full" height="547" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/VaultGemma4_Performance.width-1250.png" width="1250" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      VaultGemma does surprisingly well versus non-private AI models.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The team hopes this work on differential privacy scaling laws will help others efficiently allocate resources to train private AI models. This probably won't change the way the largest and most capable AI models operate—performance is everything in supersized general models. And regardless, the research suggests that differential privacy works better with smaller LLMs, like the purpose-built models that power specific AI features.&lt;/p&gt;
&lt;p&gt;You can download VaultGemma now from Hugging Face and Kaggle. Like other Gemma models, this one has open weights, but it's not quite open source. While Google will let you modify and distribute Gemma models, you must agree not to use them for nefarious purposes and to distribute a copy of the Gemma license with any and all modified versions.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google Research shows that AI models can keep training data private.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/VaultGemma-640x360.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="450" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/VaultGemma.jpg" width="800" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The companies seeking to build larger AI models have been increasingly stymied by a lack of high-quality training data. As tech firms scour the web for more data to feed their models, they could increasingly rely on potentially sensitive user data. A team at Google Research is exploring new techniques to make the resulting large language models (LLMs) less likely to "memorize" any of that content.&lt;/p&gt;
&lt;p&gt;LLMs have non-deterministic outputs, meaning you can't exactly predict what they'll say. While the output varies even for identical inputs, models do sometimes regurgitate something from their training data—if trained with personal data, the output could be a violation of user privacy. In the event copyrighted data makes it into training data (either accidentally or on purpose), its appearance in outputs can cause a different kind of headache for devs. Differential privacy can prevent such memorization by introducing calibrated noise during the training phase.&lt;/p&gt;
&lt;p&gt;Adding differential privacy to a model comes with drawbacks in terms of accuracy and compute requirements. No one has bothered to figure out the degree to which that alters the scaling laws of AI models until now. The team worked from the assumption that model performance would be primarily affected by the noise-batch ratio, which compares the volume of randomized noise to the size of the original training data.&lt;/p&gt;
&lt;p&gt;By running experiments with varying model sizes and noise-batch ratios, the team established a basic understanding of differential privacy scaling laws, which is a balance between the compute budget, privacy budget, and data budget. In short, more noise leads to lower-quality outputs unless offset with a higher compute budget (FLOPs) or data budget (tokens). The paper details the scaling laws for private LLMs, which could help developers find an ideal noise-batch ratio to make a model more private.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Building VaultGemma&lt;/h2&gt;
&lt;p&gt;This work on differential privacy has led to a new open-weight Google model called VaultGemma. The model uses differential privacy to reduce the possibility of memorization, which could change how Google builds privacy into its future AI agents. For now, though, the company's first differential privacy model is an experiment.&lt;/p&gt;
&lt;p&gt;VaultGemma is based on the Gemma 2 foundational model, which is a generation behind Google's latest open model family. The team used the scaling laws derived from its initial testing to train VaultGemma with the optimal&amp;nbsp;differential privacy. This model isn't particularly large in the grand scheme, clocking in at just 1 billion parameters. However, Google Research says VaultGemma performs similarly to non-private models of a similar size.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2117184 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="VaultGemma tests" class="fullwidth full" height="547" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/VaultGemma4_Performance.width-1250.png" width="1250" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      VaultGemma does surprisingly well versus non-private AI models.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The team hopes this work on differential privacy scaling laws will help others efficiently allocate resources to train private AI models. This probably won't change the way the largest and most capable AI models operate—performance is everything in supersized general models. And regardless, the research suggests that differential privacy works better with smaller LLMs, like the purpose-built models that power specific AI features.&lt;/p&gt;
&lt;p&gt;You can download VaultGemma now from Hugging Face and Kaggle. Like other Gemma models, this one has open weights, but it's not quite open source. While Google will let you modify and distribute Gemma models, you must agree not to use them for nefarious purposes and to distribute a copy of the Gemma license with any and all modified versions.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/09/google-releases-vaultgemma-its-first-privacy-preserving-llm/</guid><pubDate>Mon, 15 Sep 2025 21:04:04 +0000</pubDate></item></channel></rss>