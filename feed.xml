<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 10 Jul 2025 01:52:43 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>Tencent improves testing creative AI models with new benchmark (AI News)</title><link>https://www.artificialintelligence-news.com/news/tencent-improves-testing-creative-ai-models-new-benchmark/</link><description>&lt;p&gt;Tencent has introduced a new benchmark, ArtifactsBench, that aims to fix current problems with testing creative AI models.&lt;/p&gt;&lt;p&gt;Ever asked an AI to build something like a simple webpage or a chart and received something that works but has a poor user experience? The buttons might be in the wrong place, the colours might clash, or the animations feel clunky. It‚Äôs a common problem, and it highlights a huge challenge in the world of AI development: how do you teach a machine to have good taste?&lt;/p&gt;&lt;p&gt;For a long time, we‚Äôve been testing AI models on their ability to write code that is functionally correct. These tests could confirm the code would run, but they were completely ‚Äúblind to the visual fidelity and interactive integrity that define modern user experiences.‚Äù&lt;/p&gt;&lt;p&gt;This is the exact problem ArtifactsBench has been designed to solve. It‚Äôs less of a test and more of an automated art critic for AI-generated code&lt;/p&gt;&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;&lt;blockquote class="cmplz-placeholder-element twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;üöÄThrilled to introduce #ArtifactsBench! We're bridging the visual-interactive gap in code generation evaluation.&lt;/p&gt;&lt;p&gt;Our benchmark uses a novel automated, multimodal pipeline to assess LLMs on 1,825 diverse tasks. An MLLM-as-Judge evaluates visual artifacts, achieving 94.4% ranking‚Ä¶ pic.twitter.com/84xClcnNyS&lt;/p&gt;‚Äî Hunyuan (@TencentHunyuan) July 9, 2025&lt;/blockquote&gt;&lt;/div&gt;&lt;/figure&gt;&lt;h3 class="wp-block-heading" id="h-getting-it-right-like-a-human-would-should"&gt;Getting it right, like a human &lt;s&gt;would&lt;/s&gt; should&lt;/h3&gt;&lt;p&gt;So, how does Tencent‚Äôs AI benchmark work? First, an AI is given a creative task from a catalogue of over 1,800 challenges, from building data visualisations and web apps to making interactive mini-games.&lt;/p&gt;&lt;p&gt;Once the AI generates the code, ArtifactsBench gets to work. It automatically builds and runs the code in a safe and sandboxed environment.&lt;/p&gt;&lt;p&gt;To see how the application behaves, it captures a series of screenshots over time. This allows it to check for things like animations, state changes after a button click, and other dynamic user feedback.&lt;/p&gt;&lt;p&gt;Finally, it hands over all this evidence ‚Äì the original request, the AI‚Äôs code, and the screenshots ‚Äì to a Multimodal LLM (MLLM), to act as a judge.&lt;/p&gt;&lt;p&gt;This MLLM judge isn‚Äôt just giving a vague opinion and instead uses a detailed, per-task checklist to score the result across ten different metrics. Scoring includes functionality, user experience, and even aesthetic quality. This ensures the scoring is fair, consistent, and thorough.&lt;/p&gt;&lt;p&gt;The big question is, does this automated judge actually have good taste? The results suggest it does.&lt;/p&gt;&lt;p&gt;When the rankings from ArtifactsBench were compared to WebDev Arena, the gold-standard platform where real humans vote on the best AI creations, they matched up with a 94.4% consistency. This is a massive leap from older automated benchmarks, which only managed around 69.4% consistency.&lt;/p&gt;&lt;p&gt;On top of this, the framework‚Äôs judgments showed over 90% agreement with professional human developers.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-tencent-evaluates-the-creativity-of-top-ai-models-with-its-new-benchmark"&gt;Tencent evaluates the creativity of top AI models with its new benchmark&lt;/h3&gt;&lt;p&gt;When Tencent put more than 30 of the world‚Äôs top AI models through their paces, the leaderboard was revealing. While top commercial models from Google (Gemini-2.5-Pro) and Anthropic (Claude 4.0-Sonnet) took the lead, the tests unearthed a fascinating insight.&lt;/p&gt;&lt;p&gt;You might think that an AI specialised in writing code would be the best at these tasks. But the opposite was true. The research found that ‚Äúthe holistic capabilities of generalist models often surpass those of specialized ones.‚Äù&lt;/p&gt;&lt;p&gt;A general-purpose model, Qwen-2.5-Instruct, actually beat its more specialised siblings, Qwen-2.5-coder (a code-specific model) and Qwen2.5-VL (a vision-specialised model).&lt;/p&gt;&lt;p&gt;The researchers believe this is because creating a great visual application isn‚Äôt just about coding or visual understanding in isolation and requires a blend of skills.&lt;/p&gt;&lt;p&gt;‚ÄúRobust reasoning, nuanced instruction following, and an implicit sense of design aesthetics,‚Äù the researchers highlight as example vital skills. These are the kinds of well-rounded, almost human-like abilities that the best generalist models are beginning to develop.&lt;/p&gt;&lt;p&gt;Tencent hopes its ArtifactsBench benchmark can reliably evaluate these qualities and thus measure future progress in the ability for AI to create things that are not just functional but what users actually want to use.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Tencent Hunyuan3D-PolyGen: A model for ‚Äòart-grade‚Äô 3D assets&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Tencent has introduced a new benchmark, ArtifactsBench, that aims to fix current problems with testing creative AI models.&lt;/p&gt;&lt;p&gt;Ever asked an AI to build something like a simple webpage or a chart and received something that works but has a poor user experience? The buttons might be in the wrong place, the colours might clash, or the animations feel clunky. It‚Äôs a common problem, and it highlights a huge challenge in the world of AI development: how do you teach a machine to have good taste?&lt;/p&gt;&lt;p&gt;For a long time, we‚Äôve been testing AI models on their ability to write code that is functionally correct. These tests could confirm the code would run, but they were completely ‚Äúblind to the visual fidelity and interactive integrity that define modern user experiences.‚Äù&lt;/p&gt;&lt;p&gt;This is the exact problem ArtifactsBench has been designed to solve. It‚Äôs less of a test and more of an automated art critic for AI-generated code&lt;/p&gt;&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;&lt;blockquote class="cmplz-placeholder-element twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;üöÄThrilled to introduce #ArtifactsBench! We're bridging the visual-interactive gap in code generation evaluation.&lt;/p&gt;&lt;p&gt;Our benchmark uses a novel automated, multimodal pipeline to assess LLMs on 1,825 diverse tasks. An MLLM-as-Judge evaluates visual artifacts, achieving 94.4% ranking‚Ä¶ pic.twitter.com/84xClcnNyS&lt;/p&gt;‚Äî Hunyuan (@TencentHunyuan) July 9, 2025&lt;/blockquote&gt;&lt;/div&gt;&lt;/figure&gt;&lt;h3 class="wp-block-heading" id="h-getting-it-right-like-a-human-would-should"&gt;Getting it right, like a human &lt;s&gt;would&lt;/s&gt; should&lt;/h3&gt;&lt;p&gt;So, how does Tencent‚Äôs AI benchmark work? First, an AI is given a creative task from a catalogue of over 1,800 challenges, from building data visualisations and web apps to making interactive mini-games.&lt;/p&gt;&lt;p&gt;Once the AI generates the code, ArtifactsBench gets to work. It automatically builds and runs the code in a safe and sandboxed environment.&lt;/p&gt;&lt;p&gt;To see how the application behaves, it captures a series of screenshots over time. This allows it to check for things like animations, state changes after a button click, and other dynamic user feedback.&lt;/p&gt;&lt;p&gt;Finally, it hands over all this evidence ‚Äì the original request, the AI‚Äôs code, and the screenshots ‚Äì to a Multimodal LLM (MLLM), to act as a judge.&lt;/p&gt;&lt;p&gt;This MLLM judge isn‚Äôt just giving a vague opinion and instead uses a detailed, per-task checklist to score the result across ten different metrics. Scoring includes functionality, user experience, and even aesthetic quality. This ensures the scoring is fair, consistent, and thorough.&lt;/p&gt;&lt;p&gt;The big question is, does this automated judge actually have good taste? The results suggest it does.&lt;/p&gt;&lt;p&gt;When the rankings from ArtifactsBench were compared to WebDev Arena, the gold-standard platform where real humans vote on the best AI creations, they matched up with a 94.4% consistency. This is a massive leap from older automated benchmarks, which only managed around 69.4% consistency.&lt;/p&gt;&lt;p&gt;On top of this, the framework‚Äôs judgments showed over 90% agreement with professional human developers.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-tencent-evaluates-the-creativity-of-top-ai-models-with-its-new-benchmark"&gt;Tencent evaluates the creativity of top AI models with its new benchmark&lt;/h3&gt;&lt;p&gt;When Tencent put more than 30 of the world‚Äôs top AI models through their paces, the leaderboard was revealing. While top commercial models from Google (Gemini-2.5-Pro) and Anthropic (Claude 4.0-Sonnet) took the lead, the tests unearthed a fascinating insight.&lt;/p&gt;&lt;p&gt;You might think that an AI specialised in writing code would be the best at these tasks. But the opposite was true. The research found that ‚Äúthe holistic capabilities of generalist models often surpass those of specialized ones.‚Äù&lt;/p&gt;&lt;p&gt;A general-purpose model, Qwen-2.5-Instruct, actually beat its more specialised siblings, Qwen-2.5-coder (a code-specific model) and Qwen2.5-VL (a vision-specialised model).&lt;/p&gt;&lt;p&gt;The researchers believe this is because creating a great visual application isn‚Äôt just about coding or visual understanding in isolation and requires a blend of skills.&lt;/p&gt;&lt;p&gt;‚ÄúRobust reasoning, nuanced instruction following, and an implicit sense of design aesthetics,‚Äù the researchers highlight as example vital skills. These are the kinds of well-rounded, almost human-like abilities that the best generalist models are beginning to develop.&lt;/p&gt;&lt;p&gt;Tencent hopes its ArtifactsBench benchmark can reliably evaluate these qualities and thus measure future progress in the ability for AI to create things that are not just functional but what users actually want to use.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Tencent Hunyuan3D-PolyGen: A model for ‚Äòart-grade‚Äô 3D assets&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/tencent-improves-testing-creative-ai-models-new-benchmark/</guid><pubDate>Wed, 09 Jul 2025 14:10:13 +0000</pubDate></item><item><title>iMerit believes better-quality data, not more data, is the future of AI (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/09/imerit-believes-better-quality-data-not-more-data-is-the-future-of-ai/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI data platform iMerit believes the next step toward integrating AI tools at the enterprise level is not more data, but better data. And better data doesn‚Äôt come from hordes of gig workers, but from experts across mathematics, medicine, healthcare, finance, autonomy, and other cognitive fields, the company says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWhat‚Äôs become exceedingly important is the ability to attract and retain the best cognitive experts, because we have to take these large models and make them very customized towards solving enterprise AI problems,‚Äù Radha Basu, CEO and founder of iMerit, told TechCrunch.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The California- and India-based startup has for the past nine years quietly built itself into a trusted data annotation partner for companies working in computer vision, medical imaging, autonomous mobility, and other AI applications that require high-accuracy, human-in-the-loop labeling.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now, iMerit is bringing its Scholars program out of beta, the company exclusively told TechCrunch. The goal of the program is to build a growing workforce of experts to fine-tune generative AI models for enterprise applications and, increasingly, foundational models.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;iMerit already calls some of the top AI firms customers, including three of the big seven generative AI companies, eight of the top autonomous vehicle companies, three large U.S. government agencies, and two of the top three cloud providers, according to the company.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3026066" height="417" src="https://techcrunch.com/wp-content/uploads/2025/07/Math-CoT.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;iMerit Scholars workflow example focused on mathematics&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;iMerit&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The news comes as Scale AI, arguably the biggest name in AI data annotation, has lost its founder and CEO Alexandr Wang to Meta, which also acquired a 49% in the company. In the wake of Meta‚Äôs investment, many of Scale‚Äôs major clients pulled back, including Google, OpenAI, Microsoft, and xAI, out of concerns that Meta could gain access to their product roadmaps.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;iMerit doesn‚Äôt claim to replace Scale AI‚Äôs core offering of high-throughput, developer-focused ‚Äúblitz data.‚Äù Instead, it‚Äôs betting that now is the right moment to double down on expert-led, high-quality data, the kind that requires deep human judgment and domain-specific oversight.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWe‚Äôre the adults in the room,‚Äù Rob Laing, iMerit‚Äôs VP of global specialist workforce, told TechCrunch. ‚ÄúA lot of money is being spent on AI right now. There are some very intelligent people building large platforms of human workforces. The output that they‚Äôre getting from that mass approach and that very quick speed to market approach is not at the level of quality that enterprises need.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Basu brought up the example of healthcare scribes that have come to market off the back of foundational large language models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúIf you don‚Äôt have the expertise of the cardiologist or the physician, what you‚Äôre doing is basically creating something that‚Äôs maybe 50% or 60% accurate,‚Äù Basu said. ‚ÄúYou want that to be 99%. You want to question the model. You want to break it. You want to fix it. That is what expert-led AI is making possible for enterprise.‚Äù&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;iMerit‚Äôs experts are tasked with finetuning, or ‚Äútormenting,‚Äù enterprise and foundational AI models using the startup‚Äôs proprietary platform Ango Hub. Ango allows iMerit‚Äôs ‚ÄúScholars‚Äù to interact with the customer‚Äôs model to generate and evaluate problems for the model to solve.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For iMerritt, attracting and retaining cognitive experts is key to success because the experts aren‚Äôt just doing a few tasks and disappearing; they‚Äôre working on projects for multiple years. iMerit boasts a 91% retention rate, with 50% of its experts being women.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Laing, whose experience founding the human translation platform myGengo helped him understand how to crowdsource, said it‚Äôs relatively easy to get warm bodies to perform menial tasks. Creating community requires a more human-centered approach.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúInstead of someone being a name on a database, when someone joins the Scholars program, they actually meet folks on the team,‚Äù Laing said. ‚ÄúThey have collaborative discussions. They‚Äôre very much pushed to work at the highest possible level. And we are very, very, very selective about how we bring people in.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúI think what we‚Äôre going to see over the next couple of years is that companies like iMerit that are really focusing on that engagement, that retention, and that quality, are going to be the go-to companies for people to train the AI,‚Äù Laing added.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Today, iMerit works with over 4,000 Scholars and hopes to bring on more as it scales. Basu told TechCrunch that even though the company hasn‚Äôt raised since 2020 ‚Äî when it brought on investors like Khosla Ventures, Omidyar Network, Dell.org, and British International Investment ‚Äî iMerit is sustainable and profitable. With its own cash reserves, iMerit can afford to scale to 10,000 experts, Basu said. To scale further would require more outside investment, which iMerit is open to, but not desperate for.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;iMerit has been working on Scholars for the past year, mainly with a focus on healthcare. The goal is to grow across other enterprise applications, including finance and medicine. Laing noted that generative AI is its fastest-growing area as top AI firms work with iMerit to improve their foundation models.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúThe free data out there on the internet is gone, and the lower level of human input data has also become commoditized,‚Äù Laing said. ‚ÄúWhere these folks are going is really trying to tune these things to achieve AGI or superintelligence.‚Äù&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI data platform iMerit believes the next step toward integrating AI tools at the enterprise level is not more data, but better data. And better data doesn‚Äôt come from hordes of gig workers, but from experts across mathematics, medicine, healthcare, finance, autonomy, and other cognitive fields, the company says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWhat‚Äôs become exceedingly important is the ability to attract and retain the best cognitive experts, because we have to take these large models and make them very customized towards solving enterprise AI problems,‚Äù Radha Basu, CEO and founder of iMerit, told TechCrunch.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The California- and India-based startup has for the past nine years quietly built itself into a trusted data annotation partner for companies working in computer vision, medical imaging, autonomous mobility, and other AI applications that require high-accuracy, human-in-the-loop labeling.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now, iMerit is bringing its Scholars program out of beta, the company exclusively told TechCrunch. The goal of the program is to build a growing workforce of experts to fine-tune generative AI models for enterprise applications and, increasingly, foundational models.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;iMerit already calls some of the top AI firms customers, including three of the big seven generative AI companies, eight of the top autonomous vehicle companies, three large U.S. government agencies, and two of the top three cloud providers, according to the company.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3026066" height="417" src="https://techcrunch.com/wp-content/uploads/2025/07/Math-CoT.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;iMerit Scholars workflow example focused on mathematics&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;iMerit&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The news comes as Scale AI, arguably the biggest name in AI data annotation, has lost its founder and CEO Alexandr Wang to Meta, which also acquired a 49% in the company. In the wake of Meta‚Äôs investment, many of Scale‚Äôs major clients pulled back, including Google, OpenAI, Microsoft, and xAI, out of concerns that Meta could gain access to their product roadmaps.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;iMerit doesn‚Äôt claim to replace Scale AI‚Äôs core offering of high-throughput, developer-focused ‚Äúblitz data.‚Äù Instead, it‚Äôs betting that now is the right moment to double down on expert-led, high-quality data, the kind that requires deep human judgment and domain-specific oversight.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWe‚Äôre the adults in the room,‚Äù Rob Laing, iMerit‚Äôs VP of global specialist workforce, told TechCrunch. ‚ÄúA lot of money is being spent on AI right now. There are some very intelligent people building large platforms of human workforces. The output that they‚Äôre getting from that mass approach and that very quick speed to market approach is not at the level of quality that enterprises need.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Basu brought up the example of healthcare scribes that have come to market off the back of foundational large language models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúIf you don‚Äôt have the expertise of the cardiologist or the physician, what you‚Äôre doing is basically creating something that‚Äôs maybe 50% or 60% accurate,‚Äù Basu said. ‚ÄúYou want that to be 99%. You want to question the model. You want to break it. You want to fix it. That is what expert-led AI is making possible for enterprise.‚Äù&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;iMerit‚Äôs experts are tasked with finetuning, or ‚Äútormenting,‚Äù enterprise and foundational AI models using the startup‚Äôs proprietary platform Ango Hub. Ango allows iMerit‚Äôs ‚ÄúScholars‚Äù to interact with the customer‚Äôs model to generate and evaluate problems for the model to solve.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For iMerritt, attracting and retaining cognitive experts is key to success because the experts aren‚Äôt just doing a few tasks and disappearing; they‚Äôre working on projects for multiple years. iMerit boasts a 91% retention rate, with 50% of its experts being women.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Laing, whose experience founding the human translation platform myGengo helped him understand how to crowdsource, said it‚Äôs relatively easy to get warm bodies to perform menial tasks. Creating community requires a more human-centered approach.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúInstead of someone being a name on a database, when someone joins the Scholars program, they actually meet folks on the team,‚Äù Laing said. ‚ÄúThey have collaborative discussions. They‚Äôre very much pushed to work at the highest possible level. And we are very, very, very selective about how we bring people in.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúI think what we‚Äôre going to see over the next couple of years is that companies like iMerit that are really focusing on that engagement, that retention, and that quality, are going to be the go-to companies for people to train the AI,‚Äù Laing added.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Today, iMerit works with over 4,000 Scholars and hopes to bring on more as it scales. Basu told TechCrunch that even though the company hasn‚Äôt raised since 2020 ‚Äî when it brought on investors like Khosla Ventures, Omidyar Network, Dell.org, and British International Investment ‚Äî iMerit is sustainable and profitable. With its own cash reserves, iMerit can afford to scale to 10,000 experts, Basu said. To scale further would require more outside investment, which iMerit is open to, but not desperate for.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;iMerit has been working on Scholars for the past year, mainly with a focus on healthcare. The goal is to grow across other enterprise applications, including finance and medicine. Laing noted that generative AI is its fastest-growing area as top AI firms work with iMerit to improve their foundation models.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúThe free data out there on the internet is gone, and the lower level of human input data has also become commoditized,‚Äù Laing said. ‚ÄúWhere these folks are going is really trying to tune these things to achieve AGI or superintelligence.‚Äù&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/09/imerit-believes-better-quality-data-not-more-data-is-the-future-of-ai/</guid><pubDate>Wed, 09 Jul 2025 15:20:14 +0000</pubDate></item><item><title>Pinecone founder Edo Liberty explores the real missing link in enterprise AI at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/09/pinecone-founder-edo-liberty-explores-the-real-missing-link-in-enterprise-ai-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;At &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, the AI conversation goes deeper than just the latest models. On one of the AI Stages, Edo Liberty, founder and CEO of Pinecone, will deliver a session that challenges one of the most persistent assumptions in the field ‚Äî that raw intelligence alone is enough. With 10,000+ startup and VC leaders expected in San Francisco from October 27‚Äì29, &lt;strong&gt;this fireside chat&lt;/strong&gt; and presentation is one of the must-attend moments for anyone building AI systems that actually work in the real world.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Edo Liberty" class="wp-image-3025928" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/TC25_-Edo-Liberty-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-intelligence-is-only-half-the-equation"&gt;Intelligence is only half the equation&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;For AI to be truly useful to businesses, it needs more than language fluency or prediction accuracy. It needs knowledge. Proprietary data, domain-specific insights, real-time information retrieval ‚Äî these are the ingredients that power task completion, accurate answers, and enterprise value. Liberty will break down the critical difference between intelligence and knowledge, and will explain why delivering both is the key to unlocking AI‚Äôs true impact.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As the founder of Pinecone, Liberty is leading one of the most important infrastructure companies in the AI ecosystem. Pinecone‚Äôs vector database helps organizations build high-performance AI applications at scale, with reliable retrieval and memory systems that enable real-time use of massive knowledge bases.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-from-amazon-ai-to-academia-to-building-infrastructure-for-the-next-era"&gt;From Amazon AI to academia to building infrastructure for the next era&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Before launching Pinecone, Liberty served as director of research at AWS and led Amazon AI Labs, where he worked on key services like SageMaker and OpenSearch. He also ran Yahoo‚Äôs research lab in New York, taught at Princeton and Tel Aviv University, and authored more than 75 papers and patents on machine learning, data mining, and streaming algorithms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At Disrupt 2025, Liberty brings all of that experience to bear in a session that will speak to technical leaders, AI founders, enterprise builders, and anyone trying to bridge the gap between promise and performance in artificial intelligence.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Catch this conversation on one of the two AI Stages at TechCrunch Disrupt 2025, happening October 27‚Äì29 at Moscone West in San Francisco. The exact session timing to be announced on the &lt;strong&gt;Disrupt agenda page&lt;/strong&gt;, so check back in often for frequent updates. Register now to join more than 10,000 startup and VC leaders and &lt;strong&gt;save up to $675&lt;/strong&gt; before prices increase.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;At &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, the AI conversation goes deeper than just the latest models. On one of the AI Stages, Edo Liberty, founder and CEO of Pinecone, will deliver a session that challenges one of the most persistent assumptions in the field ‚Äî that raw intelligence alone is enough. With 10,000+ startup and VC leaders expected in San Francisco from October 27‚Äì29, &lt;strong&gt;this fireside chat&lt;/strong&gt; and presentation is one of the must-attend moments for anyone building AI systems that actually work in the real world.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Edo Liberty" class="wp-image-3025928" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/TC25_-Edo-Liberty-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-intelligence-is-only-half-the-equation"&gt;Intelligence is only half the equation&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;For AI to be truly useful to businesses, it needs more than language fluency or prediction accuracy. It needs knowledge. Proprietary data, domain-specific insights, real-time information retrieval ‚Äî these are the ingredients that power task completion, accurate answers, and enterprise value. Liberty will break down the critical difference between intelligence and knowledge, and will explain why delivering both is the key to unlocking AI‚Äôs true impact.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As the founder of Pinecone, Liberty is leading one of the most important infrastructure companies in the AI ecosystem. Pinecone‚Äôs vector database helps organizations build high-performance AI applications at scale, with reliable retrieval and memory systems that enable real-time use of massive knowledge bases.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-from-amazon-ai-to-academia-to-building-infrastructure-for-the-next-era"&gt;From Amazon AI to academia to building infrastructure for the next era&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Before launching Pinecone, Liberty served as director of research at AWS and led Amazon AI Labs, where he worked on key services like SageMaker and OpenSearch. He also ran Yahoo‚Äôs research lab in New York, taught at Princeton and Tel Aviv University, and authored more than 75 papers and patents on machine learning, data mining, and streaming algorithms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At Disrupt 2025, Liberty brings all of that experience to bear in a session that will speak to technical leaders, AI founders, enterprise builders, and anyone trying to bridge the gap between promise and performance in artificial intelligence.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Catch this conversation on one of the two AI Stages at TechCrunch Disrupt 2025, happening October 27‚Äì29 at Moscone West in San Francisco. The exact session timing to be announced on the &lt;strong&gt;Disrupt agenda page&lt;/strong&gt;, so check back in often for frequent updates. Register now to join more than 10,000 startup and VC leaders and &lt;strong&gt;save up to $675&lt;/strong&gt; before prices increase.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/09/pinecone-founder-edo-liberty-explores-the-real-missing-link-in-enterprise-ai-at-techcrunch-disrupt-2025/</guid><pubDate>Wed, 09 Jul 2025 15:30:00 +0000</pubDate></item><item><title>Blok is using AI personas to simulate real-world app usage (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/09/blok-is-using-ai-persons-to-simulate-real-world-app-usage/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI-powered coding tools like Cursor, Replit, Claude Code, and Lovable are helping developers write many lines of code every day to ship products faster. However, app makers still have to rely on either shipping full beta versions of their apps or using simulation software to gauge how upcoming features will work.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Blok, a company that is coming out of stealth, allows developers to use AI to simulate different user personas to test an app‚Äôs features and learn how to make their apps better.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company was founded by Tom Charman and Olivia Higgs in 2024. Both have been serial entrepreneurs and worked on startups together in areas including travel and learning.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3025994" height="453" src="https://techcrunch.com/wp-content/uploads/2025/07/Founder-Headshots-3.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Founders Tom Charman and Olivia Higgs &lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;To date, the startup has raised $7.5 million across two rounds. Its seed round of $5 million was led by MaC Venture Capital, with participation from people working at Discord, Google, Meta, Apple, Snapchat, and Pinterest. Blok‚Äôs pre-seed round was with Protagonist with participation from Rackhouse, Ryan Hoover‚Äôs Weekend Fund, and Blank Ventures.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Marlon Nichols, managing GP at MaC Venture Capital, said that Blok is often compared to Optimizely and Amplitude, but those tools are more reactive. He said that Blok is edging them out by providing a predictive layer of testing for apps.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWe backed Blok because we believe product development is at an inflection point. Teams are shipping faster than ever, but they‚Äôre still making critical decisions based on A/B tests and gut instinct. Blok‚Äôs simulation engine flips that model ‚Äî&amp;nbsp;giving teams the ability to predict user behavior before a single line of code is written,‚Äù he told TechCrunch over email.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Higgs said that the need for testing is increasing as the complexity of interfaces has increased over time. She mentioned that they interviewed more than 100 product engineers to understand problems faced by product teams. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúThere is a real need for increased testing because the bar for visual interfaces is getting a lot higher. We‚Äôre seeing people interact with technology through chat, through voice. So if you‚Äôre introducing visual UI [elements] into the mix, you have to make sure that you are not introducing unnecessary friction into a user‚Äôs workflow,‚Äù she said.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3025996" height="396" src="https://techcrunch.com/wp-content/uploads/2025/07/Blok-experiment.jpeg?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Charman said that both big and small companies face different problems. While small companies don‚Äôt have cohorts to test out their products and get live feedback, big companies want to avoid stuffing features into their apps and making them clunky. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWe are trying to reach a place where companies don‚Äôt need to release their features on an experimental basis and wait for a few weeks or months for results to show up,‚Äù he said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;When a customer starts working with Blok, they upload their event log data from Amplitude, Mixpanel, or Segment. Blok then performs behavioral modeling and creates different user personas for app makers to test. These personas would roughly cover most of an app‚Äôs user base. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3025998" height="396" src="https://techcrunch.com/wp-content/uploads/2025/07/Blok-personas.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Blok&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Then the development team submits a Figma design and experiment details ‚Äî including the hypothesis they want to test and the user goal they want to achieve ‚Äî to Blok, and the user persona agents then try to run the simulation many times. At the end, Blok will show insights about how users would use a particular feature and give recommendations. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These insights include an overall report of the experiment and details about what went well and what could be improved. Teams can also look at a persona-wise report and suggestions. Plus, because it is 2025, there is a chatbot that you can ask queries about your experiment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Blok has put its product behind a waitlist and is working with an initial set of customers, largely developing solutions in finance and healthcare. The startup said these areas are ideal to target as they can‚Äôt put out bad experiments in public and play around with the product a lot.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup charges companies through a SaaS model, but it is also figuring out how to balance out compute costs. The company is aiming to hit mid-single-digit millions in revenue this year and open up to more customers. &lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI-powered coding tools like Cursor, Replit, Claude Code, and Lovable are helping developers write many lines of code every day to ship products faster. However, app makers still have to rely on either shipping full beta versions of their apps or using simulation software to gauge how upcoming features will work.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Blok, a company that is coming out of stealth, allows developers to use AI to simulate different user personas to test an app‚Äôs features and learn how to make their apps better.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company was founded by Tom Charman and Olivia Higgs in 2024. Both have been serial entrepreneurs and worked on startups together in areas including travel and learning.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3025994" height="453" src="https://techcrunch.com/wp-content/uploads/2025/07/Founder-Headshots-3.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Founders Tom Charman and Olivia Higgs &lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;To date, the startup has raised $7.5 million across two rounds. Its seed round of $5 million was led by MaC Venture Capital, with participation from people working at Discord, Google, Meta, Apple, Snapchat, and Pinterest. Blok‚Äôs pre-seed round was with Protagonist with participation from Rackhouse, Ryan Hoover‚Äôs Weekend Fund, and Blank Ventures.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Marlon Nichols, managing GP at MaC Venture Capital, said that Blok is often compared to Optimizely and Amplitude, but those tools are more reactive. He said that Blok is edging them out by providing a predictive layer of testing for apps.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWe backed Blok because we believe product development is at an inflection point. Teams are shipping faster than ever, but they‚Äôre still making critical decisions based on A/B tests and gut instinct. Blok‚Äôs simulation engine flips that model ‚Äî&amp;nbsp;giving teams the ability to predict user behavior before a single line of code is written,‚Äù he told TechCrunch over email.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Higgs said that the need for testing is increasing as the complexity of interfaces has increased over time. She mentioned that they interviewed more than 100 product engineers to understand problems faced by product teams. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúThere is a real need for increased testing because the bar for visual interfaces is getting a lot higher. We‚Äôre seeing people interact with technology through chat, through voice. So if you‚Äôre introducing visual UI [elements] into the mix, you have to make sure that you are not introducing unnecessary friction into a user‚Äôs workflow,‚Äù she said.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3025996" height="396" src="https://techcrunch.com/wp-content/uploads/2025/07/Blok-experiment.jpeg?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Charman said that both big and small companies face different problems. While small companies don‚Äôt have cohorts to test out their products and get live feedback, big companies want to avoid stuffing features into their apps and making them clunky. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWe are trying to reach a place where companies don‚Äôt need to release their features on an experimental basis and wait for a few weeks or months for results to show up,‚Äù he said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;When a customer starts working with Blok, they upload their event log data from Amplitude, Mixpanel, or Segment. Blok then performs behavioral modeling and creates different user personas for app makers to test. These personas would roughly cover most of an app‚Äôs user base. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3025998" height="396" src="https://techcrunch.com/wp-content/uploads/2025/07/Blok-personas.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Blok&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Then the development team submits a Figma design and experiment details ‚Äî including the hypothesis they want to test and the user goal they want to achieve ‚Äî to Blok, and the user persona agents then try to run the simulation many times. At the end, Blok will show insights about how users would use a particular feature and give recommendations. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These insights include an overall report of the experiment and details about what went well and what could be improved. Teams can also look at a persona-wise report and suggestions. Plus, because it is 2025, there is a chatbot that you can ask queries about your experiment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Blok has put its product behind a waitlist and is working with an initial set of customers, largely developing solutions in finance and healthcare. The startup said these areas are ideal to target as they can‚Äôt put out bad experiments in public and play around with the product a lot.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup charges companies through a SaaS model, but it is also figuring out how to balance out compute costs. The company is aiming to hit mid-single-digit millions in revenue this year and open up to more customers. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/09/blok-is-using-ai-persons-to-simulate-real-world-app-usage/</guid><pubDate>Wed, 09 Jul 2025 16:00:00 +0000</pubDate></item><item><title>MedGemma: Our most capable open models for health AI development (The latest research from Google)</title><link>https://research.google/blog/medgemma-our-most-capable-open-models-for-health-ai-development/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Healthcare is increasingly embracing AI to improve workflow management, patient communication, and diagnostic and treatment support. It‚Äôs critical that these AI-based systems are not only high-performing, but also efficient and privacy-preserving. It‚Äôs with these considerations in mind that we built and recently released Health AI Developer Foundations (HAI-DEF). HAI-DEF is a collection of lightweight open models designed to offer developers robust starting points for their own health research and application development. Because HAI-DEF models are open, developers retain full control over privacy, infrastructure and modifications to the models. In May of this year, we expanded the HAI-DEF collection with MedGemma, a collection of generative models based on Gemma 3 that are designed to accelerate healthcare and lifesciences AI development.&lt;/p&gt;&lt;p&gt;Today, we‚Äôre proud to announce two new models in this collection. The first is MedGemma 27B Multimodal, which complements the previously-released 4B Multimodal and 27B text-only models by adding support for complex multimodal and longitudinal electronic health record interpretation. The second new model is MedSigLIP, a lightweight image and text encoder for classification, search, and related tasks. MedSigLIP is based on the same image encoder that powers the 4B and 27B MedGemma models.&lt;/p&gt;&lt;p&gt;MedGemma and MedSigLIP are strong starting points for medical research and product development. MedGemma is useful for medical text or imaging tasks that require generating free text, like report generation or visual question answering. MedSigLIP is recommended for imaging tasks that involve structured outputs like classification or retrieval. All of the above models can be run on a single GPU, and MedGemma 4B and MedSigLIP can even be adapted to run on mobile hardware.&lt;/p&gt;&lt;p&gt;Full details of MedGemma and MedSigLIP development and evaluation can be found in the MedGemma technical report.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Healthcare is increasingly embracing AI to improve workflow management, patient communication, and diagnostic and treatment support. It‚Äôs critical that these AI-based systems are not only high-performing, but also efficient and privacy-preserving. It‚Äôs with these considerations in mind that we built and recently released Health AI Developer Foundations (HAI-DEF). HAI-DEF is a collection of lightweight open models designed to offer developers robust starting points for their own health research and application development. Because HAI-DEF models are open, developers retain full control over privacy, infrastructure and modifications to the models. In May of this year, we expanded the HAI-DEF collection with MedGemma, a collection of generative models based on Gemma 3 that are designed to accelerate healthcare and lifesciences AI development.&lt;/p&gt;&lt;p&gt;Today, we‚Äôre proud to announce two new models in this collection. The first is MedGemma 27B Multimodal, which complements the previously-released 4B Multimodal and 27B text-only models by adding support for complex multimodal and longitudinal electronic health record interpretation. The second new model is MedSigLIP, a lightweight image and text encoder for classification, search, and related tasks. MedSigLIP is based on the same image encoder that powers the 4B and 27B MedGemma models.&lt;/p&gt;&lt;p&gt;MedGemma and MedSigLIP are strong starting points for medical research and product development. MedGemma is useful for medical text or imaging tasks that require generating free text, like report generation or visual question answering. MedSigLIP is recommended for imaging tasks that involve structured outputs like classification or retrieval. All of the above models can be run on a single GPU, and MedGemma 4B and MedSigLIP can even be adapted to run on mobile hardware.&lt;/p&gt;&lt;p&gt;Full details of MedGemma and MedSigLIP development and evaluation can be found in the MedGemma technical report.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/medgemma-our-most-capable-open-models-for-health-ai-development/</guid><pubDate>Wed, 09 Jul 2025 17:00:00 +0000</pubDate></item><item><title>ChatGPT hallucinated about music app Soundslice so often, the founder made the lie come true (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/09/chatgpt-hallucinated-about-music-app-soundslice-so-often-the-founder-made-the-lie-come-true/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Earlier this month, Adrian Holovaty, founder of music-teaching platform Soundslice, solved a mystery that had been plaguing him for weeks. Weird images of what were clearly ChatGPT sessions kept being uploaded to the site.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Once he solved it, he realized that ChatGPT had become one of his company‚Äôs greatest hype men ‚Äî but it was also lying to people about what his app could do.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Holovaty is best known as one of the creators of the open source Django project, a popular Python web development framework (though he retired from managing the project in 2014). In 2012, he launched Soundslice, which remains ‚Äúproudly bootstrapped,‚Äù he tells TechCrunch. Currently, he‚Äôs focused on his music career both as an artist and as a founder.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Soundslice is an app for teaching music, used by students and teachers. It‚Äôs known for its video player synchronized to the music notations that guide users on how the notes should be played.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It also offers a feature called ‚Äúsheet music scanner‚Äù that allows users to upload an image of paper sheet music and, using AI, will automatically turn that into an interactive sheet, complete with notations. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Holovaty carefully watches this feature‚Äôs error logs to see what problems occur, where to add improvements, he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That‚Äôs where he started seeing the uploaded ChatGPT sessions. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;They were creating a bunch of error logs. Instead of images of sheet music, these were images of words and a box of symbols known as ASCII tablature. That‚Äôs a basic text-based system used for guitar notations that uses a regular keyboard. (There‚Äôs no treble key, for instance, on your standard QWERTY keyboard.)&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Soundslice uploaded images" class="wp-image-3026106" height="386" src="https://techcrunch.com/wp-content/uploads/2025/07/Soundslice-upload-images.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Adrian Holovaty&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The volume of these ChatGPT session images was not so onerous that it was costing his company money to store them and crushing his app‚Äôs bandwidth, Holovaty said. He was baffled, he wrote in a blog post about the situation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúOur scanning system wasn‚Äôt intended to support this style of notation. Why, then, were we being bombarded with so many ASCII tab ChatGPT screenshots? I was mystified for weeks ‚Äî until I messed around with ChatGPT myself.‚Äù&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That‚Äôs how he saw ChatGPT telling people they could hear this music by opening a Soundslice account and uploading the image of the chat session. Only, they couldn‚Äôt. Uploading those images wouldn‚Äôt translate the ASCII tab into audio notes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He was struck with a new problem. ‚ÄúThe main cost was reputational: New Soundslice users were going in with a false expectation. They‚Äôd been confidently told we would do something that we don‚Äôt actually do,‚Äù he described to TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He and his team discussed their options: Slap disclaimers all over the site about it ‚Äî ‚ÄúNo, we can‚Äôt turn a ChatGPT session into hearable music‚Äù ‚Äî or build that feature into the scanner, even though he had never before considered supporting that offbeat musical notation system.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He opted to build the feature.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúMy feelings on this are conflicted. I‚Äôm happy to add a tool that helps people. But I feel like our hand was forced in a weird way. Should we really be developing features in response to misinformation?‚Äù he wrote.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He also wondered if this was the first documented case of a company having to develop a feature because ChatGPT kept repeating, to many people, its hallucination about it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The fellow programmers on Hacker News had an interesting take about it: Several of them said that it‚Äôs no different than an overeager human salesperson promising the world to prospects and then forcing developers to deliver new features.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúI think that‚Äôs a very apt and amusing comparison!‚Äù Holovaty agreed.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Earlier this month, Adrian Holovaty, founder of music-teaching platform Soundslice, solved a mystery that had been plaguing him for weeks. Weird images of what were clearly ChatGPT sessions kept being uploaded to the site.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Once he solved it, he realized that ChatGPT had become one of his company‚Äôs greatest hype men ‚Äî but it was also lying to people about what his app could do.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Holovaty is best known as one of the creators of the open source Django project, a popular Python web development framework (though he retired from managing the project in 2014). In 2012, he launched Soundslice, which remains ‚Äúproudly bootstrapped,‚Äù he tells TechCrunch. Currently, he‚Äôs focused on his music career both as an artist and as a founder.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Soundslice is an app for teaching music, used by students and teachers. It‚Äôs known for its video player synchronized to the music notations that guide users on how the notes should be played.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It also offers a feature called ‚Äúsheet music scanner‚Äù that allows users to upload an image of paper sheet music and, using AI, will automatically turn that into an interactive sheet, complete with notations. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Holovaty carefully watches this feature‚Äôs error logs to see what problems occur, where to add improvements, he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That‚Äôs where he started seeing the uploaded ChatGPT sessions. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;They were creating a bunch of error logs. Instead of images of sheet music, these were images of words and a box of symbols known as ASCII tablature. That‚Äôs a basic text-based system used for guitar notations that uses a regular keyboard. (There‚Äôs no treble key, for instance, on your standard QWERTY keyboard.)&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Soundslice uploaded images" class="wp-image-3026106" height="386" src="https://techcrunch.com/wp-content/uploads/2025/07/Soundslice-upload-images.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Adrian Holovaty&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The volume of these ChatGPT session images was not so onerous that it was costing his company money to store them and crushing his app‚Äôs bandwidth, Holovaty said. He was baffled, he wrote in a blog post about the situation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúOur scanning system wasn‚Äôt intended to support this style of notation. Why, then, were we being bombarded with so many ASCII tab ChatGPT screenshots? I was mystified for weeks ‚Äî until I messed around with ChatGPT myself.‚Äù&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That‚Äôs how he saw ChatGPT telling people they could hear this music by opening a Soundslice account and uploading the image of the chat session. Only, they couldn‚Äôt. Uploading those images wouldn‚Äôt translate the ASCII tab into audio notes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He was struck with a new problem. ‚ÄúThe main cost was reputational: New Soundslice users were going in with a false expectation. They‚Äôd been confidently told we would do something that we don‚Äôt actually do,‚Äù he described to TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He and his team discussed their options: Slap disclaimers all over the site about it ‚Äî ‚ÄúNo, we can‚Äôt turn a ChatGPT session into hearable music‚Äù ‚Äî or build that feature into the scanner, even though he had never before considered supporting that offbeat musical notation system.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He opted to build the feature.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúMy feelings on this are conflicted. I‚Äôm happy to add a tool that helps people. But I feel like our hand was forced in a weird way. Should we really be developing features in response to misinformation?‚Äù he wrote.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He also wondered if this was the first documented case of a company having to develop a feature because ChatGPT kept repeating, to many people, its hallucination about it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The fellow programmers on Hacker News had an interesting take about it: Several of them said that it‚Äôs no different than an overeager human salesperson promising the world to prospects and then forcing developers to deliver new features.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúI think that‚Äôs a very apt and amusing comparison!‚Äù Holovaty agreed.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/09/chatgpt-hallucinated-about-music-app-soundslice-so-often-the-founder-made-the-lie-come-true/</guid><pubDate>Wed, 09 Jul 2025 17:20:14 +0000</pubDate></item><item><title>SaaS is in the past. The future belongs to agents, says Narada AI‚Äôs CEO. (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/podcast/saas-is-in-the-past-the-future-belongs-to-agents-says-narada-ais-ceo/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/54569914657_d267199249_o.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;‚ÄúSaaS is going away,‚Äù said Dave Park, co-founder and CEO of Narada AI. The company is betting big on a different future for enterprise software, one powered by agentic AI.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Change is coming ‚Äúin the not-too-distant future,‚Äù Park said on Equity, TechCrunch‚Äôs flagship podcast. ‚ÄúThe typical knowledge worker today deals with anywhere from 17 to 25 different SaaS tools and portals every day, wasting two and a half hours just manually looking up or updating these systems. We believe in a future where it‚Äôll just be the data, the databases, and AI agents or agentic models that take your request and operate across those silos to get the job done.‚Äù&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Narada AI, which made its debut at TechCrunch Disrupt 2024 and is based on UC Berkeley research, has developed large action models: a spin on LLMs that can reason through and complete multi-step tasks across different work tools even when APIs are missing.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Park joined Rebecca Bellan on Equity to talk about the rise of agentic AI, what it actually is, how it differs from traditional automation, and what real-world changes enterprises need to make to deploy it at scale. The timing for the conversation is ripe: YC‚Äôs most recent batch included 70+ agentic startups, and major players like Grammarly are building full AI work stacks through partnerships and acquisitions.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear more about:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;What most people misunderstand about automation and who‚Äôs getting caught in the agentic hype.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;How tools like Narada could eventually help solopreneurs and smaller teams, not just the enterprise giants.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Why the future of software might not be ‚Äúusing‚Äù apps at all.&lt;/li&gt;
&lt;/ul&gt;



&lt;p class="wp-block-paragraph"&gt;Equity will be back on Friday with our weekly news rundown, so don‚Äôt miss it!&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch‚Äôs flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Subscribe to us on&lt;/em&gt;&lt;em&gt; Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; &lt;/em&gt;&lt;em&gt;X and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/54569914657_d267199249_o.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;‚ÄúSaaS is going away,‚Äù said Dave Park, co-founder and CEO of Narada AI. The company is betting big on a different future for enterprise software, one powered by agentic AI.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Change is coming ‚Äúin the not-too-distant future,‚Äù Park said on Equity, TechCrunch‚Äôs flagship podcast. ‚ÄúThe typical knowledge worker today deals with anywhere from 17 to 25 different SaaS tools and portals every day, wasting two and a half hours just manually looking up or updating these systems. We believe in a future where it‚Äôll just be the data, the databases, and AI agents or agentic models that take your request and operate across those silos to get the job done.‚Äù&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Narada AI, which made its debut at TechCrunch Disrupt 2024 and is based on UC Berkeley research, has developed large action models: a spin on LLMs that can reason through and complete multi-step tasks across different work tools even when APIs are missing.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Park joined Rebecca Bellan on Equity to talk about the rise of agentic AI, what it actually is, how it differs from traditional automation, and what real-world changes enterprises need to make to deploy it at scale. The timing for the conversation is ripe: YC‚Äôs most recent batch included 70+ agentic startups, and major players like Grammarly are building full AI work stacks through partnerships and acquisitions.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear more about:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;What most people misunderstand about automation and who‚Äôs getting caught in the agentic hype.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;How tools like Narada could eventually help solopreneurs and smaller teams, not just the enterprise giants.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Why the future of software might not be ‚Äúusing‚Äù apps at all.&lt;/li&gt;
&lt;/ul&gt;



&lt;p class="wp-block-paragraph"&gt;Equity will be back on Friday with our weekly news rundown, so don‚Äôt miss it!&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch‚Äôs flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Subscribe to us on&lt;/em&gt;&lt;em&gt; Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; &lt;/em&gt;&lt;em&gt;X and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/podcast/saas-is-in-the-past-the-future-belongs-to-agents-says-narada-ais-ceo/</guid><pubDate>Wed, 09 Jul 2025 17:21:25 +0000</pubDate></item><item><title>YouTube prepares crackdown on ‚Äòmass-produced‚Äô and ‚Äòrepetitive‚Äô videos, as concern over AI slop grows (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/09/youtube-prepares-crackdown-on-mass-produced-and-repetitive-videos-as-concern-over-ai-slop-grows/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2021/12/GettyImages-1184040131.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;YouTube is preparing to update its policies to crack down on creators‚Äô ability to generate revenue from ‚Äúinauthentic‚Äù content, including mass-produced videos and other types of repetitive content ‚Äî things that have become easier to generate with the help of AI technology.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On July 15, the company will update its YouTube Partner Program (YPP) Monetization policies with more detailed guidelines around what type of content can earn creators money and what cannot. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The exact policy language itself has not yet been released, but a page on YouTube‚Äôs Help documentation explains that creators have always been required to upload ‚Äúoriginal‚Äù and ‚Äúauthentic‚Äù content. The update says that the new language will help creators to better understand what ‚Äúinauthentic‚Äù content looks like today.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some YouTube creators were concerned that the update would limit their ability to monetize certain types of videos, like reaction videos or those featuring clips, but a post from YouTube Head of Editorial &amp;amp; Creator Liaison Rene Ritchie says that‚Äôs not the case.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a video update published on Tuesday, Ritchie says that the change is just a ‚Äúminor update‚Äù to YouTube‚Äôs longstanding YPP policies and is designed to better identify when content is mass-produced or repetitive.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, Ritchie adds, this type of content has been ineligible for monetization for years, as it‚Äôs content that viewers often consider spam.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;What Ritchie is not saying, however, is how much easier it is to create such videos these days.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the rise of AI technology, YouTube has become flooded with AI slop, a term referencing low-quality media or content made using generative AI technology. For instance, it‚Äôs common to find an AI voice overlaid on photos, video clips, or other repurposed content, thanks to text-to-video AI tools. Some channels filled with AI music have millions of subscribers. Fake, AI-generated videos about news events, like the Diddy trial, have racked up millions of views.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In another example, a true crime murder series on YouTube that went viral was found to be entirely AI-generated, 404 Media reported earlier this year. Even YouTube CEO Neal Mohan‚Äôs likeness was used in an AI-generated phishing scam on the site, despite having tools in place that allow users to report deepfake videos.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While YouTube may downplay the coming changes as a ‚Äúminor‚Äù update or clarification, the reality is that allowing this type of content to grow and its creators to profit could ultimately damage YouTube‚Äôs reputation and value. It‚Äôs no surprise, then, that the company wants clear policies in place that allow it to enact mass bans of AI slop creators from YPP.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2021/12/GettyImages-1184040131.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;YouTube is preparing to update its policies to crack down on creators‚Äô ability to generate revenue from ‚Äúinauthentic‚Äù content, including mass-produced videos and other types of repetitive content ‚Äî things that have become easier to generate with the help of AI technology.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On July 15, the company will update its YouTube Partner Program (YPP) Monetization policies with more detailed guidelines around what type of content can earn creators money and what cannot. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The exact policy language itself has not yet been released, but a page on YouTube‚Äôs Help documentation explains that creators have always been required to upload ‚Äúoriginal‚Äù and ‚Äúauthentic‚Äù content. The update says that the new language will help creators to better understand what ‚Äúinauthentic‚Äù content looks like today.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some YouTube creators were concerned that the update would limit their ability to monetize certain types of videos, like reaction videos or those featuring clips, but a post from YouTube Head of Editorial &amp;amp; Creator Liaison Rene Ritchie says that‚Äôs not the case.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a video update published on Tuesday, Ritchie says that the change is just a ‚Äúminor update‚Äù to YouTube‚Äôs longstanding YPP policies and is designed to better identify when content is mass-produced or repetitive.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, Ritchie adds, this type of content has been ineligible for monetization for years, as it‚Äôs content that viewers often consider spam.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;What Ritchie is not saying, however, is how much easier it is to create such videos these days.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the rise of AI technology, YouTube has become flooded with AI slop, a term referencing low-quality media or content made using generative AI technology. For instance, it‚Äôs common to find an AI voice overlaid on photos, video clips, or other repurposed content, thanks to text-to-video AI tools. Some channels filled with AI music have millions of subscribers. Fake, AI-generated videos about news events, like the Diddy trial, have racked up millions of views.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In another example, a true crime murder series on YouTube that went viral was found to be entirely AI-generated, 404 Media reported earlier this year. Even YouTube CEO Neal Mohan‚Äôs likeness was used in an AI-generated phishing scam on the site, despite having tools in place that allow users to report deepfake videos.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While YouTube may downplay the coming changes as a ‚Äúminor‚Äù update or clarification, the reality is that allowing this type of content to grow and its creators to profit could ultimately damage YouTube‚Äôs reputation and value. It‚Äôs no surprise, then, that the company wants clear policies in place that allow it to enact mass bans of AI slop creators from YPP.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/09/youtube-prepares-crackdown-on-mass-produced-and-repetitive-videos-as-concern-over-ai-slop-grows/</guid><pubDate>Wed, 09 Jul 2025 17:23:13 +0000</pubDate></item><item><title>[NEW] AI mania pushes Nvidia to record $4 trillion valuation (AI ‚Äì Ars Technica)</title><link>https://arstechnica.com/ai/2025/07/ai-mania-pushes-nvidia-to-record-4-trillion-valuation/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        AI craze makes Nvidia the most valuable publicly traded company in history.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The Nvidia logo on a green background." class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/02/nvidia_green_1-300x169.jpg" width="300" /&gt;
                  &lt;img alt="The Nvidia logo on a green background." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/02/nvidia_green_1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Nvidia / Benj Edwards

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Wednesday, Nvidia became the first company in history to reach $4 trillion market valuation as shares rose more than 2 percent, reports CNBC. The GPU maker's stock has climbed 22 percent since the start of 2025, continuing a trend driven by demand for AI hardware following ChatGPT's late 2022 launch.&lt;/p&gt;
&lt;p&gt;The milestone marks the highest market cap ever recorded for a publicly traded company, surpassing Apple's previous record of $3.8 trillion set in December. Nvidia first crossed $2 trillion in February 2024 and reached $3 trillion just four months later in June. The $4 trillion valuation represents a market capitalization larger than the GDP of most countries.&lt;/p&gt;
&lt;p&gt;As we explained in 2023, Nvidia's continued success has been intimately tied to growth in demand for hardware that runs AI models as capably and efficiently as possible. The company's data center GPUs excel at performing billions of matrix multiplications necessary to train and run neural networks due to their parallel architecture‚Äîhardware architectures that originated as video game graphics accelerators now power the generative AI boom.&lt;/p&gt;
&lt;p&gt;Companies like OpenAI, Microsoft, and others need tens of thousands of these specialized chips to power services like ChatGPT, AI image generators, and enterprise AI applications. Meanwhile, Nvidia's CUDA platform (which makes developing AI applications that use GPUs easier) has become a de facto standard, creating a moat around its hardware ecosystem.&lt;/p&gt;
&lt;h2&gt;China restrictions and market resilience&lt;/h2&gt;
&lt;p&gt;It has been a roller-coaster year for Nvidia stock after multiple shocks. In January, a brief investor panic over the emergence of China's DeepSeek model had some analysts suggesting it might reduce future AI chip requirements. In April, Trump's "Liberation Day" tariff announcement caused Nvidia's shares to dive even more dramatically, but the company's valuation has gained more than 15 percent over the past month despite these episodes.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Beyond market volatility, Nvidia faces ongoing geopolitical challenges that threaten its access to one of its largest markets. Export controls on Nvidia's chips designed to keep advanced AI tech out of Chinese hands (that date back to 2022, during the early Biden era) have created a thorny obstacle for the company that it has tried to work around over time with new chip designs, including a special lower-speed chip called the H20.&lt;/p&gt;
&lt;p&gt;In April, the Trump administration imposed export restrictions on the H20, which require Nvidia to apply for licenses each time it wants to sell the chip to customers in China, costing the company $5.5 billion in charges and effectively shutting Nvidia out of what CEO Jensen Huang has described as a "$50 billion China market."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-1877557 align-"&gt;
    &lt;div&gt;
                        &lt;img alt="The Nvidia logo superimposed over China's flag." class=" large" height="358" src="https://cdn.arstechnica.net/wp-content/uploads/2022/09/nvidia_china_hero_1-640x358.jpg" width="640" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards / Nvidia

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Simultaneously, Trump has also signaled that he may be willing to ease some restrictions after Nvidia promised the Trump administration new US investments in AI data centers. But the administration's approach remains unpredictable‚ÄîTrump has continued to voice his desire for the US to remain an AI leader while trying to keep top tech out of the hands of China, creating a challenging environment for Nvidia to navigate.&lt;/p&gt;
&lt;p&gt;Meanwhile, Nvidia's continued success depends on the continued growth of the AI industry, which some critics consider unsustainable at current levels. Some analysts point to the massive capital expenditures by tech giants on AI infrastructure‚Äîwith companies like Microsoft, Google, and Meta each spending tens of billions annually on data centers‚Äîand question whether the returns will justify the investment.&lt;/p&gt;
&lt;p&gt;For now, Nvidia sits atop the tech world as the most valuable company, but whether that position proves sustainable will depend on factors ranging from geopolitical tensions to the question of whether AI applications can actually deliver on the tech industry's promises.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        AI craze makes Nvidia the most valuable publicly traded company in history.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The Nvidia logo on a green background." class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/02/nvidia_green_1-300x169.jpg" width="300" /&gt;
                  &lt;img alt="The Nvidia logo on a green background." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/02/nvidia_green_1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Nvidia / Benj Edwards

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Wednesday, Nvidia became the first company in history to reach $4 trillion market valuation as shares rose more than 2 percent, reports CNBC. The GPU maker's stock has climbed 22 percent since the start of 2025, continuing a trend driven by demand for AI hardware following ChatGPT's late 2022 launch.&lt;/p&gt;
&lt;p&gt;The milestone marks the highest market cap ever recorded for a publicly traded company, surpassing Apple's previous record of $3.8 trillion set in December. Nvidia first crossed $2 trillion in February 2024 and reached $3 trillion just four months later in June. The $4 trillion valuation represents a market capitalization larger than the GDP of most countries.&lt;/p&gt;
&lt;p&gt;As we explained in 2023, Nvidia's continued success has been intimately tied to growth in demand for hardware that runs AI models as capably and efficiently as possible. The company's data center GPUs excel at performing billions of matrix multiplications necessary to train and run neural networks due to their parallel architecture‚Äîhardware architectures that originated as video game graphics accelerators now power the generative AI boom.&lt;/p&gt;
&lt;p&gt;Companies like OpenAI, Microsoft, and others need tens of thousands of these specialized chips to power services like ChatGPT, AI image generators, and enterprise AI applications. Meanwhile, Nvidia's CUDA platform (which makes developing AI applications that use GPUs easier) has become a de facto standard, creating a moat around its hardware ecosystem.&lt;/p&gt;
&lt;h2&gt;China restrictions and market resilience&lt;/h2&gt;
&lt;p&gt;It has been a roller-coaster year for Nvidia stock after multiple shocks. In January, a brief investor panic over the emergence of China's DeepSeek model had some analysts suggesting it might reduce future AI chip requirements. In April, Trump's "Liberation Day" tariff announcement caused Nvidia's shares to dive even more dramatically, but the company's valuation has gained more than 15 percent over the past month despite these episodes.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Beyond market volatility, Nvidia faces ongoing geopolitical challenges that threaten its access to one of its largest markets. Export controls on Nvidia's chips designed to keep advanced AI tech out of Chinese hands (that date back to 2022, during the early Biden era) have created a thorny obstacle for the company that it has tried to work around over time with new chip designs, including a special lower-speed chip called the H20.&lt;/p&gt;
&lt;p&gt;In April, the Trump administration imposed export restrictions on the H20, which require Nvidia to apply for licenses each time it wants to sell the chip to customers in China, costing the company $5.5 billion in charges and effectively shutting Nvidia out of what CEO Jensen Huang has described as a "$50 billion China market."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-1877557 align-"&gt;
    &lt;div&gt;
                        &lt;img alt="The Nvidia logo superimposed over China's flag." class=" large" height="358" src="https://cdn.arstechnica.net/wp-content/uploads/2022/09/nvidia_china_hero_1-640x358.jpg" width="640" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards / Nvidia

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Simultaneously, Trump has also signaled that he may be willing to ease some restrictions after Nvidia promised the Trump administration new US investments in AI data centers. But the administration's approach remains unpredictable‚ÄîTrump has continued to voice his desire for the US to remain an AI leader while trying to keep top tech out of the hands of China, creating a challenging environment for Nvidia to navigate.&lt;/p&gt;
&lt;p&gt;Meanwhile, Nvidia's continued success depends on the continued growth of the AI industry, which some critics consider unsustainable at current levels. Some analysts point to the massive capital expenditures by tech giants on AI infrastructure‚Äîwith companies like Microsoft, Google, and Meta each spending tens of billions annually on data centers‚Äîand question whether the returns will justify the investment.&lt;/p&gt;
&lt;p&gt;For now, Nvidia sits atop the tech world as the most valuable company, but whether that position proves sustainable will depend on factors ranging from geopolitical tensions to the question of whether AI applications can actually deliver on the tech industry's promises.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/07/ai-mania-pushes-nvidia-to-record-4-trillion-valuation/</guid><pubDate>Wed, 09 Jul 2025 18:35:15 +0000</pubDate></item><item><title>[NEW] OpenAI is reportedly releasing an AI browser in the coming weeks (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/09/openai-is-reportedly-releasing-an-ai-browser-in-the-coming-weeks/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2170386424.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Hot on the heels of Perplexity‚Äôs Comet launch, OpenAI is planning to release an AI-powered web browser of its own to challenge Google Chrome, according to a report from Reuters on Wednesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The ChatGPT maker reportedly aims to release its browser in the coming weeks. Much like Perplexity‚Äôs Comet and The Browser Company‚Äôs Dia, OpenAI‚Äôs browser is said to use AI to rethink how users browse the web. Supposedly, the browser keeps some user interactions inside ChatGPT instead of linking out to websites. Reuters reports that OpenAI‚Äôs browser may integrate Operator, the company‚Äôs web-browsing AI agent, as a key feature.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI had considered building a browser to compete with Google Chrome in 2024, according to The Information. Much like Perplexity, OpenAI likely wants to get direct access to user data and have the freedom to create novel user experiences that aren‚Äôt intermediated by Google.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2170386424.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Hot on the heels of Perplexity‚Äôs Comet launch, OpenAI is planning to release an AI-powered web browser of its own to challenge Google Chrome, according to a report from Reuters on Wednesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The ChatGPT maker reportedly aims to release its browser in the coming weeks. Much like Perplexity‚Äôs Comet and The Browser Company‚Äôs Dia, OpenAI‚Äôs browser is said to use AI to rethink how users browse the web. Supposedly, the browser keeps some user interactions inside ChatGPT instead of linking out to websites. Reuters reports that OpenAI‚Äôs browser may integrate Operator, the company‚Äôs web-browsing AI agent, as a key feature.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI had considered building a browser to compete with Google Chrome in 2024, according to The Information. Much like Perplexity, OpenAI likely wants to get direct access to user data and have the freedom to create novel user experiences that aren‚Äôt intermediated by Google.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/09/openai-is-reportedly-releasing-an-ai-browser-in-the-coming-weeks/</guid><pubDate>Wed, 09 Jul 2025 18:48:06 +0000</pubDate></item><item><title>[NEW] AI shapes autonomous underwater ‚Äúgliders‚Äù (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/ai-shapes-autonomous-underwater-gliders-0709</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202506/mit-auv-Gliders.png" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr" id="docs-internal-guid-cf34fa1c-7fff-d3f4-d4e3-35ce42aa6255"&gt;Marine scientists have long marveled at how animals like fish and seals swim so efficiently despite having different shapes. Their bodies are optimized for efficient, hydrodynamic aquatic navigation so they can exert minimal energy when traveling long distances.&lt;/p&gt;&lt;p&gt;Autonomous vehicles can drift through the ocean in a similar way, collecting data about vast underwater environments. However, the shapes of these gliding machines are less diverse than what we find in marine life ‚Äî go-to designs often resemble tubes or torpedoes, since they‚Äôre fairly hydrodynamic as well. Plus, testing new builds requires lots of real-world trial-and-error.&lt;/p&gt;&lt;p&gt;Researchers from MIT‚Äôs Computer Science and Artificial Intelligence Laboratory (CSAIL) and the University of Wisconsin at Madison propose that AI could help us explore uncharted glider designs more conveniently. Their method uses machine learning to test different 3D designs in a physics simulator, then molds them into more hydrodynamic shapes. The resulting model can be fabricated via a 3D printer using significantly less energy than hand-made ones.&lt;/p&gt;&lt;p&gt;The MIT scientists say that this design pipeline could create new, more efficient machines that help oceanographers measure water temperature and salt levels, gather more detailed insights about currents, and monitor the impacts of climate change. The team demonstrated this potential by producing two gliders roughly the size of a boogie board: a two-winged machine resembling an airplane, and a unique, four-winged object resembling a flat fish with four fins.&lt;/p&gt;&lt;p dir="ltr"&gt;Peter Yichen Chen, MIT CSAIL postdoc and co-lead researcher on the project, notes that these designs are just a few of the novel shapes his team‚Äôs approach can generate. ‚ÄúWe‚Äôve developed a semi-automated process that can help us test unconventional designs that would be very taxing for humans to design,‚Äù he says. ‚ÄúThis level of shape diversity hasn‚Äôt been explored previously, so most of these designs haven‚Äôt been tested in the real world.‚Äù&lt;/p&gt;&lt;p dir="ltr"&gt;But how did AI come up with these ideas in the first place? First, the researchers found 3D models of over 20 conventional sea exploration shapes, such as submarines, whales, manta rays, and sharks. Then, they enclosed these models in ‚Äúdeformation cages‚Äù that map out different articulation points that the researchers pulled around to create new shapes.&lt;/p&gt;&lt;p dir="ltr"&gt;The CSAIL-led team built a dataset of conventional and deformed shapes before simulating how they would perform at different ‚Äúangles-of-attack‚Äù ‚Äî the direction a vessel will tilt as it glides through the water. For example, a swimmer may want to dive at a -30 degree angle to retrieve an item from a pool.&lt;/p&gt;&lt;p dir="ltr"&gt;These diverse shapes and angles of attack were then used as inputs for a neural network that essentially anticipates how efficiently a glider shape will perform at particular angles and optimizes it as needed.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Giving gliding robots a lift&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;The team‚Äôs neural network simulates how a particular glider would react to underwater physics, aiming to capture how it moves forward and the force that drags against it. The goal: find the best lift-to-drag ratio, representing how much the glider is being held up compared to how much it‚Äôs being held back. The higher the ratio, the more efficiently the vehicle travels; the lower it is, the more the glider will slow down during its voyage.&lt;/p&gt;&lt;p dir="ltr"&gt;Lift-to-drag ratios are key for flying planes: At takeoff, you want to maximize lift to ensure it can glide well against wind currents, and when landing, you need sufficient force to drag it to a full stop.&lt;/p&gt;&lt;p dir="ltr"&gt;Niklas Hagemann, an MIT graduate student in architecture and CSAIL affiliate, notes that this ratio is just as useful if you want a similar gliding motion in the ocean.&lt;/p&gt;&lt;p&gt;‚ÄúOur pipeline modifies glider shapes to find the best lift-to-drag ratio, optimizing its performance underwater,‚Äù says Hagemann, who is also a co-lead author on a&amp;nbsp;paper that was presented at the International Conference on Robotics and Automation in June. ‚ÄúYou can then export the top-performing designs so they can be 3D-printed.‚Äù&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;Going for a quick glide&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;While their AI pipeline seemed realistic, the researchers needed to ensure its predictions about glider performance were accurate by experimenting in more lifelike environments.&lt;/p&gt;&lt;p dir="ltr"&gt;They first fabricated their two-wing design as a scaled-down vehicle resembling a paper airplane. This glider was taken to MIT‚Äôs Wright Brothers Wind Tunnel, an indoor space with fans that simulate wind flow. Placed at different angles, the glider‚Äôs predicted lift-to-drag ratio was only about 5 percent higher on average than the ones recorded in the wind experiments ‚Äî a small difference between simulation and reality.&lt;/p&gt;&lt;p&gt;A digital evaluation involving a visual, more complex physics simulator also supported the notion that the AI pipeline made fairly accurate predictions about how the gliders would move. It visualized how these machines would descend in 3D.&lt;/p&gt;&lt;p&gt;To truly evaluate these gliders in the real world, though, the team needed to see how their devices would fare underwater. They printed two designs that performed the best at specific points-of-attack for this test: a jet-like device at 9 degrees and the four-wing vehicle at 30 degrees.&lt;/p&gt;&lt;p dir="ltr"&gt;Both shapes were fabricated in a 3D printer as hollow shells with small holes that flood when fully submerged. This lightweight design makes the vehicle easier to handle outside of the water and requires less material to be fabricated. The researchers placed a tube-like device inside these shell coverings, which housed a range of hardware, including a pump to change the glider‚Äôs buoyancy, a mass shifter (a device that controls the machine‚Äôs angle-of-attack), and electronic components.&lt;/p&gt;&lt;p&gt;Each design outperformed a handmade torpedo-shaped glider by moving more efficiently across a pool. With higher lift-to-drag ratios than their counterpart, both AI-driven machines exerted less energy, similar to the effortless ways marine animals navigate the oceans.&lt;/p&gt;&lt;p&gt;As much as the project is an encouraging step forward for glider design, the researchers are looking to narrow the gap between simulation and real-world performance. They are also hoping to develop machines that can react to sudden changes in currents, making the gliders more adaptable to seas and oceans.&lt;/p&gt;&lt;p&gt;Chen adds that the team is looking to explore new types of shapes, particularly thinner glider designs. They intend to make their framework faster, perhaps bolstering it with new features that enable more customization, maneuverability, or even the creation of miniature vehicles.&lt;/p&gt;&lt;p&gt;Chen and Hagemann co-led research on this project with OpenAI researcher Pingchuan Ma SM ‚Äô23, PhD ‚Äô25. They authored the paper with Wei Wang, a University of Wisconsin at Madison assistant professor and recent CSAIL postdoc; John Romanishin ‚Äô12, SM ‚Äô18, PhD ‚Äô23; and two MIT professors and CSAIL members: lab director Daniela Rus and senior author Wojciech Matusik. Their work was supported, in part, by a Defense Advanced Research Projects Agency (DARPA) grant and the MIT-GIST Program.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202506/mit-auv-Gliders.png" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr" id="docs-internal-guid-cf34fa1c-7fff-d3f4-d4e3-35ce42aa6255"&gt;Marine scientists have long marveled at how animals like fish and seals swim so efficiently despite having different shapes. Their bodies are optimized for efficient, hydrodynamic aquatic navigation so they can exert minimal energy when traveling long distances.&lt;/p&gt;&lt;p&gt;Autonomous vehicles can drift through the ocean in a similar way, collecting data about vast underwater environments. However, the shapes of these gliding machines are less diverse than what we find in marine life ‚Äî go-to designs often resemble tubes or torpedoes, since they‚Äôre fairly hydrodynamic as well. Plus, testing new builds requires lots of real-world trial-and-error.&lt;/p&gt;&lt;p&gt;Researchers from MIT‚Äôs Computer Science and Artificial Intelligence Laboratory (CSAIL) and the University of Wisconsin at Madison propose that AI could help us explore uncharted glider designs more conveniently. Their method uses machine learning to test different 3D designs in a physics simulator, then molds them into more hydrodynamic shapes. The resulting model can be fabricated via a 3D printer using significantly less energy than hand-made ones.&lt;/p&gt;&lt;p&gt;The MIT scientists say that this design pipeline could create new, more efficient machines that help oceanographers measure water temperature and salt levels, gather more detailed insights about currents, and monitor the impacts of climate change. The team demonstrated this potential by producing two gliders roughly the size of a boogie board: a two-winged machine resembling an airplane, and a unique, four-winged object resembling a flat fish with four fins.&lt;/p&gt;&lt;p dir="ltr"&gt;Peter Yichen Chen, MIT CSAIL postdoc and co-lead researcher on the project, notes that these designs are just a few of the novel shapes his team‚Äôs approach can generate. ‚ÄúWe‚Äôve developed a semi-automated process that can help us test unconventional designs that would be very taxing for humans to design,‚Äù he says. ‚ÄúThis level of shape diversity hasn‚Äôt been explored previously, so most of these designs haven‚Äôt been tested in the real world.‚Äù&lt;/p&gt;&lt;p dir="ltr"&gt;But how did AI come up with these ideas in the first place? First, the researchers found 3D models of over 20 conventional sea exploration shapes, such as submarines, whales, manta rays, and sharks. Then, they enclosed these models in ‚Äúdeformation cages‚Äù that map out different articulation points that the researchers pulled around to create new shapes.&lt;/p&gt;&lt;p dir="ltr"&gt;The CSAIL-led team built a dataset of conventional and deformed shapes before simulating how they would perform at different ‚Äúangles-of-attack‚Äù ‚Äî the direction a vessel will tilt as it glides through the water. For example, a swimmer may want to dive at a -30 degree angle to retrieve an item from a pool.&lt;/p&gt;&lt;p dir="ltr"&gt;These diverse shapes and angles of attack were then used as inputs for a neural network that essentially anticipates how efficiently a glider shape will perform at particular angles and optimizes it as needed.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Giving gliding robots a lift&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;The team‚Äôs neural network simulates how a particular glider would react to underwater physics, aiming to capture how it moves forward and the force that drags against it. The goal: find the best lift-to-drag ratio, representing how much the glider is being held up compared to how much it‚Äôs being held back. The higher the ratio, the more efficiently the vehicle travels; the lower it is, the more the glider will slow down during its voyage.&lt;/p&gt;&lt;p dir="ltr"&gt;Lift-to-drag ratios are key for flying planes: At takeoff, you want to maximize lift to ensure it can glide well against wind currents, and when landing, you need sufficient force to drag it to a full stop.&lt;/p&gt;&lt;p dir="ltr"&gt;Niklas Hagemann, an MIT graduate student in architecture and CSAIL affiliate, notes that this ratio is just as useful if you want a similar gliding motion in the ocean.&lt;/p&gt;&lt;p&gt;‚ÄúOur pipeline modifies glider shapes to find the best lift-to-drag ratio, optimizing its performance underwater,‚Äù says Hagemann, who is also a co-lead author on a&amp;nbsp;paper that was presented at the International Conference on Robotics and Automation in June. ‚ÄúYou can then export the top-performing designs so they can be 3D-printed.‚Äù&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;Going for a quick glide&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;While their AI pipeline seemed realistic, the researchers needed to ensure its predictions about glider performance were accurate by experimenting in more lifelike environments.&lt;/p&gt;&lt;p dir="ltr"&gt;They first fabricated their two-wing design as a scaled-down vehicle resembling a paper airplane. This glider was taken to MIT‚Äôs Wright Brothers Wind Tunnel, an indoor space with fans that simulate wind flow. Placed at different angles, the glider‚Äôs predicted lift-to-drag ratio was only about 5 percent higher on average than the ones recorded in the wind experiments ‚Äî a small difference between simulation and reality.&lt;/p&gt;&lt;p&gt;A digital evaluation involving a visual, more complex physics simulator also supported the notion that the AI pipeline made fairly accurate predictions about how the gliders would move. It visualized how these machines would descend in 3D.&lt;/p&gt;&lt;p&gt;To truly evaluate these gliders in the real world, though, the team needed to see how their devices would fare underwater. They printed two designs that performed the best at specific points-of-attack for this test: a jet-like device at 9 degrees and the four-wing vehicle at 30 degrees.&lt;/p&gt;&lt;p dir="ltr"&gt;Both shapes were fabricated in a 3D printer as hollow shells with small holes that flood when fully submerged. This lightweight design makes the vehicle easier to handle outside of the water and requires less material to be fabricated. The researchers placed a tube-like device inside these shell coverings, which housed a range of hardware, including a pump to change the glider‚Äôs buoyancy, a mass shifter (a device that controls the machine‚Äôs angle-of-attack), and electronic components.&lt;/p&gt;&lt;p&gt;Each design outperformed a handmade torpedo-shaped glider by moving more efficiently across a pool. With higher lift-to-drag ratios than their counterpart, both AI-driven machines exerted less energy, similar to the effortless ways marine animals navigate the oceans.&lt;/p&gt;&lt;p&gt;As much as the project is an encouraging step forward for glider design, the researchers are looking to narrow the gap between simulation and real-world performance. They are also hoping to develop machines that can react to sudden changes in currents, making the gliders more adaptable to seas and oceans.&lt;/p&gt;&lt;p&gt;Chen adds that the team is looking to explore new types of shapes, particularly thinner glider designs. They intend to make their framework faster, perhaps bolstering it with new features that enable more customization, maneuverability, or even the creation of miniature vehicles.&lt;/p&gt;&lt;p&gt;Chen and Hagemann co-led research on this project with OpenAI researcher Pingchuan Ma SM ‚Äô23, PhD ‚Äô25. They authored the paper with Wei Wang, a University of Wisconsin at Madison assistant professor and recent CSAIL postdoc; John Romanishin ‚Äô12, SM ‚Äô18, PhD ‚Äô23; and two MIT professors and CSAIL members: lab director Daniela Rus and senior author Wojciech Matusik. Their work was supported, in part, by a Defense Advanced Research Projects Agency (DARPA) grant and the MIT-GIST Program.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/ai-shapes-autonomous-underwater-gliders-0709</guid><pubDate>Wed, 09 Jul 2025 20:35:00 +0000</pubDate></item><item><title>[NEW] Changing the conversation in health care (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/changing-conversation-health-care-0709</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202506/mit-language-ai-incubator.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr"&gt;Generative artificial intelligence is transforming the ways humans write, read, speak, think, empathize, and act within and across languages and cultures. In health care, gaps in communication between patients and practitioners can worsen patient outcomes and prevent improvements in practice and care. The Language/AI Incubator, made possible through funding from the&amp;nbsp;MIT Human Insight Collaborative (MITHIC), offers a potential response to these challenges.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;The project envisions a research community rooted in the humanities that will foster interdisciplinary collaboration across MIT to deepen understanding of generative AI‚Äôs impact on cross-linguistic and cross-cultural communication. The project‚Äôs focus on health care and communication seeks to build bridges across socioeconomic, cultural, and linguistic strata.&lt;/p&gt;&lt;p dir="ltr"&gt;The incubator is co-led by&amp;nbsp;Leo Celi, a physician and the research director and senior research scientist with the&amp;nbsp;Institute for Medical Engineering and Science (IMES), and&amp;nbsp;Per Urlaub, professor of the practice in German and second language studies and director of MIT‚Äôs&amp;nbsp;Global Languages program.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;‚ÄúThe basis of health care delivery is the knowledge of health and disease,‚Äù Celi says. ‚ÄúWe‚Äôre seeing poor outcomes despite massive investments because our knowledge system is broken.‚Äù&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A chance collaboration&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;Urlaub and Celi met during a MITHIC launch event. Conversations during the event reception revealed a shared interest in exploring improvements in medical communication and practice with AI.&lt;/p&gt;&lt;p dir="ltr"&gt;‚ÄúWe‚Äôre trying to incorporate data science into health-care delivery,‚Äù Celi says. ‚ÄúWe‚Äôve been recruiting social scientists [at IMES] to help advance our work, because the science we create isn‚Äôt neutral.‚Äù&lt;/p&gt;&lt;p dir="ltr"&gt;Language is a non-neutral mediator in health care delivery, the team believes, and can be a boon or barrier to effective treatment. ‚ÄúLater, after we met, I joined one of his working groups whose focus was metaphors for pain: the language we use to describe it and its measurement,‚Äù Urlaub continues. ‚ÄúOne of the questions we considered was how effective communication can occur between doctors and patients.‚Äù&lt;/p&gt;&lt;p dir="ltr"&gt;Technology, they argue, impacts casual communication, and its impact depends on both users and creators. As AI and large language models (LLMs) gain power and prominence, their use is broadening to include fields like health care and wellness.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;Rodrigo Gameiro, a physician and researcher with MIT‚Äôs Laboratory for Computational Physiology, is another program participant. He notes that work at the laboratory centers responsible AI development and implementation. Designing systems that leverage AI effectively, particularly when considering challenges related to communicating across linguistic and cultural divides that can occur in health care, demands a nuanced approach.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;‚ÄúWhen we build AI systems that interact with human language, we‚Äôre not just teaching machines how to process words; we‚Äôre teaching them to navigate the complex web of meaning embedded in language,‚Äù Gameiro says.&lt;/p&gt;&lt;p dir="ltr"&gt;Language‚Äôs complexities can impact treatment and patient care. ‚ÄúPain can only be communicated through metaphor,‚Äù Urlaub continues, ‚Äúbut metaphors don‚Äôt always match, linguistically and culturally.‚Äù Smiley faces and one-to-10 scales ‚Äî pain measurement tools English-speaking medical professionals may use to assess their patients ‚Äî may not travel well across racial, ethnic, cultural, and language boundaries.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;‚ÄúScience has to have a heart‚Äù&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;LLMs can potentially help scientists improve health care, although there are some systemic and pedagogical challenges to consider. Science can focus on outcomes to the exclusion of the people it‚Äôs meant to help, Celi argues. ‚ÄúScience has to have a heart,‚Äù he says. ‚ÄúMeasuring students‚Äô effectiveness by counting the number of papers they publish or patents they produce misses the point.‚Äù&lt;/p&gt;&lt;p dir="ltr"&gt;The point, Urlaub says, is to investigate carefully while simultaneously acknowledging what we don‚Äôt know, citing what philosophers call Epistemic Humility. Knowledge, the investigators argue, is provisional, and always incomplete. Deeply held beliefs may require revision in light of new evidence.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;‚ÄúNo one‚Äôs mental view of the world is complete,‚Äù Celi says. ‚ÄúYou need to create an environment in which people are comfortable acknowledging their biases.‚Äù&lt;/p&gt;&lt;p dir="ltr"&gt;‚ÄúHow do we share concerns between language educators and others interested in AI?‚Äù Urlaub asks. ‚ÄúHow do we identify and investigate the relationship between medical professionals and language educators interested in AI‚Äôs potential to aid in the elimination of gaps in communication between doctors and patients?‚Äù&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;Language, in Gameiro‚Äôs estimation, is more than just a tool for communication. ‚ÄúIt reflects culture, identity, and power dynamics,‚Äù he says. In situations where a patient might not be comfortable describing pain or discomfort because of the physician‚Äôs position as an authority, or because their culture demands yielding to those perceived as authority figures, misunderstandings can be dangerous.&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Changing the conversation&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;AI‚Äôs facility with language can help medical professionals navigate these areas more carefully, providing digital frameworks offering valuable cultural and linguistic contexts in which patient and practitioner can rely on data-driven, research-supported tools to improve dialogue. Institutions need to reconsider how they educate medical professionals and invite the communities they serve into the conversation, the team says.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;‚ÄòWe need to ask ourselves what we truly want,‚Äù Celi says. ‚ÄúWhy are we measuring what we‚Äôre measuring?‚Äù The biases we bring with us to these interactions ‚Äî doctors, patients, their families, and their communities ‚Äî remain barriers to improved care, Urlaub and Gameiro say.&lt;/p&gt;&lt;p dir="ltr"&gt;‚ÄúWe want to connect people who think differently, and make AI work for everyone,‚Äù Gameiro continues. ‚ÄúTechnology without purpose is just exclusion at scale.‚Äù&lt;/p&gt;&lt;p dir="ltr"&gt;‚ÄúCollaborations like these can allow for deep processing and better ideas,‚Äù Urlaub says.&lt;/p&gt;&lt;p dir="ltr"&gt;Creating spaces where ideas about AI and health care can potentially become actions is a key element of the project. The Language/AI Incubator hosted its first colloquium at MIT in May, which was led by Mena Ramos, a physician and the co-founder and CEO of the&amp;nbsp;Global Ultrasound Institute.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;The colloquium also featured presentations from Celi, as well as Alfred Spector, a visiting scholar in MIT‚Äôs&amp;nbsp;Department of Electrical Engineering and Computer Science, and Douglas Jones, a senior staff member in the MIT Lincoln Laboratory‚Äôs Human Language Technology Group. A second Language/AI Incubator colloquium is planned for August.&lt;/p&gt;&lt;p dir="ltr"&gt;Greater integration between the social and hard sciences can potentially increase the likelihood of developing viable solutions and reducing biases. Allowing for shifts in the ways patients and doctors view the relationship, while offering each shared ownership of the interaction, can help improve outcomes. Facilitating these conversations with AI may speed the integration of these perspectives.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;‚ÄúCommunity advocates have a voice and should be included in these conversations,‚Äù Celi says. ‚ÄúAI and statistical modeling can‚Äôt collect all the data needed to treat all the people who need it.‚Äù&lt;/p&gt;&lt;p dir="ltr"&gt;Community needs and improved educational opportunities and practices should be coupled with cross-disciplinary approaches to knowledge acquisition and transfer. The ways people see things are limited by their perceptions and other factors. ‚ÄúWhose language are we modeling?‚Äù Gameiro asks about building LLMs. ‚ÄúWhich varieties of speech are being included or excluded?‚Äù Since meaning and intent can shift across those contexts, it‚Äôs important to remember these when designing AI tools.&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;‚ÄúAI is our chance to rewrite the rules‚Äù&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;While there‚Äôs lots of potential in the collaboration, there are serious challenges to overcome, including establishing and scaling the technological means to improve patient-provider communication with AI, extending opportunities for collaboration to marginalized and underserved communities, and reconsidering and revamping patient care.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;But the team isn‚Äôt daunted.&lt;/p&gt;&lt;p dir="ltr"&gt;Celi believes there are opportunities to address the widening gap between people and practitioners while addressing gaps in health care. ‚ÄúOur intent is to reattach the string that‚Äôs been cut between society and science,‚Äù he says. ‚ÄúWe can empower scientists and the public to investigate the world together while also acknowledging the limitations engendered in overcoming their biases.‚Äù&lt;/p&gt;&lt;p dir="ltr"&gt;Gameiro is a passionate advocate for AI‚Äôs ability to change everything we know about medicine. ‚ÄúI‚Äôm a medical doctor, and I don‚Äôt think I‚Äôm being hyperbolic when I say I believe AI is our chance to rewrite the rules of what medicine can do and who we can reach,‚Äù he says.&lt;/p&gt;&lt;p dir="ltr"&gt;‚ÄúEducation changes humans from objects to subjects,‚Äù Urlaub argues, describing the difference between disinterested observers and active and engaged participants in the new care model he hopes to build. ‚ÄúWe need to better understand technology‚Äôs impact on the lines between these states of being.‚Äù&lt;/p&gt;&lt;p dir="ltr"&gt;Celi, Gameiro, and Urlaub each advocate for MITHIC-like spaces across health care, places where innovation and collaboration are allowed to occur without the kinds of arbitrary benchmarks institutions have previously used to mark success.&lt;/p&gt;&lt;p dir="ltr"&gt;‚ÄúAI will transform all these sectors,‚Äù Urlaub believes. ‚ÄúMITHIC is a generous framework that allows us to embrace uncertainty with flexibility.‚Äù&lt;/p&gt;&lt;p dir="ltr"&gt;‚ÄúWe want to employ our power to build community among disparate audiences while admitting we don‚Äôt have all the answers,‚Äù Celi says. ‚ÄúIf we fail, it‚Äôs because we failed to dream big enough about how a reimagined world could look.‚Äù&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202506/mit-language-ai-incubator.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr"&gt;Generative artificial intelligence is transforming the ways humans write, read, speak, think, empathize, and act within and across languages and cultures. In health care, gaps in communication between patients and practitioners can worsen patient outcomes and prevent improvements in practice and care. The Language/AI Incubator, made possible through funding from the&amp;nbsp;MIT Human Insight Collaborative (MITHIC), offers a potential response to these challenges.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;The project envisions a research community rooted in the humanities that will foster interdisciplinary collaboration across MIT to deepen understanding of generative AI‚Äôs impact on cross-linguistic and cross-cultural communication. The project‚Äôs focus on health care and communication seeks to build bridges across socioeconomic, cultural, and linguistic strata.&lt;/p&gt;&lt;p dir="ltr"&gt;The incubator is co-led by&amp;nbsp;Leo Celi, a physician and the research director and senior research scientist with the&amp;nbsp;Institute for Medical Engineering and Science (IMES), and&amp;nbsp;Per Urlaub, professor of the practice in German and second language studies and director of MIT‚Äôs&amp;nbsp;Global Languages program.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;‚ÄúThe basis of health care delivery is the knowledge of health and disease,‚Äù Celi says. ‚ÄúWe‚Äôre seeing poor outcomes despite massive investments because our knowledge system is broken.‚Äù&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A chance collaboration&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;Urlaub and Celi met during a MITHIC launch event. Conversations during the event reception revealed a shared interest in exploring improvements in medical communication and practice with AI.&lt;/p&gt;&lt;p dir="ltr"&gt;‚ÄúWe‚Äôre trying to incorporate data science into health-care delivery,‚Äù Celi says. ‚ÄúWe‚Äôve been recruiting social scientists [at IMES] to help advance our work, because the science we create isn‚Äôt neutral.‚Äù&lt;/p&gt;&lt;p dir="ltr"&gt;Language is a non-neutral mediator in health care delivery, the team believes, and can be a boon or barrier to effective treatment. ‚ÄúLater, after we met, I joined one of his working groups whose focus was metaphors for pain: the language we use to describe it and its measurement,‚Äù Urlaub continues. ‚ÄúOne of the questions we considered was how effective communication can occur between doctors and patients.‚Äù&lt;/p&gt;&lt;p dir="ltr"&gt;Technology, they argue, impacts casual communication, and its impact depends on both users and creators. As AI and large language models (LLMs) gain power and prominence, their use is broadening to include fields like health care and wellness.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;Rodrigo Gameiro, a physician and researcher with MIT‚Äôs Laboratory for Computational Physiology, is another program participant. He notes that work at the laboratory centers responsible AI development and implementation. Designing systems that leverage AI effectively, particularly when considering challenges related to communicating across linguistic and cultural divides that can occur in health care, demands a nuanced approach.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;‚ÄúWhen we build AI systems that interact with human language, we‚Äôre not just teaching machines how to process words; we‚Äôre teaching them to navigate the complex web of meaning embedded in language,‚Äù Gameiro says.&lt;/p&gt;&lt;p dir="ltr"&gt;Language‚Äôs complexities can impact treatment and patient care. ‚ÄúPain can only be communicated through metaphor,‚Äù Urlaub continues, ‚Äúbut metaphors don‚Äôt always match, linguistically and culturally.‚Äù Smiley faces and one-to-10 scales ‚Äî pain measurement tools English-speaking medical professionals may use to assess their patients ‚Äî may not travel well across racial, ethnic, cultural, and language boundaries.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;‚ÄúScience has to have a heart‚Äù&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;LLMs can potentially help scientists improve health care, although there are some systemic and pedagogical challenges to consider. Science can focus on outcomes to the exclusion of the people it‚Äôs meant to help, Celi argues. ‚ÄúScience has to have a heart,‚Äù he says. ‚ÄúMeasuring students‚Äô effectiveness by counting the number of papers they publish or patents they produce misses the point.‚Äù&lt;/p&gt;&lt;p dir="ltr"&gt;The point, Urlaub says, is to investigate carefully while simultaneously acknowledging what we don‚Äôt know, citing what philosophers call Epistemic Humility. Knowledge, the investigators argue, is provisional, and always incomplete. Deeply held beliefs may require revision in light of new evidence.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;‚ÄúNo one‚Äôs mental view of the world is complete,‚Äù Celi says. ‚ÄúYou need to create an environment in which people are comfortable acknowledging their biases.‚Äù&lt;/p&gt;&lt;p dir="ltr"&gt;‚ÄúHow do we share concerns between language educators and others interested in AI?‚Äù Urlaub asks. ‚ÄúHow do we identify and investigate the relationship between medical professionals and language educators interested in AI‚Äôs potential to aid in the elimination of gaps in communication between doctors and patients?‚Äù&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;Language, in Gameiro‚Äôs estimation, is more than just a tool for communication. ‚ÄúIt reflects culture, identity, and power dynamics,‚Äù he says. In situations where a patient might not be comfortable describing pain or discomfort because of the physician‚Äôs position as an authority, or because their culture demands yielding to those perceived as authority figures, misunderstandings can be dangerous.&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Changing the conversation&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;AI‚Äôs facility with language can help medical professionals navigate these areas more carefully, providing digital frameworks offering valuable cultural and linguistic contexts in which patient and practitioner can rely on data-driven, research-supported tools to improve dialogue. Institutions need to reconsider how they educate medical professionals and invite the communities they serve into the conversation, the team says.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;‚ÄòWe need to ask ourselves what we truly want,‚Äù Celi says. ‚ÄúWhy are we measuring what we‚Äôre measuring?‚Äù The biases we bring with us to these interactions ‚Äî doctors, patients, their families, and their communities ‚Äî remain barriers to improved care, Urlaub and Gameiro say.&lt;/p&gt;&lt;p dir="ltr"&gt;‚ÄúWe want to connect people who think differently, and make AI work for everyone,‚Äù Gameiro continues. ‚ÄúTechnology without purpose is just exclusion at scale.‚Äù&lt;/p&gt;&lt;p dir="ltr"&gt;‚ÄúCollaborations like these can allow for deep processing and better ideas,‚Äù Urlaub says.&lt;/p&gt;&lt;p dir="ltr"&gt;Creating spaces where ideas about AI and health care can potentially become actions is a key element of the project. The Language/AI Incubator hosted its first colloquium at MIT in May, which was led by Mena Ramos, a physician and the co-founder and CEO of the&amp;nbsp;Global Ultrasound Institute.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;The colloquium also featured presentations from Celi, as well as Alfred Spector, a visiting scholar in MIT‚Äôs&amp;nbsp;Department of Electrical Engineering and Computer Science, and Douglas Jones, a senior staff member in the MIT Lincoln Laboratory‚Äôs Human Language Technology Group. A second Language/AI Incubator colloquium is planned for August.&lt;/p&gt;&lt;p dir="ltr"&gt;Greater integration between the social and hard sciences can potentially increase the likelihood of developing viable solutions and reducing biases. Allowing for shifts in the ways patients and doctors view the relationship, while offering each shared ownership of the interaction, can help improve outcomes. Facilitating these conversations with AI may speed the integration of these perspectives.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;‚ÄúCommunity advocates have a voice and should be included in these conversations,‚Äù Celi says. ‚ÄúAI and statistical modeling can‚Äôt collect all the data needed to treat all the people who need it.‚Äù&lt;/p&gt;&lt;p dir="ltr"&gt;Community needs and improved educational opportunities and practices should be coupled with cross-disciplinary approaches to knowledge acquisition and transfer. The ways people see things are limited by their perceptions and other factors. ‚ÄúWhose language are we modeling?‚Äù Gameiro asks about building LLMs. ‚ÄúWhich varieties of speech are being included or excluded?‚Äù Since meaning and intent can shift across those contexts, it‚Äôs important to remember these when designing AI tools.&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;‚ÄúAI is our chance to rewrite the rules‚Äù&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;While there‚Äôs lots of potential in the collaboration, there are serious challenges to overcome, including establishing and scaling the technological means to improve patient-provider communication with AI, extending opportunities for collaboration to marginalized and underserved communities, and reconsidering and revamping patient care.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;But the team isn‚Äôt daunted.&lt;/p&gt;&lt;p dir="ltr"&gt;Celi believes there are opportunities to address the widening gap between people and practitioners while addressing gaps in health care. ‚ÄúOur intent is to reattach the string that‚Äôs been cut between society and science,‚Äù he says. ‚ÄúWe can empower scientists and the public to investigate the world together while also acknowledging the limitations engendered in overcoming their biases.‚Äù&lt;/p&gt;&lt;p dir="ltr"&gt;Gameiro is a passionate advocate for AI‚Äôs ability to change everything we know about medicine. ‚ÄúI‚Äôm a medical doctor, and I don‚Äôt think I‚Äôm being hyperbolic when I say I believe AI is our chance to rewrite the rules of what medicine can do and who we can reach,‚Äù he says.&lt;/p&gt;&lt;p dir="ltr"&gt;‚ÄúEducation changes humans from objects to subjects,‚Äù Urlaub argues, describing the difference between disinterested observers and active and engaged participants in the new care model he hopes to build. ‚ÄúWe need to better understand technology‚Äôs impact on the lines between these states of being.‚Äù&lt;/p&gt;&lt;p dir="ltr"&gt;Celi, Gameiro, and Urlaub each advocate for MITHIC-like spaces across health care, places where innovation and collaboration are allowed to occur without the kinds of arbitrary benchmarks institutions have previously used to mark success.&lt;/p&gt;&lt;p dir="ltr"&gt;‚ÄúAI will transform all these sectors,‚Äù Urlaub believes. ‚ÄúMITHIC is a generous framework that allows us to embrace uncertainty with flexibility.‚Äù&lt;/p&gt;&lt;p dir="ltr"&gt;‚ÄúWe want to employ our power to build community among disparate audiences while admitting we don‚Äôt have all the answers,‚Äù Celi says. ‚ÄúIf we fail, it‚Äôs because we failed to dream big enough about how a reimagined world could look.‚Äù&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/changing-conversation-health-care-0709</guid><pubDate>Wed, 09 Jul 2025 20:50:00 +0000</pubDate></item><item><title>[NEW] California lawmaker behind SB 1047 reignites push for mandated AI safety reports (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/09/california-lawmaker-behind-sb-1047-reignites-push-for-mandated-ai-safety-reports/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/08/GettyImages-950173010.jpg?resize=1200,861" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;California State Senator Scott Wiener on Wednesday introduced new amendments to his latest bill, SB 53, that would require the world‚Äôs largest AI companies to publish safety and security protocols and issue reports when safety incidents occur.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If signed into law, California would be the first state to impose meaningful transparency requirements onto leading AI developers, likely including OpenAI, Google, Anthropic, and xAI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Senator Wiener‚Äôs previous AI bill, SB 1047, included similar requirements for AI model developers to publish safety reports. However, Silicon Valley fought ferociously against that bill, and it was ultimately vetoed by Governor Gavin Newsom. California‚Äôs governor then called for a group of AI leaders ‚Äî including the leading Stanford researcher and co-founder of World Labs, Fei-Fei Li ‚Äî to form a policy group and set goals for the state‚Äôs AI safety efforts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;California‚Äôs AI policy group recently published their final recommendations, citing a need for ‚Äúrequirements on industry to publish information about their systems‚Äù in order to establish a ‚Äúrobust and transparent evidence environment.‚Äù Senator Wiener‚Äôs office said in a press release that SB 53‚Äôs amendments were heavily influenced by this report.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúThe bill continues to be a work in progress, and I look forward to working with all stakeholders in the coming weeks to refine this proposal into the most scientific and fair law it can be,‚Äù Senator Wiener said in the release.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SB 53 aims to strike a balance that Governor Newsom claimed SB 1047 failed to achieve ‚Äî ideally, creating meaningful transparency requirements for the largest AI developers without thwarting the rapid growth of California‚Äôs AI industry.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúThese are concerns that my organization and others have been talking about for a while,‚Äù said Nathan Calvin, VP of State Affairs for the nonprofit AI safety group, Encode, in an interview with TechCrunch. ‚ÄúHaving companies explain to the public and government what measures they‚Äôre taking to address these risks feels like a bare minimum, reasonable step to take.‚Äù&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The bill also creates whistleblower protections for employees of AI labs who believe their company‚Äôs technology poses a ‚Äúcritical risk‚Äù to society ‚Äî defined in the bill as contributing to the death or injury of more than 100 people, or more than $1 billion in damage. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Additionally, the bill aims to create CalCompute, a public cloud computing cluster to support startups and researchers developing large-scale AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike SB 1047, Senator Wiener‚Äôs new bill does not make AI model developers liable for the harms of their AI models. SB 53 was also designed not to pose a burden on startups and researchers that fine-tune AI models from leading AI developers, or use open source models.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With the new amendments, SB 53 is now headed to the California State Assembly Committee on Privacy and Consumer Protection for approval. Should it pass there, the bill will also need to pass through several other legislative bodies before reaching Governor Newsom‚Äôs desk.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the other side of the U.S., New York Governor Kathy Hochul is now considering a similar AI safety bill, the RAISE Act, which would also require large AI developers to publish safety and security reports.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The fate of state AI laws like the RAISE Act and SB 53 were briefly in jeopardy as federal lawmakers considered a 10-year AI moratorium on state AI regulation ‚Äî an attempt to limit a ‚Äúpatchwork‚Äù of AI laws that companies would have to navigate. However, that proposal failed in a 99-1 Senate vote earlier in July.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúEnsuring AI is developed safely should not be controversial ‚Äî it should be foundational,‚Äù said Geoff Ralston, the former president of Y Combinator, in a statement to TechCrunch. ‚ÄúCongress should be leading, demanding transparency and accountability from the companies building frontier models. But with no serious federal action in sight, states must step up. California‚Äôs SB 53 is a thoughtful, well-structured example of state leadership.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Up to this point, lawmakers have failed to get AI companies on board with state-mandated transparency requirements. Anthropic has broadly endorsed the need for increased transparency into AI companies, and even expressed modest optimism about the recommendations from California‚Äôs AI policy group. But companies such as OpenAI, Google, and Meta have been more resistant to these efforts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Leading AI model developers typically publish safety reports for their AI models, but they‚Äôve been less consistent in recent months. Google, for example, decided not to publish a safety report for its most advanced AI model ever released, Gemini 2.5 Pro, until months after it was made available. OpenAI also decided not to publish a safety report for its GPT-4.1 model. Later, a third-party study came out that suggested it may be less aligned than previous AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SB 53 represents a toned-down version of previous AI safety bills, but it still could force AI companies to publish more information than they do today. For now, they‚Äôll be watching closely as Senator Wiener once again tests those boundaries.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/08/GettyImages-950173010.jpg?resize=1200,861" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;California State Senator Scott Wiener on Wednesday introduced new amendments to his latest bill, SB 53, that would require the world‚Äôs largest AI companies to publish safety and security protocols and issue reports when safety incidents occur.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If signed into law, California would be the first state to impose meaningful transparency requirements onto leading AI developers, likely including OpenAI, Google, Anthropic, and xAI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Senator Wiener‚Äôs previous AI bill, SB 1047, included similar requirements for AI model developers to publish safety reports. However, Silicon Valley fought ferociously against that bill, and it was ultimately vetoed by Governor Gavin Newsom. California‚Äôs governor then called for a group of AI leaders ‚Äî including the leading Stanford researcher and co-founder of World Labs, Fei-Fei Li ‚Äî to form a policy group and set goals for the state‚Äôs AI safety efforts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;California‚Äôs AI policy group recently published their final recommendations, citing a need for ‚Äúrequirements on industry to publish information about their systems‚Äù in order to establish a ‚Äúrobust and transparent evidence environment.‚Äù Senator Wiener‚Äôs office said in a press release that SB 53‚Äôs amendments were heavily influenced by this report.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúThe bill continues to be a work in progress, and I look forward to working with all stakeholders in the coming weeks to refine this proposal into the most scientific and fair law it can be,‚Äù Senator Wiener said in the release.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SB 53 aims to strike a balance that Governor Newsom claimed SB 1047 failed to achieve ‚Äî ideally, creating meaningful transparency requirements for the largest AI developers without thwarting the rapid growth of California‚Äôs AI industry.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúThese are concerns that my organization and others have been talking about for a while,‚Äù said Nathan Calvin, VP of State Affairs for the nonprofit AI safety group, Encode, in an interview with TechCrunch. ‚ÄúHaving companies explain to the public and government what measures they‚Äôre taking to address these risks feels like a bare minimum, reasonable step to take.‚Äù&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The bill also creates whistleblower protections for employees of AI labs who believe their company‚Äôs technology poses a ‚Äúcritical risk‚Äù to society ‚Äî defined in the bill as contributing to the death or injury of more than 100 people, or more than $1 billion in damage. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Additionally, the bill aims to create CalCompute, a public cloud computing cluster to support startups and researchers developing large-scale AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike SB 1047, Senator Wiener‚Äôs new bill does not make AI model developers liable for the harms of their AI models. SB 53 was also designed not to pose a burden on startups and researchers that fine-tune AI models from leading AI developers, or use open source models.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With the new amendments, SB 53 is now headed to the California State Assembly Committee on Privacy and Consumer Protection for approval. Should it pass there, the bill will also need to pass through several other legislative bodies before reaching Governor Newsom‚Äôs desk.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the other side of the U.S., New York Governor Kathy Hochul is now considering a similar AI safety bill, the RAISE Act, which would also require large AI developers to publish safety and security reports.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The fate of state AI laws like the RAISE Act and SB 53 were briefly in jeopardy as federal lawmakers considered a 10-year AI moratorium on state AI regulation ‚Äî an attempt to limit a ‚Äúpatchwork‚Äù of AI laws that companies would have to navigate. However, that proposal failed in a 99-1 Senate vote earlier in July.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúEnsuring AI is developed safely should not be controversial ‚Äî it should be foundational,‚Äù said Geoff Ralston, the former president of Y Combinator, in a statement to TechCrunch. ‚ÄúCongress should be leading, demanding transparency and accountability from the companies building frontier models. But with no serious federal action in sight, states must step up. California‚Äôs SB 53 is a thoughtful, well-structured example of state leadership.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Up to this point, lawmakers have failed to get AI companies on board with state-mandated transparency requirements. Anthropic has broadly endorsed the need for increased transparency into AI companies, and even expressed modest optimism about the recommendations from California‚Äôs AI policy group. But companies such as OpenAI, Google, and Meta have been more resistant to these efforts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Leading AI model developers typically publish safety reports for their AI models, but they‚Äôve been less consistent in recent months. Google, for example, decided not to publish a safety report for its most advanced AI model ever released, Gemini 2.5 Pro, until months after it was made available. OpenAI also decided not to publish a safety report for its GPT-4.1 model. Later, a third-party study came out that suggested it may be less aligned than previous AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SB 53 represents a toned-down version of previous AI safety bills, but it still could force AI companies to publish more information than they do today. For now, they‚Äôll be watching closely as Senator Wiener once again tests those boundaries.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/09/california-lawmaker-behind-sb-1047-reignites-push-for-mandated-ai-safety-reports/</guid><pubDate>Wed, 09 Jul 2025 20:54:30 +0000</pubDate></item><item><title>[NEW] Cloudflare wants Google to change its AI search crawling. Google likely won‚Äôt. (AI ‚Äì Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/07/cloudflare-wants-google-to-change-its-ai-search-crawling-google-likely-wont/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Cloudflare pushes Google to separate bots for AI Overviews and search indexing.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1186369127-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1186369127-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Sundry Photography | iStock Editorial / Getty Images Plus

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;After Cloudflare started testing new features that would allow websites to block AI crawlers or require payment for scraping, the tech company immediately faced questions over the logistics of the plan.&lt;/p&gt;
&lt;p&gt;In particular, website owners and SEO experts wanted to know how Cloudflare planned to block Google's bot from scraping sites to fuel AI overviews without risking blocking the same bot from crawling for valuable search engine placements.&lt;/p&gt;
&lt;p&gt;Last week, a travel blogger raised questions about the blocking and so-called pay-per-crawl features pushed Cloudflare CEO Matthew Prince to respond on X (formerly Twitter).&lt;/p&gt;
&lt;p&gt;"We will get Google to provide ways to block Answer Box and AI Overview, without blocking classic search indexing, as well," Prince said. Asked if that was even possible, Prince doubled down, responding, "it is. #staytuned"&lt;/p&gt;
&lt;p&gt;In another post responding to a search engine optimization specialist, he claimed that Cloudflare was in "encouraging" talks with Google that he hopes will result in Google separating its crawlers to better work in Cloudflare's system. But if those talks go nowhere, he revealed Cloudflare is pushing for a law to be passed that's considered a "very viable option" in "many jurisdictions."&lt;/p&gt;
&lt;p&gt;"Worst case we‚Äôll pass a law somewhere that requires them to break out their crawlers and then announce all routes to their crawlers from there," Prince said. "And that wouldn‚Äôt be hard. But I‚Äôm hopeful it won‚Äôt need to come to that."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Ars could not immediately find any legislation that seemed to match Prince's description, and Cloudflare did not respond to Ars' request to comment. Passing tech laws is notoriously hard, though, partly because technology keeps advancing as policy debates drag on, and challenges with regulating artificial intelligence are an obvious example of that pattern today.&lt;/p&gt;
&lt;p&gt;Google declined Ars' request to confirm whether talks were underway or if the company was open to separating its crawlers.&lt;/p&gt;
&lt;p&gt;Although Cloudflare singled out Google, other search engines that view AI search features as part of their search products also use the same bots for training as they do for search indexing. It seems likely that Cloudflare's proposed legislation would face resistance from tech companies in a similar position to Google, as The Wall Street Journal reported that the tech companies "have few incentives to work with intermediaries."&lt;/p&gt;
&lt;p&gt;Additionally, Cloudflare's initiative faces criticism from those who "worry that academic research, security scans, and other types of benign web crawling will get elbowed out of websites as barriers are built around more sites" through Cloudflare's blocks and paywalls, the WSJ reported. Cloudflare's system could also threaten web projects like The Internet Archive, which notably played a crucial role in helping track data deleted from government websites after Donald Trump took office.&lt;/p&gt;
&lt;p&gt;Among commenters discussing Cloudflare's claims about Google on Search Engine Round Table, one user suggested Cloudflare may risk a lawsuit or other penalties from Google for poking the bear.&lt;/p&gt;
&lt;p&gt;Ars will continue monitoring for updates on Cloudflare's attempts to get Google on board with its plan.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Cloudflare pushes Google to separate bots for AI Overviews and search indexing.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1186369127-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1186369127-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Sundry Photography | iStock Editorial / Getty Images Plus

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;After Cloudflare started testing new features that would allow websites to block AI crawlers or require payment for scraping, the tech company immediately faced questions over the logistics of the plan.&lt;/p&gt;
&lt;p&gt;In particular, website owners and SEO experts wanted to know how Cloudflare planned to block Google's bot from scraping sites to fuel AI overviews without risking blocking the same bot from crawling for valuable search engine placements.&lt;/p&gt;
&lt;p&gt;Last week, a travel blogger raised questions about the blocking and so-called pay-per-crawl features pushed Cloudflare CEO Matthew Prince to respond on X (formerly Twitter).&lt;/p&gt;
&lt;p&gt;"We will get Google to provide ways to block Answer Box and AI Overview, without blocking classic search indexing, as well," Prince said. Asked if that was even possible, Prince doubled down, responding, "it is. #staytuned"&lt;/p&gt;
&lt;p&gt;In another post responding to a search engine optimization specialist, he claimed that Cloudflare was in "encouraging" talks with Google that he hopes will result in Google separating its crawlers to better work in Cloudflare's system. But if those talks go nowhere, he revealed Cloudflare is pushing for a law to be passed that's considered a "very viable option" in "many jurisdictions."&lt;/p&gt;
&lt;p&gt;"Worst case we‚Äôll pass a law somewhere that requires them to break out their crawlers and then announce all routes to their crawlers from there," Prince said. "And that wouldn‚Äôt be hard. But I‚Äôm hopeful it won‚Äôt need to come to that."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Ars could not immediately find any legislation that seemed to match Prince's description, and Cloudflare did not respond to Ars' request to comment. Passing tech laws is notoriously hard, though, partly because technology keeps advancing as policy debates drag on, and challenges with regulating artificial intelligence are an obvious example of that pattern today.&lt;/p&gt;
&lt;p&gt;Google declined Ars' request to confirm whether talks were underway or if the company was open to separating its crawlers.&lt;/p&gt;
&lt;p&gt;Although Cloudflare singled out Google, other search engines that view AI search features as part of their search products also use the same bots for training as they do for search indexing. It seems likely that Cloudflare's proposed legislation would face resistance from tech companies in a similar position to Google, as The Wall Street Journal reported that the tech companies "have few incentives to work with intermediaries."&lt;/p&gt;
&lt;p&gt;Additionally, Cloudflare's initiative faces criticism from those who "worry that academic research, security scans, and other types of benign web crawling will get elbowed out of websites as barriers are built around more sites" through Cloudflare's blocks and paywalls, the WSJ reported. Cloudflare's system could also threaten web projects like The Internet Archive, which notably played a crucial role in helping track data deleted from government websites after Donald Trump took office.&lt;/p&gt;
&lt;p&gt;Among commenters discussing Cloudflare's claims about Google on Search Engine Round Table, one user suggested Cloudflare may risk a lawsuit or other penalties from Google for poking the bear.&lt;/p&gt;
&lt;p&gt;Ars will continue monitoring for updates on Cloudflare's attempts to get Google on board with its plan.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/07/cloudflare-wants-google-to-change-its-ai-search-crawling-google-likely-wont/</guid><pubDate>Wed, 09 Jul 2025 21:00:00 +0000</pubDate></item><item><title>[NEW] ChatGPT made up a product feature out of thin air, so this company created it (AI ‚Äì Ars Technica)</title><link>https://arstechnica.com/ai/2025/07/chatgpt-made-up-a-product-feature-out-of-thin-air-so-this-company-created-it/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Soundslice caught OpenAI's bot telling users about a fake music notation feature‚Äîthen built it.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Orchestra conductor watching AI robot conduct music notes on beige background - stock illustration" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/surprise_music_2-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Orchestra conductor watching AI robot conduct music notes on beige background - stock illustration" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/surprise_music_2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Malte Mueller via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Monday, sheet music platform Soundslice says it developed a new feature after discovering that ChatGPT was incorrectly telling users the service could import ASCII tablature‚Äîa text-based guitar notation format the company had never supported. The incident reportedly marks what might be the first case of a business building functionality in direct response to an AI model's confabulation.&lt;/p&gt;
&lt;p&gt;Typically, Soundslice digitizes sheet music from photos or PDFs and syncs the notation with audio or video recordings, allowing musicians to see the music scroll by as they hear it played. The platform also includes tools for slowing down playback and practicing difficult passages.&lt;/p&gt;
&lt;p&gt;Adrian Holovaty, co-founder of Soundslice, wrote in a recent blog post that the recent feature development process began as a complete mystery. A few months ago, Holovaty began noticing unusual&amp;nbsp;activity in the company's error logs. Instead of typical sheet music uploads, users were submitting screenshots of ChatGPT conversations containing ASCII tablature‚Äîsimple text representations of guitar music that look like strings with numbers indicating fret positions.&lt;/p&gt;
&lt;p&gt;"Our scanning system wasn't intended to support this style of notation," wrote Holovaty in the blog post. "Why, then, were we being bombarded with so many ASCII tab ChatGPT screenshots? I was mystified for weeks‚Äîuntil I messed around with ChatGPT myself."&lt;/p&gt;
&lt;p&gt;When Holovaty tested ChatGPT, he discovered the source of the confusion: The AI model was instructing users to create Soundslice accounts and use the platform to import ASCII tabs for audio playback‚Äîa feature that didn't exist. "We've never supported ASCII tab; ChatGPT was outright lying to people," Holovaty wrote. "And making us look bad in the process, setting false expectations about our service."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2105045 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="A screenshot of Soundslice's new ASCII tab importer documentation." class="center large" height="723" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/ascii_tabs-1024x723.png" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A screenshot of Soundslice's new ASCII tab importer documentation, hallucinated by ChatGPT and made real later.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          https://www.soundslice.com/help/en/creating/importing/331/ascii-tab/

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;When AI models like ChatGPT generate false information with apparent confidence, AI researchers call it a "hallucination" or&amp;nbsp; "confabulation." The problem of AI models confabulating false information has plagued AI models since ChatGPT's public release in November 2022, when people began erroneously using the chatbot as a replacement for a search engine.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;As prediction machines, large language models trained on massive text datasets can easily produce outputs that seem plausible but are completely inaccurate. The models statistically improvise to fill "knowledge" gaps on topics poorly represented in their training data, generating text based on statistical patterns rather than factual accuracy. In this way, ChatGPT told its users what they wanted to hear by making up a Soundslice feature that made sense but didn't exist.&lt;/p&gt;
&lt;p&gt;Usually, confabulations get people in trouble. In one notable case from 2023, lawyers faced sanctions after submitting legal briefs containing ChatGPT-generated citations to non-existent court cases. In February 2024, Canada's Civil Resolution Tribunal ordered Air Canada to pay damages to a customer and honor a bereavement fare policy that was hallucinated by a support chatbot, which incorrectly stated that customers could retroactively request a bereavement discount within 90 days of the date the ticket was issued.&lt;/p&gt;
&lt;h2&gt;From bug to feature&lt;/h2&gt;
&lt;p&gt;The discovery presented Soundslice with an unusual dilemma. The company could have posted disclaimers warning users to ignore ChatGPT's claims, but instead chose a different path. "We ended up deciding: what the heck, we might as well meet the market demand," Holovaty explained. The team built an ASCII tab importer‚Äîa feature that had been "near the bottom of my 'Software I expected to write in 2025' list"‚Äîand updated their user interface to inform users about the new capability.&lt;/p&gt;
&lt;p&gt;Soundslice's solution presents an interesting case of making lemonade from lemons, but for Holovaty, the situation raises philosophical questions about product development. "My feelings on this are conflicted," he wrote. "I'm happy to add a tool that helps people. But I feel like our hand was forced in a weird way. Should we really be developing features in response to misinformation?"&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Soundslice caught OpenAI's bot telling users about a fake music notation feature‚Äîthen built it.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Orchestra conductor watching AI robot conduct music notes on beige background - stock illustration" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/surprise_music_2-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Orchestra conductor watching AI robot conduct music notes on beige background - stock illustration" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/surprise_music_2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Malte Mueller via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Monday, sheet music platform Soundslice says it developed a new feature after discovering that ChatGPT was incorrectly telling users the service could import ASCII tablature‚Äîa text-based guitar notation format the company had never supported. The incident reportedly marks what might be the first case of a business building functionality in direct response to an AI model's confabulation.&lt;/p&gt;
&lt;p&gt;Typically, Soundslice digitizes sheet music from photos or PDFs and syncs the notation with audio or video recordings, allowing musicians to see the music scroll by as they hear it played. The platform also includes tools for slowing down playback and practicing difficult passages.&lt;/p&gt;
&lt;p&gt;Adrian Holovaty, co-founder of Soundslice, wrote in a recent blog post that the recent feature development process began as a complete mystery. A few months ago, Holovaty began noticing unusual&amp;nbsp;activity in the company's error logs. Instead of typical sheet music uploads, users were submitting screenshots of ChatGPT conversations containing ASCII tablature‚Äîsimple text representations of guitar music that look like strings with numbers indicating fret positions.&lt;/p&gt;
&lt;p&gt;"Our scanning system wasn't intended to support this style of notation," wrote Holovaty in the blog post. "Why, then, were we being bombarded with so many ASCII tab ChatGPT screenshots? I was mystified for weeks‚Äîuntil I messed around with ChatGPT myself."&lt;/p&gt;
&lt;p&gt;When Holovaty tested ChatGPT, he discovered the source of the confusion: The AI model was instructing users to create Soundslice accounts and use the platform to import ASCII tabs for audio playback‚Äîa feature that didn't exist. "We've never supported ASCII tab; ChatGPT was outright lying to people," Holovaty wrote. "And making us look bad in the process, setting false expectations about our service."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2105045 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="A screenshot of Soundslice's new ASCII tab importer documentation." class="center large" height="723" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/ascii_tabs-1024x723.png" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A screenshot of Soundslice's new ASCII tab importer documentation, hallucinated by ChatGPT and made real later.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          https://www.soundslice.com/help/en/creating/importing/331/ascii-tab/

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;When AI models like ChatGPT generate false information with apparent confidence, AI researchers call it a "hallucination" or&amp;nbsp; "confabulation." The problem of AI models confabulating false information has plagued AI models since ChatGPT's public release in November 2022, when people began erroneously using the chatbot as a replacement for a search engine.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;As prediction machines, large language models trained on massive text datasets can easily produce outputs that seem plausible but are completely inaccurate. The models statistically improvise to fill "knowledge" gaps on topics poorly represented in their training data, generating text based on statistical patterns rather than factual accuracy. In this way, ChatGPT told its users what they wanted to hear by making up a Soundslice feature that made sense but didn't exist.&lt;/p&gt;
&lt;p&gt;Usually, confabulations get people in trouble. In one notable case from 2023, lawyers faced sanctions after submitting legal briefs containing ChatGPT-generated citations to non-existent court cases. In February 2024, Canada's Civil Resolution Tribunal ordered Air Canada to pay damages to a customer and honor a bereavement fare policy that was hallucinated by a support chatbot, which incorrectly stated that customers could retroactively request a bereavement discount within 90 days of the date the ticket was issued.&lt;/p&gt;
&lt;h2&gt;From bug to feature&lt;/h2&gt;
&lt;p&gt;The discovery presented Soundslice with an unusual dilemma. The company could have posted disclaimers warning users to ignore ChatGPT's claims, but instead chose a different path. "We ended up deciding: what the heck, we might as well meet the market demand," Holovaty explained. The team built an ASCII tab importer‚Äîa feature that had been "near the bottom of my 'Software I expected to write in 2025' list"‚Äîand updated their user interface to inform users about the new capability.&lt;/p&gt;
&lt;p&gt;Soundslice's solution presents an interesting case of making lemonade from lemons, but for Holovaty, the situation raises philosophical questions about product development. "My feelings on this are conflicted," he wrote. "I'm happy to add a tool that helps people. But I feel like our hand was forced in a weird way. Should we really be developing features in response to misinformation?"&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/07/chatgpt-made-up-a-product-feature-out-of-thin-air-so-this-company-created-it/</guid><pubDate>Wed, 09 Jul 2025 21:59:25 +0000</pubDate></item><item><title>[NEW] Microsoft shares $500M in AI savings internally days after cutting 9,000 jobs (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/09/microsoft-shares-500m-in-ai-savings-internally-days-after-cutting-9000-jobs/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/Copilot-Hero-Image.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Microsoft‚Äôs chief commercial officer Judson Althoff said during a presentation this week that AI tools are boosting productivity across sales, customer service, and software engineering, Bloomberg reports. Althoff noted AI has been so useful that Microsoft was able to save more than $500 million last year in its call center alone.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The internal remarks come a week after Microsoft laid off more than 9,000 workers, the company‚Äôs third round of layoffs this year that put the total number of affected employees somewhere around 15,000.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For employees who lost their jobs while working at a company that is reporting impressive cost-savings and recording one of its most profitable quarters yet, Althoff‚Äôs remarks might come off as tone deaf.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The situation had already been complicated by a now-deleted LinkedIn post from Xbox Game Studios‚Äô producer Matt Turnbull, who last week suggested that workers feeling ‚Äúoverwhelmed‚Äù by Microsoft‚Äôs layoffs ‚Äî which included job cuts across Xbox ‚Äî might find support through AI tools like ChatGPT and Copilot to help manage the cognitive load that comes with job loss.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It‚Äôs not clear whether the thousands of workers who lost their jobs this year were replaced by AI or whether the layoffs represent post-pandemic right-sizing. What is clear is that workforce adjustments during a period of record profitability creates a challenging dynamic that, for some, has to sting. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft closed out the first quarter with $26 billion in profit and $70 billion in revenue. The company‚Äôs market capitalization has also surged in recent months to around $3.74 trillion, displacing Apple and trailing only Nvidia.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft has signaled that much of that profit will flow directly into AI. The company said in January it would invest $80 billion into AI infrastructure across 2025. While Microsoft continues to hire talent, too, the company appears positioned to more actively participate in the industrywide competition of ‚ÄúWho Can Pay Top AI Researchers The Most?‚Äù In short, it‚Äôs more likely we‚Äôll see Microsoft spend millions of dollars on top AI researchers rather than middle managers and other employees.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/Copilot-Hero-Image.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Microsoft‚Äôs chief commercial officer Judson Althoff said during a presentation this week that AI tools are boosting productivity across sales, customer service, and software engineering, Bloomberg reports. Althoff noted AI has been so useful that Microsoft was able to save more than $500 million last year in its call center alone.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The internal remarks come a week after Microsoft laid off more than 9,000 workers, the company‚Äôs third round of layoffs this year that put the total number of affected employees somewhere around 15,000.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For employees who lost their jobs while working at a company that is reporting impressive cost-savings and recording one of its most profitable quarters yet, Althoff‚Äôs remarks might come off as tone deaf.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The situation had already been complicated by a now-deleted LinkedIn post from Xbox Game Studios‚Äô producer Matt Turnbull, who last week suggested that workers feeling ‚Äúoverwhelmed‚Äù by Microsoft‚Äôs layoffs ‚Äî which included job cuts across Xbox ‚Äî might find support through AI tools like ChatGPT and Copilot to help manage the cognitive load that comes with job loss.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It‚Äôs not clear whether the thousands of workers who lost their jobs this year were replaced by AI or whether the layoffs represent post-pandemic right-sizing. What is clear is that workforce adjustments during a period of record profitability creates a challenging dynamic that, for some, has to sting. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft closed out the first quarter with $26 billion in profit and $70 billion in revenue. The company‚Äôs market capitalization has also surged in recent months to around $3.74 trillion, displacing Apple and trailing only Nvidia.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft has signaled that much of that profit will flow directly into AI. The company said in January it would invest $80 billion into AI infrastructure across 2025. While Microsoft continues to hire talent, too, the company appears positioned to more actively participate in the industrywide competition of ‚ÄúWho Can Pay Top AI Researchers The Most?‚Äù In short, it‚Äôs more likely we‚Äôll see Microsoft spend millions of dollars on top AI researchers rather than middle managers and other employees.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/09/microsoft-shares-500m-in-ai-savings-internally-days-after-cutting-9000-jobs/</guid><pubDate>Wed, 09 Jul 2025 23:06:01 +0000</pubDate></item><item><title>[NEW] Why Cluely‚Äôs Roy Lee isn‚Äôt sweating cheating detectors (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/09/why-cluelys-roy-lee-isnt-sweating-cheating-detectors/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/IMG-0036-from-100CANON.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Cluely, an AI startup that uses a hidden in-browser window to analyze online conversations, has shot to fame with the controversial claim that its ‚Äòundetectability‚Äô feature lets users ‚Äúcheat on everything.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company‚Äôs co-founder, Roy Lee, was suspended from Columbia University for boasting that he used Cluely, originally called Interview Coder, to ‚Äúcheat‚Äù on a coding test when he was applying for a developer job at Amazon.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On Tuesday, another Columbia University student, Patrick Shen, announced on X that he had built Truely, a product designed to help catch ‚Äúcheaters‚Äù who use Cluely. Marketing itself as an ‚Äúanti-Cluely,‚Äù Truely claims it can detect the use of unauthorized applications by interviewees or others during online meetings.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Truely‚Äôs launch didn‚Äôt faze Lee.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWe don‚Äôt care if we‚Äôre able to be detected or not,‚Äù Lee told TechCrunch last week. ‚ÄúThe invisibility function is not a core feature of Cluely. It‚Äôs a nifty add-on. In fact, most enterprises opt to disable the invisibility altogether because of legal implications.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lee responded to Shen on X by praising Truely, but adding that Cluely ‚Äúwill likely start prompting our users to be much more transparent about usage.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since securing a $15 million Series A from Andreessen Horowitz last month, Cluely has shifted its marketing strategy away from promoting ‚Äòcheating.‚Äô&amp;nbsp; The company‚Äôs tagline has recently been changed from ‚Äúcheat on everything‚Äù to ‚ÄúEverything You Need. Before You Ask. ‚Ä¶ This feels like cheating.‚Äù&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Cluely‚Äôs marketing tactics have been described as rage-bait marketing, and now it seems that the company has baited us into thinking of its technology as a cheating tool.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, Lee has much bigger ambitions for Cluely: to take the place of ChatGPT.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúEvery time you would reach for chatgpt.com, our goal is to create a world where you instead reach for Cluely,‚Äù Lee said. ‚ÄúCluely does functionally the same thing as ChatGPT. The only difference is that it also knows what‚Äôs on your screen and hears what‚Äôs going on in your audio.‚Äù&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/IMG-0036-from-100CANON.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Cluely, an AI startup that uses a hidden in-browser window to analyze online conversations, has shot to fame with the controversial claim that its ‚Äòundetectability‚Äô feature lets users ‚Äúcheat on everything.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company‚Äôs co-founder, Roy Lee, was suspended from Columbia University for boasting that he used Cluely, originally called Interview Coder, to ‚Äúcheat‚Äù on a coding test when he was applying for a developer job at Amazon.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On Tuesday, another Columbia University student, Patrick Shen, announced on X that he had built Truely, a product designed to help catch ‚Äúcheaters‚Äù who use Cluely. Marketing itself as an ‚Äúanti-Cluely,‚Äù Truely claims it can detect the use of unauthorized applications by interviewees or others during online meetings.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Truely‚Äôs launch didn‚Äôt faze Lee.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWe don‚Äôt care if we‚Äôre able to be detected or not,‚Äù Lee told TechCrunch last week. ‚ÄúThe invisibility function is not a core feature of Cluely. It‚Äôs a nifty add-on. In fact, most enterprises opt to disable the invisibility altogether because of legal implications.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lee responded to Shen on X by praising Truely, but adding that Cluely ‚Äúwill likely start prompting our users to be much more transparent about usage.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since securing a $15 million Series A from Andreessen Horowitz last month, Cluely has shifted its marketing strategy away from promoting ‚Äòcheating.‚Äô&amp;nbsp; The company‚Äôs tagline has recently been changed from ‚Äúcheat on everything‚Äù to ‚ÄúEverything You Need. Before You Ask. ‚Ä¶ This feels like cheating.‚Äù&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Cluely‚Äôs marketing tactics have been described as rage-bait marketing, and now it seems that the company has baited us into thinking of its technology as a cheating tool.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, Lee has much bigger ambitions for Cluely: to take the place of ChatGPT.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúEvery time you would reach for chatgpt.com, our goal is to create a world where you instead reach for Cluely,‚Äù Lee said. ‚ÄúCluely does functionally the same thing as ChatGPT. The only difference is that it also knows what‚Äôs on your screen and hears what‚Äôs going on in your audio.‚Äù&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/09/why-cluelys-roy-lee-isnt-sweating-cheating-detectors/</guid><pubDate>Thu, 10 Jul 2025 00:36:02 +0000</pubDate></item></channel></rss>