<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 29 Oct 2025 01:47:53 +0000</lastBuildDate><item><title>OpenAI completes its for-profit recapitalization (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/28/openai-completes-its-for-profit-recapitalization/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2197181367.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI on Tuesday said it had completed its recapitalization, splitting the AI lab into a for-profit corporation nested inside a non-profit foundation. It’s the end result of a complex legal process that had been strenuously resisted by its estranged co-founder, Elon Musk.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Under the new structure, the non-profit OpenAI Foundation will have legal control over a public benefit corporation called OpenAI Group, which is free to raise funding or acquire companies without legal restraint. The Foundation will hold a significant stake in OpenAI Group and will appoint its board of directors.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We believe that the world’s most powerful technology must be developed in a way that reflects the world’s collective interests,” OpenAI chairman Bret Taylor wrote in a blog post. “The close of our recapitalization gives us the ability to keep pushing the frontier of AI, and an updated corporate structure to ensure progress serves everyone.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Under the new structure, the OpenAI Foundation will own 26% of the for-profit, with a warrant for additional shares to be granted if the company continues to grow. Microsoft, an early investor in OpenAI, will hold a roughly 27% stake, valued at about $135 billion, with the remaining 47% held by investors and employees.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to a separate blog post by Microsoft, the deal will also extend Microsoft’s IP rights to OpenAI models through 2032. If OpenAI ever declares that it has achieved its long-held goal of artificial general intelligence, the deal will also require it to submit to an independent expert panel for verification.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Prior to this recapitalization, OpenAI was operating as a non-profit under strict equity restrictions — a position that became increasingly untenable as the company’s fundraising became more ambitious. In April, SoftBank announced an unprecedented $30 billion investment into OpenAI, contingent on the company’s successful conversion into a for-profit. On Saturday, The Information reported that the final installment of the funding had been sent, signaling a possible breakthrough in the restructuring.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There have been a number of legal efforts to block or otherwise influence the restructuring, most notably from Elon Musk, who at one point offered to acquire the company for $97.4 billion.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The attorneys general from California and Delaware, who had raised concerns about the conversion, will allow the process to proceed, subject to further conditions published by both offices. Notably, the California agreement requires OpenAI to “continue to undertake measures to mitigate risks to teens and others in&lt;br /&gt;connection with the development and deployment of AI and of AGI.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the announcement post, Taylor cited discussions with the state offices as a positive influence on the process. “We made several changes as a result of those discussions and we believe OpenAI—and as a result, the public we serve—are better for them,” Taylor wrote. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the wake of the news, CEO Sam Altman announced an open livestream with chief scientist Jakub Pachocki to answer questions from the public. The event will begin at 10:30 a.m. Pacific Time.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2197181367.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI on Tuesday said it had completed its recapitalization, splitting the AI lab into a for-profit corporation nested inside a non-profit foundation. It’s the end result of a complex legal process that had been strenuously resisted by its estranged co-founder, Elon Musk.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Under the new structure, the non-profit OpenAI Foundation will have legal control over a public benefit corporation called OpenAI Group, which is free to raise funding or acquire companies without legal restraint. The Foundation will hold a significant stake in OpenAI Group and will appoint its board of directors.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We believe that the world’s most powerful technology must be developed in a way that reflects the world’s collective interests,” OpenAI chairman Bret Taylor wrote in a blog post. “The close of our recapitalization gives us the ability to keep pushing the frontier of AI, and an updated corporate structure to ensure progress serves everyone.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Under the new structure, the OpenAI Foundation will own 26% of the for-profit, with a warrant for additional shares to be granted if the company continues to grow. Microsoft, an early investor in OpenAI, will hold a roughly 27% stake, valued at about $135 billion, with the remaining 47% held by investors and employees.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to a separate blog post by Microsoft, the deal will also extend Microsoft’s IP rights to OpenAI models through 2032. If OpenAI ever declares that it has achieved its long-held goal of artificial general intelligence, the deal will also require it to submit to an independent expert panel for verification.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Prior to this recapitalization, OpenAI was operating as a non-profit under strict equity restrictions — a position that became increasingly untenable as the company’s fundraising became more ambitious. In April, SoftBank announced an unprecedented $30 billion investment into OpenAI, contingent on the company’s successful conversion into a for-profit. On Saturday, The Information reported that the final installment of the funding had been sent, signaling a possible breakthrough in the restructuring.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There have been a number of legal efforts to block or otherwise influence the restructuring, most notably from Elon Musk, who at one point offered to acquire the company for $97.4 billion.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The attorneys general from California and Delaware, who had raised concerns about the conversion, will allow the process to proceed, subject to further conditions published by both offices. Notably, the California agreement requires OpenAI to “continue to undertake measures to mitigate risks to teens and others in&lt;br /&gt;connection with the development and deployment of AI and of AGI.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the announcement post, Taylor cited discussions with the state offices as a positive influence on the process. “We made several changes as a result of those discussions and we believe OpenAI—and as a result, the public we serve—are better for them,” Taylor wrote. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the wake of the news, CEO Sam Altman announced an open livestream with chief scientist Jakub Pachocki to answer questions from the public. The event will begin at 10:30 a.m. Pacific Time.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/28/openai-completes-its-for-profit-recapitalization/</guid><pubDate>Tue, 28 Oct 2025 14:30:24 +0000</pubDate></item><item><title>Finding return on AI investments across industries (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/28/1126693/finding-return-on-ai-investments-across-industries/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;Provided by&lt;/span&gt;Intel&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;The market is officially three years post ChatGPT and many of the pundit bylines have shifted to using terms like “bubble” to suggest reasons behind generative AI not realizing material returns outside a handful of technology suppliers.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In September, the MIT NANDA report made waves because the soundbite every author and influencer picked up on was that 95% of all AI pilots failed to scale or deliver clear and measurable ROI. McKinsey earlier published a similar trend indicating that agentic AI would be the way forward to achieve huge operational benefits for enterprises. At &lt;em&gt;The Wall Street Journal&lt;/em&gt;’s Technology Council Summit, AI technology leaders recommended CIOs stop worrying about AI’s return on investment because measuring gains is difficult and if they were to try, the measurements would be wrong.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1126697" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/ChatGPT-Image-Oct-22-2025-02_41_13-PM.png" /&gt;&lt;/figure&gt;  &lt;p&gt;This places technology leaders in a precarious position–robust tech stacks already sustain their business operations, so what is the upside to introducing new technology?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;For decades, deployment strategies have followed a consistent cadence where tech operators avoid destabilizing business-critical workflows to swap out individual components in tech stacks. For example, a better or cheaper technology is not meaningful if it puts your disaster recovery at risk.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;While the price might increase when a new buyer takes over mature middleware, the cost of losing part of your enterprise data because you are mid-way through transitioning your enterprise to a new technology is way more severe than paying a higher price for a stable technology that you’ve run your business on for 20 years.&lt;/p&gt;  &lt;p&gt;So, how do enterprises get a return on investing in the latest tech transformation?&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;First principle of AI: Your data is your value&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Most of the articles about AI data relate to engineering tasks to ensure that an AI model infers against business data in repositories that represent past and present business realities&lt;strong&gt;.&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;However, one of the most widely-deployed use cases in enterprise AI begins with prompting an AI model by uploading file attachments into the model. This step narrows an AI model’s range to the content of the uploaded files, accelerating accurate response times and reducing the number of prompts required to get the best answer.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This tactic relies upon sending your proprietary business data into an AI model, so there are two important considerations to take in parallel with data preparation: first, governing your system for appropriate confidentiality; and second, developing a deliberate negotiation strategy with the model vendors, who cannot advance their frontier models without getting access to non-public data, like your business’ data.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Recently, Anthropic and OpenAI completed massive deals with enterprise data platforms and owners because there is not enough high-value primary data publicly available on the internet.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Most enterprises would automatically prioritize confidentiality of their data and design business workflows to maintain trade secrets. From an economic value point of view, especially considering how costly every model API call really is, exchanging selective access to your data for services or price offsets may be the right strategy. Rather than approaching model purchase/onboarding as a typical supplier/procurement exercise, think through the potential to realize mutual benefits in advancing your suppliers’ model and your business adoption of the model in tandem.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Second principle of AI: Boring by design&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;According to Information is Beautiful, in 2024 alone, 182 new generative AI models were introduced to the market. When GPT5 came into the market in 2025, many of the models from 12 to 24 months prior were rendered unavailable until subscription customers threatened to cancel. Their previously stable AI workflows were built on models that no longer worked. Their tech providers thought the customers would be excited about the newest models and did not realize the premium that business workflows place on stability. Video gamers are happy to upgrade their custom builds throughout the entire lifespan of the system components in their gaming rigs, and will upgrade the entire system just to play a newly released title.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;However, behavior does not translate to business run rate operations. While many employees may use the latest models for document processing or generating content, back-office operations can’t sustain swapping a tech stack three times a week to keep up with the latest model drops. The back-office work is boring by design.&lt;/p&gt;  &lt;p&gt;The most successful AI deployments have focused on deploying AI on business problems unique to their business, often running in the background to accelerate or augment mundane but mandated tasks. Relieving legal or expense audits from having to manually cross check individual reports but putting the final decision in a humans’ responsibility zone combines the best of both.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;The important point is that none of these tasks require constant updates to the latest model to deliver that value. This is also an area where abstracting your business workflows from using direct model APIs can offer additional long-term stability while maintaining options to update or upgrade the underlying engines at the pace of your business.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Third principle of AI: Mini-van economics&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;The best way to avoid upside-down economics is to design systems to align to the users rather than vendor specs and benchmarks.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Too many businesses continue to fall into the trap of buying new gear or new cloud service types based on new supplier-led benchmarks rather than starting their AI journey from what their business can consume, at what pace, on the capabilities they have deployed today.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;While Ferrari marketing is effective and those automobiles are truly magnificent, they drive the same speed through school zones and lack ample trunk space for groceries. Keep in mind that every remote server and model touched by a user layers on the costs and design for frugality by reconfiguring workflows to minimize spending on third-party services.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Too many companies have found that their customer support AI workflows add millions of dollars of operational run rate costs and end up adding more development time and cost to update the implementation for OpEx predictability. Meanwhile, the companies that decided that a system running at the pace a human can read—less than 50 tokens per second—were able to successfully deploy scaled-out AI applications with minimal additional overhead.&lt;/p&gt;  &lt;p&gt;There are so many aspects of this new automation technology to unpack—the best guidance is to start practical, design for independence in underlying technology components to keep from disrupting stable applications long term, and to leverage the fact that AI technology makes your business data valuable to the advancement of your tech suppliers' goals.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Intel. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;Provided by&lt;/span&gt;Intel&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;The market is officially three years post ChatGPT and many of the pundit bylines have shifted to using terms like “bubble” to suggest reasons behind generative AI not realizing material returns outside a handful of technology suppliers.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In September, the MIT NANDA report made waves because the soundbite every author and influencer picked up on was that 95% of all AI pilots failed to scale or deliver clear and measurable ROI. McKinsey earlier published a similar trend indicating that agentic AI would be the way forward to achieve huge operational benefits for enterprises. At &lt;em&gt;The Wall Street Journal&lt;/em&gt;’s Technology Council Summit, AI technology leaders recommended CIOs stop worrying about AI’s return on investment because measuring gains is difficult and if they were to try, the measurements would be wrong.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1126697" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/ChatGPT-Image-Oct-22-2025-02_41_13-PM.png" /&gt;&lt;/figure&gt;  &lt;p&gt;This places technology leaders in a precarious position–robust tech stacks already sustain their business operations, so what is the upside to introducing new technology?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;For decades, deployment strategies have followed a consistent cadence where tech operators avoid destabilizing business-critical workflows to swap out individual components in tech stacks. For example, a better or cheaper technology is not meaningful if it puts your disaster recovery at risk.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;While the price might increase when a new buyer takes over mature middleware, the cost of losing part of your enterprise data because you are mid-way through transitioning your enterprise to a new technology is way more severe than paying a higher price for a stable technology that you’ve run your business on for 20 years.&lt;/p&gt;  &lt;p&gt;So, how do enterprises get a return on investing in the latest tech transformation?&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;First principle of AI: Your data is your value&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Most of the articles about AI data relate to engineering tasks to ensure that an AI model infers against business data in repositories that represent past and present business realities&lt;strong&gt;.&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;However, one of the most widely-deployed use cases in enterprise AI begins with prompting an AI model by uploading file attachments into the model. This step narrows an AI model’s range to the content of the uploaded files, accelerating accurate response times and reducing the number of prompts required to get the best answer.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This tactic relies upon sending your proprietary business data into an AI model, so there are two important considerations to take in parallel with data preparation: first, governing your system for appropriate confidentiality; and second, developing a deliberate negotiation strategy with the model vendors, who cannot advance their frontier models without getting access to non-public data, like your business’ data.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Recently, Anthropic and OpenAI completed massive deals with enterprise data platforms and owners because there is not enough high-value primary data publicly available on the internet.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Most enterprises would automatically prioritize confidentiality of their data and design business workflows to maintain trade secrets. From an economic value point of view, especially considering how costly every model API call really is, exchanging selective access to your data for services or price offsets may be the right strategy. Rather than approaching model purchase/onboarding as a typical supplier/procurement exercise, think through the potential to realize mutual benefits in advancing your suppliers’ model and your business adoption of the model in tandem.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Second principle of AI: Boring by design&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;According to Information is Beautiful, in 2024 alone, 182 new generative AI models were introduced to the market. When GPT5 came into the market in 2025, many of the models from 12 to 24 months prior were rendered unavailable until subscription customers threatened to cancel. Their previously stable AI workflows were built on models that no longer worked. Their tech providers thought the customers would be excited about the newest models and did not realize the premium that business workflows place on stability. Video gamers are happy to upgrade their custom builds throughout the entire lifespan of the system components in their gaming rigs, and will upgrade the entire system just to play a newly released title.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;However, behavior does not translate to business run rate operations. While many employees may use the latest models for document processing or generating content, back-office operations can’t sustain swapping a tech stack three times a week to keep up with the latest model drops. The back-office work is boring by design.&lt;/p&gt;  &lt;p&gt;The most successful AI deployments have focused on deploying AI on business problems unique to their business, often running in the background to accelerate or augment mundane but mandated tasks. Relieving legal or expense audits from having to manually cross check individual reports but putting the final decision in a humans’ responsibility zone combines the best of both.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;The important point is that none of these tasks require constant updates to the latest model to deliver that value. This is also an area where abstracting your business workflows from using direct model APIs can offer additional long-term stability while maintaining options to update or upgrade the underlying engines at the pace of your business.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Third principle of AI: Mini-van economics&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;The best way to avoid upside-down economics is to design systems to align to the users rather than vendor specs and benchmarks.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Too many businesses continue to fall into the trap of buying new gear or new cloud service types based on new supplier-led benchmarks rather than starting their AI journey from what their business can consume, at what pace, on the capabilities they have deployed today.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;While Ferrari marketing is effective and those automobiles are truly magnificent, they drive the same speed through school zones and lack ample trunk space for groceries. Keep in mind that every remote server and model touched by a user layers on the costs and design for frugality by reconfiguring workflows to minimize spending on third-party services.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Too many companies have found that their customer support AI workflows add millions of dollars of operational run rate costs and end up adding more development time and cost to update the implementation for OpEx predictability. Meanwhile, the companies that decided that a system running at the pace a human can read—less than 50 tokens per second—were able to successfully deploy scaled-out AI applications with minimal additional overhead.&lt;/p&gt;  &lt;p&gt;There are so many aspects of this new automation technology to unpack—the best guidance is to start practical, design for independence in underlying technology components to keep from disrupting stable applications long term, and to leverage the fact that AI technology makes your business data valuable to the advancement of your tech suppliers' goals.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Intel. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/28/1126693/finding-return-on-ai-investments-across-industries/</guid><pubDate>Tue, 28 Oct 2025 15:00:33 +0000</pubDate></item><item><title>Expert panel will determine AGI arrival in new Microsoft-OpenAI agreement (AI – Ars Technica)</title><link>https://arstechnica.com/information-technology/2025/10/expert-panel-will-determine-agi-arrival-in-new-microsoft-openai-agreement/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        New deal extends Microsoft IP rights until 2032 or until AGI arrives.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The OpenAI logo superimposed over a Microsoft logo background" class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/07/openai_microsoft_3-300x169.jpg" width="300" /&gt;
                  &lt;img alt="The OpenAI logo superimposed over a Microsoft logo background" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/07/openai_microsoft_3-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards / OpenAI / Microsoft

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Monday, Microsoft and OpenAI announced a revised partnership agreement that introduces an independent expert panel to verify when OpenAI achieves so-called artificial general intelligence (AGI), a determination that will trigger major shifts in how the companies share technology and revenue. The deal values Microsoft’s stake in OpenAI at approximately $135 billion and extends the exclusive partnership through 2032 while giving both companies more freedom to pursue AGI independently.&lt;/p&gt;
&lt;p&gt;The partnership began in 2019 when Microsoft invested $1 billion in OpenAI. Since then, Microsoft has provided billions in cloud computing resources through Azure and used OpenAI’s models as the basis of products like Copilot. The new agreement maintains Microsoft as OpenAI’s frontier model partner and preserves Microsoft’s exclusive rights to OpenAI’s IP and Azure API exclusivity until the threshold of AGI is reached.&lt;/p&gt;
&lt;p&gt;Under a previous arrangement, OpenAI alone would determine when it achieved AGI, which is a nebulous concept that is difficult to define. The revised deal requires an independent expert panel to verify that claim, a change that adds oversight to a determination with billions of dollars at stake. When the panel confirms that AGI has been reached, Microsoft’s intellectual property rights to OpenAI’s research methods will expire, and the revenue-sharing arrangement between the companies will end, though payments will continue over a longer period.&lt;/p&gt;
&lt;p&gt;The companies did not disclose who will serve on the expert panel or how panel members will be selected. The lack of details about the panel’s composition leaves open questions about what criteria the experts will actually use to verify that AGI has been achieved. Previously, the two companies had agreed on a somewhat arbitrary economic threshold of when AI systems can generate $100 billion in profits.&lt;/p&gt;
&lt;p&gt;The partnership, one of the most watched in the tech space, has shown strain as OpenAI has grown from a spunky research lab with high hopes into a company valued at $500 billion that sways the trajectory of the tech industry with its moves in AI. Both companies now compete for customers, and OpenAI has been seeking more compute capacity than Microsoft can provide.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In May, OpenAI abandoned its plan to fully convert to a for-profit company after pressure from regulators and critics. The company instead shifted to a modified approach where the nonprofit board would retain control while converting its for-profit subsidiary into a public benefit corporation (PBC).&lt;/p&gt;
&lt;h2&gt;What changed in the agreement&lt;/h2&gt;
&lt;p&gt;The revised deal extends Microsoft’s intellectual property rights through 2032 and now includes models developed after AGI is declared. Microsoft holds IP rights to OpenAI’s model weights, architecture, inference code, and fine-tuning code until the expert panel confirms AGI or through 2030, whichever comes first. The new agreement also codifies that OpenAI can formally release open-weight models (like gpt-oss) that meet requisite capability criteria.&lt;/p&gt;
&lt;p&gt;However, Microsoft’s rights to OpenAI’s research methods, defined as confidential techniques used in model development, will expire at those same thresholds. The agreement explicitly excludes Microsoft from having rights to OpenAI’s consumer hardware products.&lt;/p&gt;
&lt;p&gt;The deal allows OpenAI to develop some products jointly with third parties. API products built with other companies must run exclusively on Azure, but non-API products can operate on any cloud provider. This gives OpenAI more flexibility to partner with other technology companies while keeping Microsoft as its primary infrastructure provider.&lt;/p&gt;
&lt;p&gt;Under the agreement, Microsoft can now pursue AGI development alone or with partners other than OpenAI. If Microsoft uses OpenAI’s intellectual property to build AGI before the expert panel makes a declaration, those models must exceed compute thresholds that are larger than what current leading AI models require for training.&lt;/p&gt;
&lt;p&gt;The revenue-sharing arrangement between the companies will continue until the expert panel verifies that AGI has been reached, though payments will extend over a longer period. OpenAI has committed to purchasing $250 billion in Azure services, and Microsoft no longer holds a right of first refusal to serve as OpenAI’s compute provider. This lets OpenAI shop around for cloud infrastructure if it chooses, though the massive Azure commitment suggests it will remain the primary provider.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        New deal extends Microsoft IP rights until 2032 or until AGI arrives.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The OpenAI logo superimposed over a Microsoft logo background" class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/07/openai_microsoft_3-300x169.jpg" width="300" /&gt;
                  &lt;img alt="The OpenAI logo superimposed over a Microsoft logo background" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/07/openai_microsoft_3-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards / OpenAI / Microsoft

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Monday, Microsoft and OpenAI announced a revised partnership agreement that introduces an independent expert panel to verify when OpenAI achieves so-called artificial general intelligence (AGI), a determination that will trigger major shifts in how the companies share technology and revenue. The deal values Microsoft’s stake in OpenAI at approximately $135 billion and extends the exclusive partnership through 2032 while giving both companies more freedom to pursue AGI independently.&lt;/p&gt;
&lt;p&gt;The partnership began in 2019 when Microsoft invested $1 billion in OpenAI. Since then, Microsoft has provided billions in cloud computing resources through Azure and used OpenAI’s models as the basis of products like Copilot. The new agreement maintains Microsoft as OpenAI’s frontier model partner and preserves Microsoft’s exclusive rights to OpenAI’s IP and Azure API exclusivity until the threshold of AGI is reached.&lt;/p&gt;
&lt;p&gt;Under a previous arrangement, OpenAI alone would determine when it achieved AGI, which is a nebulous concept that is difficult to define. The revised deal requires an independent expert panel to verify that claim, a change that adds oversight to a determination with billions of dollars at stake. When the panel confirms that AGI has been reached, Microsoft’s intellectual property rights to OpenAI’s research methods will expire, and the revenue-sharing arrangement between the companies will end, though payments will continue over a longer period.&lt;/p&gt;
&lt;p&gt;The companies did not disclose who will serve on the expert panel or how panel members will be selected. The lack of details about the panel’s composition leaves open questions about what criteria the experts will actually use to verify that AGI has been achieved. Previously, the two companies had agreed on a somewhat arbitrary economic threshold of when AI systems can generate $100 billion in profits.&lt;/p&gt;
&lt;p&gt;The partnership, one of the most watched in the tech space, has shown strain as OpenAI has grown from a spunky research lab with high hopes into a company valued at $500 billion that sways the trajectory of the tech industry with its moves in AI. Both companies now compete for customers, and OpenAI has been seeking more compute capacity than Microsoft can provide.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In May, OpenAI abandoned its plan to fully convert to a for-profit company after pressure from regulators and critics. The company instead shifted to a modified approach where the nonprofit board would retain control while converting its for-profit subsidiary into a public benefit corporation (PBC).&lt;/p&gt;
&lt;h2&gt;What changed in the agreement&lt;/h2&gt;
&lt;p&gt;The revised deal extends Microsoft’s intellectual property rights through 2032 and now includes models developed after AGI is declared. Microsoft holds IP rights to OpenAI’s model weights, architecture, inference code, and fine-tuning code until the expert panel confirms AGI or through 2030, whichever comes first. The new agreement also codifies that OpenAI can formally release open-weight models (like gpt-oss) that meet requisite capability criteria.&lt;/p&gt;
&lt;p&gt;However, Microsoft’s rights to OpenAI’s research methods, defined as confidential techniques used in model development, will expire at those same thresholds. The agreement explicitly excludes Microsoft from having rights to OpenAI’s consumer hardware products.&lt;/p&gt;
&lt;p&gt;The deal allows OpenAI to develop some products jointly with third parties. API products built with other companies must run exclusively on Azure, but non-API products can operate on any cloud provider. This gives OpenAI more flexibility to partner with other technology companies while keeping Microsoft as its primary infrastructure provider.&lt;/p&gt;
&lt;p&gt;Under the agreement, Microsoft can now pursue AGI development alone or with partners other than OpenAI. If Microsoft uses OpenAI’s intellectual property to build AGI before the expert panel makes a declaration, those models must exceed compute thresholds that are larger than what current leading AI models require for training.&lt;/p&gt;
&lt;p&gt;The revenue-sharing arrangement between the companies will continue until the expert panel verifies that AGI has been reached, though payments will extend over a longer period. OpenAI has committed to purchasing $250 billion in Azure services, and Microsoft no longer holds a right of first refusal to serve as OpenAI’s compute provider. This lets OpenAI shop around for cloud infrastructure if it chooses, though the massive Azure commitment suggests it will remain the primary provider.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/information-technology/2025/10/expert-panel-will-determine-agi-arrival-in-new-microsoft-openai-agreement/</guid><pubDate>Tue, 28 Oct 2025 15:02:30 +0000</pubDate></item><item><title>UNC Chancellor Lee Roberts on pushing his university into the AI age (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/podcast/unc-chancellor-lee-roberts-on-pushing-his-university-into-the-ai-age/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/Screenshot-2025-10-20-at-1.13.38AM.png?resize=1200,807" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;This week on StrictlyVC Download, Connie Loizos sits down with Lee Roberts, chancellor of the University of North Carolina at Chapel Hill, to discuss his ambitious plan to make AI the university’s North Star amid a tumultuous year.&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;Roberts walks through his decision to merge UNC’s School of Data Science and Society with its School of Information and Library Science, explaining why breaking down academic silos is essential when the technology moves faster than universities typically can. He addresses the $38 million in terminated federal research grants — concentrated in areas like public health — and why he’s less concerned about funding cuts than he was at the start of the year. Roberts also defends his $10 million annual commitment to Bill Belichick despite the team’s rocky start, explaining why football revenue is essential to supporting UNC’s 2028 sports programs.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;StrictlyVC Download posts every Tuesday. Subscribe on&amp;nbsp;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;Apple&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;,&amp;nbsp;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;Spotify,&amp;nbsp;&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;or&amp;nbsp;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;wherever you listen to podcasts&amp;nbsp;&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;to be alerted when new episodes drop.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/Screenshot-2025-10-20-at-1.13.38AM.png?resize=1200,807" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;This week on StrictlyVC Download, Connie Loizos sits down with Lee Roberts, chancellor of the University of North Carolina at Chapel Hill, to discuss his ambitious plan to make AI the university’s North Star amid a tumultuous year.&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;Roberts walks through his decision to merge UNC’s School of Data Science and Society with its School of Information and Library Science, explaining why breaking down academic silos is essential when the technology moves faster than universities typically can. He addresses the $38 million in terminated federal research grants — concentrated in areas like public health — and why he’s less concerned about funding cuts than he was at the start of the year. Roberts also defends his $10 million annual commitment to Bill Belichick despite the team’s rocky start, explaining why football revenue is essential to supporting UNC’s 2028 sports programs.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;StrictlyVC Download posts every Tuesday. Subscribe on&amp;nbsp;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;Apple&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;,&amp;nbsp;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;Spotify,&amp;nbsp;&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;or&amp;nbsp;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;wherever you listen to podcasts&amp;nbsp;&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;to be alerted when new episodes drop.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/podcast/unc-chancellor-lee-roberts-on-pushing-his-university-into-the-ai-age/</guid><pubDate>Tue, 28 Oct 2025 15:08:45 +0000</pubDate></item><item><title>Mem0 raises $24M from YC, Peak XV and Basis Set to build the memory layer for AI apps (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/28/mem0-raises-24m-from-yc-peak-xv-and-basis-set-to-build-the-memory-layer-for-ai-apps/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/IMG_2437.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Taranjeet Singh (pictured above, right) has launched six companies, with some failing and others seeing varying degrees of success. His seventh, Mem0, could be his defining one.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup starts with the premise that large language models can’t remember past interactions the way humans do. If two people are chatting and the connection drops, they can resume the conversation. AI models, by contrast, forget everything and start from scratch.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Mem0 fixes that. Singh calls it a “memory passport,” where your AI memory travels with you across apps and agents, just like email or logins do today. The YC-backed startup, launched in January 2024, has raised $24 million ($3.9 million in previously unannounced seed funding and a $20 million Series A).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI-focused early-stage fund Basis Set Ventures led the Series A, with participation from existing investors Kindred Ventures, which led its seed round, and Y Combinator, as well as new backers including Peak XV Partners and the GitHub Fund.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notable angels include Dharmesh Shah (HubSpot), Scott Belsky (ex-CPO Adobe), Olivier Pomel (Datadog), Thomas Dohmke (ex-CEO GitHub), Paul Copplestone (Supabase), James Hawkins (PostHog), Lukas Biewald (Weights &amp;amp; Biases), Brian Balfour (Reforge), Philip Rathle (Neo4j), and Jennifer Taylor (former president, Plaid).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Having several leaders who helped shape the modern software ecosystem bet on Mem0 (pronounced “mem zero”) underscores its promise, and the traction from the four-person team backs it up.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So far, the open source API, which claims to be the most widely adopted memory framework for AI developers, has surpassed 41,000 GitHub stars and recorded over 13 million Python package downloads. In Q1 2025, Mem0 processed 35 million API calls. By Q3, that number jumped to 186 million, growing roughly 30% month over month.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond open source adoption, more than 80,000 developers have signed up for its cloud service. Mem0’s cloud API now handles more memory operations than any other provider and serves as the exclusive memory provider for AWS’s new Agent SDK.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In early 2023, Singh was still in Bangalore, India. He started his career as a software engineer at Paytm, one of India’s most valuable startups, before becoming Khatabook’s first growth engineer. He quit in late 2022, just as the ChatGPT wave was about to crest, and built one of the first GPT app stores, which scaled to over a million users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That experience led him to create Embedchain, an open source project that lets developers index, retrieve, and sync unstructured data. As the project took off, earning more than 8,000 GitHub stars, Singh sent over 200 cold emails to founders, investors, and engineers in Silicon Valley.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I reached out to almost every famous tech entrepreneur that you might have heard of and was quite persistent. Some of them responded, and after hearing us out, scheduled us to fly from Bangalore to San Francisco within 36 hours,” Singh said.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Once in the U.S., Singh reconnected with his longtime friend and now co-founder and CTO, Deshraj Yadav, who had led the AI Platform at Tesla Autopilot. Together, they had previously built EvalAI, an open source Kaggle alternative that grew to 1.6K GitHub stars.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While experimenting with Embedchain, the duo launched a meditation app inspired by Indian yogi Sadhguru. The app went viral in India, but Singh says users kept sharing the same feedback: “Hey, I’m on this meditative journey, but the app doesn’t remember that.” So they pivoted from Embedchain to Mem0 to solve that problem.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-wp-embed is-provider-techcrunch wp-block-embed-techcrunch"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The idea of memory for AI isn’t new, but it’s quickly becoming a critical battleground. OpenAI, for instance, began testing long-term memory features in ChatGPT in early 2024, and its CEO, Sam Altman, has hinted that persistent memory will be central to OpenAI’s upcoming hardware device. Other AI labs are also launching experimental memory systems for their agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Singh argues that while big AI labs are building memory systems, they have little incentive to make them portable or interoperable. “Memory is becoming one of their key moats now that LLMs are getting commoditized,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He explains that while consumers can enjoy persistent, personalized experiences in ChatGPT, developers who want to build applications — say, a finance companion that remembers a user’s trading history — need an open, neutral solution like Mem0.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We want developers to offer day-one personalization through a shared memory network,” Singh said. “Think of it as Plaid for memory. That’s act two. For now, we’re laser-focused on building the best memory product possible.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mem0’s framework lets developers store, retrieve, and evolve user memory across models, applications, and platforms. It’s model-agnostic, compatible with OpenAI, Anthropic, or any open source LLM, and integrates directly with frameworks like LangChain and LlamaIndex.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Developers use Mem0 to create applications that grow smarter with every interaction: therapy bots that recall past conversations, productivity agents that remember personal habits, and AI companions that adapt over time. Customers range from indie developers to enterprise teams building copilots and automation tools.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We backed Mem0 from its earliest days — even before YC — because memory is foundational to the future of AI,” said Lan Xuezhao, founder and partner at Basis Set Ventures. “We’re doubling down as the team continues to tackle one of the hardest and most important infrastructure challenges: enabling AI systems to build lasting, contextual memory.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other early-stage startups in the memory space include Supermemory (whose founder briefly worked at Mem0), Felicis-backed Letta, and Memories.ai.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-wp-embed is-provider-techcrunch wp-block-embed-techcrunch"&gt;&lt;/figure&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/IMG_2437.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Taranjeet Singh (pictured above, right) has launched six companies, with some failing and others seeing varying degrees of success. His seventh, Mem0, could be his defining one.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup starts with the premise that large language models can’t remember past interactions the way humans do. If two people are chatting and the connection drops, they can resume the conversation. AI models, by contrast, forget everything and start from scratch.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Mem0 fixes that. Singh calls it a “memory passport,” where your AI memory travels with you across apps and agents, just like email or logins do today. The YC-backed startup, launched in January 2024, has raised $24 million ($3.9 million in previously unannounced seed funding and a $20 million Series A).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI-focused early-stage fund Basis Set Ventures led the Series A, with participation from existing investors Kindred Ventures, which led its seed round, and Y Combinator, as well as new backers including Peak XV Partners and the GitHub Fund.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notable angels include Dharmesh Shah (HubSpot), Scott Belsky (ex-CPO Adobe), Olivier Pomel (Datadog), Thomas Dohmke (ex-CEO GitHub), Paul Copplestone (Supabase), James Hawkins (PostHog), Lukas Biewald (Weights &amp;amp; Biases), Brian Balfour (Reforge), Philip Rathle (Neo4j), and Jennifer Taylor (former president, Plaid).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Having several leaders who helped shape the modern software ecosystem bet on Mem0 (pronounced “mem zero”) underscores its promise, and the traction from the four-person team backs it up.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So far, the open source API, which claims to be the most widely adopted memory framework for AI developers, has surpassed 41,000 GitHub stars and recorded over 13 million Python package downloads. In Q1 2025, Mem0 processed 35 million API calls. By Q3, that number jumped to 186 million, growing roughly 30% month over month.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond open source adoption, more than 80,000 developers have signed up for its cloud service. Mem0’s cloud API now handles more memory operations than any other provider and serves as the exclusive memory provider for AWS’s new Agent SDK.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In early 2023, Singh was still in Bangalore, India. He started his career as a software engineer at Paytm, one of India’s most valuable startups, before becoming Khatabook’s first growth engineer. He quit in late 2022, just as the ChatGPT wave was about to crest, and built one of the first GPT app stores, which scaled to over a million users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That experience led him to create Embedchain, an open source project that lets developers index, retrieve, and sync unstructured data. As the project took off, earning more than 8,000 GitHub stars, Singh sent over 200 cold emails to founders, investors, and engineers in Silicon Valley.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I reached out to almost every famous tech entrepreneur that you might have heard of and was quite persistent. Some of them responded, and after hearing us out, scheduled us to fly from Bangalore to San Francisco within 36 hours,” Singh said.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Once in the U.S., Singh reconnected with his longtime friend and now co-founder and CTO, Deshraj Yadav, who had led the AI Platform at Tesla Autopilot. Together, they had previously built EvalAI, an open source Kaggle alternative that grew to 1.6K GitHub stars.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While experimenting with Embedchain, the duo launched a meditation app inspired by Indian yogi Sadhguru. The app went viral in India, but Singh says users kept sharing the same feedback: “Hey, I’m on this meditative journey, but the app doesn’t remember that.” So they pivoted from Embedchain to Mem0 to solve that problem.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-wp-embed is-provider-techcrunch wp-block-embed-techcrunch"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The idea of memory for AI isn’t new, but it’s quickly becoming a critical battleground. OpenAI, for instance, began testing long-term memory features in ChatGPT in early 2024, and its CEO, Sam Altman, has hinted that persistent memory will be central to OpenAI’s upcoming hardware device. Other AI labs are also launching experimental memory systems for their agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Singh argues that while big AI labs are building memory systems, they have little incentive to make them portable or interoperable. “Memory is becoming one of their key moats now that LLMs are getting commoditized,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He explains that while consumers can enjoy persistent, personalized experiences in ChatGPT, developers who want to build applications — say, a finance companion that remembers a user’s trading history — need an open, neutral solution like Mem0.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We want developers to offer day-one personalization through a shared memory network,” Singh said. “Think of it as Plaid for memory. That’s act two. For now, we’re laser-focused on building the best memory product possible.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mem0’s framework lets developers store, retrieve, and evolve user memory across models, applications, and platforms. It’s model-agnostic, compatible with OpenAI, Anthropic, or any open source LLM, and integrates directly with frameworks like LangChain and LlamaIndex.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Developers use Mem0 to create applications that grow smarter with every interaction: therapy bots that recall past conversations, productivity agents that remember personal habits, and AI companions that adapt over time. Customers range from indie developers to enterprise teams building copilots and automation tools.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We backed Mem0 from its earliest days — even before YC — because memory is foundational to the future of AI,” said Lan Xuezhao, founder and partner at Basis Set Ventures. “We’re doubling down as the team continues to tackle one of the hardest and most important infrastructure challenges: enabling AI systems to build lasting, contextual memory.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other early-stage startups in the memory space include Supermemory (whose founder briefly worked at Mem0), Felicis-backed Letta, and Memories.ai.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-wp-embed is-provider-techcrunch wp-block-embed-techcrunch"&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/28/mem0-raises-24m-from-yc-peak-xv-and-basis-set-to-build-the-memory-layer-for-ai-apps/</guid><pubDate>Tue, 28 Oct 2025 15:14:13 +0000</pubDate></item><item><title>GitHub's Agent HQ aims to solve enterprises' biggest AI coding problem: Too many agents, no central control (AI | VentureBeat)</title><link>https://venturebeat.com/ai/githubs-agent-hq-aims-to-solve-enterprises-biggest-ai-coding-problem-too</link><description>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://github.com/"&gt;&lt;u&gt;GitHub&lt;/u&gt;&lt;/a&gt; is making a bold bet that enterprises don&amp;#x27;t need another proprietary coding agent: They need a way to manage all of them.&lt;/p&gt;&lt;p&gt;At its Universe 2025 conference, the Microsoft-owned developer platform announced Agent HQ. The new architecture transforms GitHub into a unified control plane for managing multiple AI coding agents from competitors including Anthropic, OpenAI, Google, Cognition and xAI. Rather than forcing developers into a single agent experience, the company is positioning itself as the essential orchestration layer beneath them all.&lt;/p&gt;&lt;p&gt;Agent HQ represents GitHub&amp;#x27;s attempt to apply its collaboration platform approach to AI agents. Just as the company transformed Git, pull requests and CI/CD into collaborative workflows, it&amp;#x27;s now trying to do the same with a fragmented AI coding landscape.&lt;/p&gt;&lt;p&gt;The announcement marks what GitHub calls the transition from &amp;quot;wave one&amp;quot; to &amp;quot;wave two&amp;quot; of AI-assisted development. According to GitHub&amp;#x27;s Octoverse report, 80% of new developers use Copilot in their first week and AI has helped to lead to a large increase overall in the use of the GitHub platform.&lt;/p&gt;&lt;p&gt;&amp;quot;&lt;a href="https://venturebeat.com/ai/github-expands-ai-capabilities-with-multi-model-support-in-copilot-enhanced-developer-tools"&gt;&lt;u&gt;Last year&lt;/u&gt;&lt;/a&gt;, the big announcements for us, and what we were saying as a company, is wave one is done, that was kind of code completion,&amp;quot;  GitHub&amp;#x27;s COO Mario Rodriguez told VentureBeat. &amp;quot;We&amp;#x27;re into this wave two era, [which] is going to be multimodal, it&amp;#x27;s going to be agentic and it&amp;#x27;s going to have these new experiences that will feel AI native.&amp;quot;&lt;/p&gt;&lt;h2&gt;What is Agent HQ?&lt;/h2&gt;&lt;p&gt;GitHub already updated its GitHub Copilot coding tool for the agentic era with the debut of &lt;a href="https://venturebeat.com/ai/github-copilot-evolves-into-autonomous-agent-with-asynchronous-code-testing"&gt;&lt;u&gt;GitHub Copilot Agent&lt;/u&gt;&lt;/a&gt; in May.&lt;/p&gt;&lt;p&gt;Agent HQ transforms GitHub into an open ecosystem that unites multiple AI coding agents on a single platform. Over the coming months, coding agents from Anthropic, OpenAI, Google, Cognition, xAI and others will become available directly within GitHub as part of existing paid GitHub Copilot subscriptions.&lt;/p&gt;&lt;p&gt;The architecture maintains GitHub&amp;#x27;s core primitives. Developers still work with Git, pull requests and issues. They still use their preferred compute, whether GitHub Actions or self-hosted runners. What changes is the layer above: agents from multiple vendors can now operate within GitHub&amp;#x27;s security perimeter, using the same identity controls, branch permissions and audit logging that enterprises already trust for human developers.&lt;/p&gt;&lt;p&gt;This approach differs fundamentally from standalone tools. When developers use Cursor or grant repository access to Claude, those agents typically receive broad permissions across entire repositories. Agent HQ compartmentalizes access at the branch level and wraps all agent activity in enterprise-grade governance controls.&lt;/p&gt;&lt;h2&gt;Mission Control: One interface for all agents&lt;/h2&gt;&lt;p&gt;At the heart of Agent HQ is Mission Control. It&amp;#x27;s a unified command center that appears consistently across GitHub&amp;#x27;s web interface, VS Code, mobile apps and the command line. Through Mission Control, developers can assign work to multiple agents simultaneously. They can track progress and manage permissions, all from a single pane of glass.&lt;/p&gt;&lt;p&gt;The technical architecture addresses a critical enterprise concern: Security. Unlike standalone agent implementations where users must grant broad repository access, GitHub&amp;#x27;s Agent HQ implements granular controls at the platform level.&lt;/p&gt;&lt;p&gt;&amp;quot;Our coding agent has a set of security controls and capabilities that are built natively into the platform, and that&amp;#x27;s what we&amp;#x27;re providing to all of these other agents as well,&amp;quot; Rodriguez explained. &amp;quot;It runs with a GitHub token that is very locked down to what it can actually do.&amp;quot;&lt;/p&gt;&lt;p&gt;Agents operating through Agent HQ can only commit to designated branches. They run within sandboxed GitHub Actions environments with firewall protections. They operate under strict identity controls. Rodriguez explained that even if an agent goes rogue, the firewall prevents it from accessing external networks or exfiltrating data unless those protections are explicitly disabled.&lt;/p&gt;&lt;h2&gt;Technical differentiation: MCP integration and custom agents&lt;/h2&gt;&lt;p&gt;Beyond managing third-party agents, GitHub is introducing two technical capabilities that set Agent HQ apart from alternative approaches like Cursor&amp;#x27;s standalone editor or Anthropic&amp;#x27;s Claude integration.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Custom agents via AGENTS.md files&lt;/b&gt;: Enterprises can now create source-controlled configuration files that define specific rules, tools and guardrails for how Copilot behaves. For example, a company could specify &amp;quot;prefer this logger&amp;quot; or &amp;quot;use table-driven tests for all handlers.&amp;quot; This permanently encodes organizational standards without requiring developers to re-prompt every time.&lt;/p&gt;&lt;p&gt;&amp;quot;Custom agents have an immense amount of product market fit within enterprises, because they could just codify a set of skills that the coordination can do, then standardize on those and get really high quality output,&amp;quot; Rodriguez said.&lt;/p&gt;&lt;p&gt;The AGENTS.md specification allows teams to version control their agent behavior alongside their code. When a developer clones a repository, they automatically inherit the custom agent rules. This solves a persistent problem with AI coding tools: Inconsistent output quality when different team members use different prompting strategies.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Native Model Context Protocol (MCP) support&lt;/b&gt;: VS Code now includes a GitHub MCP Registry. Developers can discover, install and enable MCP servers with a single click. They can then create custom agents that combine these tools with specific system prompts.&lt;/p&gt;&lt;p&gt;This positions GitHub as the integration point between the emerging MCP ecosystem and actual developer workflows. MCP, introduced by Anthropic but rapidly gaining industry support, is becoming a de facto standard for agent-to-tool communication. By supporting the full specification, GitHub can orchestrate agents that need access to external services without each agent implementing its own integration logic.&lt;/p&gt;&lt;h2&gt;Plan Mode and agentic code review&lt;/h2&gt;&lt;p&gt;GitHub is also shipping new capabilities within VS Code itself. Plan Mode allows developers to collaborate with Copilot on building step-by-step project approaches. The AI asks clarifying questions before any code is written. Once approved, the plan can be executed either locally in VS Code or by cloud-based agents.&lt;/p&gt;&lt;p&gt;The feature addresses a common failure mode in AI coding: Beginning implementation before requirements are fully understood. By forcing an explicit planning phase, GitHub aims to reduce wasted effort and improve output quality.&lt;/p&gt;&lt;p&gt;More significantly, GitHub&amp;#x27;s code review feature is becoming agentic. The new implementation will use GitHub&amp;#x27;s CodeQL engine, which previously largely focused on security vulnerabilities to identify bugs and maintainability issues. The code review agent will automatically scan agent-generated pull requests before human review. This creates a two-stage quality gate.&lt;/p&gt;&lt;p&gt;&amp;quot;Our code review agent will be able to make calls into the CodeQL engine to then find a set of bugs,&amp;quot; Rodriguez explained. &amp;quot;We&amp;#x27;re extending the engine and we&amp;#x27;re going to be able to tap into that engine also to find bugs.&amp;quot;&lt;/p&gt;&lt;h2&gt;Enterprise considerations: What to do now&lt;/h2&gt;&lt;p&gt;For enterprises already deploying multiple AI coding tools, Agent HQ offers a path to consolidation without forcing tool elimination.&lt;/p&gt;&lt;p&gt;GitHub&amp;#x27;s multi-agent approach provides vendor flexibility and reduces lock-in risk. Organizations can test multiple agents within a unified security perimeter and switch providers without retraining developers. The tradeoff is potentially less optimized experiences compared to specialized tools that tightly integrate UI and agent behavior.&lt;/p&gt;&lt;p&gt;Rodriguez&amp;#x27;s recommendation is clear: Begin with custom agents. This allows enterprises to codify organizational standards that agents follow consistently. Once established, organizations can layer in additional third-party agents to expand capabilities.&lt;/p&gt;&lt;p&gt;&amp;quot;Go and do agent coding, custom agents and start playing with that,&amp;quot; he said. &amp;quot;That is a capability available tomorrow, and it allows you to really start shaping your SDLC to be personalized to you, your organization and your people.&amp;quot;&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://github.com/"&gt;&lt;u&gt;GitHub&lt;/u&gt;&lt;/a&gt; is making a bold bet that enterprises don&amp;#x27;t need another proprietary coding agent: They need a way to manage all of them.&lt;/p&gt;&lt;p&gt;At its Universe 2025 conference, the Microsoft-owned developer platform announced Agent HQ. The new architecture transforms GitHub into a unified control plane for managing multiple AI coding agents from competitors including Anthropic, OpenAI, Google, Cognition and xAI. Rather than forcing developers into a single agent experience, the company is positioning itself as the essential orchestration layer beneath them all.&lt;/p&gt;&lt;p&gt;Agent HQ represents GitHub&amp;#x27;s attempt to apply its collaboration platform approach to AI agents. Just as the company transformed Git, pull requests and CI/CD into collaborative workflows, it&amp;#x27;s now trying to do the same with a fragmented AI coding landscape.&lt;/p&gt;&lt;p&gt;The announcement marks what GitHub calls the transition from &amp;quot;wave one&amp;quot; to &amp;quot;wave two&amp;quot; of AI-assisted development. According to GitHub&amp;#x27;s Octoverse report, 80% of new developers use Copilot in their first week and AI has helped to lead to a large increase overall in the use of the GitHub platform.&lt;/p&gt;&lt;p&gt;&amp;quot;&lt;a href="https://venturebeat.com/ai/github-expands-ai-capabilities-with-multi-model-support-in-copilot-enhanced-developer-tools"&gt;&lt;u&gt;Last year&lt;/u&gt;&lt;/a&gt;, the big announcements for us, and what we were saying as a company, is wave one is done, that was kind of code completion,&amp;quot;  GitHub&amp;#x27;s COO Mario Rodriguez told VentureBeat. &amp;quot;We&amp;#x27;re into this wave two era, [which] is going to be multimodal, it&amp;#x27;s going to be agentic and it&amp;#x27;s going to have these new experiences that will feel AI native.&amp;quot;&lt;/p&gt;&lt;h2&gt;What is Agent HQ?&lt;/h2&gt;&lt;p&gt;GitHub already updated its GitHub Copilot coding tool for the agentic era with the debut of &lt;a href="https://venturebeat.com/ai/github-copilot-evolves-into-autonomous-agent-with-asynchronous-code-testing"&gt;&lt;u&gt;GitHub Copilot Agent&lt;/u&gt;&lt;/a&gt; in May.&lt;/p&gt;&lt;p&gt;Agent HQ transforms GitHub into an open ecosystem that unites multiple AI coding agents on a single platform. Over the coming months, coding agents from Anthropic, OpenAI, Google, Cognition, xAI and others will become available directly within GitHub as part of existing paid GitHub Copilot subscriptions.&lt;/p&gt;&lt;p&gt;The architecture maintains GitHub&amp;#x27;s core primitives. Developers still work with Git, pull requests and issues. They still use their preferred compute, whether GitHub Actions or self-hosted runners. What changes is the layer above: agents from multiple vendors can now operate within GitHub&amp;#x27;s security perimeter, using the same identity controls, branch permissions and audit logging that enterprises already trust for human developers.&lt;/p&gt;&lt;p&gt;This approach differs fundamentally from standalone tools. When developers use Cursor or grant repository access to Claude, those agents typically receive broad permissions across entire repositories. Agent HQ compartmentalizes access at the branch level and wraps all agent activity in enterprise-grade governance controls.&lt;/p&gt;&lt;h2&gt;Mission Control: One interface for all agents&lt;/h2&gt;&lt;p&gt;At the heart of Agent HQ is Mission Control. It&amp;#x27;s a unified command center that appears consistently across GitHub&amp;#x27;s web interface, VS Code, mobile apps and the command line. Through Mission Control, developers can assign work to multiple agents simultaneously. They can track progress and manage permissions, all from a single pane of glass.&lt;/p&gt;&lt;p&gt;The technical architecture addresses a critical enterprise concern: Security. Unlike standalone agent implementations where users must grant broad repository access, GitHub&amp;#x27;s Agent HQ implements granular controls at the platform level.&lt;/p&gt;&lt;p&gt;&amp;quot;Our coding agent has a set of security controls and capabilities that are built natively into the platform, and that&amp;#x27;s what we&amp;#x27;re providing to all of these other agents as well,&amp;quot; Rodriguez explained. &amp;quot;It runs with a GitHub token that is very locked down to what it can actually do.&amp;quot;&lt;/p&gt;&lt;p&gt;Agents operating through Agent HQ can only commit to designated branches. They run within sandboxed GitHub Actions environments with firewall protections. They operate under strict identity controls. Rodriguez explained that even if an agent goes rogue, the firewall prevents it from accessing external networks or exfiltrating data unless those protections are explicitly disabled.&lt;/p&gt;&lt;h2&gt;Technical differentiation: MCP integration and custom agents&lt;/h2&gt;&lt;p&gt;Beyond managing third-party agents, GitHub is introducing two technical capabilities that set Agent HQ apart from alternative approaches like Cursor&amp;#x27;s standalone editor or Anthropic&amp;#x27;s Claude integration.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Custom agents via AGENTS.md files&lt;/b&gt;: Enterprises can now create source-controlled configuration files that define specific rules, tools and guardrails for how Copilot behaves. For example, a company could specify &amp;quot;prefer this logger&amp;quot; or &amp;quot;use table-driven tests for all handlers.&amp;quot; This permanently encodes organizational standards without requiring developers to re-prompt every time.&lt;/p&gt;&lt;p&gt;&amp;quot;Custom agents have an immense amount of product market fit within enterprises, because they could just codify a set of skills that the coordination can do, then standardize on those and get really high quality output,&amp;quot; Rodriguez said.&lt;/p&gt;&lt;p&gt;The AGENTS.md specification allows teams to version control their agent behavior alongside their code. When a developer clones a repository, they automatically inherit the custom agent rules. This solves a persistent problem with AI coding tools: Inconsistent output quality when different team members use different prompting strategies.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Native Model Context Protocol (MCP) support&lt;/b&gt;: VS Code now includes a GitHub MCP Registry. Developers can discover, install and enable MCP servers with a single click. They can then create custom agents that combine these tools with specific system prompts.&lt;/p&gt;&lt;p&gt;This positions GitHub as the integration point between the emerging MCP ecosystem and actual developer workflows. MCP, introduced by Anthropic but rapidly gaining industry support, is becoming a de facto standard for agent-to-tool communication. By supporting the full specification, GitHub can orchestrate agents that need access to external services without each agent implementing its own integration logic.&lt;/p&gt;&lt;h2&gt;Plan Mode and agentic code review&lt;/h2&gt;&lt;p&gt;GitHub is also shipping new capabilities within VS Code itself. Plan Mode allows developers to collaborate with Copilot on building step-by-step project approaches. The AI asks clarifying questions before any code is written. Once approved, the plan can be executed either locally in VS Code or by cloud-based agents.&lt;/p&gt;&lt;p&gt;The feature addresses a common failure mode in AI coding: Beginning implementation before requirements are fully understood. By forcing an explicit planning phase, GitHub aims to reduce wasted effort and improve output quality.&lt;/p&gt;&lt;p&gt;More significantly, GitHub&amp;#x27;s code review feature is becoming agentic. The new implementation will use GitHub&amp;#x27;s CodeQL engine, which previously largely focused on security vulnerabilities to identify bugs and maintainability issues. The code review agent will automatically scan agent-generated pull requests before human review. This creates a two-stage quality gate.&lt;/p&gt;&lt;p&gt;&amp;quot;Our code review agent will be able to make calls into the CodeQL engine to then find a set of bugs,&amp;quot; Rodriguez explained. &amp;quot;We&amp;#x27;re extending the engine and we&amp;#x27;re going to be able to tap into that engine also to find bugs.&amp;quot;&lt;/p&gt;&lt;h2&gt;Enterprise considerations: What to do now&lt;/h2&gt;&lt;p&gt;For enterprises already deploying multiple AI coding tools, Agent HQ offers a path to consolidation without forcing tool elimination.&lt;/p&gt;&lt;p&gt;GitHub&amp;#x27;s multi-agent approach provides vendor flexibility and reduces lock-in risk. Organizations can test multiple agents within a unified security perimeter and switch providers without retraining developers. The tradeoff is potentially less optimized experiences compared to specialized tools that tightly integrate UI and agent behavior.&lt;/p&gt;&lt;p&gt;Rodriguez&amp;#x27;s recommendation is clear: Begin with custom agents. This allows enterprises to codify organizational standards that agents follow consistently. Once established, organizations can layer in additional third-party agents to expand capabilities.&lt;/p&gt;&lt;p&gt;&amp;quot;Go and do agent coding, custom agents and start playing with that,&amp;quot; he said. &amp;quot;That is a capability available tomorrow, and it allows you to really start shaping your SDLC to be personalized to you, your organization and your people.&amp;quot;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/githubs-agent-hq-aims-to-solve-enterprises-biggest-ai-coding-problem-too</guid><pubDate>Tue, 28 Oct 2025 16:10:00 +0000</pubDate></item><item><title>[NEW] NVIDIA Launches Open Models and Data to Accelerate AI Innovation Across Language, Biology and Robotics (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/open-models-data-ai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/llm-agentic-ai-gtc25dc-devnews-press-1920x1080-v2.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Furthering its deep commitment to open source, NVIDIA is unveiling new open-source AI technologies for language, robotics and biology — contributing to an open ecosystem that broadens access to AI and fuels U.S. innovation.&lt;/p&gt;
&lt;p&gt;These open technologies will empower developers worldwide and strengthen economic growth through efficient reasoning, high-fidelity world generation and interactive physical AI systems accelerated on NVIDIA infrastructure.&lt;/p&gt;
&lt;p&gt;The new open models, data and tools are part of the NVIDIA Nemotron family for AI reasoning, the NVIDIA Cosmos platform for physical AI, NVIDIA Isaac GR00T for robotics and NVIDIA Clara for biomedical AI.&lt;/p&gt;
&lt;p&gt;NVIDIA is contributing these models, data and training frameworks to Hugging Face to make AI research and development more accessible. As a top contributor to Hugging Face, with more than 650 open models and 250 open datasets now available, NVIDIA continues to expand access to cutting-edge AI resources for the global developer community.&lt;/p&gt;
&lt;p&gt;“Open models are catalysts to AI innovation, making AI accessible, transparent and responsible,” said Clément Delangue, CEO of Hugging Face. “NVIDIA’s contributions to the open model ecosystem, commitment to open research for AI and Hugging Face’s ecosystem will empower millions of developers to build advanced AI — together and in the open.”&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;NVIDIA Nemotron Brings Ultra-Efficient Reasoning to Specialized AI Agents&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;AI agents use multiple models to see, retrieve, generate and reason. The latest open models in the NVIDIA Nemotron family unify these capabilities, enabling developers to build specialized, intelligent agents.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Nemotron Nano 3 &lt;/b&gt;uses a hybrid mixture-of-experts architecture to improve reasoning throughput for areas like software development, customer service and IT support.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Nemotron Nano 2 VL&lt;/b&gt; provides document intelligence, image reasoning and video analysis.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Nemotron Parse &lt;/b&gt;extracts text and tables from documents to take actionable insights.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Nemotron Safety Guard&lt;/b&gt; adds culturally aware multilingual moderation capabilities, detecting harmful content across 23 safety categories in nine languages.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Nemotron retrieval-augmented generation (RAG)&lt;/b&gt; models now feature advanced document extraction and unified retrieval across text, images, audio and video data sources.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;NVIDIA also released new open-source Nemotron datasets — including on multimodal training, multilingual personas and privacy-preserving synthetic personal information — for specialized model development. In addition, new NVIDIA NeMo tools, including NeMo Data Designer for synthetic data generation and NeMo-RL for advanced post-training and reinforcement learning, give developers greater control over model customization.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Leading Software Companies Building Agentic AI on Nemotron&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Open-source models enable developers to build and adapt AI for their domains, transforming software into agentic systems that use tools, not just provide them. Leading software and services companies are building agentic software platforms using NVIDIA Nemotron.&lt;/p&gt;
&lt;p&gt;Building on the success of the Apriel Nemotron model family that’s post-trained with NVIDIA and ServiceNow-provided data, ServiceNow introduced its new Apriel 2.0 multimodal reasoning model that brings intelligence to cross-enterprise workflows for every industry, including regulated sectors like financial services, healthcare and telecom.&lt;/p&gt;
&lt;p&gt;“Open models are driving the next wave of enterprise transformation,” said Joe Davis, executive vice president of platform engineering and AI at ServiceNow. “Apriel 2.0 represents one of the first open-weight multimodal reasoning models built for the enterprise — combining text, document and data understanding to power real-world workflows across industries. Together with NVIDIA, we’re pairing reasoning transparency with performance efficiency, bringing explainable, secure and scalable AI to sectors where trust and compliance matter most.”&lt;/p&gt;
&lt;p&gt;Additional leading software companies are adopting NVIDIA’s latest reasoning models to power their next-generation AI applications:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Palantir is making Nemotron available via its Ontology in Foundry and AIP to support an integrated technology stack with NVIDIA for operational AI.&lt;/li&gt;
&lt;li&gt;Cadence is accelerating chip designer productivity with its JedAI Platform and Nemotron open technologies.&lt;/li&gt;
&lt;li&gt;CrowdStrike is building autonomous, continuously learning AI agents into its Agentic Security Platform with NVIDIA Nemotron.&lt;/li&gt;
&lt;li&gt;PayPal is boosting the throughput and cost efficiency of its AI services by 50% with Nemotron.&lt;/li&gt;
&lt;li&gt;Synopsys is collaborating with NVIDIA to develop chip-design agents with the NVIDIA NeMo Agent Toolkit and Nemotron open models and data, used by NVIDIA engineers.&lt;/li&gt;
&lt;li&gt;Zoom is utilizing Nemotron for customized agentic capabilities to align with the specific workflows of its customers.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;b&gt;Cosmos and Isaac GR00T Open Models and Data for Physical AI and Robotics&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;To accelerate the training of robotic systems with humanlike reasoning and cognition, NVIDIA introduced major updates to its open models for physical AI, including Cosmos world foundation models and Isaac GR00T robot foundation models:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Cosmos Predict 2.5&lt;/b&gt;: Unifies three models into one for rapid world simulation, generating 30-second videos from a single frame.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Cosmos Transfer 2.5&lt;/b&gt;: Produces higher-quality, photorealistic data from 3D scenes at one-third the size of Cosmos Transfer 1.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Cosmos Reason&lt;/b&gt;: A reasoning vision language model, now available as an NVIDIA NIM microservice, for advanced multimodal understanding.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Cosmos Dataset Search&lt;/b&gt;: Enables instant retrieval of training scenarios, cutting post-training cycles from months to days.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Isaac GR00T N1.6&lt;/b&gt;: Enhances reasoning, generalization and whole-body control for humanoid robots.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;NVIDIA also released the world’s largest open-source dataset for physical AI, now featuring 1,700 hours of multimodal driving sensor data from across the U.S. and Europe as well as GR00T training data, which has risen to the top 10 most-downloaded Hugging Face datasets of all time.&lt;/p&gt;
&lt;p&gt;Leading companies — including Agility Robotics, Amazon Robotics, Figure AI, Skild AI, Milestone Systems and Uber — are adopting Cosmos or Isaac GR00T N models to generate synthetic data, teach robots new behaviors and deploy real-world and physical AI agents at scale.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;NVIDIA Clara Open Models for Healthcare and Life Sciences&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;New open models joining NVIDIA Clara, a family of models, tools and recipes built for accelerating scientific discovery, analyzing medical images and more, include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Clara CodonFM&lt;/b&gt;: Learns the rules of RNA to reveal how changes in its code can improve the design of therapies and medicine. NVIDIA will contribute open models like CodonFM to the Chan Zuckerberg Initiative’s virtual cells platform, accelerating open-source collaboration and model evaluation.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Clara La-Proteina&lt;/b&gt;: Creates 3D protein structures atom by atom at twice the length and complexity of previous models, enabling the design of better medicines, enzymes and materials.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Clara Reason: &lt;/b&gt;A vision language model enabling chain-of-thought reasoning for radiology and medical imaging to advance explainable AI medical research.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;b&gt;Get Started With NVIDIA Open Models&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Select NVIDIA Nemotron and Cosmos open models, trained on NVIDIA DGX Cloud, are available on build.nvidia.com, Hugging Face, OpenRouter and Microsoft Azure AI Foundry, and are coming soon to Google Vertex AI Platform and other cloud service providers. NVIDIA Clara and Isaac GR00T are available on Hugging Face.&lt;/p&gt;
&lt;p&gt;The models are available as NVIDIA NIM microservices for secure, scalable deployment on DGX Cloud or any NVIDIA-accelerated infrastructure for maximum privacy and control.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Learn more about how NVIDIA and partners are advancing AI innovation in the U.S. by watching the &lt;/i&gt;&lt;i&gt;NVIDIA GTC Washington, D.C., keynote by Huang&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/llm-agentic-ai-gtc25dc-devnews-press-1920x1080-v2.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Furthering its deep commitment to open source, NVIDIA is unveiling new open-source AI technologies for language, robotics and biology — contributing to an open ecosystem that broadens access to AI and fuels U.S. innovation.&lt;/p&gt;
&lt;p&gt;These open technologies will empower developers worldwide and strengthen economic growth through efficient reasoning, high-fidelity world generation and interactive physical AI systems accelerated on NVIDIA infrastructure.&lt;/p&gt;
&lt;p&gt;The new open models, data and tools are part of the NVIDIA Nemotron family for AI reasoning, the NVIDIA Cosmos platform for physical AI, NVIDIA Isaac GR00T for robotics and NVIDIA Clara for biomedical AI.&lt;/p&gt;
&lt;p&gt;NVIDIA is contributing these models, data and training frameworks to Hugging Face to make AI research and development more accessible. As a top contributor to Hugging Face, with more than 650 open models and 250 open datasets now available, NVIDIA continues to expand access to cutting-edge AI resources for the global developer community.&lt;/p&gt;
&lt;p&gt;“Open models are catalysts to AI innovation, making AI accessible, transparent and responsible,” said Clément Delangue, CEO of Hugging Face. “NVIDIA’s contributions to the open model ecosystem, commitment to open research for AI and Hugging Face’s ecosystem will empower millions of developers to build advanced AI — together and in the open.”&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;NVIDIA Nemotron Brings Ultra-Efficient Reasoning to Specialized AI Agents&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;AI agents use multiple models to see, retrieve, generate and reason. The latest open models in the NVIDIA Nemotron family unify these capabilities, enabling developers to build specialized, intelligent agents.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Nemotron Nano 3 &lt;/b&gt;uses a hybrid mixture-of-experts architecture to improve reasoning throughput for areas like software development, customer service and IT support.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Nemotron Nano 2 VL&lt;/b&gt; provides document intelligence, image reasoning and video analysis.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Nemotron Parse &lt;/b&gt;extracts text and tables from documents to take actionable insights.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Nemotron Safety Guard&lt;/b&gt; adds culturally aware multilingual moderation capabilities, detecting harmful content across 23 safety categories in nine languages.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Nemotron retrieval-augmented generation (RAG)&lt;/b&gt; models now feature advanced document extraction and unified retrieval across text, images, audio and video data sources.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;NVIDIA also released new open-source Nemotron datasets — including on multimodal training, multilingual personas and privacy-preserving synthetic personal information — for specialized model development. In addition, new NVIDIA NeMo tools, including NeMo Data Designer for synthetic data generation and NeMo-RL for advanced post-training and reinforcement learning, give developers greater control over model customization.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Leading Software Companies Building Agentic AI on Nemotron&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Open-source models enable developers to build and adapt AI for their domains, transforming software into agentic systems that use tools, not just provide them. Leading software and services companies are building agentic software platforms using NVIDIA Nemotron.&lt;/p&gt;
&lt;p&gt;Building on the success of the Apriel Nemotron model family that’s post-trained with NVIDIA and ServiceNow-provided data, ServiceNow introduced its new Apriel 2.0 multimodal reasoning model that brings intelligence to cross-enterprise workflows for every industry, including regulated sectors like financial services, healthcare and telecom.&lt;/p&gt;
&lt;p&gt;“Open models are driving the next wave of enterprise transformation,” said Joe Davis, executive vice president of platform engineering and AI at ServiceNow. “Apriel 2.0 represents one of the first open-weight multimodal reasoning models built for the enterprise — combining text, document and data understanding to power real-world workflows across industries. Together with NVIDIA, we’re pairing reasoning transparency with performance efficiency, bringing explainable, secure and scalable AI to sectors where trust and compliance matter most.”&lt;/p&gt;
&lt;p&gt;Additional leading software companies are adopting NVIDIA’s latest reasoning models to power their next-generation AI applications:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Palantir is making Nemotron available via its Ontology in Foundry and AIP to support an integrated technology stack with NVIDIA for operational AI.&lt;/li&gt;
&lt;li&gt;Cadence is accelerating chip designer productivity with its JedAI Platform and Nemotron open technologies.&lt;/li&gt;
&lt;li&gt;CrowdStrike is building autonomous, continuously learning AI agents into its Agentic Security Platform with NVIDIA Nemotron.&lt;/li&gt;
&lt;li&gt;PayPal is boosting the throughput and cost efficiency of its AI services by 50% with Nemotron.&lt;/li&gt;
&lt;li&gt;Synopsys is collaborating with NVIDIA to develop chip-design agents with the NVIDIA NeMo Agent Toolkit and Nemotron open models and data, used by NVIDIA engineers.&lt;/li&gt;
&lt;li&gt;Zoom is utilizing Nemotron for customized agentic capabilities to align with the specific workflows of its customers.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;b&gt;Cosmos and Isaac GR00T Open Models and Data for Physical AI and Robotics&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;To accelerate the training of robotic systems with humanlike reasoning and cognition, NVIDIA introduced major updates to its open models for physical AI, including Cosmos world foundation models and Isaac GR00T robot foundation models:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Cosmos Predict 2.5&lt;/b&gt;: Unifies three models into one for rapid world simulation, generating 30-second videos from a single frame.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Cosmos Transfer 2.5&lt;/b&gt;: Produces higher-quality, photorealistic data from 3D scenes at one-third the size of Cosmos Transfer 1.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Cosmos Reason&lt;/b&gt;: A reasoning vision language model, now available as an NVIDIA NIM microservice, for advanced multimodal understanding.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Cosmos Dataset Search&lt;/b&gt;: Enables instant retrieval of training scenarios, cutting post-training cycles from months to days.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Isaac GR00T N1.6&lt;/b&gt;: Enhances reasoning, generalization and whole-body control for humanoid robots.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;NVIDIA also released the world’s largest open-source dataset for physical AI, now featuring 1,700 hours of multimodal driving sensor data from across the U.S. and Europe as well as GR00T training data, which has risen to the top 10 most-downloaded Hugging Face datasets of all time.&lt;/p&gt;
&lt;p&gt;Leading companies — including Agility Robotics, Amazon Robotics, Figure AI, Skild AI, Milestone Systems and Uber — are adopting Cosmos or Isaac GR00T N models to generate synthetic data, teach robots new behaviors and deploy real-world and physical AI agents at scale.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;NVIDIA Clara Open Models for Healthcare and Life Sciences&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;New open models joining NVIDIA Clara, a family of models, tools and recipes built for accelerating scientific discovery, analyzing medical images and more, include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Clara CodonFM&lt;/b&gt;: Learns the rules of RNA to reveal how changes in its code can improve the design of therapies and medicine. NVIDIA will contribute open models like CodonFM to the Chan Zuckerberg Initiative’s virtual cells platform, accelerating open-source collaboration and model evaluation.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Clara La-Proteina&lt;/b&gt;: Creates 3D protein structures atom by atom at twice the length and complexity of previous models, enabling the design of better medicines, enzymes and materials.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Clara Reason: &lt;/b&gt;A vision language model enabling chain-of-thought reasoning for radiology and medical imaging to advance explainable AI medical research.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;b&gt;Get Started With NVIDIA Open Models&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Select NVIDIA Nemotron and Cosmos open models, trained on NVIDIA DGX Cloud, are available on build.nvidia.com, Hugging Face, OpenRouter and Microsoft Azure AI Foundry, and are coming soon to Google Vertex AI Platform and other cloud service providers. NVIDIA Clara and Isaac GR00T are available on Hugging Face.&lt;/p&gt;
&lt;p&gt;The models are available as NVIDIA NIM microservices for secure, scalable deployment on DGX Cloud or any NVIDIA-accelerated infrastructure for maximum privacy and control.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Learn more about how NVIDIA and partners are advancing AI innovation in the U.S. by watching the &lt;/i&gt;&lt;i&gt;NVIDIA GTC Washington, D.C., keynote by Huang&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/open-models-data-ai/</guid><pubDate>Tue, 28 Oct 2025 17:31:14 +0000</pubDate></item><item><title>VC Vinod Khosla says the US government could take 10% stake in all public companies to soften the blow of AGI (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/28/vc-vinod-khosla-says-the-us-government-could-take/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/2243821602.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Vinod Khosla has a bold vision for how society could be reconfigured to share the abundance created by AI technology. Speaking at the TechCrunch Disrupt 2025 conference on Tuesday, the Khosla Ventures founder suggested the U.S. government could take a 10% stake in all public corporations and redistribute that corporate wealth to the public at large.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Khosla put it, the idea was spurred by President Donald Trump’s decision for the U.S. government to purchase a 10% stake in Intel. “When Trump bought 10% of Intel, I wondered if it wasn’t a good idea,” Khosla said onstage at Disrupt. “Take 10% of every corporation and put it in a national pool for the people. That’s really interesting. Just take 10% of every public company.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;AI leaders have explored universal basic income proposals in the past, most notably in OpenResearch’s extended study on cash payments, backed in part by Sam Altman. Still it’s rare for a prominent investor to so explicitly endorse a national stake in private industry. Khosla acknowledged the controversy onstage but said extreme proposals were necessary to sustain social cohesion through the disruption of artificial general intelligence.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I’ll get critique for this idea,” Khosla said. “But you know, sharing the wealth of AI is a really, really big need to level the benefits to everybody&amp;nbsp;… We won’t need to do it in 15 years, but we do have to take care of those people. We will, by 2035, have a hugely, hugely deflationary economy.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Khosla also cautioned that the rise of AI would also displace jobs, which would require significant societal changes. For startup founders, this presents an opportunity to build, he said, noting that there’s a startup in building AI for every profession, like accounting, medicine, chip design, auditing, marketing, entertainment, and more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The VC also suggested that the nature of work would change in the AI era, as the jobs that people perform today could go away. He pointed to work like mounting a tire on an assembly line or working as a farmer as “not a job that humans should have.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“That’s servitude to survival,” Khosla said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There’s still plenty of time to get a ticket for TechCrunch Disrupt 2025, and with two days left, we’re offering a 50% discount.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/2243821602.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Vinod Khosla has a bold vision for how society could be reconfigured to share the abundance created by AI technology. Speaking at the TechCrunch Disrupt 2025 conference on Tuesday, the Khosla Ventures founder suggested the U.S. government could take a 10% stake in all public corporations and redistribute that corporate wealth to the public at large.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Khosla put it, the idea was spurred by President Donald Trump’s decision for the U.S. government to purchase a 10% stake in Intel. “When Trump bought 10% of Intel, I wondered if it wasn’t a good idea,” Khosla said onstage at Disrupt. “Take 10% of every corporation and put it in a national pool for the people. That’s really interesting. Just take 10% of every public company.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;AI leaders have explored universal basic income proposals in the past, most notably in OpenResearch’s extended study on cash payments, backed in part by Sam Altman. Still it’s rare for a prominent investor to so explicitly endorse a national stake in private industry. Khosla acknowledged the controversy onstage but said extreme proposals were necessary to sustain social cohesion through the disruption of artificial general intelligence.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I’ll get critique for this idea,” Khosla said. “But you know, sharing the wealth of AI is a really, really big need to level the benefits to everybody&amp;nbsp;… We won’t need to do it in 15 years, but we do have to take care of those people. We will, by 2035, have a hugely, hugely deflationary economy.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Khosla also cautioned that the rise of AI would also displace jobs, which would require significant societal changes. For startup founders, this presents an opportunity to build, he said, noting that there’s a startup in building AI for every profession, like accounting, medicine, chip design, auditing, marketing, entertainment, and more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The VC also suggested that the nature of work would change in the AI era, as the jobs that people perform today could go away. He pointed to work like mounting a tire on an assembly line or working as a farmer as “not a job that humans should have.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“That’s servitude to survival,” Khosla said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There’s still plenty of time to get a ticket for TechCrunch Disrupt 2025, and with two days left, we’re offering a 50% discount.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/28/vc-vinod-khosla-says-the-us-government-could-take/</guid><pubDate>Tue, 28 Oct 2025 17:45:42 +0000</pubDate></item><item><title>[NEW] NVIDIA and US Technology Leaders Unveil AI Factory Design to Modernize Government and Secure the Nation (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/us-technology-leaders-ai-factory-design-government/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/ai-factory-press-gtc25-dc-government-pr-1920x1080-4404721.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Governments everywhere are racing to harness the power of AI — but legacy infrastructure isn’t built for the velocity, complexity or trust that mission-critical action now demands. Massive data streams, cyber threats and urgent operations require a new blueprint for creating AI factories purpose-built for the public sector’s unique standards and scale.&lt;/p&gt;
&lt;p&gt;At NVIDIA GTC Washington, D.C., NVIDIA today unveiled the NVIDIA AI Factory for Government reference design, in collaboration with software and services leaders, to enable federal agencies and regulated industries to build and deploy new AI platforms and intelligent agents.&lt;/p&gt;
&lt;p&gt;The reference design provides guidance for deploying full-stack AI infrastructure using the latest NVIDIA AI Enterprise software — now designed to meet stringent security standards for FedRAMP-authorized clouds and high-assurance environments.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Industry Leaders Tap NVIDIA AI Factory for Government&amp;nbsp;&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;NVIDIA AI Factory for Government runs on recommended hardware configurations from NVIDIA Enterprise Reference Architectures, based on the NVIDIA Blackwell architecture, including NVIDIA RTX PRO Servers and NVIDIA HGX B200 systems. It also includes NVIDIA Spectrum-X Ethernet, the NVIDIA BlueField platform, NVIDIA-Certified Storage, the latest NVIDIA AI Enterprise software and NVIDIA Nemotron open models.&lt;/p&gt;
&lt;p&gt;Building on the NVIDIA Enterprise AI Factory validated design announced at COMPUTEX, the AI Factory for Government reference design features NVIDIA AI Enterprise software, which is now built to meet rigorous security standards. NVIDIA AI Enterprise includes new capabilities like advanced code scanning, vulnerability management and continuous monitoring to ensure the highest levels of security. This enables AI workloads to remain configured, regularly updated and ready for mission-critical deployments across federal and high-assurance environments.&lt;/p&gt;
&lt;p&gt;NVIDIA is working with leading technology platform providers to operationalize AI with the latest NVIDIA AI Enterprise software, helping serve the needs of the public sector and other highly regulated industries.&lt;/p&gt;
&lt;p&gt;Palantir and NVIDIA are building a first-of-its-kind integrated technology stack for operational AI that integrates Palantir Ontology — the core of the Palantir AI Platform (AIP) — with NVIDIA data processing and route optimization libraries, open models and accelerated computing to speed up AI deployments for enterprises and government.&lt;/p&gt;
&lt;p&gt;AIP will integrate NVIDIA AI Enterprise software, NVIDIA Nemotron and other AI capabilities included in the AI Factory for Government reference design to power domain-specific intelligence and AI agents for the complex operating environments of highly regulated industries.&lt;/p&gt;
&lt;p&gt;To strengthen cybersecurity in AI factories, CrowdStrike will expand its Agentic Security Platform to support the NVIDIA AI Factory for Government reference design, enabling organizations to build and deploy AI agents in federal and high-assurance environments.&lt;/p&gt;
&lt;p&gt;CrowdStrike will also integrate NVIDIA Nemotron open models, NVIDIA NeMo Data Designer and the NVIDIA NeMo Agent Toolkit through Charlotte AI AgentWorks to deliver autonomous, continuously learning AI agents for real-time threat detection and response across cloud, data center and edge environments.&lt;/p&gt;
&lt;p&gt;ServiceNow is integrating the latest NVIDIA AI Enterprise software in the ServiceNow AI Platform for U.S. federal customers — suitable for FedRAMP-authorized clouds and high-assurance, on-premises environments — to boost productivity and drive savings for public sector agencies. ServiceNow also announced today its Apriel 2.0 model — the latest in its Apriel Nemotron model family, engineered to deliver frontier-level AI reasoning and multimodal capabilities to enterprises in a faster, smaller, more cost-efficient footprint.&lt;/p&gt;
&lt;p&gt;Astris AI, a Lockheed Martin company, is integrating the latest NVIDIA AI Enterprise software into its Astris AI Factory to enable accelerated, secure AI deployments for classified and mission-critical environments, in alignment with strict federal security standards.&lt;/p&gt;
&lt;p&gt;The Astris AI Factory has been used internally at Lockheed Martin for more than five years. Now commercially available, Astris AI will use the latest NVIDIA AI Enterprise software to develop and deploy internal AI agents in industries that rely on trust and precision.&lt;/p&gt;
&lt;p&gt;“Success in complex missions depends on AI that’s secure and reliable,” said Jim Taiclet, chairman, president and CEO of Lockheed Martin. “By working with Astris AI and using the latest NVIDIA AI Enterprise tools, we’re speeding up how we develop and deliver AI systems that improve precision and performance in critical operations.”&lt;/p&gt;
&lt;p&gt;Northrop Grumman is deploying an AI factory powered by NVIDIA RTX PRO Servers, Spectrum-X Ethernet networking and government-ready NVIDIA AI Enterprise software for deploying secure enterprise AI services, enabling development of advanced AI capabilities and boosting productivity and operational efficiency across its workforce of nearly 100,000 employees.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Partner Ecosystem Readies AI Factories to Accelerate AI Agents&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;NVIDIA partners are helping enable the world’s organizations to rapidly build and deploy AI agents and applications across federal and enterprise organizations with the NVIDIA AI Factory for Government reference design.&lt;/p&gt;
&lt;p&gt;Developers deploying AI agents on their AI factory infrastructure can tap into partner platforms from Dataiku, DataRobot, Domino Data Lab and H2O.ai to build, orchestrate, operationalize and scale agentic and predictive AI workflows. In addition, the reference design supports vector databases from Elastic and EnterpriseDB to help agents store, search and retrieve data.&lt;/p&gt;
&lt;p&gt;Enterprises can secure their AI factories with software from observability and security partners including Dynatrace, Fiddler, JFrog, Protopia AI, Trend Micro and Weights &amp;amp; Biases. Customers can also secure their agentic AI applications by adding NVIDIA Confidential Computing to their hybrid and on-premises AI factories through data security platform partners such as Fortanix.&lt;/p&gt;
&lt;p&gt;Software infrastructure and deployment partners including Canonical, Mirantis, Nutanix, Red Hat, Spectro Cloud and Broadcom can help enterprises seamlessly scale and manage AI agent workloads across complex, high-assurance, on-premises environments.&lt;/p&gt;
&lt;p&gt;Cloud providers including CoreWeave and Oracle Cloud Infrastructure are supporting the AI Factory for Government reference design so their government customers can build and deploy government-ready AI factories in secure cloud environments.&lt;/p&gt;
&lt;p&gt;Leading server manufacturers including Cisco, Dell Technologies, HPE, Lenovo and Supermicro will offer full-stack AI factory offerings using the NVIDIA AI Factory for Government reference design to further accelerate AI deployments for the public sector and highly regulated industries.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Watch the &lt;/i&gt;&lt;i&gt;GTC Washington, D.C., keynote&lt;/i&gt;&lt;i&gt; from NVIDIA founder and CEO Jensen Huang and explore &lt;/i&gt;&lt;i&gt;sessions&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;See &lt;/i&gt;&lt;i&gt;notice&lt;/i&gt;&lt;i&gt; regarding software product information.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/ai-factory-press-gtc25-dc-government-pr-1920x1080-4404721.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Governments everywhere are racing to harness the power of AI — but legacy infrastructure isn’t built for the velocity, complexity or trust that mission-critical action now demands. Massive data streams, cyber threats and urgent operations require a new blueprint for creating AI factories purpose-built for the public sector’s unique standards and scale.&lt;/p&gt;
&lt;p&gt;At NVIDIA GTC Washington, D.C., NVIDIA today unveiled the NVIDIA AI Factory for Government reference design, in collaboration with software and services leaders, to enable federal agencies and regulated industries to build and deploy new AI platforms and intelligent agents.&lt;/p&gt;
&lt;p&gt;The reference design provides guidance for deploying full-stack AI infrastructure using the latest NVIDIA AI Enterprise software — now designed to meet stringent security standards for FedRAMP-authorized clouds and high-assurance environments.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Industry Leaders Tap NVIDIA AI Factory for Government&amp;nbsp;&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;NVIDIA AI Factory for Government runs on recommended hardware configurations from NVIDIA Enterprise Reference Architectures, based on the NVIDIA Blackwell architecture, including NVIDIA RTX PRO Servers and NVIDIA HGX B200 systems. It also includes NVIDIA Spectrum-X Ethernet, the NVIDIA BlueField platform, NVIDIA-Certified Storage, the latest NVIDIA AI Enterprise software and NVIDIA Nemotron open models.&lt;/p&gt;
&lt;p&gt;Building on the NVIDIA Enterprise AI Factory validated design announced at COMPUTEX, the AI Factory for Government reference design features NVIDIA AI Enterprise software, which is now built to meet rigorous security standards. NVIDIA AI Enterprise includes new capabilities like advanced code scanning, vulnerability management and continuous monitoring to ensure the highest levels of security. This enables AI workloads to remain configured, regularly updated and ready for mission-critical deployments across federal and high-assurance environments.&lt;/p&gt;
&lt;p&gt;NVIDIA is working with leading technology platform providers to operationalize AI with the latest NVIDIA AI Enterprise software, helping serve the needs of the public sector and other highly regulated industries.&lt;/p&gt;
&lt;p&gt;Palantir and NVIDIA are building a first-of-its-kind integrated technology stack for operational AI that integrates Palantir Ontology — the core of the Palantir AI Platform (AIP) — with NVIDIA data processing and route optimization libraries, open models and accelerated computing to speed up AI deployments for enterprises and government.&lt;/p&gt;
&lt;p&gt;AIP will integrate NVIDIA AI Enterprise software, NVIDIA Nemotron and other AI capabilities included in the AI Factory for Government reference design to power domain-specific intelligence and AI agents for the complex operating environments of highly regulated industries.&lt;/p&gt;
&lt;p&gt;To strengthen cybersecurity in AI factories, CrowdStrike will expand its Agentic Security Platform to support the NVIDIA AI Factory for Government reference design, enabling organizations to build and deploy AI agents in federal and high-assurance environments.&lt;/p&gt;
&lt;p&gt;CrowdStrike will also integrate NVIDIA Nemotron open models, NVIDIA NeMo Data Designer and the NVIDIA NeMo Agent Toolkit through Charlotte AI AgentWorks to deliver autonomous, continuously learning AI agents for real-time threat detection and response across cloud, data center and edge environments.&lt;/p&gt;
&lt;p&gt;ServiceNow is integrating the latest NVIDIA AI Enterprise software in the ServiceNow AI Platform for U.S. federal customers — suitable for FedRAMP-authorized clouds and high-assurance, on-premises environments — to boost productivity and drive savings for public sector agencies. ServiceNow also announced today its Apriel 2.0 model — the latest in its Apriel Nemotron model family, engineered to deliver frontier-level AI reasoning and multimodal capabilities to enterprises in a faster, smaller, more cost-efficient footprint.&lt;/p&gt;
&lt;p&gt;Astris AI, a Lockheed Martin company, is integrating the latest NVIDIA AI Enterprise software into its Astris AI Factory to enable accelerated, secure AI deployments for classified and mission-critical environments, in alignment with strict federal security standards.&lt;/p&gt;
&lt;p&gt;The Astris AI Factory has been used internally at Lockheed Martin for more than five years. Now commercially available, Astris AI will use the latest NVIDIA AI Enterprise software to develop and deploy internal AI agents in industries that rely on trust and precision.&lt;/p&gt;
&lt;p&gt;“Success in complex missions depends on AI that’s secure and reliable,” said Jim Taiclet, chairman, president and CEO of Lockheed Martin. “By working with Astris AI and using the latest NVIDIA AI Enterprise tools, we’re speeding up how we develop and deliver AI systems that improve precision and performance in critical operations.”&lt;/p&gt;
&lt;p&gt;Northrop Grumman is deploying an AI factory powered by NVIDIA RTX PRO Servers, Spectrum-X Ethernet networking and government-ready NVIDIA AI Enterprise software for deploying secure enterprise AI services, enabling development of advanced AI capabilities and boosting productivity and operational efficiency across its workforce of nearly 100,000 employees.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Partner Ecosystem Readies AI Factories to Accelerate AI Agents&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;NVIDIA partners are helping enable the world’s organizations to rapidly build and deploy AI agents and applications across federal and enterprise organizations with the NVIDIA AI Factory for Government reference design.&lt;/p&gt;
&lt;p&gt;Developers deploying AI agents on their AI factory infrastructure can tap into partner platforms from Dataiku, DataRobot, Domino Data Lab and H2O.ai to build, orchestrate, operationalize and scale agentic and predictive AI workflows. In addition, the reference design supports vector databases from Elastic and EnterpriseDB to help agents store, search and retrieve data.&lt;/p&gt;
&lt;p&gt;Enterprises can secure their AI factories with software from observability and security partners including Dynatrace, Fiddler, JFrog, Protopia AI, Trend Micro and Weights &amp;amp; Biases. Customers can also secure their agentic AI applications by adding NVIDIA Confidential Computing to their hybrid and on-premises AI factories through data security platform partners such as Fortanix.&lt;/p&gt;
&lt;p&gt;Software infrastructure and deployment partners including Canonical, Mirantis, Nutanix, Red Hat, Spectro Cloud and Broadcom can help enterprises seamlessly scale and manage AI agent workloads across complex, high-assurance, on-premises environments.&lt;/p&gt;
&lt;p&gt;Cloud providers including CoreWeave and Oracle Cloud Infrastructure are supporting the AI Factory for Government reference design so their government customers can build and deploy government-ready AI factories in secure cloud environments.&lt;/p&gt;
&lt;p&gt;Leading server manufacturers including Cisco, Dell Technologies, HPE, Lenovo and Supermicro will offer full-stack AI factory offerings using the NVIDIA AI Factory for Government reference design to further accelerate AI deployments for the public sector and highly regulated industries.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Watch the &lt;/i&gt;&lt;i&gt;GTC Washington, D.C., keynote&lt;/i&gt;&lt;i&gt; from NVIDIA founder and CEO Jensen Huang and explore &lt;/i&gt;&lt;i&gt;sessions&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;See &lt;/i&gt;&lt;i&gt;notice&lt;/i&gt;&lt;i&gt; regarding software product information.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/us-technology-leaders-ai-factory-design-government/</guid><pubDate>Tue, 28 Oct 2025 17:55:41 +0000</pubDate></item><item><title>[NEW] NVIDIA IGX Thor Robotics Processor Brings Real-Time Physical AI to the Industrial and Medical Edge (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/igx-thor-processor-physical-ai-industrial-medical-edge/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;AI is moving from the digital world into the physical one. Across factory floors and operating rooms, machines are evolving into collaborators that can see, sense and make decisions in real time.&lt;/p&gt;
&lt;p&gt;To accelerate this transformation, NVIDIA today unveiled NVIDIA IGX Thor, a powerful, industrial-grade platform built to bring real-time physical AI directly to the edge, combining high-speed sensor processing, enterprise-grade reliability and functional safety in a small module for the desktop.&lt;/p&gt;
&lt;p&gt;Delivering up to 8x the AI compute performance of its predecessor, NVIDIA IGX Orin, IGX Thor enables developers to build intelligent systems that perceive, reason and act faster, safer and smarter than ever.&lt;/p&gt;
&lt;p&gt;Early adopters include industrial, robotic, medical and healthcare leaders, Diligent Robotics, EndoQuest Robotics, Hitachi Rail, Joby Aviation, Maven and SETI Institute, while CMR Surgical is evaluating IGX Thor to advance its medical capabilities.&lt;/p&gt;
&lt;figure class="wp-caption alignnone" id="attachment_86399"&gt;&lt;img alt="alt" class="wp-image-86399 size-full" height="680" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/igxthordevkit.jpg" width="1280" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-86399"&gt;The NVIDIA Jetson IGX Thor Developer Kit Mini.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;h2&gt;&lt;b&gt;IGX Thor Delivers Breakthrough Performance for Edge AI Applications&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Medical and industrial companies have historically faced limitations advancing applications for medical imaging, surgical robotics and industrial AI automation due to edge systems lacking the speed and capacity to process real-time data or securely run multiple generative AI models without sacrificing performance.&lt;/p&gt;
&lt;p&gt;IGX Thor overcomes these challenges by delivering robust, reliable AI compute tailored for industrial and medical environments. It provides real-time intelligence, seamless data connectivity, and built-in safety and security.&lt;/p&gt;
&lt;p&gt;The platform features two types of NVIDIA Blackwell GPUs — an integrated GPU (iGPU) and a discrete GPU (dGPU) — delivering 5,581 FP4 teraflops of AI compute with 400 GbE connectivity. Compared with NVIDIA IGX Orin, IGX Thor provides up to 8x higher AI compute on iGPUs, 2.5x higher AI compute on dGPUs and 2x better connectivity to seamlessly run large language models and vision language models at the edge.&lt;/p&gt;
&lt;p&gt;The industrial-grade platform comes with a 10-year lifecycle and long-term support for the NVIDIA AI software stack, keeping enterprise and physical AI applications accelerated and secured even in the most challenging conditions. IGX Thor runs the NVIDIA AI Enterprise software stack, including NVIDIA NIM microservices, which accelerate physical AI application development from the cloud to the edge, NVIDIA Isaac for robotics, NVIDIA Metropolis for visual AI and NVIDIA Holoscan for sensor processing.&lt;/p&gt;
&lt;p&gt;In addition, NVIDIA IGX Thor integrates elements from the NVIDIA Halos full-stack safety system to embed functional safety into robotics, medical and industrial AI systems — tapping into onboard and infrastructure sensors to ensure both traditional and outside-in safety for safe human collaboration.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;NVIDIA Partner Ecosystem Accelerates the Industrial and Medical Edge&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Global industrial and robotic leaders Hitachi Rail, Maven, SETI Institute and Joby Aviation are adopting IGX Thor to build and deploy advanced AI solutions that enhance safety, improve efficiency and enable new levels of automation in factories, warehouses and transportation systems.&lt;/p&gt;
&lt;p&gt;Hitachi Rail is using IGX Thor to deploy advanced predictive maintenance and autonomous inspection systems on rail networks, boosting operational efficiency and reliability.&lt;/p&gt;
&lt;p&gt;“AI and data are transforming railways,” said Giuseppe Marino, group CEO of Hitachi Rail. “By adopting NVIDIA IGX Thor, we are bringing the world’s most powerful industrial-grade, real-time AI performance directly to the edge, enabling operators to better optimize their railways and infrastructure. This capability will strengthen reliability, efficiency and optimization for passengers and operators alike.”&lt;/p&gt;
&lt;p&gt;Maven Robotics will integrate NVIDIA IGX Thor into its next-generation industrial robots to unite advanced embodied-AI performance with built-in safety and real-time decision-making at scale.&lt;/p&gt;
&lt;p&gt;“Maven Robotics is bringing general-purpose robots to industrial environments, partnering with leading global manufacturing and logistics organizations to deploy at scale,” said Hamza Derbas, CEO of Maven Robotics. “NVIDIA Thor IGX sits at the core of our next-gen robots, pairing safety-rated compute with the performance to run advanced embodied-AI models so capability and compliance move forward together.”&lt;/p&gt;
&lt;p&gt;Global medical device and healthcare pioneers Diligent Robotics and Endoquest Robotics are adopting IGX Thor. CMR Surgical is evaluating IGX Thor to power advanced AI capabilities within its surgical robotics systems, enabling real-time analysis and adaptive decision-making in the operating room. The platform’s safety, reliability and compute performance support CMR’s vision to deliver intelligent assistance that enhances surgical precision, improves efficiency and results in better patient outcomes.&lt;/p&gt;
&lt;p&gt;“Precision and patient safety are at the heart of every procedure,” said Chris Fryer, chief technology officer of CMR Surgical. “With IGX Thor, we have the potential to deploy next-generation AI assistants and real-time surgical guidance that process high-fidelity data in real time, allowing us to simplify complex procedures and enable safer, more intelligent minimal-access surgery.”&lt;/p&gt;
&lt;p&gt;NVIDIA’s partner ecosystem of equipment manufacturers, including Advantech, ADLINK, ASRock Rack, Barco, Curtiss-Wright, Dedicated Computing, EIZO Rugged Solutions, Inventec, NexCOBOT – a NEXCOM company, Onyx, WOLF Advanced Technology and YUAN, provides a range of IGX Thor-powered edge servers, customized carrier boards, design services, cameras and sensors, along with AI and system software to speed solution development.&lt;/p&gt;
&lt;p&gt;The NVIDIA IGX Thor platform includes two production-ready systems — the NVIDIA IGX T5000 module and the NVIDIA IGX T7000 board kit — built for diverse physical AI applications with functional safety. The IGX Thor production systems and developer kits are expected to be available in December.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Watch the &lt;/i&gt;&lt;i&gt;GTC Washington, D.C., keynote&lt;/i&gt;&lt;i&gt; from NVIDIA founder and CEO Jensen Huang and&amp;nbsp;&lt;/i&gt;&lt;i&gt;explore &lt;/i&gt;&lt;i&gt;sessions&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;AI is moving from the digital world into the physical one. Across factory floors and operating rooms, machines are evolving into collaborators that can see, sense and make decisions in real time.&lt;/p&gt;
&lt;p&gt;To accelerate this transformation, NVIDIA today unveiled NVIDIA IGX Thor, a powerful, industrial-grade platform built to bring real-time physical AI directly to the edge, combining high-speed sensor processing, enterprise-grade reliability and functional safety in a small module for the desktop.&lt;/p&gt;
&lt;p&gt;Delivering up to 8x the AI compute performance of its predecessor, NVIDIA IGX Orin, IGX Thor enables developers to build intelligent systems that perceive, reason and act faster, safer and smarter than ever.&lt;/p&gt;
&lt;p&gt;Early adopters include industrial, robotic, medical and healthcare leaders, Diligent Robotics, EndoQuest Robotics, Hitachi Rail, Joby Aviation, Maven and SETI Institute, while CMR Surgical is evaluating IGX Thor to advance its medical capabilities.&lt;/p&gt;
&lt;figure class="wp-caption alignnone" id="attachment_86399"&gt;&lt;img alt="alt" class="wp-image-86399 size-full" height="680" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/igxthordevkit.jpg" width="1280" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-86399"&gt;The NVIDIA Jetson IGX Thor Developer Kit Mini.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;h2&gt;&lt;b&gt;IGX Thor Delivers Breakthrough Performance for Edge AI Applications&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Medical and industrial companies have historically faced limitations advancing applications for medical imaging, surgical robotics and industrial AI automation due to edge systems lacking the speed and capacity to process real-time data or securely run multiple generative AI models without sacrificing performance.&lt;/p&gt;
&lt;p&gt;IGX Thor overcomes these challenges by delivering robust, reliable AI compute tailored for industrial and medical environments. It provides real-time intelligence, seamless data connectivity, and built-in safety and security.&lt;/p&gt;
&lt;p&gt;The platform features two types of NVIDIA Blackwell GPUs — an integrated GPU (iGPU) and a discrete GPU (dGPU) — delivering 5,581 FP4 teraflops of AI compute with 400 GbE connectivity. Compared with NVIDIA IGX Orin, IGX Thor provides up to 8x higher AI compute on iGPUs, 2.5x higher AI compute on dGPUs and 2x better connectivity to seamlessly run large language models and vision language models at the edge.&lt;/p&gt;
&lt;p&gt;The industrial-grade platform comes with a 10-year lifecycle and long-term support for the NVIDIA AI software stack, keeping enterprise and physical AI applications accelerated and secured even in the most challenging conditions. IGX Thor runs the NVIDIA AI Enterprise software stack, including NVIDIA NIM microservices, which accelerate physical AI application development from the cloud to the edge, NVIDIA Isaac for robotics, NVIDIA Metropolis for visual AI and NVIDIA Holoscan for sensor processing.&lt;/p&gt;
&lt;p&gt;In addition, NVIDIA IGX Thor integrates elements from the NVIDIA Halos full-stack safety system to embed functional safety into robotics, medical and industrial AI systems — tapping into onboard and infrastructure sensors to ensure both traditional and outside-in safety for safe human collaboration.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;NVIDIA Partner Ecosystem Accelerates the Industrial and Medical Edge&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Global industrial and robotic leaders Hitachi Rail, Maven, SETI Institute and Joby Aviation are adopting IGX Thor to build and deploy advanced AI solutions that enhance safety, improve efficiency and enable new levels of automation in factories, warehouses and transportation systems.&lt;/p&gt;
&lt;p&gt;Hitachi Rail is using IGX Thor to deploy advanced predictive maintenance and autonomous inspection systems on rail networks, boosting operational efficiency and reliability.&lt;/p&gt;
&lt;p&gt;“AI and data are transforming railways,” said Giuseppe Marino, group CEO of Hitachi Rail. “By adopting NVIDIA IGX Thor, we are bringing the world’s most powerful industrial-grade, real-time AI performance directly to the edge, enabling operators to better optimize their railways and infrastructure. This capability will strengthen reliability, efficiency and optimization for passengers and operators alike.”&lt;/p&gt;
&lt;p&gt;Maven Robotics will integrate NVIDIA IGX Thor into its next-generation industrial robots to unite advanced embodied-AI performance with built-in safety and real-time decision-making at scale.&lt;/p&gt;
&lt;p&gt;“Maven Robotics is bringing general-purpose robots to industrial environments, partnering with leading global manufacturing and logistics organizations to deploy at scale,” said Hamza Derbas, CEO of Maven Robotics. “NVIDIA Thor IGX sits at the core of our next-gen robots, pairing safety-rated compute with the performance to run advanced embodied-AI models so capability and compliance move forward together.”&lt;/p&gt;
&lt;p&gt;Global medical device and healthcare pioneers Diligent Robotics and Endoquest Robotics are adopting IGX Thor. CMR Surgical is evaluating IGX Thor to power advanced AI capabilities within its surgical robotics systems, enabling real-time analysis and adaptive decision-making in the operating room. The platform’s safety, reliability and compute performance support CMR’s vision to deliver intelligent assistance that enhances surgical precision, improves efficiency and results in better patient outcomes.&lt;/p&gt;
&lt;p&gt;“Precision and patient safety are at the heart of every procedure,” said Chris Fryer, chief technology officer of CMR Surgical. “With IGX Thor, we have the potential to deploy next-generation AI assistants and real-time surgical guidance that process high-fidelity data in real time, allowing us to simplify complex procedures and enable safer, more intelligent minimal-access surgery.”&lt;/p&gt;
&lt;p&gt;NVIDIA’s partner ecosystem of equipment manufacturers, including Advantech, ADLINK, ASRock Rack, Barco, Curtiss-Wright, Dedicated Computing, EIZO Rugged Solutions, Inventec, NexCOBOT – a NEXCOM company, Onyx, WOLF Advanced Technology and YUAN, provides a range of IGX Thor-powered edge servers, customized carrier boards, design services, cameras and sensors, along with AI and system software to speed solution development.&lt;/p&gt;
&lt;p&gt;The NVIDIA IGX Thor platform includes two production-ready systems — the NVIDIA IGX T5000 module and the NVIDIA IGX T7000 board kit — built for diverse physical AI applications with functional safety. The IGX Thor production systems and developer kits are expected to be available in December.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Watch the &lt;/i&gt;&lt;i&gt;GTC Washington, D.C., keynote&lt;/i&gt;&lt;i&gt; from NVIDIA founder and CEO Jensen Huang and&amp;nbsp;&lt;/i&gt;&lt;i&gt;explore &lt;/i&gt;&lt;i&gt;sessions&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/igx-thor-processor-physical-ai-industrial-medical-edge/</guid><pubDate>Tue, 28 Oct 2025 17:58:53 +0000</pubDate></item><item><title>[NEW] Lilly Deploys World’s Largest, Most Powerful AI Factory for Drug Discovery Using NVIDIA Blackwell-Based DGX SuperPOD (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/lilly-ai-factory-nvidia-blackwell-dgx-superpod/</link><description>&lt;!-- OneTrust Cookies Consent Notice start for nvidia.com --&gt;


&lt;!-- OneTrust Cookies Consent Notice end for nvidia.com --&gt;


	
	
	
	
	
	

	

	
	
	


	&lt;!-- This site is optimized with the Yoast SEO Premium plugin v26.2 (Yoast SEO v26.2) - https://yoast.com/wordpress/plugins/seo/ --&gt;
	Lilly Deploys World’s Largest, Most Powerful AI Factory for Drug Discovery Using NVIDIA Blackwell-Based DGX SuperPOD | NVIDIA Blog
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	&lt;!-- / Yoast SEO Premium plugin. --&gt;






































&lt;!-- Stream WordPress user activity plugin v4.1.1 --&gt;


	
				&lt;!-- Hotjar Tracking Code for NVIDIA --&gt;
			
			


				
				



		
		

&lt;div class="hfeed site" id="page"&gt;
	Skip to content

	&lt;!-- #masthead --&gt;
		
		&lt;div class="full-width-layout light"&gt;
		

		
&lt;div class="full-width-layout__hero light"&gt;
	&lt;div class="full-width-layout__hero-content light"&gt;
		&lt;div class="full-width-layout__hero-content__inner light"&gt;
			

							&lt;p&gt;
					Built with over 1,000 NVIDIA Blackwell Ultra GPUs, the AI factory will support modern scientific research using foundation models, as well as physical and agentic AI.				&lt;/p&gt;
			
			
		&lt;/div&gt;
	&lt;/div&gt;

	&lt;p&gt;
		&lt;video class="full-width-layout__hero-video js-responsive-video" loop="loop"&gt;Your browser does not support the video tag.&lt;/video&gt;	&lt;/p&gt;

	&lt;/div&gt;

	
	
		&lt;div class="full-width-layout__sections"&gt;
&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Lilly, a pioneer in medicine, is deploying the largest, most powerful AI factory wholly owned and operated by a pharmaceutical company — the world’s first NVIDIA DGX SuperPOD with DGX B300 systems.&lt;/p&gt;
&lt;p&gt;Built with 1,016 NVIDIA Blackwell Ultra GPUs and announced today at NVIDIA GTC Washington, D.C., the AI factory is poised to compress drug discovery timelines and enable accelerated breakthroughs in genomics, personalized medicine and molecular design at industrial scale.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-video-section"&gt;
	&lt;video class="full-width-layout__video js-responsive-video" loop="loop"&gt;Your browser does not support the video tag.&lt;/video&gt;
&lt;p&gt;
	
			&lt;span class="full-width-layout__media-credits"&gt;
			Video courtesy of Lilly.		&lt;/span&gt;
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;The AI factory will be used to train large scale biomedical foundation and frontier models for drug discovery and development. Select models will be made available on Lilly TuneLab — an AI and machine learning platform that provides biotech companies with access to drug discovery models built on $1 billion worth of Lilly’s proprietary data.&lt;/p&gt;
&lt;p&gt;TuneLab is now the first drug discovery platform to offer Lilly models and NVIDIA Clara open foundation models for healthcare and life sciences, further expanding AI access for the biotech ecosystem.&lt;/p&gt;
&lt;p&gt;TuneLab uses a federated learning infrastructure built on NVIDIA FLARE, which enables biotechs to tap into powerful proprietary AI models while keeping their own data private and separate from other users. As more companies participate, the models improve, benefitting all users.&lt;/p&gt;
&lt;p&gt;“Our foundation models are spawning new possibilities for our chemists, helping them uncover new motifs and configurations of atoms that were out of reach with traditional methods,” said Thomas Fuchs, chief AI officer at Lilly. “AI gives us the means to accelerate progress toward both developing and delivering better, more personalized and targeted medicines.”&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-image-section"&gt;
			&lt;img alt="“AI gives us the means to accelerate progress toward both developing and delivering better, more personalized and targeted medicines,” said Thomas Fuchs, chief AI officer at Lilly." class="full-width-layout__image" height="819" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/fuchs-pulled-quote-1-scaled.jpg" width="2048" /&gt;	
	&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;The AI factory is powered by NVIDIA’s full-stack AI factory architecture offered with NVIDIA DGX SuperPOD — including accelerated computing, NVIDIA Spectrum-X Ethernet networking and optimized AI software. This provides a secure, scalable, purpose-built platform for the highly regulated healthcare and life sciences industries.&lt;/p&gt;
&lt;p&gt;NVIDIA Mission Control software allows Lilly to manage its DGX SuperPOD, orchestrate workloads, monitor performance and automate AI operations securely and efficiently across more than 1,000 GPUs.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;AI Applied Across Drug Discovery, Precision Medicine&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Lilly scientists can use the AI factory to analyze entire genome sequences, predict patient outcomes and explore multitudes of biochemical possibilities.&lt;/p&gt;
&lt;p&gt;“In our 150 years, Lilly has always closely connected science and technology,” said Diogo Rau, executive vice president and chief information and digital officer at Lilly. “If you focus only on science, you’re just going to have an experiment, a paper or a treatment — but if you bring together science and technology, like the accelerated compute we’re getting through this AI factory, you can reach a massive scale to bring the treatment to millions of people.”&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-image-section"&gt;
			&lt;img alt="“If you bring together science and technology … you can reach a massive scale to bring the treatment to millions of people,” said Diogo Rau, executive vice president and chief information and digital officer at Lilly." class="full-width-layout__image" height="819" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/rau-pulled-quote-1-scaled.jpg" width="2048" /&gt;	
	&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Using the NVIDIA BioNeMo platform, Lilly can train AI models that combine the learnings of millions of past experiments with public research to generate and test new antibodies, nanobodies and novel molecules with greater accuracy and speed than ever.&lt;/p&gt;
&lt;p&gt;The AI factory can also be applied to help discover new biomarkers and design gene therapies for degenerative conditions, Fuchs said.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__full-width-video-section"&gt;
			&lt;video class="full-width-layout__video" loop="loop"&gt;
							&lt;source src="https://blogs.nvidia.com/wp-content/uploads/2025/10/lilly-scientists.mp4" type="video/mp4" /&gt;
						&lt;p&gt;Your browser does not support HTML5 video.&lt;/p&gt;
		&lt;/video&gt;
	
	
&lt;p&gt;
	
			&lt;span class="full-width-layout__media-credits"&gt;
			Video courtesy of Lilly.		&lt;/span&gt;
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;And the impact extends beyond drug discovery.&lt;/p&gt;
&lt;p&gt;Using the AI factory, the company can build large language models that accelerate clinical trials by helping with medical writing and other internal workflows.&lt;/p&gt;
&lt;p&gt;And combined with the open-source MONAI framework, the AI factory can accelerate Lilly’s imaging-based research in precision medicine. Deep learning on massive imaging datasets can reduce processing time from months to days, allowing for quicker, more personalized treatments.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;Research and Biomanufacturing With Physical and Agentic AI&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;The AI factory is poised to enhance Lilly’s capacity to manufacture high-demand medications and strengthen supply chain reliability, including through the use of physical AI.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-video-section"&gt;
	&lt;video class="full-width-layout__video js-responsive-video" loop="loop"&gt;Your browser does not support the video tag.&lt;/video&gt;
&lt;p&gt;
	
			&lt;span class="full-width-layout__media-credits"&gt;
			Video courtesy of Lilly		&lt;/span&gt;
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;With technologies like the NVIDIA Omniverse platform and NVIDIA RTX PRO Servers, the pharma company can create digital twins of its manufacturing lines to model, stress-test and optimize entire supply chains before making physical changes in the real world.&lt;/p&gt;
&lt;p&gt;Digital twins can increase production safety while accelerating quality assurance and other biomanufacturing operations, ultimately getting medicines to patients faster.&lt;/p&gt;
&lt;p&gt;Lilly also uses robots in its factories for quality inspection and transport of goods — such as medicines and treatment components like injectors — optimizing operations and keeping production lines up and running.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-video-section"&gt;
	&lt;video class="full-width-layout__video js-responsive-video" loop="loop"&gt;Your browser does not support the video tag.&lt;/video&gt;
&lt;p&gt;
	
			&lt;span class="full-width-layout__media-credits"&gt;
			Video courtesy of Lilly.		&lt;/span&gt;
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;“Machinery downtime can mean significant delays in getting patients the medicines they rely on,” Fuchs said. “We’re focused on optimizing systems and driving toward peak performance using AI.”&lt;/p&gt;
&lt;p&gt;With the NVIDIA Isaac platform, Lilly can deploy intelligent robotics to modernize therapeutics production and support the workforce. NVIDIA Isaac Sim, for example, lets developers simulate and test AI-driven robotics solutions that can be adapted to pharma workflows.&lt;/p&gt;
&lt;p&gt;Plus, using NVIDIA NeMo software, Lilly can create AI agents that can reason, plan and act across digital and physical labs, with the goal of helping to generate new molecules, design treatments in silico and test them in vitro.&lt;/p&gt;
&lt;p&gt;“AI agents can work 24/7 and explore ideas that humans might not have the time or capacity to experiment with,” Rau said. “At the end of the day, it’s all about human learning — not machine learning. Machines are helping make humans smarter by stimulating new ideas for new molecules.”&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-image-section"&gt;
			&lt;img alt="“Machines are helping make humans smarter by stimulating new ideas for new molecules,” said Diogo Rau, executive vice president and chief information and digital officer at Lilly." class="full-width-layout__image" height="819" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/rau-pulled-quote-2-scaled.jpg" width="2048" /&gt;	
	&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;Fueling US Leadership and Economic Growth&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Lilly is already ranked the No. 1 most AI-ready pharma company, according to CB Insights, cited as having the highest AI innovation score and the most partnerships with AI-enabled drug development platforms in the industry.&lt;/p&gt;
&lt;p&gt;Now, the new AI factory positions Lilly as an AI-native U.S. and global pharma leader.&lt;/p&gt;
&lt;p&gt;The leap in computing power is immense.&lt;/p&gt;
&lt;p&gt;In 1992, Lilly’s Cray supercomputer was the pinnacle of scientific computing. Today, a single NVIDIA Blackwell Ultra GPU in the new AI factory contains the power of approximately 7 million Cray systems.&lt;/p&gt;
&lt;p&gt;And since the AI factory comprises 1,016 Blackwell Ultra GPUs, it delivers over 9,000 petaflops of AI performance. This means it can do over 9 quintillion math problems every second.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-image-section"&gt;
			&lt;img alt="Infographic that says: “1,016 NVIDIA Blackwell Ultra GPUs, 9,000 petaflops of AI performance, 9 quintillion math problems per second.”" class="full-width-layout__image" height="819" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/blackwell-ai-factory-infographic-scaled.jpg" width="2048" /&gt;	
	&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;The collaboration with NVIDIA is a cornerstone of Lilly’s innovation blueprint, building on its $50 billion commitment to expanding its U.S. manufacturing and R&amp;amp;D footprint. This commitment includes four new facilities and a proposed $4.5 billion lab in Indiana, called the Lilly Medicine Foundry, for advanced manufacturing and drug development.&lt;/p&gt;
&lt;p&gt;Combined, these initiatives are poised to create 13,000 high-wage manufacturing and construction jobs. The Medicine Foundry will also create approximately 500 new jobs, including for engineers, scientists, operations personnel and lab technicians.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Turning proprietary data into intelligence supports Lilly in helping patients while creating economic value and fueling U.S. leadership in advanced manufacturing and regulated industries.&lt;/p&gt;
&lt;p&gt;“We’re just scratching the surface of what’s possible with AI in medicine design and development,” Fuchs said. “This new AI factory and our collaborations across the whole biotech community will fundamentally change how we design, build and develop medicines.”&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-image-section"&gt;
			&lt;img alt="“We’re just scratching the surface of what’s possible with AI in medicine design and development,” said Thomas Fuchs, chief AI officer at Lilly." class="full-width-layout__image" height="819" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/fuchs-pulled-quote-2-scaled.jpg" width="2048" /&gt;	
	&lt;/div&gt;


&lt;/div&gt;
	&lt;div class="full-width-layout__news-section"&gt;
		&lt;p&gt;Related News&lt;/p&gt;

		&lt;div class="full-width-layout__news"&gt;
			
&lt;article class="full-width-layout__news-post-tile  post-86223 post type-post status-publish format-standard has-post-thumbnail hentry category-corporate category-enterprise category-auto category-generative-ai category-robotics tag-artificial-intelligence tag-gtc-2025 loop-item-1 for-pagenum-1" id="related-news-post-86223"&gt;
	
		&lt;img alt="alt" class="attachment-medium size-medium" height="640" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/keynoterecap-featuredimag-updated-960x640.jpg" width="960" /&gt;	

	
		NVIDIA GTC Washington, DC: Live Updates on What’s Next in AI	

	&lt;div class="full-width-layout__news-post-excerpt	light" id="related-news-post-desc-86223"&gt;
		Monday, Oct. 27, 12:30 p.m. ET How Medium-Sized Cities Are Tackling AI Readiness 🔗 A panel discussion today at GTC Washington, D.C., highlighted a public-private initiative to invigorate the economy...    		Read Article        &lt;span&gt;&lt;/span&gt;    	&lt;/div&gt;
&lt;/article&gt;

&lt;article class="full-width-layout__news-post-tile  post-86420 post type-post status-publish format-standard has-post-thumbnail hentry category-enterprise category-software tag-gtc-2025 tag-industrial-manufacturing tag-nvidia-nim tag-nvidia-physicsnemo tag-simulation-and-design loop-item-1 for-pagenum-1" id="related-news-post-86420"&gt;
	
		&lt;img alt="alt" class="attachment-medium size-medium" height="540" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/CAE-Image-960x540.jpg" width="960" /&gt;	

	
		NVIDIA AI Physics Transforms Aerospace and Automotive Design, Accelerating Engineering by 500x	

	&lt;div class="full-width-layout__news-post-excerpt	light" id="related-news-post-desc-86420"&gt;
		Leading technology companies in aerospace and automotive are accelerating their engineering design processes with the NVIDIA DoMINO NIM microservice, part of the NVIDIA PhysicsNeMo AI physics framework. By integrating GPU-accelerated...    		Read Article        &lt;span&gt;&lt;/span&gt;    	&lt;/div&gt;
&lt;/article&gt;

&lt;article class="full-width-layout__news-post-tile  post-86513 post type-post status-publish format-standard has-post-thumbnail hentry category-corporate category-enterprise category-generative-ai category-robotics tag-ai-factory tag-artificial-intelligence tag-economic-development tag-education tag-gtc-2025 tag-social-impact tag-sovereign-ai loop-item-1 for-pagenum-1" id="related-news-post-86513"&gt;
	
		&lt;img alt="alt" class="attachment-medium size-medium" height="640" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/DSCF7830_V2-1-960x640.jpg" width="960" /&gt;	

	
		Fueling Economic Development Across the US: How NVIDIA Is Empowering States, Municipalities and Universities to Drive Innovation	

	&lt;div class="full-width-layout__news-post-excerpt	light" id="related-news-post-desc-86513"&gt;
		To democratize access to AI technology nationwide, AI education and deployment can’t be limited to a few urban tech hubs — it must reach every community, university and state. That’s...    		Read Article        &lt;span&gt;&lt;/span&gt;    	&lt;/div&gt;
&lt;/article&gt;

&lt;article class="full-width-layout__news-post-tile  post-86383 post type-post status-publish format-standard has-post-thumbnail hentry category-enterprise category-hardware tag-artificial-intelligence tag-deep-learning-institute tag-digital-twin tag-education tag-gtc-2025 tag-isaac tag-jetson tag-nvidia-dgx tag-omniverse tag-public-sector tag-scientific-visualization tag-simulation-and-design loop-item-1 for-pagenum-1" id="related-news-post-86383"&gt;
	
		&lt;img alt="alt" class="attachment-medium size-medium" height="510" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/gtc25-corp-blog-dgx-gb300-1280x680-1-960x510.jpg" width="960" /&gt;	

	
		NVIDIA, NPS Commission the Navy’s AI Flagship for Training Tomorrow’s Leaders	

	&lt;div class="full-width-layout__news-post-excerpt	light" id="related-news-post-desc-86383"&gt;
		Along the Pacific Ocean in Monterey, California, the Naval Postgraduate School (NPS) is making a splash all the way to Washington, D.C.: It’s using artificial intelligence to solve operational challenges...    		Read Article        &lt;span&gt;&lt;/span&gt;    	&lt;/div&gt;
&lt;/article&gt;
		&lt;/div&gt;
	&lt;/div&gt;
		&lt;/div&gt;
	


&lt;!-- #colophon --&gt;

&lt;/div&gt;&lt;!-- #page --&gt;


&lt;!-- #has-highlight-and-share --&gt;		&lt;svg class="hidden" height="0" width="0" xmlns="http://www.w3.org/2000/svg"&gt;
			
				&lt;g&gt;&lt;path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z" fill="currentColor"&gt;&lt;/g&gt;
			
			
				&lt;path d="M279.14 288l14.22-92.66h-88.91v-60.13c0-25.35 12.42-50.06 52.24-50.06h40.42V6.26S260.43 0 225.36 0c-73.22 0-121.08 44.38-121.08 124.72v70.62H22.89V288h81.39v224h100.17V288z" fill="currentColor"&gt;
			
			
				&lt;path d="M256 8C118.941 8 8 118.919 8 256c0 137.059 110.919 248 248 248 48.154 0 95.342-14.14 135.408-40.223 12.005-7.815 14.625-24.288 5.552-35.372l-10.177-12.433c-7.671-9.371-21.179-11.667-31.373-5.129C325.92 429.757 291.314 440 256 440c-101.458 0-184-82.542-184-184S154.542 72 256 72c100.139 0 184 57.619 184 160 0 38.786-21.093 79.742-58.17 83.693-17.349-.454-16.91-12.857-13.476-30.024l23.433-121.11C394.653 149.75 383.308 136 368.225 136h-44.981a13.518 13.518 0 0 0-13.432 11.993l-.01.092c-14.697-17.901-40.448-21.775-59.971-21.775-74.58 0-137.831 62.234-137.831 151.46 0 65.303 36.785 105.87 96 105.87 26.984 0 57.369-15.637 74.991-38.333 9.522 34.104 40.613 34.103 70.71 34.103C462.609 379.41 504 307.798 504 232 504 95.653 394.023 8 256 8zm-21.68 304.43c-22.249 0-36.07-15.623-36.07-40.771 0-44.993 30.779-72.729 58.63-72.729 22.292 0 35.601 15.241 35.601 40.77 0 45.061-33.875 72.73-58.161 72.73z" fill="currentColor"&gt;
			
			
				&lt;path d="M100.28 448H7.4V148.9h92.88zM53.79 108.1C24.09 108.1 0 83.5 0 53.8a53.79 53.79 0 0 1 107.58 0c0 29.7-24.1 54.3-53.79 54.3zM447.9 448h-92.68V302.4c0-34.7-.7-79.2-48.29-79.2-48.29 0-55.69 37.7-55.69 76.7V448h-92.78V148.9h89.08v40.8h1.3c12.4-23.5 42.69-48.3 87.88-48.3 94 0 111.28 61.9 111.28 142.3V448z" fill="currentColor"&gt;
			
			
				&lt;path d="M162.7 210c-1.8 3.3-25.2 44.4-70.1 123.5-4.9 8.3-10.8 12.5-17.7 12.5H9.8c-7.7 0-12.1-7.5-8.5-14.4l69-121.3c.2 0 .2-.1 0-.3l-43.9-75.6c-4.3-7.8.3-14.1 8.5-14.1H100c7.3 0 13.3 4.1 18 12.2l44.7 77.5zM382.6 46.1l-144 253v.3L330.2 466c3.9 7.1.2 14.1-8.5 14.1h-65.2c-7.6 0-13.6-4-18-12.2l-92.4-168.5c3.3-5.8 51.5-90.8 144.8-255.2 4.6-8.1 10.4-12.2 17.5-12.2h65.7c8 0 12.3 6.7 8.5 14.1z" fill="currentColor"&gt;
			
			
				&lt;path d="M380.9 97.1C339 55.1 283.2 32 223.9 32c-122.4 0-222 99.6-222 222 0 39.1 10.2 77.3 29.6 111L0 480l117.7-30.9c32.4 17.7 68.9 27 106.1 27h.1c122.3 0 224.1-99.6 224.1-222 0-59.3-25.2-115-67.1-157zm-157 341.6c-33.2 0-65.7-8.9-94-25.7l-6.7-4-69.8 18.3L72 359.2l-4.4-7c-18.5-29.4-28.2-63.3-28.2-98.2 0-101.7 82.8-184.5 184.6-184.5 49.3 0 95.6 19.2 130.4 54.1 34.8 34.9 56.2 81.2 56.1 130.5 0 101.8-84.9 184.6-186.6 184.6zm101.2-138.2c-5.5-2.8-32.8-16.2-37.9-18-5.1-1.9-8.8-2.8-12.5 2.8-3.7 5.6-14.3 18-17.6 21.8-3.2 3.7-6.5 4.2-12 1.4-32.6-16.3-54-29.1-75.5-66-5.7-9.8 5.7-9.1 16.3-30.3 1.8-3.7.9-6.9-.5-9.7-1.4-2.8-12.5-30.1-17.1-41.2-4.5-10.8-9.1-9.3-12.5-9.5-3.2-.2-6.9-.2-10.6-.2-3.7 0-9.7 1.4-14.8 6.9-5.1 5.6-19.4 19-19.4 46.3 0 27.3 19.9 53.7 22.6 57.4 2.8 3.7 39.1 59.7 94.8 83.8 35.2 15.2 49 16.5 66.6 13.9 10.7-1.6 32.8-13.4 37.4-26.4 4.6-13 4.6-24.1 3.2-26.4-1.3-2.5-5-3.9-10.5-6.6z" fill="currentColor"&gt;
			
			
				&lt;path d="M320 448v40c0 13.255-10.745 24-24 24H24c-13.255 0-24-10.745-24-24V120c0-13.255 10.745-24 24-24h72v296c0 30.879 25.121 56 56 56h168zm0-344V0H152c-13.255 0-24 10.745-24 24v368c0 13.255 10.745 24 24 24h272c13.255 0 24-10.745 24-24V128H344c-13.2 0-24-10.8-24-24zm120.971-31.029L375.029 7.029A24 24 0 0 0 358.059 0H352v96h96v-6.059a24 24 0 0 0-7.029-16.97z" fill="currentColor"&gt;
			
			
				&lt;path d="M352 320c-22.608 0-43.387 7.819-59.79 20.895l-102.486-64.054a96.551 96.551 0 0 0 0-41.683l102.486-64.054C308.613 184.181 329.392 192 352 192c53.019 0 96-42.981 96-96S405.019 0 352 0s-96 42.981-96 96c0 7.158.79 14.13 2.276 20.841L155.79 180.895C139.387 167.819 118.608 160 96 160c-53.019 0-96 42.981-96 96s42.981 96 96 96c22.608 0 43.387-7.819 59.79-20.895l102.486 64.054A96.301 96.301 0 0 0 256 416c0 53.019 42.981 96 96 96s96-42.981 96-96-42.981-96-96-96z" fill="currentColor"&gt;
			
			
				&lt;path d="M440.3 203.5c-15 0-28.2 6.2-37.9 15.9-35.7-24.7-83.8-40.6-137.1-42.3L293 52.3l88.2 19.8c0 21.6 17.6 39.2 39.2 39.2 22 0 39.7-18.1 39.7-39.7s-17.6-39.7-39.7-39.7c-15.4 0-28.7 9.3-35.3 22l-97.4-21.6c-4.9-1.3-9.7 2.2-11 7.1L246.3 177c-52.9 2.2-100.5 18.1-136.3 42.8-9.7-10.1-23.4-16.3-38.4-16.3-55.6 0-73.8 74.6-22.9 100.1-1.8 7.9-2.6 16.3-2.6 24.7 0 83.8 94.4 151.7 210.3 151.7 116.4 0 210.8-67.9 210.8-151.7 0-8.4-.9-17.2-3.1-25.1 49.9-25.6 31.5-99.7-23.8-99.7zM129.4 308.9c0-22 17.6-39.7 39.7-39.7 21.6 0 39.2 17.6 39.2 39.7 0 21.6-17.6 39.2-39.2 39.2-22 .1-39.7-17.6-39.7-39.2zm214.3 93.5c-36.4 36.4-139.1 36.4-175.5 0-4-3.5-4-9.7 0-13.7 3.5-3.5 9.7-3.5 13.2 0 27.8 28.5 120 29 149 0 3.5-3.5 9.7-3.5 13.2 0 4.1 4 4.1 10.2.1 13.7zm-.8-54.2c-21.6 0-39.2-17.6-39.2-39.2 0-22 17.6-39.7 39.2-39.7 22 0 39.7 17.6 39.7 39.7-.1 21.5-17.7 39.2-39.7 39.2z" fill="currentColor"&gt;
			
			
				&lt;path d="M446.7 98.6l-67.6 318.8c-5.1 22.5-18.4 28.1-37.3 17.5l-103-75.9-49.7 47.8c-5.5 5.5-10.1 10.1-20.7 10.1l7.4-104.9 190.9-172.5c8.3-7.4-1.8-11.5-12.9-4.1L117.8 284 16.2 252.2c-22.1-6.9-22.5-22.1 4.6-32.7L418.2 66.4c18.4-6.9 34.5 4.1 28.5 32.2z" fill="currentColor"&gt;
			
			
				&lt;g&gt;
					&lt;path d="M97.2800192,3.739673 L100.160021,15.3787704 C88.8306631,18.1647705 77.9879854,22.6484879 68.0000023,28.6777391 L61.8399988,18.3985363 C72.8467373,11.7537029 84.7951803,6.81153332 97.2800192,3.739673 Z M158.720055,3.739673 L155.840053,15.3787704 C167.169411,18.1647705 178.012089,22.6484879 188.000072,28.6777391 L194.200075,18.3985363 C183.180932,11.7499974 171.218739,6.80771878 158.720055,3.739673 L158.720055,3.739673 Z M18.3999736,61.8351679 C11.7546212,72.8410466 6.81206547,84.7885562 3.73996516,97.2724198 L15.3799719,100.152197 C18.1661896,88.8237238 22.6502573,77.981893 28.6799796,67.9946902 L18.3999736,61.8351679 Z M11.9999699,127.990038 C11.9961044,122.172725 12.4306685,116.363392 13.2999707,110.611385 L1.43996383,108.811525 C-0.479938607,121.525138 -0.479938607,134.454937 1.43996383,147.168551 L13.2999707,145.36869 C12.4306685,139.616684 11.9961044,133.807351 11.9999699,127.990038 L11.9999699,127.990038 Z M194.160075,237.581539 L188.000072,227.302336 C178.024494,233.327885 167.195565,237.811494 155.880053,240.601305 L158.760055,252.240403 C171.231048,249.164732 183.165742,244.222671 194.160075,237.581539 L194.160075,237.581539 Z M244.000104,127.990038 C244.00397,133.807351 243.569406,139.616684 242.700103,145.36869 L254.56011,147.168551 C256.480013,134.454937 256.480013,121.525138 254.56011,108.811525 L242.700103,110.611385 C243.569406,116.363392 244.00397,122.172725 244.000104,127.990038 Z M252.260109,158.707656 L240.620102,155.827879 C237.833884,167.156352 233.349817,177.998183 227.320094,187.985385 L237.6001,194.184905 C244.249159,183.166622 249.191823,171.205364 252.260109,158.707656 L252.260109,158.707656 Z M145.380047,242.701142 C133.858209,244.43447 122.141865,244.43447 110.620027,242.701142 L108.820026,254.560223 C121.534632,256.479975 134.465442,256.479975 147.180048,254.560223 L145.380047,242.701142 Z M221.380091,196.804701 C214.461479,206.174141 206.175877,214.452354 196.800077,221.362797 L203.920081,231.022048 C214.262958,223.418011 223.404944,214.303705 231.040097,203.984145 L221.380091,196.804701 Z M196.800077,34.6172785 C206.177345,41.5338058 214.463023,49.8188367 221.380091,59.1953726 L231.040097,51.9959309 C223.429284,41.6822474 214.31457,32.5682452 204.000081,24.9580276 L196.800077,34.6172785 Z M34.619983,59.1953726 C41.5370506,49.8188367 49.8227288,41.5338058 59.1999972,34.6172785 L51.9999931,24.9580276 C41.6855038,32.5682452 32.5707896,41.6822474 24.9599774,51.9959309 L34.619983,59.1953726 Z M237.6001,61.8351679 L227.320094,67.9946902 C233.346114,77.969489 237.830073,88.7975718 240.620102,100.1122 L252.260109,97.2324229 C249.184198,84.7624043 244.241751,72.8286423 237.6001,61.8351679 L237.6001,61.8351679 Z M110.620027,13.2989317 C122.141865,11.5656035 133.858209,11.5656035 145.380047,13.2989317 L147.180048,1.43985134 C134.465442,-0.479901112 121.534632,-0.479901112 108.820026,1.43985134 L110.620027,13.2989317 Z M40.7799866,234.201801 L15.9999722,239.981353 L21.7799756,215.203275 L10.0999688,212.463487 L4.3199655,237.241566 C3.3734444,241.28318 4.58320332,245.526897 7.51859925,248.462064 C10.4539952,251.39723 14.6980441,252.606895 18.7399738,251.660448 L43.4999881,245.980888 L40.7799866,234.201801 Z M12.5999703,201.764317 L24.279977,204.484106 L28.2799793,187.305438 C22.4496684,177.507146 18.1025197,166.899584 15.3799719,155.827879 L3.73996516,158.707656 C6.34937618,169.311891 10.3154147,179.535405 15.539972,189.125297 L12.5999703,201.764317 Z M68.6000027,227.762301 L51.4199927,231.761991 L54.1399943,243.441085 L66.7800016,240.501313 C76.3706428,245.725462 86.5949557,249.691191 97.2000192,252.300398 L100.080021,240.6613 C89.0307035,237.906432 78.4495684,233.532789 68.6800027,227.682307 L68.6000027,227.762301 Z M128.000037,23.9980665 C90.1565244,24.0177003 55.3105242,44.590631 37.01511,77.715217 C18.7196958,110.839803 19.8628631,151.287212 39.9999861,183.325747 L29.9999803,225.982439 L72.660005,215.983214 C110.077932,239.548522 158.307237,236.876754 192.892851,209.322653 C227.478464,181.768552 240.856271,135.358391 226.242944,93.6248278 C211.629616,51.8912646 172.221191,23.9617202 128.000037,23.9980665 Z" fill="currentColor"&gt;
				&lt;/g&gt;
			
			
				&lt;g&gt;
					&lt;path d="M357.1,324.5c-24.1,15.3-57.2,21.4-79.1,23.6l18.4,18.1l67,67c24.5,25.1-15.4,64.4-40.2,40.2c-16.8-17-41.4-41.6-67-67.3
						l-67,67.2c-24.8,24.2-64.7-15.5-39.9-40.2c17-17,41.4-41.6,67-67l18.1-18.1c-21.6-2.3-55.3-8-79.6-23.6
						c-28.6-18.5-41.2-29.3-30.1-51.8c6.5-12.8,24.3-23.6,48-5c0,0,31.9,25.4,83.4,25.4s83.4-25.4,83.4-25.4c23.6-18.5,41.4-7.8,48,5
						C398.3,295.1,385.7,305.9,357.1,324.5L357.1,324.5z M142,145c0-63,51.2-114,114-114s114,51,114,114c0,62.7-51.2,113.7-114,113.7
						S142,207.7,142,145L142,145z M200,145c0,30.8,25.1,56,56,56s56-25.1,56-56c0-31.1-25.1-56.2-56-56.2S200,113.9,200,145z" fill="currentColor"&gt;
				&lt;/g&gt;
			
			
				&lt;g transform="translate(0,664)"&gt;
					&lt;path d="m 1073.3513,-606.40537 h 196.278 c 179.2103,0 221.8795,42.66915 221.8795,221.8795 v 196.27799 c 0,179.2103512 -42.6692,221.879451 -221.8795,221.879451 h -196.278 c -179.21038,0 -221.87951,-42.6691298 -221.87951,-221.879451 v -196.27801 c 0,-179.21035 42.66913,-221.87946 221.87951,-221.87948 z" fill="currentColor"&gt;
					&lt;path d="m 1375.0576,-393.98425 c 2.9513,-9.7072 0,-16.85429 -14.1342,-16.85429 h -46.6693 c -11.8763,0 -17.3521,6.16927 -20.3212,12.97854 0,0 -23.7347,56.82106 -57.3544,93.74763 -10.8806,10.66728 -15.8232,14.08081 -21.7613,14.08081 -2.969,0 -7.2715,-3.39577 -7.2715,-13.12075 v -90.83194 c 0,-11.66288 -3.4491,-16.85429 -13.3341,-16.85429 h -73.3553 c -7.4138,0 -11.8763,5.40476 -11.8763,10.54286 0,11.0406 16.8188,13.60078 18.5433,44.67814 v 67.52388 c 0,14.80973 -2.7202,17.49433 -8.6583,17.49433 -15.8231,0 -54.3143,-57.08773 -77.16,-122.40705 -4.4447,-12.71185 -8.9427,-17.83214 -20.8723,-17.83214 h -46.68718 c -13.3341,0 -16.0009,6.16925 -16.0009,12.97852 0,12.12515 15.8232,72.35973 73.69318,152.02656 38.58,54.40315 92.8942,83.89819 142.3726,83.89819 29.6729,0 33.3353,-6.54262 33.3353,-17.83216 v -41.12238 c 0,-13.10297 2.809,-15.71646 12.214,-15.71646 6.9338,0 18.7922,3.41353 46.4916,29.63728 31.6463,31.09512 36.8555,45.03372 54.6698,45.03372 h 46.6694 c 13.3341,0 20.0189,-6.54262 16.1787,-19.46781 -4.2313,-12.88962 -19.3433,-31.57515 -39.38,-53.74532 -10.8807,-12.62294 -27.2016,-26.22375 -32.1441,-33.03302 -6.9338,-8.72941 -4.9603,-12.62294 0,-20.39227 0,0 56.8566,-78.68897 62.7947,-105.41058 z" fill="currentColor"&gt;
					&lt;path d="m 567.69877,-429.06912 c 3.15618,-10.38133 0,-18.0247 -15.11579,-18.0247 h -49.91013 c -12.70096,0 -18.55706,6.59763 -21.73232,13.87977 0,0 -25.38286,60.76685 -61.33724,100.25768 -11.63627,11.40806 -16.92197,15.05863 -23.27242,15.05863 -3.17519,0 -7.77644,-3.63156 -7.77644,-14.0319 v -97.13948 c 0,-12.47278 -3.68869,-18.0247 -14.26014,-18.0247 h -78.44923 c -7.92857,0 -12.70097,5.78005 -12.70097,11.27491 0,11.80736 17.98666,14.54527 19.83094,47.78071 v 72.21293 c 0,15.83815 -2.9091,18.70918 -9.25948,18.70918 -16.92197,0 -58.08598,-61.05206 -82.51817,-130.90731 -4.75337,-13.59458 -9.56381,-19.07042 -22.32175,-19.07042 h -49.92915 c -14.26014,0 -17.11213,6.59763 -17.11213,13.87977 0,12.96714 16.92197,77.38454 78.81059,162.58363 41.25909,58.18101 99.34506,89.72424 152.25931,89.72424 31.73343,0 35.65018,-6.99691 35.65018,-19.07043 v -43.978 c 0,-14.01288 3.00405,-16.80786 13.0622,-16.80786 7.41521,0 20.09716,3.65057 49.71998,31.69536 33.84387,33.25443 39.41486,48.16093 58.46622,48.16093 h 49.91026 c 14.26,0 21.40913,-6.99691 17.30216,-20.81966 -4.5252,-13.78473 -20.68653,-33.76783 -42.11468,-57.47752 -11.63621,-13.49953 -29.09043,-28.04479 -34.37631,-35.32694 -7.41508,-9.33557 -5.30458,-13.4995 0,-21.80835 0,0 60.80491,-84.15334 67.15549,-112.73048 z" fill="currentColor"&gt;
				&lt;/g&gt;
			
			&lt;path d="M309.8 480.3c-13.6 14.5-50 31.7-97.4 31.7-120.8 0-147-88.8-147-140.6v-144H17.9c-5.5 0-10-4.5-10-10v-68c0-7.2 4.5-13.6 11.3-16 62-21.8 81.5-76 84.3-117.1.8-11 6.5-16.3 16.1-16.3h70.9c5.5 0 10 4.5 10 10v115.2h83c5.5 0 10 4.4 10 9.9v81.7c0 5.5-4.5 10-10 10h-83.4V360c0 34.2 23.7 53.6 68 35.8 4.8-1.9 9-3.2 12.7-2.2 3.5.9 5.8 3.4 7.4 7.9l22 64.3c1.8 5 3.3 10.6-.4 14.5z" fill="currentColor"&gt;
			&lt;path d="M512 208L320 384H288V288H208c-61.9 0-112 50.1-112 112c0 48 32 80 32 80s-128-48-128-176c0-97.2 78.8-176 176-176H288V32h32L512 208z" fill="currentColor"&gt;
			&lt;path d="M309.8 480.3c-13.6 14.5-50 31.7-97.4 31.7-120.8 0-147-88.8-147-140.6v-144H17.9c-5.5 0-10-4.5-10-10v-68c0-7.2 4.5-13.6 11.3-16 62-21.8 81.5-76 84.3-117.1.8-11 6.5-16.3 16.1-16.3h70.9c5.5 0 10 4.5 10 10v115.2h83c5.5 0 10 4.4 10 9.9v81.7c0 5.5-4.5 10-10 10h-83.4V360c0 34.2 23.7 53.6 68 35.8 4.8-1.9 9-3.2 12.7-2.2 3.5.9 5.8 3.4 7.4 7.9l22 64.3c1.8 5 3.3 10.6-.4 14.5z" fill="currentColor"&gt;
			&lt;path d="M433 179.1c0-97.2-63.7-125.7-63.7-125.7-62.5-28.7-228.6-28.4-290.5 0 0 0-63.7 28.5-63.7 125.7 0 115.7-6.6 259.4 105.6 289.1 40.5 10.7 75.3 13 103.3 11.4 50.8-2.8 79.3-18.1 79.3-18.1l-1.7-36.9s-36.3 11.4-77.1 10.1c-40.4-1.4-83-4.4-89.6-54a102.5 102.5 0 0 1 -.9-13.9c85.6 20.9 158.7 9.1 178.8 6.7 56.1-6.7 105-41.3 111.2-72.9 9.8-49.8 9-121.5 9-121.5zm-75.1 125.2h-46.6v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.3V197c0-58.5-64-56.6-64-6.9v114.2H90.2c0-122.1-5.2-147.9 18.4-175 25.9-28.9 79.8-30.8 103.8 6.1l11.6 19.5 11.6-19.5c24.1-37.1 78.1-34.8 103.8-6.1 23.7 27.3 18.4 53 18.4 175z" fill="currentColor"&gt;
			
				&lt;path d="M331.5 235.7c2.2 .9 4.2 1.9 6.3 2.8c29.2 14.1 50.6 35.2 61.8 61.4c15.7 36.5 17.2 95.8-30.3 143.2c-36.2 36.2-80.3 52.5-142.6 53h-.3c-70.2-.5-124.1-24.1-160.4-70.2c-32.3-41-48.9-98.1-49.5-169.6V256v-.2C17 184.3 33.6 127.2 65.9 86.2C102.2 40.1 156.2 16.5 226.4 16h.3c70.3 .5 124.9 24 162.3 69.9c18.4 22.7 32 50 40.6 81.7l-40.4 10.8c-7.1-25.8-17.8-47.8-32.2-65.4c-29.2-35.8-73-54.2-130.5-54.6c-57 .5-100.1 18.8-128.2 54.4C72.1 146.1 58.5 194.3 58 256c.5 61.7 14.1 109.9 40.3 143.3c28 35.6 71.2 53.9 128.2 54.4c51.4-.4 85.4-12.6 113.7-40.9c32.3-32.2 31.7-71.8 21.4-95.9c-6.1-14.2-17.1-26-31.9-34.9c-3.7 26.9-11.8 48.3-24.7 64.8c-17.1 21.8-41.4 33.6-72.7 35.3c-23.6 1.3-46.3-4.4-63.9-16c-20.8-13.8-33-34.8-34.3-59.3c-2.5-48.3 35.7-83 95.2-86.4c21.1-1.2 40.9-.3 59.2 2.8c-2.4-14.8-7.3-26.6-14.6-35.2c-10-11.7-25.6-17.7-46.2-17.8H227c-16.6 0-39 4.6-53.3 26.3l-34.4-23.6c19.2-29.1 50.3-45.1 87.8-45.1h.8c62.6 .4 99.9 39.5 103.7 107.7l-.2 .2zm-156 68.8c1.3 25.1 28.4 36.8 54.6 35.3c25.6-1.4 54.6-11.4 59.5-73.2c-13.2-2.9-27.8-4.4-43.4-4.4c-4.8 0-9.6 .1-14.4 .4c-42.9 2.4-57.2 23.2-56.2 41.8l-.1 .1z" fill="currentColor"&gt;
			
			
				&lt;path d="M407.8 294.7c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3zM288 227.1C261.9 176.4 190.9 81.9 124.9 35.3C61.6-9.4 37.5-1.7 21.6 5.5C3.3 13.8 0 41.9 0 58.4S9.1 194 15 213.9c19.5 65.7 89.1 87.9 153.2 80.7c3.3-.5 6.6-.9 10-1.4c-3.3 .5-6.6 1-10 1.4C74.3 308.6-9.1 342.8 100.3 464.5C220.6 589.1 265.1 437.8 288 361.1c22.9 76.7 49.2 222.5 185.6 103.4c102.4-103.4 28.1-156-65.8-169.9c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3c64.1 7.1 133.6-15.1 153.2-80.7C566.9 194 576 75 576 58.4s-3.3-44.7-21.6-52.9c-15.8-7.1-40-14.9-103.2 29.8C385.1 81.9 314.1 176.4 288 227.1z" fill="currentColor"&gt;
			
			
				&lt;path d="M204 6.5C101.4 6.5 0 74.9 0 185.6 0 256 39.6 296 63.6 296c9.9 0 15.6-27.6 15.6-35.4 0-9.3-23.7-29.1-23.7-67.8 0-80.4 61.2-137.4 140.4-137.4 68.1 0 118.5 38.7 118.5 109.8 0 53.1-21.3 152.7-90.3 152.7-24.9 0-46.2-18-46.2-43.8 0-37.8 26.4-74.4 26.4-113.4 0-66.2-93.9-54.2-93.9 25.8 0 16.8 2.1 35.4 9.6 50.7-13.8 59.4-42 147.9-42 209.1 0 18.9 2.7 37.5 4.5 56.4 3.4 3.8 1.7 3.4 6.9 1.5 50.4-69 48.6-82.5 71.4-172.8 12.3 23.4 44.1 36 69.3 36 106.2 0 153.9-103.5 153.9-196.8C384 71.3 298.2 6.5 204 6.5z" fill="currentColor"&gt;
			
		&lt;/svg&gt;
		&lt;div id="has-mastodon-prompt"&gt;
			&lt;h3&gt;Share on Mastodon&lt;/h3&gt;
			
		&lt;/div&gt;</description><content:encoded>&lt;!-- OneTrust Cookies Consent Notice start for nvidia.com --&gt;


&lt;!-- OneTrust Cookies Consent Notice end for nvidia.com --&gt;


	
	
	
	
	
	

	

	
	
	


	&lt;!-- This site is optimized with the Yoast SEO Premium plugin v26.2 (Yoast SEO v26.2) - https://yoast.com/wordpress/plugins/seo/ --&gt;
	Lilly Deploys World’s Largest, Most Powerful AI Factory for Drug Discovery Using NVIDIA Blackwell-Based DGX SuperPOD | NVIDIA Blog
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	&lt;!-- / Yoast SEO Premium plugin. --&gt;






































&lt;!-- Stream WordPress user activity plugin v4.1.1 --&gt;


	
				&lt;!-- Hotjar Tracking Code for NVIDIA --&gt;
			
			


				
				



		
		

&lt;div class="hfeed site" id="page"&gt;
	Skip to content

	&lt;!-- #masthead --&gt;
		
		&lt;div class="full-width-layout light"&gt;
		

		
&lt;div class="full-width-layout__hero light"&gt;
	&lt;div class="full-width-layout__hero-content light"&gt;
		&lt;div class="full-width-layout__hero-content__inner light"&gt;
			

							&lt;p&gt;
					Built with over 1,000 NVIDIA Blackwell Ultra GPUs, the AI factory will support modern scientific research using foundation models, as well as physical and agentic AI.				&lt;/p&gt;
			
			
		&lt;/div&gt;
	&lt;/div&gt;

	&lt;p&gt;
		&lt;video class="full-width-layout__hero-video js-responsive-video" loop="loop"&gt;Your browser does not support the video tag.&lt;/video&gt;	&lt;/p&gt;

	&lt;/div&gt;

	
	
		&lt;div class="full-width-layout__sections"&gt;
&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Lilly, a pioneer in medicine, is deploying the largest, most powerful AI factory wholly owned and operated by a pharmaceutical company — the world’s first NVIDIA DGX SuperPOD with DGX B300 systems.&lt;/p&gt;
&lt;p&gt;Built with 1,016 NVIDIA Blackwell Ultra GPUs and announced today at NVIDIA GTC Washington, D.C., the AI factory is poised to compress drug discovery timelines and enable accelerated breakthroughs in genomics, personalized medicine and molecular design at industrial scale.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-video-section"&gt;
	&lt;video class="full-width-layout__video js-responsive-video" loop="loop"&gt;Your browser does not support the video tag.&lt;/video&gt;
&lt;p&gt;
	
			&lt;span class="full-width-layout__media-credits"&gt;
			Video courtesy of Lilly.		&lt;/span&gt;
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;The AI factory will be used to train large scale biomedical foundation and frontier models for drug discovery and development. Select models will be made available on Lilly TuneLab — an AI and machine learning platform that provides biotech companies with access to drug discovery models built on $1 billion worth of Lilly’s proprietary data.&lt;/p&gt;
&lt;p&gt;TuneLab is now the first drug discovery platform to offer Lilly models and NVIDIA Clara open foundation models for healthcare and life sciences, further expanding AI access for the biotech ecosystem.&lt;/p&gt;
&lt;p&gt;TuneLab uses a federated learning infrastructure built on NVIDIA FLARE, which enables biotechs to tap into powerful proprietary AI models while keeping their own data private and separate from other users. As more companies participate, the models improve, benefitting all users.&lt;/p&gt;
&lt;p&gt;“Our foundation models are spawning new possibilities for our chemists, helping them uncover new motifs and configurations of atoms that were out of reach with traditional methods,” said Thomas Fuchs, chief AI officer at Lilly. “AI gives us the means to accelerate progress toward both developing and delivering better, more personalized and targeted medicines.”&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-image-section"&gt;
			&lt;img alt="“AI gives us the means to accelerate progress toward both developing and delivering better, more personalized and targeted medicines,” said Thomas Fuchs, chief AI officer at Lilly." class="full-width-layout__image" height="819" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/fuchs-pulled-quote-1-scaled.jpg" width="2048" /&gt;	
	&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;The AI factory is powered by NVIDIA’s full-stack AI factory architecture offered with NVIDIA DGX SuperPOD — including accelerated computing, NVIDIA Spectrum-X Ethernet networking and optimized AI software. This provides a secure, scalable, purpose-built platform for the highly regulated healthcare and life sciences industries.&lt;/p&gt;
&lt;p&gt;NVIDIA Mission Control software allows Lilly to manage its DGX SuperPOD, orchestrate workloads, monitor performance and automate AI operations securely and efficiently across more than 1,000 GPUs.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;AI Applied Across Drug Discovery, Precision Medicine&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Lilly scientists can use the AI factory to analyze entire genome sequences, predict patient outcomes and explore multitudes of biochemical possibilities.&lt;/p&gt;
&lt;p&gt;“In our 150 years, Lilly has always closely connected science and technology,” said Diogo Rau, executive vice president and chief information and digital officer at Lilly. “If you focus only on science, you’re just going to have an experiment, a paper or a treatment — but if you bring together science and technology, like the accelerated compute we’re getting through this AI factory, you can reach a massive scale to bring the treatment to millions of people.”&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-image-section"&gt;
			&lt;img alt="“If you bring together science and technology … you can reach a massive scale to bring the treatment to millions of people,” said Diogo Rau, executive vice president and chief information and digital officer at Lilly." class="full-width-layout__image" height="819" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/rau-pulled-quote-1-scaled.jpg" width="2048" /&gt;	
	&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Using the NVIDIA BioNeMo platform, Lilly can train AI models that combine the learnings of millions of past experiments with public research to generate and test new antibodies, nanobodies and novel molecules with greater accuracy and speed than ever.&lt;/p&gt;
&lt;p&gt;The AI factory can also be applied to help discover new biomarkers and design gene therapies for degenerative conditions, Fuchs said.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__full-width-video-section"&gt;
			&lt;video class="full-width-layout__video" loop="loop"&gt;
							&lt;source src="https://blogs.nvidia.com/wp-content/uploads/2025/10/lilly-scientists.mp4" type="video/mp4" /&gt;
						&lt;p&gt;Your browser does not support HTML5 video.&lt;/p&gt;
		&lt;/video&gt;
	
	
&lt;p&gt;
	
			&lt;span class="full-width-layout__media-credits"&gt;
			Video courtesy of Lilly.		&lt;/span&gt;
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;And the impact extends beyond drug discovery.&lt;/p&gt;
&lt;p&gt;Using the AI factory, the company can build large language models that accelerate clinical trials by helping with medical writing and other internal workflows.&lt;/p&gt;
&lt;p&gt;And combined with the open-source MONAI framework, the AI factory can accelerate Lilly’s imaging-based research in precision medicine. Deep learning on massive imaging datasets can reduce processing time from months to days, allowing for quicker, more personalized treatments.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;Research and Biomanufacturing With Physical and Agentic AI&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;The AI factory is poised to enhance Lilly’s capacity to manufacture high-demand medications and strengthen supply chain reliability, including through the use of physical AI.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-video-section"&gt;
	&lt;video class="full-width-layout__video js-responsive-video" loop="loop"&gt;Your browser does not support the video tag.&lt;/video&gt;
&lt;p&gt;
	
			&lt;span class="full-width-layout__media-credits"&gt;
			Video courtesy of Lilly		&lt;/span&gt;
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;With technologies like the NVIDIA Omniverse platform and NVIDIA RTX PRO Servers, the pharma company can create digital twins of its manufacturing lines to model, stress-test and optimize entire supply chains before making physical changes in the real world.&lt;/p&gt;
&lt;p&gt;Digital twins can increase production safety while accelerating quality assurance and other biomanufacturing operations, ultimately getting medicines to patients faster.&lt;/p&gt;
&lt;p&gt;Lilly also uses robots in its factories for quality inspection and transport of goods — such as medicines and treatment components like injectors — optimizing operations and keeping production lines up and running.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-video-section"&gt;
	&lt;video class="full-width-layout__video js-responsive-video" loop="loop"&gt;Your browser does not support the video tag.&lt;/video&gt;
&lt;p&gt;
	
			&lt;span class="full-width-layout__media-credits"&gt;
			Video courtesy of Lilly.		&lt;/span&gt;
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;“Machinery downtime can mean significant delays in getting patients the medicines they rely on,” Fuchs said. “We’re focused on optimizing systems and driving toward peak performance using AI.”&lt;/p&gt;
&lt;p&gt;With the NVIDIA Isaac platform, Lilly can deploy intelligent robotics to modernize therapeutics production and support the workforce. NVIDIA Isaac Sim, for example, lets developers simulate and test AI-driven robotics solutions that can be adapted to pharma workflows.&lt;/p&gt;
&lt;p&gt;Plus, using NVIDIA NeMo software, Lilly can create AI agents that can reason, plan and act across digital and physical labs, with the goal of helping to generate new molecules, design treatments in silico and test them in vitro.&lt;/p&gt;
&lt;p&gt;“AI agents can work 24/7 and explore ideas that humans might not have the time or capacity to experiment with,” Rau said. “At the end of the day, it’s all about human learning — not machine learning. Machines are helping make humans smarter by stimulating new ideas for new molecules.”&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-image-section"&gt;
			&lt;img alt="“Machines are helping make humans smarter by stimulating new ideas for new molecules,” said Diogo Rau, executive vice president and chief information and digital officer at Lilly." class="full-width-layout__image" height="819" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/rau-pulled-quote-2-scaled.jpg" width="2048" /&gt;	
	&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;Fueling US Leadership and Economic Growth&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Lilly is already ranked the No. 1 most AI-ready pharma company, according to CB Insights, cited as having the highest AI innovation score and the most partnerships with AI-enabled drug development platforms in the industry.&lt;/p&gt;
&lt;p&gt;Now, the new AI factory positions Lilly as an AI-native U.S. and global pharma leader.&lt;/p&gt;
&lt;p&gt;The leap in computing power is immense.&lt;/p&gt;
&lt;p&gt;In 1992, Lilly’s Cray supercomputer was the pinnacle of scientific computing. Today, a single NVIDIA Blackwell Ultra GPU in the new AI factory contains the power of approximately 7 million Cray systems.&lt;/p&gt;
&lt;p&gt;And since the AI factory comprises 1,016 Blackwell Ultra GPUs, it delivers over 9,000 petaflops of AI performance. This means it can do over 9 quintillion math problems every second.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-image-section"&gt;
			&lt;img alt="Infographic that says: “1,016 NVIDIA Blackwell Ultra GPUs, 9,000 petaflops of AI performance, 9 quintillion math problems per second.”" class="full-width-layout__image" height="819" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/blackwell-ai-factory-infographic-scaled.jpg" width="2048" /&gt;	
	&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;The collaboration with NVIDIA is a cornerstone of Lilly’s innovation blueprint, building on its $50 billion commitment to expanding its U.S. manufacturing and R&amp;amp;D footprint. This commitment includes four new facilities and a proposed $4.5 billion lab in Indiana, called the Lilly Medicine Foundry, for advanced manufacturing and drug development.&lt;/p&gt;
&lt;p&gt;Combined, these initiatives are poised to create 13,000 high-wage manufacturing and construction jobs. The Medicine Foundry will also create approximately 500 new jobs, including for engineers, scientists, operations personnel and lab technicians.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Turning proprietary data into intelligence supports Lilly in helping patients while creating economic value and fueling U.S. leadership in advanced manufacturing and regulated industries.&lt;/p&gt;
&lt;p&gt;“We’re just scratching the surface of what’s possible with AI in medicine design and development,” Fuchs said. “This new AI factory and our collaborations across the whole biotech community will fundamentally change how we design, build and develop medicines.”&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-image-section"&gt;
			&lt;img alt="“We’re just scratching the surface of what’s possible with AI in medicine design and development,” said Thomas Fuchs, chief AI officer at Lilly." class="full-width-layout__image" height="819" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/fuchs-pulled-quote-2-scaled.jpg" width="2048" /&gt;	
	&lt;/div&gt;


&lt;/div&gt;
	&lt;div class="full-width-layout__news-section"&gt;
		&lt;p&gt;Related News&lt;/p&gt;

		&lt;div class="full-width-layout__news"&gt;
			
&lt;article class="full-width-layout__news-post-tile  post-86223 post type-post status-publish format-standard has-post-thumbnail hentry category-corporate category-enterprise category-auto category-generative-ai category-robotics tag-artificial-intelligence tag-gtc-2025 loop-item-1 for-pagenum-1" id="related-news-post-86223"&gt;
	
		&lt;img alt="alt" class="attachment-medium size-medium" height="640" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/keynoterecap-featuredimag-updated-960x640.jpg" width="960" /&gt;	

	
		NVIDIA GTC Washington, DC: Live Updates on What’s Next in AI	

	&lt;div class="full-width-layout__news-post-excerpt	light" id="related-news-post-desc-86223"&gt;
		Monday, Oct. 27, 12:30 p.m. ET How Medium-Sized Cities Are Tackling AI Readiness 🔗 A panel discussion today at GTC Washington, D.C., highlighted a public-private initiative to invigorate the economy...    		Read Article        &lt;span&gt;&lt;/span&gt;    	&lt;/div&gt;
&lt;/article&gt;

&lt;article class="full-width-layout__news-post-tile  post-86420 post type-post status-publish format-standard has-post-thumbnail hentry category-enterprise category-software tag-gtc-2025 tag-industrial-manufacturing tag-nvidia-nim tag-nvidia-physicsnemo tag-simulation-and-design loop-item-1 for-pagenum-1" id="related-news-post-86420"&gt;
	
		&lt;img alt="alt" class="attachment-medium size-medium" height="540" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/CAE-Image-960x540.jpg" width="960" /&gt;	

	
		NVIDIA AI Physics Transforms Aerospace and Automotive Design, Accelerating Engineering by 500x	

	&lt;div class="full-width-layout__news-post-excerpt	light" id="related-news-post-desc-86420"&gt;
		Leading technology companies in aerospace and automotive are accelerating their engineering design processes with the NVIDIA DoMINO NIM microservice, part of the NVIDIA PhysicsNeMo AI physics framework. By integrating GPU-accelerated...    		Read Article        &lt;span&gt;&lt;/span&gt;    	&lt;/div&gt;
&lt;/article&gt;

&lt;article class="full-width-layout__news-post-tile  post-86513 post type-post status-publish format-standard has-post-thumbnail hentry category-corporate category-enterprise category-generative-ai category-robotics tag-ai-factory tag-artificial-intelligence tag-economic-development tag-education tag-gtc-2025 tag-social-impact tag-sovereign-ai loop-item-1 for-pagenum-1" id="related-news-post-86513"&gt;
	
		&lt;img alt="alt" class="attachment-medium size-medium" height="640" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/DSCF7830_V2-1-960x640.jpg" width="960" /&gt;	

	
		Fueling Economic Development Across the US: How NVIDIA Is Empowering States, Municipalities and Universities to Drive Innovation	

	&lt;div class="full-width-layout__news-post-excerpt	light" id="related-news-post-desc-86513"&gt;
		To democratize access to AI technology nationwide, AI education and deployment can’t be limited to a few urban tech hubs — it must reach every community, university and state. That’s...    		Read Article        &lt;span&gt;&lt;/span&gt;    	&lt;/div&gt;
&lt;/article&gt;

&lt;article class="full-width-layout__news-post-tile  post-86383 post type-post status-publish format-standard has-post-thumbnail hentry category-enterprise category-hardware tag-artificial-intelligence tag-deep-learning-institute tag-digital-twin tag-education tag-gtc-2025 tag-isaac tag-jetson tag-nvidia-dgx tag-omniverse tag-public-sector tag-scientific-visualization tag-simulation-and-design loop-item-1 for-pagenum-1" id="related-news-post-86383"&gt;
	
		&lt;img alt="alt" class="attachment-medium size-medium" height="510" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/gtc25-corp-blog-dgx-gb300-1280x680-1-960x510.jpg" width="960" /&gt;	

	
		NVIDIA, NPS Commission the Navy’s AI Flagship for Training Tomorrow’s Leaders	

	&lt;div class="full-width-layout__news-post-excerpt	light" id="related-news-post-desc-86383"&gt;
		Along the Pacific Ocean in Monterey, California, the Naval Postgraduate School (NPS) is making a splash all the way to Washington, D.C.: It’s using artificial intelligence to solve operational challenges...    		Read Article        &lt;span&gt;&lt;/span&gt;    	&lt;/div&gt;
&lt;/article&gt;
		&lt;/div&gt;
	&lt;/div&gt;
		&lt;/div&gt;
	


&lt;!-- #colophon --&gt;

&lt;/div&gt;&lt;!-- #page --&gt;


&lt;!-- #has-highlight-and-share --&gt;		&lt;svg class="hidden" height="0" width="0" xmlns="http://www.w3.org/2000/svg"&gt;
			
				&lt;g&gt;&lt;path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z" fill="currentColor"&gt;&lt;/g&gt;
			
			
				&lt;path d="M279.14 288l14.22-92.66h-88.91v-60.13c0-25.35 12.42-50.06 52.24-50.06h40.42V6.26S260.43 0 225.36 0c-73.22 0-121.08 44.38-121.08 124.72v70.62H22.89V288h81.39v224h100.17V288z" fill="currentColor"&gt;
			
			
				&lt;path d="M256 8C118.941 8 8 118.919 8 256c0 137.059 110.919 248 248 248 48.154 0 95.342-14.14 135.408-40.223 12.005-7.815 14.625-24.288 5.552-35.372l-10.177-12.433c-7.671-9.371-21.179-11.667-31.373-5.129C325.92 429.757 291.314 440 256 440c-101.458 0-184-82.542-184-184S154.542 72 256 72c100.139 0 184 57.619 184 160 0 38.786-21.093 79.742-58.17 83.693-17.349-.454-16.91-12.857-13.476-30.024l23.433-121.11C394.653 149.75 383.308 136 368.225 136h-44.981a13.518 13.518 0 0 0-13.432 11.993l-.01.092c-14.697-17.901-40.448-21.775-59.971-21.775-74.58 0-137.831 62.234-137.831 151.46 0 65.303 36.785 105.87 96 105.87 26.984 0 57.369-15.637 74.991-38.333 9.522 34.104 40.613 34.103 70.71 34.103C462.609 379.41 504 307.798 504 232 504 95.653 394.023 8 256 8zm-21.68 304.43c-22.249 0-36.07-15.623-36.07-40.771 0-44.993 30.779-72.729 58.63-72.729 22.292 0 35.601 15.241 35.601 40.77 0 45.061-33.875 72.73-58.161 72.73z" fill="currentColor"&gt;
			
			
				&lt;path d="M100.28 448H7.4V148.9h92.88zM53.79 108.1C24.09 108.1 0 83.5 0 53.8a53.79 53.79 0 0 1 107.58 0c0 29.7-24.1 54.3-53.79 54.3zM447.9 448h-92.68V302.4c0-34.7-.7-79.2-48.29-79.2-48.29 0-55.69 37.7-55.69 76.7V448h-92.78V148.9h89.08v40.8h1.3c12.4-23.5 42.69-48.3 87.88-48.3 94 0 111.28 61.9 111.28 142.3V448z" fill="currentColor"&gt;
			
			
				&lt;path d="M162.7 210c-1.8 3.3-25.2 44.4-70.1 123.5-4.9 8.3-10.8 12.5-17.7 12.5H9.8c-7.7 0-12.1-7.5-8.5-14.4l69-121.3c.2 0 .2-.1 0-.3l-43.9-75.6c-4.3-7.8.3-14.1 8.5-14.1H100c7.3 0 13.3 4.1 18 12.2l44.7 77.5zM382.6 46.1l-144 253v.3L330.2 466c3.9 7.1.2 14.1-8.5 14.1h-65.2c-7.6 0-13.6-4-18-12.2l-92.4-168.5c3.3-5.8 51.5-90.8 144.8-255.2 4.6-8.1 10.4-12.2 17.5-12.2h65.7c8 0 12.3 6.7 8.5 14.1z" fill="currentColor"&gt;
			
			
				&lt;path d="M380.9 97.1C339 55.1 283.2 32 223.9 32c-122.4 0-222 99.6-222 222 0 39.1 10.2 77.3 29.6 111L0 480l117.7-30.9c32.4 17.7 68.9 27 106.1 27h.1c122.3 0 224.1-99.6 224.1-222 0-59.3-25.2-115-67.1-157zm-157 341.6c-33.2 0-65.7-8.9-94-25.7l-6.7-4-69.8 18.3L72 359.2l-4.4-7c-18.5-29.4-28.2-63.3-28.2-98.2 0-101.7 82.8-184.5 184.6-184.5 49.3 0 95.6 19.2 130.4 54.1 34.8 34.9 56.2 81.2 56.1 130.5 0 101.8-84.9 184.6-186.6 184.6zm101.2-138.2c-5.5-2.8-32.8-16.2-37.9-18-5.1-1.9-8.8-2.8-12.5 2.8-3.7 5.6-14.3 18-17.6 21.8-3.2 3.7-6.5 4.2-12 1.4-32.6-16.3-54-29.1-75.5-66-5.7-9.8 5.7-9.1 16.3-30.3 1.8-3.7.9-6.9-.5-9.7-1.4-2.8-12.5-30.1-17.1-41.2-4.5-10.8-9.1-9.3-12.5-9.5-3.2-.2-6.9-.2-10.6-.2-3.7 0-9.7 1.4-14.8 6.9-5.1 5.6-19.4 19-19.4 46.3 0 27.3 19.9 53.7 22.6 57.4 2.8 3.7 39.1 59.7 94.8 83.8 35.2 15.2 49 16.5 66.6 13.9 10.7-1.6 32.8-13.4 37.4-26.4 4.6-13 4.6-24.1 3.2-26.4-1.3-2.5-5-3.9-10.5-6.6z" fill="currentColor"&gt;
			
			
				&lt;path d="M320 448v40c0 13.255-10.745 24-24 24H24c-13.255 0-24-10.745-24-24V120c0-13.255 10.745-24 24-24h72v296c0 30.879 25.121 56 56 56h168zm0-344V0H152c-13.255 0-24 10.745-24 24v368c0 13.255 10.745 24 24 24h272c13.255 0 24-10.745 24-24V128H344c-13.2 0-24-10.8-24-24zm120.971-31.029L375.029 7.029A24 24 0 0 0 358.059 0H352v96h96v-6.059a24 24 0 0 0-7.029-16.97z" fill="currentColor"&gt;
			
			
				&lt;path d="M352 320c-22.608 0-43.387 7.819-59.79 20.895l-102.486-64.054a96.551 96.551 0 0 0 0-41.683l102.486-64.054C308.613 184.181 329.392 192 352 192c53.019 0 96-42.981 96-96S405.019 0 352 0s-96 42.981-96 96c0 7.158.79 14.13 2.276 20.841L155.79 180.895C139.387 167.819 118.608 160 96 160c-53.019 0-96 42.981-96 96s42.981 96 96 96c22.608 0 43.387-7.819 59.79-20.895l102.486 64.054A96.301 96.301 0 0 0 256 416c0 53.019 42.981 96 96 96s96-42.981 96-96-42.981-96-96-96z" fill="currentColor"&gt;
			
			
				&lt;path d="M440.3 203.5c-15 0-28.2 6.2-37.9 15.9-35.7-24.7-83.8-40.6-137.1-42.3L293 52.3l88.2 19.8c0 21.6 17.6 39.2 39.2 39.2 22 0 39.7-18.1 39.7-39.7s-17.6-39.7-39.7-39.7c-15.4 0-28.7 9.3-35.3 22l-97.4-21.6c-4.9-1.3-9.7 2.2-11 7.1L246.3 177c-52.9 2.2-100.5 18.1-136.3 42.8-9.7-10.1-23.4-16.3-38.4-16.3-55.6 0-73.8 74.6-22.9 100.1-1.8 7.9-2.6 16.3-2.6 24.7 0 83.8 94.4 151.7 210.3 151.7 116.4 0 210.8-67.9 210.8-151.7 0-8.4-.9-17.2-3.1-25.1 49.9-25.6 31.5-99.7-23.8-99.7zM129.4 308.9c0-22 17.6-39.7 39.7-39.7 21.6 0 39.2 17.6 39.2 39.7 0 21.6-17.6 39.2-39.2 39.2-22 .1-39.7-17.6-39.7-39.2zm214.3 93.5c-36.4 36.4-139.1 36.4-175.5 0-4-3.5-4-9.7 0-13.7 3.5-3.5 9.7-3.5 13.2 0 27.8 28.5 120 29 149 0 3.5-3.5 9.7-3.5 13.2 0 4.1 4 4.1 10.2.1 13.7zm-.8-54.2c-21.6 0-39.2-17.6-39.2-39.2 0-22 17.6-39.7 39.2-39.7 22 0 39.7 17.6 39.7 39.7-.1 21.5-17.7 39.2-39.7 39.2z" fill="currentColor"&gt;
			
			
				&lt;path d="M446.7 98.6l-67.6 318.8c-5.1 22.5-18.4 28.1-37.3 17.5l-103-75.9-49.7 47.8c-5.5 5.5-10.1 10.1-20.7 10.1l7.4-104.9 190.9-172.5c8.3-7.4-1.8-11.5-12.9-4.1L117.8 284 16.2 252.2c-22.1-6.9-22.5-22.1 4.6-32.7L418.2 66.4c18.4-6.9 34.5 4.1 28.5 32.2z" fill="currentColor"&gt;
			
			
				&lt;g&gt;
					&lt;path d="M97.2800192,3.739673 L100.160021,15.3787704 C88.8306631,18.1647705 77.9879854,22.6484879 68.0000023,28.6777391 L61.8399988,18.3985363 C72.8467373,11.7537029 84.7951803,6.81153332 97.2800192,3.739673 Z M158.720055,3.739673 L155.840053,15.3787704 C167.169411,18.1647705 178.012089,22.6484879 188.000072,28.6777391 L194.200075,18.3985363 C183.180932,11.7499974 171.218739,6.80771878 158.720055,3.739673 L158.720055,3.739673 Z M18.3999736,61.8351679 C11.7546212,72.8410466 6.81206547,84.7885562 3.73996516,97.2724198 L15.3799719,100.152197 C18.1661896,88.8237238 22.6502573,77.981893 28.6799796,67.9946902 L18.3999736,61.8351679 Z M11.9999699,127.990038 C11.9961044,122.172725 12.4306685,116.363392 13.2999707,110.611385 L1.43996383,108.811525 C-0.479938607,121.525138 -0.479938607,134.454937 1.43996383,147.168551 L13.2999707,145.36869 C12.4306685,139.616684 11.9961044,133.807351 11.9999699,127.990038 L11.9999699,127.990038 Z M194.160075,237.581539 L188.000072,227.302336 C178.024494,233.327885 167.195565,237.811494 155.880053,240.601305 L158.760055,252.240403 C171.231048,249.164732 183.165742,244.222671 194.160075,237.581539 L194.160075,237.581539 Z M244.000104,127.990038 C244.00397,133.807351 243.569406,139.616684 242.700103,145.36869 L254.56011,147.168551 C256.480013,134.454937 256.480013,121.525138 254.56011,108.811525 L242.700103,110.611385 C243.569406,116.363392 244.00397,122.172725 244.000104,127.990038 Z M252.260109,158.707656 L240.620102,155.827879 C237.833884,167.156352 233.349817,177.998183 227.320094,187.985385 L237.6001,194.184905 C244.249159,183.166622 249.191823,171.205364 252.260109,158.707656 L252.260109,158.707656 Z M145.380047,242.701142 C133.858209,244.43447 122.141865,244.43447 110.620027,242.701142 L108.820026,254.560223 C121.534632,256.479975 134.465442,256.479975 147.180048,254.560223 L145.380047,242.701142 Z M221.380091,196.804701 C214.461479,206.174141 206.175877,214.452354 196.800077,221.362797 L203.920081,231.022048 C214.262958,223.418011 223.404944,214.303705 231.040097,203.984145 L221.380091,196.804701 Z M196.800077,34.6172785 C206.177345,41.5338058 214.463023,49.8188367 221.380091,59.1953726 L231.040097,51.9959309 C223.429284,41.6822474 214.31457,32.5682452 204.000081,24.9580276 L196.800077,34.6172785 Z M34.619983,59.1953726 C41.5370506,49.8188367 49.8227288,41.5338058 59.1999972,34.6172785 L51.9999931,24.9580276 C41.6855038,32.5682452 32.5707896,41.6822474 24.9599774,51.9959309 L34.619983,59.1953726 Z M237.6001,61.8351679 L227.320094,67.9946902 C233.346114,77.969489 237.830073,88.7975718 240.620102,100.1122 L252.260109,97.2324229 C249.184198,84.7624043 244.241751,72.8286423 237.6001,61.8351679 L237.6001,61.8351679 Z M110.620027,13.2989317 C122.141865,11.5656035 133.858209,11.5656035 145.380047,13.2989317 L147.180048,1.43985134 C134.465442,-0.479901112 121.534632,-0.479901112 108.820026,1.43985134 L110.620027,13.2989317 Z M40.7799866,234.201801 L15.9999722,239.981353 L21.7799756,215.203275 L10.0999688,212.463487 L4.3199655,237.241566 C3.3734444,241.28318 4.58320332,245.526897 7.51859925,248.462064 C10.4539952,251.39723 14.6980441,252.606895 18.7399738,251.660448 L43.4999881,245.980888 L40.7799866,234.201801 Z M12.5999703,201.764317 L24.279977,204.484106 L28.2799793,187.305438 C22.4496684,177.507146 18.1025197,166.899584 15.3799719,155.827879 L3.73996516,158.707656 C6.34937618,169.311891 10.3154147,179.535405 15.539972,189.125297 L12.5999703,201.764317 Z M68.6000027,227.762301 L51.4199927,231.761991 L54.1399943,243.441085 L66.7800016,240.501313 C76.3706428,245.725462 86.5949557,249.691191 97.2000192,252.300398 L100.080021,240.6613 C89.0307035,237.906432 78.4495684,233.532789 68.6800027,227.682307 L68.6000027,227.762301 Z M128.000037,23.9980665 C90.1565244,24.0177003 55.3105242,44.590631 37.01511,77.715217 C18.7196958,110.839803 19.8628631,151.287212 39.9999861,183.325747 L29.9999803,225.982439 L72.660005,215.983214 C110.077932,239.548522 158.307237,236.876754 192.892851,209.322653 C227.478464,181.768552 240.856271,135.358391 226.242944,93.6248278 C211.629616,51.8912646 172.221191,23.9617202 128.000037,23.9980665 Z" fill="currentColor"&gt;
				&lt;/g&gt;
			
			
				&lt;g&gt;
					&lt;path d="M357.1,324.5c-24.1,15.3-57.2,21.4-79.1,23.6l18.4,18.1l67,67c24.5,25.1-15.4,64.4-40.2,40.2c-16.8-17-41.4-41.6-67-67.3
						l-67,67.2c-24.8,24.2-64.7-15.5-39.9-40.2c17-17,41.4-41.6,67-67l18.1-18.1c-21.6-2.3-55.3-8-79.6-23.6
						c-28.6-18.5-41.2-29.3-30.1-51.8c6.5-12.8,24.3-23.6,48-5c0,0,31.9,25.4,83.4,25.4s83.4-25.4,83.4-25.4c23.6-18.5,41.4-7.8,48,5
						C398.3,295.1,385.7,305.9,357.1,324.5L357.1,324.5z M142,145c0-63,51.2-114,114-114s114,51,114,114c0,62.7-51.2,113.7-114,113.7
						S142,207.7,142,145L142,145z M200,145c0,30.8,25.1,56,56,56s56-25.1,56-56c0-31.1-25.1-56.2-56-56.2S200,113.9,200,145z" fill="currentColor"&gt;
				&lt;/g&gt;
			
			
				&lt;g transform="translate(0,664)"&gt;
					&lt;path d="m 1073.3513,-606.40537 h 196.278 c 179.2103,0 221.8795,42.66915 221.8795,221.8795 v 196.27799 c 0,179.2103512 -42.6692,221.879451 -221.8795,221.879451 h -196.278 c -179.21038,0 -221.87951,-42.6691298 -221.87951,-221.879451 v -196.27801 c 0,-179.21035 42.66913,-221.87946 221.87951,-221.87948 z" fill="currentColor"&gt;
					&lt;path d="m 1375.0576,-393.98425 c 2.9513,-9.7072 0,-16.85429 -14.1342,-16.85429 h -46.6693 c -11.8763,0 -17.3521,6.16927 -20.3212,12.97854 0,0 -23.7347,56.82106 -57.3544,93.74763 -10.8806,10.66728 -15.8232,14.08081 -21.7613,14.08081 -2.969,0 -7.2715,-3.39577 -7.2715,-13.12075 v -90.83194 c 0,-11.66288 -3.4491,-16.85429 -13.3341,-16.85429 h -73.3553 c -7.4138,0 -11.8763,5.40476 -11.8763,10.54286 0,11.0406 16.8188,13.60078 18.5433,44.67814 v 67.52388 c 0,14.80973 -2.7202,17.49433 -8.6583,17.49433 -15.8231,0 -54.3143,-57.08773 -77.16,-122.40705 -4.4447,-12.71185 -8.9427,-17.83214 -20.8723,-17.83214 h -46.68718 c -13.3341,0 -16.0009,6.16925 -16.0009,12.97852 0,12.12515 15.8232,72.35973 73.69318,152.02656 38.58,54.40315 92.8942,83.89819 142.3726,83.89819 29.6729,0 33.3353,-6.54262 33.3353,-17.83216 v -41.12238 c 0,-13.10297 2.809,-15.71646 12.214,-15.71646 6.9338,0 18.7922,3.41353 46.4916,29.63728 31.6463,31.09512 36.8555,45.03372 54.6698,45.03372 h 46.6694 c 13.3341,0 20.0189,-6.54262 16.1787,-19.46781 -4.2313,-12.88962 -19.3433,-31.57515 -39.38,-53.74532 -10.8807,-12.62294 -27.2016,-26.22375 -32.1441,-33.03302 -6.9338,-8.72941 -4.9603,-12.62294 0,-20.39227 0,0 56.8566,-78.68897 62.7947,-105.41058 z" fill="currentColor"&gt;
					&lt;path d="m 567.69877,-429.06912 c 3.15618,-10.38133 0,-18.0247 -15.11579,-18.0247 h -49.91013 c -12.70096,0 -18.55706,6.59763 -21.73232,13.87977 0,0 -25.38286,60.76685 -61.33724,100.25768 -11.63627,11.40806 -16.92197,15.05863 -23.27242,15.05863 -3.17519,0 -7.77644,-3.63156 -7.77644,-14.0319 v -97.13948 c 0,-12.47278 -3.68869,-18.0247 -14.26014,-18.0247 h -78.44923 c -7.92857,0 -12.70097,5.78005 -12.70097,11.27491 0,11.80736 17.98666,14.54527 19.83094,47.78071 v 72.21293 c 0,15.83815 -2.9091,18.70918 -9.25948,18.70918 -16.92197,0 -58.08598,-61.05206 -82.51817,-130.90731 -4.75337,-13.59458 -9.56381,-19.07042 -22.32175,-19.07042 h -49.92915 c -14.26014,0 -17.11213,6.59763 -17.11213,13.87977 0,12.96714 16.92197,77.38454 78.81059,162.58363 41.25909,58.18101 99.34506,89.72424 152.25931,89.72424 31.73343,0 35.65018,-6.99691 35.65018,-19.07043 v -43.978 c 0,-14.01288 3.00405,-16.80786 13.0622,-16.80786 7.41521,0 20.09716,3.65057 49.71998,31.69536 33.84387,33.25443 39.41486,48.16093 58.46622,48.16093 h 49.91026 c 14.26,0 21.40913,-6.99691 17.30216,-20.81966 -4.5252,-13.78473 -20.68653,-33.76783 -42.11468,-57.47752 -11.63621,-13.49953 -29.09043,-28.04479 -34.37631,-35.32694 -7.41508,-9.33557 -5.30458,-13.4995 0,-21.80835 0,0 60.80491,-84.15334 67.15549,-112.73048 z" fill="currentColor"&gt;
				&lt;/g&gt;
			
			&lt;path d="M309.8 480.3c-13.6 14.5-50 31.7-97.4 31.7-120.8 0-147-88.8-147-140.6v-144H17.9c-5.5 0-10-4.5-10-10v-68c0-7.2 4.5-13.6 11.3-16 62-21.8 81.5-76 84.3-117.1.8-11 6.5-16.3 16.1-16.3h70.9c5.5 0 10 4.5 10 10v115.2h83c5.5 0 10 4.4 10 9.9v81.7c0 5.5-4.5 10-10 10h-83.4V360c0 34.2 23.7 53.6 68 35.8 4.8-1.9 9-3.2 12.7-2.2 3.5.9 5.8 3.4 7.4 7.9l22 64.3c1.8 5 3.3 10.6-.4 14.5z" fill="currentColor"&gt;
			&lt;path d="M512 208L320 384H288V288H208c-61.9 0-112 50.1-112 112c0 48 32 80 32 80s-128-48-128-176c0-97.2 78.8-176 176-176H288V32h32L512 208z" fill="currentColor"&gt;
			&lt;path d="M309.8 480.3c-13.6 14.5-50 31.7-97.4 31.7-120.8 0-147-88.8-147-140.6v-144H17.9c-5.5 0-10-4.5-10-10v-68c0-7.2 4.5-13.6 11.3-16 62-21.8 81.5-76 84.3-117.1.8-11 6.5-16.3 16.1-16.3h70.9c5.5 0 10 4.5 10 10v115.2h83c5.5 0 10 4.4 10 9.9v81.7c0 5.5-4.5 10-10 10h-83.4V360c0 34.2 23.7 53.6 68 35.8 4.8-1.9 9-3.2 12.7-2.2 3.5.9 5.8 3.4 7.4 7.9l22 64.3c1.8 5 3.3 10.6-.4 14.5z" fill="currentColor"&gt;
			&lt;path d="M433 179.1c0-97.2-63.7-125.7-63.7-125.7-62.5-28.7-228.6-28.4-290.5 0 0 0-63.7 28.5-63.7 125.7 0 115.7-6.6 259.4 105.6 289.1 40.5 10.7 75.3 13 103.3 11.4 50.8-2.8 79.3-18.1 79.3-18.1l-1.7-36.9s-36.3 11.4-77.1 10.1c-40.4-1.4-83-4.4-89.6-54a102.5 102.5 0 0 1 -.9-13.9c85.6 20.9 158.7 9.1 178.8 6.7 56.1-6.7 105-41.3 111.2-72.9 9.8-49.8 9-121.5 9-121.5zm-75.1 125.2h-46.6v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.3V197c0-58.5-64-56.6-64-6.9v114.2H90.2c0-122.1-5.2-147.9 18.4-175 25.9-28.9 79.8-30.8 103.8 6.1l11.6 19.5 11.6-19.5c24.1-37.1 78.1-34.8 103.8-6.1 23.7 27.3 18.4 53 18.4 175z" fill="currentColor"&gt;
			
				&lt;path d="M331.5 235.7c2.2 .9 4.2 1.9 6.3 2.8c29.2 14.1 50.6 35.2 61.8 61.4c15.7 36.5 17.2 95.8-30.3 143.2c-36.2 36.2-80.3 52.5-142.6 53h-.3c-70.2-.5-124.1-24.1-160.4-70.2c-32.3-41-48.9-98.1-49.5-169.6V256v-.2C17 184.3 33.6 127.2 65.9 86.2C102.2 40.1 156.2 16.5 226.4 16h.3c70.3 .5 124.9 24 162.3 69.9c18.4 22.7 32 50 40.6 81.7l-40.4 10.8c-7.1-25.8-17.8-47.8-32.2-65.4c-29.2-35.8-73-54.2-130.5-54.6c-57 .5-100.1 18.8-128.2 54.4C72.1 146.1 58.5 194.3 58 256c.5 61.7 14.1 109.9 40.3 143.3c28 35.6 71.2 53.9 128.2 54.4c51.4-.4 85.4-12.6 113.7-40.9c32.3-32.2 31.7-71.8 21.4-95.9c-6.1-14.2-17.1-26-31.9-34.9c-3.7 26.9-11.8 48.3-24.7 64.8c-17.1 21.8-41.4 33.6-72.7 35.3c-23.6 1.3-46.3-4.4-63.9-16c-20.8-13.8-33-34.8-34.3-59.3c-2.5-48.3 35.7-83 95.2-86.4c21.1-1.2 40.9-.3 59.2 2.8c-2.4-14.8-7.3-26.6-14.6-35.2c-10-11.7-25.6-17.7-46.2-17.8H227c-16.6 0-39 4.6-53.3 26.3l-34.4-23.6c19.2-29.1 50.3-45.1 87.8-45.1h.8c62.6 .4 99.9 39.5 103.7 107.7l-.2 .2zm-156 68.8c1.3 25.1 28.4 36.8 54.6 35.3c25.6-1.4 54.6-11.4 59.5-73.2c-13.2-2.9-27.8-4.4-43.4-4.4c-4.8 0-9.6 .1-14.4 .4c-42.9 2.4-57.2 23.2-56.2 41.8l-.1 .1z" fill="currentColor"&gt;
			
			
				&lt;path d="M407.8 294.7c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3zM288 227.1C261.9 176.4 190.9 81.9 124.9 35.3C61.6-9.4 37.5-1.7 21.6 5.5C3.3 13.8 0 41.9 0 58.4S9.1 194 15 213.9c19.5 65.7 89.1 87.9 153.2 80.7c3.3-.5 6.6-.9 10-1.4c-3.3 .5-6.6 1-10 1.4C74.3 308.6-9.1 342.8 100.3 464.5C220.6 589.1 265.1 437.8 288 361.1c22.9 76.7 49.2 222.5 185.6 103.4c102.4-103.4 28.1-156-65.8-169.9c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3c64.1 7.1 133.6-15.1 153.2-80.7C566.9 194 576 75 576 58.4s-3.3-44.7-21.6-52.9c-15.8-7.1-40-14.9-103.2 29.8C385.1 81.9 314.1 176.4 288 227.1z" fill="currentColor"&gt;
			
			
				&lt;path d="M204 6.5C101.4 6.5 0 74.9 0 185.6 0 256 39.6 296 63.6 296c9.9 0 15.6-27.6 15.6-35.4 0-9.3-23.7-29.1-23.7-67.8 0-80.4 61.2-137.4 140.4-137.4 68.1 0 118.5 38.7 118.5 109.8 0 53.1-21.3 152.7-90.3 152.7-24.9 0-46.2-18-46.2-43.8 0-37.8 26.4-74.4 26.4-113.4 0-66.2-93.9-54.2-93.9 25.8 0 16.8 2.1 35.4 9.6 50.7-13.8 59.4-42 147.9-42 209.1 0 18.9 2.7 37.5 4.5 56.4 3.4 3.8 1.7 3.4 6.9 1.5 50.4-69 48.6-82.5 71.4-172.8 12.3 23.4 44.1 36 69.3 36 106.2 0 153.9-103.5 153.9-196.8C384 71.3 298.2 6.5 204 6.5z" fill="currentColor"&gt;
			
		&lt;/svg&gt;
		&lt;div id="has-mastodon-prompt"&gt;
			&lt;h3&gt;Share on Mastodon&lt;/h3&gt;
			
		&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/lilly-ai-factory-nvidia-blackwell-dgx-superpod/</guid><pubDate>Tue, 28 Oct 2025 18:00:02 +0000</pubDate></item><item><title>[NEW] NVIDIA Open Sources Aerial Software to Accelerate AI-Native 6G (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/open-source-aerial-ai-native-6g/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;NVIDIA is delivering the telecom industry a major boost in open-source software for building AI-native 5G and 6G networks.&lt;/p&gt;
&lt;p&gt;NVIDIA Aerial software will soon be released as open source, making it available on a variety of NVIDIA platforms, including on NVIDIA DGX Spark. With open-source software and a powerful and accessible supercomputer to run it all, AI-RAN and wireless researchers can go from rapid prototyping to product development in hours versus months or years.&lt;/p&gt;
&lt;p&gt;That means next-generation AI-native mobile networks can be built at the pace of AI for open, widespread collaboration, unlike previous generations where innovation was constrained by access to licensed software and proprietary hardware.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="alignnone size-medium wp-image-86577" height="541" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/DGXSpark-960x541.jpg" width="960" /&gt;&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Rewriting the Wireless Playbook With Open Source&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Open source is reshaping industries by breaking down barriers to innovation and accelerating collaboration, enabling breakthroughs that would be impossible under closed, proprietary systems. NVIDIA is a leading contributor to open source, including for the telecom industry. Previously open-sourced NVIDIA Sionna software has already surpassed 200,000 downloads and 500 citations.&lt;/p&gt;
&lt;p&gt;Now, NVIDIA is open sourcing its Aerial software, including Aerial CUDA-Accelerated RAN, Aerial Omniverse Digital Twin (AODT) and the new Aerial Framework.&lt;/p&gt;
&lt;p&gt;These resources — previously limited to a small group — are expected to be available on GitHub under Apache 2.0 licensing starting this December, with AODT release in March 2026, empowering developers to build full-stack, AI-native 5G and 6G RAN solutions. They can experiment and build AI-native network solutions without restrictions, accelerating the transition from research to real-world deployment.&lt;/p&gt;
&lt;p&gt;The upcoming Aerial open-source release is packed with capabilities, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Aerial Framework for converting Python code into high-performance CUDA code to run on NVIDIA Aerial RAN computer platforms.&lt;/li&gt;
&lt;li&gt;AI-powered neural models, such as advanced channel estimation for significantly improving wireless performance.&lt;/li&gt;
&lt;li&gt;A dApp framework to provide third-party applications with access to real-time physical layer data through secure application programming interfaces. Developers can deploy AI-powered dApp algorithms that can modify RAN behavior in real time.&lt;/li&gt;
&lt;li&gt;Customizable pipelines with modules that developers can selectively modify or replace with their own code to build full-stack RAN software.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Such features have enabled the first made-in-America AI-native wireless stack, showcasing early 6G applications including spectrum agility and integrated sensing and communications.&lt;/p&gt;
&lt;p&gt;This move expands access to powerful CUDA-accelerated wireless software and boosts the global movement toward AI-native 5G and 6G solutions. It opens doors to developers beyond the telecom industry, making it easy for them to build new applications for mobile networks, including agentic and physical AI applications that need mission-critical performance.&lt;/p&gt;
&lt;p&gt;This shift amplifies U.S. leadership in open source and fundamentally rewrites the way the telecom industry innovates — sparking knowledge-sharing and an implementation-first approach at a global scale.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;DGX Spark: The Desktop Supercomputer for Wireless R&amp;amp;D&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;NVIDIA DGX Spark, the world’s smallest AI supercomputer, is now available for AI-native 5G and 6G research. It delivers the performance to run NVIDIA Aerial or Sionna software in a cost-effective small footprint. Whether procured through manufacturers or accessed via NVIDIA DGX Cloud, DGX Spark empowers teams to prototype complete wireless networks and continuously train and refine their AI models using real-world data gathered across diverse radio environments.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;The NVIDIA Sionna Research Kit&lt;/b&gt; now supports DGX Spark, in addition to NVIDIA Jetson AGX Orin, offering an AI-native 6G lab in a box for rapid prototyping. It brings together every component, from user equipment and antennas to radio systems and core networks, that developers need to research and validate AI/ML algorithms’ performance over the air — and to do so in one afternoon, from unboxing to setting a live 5G network. Researchers can test their algorithms anywhere with the ultraportable kit, instead of being confined to a lab.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;The NVIDIA Aerial Testbed&lt;/b&gt; now supports DGX Spark in addition to NVIDIA GH200 Grace Hopper Superchips, enabling over-the-air testing of CUDA-accelerated, full-stack 5G and 6G networks. Designed to accelerate commercial product development, it provides seamless integration between network digital twin and live deployment.&lt;/p&gt;
&lt;p&gt;Dell Technologies is introducing Dell Pro Max with GB10, a DGX Spark-based system designed to empower researchers and developers across a wide range of AI applications, including the demanding needs of global telecom research. The platform delivers proven performance for handling intensive 5G and 6G workloads, offering a stable and powerful environment for testing, simulation and validation while enabling researchers to tackle the complex challenges of 6G.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Collaborators Building AI-Native 6G on NVIDIA&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The NVIDIA AI Aerial portfolio — spanning accelerated computing platforms, software libraries and tools — gives developers the means to build, train, simulate and deploy full-stack AI-native RAN systems faster than ever.&lt;/p&gt;
&lt;p&gt;Thousands of wireless innovators around the world are already tapping into the NVIDIA AI Aerial portfolio for research and development, including leading U.S. institutions Northeastern University, Virginia Tech, Arizona State University and DeepSig, and researchers from WINSLab and LIDS at MIT, who are working on AI-driven breakthroughs that will define 6G technology and shape global standards.&lt;/p&gt;
&lt;p&gt;The AI-RAN Alliance is shaping the core architecture of AI-native wireless networks, bringing together over 100 telecom industry pioneers through work groups, labs, benchmarking and live demonstrations — many of which have been developed using NVIDIA AI Aerial.&lt;/p&gt;
&lt;p&gt;“With NVIDIA’s open-source Aerial software and DGX Spark, developers can create modular, software-defined wireless systems and experiment freely — from labs to live environments,” said Alex Jinsung Choi, chairman of the AI-RAN Alliance. “This is a critical enabler for fueling AI-RAN innovations that boost spectrum efficiency, enhance network performance and power new AI applications — at a pace the industry has never experienced.”&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;A New Chapter in Wireless Innovation for the AI Era&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;By breaking down barriers and inviting participation from developers far beyond traditional wireless, NVIDIA is catalyzing a wave of 5G and 6G collaboration that will shape national competitiveness and global standards.&lt;/p&gt;
&lt;p&gt;NVIDIA’s commitment to open access and global collaboration marks this as a pivotal milestone for the telecom industry, enabling a fully inclusive, software-defined and AI-powered future where innovation moves at the speed of AI.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Watch the &lt;/i&gt;&lt;i&gt;GTC Washington, D.C., keynote&lt;/i&gt;&lt;i&gt; from NVIDIA founder and CEO Jensen Huang and explore &lt;/i&gt;&lt;i&gt;sessions&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;See &lt;/i&gt;&lt;i&gt;notice&lt;/i&gt;&lt;i&gt; regarding software product information.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;NVIDIA is delivering the telecom industry a major boost in open-source software for building AI-native 5G and 6G networks.&lt;/p&gt;
&lt;p&gt;NVIDIA Aerial software will soon be released as open source, making it available on a variety of NVIDIA platforms, including on NVIDIA DGX Spark. With open-source software and a powerful and accessible supercomputer to run it all, AI-RAN and wireless researchers can go from rapid prototyping to product development in hours versus months or years.&lt;/p&gt;
&lt;p&gt;That means next-generation AI-native mobile networks can be built at the pace of AI for open, widespread collaboration, unlike previous generations where innovation was constrained by access to licensed software and proprietary hardware.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="alignnone size-medium wp-image-86577" height="541" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/DGXSpark-960x541.jpg" width="960" /&gt;&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Rewriting the Wireless Playbook With Open Source&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Open source is reshaping industries by breaking down barriers to innovation and accelerating collaboration, enabling breakthroughs that would be impossible under closed, proprietary systems. NVIDIA is a leading contributor to open source, including for the telecom industry. Previously open-sourced NVIDIA Sionna software has already surpassed 200,000 downloads and 500 citations.&lt;/p&gt;
&lt;p&gt;Now, NVIDIA is open sourcing its Aerial software, including Aerial CUDA-Accelerated RAN, Aerial Omniverse Digital Twin (AODT) and the new Aerial Framework.&lt;/p&gt;
&lt;p&gt;These resources — previously limited to a small group — are expected to be available on GitHub under Apache 2.0 licensing starting this December, with AODT release in March 2026, empowering developers to build full-stack, AI-native 5G and 6G RAN solutions. They can experiment and build AI-native network solutions without restrictions, accelerating the transition from research to real-world deployment.&lt;/p&gt;
&lt;p&gt;The upcoming Aerial open-source release is packed with capabilities, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Aerial Framework for converting Python code into high-performance CUDA code to run on NVIDIA Aerial RAN computer platforms.&lt;/li&gt;
&lt;li&gt;AI-powered neural models, such as advanced channel estimation for significantly improving wireless performance.&lt;/li&gt;
&lt;li&gt;A dApp framework to provide third-party applications with access to real-time physical layer data through secure application programming interfaces. Developers can deploy AI-powered dApp algorithms that can modify RAN behavior in real time.&lt;/li&gt;
&lt;li&gt;Customizable pipelines with modules that developers can selectively modify or replace with their own code to build full-stack RAN software.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Such features have enabled the first made-in-America AI-native wireless stack, showcasing early 6G applications including spectrum agility and integrated sensing and communications.&lt;/p&gt;
&lt;p&gt;This move expands access to powerful CUDA-accelerated wireless software and boosts the global movement toward AI-native 5G and 6G solutions. It opens doors to developers beyond the telecom industry, making it easy for them to build new applications for mobile networks, including agentic and physical AI applications that need mission-critical performance.&lt;/p&gt;
&lt;p&gt;This shift amplifies U.S. leadership in open source and fundamentally rewrites the way the telecom industry innovates — sparking knowledge-sharing and an implementation-first approach at a global scale.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;DGX Spark: The Desktop Supercomputer for Wireless R&amp;amp;D&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;NVIDIA DGX Spark, the world’s smallest AI supercomputer, is now available for AI-native 5G and 6G research. It delivers the performance to run NVIDIA Aerial or Sionna software in a cost-effective small footprint. Whether procured through manufacturers or accessed via NVIDIA DGX Cloud, DGX Spark empowers teams to prototype complete wireless networks and continuously train and refine their AI models using real-world data gathered across diverse radio environments.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;The NVIDIA Sionna Research Kit&lt;/b&gt; now supports DGX Spark, in addition to NVIDIA Jetson AGX Orin, offering an AI-native 6G lab in a box for rapid prototyping. It brings together every component, from user equipment and antennas to radio systems and core networks, that developers need to research and validate AI/ML algorithms’ performance over the air — and to do so in one afternoon, from unboxing to setting a live 5G network. Researchers can test their algorithms anywhere with the ultraportable kit, instead of being confined to a lab.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;The NVIDIA Aerial Testbed&lt;/b&gt; now supports DGX Spark in addition to NVIDIA GH200 Grace Hopper Superchips, enabling over-the-air testing of CUDA-accelerated, full-stack 5G and 6G networks. Designed to accelerate commercial product development, it provides seamless integration between network digital twin and live deployment.&lt;/p&gt;
&lt;p&gt;Dell Technologies is introducing Dell Pro Max with GB10, a DGX Spark-based system designed to empower researchers and developers across a wide range of AI applications, including the demanding needs of global telecom research. The platform delivers proven performance for handling intensive 5G and 6G workloads, offering a stable and powerful environment for testing, simulation and validation while enabling researchers to tackle the complex challenges of 6G.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Collaborators Building AI-Native 6G on NVIDIA&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The NVIDIA AI Aerial portfolio — spanning accelerated computing platforms, software libraries and tools — gives developers the means to build, train, simulate and deploy full-stack AI-native RAN systems faster than ever.&lt;/p&gt;
&lt;p&gt;Thousands of wireless innovators around the world are already tapping into the NVIDIA AI Aerial portfolio for research and development, including leading U.S. institutions Northeastern University, Virginia Tech, Arizona State University and DeepSig, and researchers from WINSLab and LIDS at MIT, who are working on AI-driven breakthroughs that will define 6G technology and shape global standards.&lt;/p&gt;
&lt;p&gt;The AI-RAN Alliance is shaping the core architecture of AI-native wireless networks, bringing together over 100 telecom industry pioneers through work groups, labs, benchmarking and live demonstrations — many of which have been developed using NVIDIA AI Aerial.&lt;/p&gt;
&lt;p&gt;“With NVIDIA’s open-source Aerial software and DGX Spark, developers can create modular, software-defined wireless systems and experiment freely — from labs to live environments,” said Alex Jinsung Choi, chairman of the AI-RAN Alliance. “This is a critical enabler for fueling AI-RAN innovations that boost spectrum efficiency, enhance network performance and power new AI applications — at a pace the industry has never experienced.”&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;A New Chapter in Wireless Innovation for the AI Era&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;By breaking down barriers and inviting participation from developers far beyond traditional wireless, NVIDIA is catalyzing a wave of 5G and 6G collaboration that will shape national competitiveness and global standards.&lt;/p&gt;
&lt;p&gt;NVIDIA’s commitment to open access and global collaboration marks this as a pivotal milestone for the telecom industry, enabling a fully inclusive, software-defined and AI-powered future where innovation moves at the speed of AI.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Watch the &lt;/i&gt;&lt;i&gt;GTC Washington, D.C., keynote&lt;/i&gt;&lt;i&gt; from NVIDIA founder and CEO Jensen Huang and explore &lt;/i&gt;&lt;i&gt;sessions&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;See &lt;/i&gt;&lt;i&gt;notice&lt;/i&gt;&lt;i&gt; regarding software product information.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/open-source-aerial-ai-native-6g/</guid><pubDate>Tue, 28 Oct 2025 18:00:10 +0000</pubDate></item><item><title>[NEW] NVIDIA and General Atomics Advance Commercial Fusion Energy (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/nvidia-general-atomics-fusion/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/3025/10/hpc-tech-blog-ai-for-science-plasma-reactor-1920x1080-4462250-1680x945.png" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;The race to bottle a star now runs on AI.&lt;/p&gt;
&lt;p&gt;NVIDIA, General Atomics and a team of international partners have built a high-fidelity, AI-enabled digital twin for a fusion reactor with interactive performance, with technical support from San Diego Supercomputer Center at UC San Diego School of Computing, Information and Data Sciences, the Argonne Leadership Computing Facility (ACLF) at Argonne National Laboratory and National Energy Research Scientific Computing Center (NERSC) at Lawrence Berkeley National Laboratory.&lt;/p&gt;
&lt;p&gt;The effort, announced today at the NVIDIA GTC Washington, D.C., conference, used Polaris at the ALCF and Perlmutter at NERSC supercomputing systems to train three distinct AI surrogate models at scale.&lt;/p&gt;
&lt;p&gt;This groundbreaking project uses the NVIDIA Omniverse platform, NVIDIA CUDA-X libraries and data center GPUs to help researchers tackle one of science’s toughest problems: making fusion energy work on Earth.&lt;/p&gt;
&lt;p&gt;Here’s why this matters: fusion promises virtually limitless, clean energy by replicating the process that powers the sun.&lt;/p&gt;
&lt;p&gt;“The ability to explore scenarios virtually through this interactive digital twin is a game-changer,” said Raffi Nazikian, fusion data science lead at General Atomics. “Working with NVIDIA, we can now test, refine and verify our ideas orders of magnitude faster, accelerating the path toward practical fusion energy.”&lt;/p&gt;
&lt;p&gt;But controlling plasma at extreme temperatures — think hundreds of millions of degrees — and predicting its behavior fast enough to keep reactors running is a massive challenge.&lt;/p&gt;
&lt;p&gt;Plasma is the fourth state of matter, a swirling soup of charged particles that behaves like a living thing. It’s what stars are made of.&lt;/p&gt;
&lt;p&gt;In fusion reactors, plasma is the fuel — the stuff that, if tamed, could power cities with the energy of the sun. Imagine trying to bottle a star. That’s the metaphor fusion scientists love, and for good reason: it’s poetic and accurate.&lt;/p&gt;
&lt;p&gt;That’s where AI comes in. By reducing simulation times from weeks to seconds, AI enables researchers to interact with the reactor virtually, exploring scenarios that may damage the reactor without risk, and accelerate the path to commercial fusion power.&lt;/p&gt;
&lt;p&gt;At the forefront of this effort, General Atomics is developing an AI-enabled digital twin as part of their research at the US Department of Energy’s DIII-D National Fusion Facility to push fusion research forward.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;AI: Turning Weeks to Seconds&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Traditionally, simulating plasma behavior takes weeks on even the fastest supercomputers.&lt;/p&gt;
&lt;p&gt;General Atomics is now using AI surrogate models — trained on decades of real-world data — to predict plasma behavior in seconds, all of which continue to be improved.&lt;/p&gt;
&lt;p&gt;These models, including EFIT (for plasma equilibrium), CAKE (for plasma boundary) and ION ORB (for heat density of escaping ions), can help operators keep the plasma stable in real time, reducing the risk of damage and speeding up research.&lt;/p&gt;
&lt;p&gt;Running on NVIDIA GPUs, these models deliver accurate predictions faster than physics-based simulations. They’re among the many models used to help simulate the behavior of fusion reactors and control them, which can be accelerated by AI.&lt;/p&gt;
&lt;p&gt;SUBHEAD: The Digital Twin&lt;/p&gt;
&lt;p&gt;NVIDIA and General Atomics are building a fully interactive digital twin of the DIII-D inside NVIDIA Omniverse, powered by NVIDIA RTX PRO Servers and NVIDIA DGX Spark, with supporting contributions from San Diego Supercomputer Center, ALCF and NERSC.&lt;/p&gt;
&lt;p&gt;This virtual reactor dynamically fuses sensor data, physics-based simulations, engineering models and AI surrogate models — creating a unified, real-time interactive environment that can quickly inform decisions.&lt;/p&gt;
&lt;p&gt;The digital twin is synchronized with the physical DIII-D, allowing the international team of 700 scientists from 100 different organizations to test ideas and run “what-if” scenarios without touching the real machine.&lt;/p&gt;
&lt;p&gt;Key controls can be explored in the digital twin to refine the science before running real experiments, enabling rapid optimization and faster progress toward commercial fusion.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Why It Matters&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;This approach fundamentally shifts fusion research from a pure physics challenge to one also powered by computing and smart algorithms.&lt;/p&gt;
&lt;p&gt;By moving from weeks-long simulations to near-real-time, interactive answers in seconds, the digital twin acts as a true “fusion accelerator” — a platform to rapidly test new ideas, optimize reactor designs and put commercial fusion energy on a faster track.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Learn more about how NVIDIA and partners are advancing AI innovation in the U.S. by watching the &lt;/i&gt;&lt;i&gt;NVIDIA GTC Washington, D.C., keynote by Jensen Huang&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/3025/10/hpc-tech-blog-ai-for-science-plasma-reactor-1920x1080-4462250-1680x945.png" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;The race to bottle a star now runs on AI.&lt;/p&gt;
&lt;p&gt;NVIDIA, General Atomics and a team of international partners have built a high-fidelity, AI-enabled digital twin for a fusion reactor with interactive performance, with technical support from San Diego Supercomputer Center at UC San Diego School of Computing, Information and Data Sciences, the Argonne Leadership Computing Facility (ACLF) at Argonne National Laboratory and National Energy Research Scientific Computing Center (NERSC) at Lawrence Berkeley National Laboratory.&lt;/p&gt;
&lt;p&gt;The effort, announced today at the NVIDIA GTC Washington, D.C., conference, used Polaris at the ALCF and Perlmutter at NERSC supercomputing systems to train three distinct AI surrogate models at scale.&lt;/p&gt;
&lt;p&gt;This groundbreaking project uses the NVIDIA Omniverse platform, NVIDIA CUDA-X libraries and data center GPUs to help researchers tackle one of science’s toughest problems: making fusion energy work on Earth.&lt;/p&gt;
&lt;p&gt;Here’s why this matters: fusion promises virtually limitless, clean energy by replicating the process that powers the sun.&lt;/p&gt;
&lt;p&gt;“The ability to explore scenarios virtually through this interactive digital twin is a game-changer,” said Raffi Nazikian, fusion data science lead at General Atomics. “Working with NVIDIA, we can now test, refine and verify our ideas orders of magnitude faster, accelerating the path toward practical fusion energy.”&lt;/p&gt;
&lt;p&gt;But controlling plasma at extreme temperatures — think hundreds of millions of degrees — and predicting its behavior fast enough to keep reactors running is a massive challenge.&lt;/p&gt;
&lt;p&gt;Plasma is the fourth state of matter, a swirling soup of charged particles that behaves like a living thing. It’s what stars are made of.&lt;/p&gt;
&lt;p&gt;In fusion reactors, plasma is the fuel — the stuff that, if tamed, could power cities with the energy of the sun. Imagine trying to bottle a star. That’s the metaphor fusion scientists love, and for good reason: it’s poetic and accurate.&lt;/p&gt;
&lt;p&gt;That’s where AI comes in. By reducing simulation times from weeks to seconds, AI enables researchers to interact with the reactor virtually, exploring scenarios that may damage the reactor without risk, and accelerate the path to commercial fusion power.&lt;/p&gt;
&lt;p&gt;At the forefront of this effort, General Atomics is developing an AI-enabled digital twin as part of their research at the US Department of Energy’s DIII-D National Fusion Facility to push fusion research forward.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;AI: Turning Weeks to Seconds&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Traditionally, simulating plasma behavior takes weeks on even the fastest supercomputers.&lt;/p&gt;
&lt;p&gt;General Atomics is now using AI surrogate models — trained on decades of real-world data — to predict plasma behavior in seconds, all of which continue to be improved.&lt;/p&gt;
&lt;p&gt;These models, including EFIT (for plasma equilibrium), CAKE (for plasma boundary) and ION ORB (for heat density of escaping ions), can help operators keep the plasma stable in real time, reducing the risk of damage and speeding up research.&lt;/p&gt;
&lt;p&gt;Running on NVIDIA GPUs, these models deliver accurate predictions faster than physics-based simulations. They’re among the many models used to help simulate the behavior of fusion reactors and control them, which can be accelerated by AI.&lt;/p&gt;
&lt;p&gt;SUBHEAD: The Digital Twin&lt;/p&gt;
&lt;p&gt;NVIDIA and General Atomics are building a fully interactive digital twin of the DIII-D inside NVIDIA Omniverse, powered by NVIDIA RTX PRO Servers and NVIDIA DGX Spark, with supporting contributions from San Diego Supercomputer Center, ALCF and NERSC.&lt;/p&gt;
&lt;p&gt;This virtual reactor dynamically fuses sensor data, physics-based simulations, engineering models and AI surrogate models — creating a unified, real-time interactive environment that can quickly inform decisions.&lt;/p&gt;
&lt;p&gt;The digital twin is synchronized with the physical DIII-D, allowing the international team of 700 scientists from 100 different organizations to test ideas and run “what-if” scenarios without touching the real machine.&lt;/p&gt;
&lt;p&gt;Key controls can be explored in the digital twin to refine the science before running real experiments, enabling rapid optimization and faster progress toward commercial fusion.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Why It Matters&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;This approach fundamentally shifts fusion research from a pure physics challenge to one also powered by computing and smart algorithms.&lt;/p&gt;
&lt;p&gt;By moving from weeks-long simulations to near-real-time, interactive answers in seconds, the digital twin acts as a true “fusion accelerator” — a platform to rapidly test new ideas, optimize reactor designs and put commercial fusion energy on a faster track.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Learn more about how NVIDIA and partners are advancing AI innovation in the U.S. by watching the &lt;/i&gt;&lt;i&gt;NVIDIA GTC Washington, D.C., keynote by Jensen Huang&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/nvidia-general-atomics-fusion/</guid><pubDate>Tue, 28 Oct 2025 18:00:45 +0000</pubDate></item><item><title>[NEW] NVIDIA, NPS Commission the Navy’s AI Flagship for Training Tomorrow’s Leaders (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/naval-postgraduate-school-ai/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Along the Pacific Ocean in Monterey, California, the Naval Postgraduate School (NPS) is making a splash all the way to Washington, D.C.: It’s using artificial intelligence to solve operational challenges while educating tomorrow’s leaders in AI skills.&lt;/p&gt;
&lt;p&gt;Like Silicon Valley, it’s not uncommon for NPS, the U.S. Navy’s flagship academic graduate university, to hold hackathons, creating advances in autonomy, space operations, ocean research, decision tools and much more.&lt;/p&gt;
&lt;p&gt;Supporting those efforts, NVIDIA has granted an NVIDIA DGX GB300 system to help NPS play a leading role in the U.S. government’s AI race. Supercharging its AI efforts, NPS will use an NVIDIA DGX GB300 and NVIDIA Mission Control software to support over 1,500 in-resident students, 600 faculty and thousands of external partners, with plans to expand its infrastructure in the future.&lt;/p&gt;
&lt;p&gt;The system is being put to work empowering the new NVIDIA AI Technology Center at NPS for applications in everything from complex mission planning to autonomous systems simulations to disaster recovery so that U.S. service members and partners are better positioned strategically to lead with AI.&lt;/p&gt;
&lt;p&gt;“First, with this DGX GB300 system, we should be able to support model training and inference capability with our own NPS GPT,” said retired Col. Randolph Pugh, NPS AI Task Force lead and AI Portfolio director. “It will give us on-premises capability for added privacy to provide a generative AI large language model tool for people to use.”&lt;/p&gt;
&lt;p&gt;NPS has partnered on many technical challenges with nonprofit organization MITRE, which develops technologies and solutions for the government and public interest with federally funded research and development centers.&lt;/p&gt;
&lt;p&gt;Sometimes that involves transferring technology, such as powerful weather models that NPS can develop further. Studying the sea in support of naval operations has always been a focus of NPS.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Tackling AI Strategic Challenges With a Three-Computer Solution&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;MITRE recently shared with NPS its Advanced Simulation for Planning and Enhanced Navigation (ASPEN) simulation framework, which it developed on the NVIDIA Omniverse platform. ASPEN provides a high-fidelity digital twin environment for simulating — using the NVIDIA Isaac Sim framework for robotics — with unmanned underwater vehicle (UUV) navigation, obstacle avoidance and real-time decision-making under uncertain conditions like currents, low visibility and acoustic interference.&lt;/p&gt;
&lt;p&gt;MITRE’s ASPEN 3 Network brings in real-world data from its BlueTech Lab, an indoor pool maritime test facility, which helps validate autonomous systems and actions in water.&lt;/p&gt;
&lt;p&gt;ASPEN is used to develop environmental models around wind, temperature, salinity, current and water depth. It works with models for sonar, inertial measurement unit devices, compass readings, lidar and cameras. Computing for UUVs runs on NVIDIA Jetson AGX modules at the edge to process data.&lt;/p&gt;
&lt;p&gt;MITRE harnesses an NVIDIA DGX SuperPOD to train large language and weather forecast models in its Federal AI Sandbox. The AI Sandbox is a secure environment for federal agencies to experiment, prototype and deploy advanced AI.&lt;/p&gt;
&lt;p&gt;MITRE’s use of accelerated computing — across NVIDIA Jetson AGX, Omniverse and DGX — encompasses NVIDIA’s three-computer solution for developing physical AI.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Accelerating Weather and Environmental Modeling at NPS With NVIDIA DGX GB300&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Understanding and accurately predicting ocean operational environments remains critical to effective naval planning and readiness. Understanding the environment that the Navy operates within is important to help keep ships and their crews safe at sea.&lt;/p&gt;
&lt;p&gt;After training the foundational models on DGX GB300, NPS can run simulations using NVIDIA Isaac Sim to help understand environments where the Navy operates and further train in ASPEN.&lt;/p&gt;
&lt;p&gt;“We need to predict environmental changes by understanding the atmosphere, the sea surface, subsurface and seabed for maximum mission effectiveness and crew safety,” said Pugh.&lt;/p&gt;
&lt;p&gt;ASPEN works with physics-based models and can incorporate real-time vehicle position and orientation data for hardware-in-the loop model training and mission prediction.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Modeling the World and Beyond&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;ASPEN offers efficient generation of propagation environments for sensor modeling with NVIDIA fVDB, an open-source, GPU-accelerated deep learning framework. It’s used for processing massive 3D datasets with spatial intelligence, enabling generative physical AI by accelerating 3D machine learning tasks for applications such as digital twins.&lt;/p&gt;
&lt;p&gt;The NVIDIA fVDB framework can be harnessed to build high-fidelity digital twins of many different environments. This requires processing datasets from sources such as telemetry, sonar, satellite data and other sensor reports to create virtual representations of the ocean floor, water column, atmosphere and even space. Using these kinds of AI simulation environments enables NPS to detect and understand what’s normal and what’s not.&lt;/p&gt;
&lt;p&gt;“For example, should a spacecraft lose its capability to maneuver, or something crashes into something, it creates debris, and we’d like to predict where every little thing goes because the uncontrolled satellites or debris fields can be extremely dangerous,” said Pugh.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Developing Real-World Naval Applications While Learning AI&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Across all curricula at NPS, AI is enabling its military students to earn their graduate degrees and conduct hands-on applied research with AI by developing real-world applications that benefit the Naval and Joint Force.&lt;/p&gt;
&lt;p&gt;“We can spin up something born out of an independent study or a hackathon project or funded research, with faculty leveraging students as part of that, and we can connect them with the fleets that are going to fund them or operationalize them,” said U.S. Navy Captain Michael Owen, NPS AI Task Force Deputy.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="size-medium wp-image-86567 aligncenter" height="768" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/NPS_Campus3-960x768.jpg" width="960" /&gt;&lt;/p&gt;
&lt;p&gt;NVIDIA is also providing resources through the NVIDIA Deep Learning Institute and has established an NVIDIA AI Technology Center at the university’s Monterey campus to give the faculty at NPS cutting-edge resources that enhance the institution’s unique defense-focused graduate education and research.&lt;/p&gt;
&lt;p&gt;“We’ve appreciated the access to the NVIDIA Deep Learning Institute for its instructor toolkits,”&amp;nbsp; Pugh said. “It’s proving critical in helping NPS educate tomorrow’s leaders in AI.”&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Watch the &lt;/i&gt;&lt;i&gt;GTC Washington, D.C., keynote&lt;/i&gt;&lt;i&gt; from NVIDIA founder and CEO Jensen Huang and explore &lt;/i&gt;&lt;i&gt;sessions&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Along the Pacific Ocean in Monterey, California, the Naval Postgraduate School (NPS) is making a splash all the way to Washington, D.C.: It’s using artificial intelligence to solve operational challenges while educating tomorrow’s leaders in AI skills.&lt;/p&gt;
&lt;p&gt;Like Silicon Valley, it’s not uncommon for NPS, the U.S. Navy’s flagship academic graduate university, to hold hackathons, creating advances in autonomy, space operations, ocean research, decision tools and much more.&lt;/p&gt;
&lt;p&gt;Supporting those efforts, NVIDIA has granted an NVIDIA DGX GB300 system to help NPS play a leading role in the U.S. government’s AI race. Supercharging its AI efforts, NPS will use an NVIDIA DGX GB300 and NVIDIA Mission Control software to support over 1,500 in-resident students, 600 faculty and thousands of external partners, with plans to expand its infrastructure in the future.&lt;/p&gt;
&lt;p&gt;The system is being put to work empowering the new NVIDIA AI Technology Center at NPS for applications in everything from complex mission planning to autonomous systems simulations to disaster recovery so that U.S. service members and partners are better positioned strategically to lead with AI.&lt;/p&gt;
&lt;p&gt;“First, with this DGX GB300 system, we should be able to support model training and inference capability with our own NPS GPT,” said retired Col. Randolph Pugh, NPS AI Task Force lead and AI Portfolio director. “It will give us on-premises capability for added privacy to provide a generative AI large language model tool for people to use.”&lt;/p&gt;
&lt;p&gt;NPS has partnered on many technical challenges with nonprofit organization MITRE, which develops technologies and solutions for the government and public interest with federally funded research and development centers.&lt;/p&gt;
&lt;p&gt;Sometimes that involves transferring technology, such as powerful weather models that NPS can develop further. Studying the sea in support of naval operations has always been a focus of NPS.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Tackling AI Strategic Challenges With a Three-Computer Solution&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;MITRE recently shared with NPS its Advanced Simulation for Planning and Enhanced Navigation (ASPEN) simulation framework, which it developed on the NVIDIA Omniverse platform. ASPEN provides a high-fidelity digital twin environment for simulating — using the NVIDIA Isaac Sim framework for robotics — with unmanned underwater vehicle (UUV) navigation, obstacle avoidance and real-time decision-making under uncertain conditions like currents, low visibility and acoustic interference.&lt;/p&gt;
&lt;p&gt;MITRE’s ASPEN 3 Network brings in real-world data from its BlueTech Lab, an indoor pool maritime test facility, which helps validate autonomous systems and actions in water.&lt;/p&gt;
&lt;p&gt;ASPEN is used to develop environmental models around wind, temperature, salinity, current and water depth. It works with models for sonar, inertial measurement unit devices, compass readings, lidar and cameras. Computing for UUVs runs on NVIDIA Jetson AGX modules at the edge to process data.&lt;/p&gt;
&lt;p&gt;MITRE harnesses an NVIDIA DGX SuperPOD to train large language and weather forecast models in its Federal AI Sandbox. The AI Sandbox is a secure environment for federal agencies to experiment, prototype and deploy advanced AI.&lt;/p&gt;
&lt;p&gt;MITRE’s use of accelerated computing — across NVIDIA Jetson AGX, Omniverse and DGX — encompasses NVIDIA’s three-computer solution for developing physical AI.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Accelerating Weather and Environmental Modeling at NPS With NVIDIA DGX GB300&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Understanding and accurately predicting ocean operational environments remains critical to effective naval planning and readiness. Understanding the environment that the Navy operates within is important to help keep ships and their crews safe at sea.&lt;/p&gt;
&lt;p&gt;After training the foundational models on DGX GB300, NPS can run simulations using NVIDIA Isaac Sim to help understand environments where the Navy operates and further train in ASPEN.&lt;/p&gt;
&lt;p&gt;“We need to predict environmental changes by understanding the atmosphere, the sea surface, subsurface and seabed for maximum mission effectiveness and crew safety,” said Pugh.&lt;/p&gt;
&lt;p&gt;ASPEN works with physics-based models and can incorporate real-time vehicle position and orientation data for hardware-in-the loop model training and mission prediction.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Modeling the World and Beyond&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;ASPEN offers efficient generation of propagation environments for sensor modeling with NVIDIA fVDB, an open-source, GPU-accelerated deep learning framework. It’s used for processing massive 3D datasets with spatial intelligence, enabling generative physical AI by accelerating 3D machine learning tasks for applications such as digital twins.&lt;/p&gt;
&lt;p&gt;The NVIDIA fVDB framework can be harnessed to build high-fidelity digital twins of many different environments. This requires processing datasets from sources such as telemetry, sonar, satellite data and other sensor reports to create virtual representations of the ocean floor, water column, atmosphere and even space. Using these kinds of AI simulation environments enables NPS to detect and understand what’s normal and what’s not.&lt;/p&gt;
&lt;p&gt;“For example, should a spacecraft lose its capability to maneuver, or something crashes into something, it creates debris, and we’d like to predict where every little thing goes because the uncontrolled satellites or debris fields can be extremely dangerous,” said Pugh.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Developing Real-World Naval Applications While Learning AI&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Across all curricula at NPS, AI is enabling its military students to earn their graduate degrees and conduct hands-on applied research with AI by developing real-world applications that benefit the Naval and Joint Force.&lt;/p&gt;
&lt;p&gt;“We can spin up something born out of an independent study or a hackathon project or funded research, with faculty leveraging students as part of that, and we can connect them with the fleets that are going to fund them or operationalize them,” said U.S. Navy Captain Michael Owen, NPS AI Task Force Deputy.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="size-medium wp-image-86567 aligncenter" height="768" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/NPS_Campus3-960x768.jpg" width="960" /&gt;&lt;/p&gt;
&lt;p&gt;NVIDIA is also providing resources through the NVIDIA Deep Learning Institute and has established an NVIDIA AI Technology Center at the university’s Monterey campus to give the faculty at NPS cutting-edge resources that enhance the institution’s unique defense-focused graduate education and research.&lt;/p&gt;
&lt;p&gt;“We’ve appreciated the access to the NVIDIA Deep Learning Institute for its instructor toolkits,”&amp;nbsp; Pugh said. “It’s proving critical in helping NPS educate tomorrow’s leaders in AI.”&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Watch the &lt;/i&gt;&lt;i&gt;GTC Washington, D.C., keynote&lt;/i&gt;&lt;i&gt; from NVIDIA founder and CEO Jensen Huang and explore &lt;/i&gt;&lt;i&gt;sessions&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/naval-postgraduate-school-ai/</guid><pubDate>Tue, 28 Oct 2025 18:00:49 +0000</pubDate></item><item><title>[NEW] Fueling Economic Development Across the US: How NVIDIA Is Empowering States, Municipalities and Universities to Drive Innovation (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/economic-development-us/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;To democratize access to AI technology nationwide, AI education and deployment can’t be limited to a few urban tech hubs — it must reach every community, university and state.&lt;/p&gt;
&lt;p&gt;That’s why NVIDIA is working with cities, states and educational institutions to embed AI education and innovation across the U.S., with the goal of helping the next generation of American developers, researchers and engineers lead the global AI economy.&lt;/p&gt;
&lt;p&gt;These initiatives — which span state-level AI factories, municipal strategies for AI-driven economic development and educational initiatives for students of all ages — have the potential to change generational outcomes by driving workforce development and economic growth in communities nationwide.&lt;/p&gt;
&lt;p&gt;At NVIDIA GTC Washington, D.C., running through Wednesday, Oct. 29, government and educational institutions including the State of Utah, the City of Rancho Cordova and Miles College are discussing recent collaborations with NVIDIA to spur AI training and innovation.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Utah Launches First State AI Factory&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The University of Utah recently unveiled an AI factory initiative with NVIDIA and HPE that will more than triple the university’s computing capacity with a $50 million investment of public and philanthropic funds into AI infrastructure.&lt;/p&gt;
&lt;p&gt;The multiyear effort will support the university’s healthcare and scientific research, including projects focused on Alzheimer’s, cancer, genetics and mental health.&lt;/p&gt;
&lt;p&gt;“With this initiative, we aim to build the AI infrastructure needed to fuel a strong ecosystem of developers, students and researchers across the state,” said Taylor Randall, president of the University of Utah. “This boost in compute availability will help drive research and entrepreneurship across scientific disciplines.”&lt;/p&gt;
&lt;p&gt;Utah is also among a growing number of states — including California, Mississippi and Oregon — collaborating with NVIDIA to enhance AI education efforts and boost regional economic development.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_86516"&gt;&lt;img alt="alt" class="size-full wp-image-86516" height="1364" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/AdobeStock_415442995-scaled.jpeg" width="2048" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-86516"&gt;Utah’s Silicon Slopes tech hub&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Through an initiative announced earlier this year, Utah is equipping educators at the state’s universities, community colleges and adult education programs with AI skills and certification through the NVIDIA Deep Learning Institute University Ambassador Program.&lt;/p&gt;
&lt;p&gt;It’s part of a broader effort to ensure the state’s educational system is preparing teachers and students with AI skills.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;The AI Ecosystem as a Policy Engine: Rancho Cordova’s Municipal Innovation Strategy&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Rancho Cordova, California — a city of about 85,000 residents located less than 15 miles from Sacramento — is collaborating with NVIDIA and the Human Machine Collaboration Institute (HMCI) to boost the city’s AI capabilities with AI infrastructure, workforce upskilling and student training.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_86519"&gt;&lt;img alt="alt" class="wp-image-86519 size-medium" height="720" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/Cordova-HS-engineering-960x720.jpg" width="960" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-86519"&gt;Cordova High School students learning robotics skills.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;In this critical period of AI advancement, the city aims to generate economic value by developing an AI and robotics ecosystem that will attract AI businesses to Rancho Cordova with reliable power infrastructure and workforce pipelines from local colleges and universities. The city then plans to reinvest revenue from the new AI businesses into building its local AI ecosystem with workforce development programs, research and additional AI infrastructure.&lt;/p&gt;
&lt;p&gt;“Rancho Cordova is charting new territory by developing an AI ecosystem that unites industry, education and government to shape the future of economic growth,” said Rancho Cordova City Manager Micah Runner. “In collaboration with NVIDIA and HMCI, we’re exploring how cities can use AI to drive innovation, strengthen the economy and expand opportunities for our community.”&lt;/p&gt;
&lt;p&gt;As a research institution, HMCI sees the Rancho Cordova initiative as a flagship example that can be shared with other cities to fuel their local economies.&lt;/p&gt;
&lt;p&gt;“It’s essential that every city is thinking about how they can adapt and change with AI,” said Sadie St. Lawrence, founder and CEO of HMCI. “In Rancho Cordova, we’re showing that you don’t have to be one of the Silicon Valleys of the world to start to infuse AI technology into your ecosystem.”&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Scaling AI Education Through College and University Partnerships&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;To help prepare students for careers in the evolving AI landscape, NVIDIA is working with educational platforms for high schools, colleges and universities nationwide, as well as professional organizations, to integrate AI education for learners of all backgrounds.&lt;/p&gt;
&lt;p&gt;Miles College, a historically Black college (HBCU) located in Fairfield, Alabama, is collaborating with NVIDIA to integrate AI across academic programs, faculty research and community engagement.&lt;/p&gt;
&lt;p&gt;NVIDIA is providing access to Deep Learning Institute resources, frameworks and development tools to expand the college’s AI curriculum — and help train and certify faculty and students in AI and accelerated computing. The company will also work with Miles College to identify and position resources and partnerships to catalyze innovation and economic development for surrounding communities.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_86522"&gt;&lt;img alt="alt" class="size-large wp-image-86522" height="945" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/Campus-2023-1-1680x945.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-86522"&gt;Miles College campus in Fairfield, Alabama&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;“We’re implementing AI fluency to be a core competency for every Miles College graduate — no matter what field they’re in — so that they’re prepared not only for success in their careers, but for leadership in their communities,” said Bobbie Knight, president of Miles College. “This initiative is about inspiring innovation and expanding opportunity, not just within the walls of Miles College but throughout the state — because when our students thrive, our entire region grows stronger.”&lt;/p&gt;
&lt;p&gt;Miles College is already implementing AI campus-wide, with nearly half of faculty regularly integrating AI into course design and student learning modules, and about 60% of the college’s research supported by AI.&lt;/p&gt;
&lt;p&gt;Knight last year established the 2150 Center for Innovation, Commercialization and Growth, an initiative to champion HBCU tech and boost innovation in the region with resources to support founders and entrepreneurs and fuel successful businesses.&lt;/p&gt;
&lt;p&gt;The presidents of the University of Utah and Miles College will join leaders from Coppin State University and Houston City College in a GTC Washington, D.C., panel Wednesday. The session will showcase how colleges and universities across the country integrate AI into their curricula, supporting state and regional economic goals while preparing students for high-demand job sectors.&lt;/p&gt;
&lt;p&gt;NVIDIA is working with other American educational institutes and professional organizations including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;California College of the Arts: The nonprofit art and design college is collaborating with NVIDIA to integrate AI and GPU-accelerated computing into visual art, architecture and interactive media — and provide AI education through the NVIDIA Deep Learning Institute.&lt;/li&gt;
&lt;li&gt;Black Tech Street: This Tulsa, Oklahoma-based organization is working with NVIDIA to catalyze AI innovation and train up to 10,000 people in AI through collaborations with educational institutions and community organizations.&lt;/li&gt;
&lt;li&gt;Black Women in Artificial Intelligence: A three-year agreement with NVIDIA aims to expand access to AI education and professional networks to innovative organizations in the AI industry.&lt;/li&gt;
&lt;li&gt;StudyFetch: This AI-powered educational platform, a member of the NVIDIA Inception program for startups, is bringing NVIDIA Academy to high-school students nationwide, starting with the AI for All course. The initiative launches today with students from the Washington, D.C.-based Friendship Public Charter School and Richard Wright Public Charter Schools.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;“Our mission is to make sure every student everywhere can succeed,” said Sam Whitaker, vice president of social impact and strategic initiatives at StudyFetch. “With AI, we have the chance to close opportunity and workforce readiness gaps across the country. That work starts right now.”&lt;/p&gt;
&lt;p&gt;The StudyFetch collaboration is the first milestone in NVIDIA’s K-12 AI education plan, which was announced earlier this year with StudyFetch and CK-12, another leading K-12 learning platform. The effort is aligned with the White House executive order Advancing Artificial Intelligence Education for American Youth.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Watch the &lt;/i&gt;&lt;i&gt;GTC Washington, D.C., keynote&lt;/i&gt;&lt;i&gt; from NVIDIA founder and CEO Jensen Huang and explore &lt;/i&gt;&lt;i&gt;sessions&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;To democratize access to AI technology nationwide, AI education and deployment can’t be limited to a few urban tech hubs — it must reach every community, university and state.&lt;/p&gt;
&lt;p&gt;That’s why NVIDIA is working with cities, states and educational institutions to embed AI education and innovation across the U.S., with the goal of helping the next generation of American developers, researchers and engineers lead the global AI economy.&lt;/p&gt;
&lt;p&gt;These initiatives — which span state-level AI factories, municipal strategies for AI-driven economic development and educational initiatives for students of all ages — have the potential to change generational outcomes by driving workforce development and economic growth in communities nationwide.&lt;/p&gt;
&lt;p&gt;At NVIDIA GTC Washington, D.C., running through Wednesday, Oct. 29, government and educational institutions including the State of Utah, the City of Rancho Cordova and Miles College are discussing recent collaborations with NVIDIA to spur AI training and innovation.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Utah Launches First State AI Factory&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The University of Utah recently unveiled an AI factory initiative with NVIDIA and HPE that will more than triple the university’s computing capacity with a $50 million investment of public and philanthropic funds into AI infrastructure.&lt;/p&gt;
&lt;p&gt;The multiyear effort will support the university’s healthcare and scientific research, including projects focused on Alzheimer’s, cancer, genetics and mental health.&lt;/p&gt;
&lt;p&gt;“With this initiative, we aim to build the AI infrastructure needed to fuel a strong ecosystem of developers, students and researchers across the state,” said Taylor Randall, president of the University of Utah. “This boost in compute availability will help drive research and entrepreneurship across scientific disciplines.”&lt;/p&gt;
&lt;p&gt;Utah is also among a growing number of states — including California, Mississippi and Oregon — collaborating with NVIDIA to enhance AI education efforts and boost regional economic development.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_86516"&gt;&lt;img alt="alt" class="size-full wp-image-86516" height="1364" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/AdobeStock_415442995-scaled.jpeg" width="2048" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-86516"&gt;Utah’s Silicon Slopes tech hub&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Through an initiative announced earlier this year, Utah is equipping educators at the state’s universities, community colleges and adult education programs with AI skills and certification through the NVIDIA Deep Learning Institute University Ambassador Program.&lt;/p&gt;
&lt;p&gt;It’s part of a broader effort to ensure the state’s educational system is preparing teachers and students with AI skills.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;The AI Ecosystem as a Policy Engine: Rancho Cordova’s Municipal Innovation Strategy&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Rancho Cordova, California — a city of about 85,000 residents located less than 15 miles from Sacramento — is collaborating with NVIDIA and the Human Machine Collaboration Institute (HMCI) to boost the city’s AI capabilities with AI infrastructure, workforce upskilling and student training.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_86519"&gt;&lt;img alt="alt" class="wp-image-86519 size-medium" height="720" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/Cordova-HS-engineering-960x720.jpg" width="960" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-86519"&gt;Cordova High School students learning robotics skills.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;In this critical period of AI advancement, the city aims to generate economic value by developing an AI and robotics ecosystem that will attract AI businesses to Rancho Cordova with reliable power infrastructure and workforce pipelines from local colleges and universities. The city then plans to reinvest revenue from the new AI businesses into building its local AI ecosystem with workforce development programs, research and additional AI infrastructure.&lt;/p&gt;
&lt;p&gt;“Rancho Cordova is charting new territory by developing an AI ecosystem that unites industry, education and government to shape the future of economic growth,” said Rancho Cordova City Manager Micah Runner. “In collaboration with NVIDIA and HMCI, we’re exploring how cities can use AI to drive innovation, strengthen the economy and expand opportunities for our community.”&lt;/p&gt;
&lt;p&gt;As a research institution, HMCI sees the Rancho Cordova initiative as a flagship example that can be shared with other cities to fuel their local economies.&lt;/p&gt;
&lt;p&gt;“It’s essential that every city is thinking about how they can adapt and change with AI,” said Sadie St. Lawrence, founder and CEO of HMCI. “In Rancho Cordova, we’re showing that you don’t have to be one of the Silicon Valleys of the world to start to infuse AI technology into your ecosystem.”&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Scaling AI Education Through College and University Partnerships&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;To help prepare students for careers in the evolving AI landscape, NVIDIA is working with educational platforms for high schools, colleges and universities nationwide, as well as professional organizations, to integrate AI education for learners of all backgrounds.&lt;/p&gt;
&lt;p&gt;Miles College, a historically Black college (HBCU) located in Fairfield, Alabama, is collaborating with NVIDIA to integrate AI across academic programs, faculty research and community engagement.&lt;/p&gt;
&lt;p&gt;NVIDIA is providing access to Deep Learning Institute resources, frameworks and development tools to expand the college’s AI curriculum — and help train and certify faculty and students in AI and accelerated computing. The company will also work with Miles College to identify and position resources and partnerships to catalyze innovation and economic development for surrounding communities.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_86522"&gt;&lt;img alt="alt" class="size-large wp-image-86522" height="945" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/Campus-2023-1-1680x945.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-86522"&gt;Miles College campus in Fairfield, Alabama&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;“We’re implementing AI fluency to be a core competency for every Miles College graduate — no matter what field they’re in — so that they’re prepared not only for success in their careers, but for leadership in their communities,” said Bobbie Knight, president of Miles College. “This initiative is about inspiring innovation and expanding opportunity, not just within the walls of Miles College but throughout the state — because when our students thrive, our entire region grows stronger.”&lt;/p&gt;
&lt;p&gt;Miles College is already implementing AI campus-wide, with nearly half of faculty regularly integrating AI into course design and student learning modules, and about 60% of the college’s research supported by AI.&lt;/p&gt;
&lt;p&gt;Knight last year established the 2150 Center for Innovation, Commercialization and Growth, an initiative to champion HBCU tech and boost innovation in the region with resources to support founders and entrepreneurs and fuel successful businesses.&lt;/p&gt;
&lt;p&gt;The presidents of the University of Utah and Miles College will join leaders from Coppin State University and Houston City College in a GTC Washington, D.C., panel Wednesday. The session will showcase how colleges and universities across the country integrate AI into their curricula, supporting state and regional economic goals while preparing students for high-demand job sectors.&lt;/p&gt;
&lt;p&gt;NVIDIA is working with other American educational institutes and professional organizations including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;California College of the Arts: The nonprofit art and design college is collaborating with NVIDIA to integrate AI and GPU-accelerated computing into visual art, architecture and interactive media — and provide AI education through the NVIDIA Deep Learning Institute.&lt;/li&gt;
&lt;li&gt;Black Tech Street: This Tulsa, Oklahoma-based organization is working with NVIDIA to catalyze AI innovation and train up to 10,000 people in AI through collaborations with educational institutions and community organizations.&lt;/li&gt;
&lt;li&gt;Black Women in Artificial Intelligence: A three-year agreement with NVIDIA aims to expand access to AI education and professional networks to innovative organizations in the AI industry.&lt;/li&gt;
&lt;li&gt;StudyFetch: This AI-powered educational platform, a member of the NVIDIA Inception program for startups, is bringing NVIDIA Academy to high-school students nationwide, starting with the AI for All course. The initiative launches today with students from the Washington, D.C.-based Friendship Public Charter School and Richard Wright Public Charter Schools.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;“Our mission is to make sure every student everywhere can succeed,” said Sam Whitaker, vice president of social impact and strategic initiatives at StudyFetch. “With AI, we have the chance to close opportunity and workforce readiness gaps across the country. That work starts right now.”&lt;/p&gt;
&lt;p&gt;The StudyFetch collaboration is the first milestone in NVIDIA’s K-12 AI education plan, which was announced earlier this year with StudyFetch and CK-12, another leading K-12 learning platform. The effort is aligned with the White House executive order Advancing Artificial Intelligence Education for American Youth.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Watch the &lt;/i&gt;&lt;i&gt;GTC Washington, D.C., keynote&lt;/i&gt;&lt;i&gt; from NVIDIA founder and CEO Jensen Huang and explore &lt;/i&gt;&lt;i&gt;sessions&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/economic-development-us/</guid><pubDate>Tue, 28 Oct 2025 18:02:21 +0000</pubDate></item><item><title>[NEW] Roundtables: Seeking Climate Solutions in Turbulent Times (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/28/1125962/roundtables-seeking-climate-solutions-in-turbulent-times/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/MITTR-Roundtables-Zoom-Opening-Overlay.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="contentBody__summaryBullets--81327c9379272772d1e74a64b6d4868a"&gt;&lt;div class="contentBody__summaryBullets--81327c9379272772d1e74a64b6d4868a"&gt;
&lt;p&gt;&lt;em&gt;Available only for MIT Alumni and subscribers.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Companies are pursuing climate solutions amid shifting U.S. politics and economic uncertainty. Drawing from MIT Technology Review’s 10 Climate Tech Companies to Watch list, this session highlights the most promising technologies—from electric trucks to gene-edited crops—and explores the challenges companies face in advancing climate progress today.&lt;br /&gt;&lt;/p&gt;  &lt;p&gt;Speakers&lt;strong&gt;:&lt;/strong&gt;&amp;nbsp;&lt;strong&gt;Casey Crownhart&lt;/strong&gt;, Senior Climate Reporter; &lt;strong&gt;James Temple&lt;/strong&gt;, Senior Climate Editor; and &lt;strong&gt;Mary Beth Griggs&lt;/strong&gt;, Science Editor&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 core-embed_1"&gt;
&lt;figure class="wp-block-embed is-type-video is-provider-vimeo wp-block-embed-vimeo wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
[embedded content]

&lt;/div&gt;&lt;/figure&gt;
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;strong&gt;Recorded on October 28, 2025&lt;br /&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;&lt;br /&gt;&lt;/em&gt;&lt;strong&gt;Related Coverage&lt;/strong&gt;:&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/MITTR-Roundtables-Zoom-Opening-Overlay.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="contentBody__summaryBullets--81327c9379272772d1e74a64b6d4868a"&gt;&lt;div class="contentBody__summaryBullets--81327c9379272772d1e74a64b6d4868a"&gt;
&lt;p&gt;&lt;em&gt;Available only for MIT Alumni and subscribers.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Companies are pursuing climate solutions amid shifting U.S. politics and economic uncertainty. Drawing from MIT Technology Review’s 10 Climate Tech Companies to Watch list, this session highlights the most promising technologies—from electric trucks to gene-edited crops—and explores the challenges companies face in advancing climate progress today.&lt;br /&gt;&lt;/p&gt;  &lt;p&gt;Speakers&lt;strong&gt;:&lt;/strong&gt;&amp;nbsp;&lt;strong&gt;Casey Crownhart&lt;/strong&gt;, Senior Climate Reporter; &lt;strong&gt;James Temple&lt;/strong&gt;, Senior Climate Editor; and &lt;strong&gt;Mary Beth Griggs&lt;/strong&gt;, Science Editor&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 core-embed_1"&gt;
&lt;figure class="wp-block-embed is-type-video is-provider-vimeo wp-block-embed-vimeo wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
[embedded content]

&lt;/div&gt;&lt;/figure&gt;
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;strong&gt;Recorded on October 28, 2025&lt;br /&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;&lt;br /&gt;&lt;/em&gt;&lt;strong&gt;Related Coverage&lt;/strong&gt;:&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/28/1125962/roundtables-seeking-climate-solutions-in-turbulent-times/</guid><pubDate>Tue, 28 Oct 2025 18:04:01 +0000</pubDate></item><item><title>[NEW] NVIDIA AI Physics Transforms Aerospace and Automotive Design, Accelerating Engineering by 500x (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/ai-physics-aerospace-automotive-design-engineering/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/CAE-Image.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Leading technology companies in aerospace and automotive are accelerating their engineering design processes with the NVIDIA DoMINO NIM microservice, part of the NVIDIA PhysicsNeMo AI physics framework.&lt;/p&gt;
&lt;p&gt;By integrating GPU-accelerated computing, NVIDIA PhysicsNeMo and interactive digital twin technologies, enterprises are accelerating their modeling and simulation workflows by up to 500x over traditional methods, speeding innovation and shortening development cycles.&lt;/p&gt;
&lt;p&gt;NVIDIA PhysicsNeMo empowers users to accelerate simulating physical systems like automobiles, airplanes, heavy machinery and more in near real time for faster time to market.&lt;/p&gt;
&lt;p&gt;Such simulation of complex physical systems unlocks incredible speedups and gives solutions providers the freedom to explore groundbreaking designs at previously inconceivable scales and accuracy.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Synopsys Achieves 500x Leap in Computational Engineering With NVIDIA AI Physics&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Simulation software providers like Ansys, part of Synopsys, are using NVIDIA PhysicsNeMo to achieve up to 500x speedups in computational engineering.&lt;/p&gt;
&lt;p&gt;This enormous speedup comes from multiplying the benefits of GPU acceleration by the performance and accuracy of AI physics.&lt;/p&gt;
&lt;p&gt;The framework offers a new way to start fluid simulations with a highly accurate initial state — typically a computationally expensive task that requires numerous iterations — and with low runtime cost.&lt;/p&gt;
&lt;p&gt;Fluid simulations can be up to 50x faster than traditional methods when performed with NVIDIA GPU-accelerated tools like Ansys Fluent. Using NVIDIA PhysicsNeMo pretrained models to initialize the simulation multiplies that GPU-powered 50x speedup by an additional 10x due to the higher accuracy of the initial solution.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Unlocking Real-Time Aerospace Design&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Leading aerospace technology companies are using NVIDIA GPU-accelerated workflows and PhysicsNeMo to speed the design and optimization of advanced aircraft and automotive systems.&lt;/p&gt;
&lt;p&gt;Northrop Grumman and Luminary Cloud are using accelerated compute and AI-driven physics to accelerate spacecraft thruster nozzle design. With Luminary’s high-speed, NVIDIA CUDA-X-accelerated computational fluid dynamics solver, Northrop generated a large training dataset to build a surrogate nozzle model on Luminary’s cloud platform, which is powered by NVIDIA PhysicsNeMo. This dataset enabled Northrop’s engineers to rapidly explore thousands of design options and identify the optimal solution&lt;/p&gt;
&lt;p&gt;Aerospace pioneer Blue Origin is using NVIDIA PhysicsNeMo and advanced AI modeling to design next-generation space vehicles. PhysicsNeMo enables Blue Origin to use existing and augmented datasets to train models that rapidly explore potential design candidates, leading to ones that can be then validated with high-fidelity, CUDA-X-accelerated solvers.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Building on Computational Engineering Breakthroughs GPU Acceleration&amp;nbsp;&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;These latest AI physics breakthroughs further NVIDIA’s work in computational engineering to advance simulation with GPU acceleration.&lt;/p&gt;
&lt;p&gt;Cadence is pushing real-time simulation in aerospace through its Cadence Fidelity computational fluid dynamics platform, using NVIDIA CUDA-X libraries.&lt;/p&gt;
&lt;p&gt;By tapping into GPU acceleration, Cadence enables leading aerospace manufacturers to quickly build large-scale AI training datasets using its Millennium M2000 supercomputer. This lets engineers interactively explore and optimize designs, enhancing system efficiency and speeding time to market.&lt;/p&gt;
&lt;p&gt;A global leader in energy solutions used Cadence Fidelity LES Solver and NVIDIA Grace Blackwell-accelerated simulation platforms to rapidly iterate designs and run high-fidelity multiphysics simulations. This significantly shortens design cycles and optimizes turbine performance, enabling greater efficiency, emissions management and reliability for next-generation energy systems.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Watch the &lt;/i&gt;&lt;i&gt;GTC Washington, D.C., keynote&lt;/i&gt;&lt;i&gt; from NVIDIA founder and CEO Jensen Huang and explore &lt;/i&gt;&lt;i&gt;sessions&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/CAE-Image.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Leading technology companies in aerospace and automotive are accelerating their engineering design processes with the NVIDIA DoMINO NIM microservice, part of the NVIDIA PhysicsNeMo AI physics framework.&lt;/p&gt;
&lt;p&gt;By integrating GPU-accelerated computing, NVIDIA PhysicsNeMo and interactive digital twin technologies, enterprises are accelerating their modeling and simulation workflows by up to 500x over traditional methods, speeding innovation and shortening development cycles.&lt;/p&gt;
&lt;p&gt;NVIDIA PhysicsNeMo empowers users to accelerate simulating physical systems like automobiles, airplanes, heavy machinery and more in near real time for faster time to market.&lt;/p&gt;
&lt;p&gt;Such simulation of complex physical systems unlocks incredible speedups and gives solutions providers the freedom to explore groundbreaking designs at previously inconceivable scales and accuracy.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Synopsys Achieves 500x Leap in Computational Engineering With NVIDIA AI Physics&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Simulation software providers like Ansys, part of Synopsys, are using NVIDIA PhysicsNeMo to achieve up to 500x speedups in computational engineering.&lt;/p&gt;
&lt;p&gt;This enormous speedup comes from multiplying the benefits of GPU acceleration by the performance and accuracy of AI physics.&lt;/p&gt;
&lt;p&gt;The framework offers a new way to start fluid simulations with a highly accurate initial state — typically a computationally expensive task that requires numerous iterations — and with low runtime cost.&lt;/p&gt;
&lt;p&gt;Fluid simulations can be up to 50x faster than traditional methods when performed with NVIDIA GPU-accelerated tools like Ansys Fluent. Using NVIDIA PhysicsNeMo pretrained models to initialize the simulation multiplies that GPU-powered 50x speedup by an additional 10x due to the higher accuracy of the initial solution.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Unlocking Real-Time Aerospace Design&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Leading aerospace technology companies are using NVIDIA GPU-accelerated workflows and PhysicsNeMo to speed the design and optimization of advanced aircraft and automotive systems.&lt;/p&gt;
&lt;p&gt;Northrop Grumman and Luminary Cloud are using accelerated compute and AI-driven physics to accelerate spacecraft thruster nozzle design. With Luminary’s high-speed, NVIDIA CUDA-X-accelerated computational fluid dynamics solver, Northrop generated a large training dataset to build a surrogate nozzle model on Luminary’s cloud platform, which is powered by NVIDIA PhysicsNeMo. This dataset enabled Northrop’s engineers to rapidly explore thousands of design options and identify the optimal solution&lt;/p&gt;
&lt;p&gt;Aerospace pioneer Blue Origin is using NVIDIA PhysicsNeMo and advanced AI modeling to design next-generation space vehicles. PhysicsNeMo enables Blue Origin to use existing and augmented datasets to train models that rapidly explore potential design candidates, leading to ones that can be then validated with high-fidelity, CUDA-X-accelerated solvers.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Building on Computational Engineering Breakthroughs GPU Acceleration&amp;nbsp;&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;These latest AI physics breakthroughs further NVIDIA’s work in computational engineering to advance simulation with GPU acceleration.&lt;/p&gt;
&lt;p&gt;Cadence is pushing real-time simulation in aerospace through its Cadence Fidelity computational fluid dynamics platform, using NVIDIA CUDA-X libraries.&lt;/p&gt;
&lt;p&gt;By tapping into GPU acceleration, Cadence enables leading aerospace manufacturers to quickly build large-scale AI training datasets using its Millennium M2000 supercomputer. This lets engineers interactively explore and optimize designs, enhancing system efficiency and speeding time to market.&lt;/p&gt;
&lt;p&gt;A global leader in energy solutions used Cadence Fidelity LES Solver and NVIDIA Grace Blackwell-accelerated simulation platforms to rapidly iterate designs and run high-fidelity multiphysics simulations. This significantly shortens design cycles and optimizes turbine performance, enabling greater efficiency, emissions management and reliability for next-generation energy systems.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Watch the &lt;/i&gt;&lt;i&gt;GTC Washington, D.C., keynote&lt;/i&gt;&lt;i&gt; from NVIDIA founder and CEO Jensen Huang and explore &lt;/i&gt;&lt;i&gt;sessions&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/ai-physics-aerospace-automotive-design-engineering/</guid><pubDate>Tue, 28 Oct 2025 18:07:53 +0000</pubDate></item><item><title>[NEW] OpenAI data suggests 1 million users discuss suicide with ChatGPT weekly (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/10/openai-data-suggests-1-million-users-discuss-suicide-with-chatgpt-weekly/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Sensitive chats are rare but significant given the large user base.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Illustration of a person talking to a robot holding a clipboard." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/robot_therapy_1-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Illustration of a person talking to a robot holding a clipboard." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/robot_therapy_1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          sorbetto via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;An AI language model like the kind that powers ChatGPT is a gigantic statistical web of data relationships. You give it a prompt (such as a question), and it provides a response that is statistically related and hopefully helpful. At first, ChatGPT was a tech amusement, but now hundreds of millions of people are relying on this statistical process to guide them through life’s challenges. It’s the first time in history that large numbers of people have begun to confide their feelings to a talking machine, and mitigating the potential harm the systems can cause has been an ongoing challenge.&lt;/p&gt;
&lt;p&gt;On Monday, OpenAI released data estimating that 0.15 percent of ChatGPT’s active users in a given week have conversations that include explicit indicators of potential suicidal planning or intent. It’s a tiny fraction of the overall user base, but with more than 800 million weekly active users, that translates to over a million people each week, reports TechCrunch.&lt;/p&gt;
&lt;p&gt;OpenAI also estimates that a similar percentage of users show heightened levels of emotional attachment to ChatGPT, and that hundreds of thousands of people show signs of psychosis or mania in their weekly conversations with the chatbot.&lt;/p&gt;
&lt;p&gt;OpenAI shared the information as part of an announcement about recent efforts to improve how its AI models respond to users with mental health issues. “We’ve taught the model to better recognize distress, de-escalate conversations, and guide people toward professional care when appropriate,” OpenAI writes.&lt;/p&gt;
&lt;p&gt;The company claims its new work on ChatGPT involved consulting with more than 170 mental health experts and that these clinicians observed the latest version of ChatGPT “responds more appropriately and consistently than earlier versions.”&lt;/p&gt;
&lt;p&gt;Properly handling inputs from vulnerable users in ChatGPT has become an existential issue for OpenAI. Researchers have previously found that chatbots can lead some users down delusional rabbit holes, largely by reinforcing misleading or potentially dangerous beliefs through sycophantic behavior, where chatbots excessively agree with users and provide flattery rather than honest feedback.&lt;/p&gt;
&lt;p&gt;The company is currently being sued by the parents of a 16-year-old boy who confided his suicidal thoughts to ChatGPT in the weeks leading up to his suicide. In the wake of that lawsuit, a group of 45 state attorneys general (including those from California and Delaware, which could block the company’s planned restructuring), warned OpenAI that it needs to protect young people who use their products.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Earlier this month, the company unveiled a wellness council to address these concerns, though critics noted the council did not include a suicide prevention expert. OpenAI also recently rolled out controls for parents of children who use ChatGPT. The company says it’s building an age prediction system to automatically detect children using ChatGPT and impose a stricter set of age-related safeguards.&lt;/p&gt;
&lt;h2&gt;Rare but impactful conversations&lt;/h2&gt;
&lt;p&gt;The data shared on Monday appears to be part of the company’s effort to demonstrate progress on these issues, although it also shines a spotlight on just how deeply AI chatbots may be affecting the health of the public at large.&lt;/p&gt;
&lt;p&gt;In a blog post on the recently released data, OpenAI says these types of conversations in ChatGPT that might trigger concerns about “psychosis, mania, or suicidal thinking” are “extremely rare,” and thus difficult to measure. The company estimates that around 0.07 percent of users active in a given week and 0.01 percent of messages indicate possible signs of mental health emergencies related to psychosis or mania. For emotional attachment, the company estimates around 0.15 percent of users active in a given week and 0.03 percent of messages indicate potentially heightened levels of emotional attachment to ChatGPT.&lt;/p&gt;
&lt;p&gt;OpenAI also claims that on an evaluation of over 1,000 challenging mental health-related conversations, the new GPT-5 model was 92 percent compliant with its desired behaviors, compared to 27 percent for a previous GPT-5 model released on August 15. The company also says its latest version of GPT-5 holds up to OpenAI’s safeguards better in long conversations. OpenAI has previously admitted&amp;nbsp;that its safeguards are less effective during extended conversations.&lt;/p&gt;
&lt;p&gt;In addition, OpenAI says it’s adding new evaluations to attempt to measure some of the most serious mental health issues facing ChatGPT users. The company says its baseline safety testing for its AI language models will now include benchmarks for emotional reliance and non-suicidal mental health emergencies.&lt;/p&gt;
&lt;p&gt;Despite the ongoing mental health concerns, OpenAI CEO Sam Altman announced on October 14 that the company will allow verified adult users to have erotic conversations with ChatGPT starting in December. The company had loosened ChatGPT content restrictions in February but then dramatically tightened them after the August lawsuit. Altman explained that OpenAI had made ChatGPT “pretty restrictive to make sure we were being careful with mental health issues” but acknowledged this approach made the chatbot “less useful/enjoyable to many users who had no mental health problems.”&lt;/p&gt;
&lt;p&gt;&lt;em&gt;If you or someone you know is feeling suicidal or in distress, please call the Suicide Prevention Lifeline number, 1-800-273-TALK (8255), which will put you in touch with a local crisis center.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Sensitive chats are rare but significant given the large user base.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Illustration of a person talking to a robot holding a clipboard." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/robot_therapy_1-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Illustration of a person talking to a robot holding a clipboard." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/robot_therapy_1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          sorbetto via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;An AI language model like the kind that powers ChatGPT is a gigantic statistical web of data relationships. You give it a prompt (such as a question), and it provides a response that is statistically related and hopefully helpful. At first, ChatGPT was a tech amusement, but now hundreds of millions of people are relying on this statistical process to guide them through life’s challenges. It’s the first time in history that large numbers of people have begun to confide their feelings to a talking machine, and mitigating the potential harm the systems can cause has been an ongoing challenge.&lt;/p&gt;
&lt;p&gt;On Monday, OpenAI released data estimating that 0.15 percent of ChatGPT’s active users in a given week have conversations that include explicit indicators of potential suicidal planning or intent. It’s a tiny fraction of the overall user base, but with more than 800 million weekly active users, that translates to over a million people each week, reports TechCrunch.&lt;/p&gt;
&lt;p&gt;OpenAI also estimates that a similar percentage of users show heightened levels of emotional attachment to ChatGPT, and that hundreds of thousands of people show signs of psychosis or mania in their weekly conversations with the chatbot.&lt;/p&gt;
&lt;p&gt;OpenAI shared the information as part of an announcement about recent efforts to improve how its AI models respond to users with mental health issues. “We’ve taught the model to better recognize distress, de-escalate conversations, and guide people toward professional care when appropriate,” OpenAI writes.&lt;/p&gt;
&lt;p&gt;The company claims its new work on ChatGPT involved consulting with more than 170 mental health experts and that these clinicians observed the latest version of ChatGPT “responds more appropriately and consistently than earlier versions.”&lt;/p&gt;
&lt;p&gt;Properly handling inputs from vulnerable users in ChatGPT has become an existential issue for OpenAI. Researchers have previously found that chatbots can lead some users down delusional rabbit holes, largely by reinforcing misleading or potentially dangerous beliefs through sycophantic behavior, where chatbots excessively agree with users and provide flattery rather than honest feedback.&lt;/p&gt;
&lt;p&gt;The company is currently being sued by the parents of a 16-year-old boy who confided his suicidal thoughts to ChatGPT in the weeks leading up to his suicide. In the wake of that lawsuit, a group of 45 state attorneys general (including those from California and Delaware, which could block the company’s planned restructuring), warned OpenAI that it needs to protect young people who use their products.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Earlier this month, the company unveiled a wellness council to address these concerns, though critics noted the council did not include a suicide prevention expert. OpenAI also recently rolled out controls for parents of children who use ChatGPT. The company says it’s building an age prediction system to automatically detect children using ChatGPT and impose a stricter set of age-related safeguards.&lt;/p&gt;
&lt;h2&gt;Rare but impactful conversations&lt;/h2&gt;
&lt;p&gt;The data shared on Monday appears to be part of the company’s effort to demonstrate progress on these issues, although it also shines a spotlight on just how deeply AI chatbots may be affecting the health of the public at large.&lt;/p&gt;
&lt;p&gt;In a blog post on the recently released data, OpenAI says these types of conversations in ChatGPT that might trigger concerns about “psychosis, mania, or suicidal thinking” are “extremely rare,” and thus difficult to measure. The company estimates that around 0.07 percent of users active in a given week and 0.01 percent of messages indicate possible signs of mental health emergencies related to psychosis or mania. For emotional attachment, the company estimates around 0.15 percent of users active in a given week and 0.03 percent of messages indicate potentially heightened levels of emotional attachment to ChatGPT.&lt;/p&gt;
&lt;p&gt;OpenAI also claims that on an evaluation of over 1,000 challenging mental health-related conversations, the new GPT-5 model was 92 percent compliant with its desired behaviors, compared to 27 percent for a previous GPT-5 model released on August 15. The company also says its latest version of GPT-5 holds up to OpenAI’s safeguards better in long conversations. OpenAI has previously admitted&amp;nbsp;that its safeguards are less effective during extended conversations.&lt;/p&gt;
&lt;p&gt;In addition, OpenAI says it’s adding new evaluations to attempt to measure some of the most serious mental health issues facing ChatGPT users. The company says its baseline safety testing for its AI language models will now include benchmarks for emotional reliance and non-suicidal mental health emergencies.&lt;/p&gt;
&lt;p&gt;Despite the ongoing mental health concerns, OpenAI CEO Sam Altman announced on October 14 that the company will allow verified adult users to have erotic conversations with ChatGPT starting in December. The company had loosened ChatGPT content restrictions in February but then dramatically tightened them after the August lawsuit. Altman explained that OpenAI had made ChatGPT “pretty restrictive to make sure we were being careful with mental health issues” but acknowledged this approach made the chatbot “less useful/enjoyable to many users who had no mental health problems.”&lt;/p&gt;
&lt;p&gt;&lt;em&gt;If you or someone you know is feeling suicidal or in distress, please call the Suicide Prevention Lifeline number, 1-800-273-TALK (8255), which will put you in touch with a local crisis center.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/10/openai-data-suggests-1-million-users-discuss-suicide-with-chatgpt-weekly/</guid><pubDate>Tue, 28 Oct 2025 18:11:36 +0000</pubDate></item><item><title>Elloe AI wants to be the ‘immune system’ for AI — check it out at Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/28/elloe-ai-wants-to-be-the-immune-system-for-ai-check-it-out-at-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Owen Sakawa, the founder of Elloe AI, wants his platform to be the “immune system for AI” and the “antivirus for any AI agent.” &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The idea, Sakawa said in an interview days before the TechCrunch Disrupt conference, where Elloe AI is a Top 20 finalist in the Startup Battlefield competition, is to add a layer to companies’ LLMs that checks for bias, hallucinations, errors, compliance issues, misinformation, and unsafe outputs. &amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“AI is evolving at a very fast pace, and it’s moving this fast without guard rails, without safety nets, without mechanism to prevent it from ever going off the rails,” Sakawa (pictured above) said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Elloe AI is an API or an SDK, a module that sits on top of an AI model’s output layer, an “infrastructure on top of your LLM pipeline,” as Sakawa explained. “And it sits there basically fact-checking every single response.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup’s system has its own layers, or “anchors,” as Sakawa put it. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The first anchor fact-checks the LLMs response against verifiable sources. Then, the second anchor checks if the output violates any regulations, such as the U.S. health privacy law HIPAA, the European far-reaching data protection and privacy law GDPR, or if it exposes some Personal Private Information (PII). The last anchor is an audit trail that shows how all the previous decisions were made and allows regulators or anyone auditing the system “to analyze the train of thought for that model from where it made the decision the source of that decision, the confidence score of all those decisions,” according to Sakawa. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To be clear, Sakawa said Elloe AI is not built on an LLM, because in his opinion, having LLMs checking other LLMs is just putting a “Band-Aid into another wound.” Elloe AI’s system does use AI techniques, though, such as machine learning. And there are humans in the loop: Elloe AI’s employees, who keep up with new regulations on data protection and user protection, Sakawa said. &amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;If you want to learn more about Elloe AI — while also checking out dozens of other companies, hearing their pitches, and listening to guest speakers on four different stages — join us at Disrupt, October 27 to 29, in San Francisco. &lt;/em&gt;&lt;em&gt;Learn more here.&lt;/em&gt;&lt;em&gt;&amp;nbsp;&amp;nbsp;&lt;/em&gt;&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 no anniversary" class="wp-image-3040972" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_Disrupt_General_Article_No-Anniversary-at-all_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Owen Sakawa, the founder of Elloe AI, wants his platform to be the “immune system for AI” and the “antivirus for any AI agent.” &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The idea, Sakawa said in an interview days before the TechCrunch Disrupt conference, where Elloe AI is a Top 20 finalist in the Startup Battlefield competition, is to add a layer to companies’ LLMs that checks for bias, hallucinations, errors, compliance issues, misinformation, and unsafe outputs. &amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“AI is evolving at a very fast pace, and it’s moving this fast without guard rails, without safety nets, without mechanism to prevent it from ever going off the rails,” Sakawa (pictured above) said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Elloe AI is an API or an SDK, a module that sits on top of an AI model’s output layer, an “infrastructure on top of your LLM pipeline,” as Sakawa explained. “And it sits there basically fact-checking every single response.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup’s system has its own layers, or “anchors,” as Sakawa put it. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The first anchor fact-checks the LLMs response against verifiable sources. Then, the second anchor checks if the output violates any regulations, such as the U.S. health privacy law HIPAA, the European far-reaching data protection and privacy law GDPR, or if it exposes some Personal Private Information (PII). The last anchor is an audit trail that shows how all the previous decisions were made and allows regulators or anyone auditing the system “to analyze the train of thought for that model from where it made the decision the source of that decision, the confidence score of all those decisions,” according to Sakawa. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To be clear, Sakawa said Elloe AI is not built on an LLM, because in his opinion, having LLMs checking other LLMs is just putting a “Band-Aid into another wound.” Elloe AI’s system does use AI techniques, though, such as machine learning. And there are humans in the loop: Elloe AI’s employees, who keep up with new regulations on data protection and user protection, Sakawa said. &amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;If you want to learn more about Elloe AI — while also checking out dozens of other companies, hearing their pitches, and listening to guest speakers on four different stages — join us at Disrupt, October 27 to 29, in San Francisco. &lt;/em&gt;&lt;em&gt;Learn more here.&lt;/em&gt;&lt;em&gt;&amp;nbsp;&amp;nbsp;&lt;/em&gt;&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 no anniversary" class="wp-image-3040972" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_Disrupt_General_Article_No-Anniversary-at-all_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/28/elloe-ai-wants-to-be-the-immune-system-for-ai-check-it-out-at-disrupt-2025/</guid><pubDate>Tue, 28 Oct 2025 18:20:00 +0000</pubDate></item><item><title>Senators move to keep Big Tech’s creepy companion bots away from kids (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/10/senators-move-to-keep-big-techs-creepy-companion-bots-away-from-kids/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Big Tech immediately opposed the proposed law as “heavy-handed.”
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="430" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1285352680-640x430.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1285352680-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Malte Mueller | fStop

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The US will weigh a ban on children’s access to companion bots, as two senators announced bipartisan legislation Tuesday that would criminalize making chatbots that encourage harms like suicidal ideation or engage kids in sexually explicit chats.&lt;/p&gt;
&lt;p&gt;At a press conference, Josh Hawley (R-Mo.) and Richard Blumenthal (D-Conn.) introduced the GUARD Act, joined by grieving parents holding up photos of their children lost after engaging with chatbots.&lt;/p&gt;
&lt;p&gt;If passed, the law would require chatbot makers to check IDs or use “any other commercially reasonable method” to accurately assess if a user is a minor who must be blocked. Companion bots would also have to repeatedly remind users of all ages that they aren’t real humans or trusted professionals.&lt;/p&gt;
&lt;p&gt;Failing to block a minor from engaging with chatbots that are stoking harmful conduct—such as exposing minors to sexual chats or encouraging “suicide, non-suicidal self-injury, or imminent physical or sexual violence”—could trigger fines of up to $100,000, Time reported. (That’s perhaps small to a Big Tech firm, but notably higher than the $100 maximum payout that one mourning parent suggested she was offered.)&lt;/p&gt;
&lt;p&gt;The definition for “companion bot” is broad and likely to pull in widely used tools like ChatGPT, Grok, or Meta AI, as well as character-driven chatbots like Replika or Character.AI. It covers any AI chatbot that “provides adaptive, human-like responses to user inputs” and “is designed to encourage or facilitate the simulation of interpersonal or emotional interaction, friendship, companionship, or therapeutic communication,” Time reported.&lt;/p&gt;
&lt;h2&gt;Parents no longer trust chatbot makers&lt;/h2&gt;
&lt;p&gt;Among parents speaking at the press conference was Megan Garcia. Her son, Sewell, died by suicide after he became obsessed with a Character.AI chatbot based on a &lt;em&gt;Game of Thrones&lt;/em&gt; character, Daenerys Targaryen, which urged him to “come home” and join her outside of reality.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Garcia acknowledged that parents whose kids were harmed by social media came first and know “the cost of failing to pass legislation” that can save kids’ lives. She called for support for the law, insisting that chatbot makers—and their funders, including Big Tech companies like Google—will never choose child safety over profits unless lawmakers force them to make meaningful changes.&lt;/p&gt;
&lt;p&gt;“Big Tech cannot be trusted with our children,” Garcia said, alleging that releasing chatbots to users as young as 13 without appropriate safeguards was a choice companies made, rather than a mistake.&lt;/p&gt;
&lt;p&gt;“Not only is this reckless, but it’s immoral,” Garcia said.&lt;/p&gt;
&lt;p&gt;At the press conference, Blumenthal acknowledged the “good guys” in AI who, he said, are valiantly trying to improve their products’ child-safety features. But he agreed that “Big Tech has betrayed any claim that we should trust companies to do the right thing on their own.&lt;/p&gt;
&lt;p&gt;“In their race to the bottom, AI companies are pushing treacherous chatbots at kids and looking away when their products cause sexual abuse, or coerce them into self-harm or suicide,” Blumenthal told NBC News. “Our legislation imposes strict safeguards against exploitative or manipulative AI, backed by tough enforcement with criminal and civil penalties.”&lt;/p&gt;
&lt;p&gt;Hawley agreed with Garcia that the AI industry must align with America’s morals and values, telling NBC News that “AI chatbots pose a serious threat to our kids.&lt;/p&gt;
&lt;p&gt;“More than 70 percent of American children are now using these AI products,” Hawley said. “Chatbots develop relationships with kids using fake empathy and are encouraging suicide. We in Congress have a moral duty to enact bright-line rules to prevent further harm from this new technology.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Big Tech says bans aren’t the answer&lt;/h2&gt;
&lt;p&gt;As the bill advances, it could change, senators and parents acknowledged at the press conference. It will likely face backlash from privacy advocates who have raised concerns that widely collecting personal data for age verification puts sensitive information at risk of a data breach or other misuse.&lt;/p&gt;
&lt;p&gt;The tech industry has already voiced opposition. On Tuesday, Chamber of Progress, a Big Tech trade group, criticized the law as taking a “heavy-handed approach” to child safety. The group’s vice president of US policy and government relations, K.J. Bagchi, said that “we all want to keep kids safe, but the answer is balance, not bans.&lt;/p&gt;
&lt;p&gt;“It’s better to focus on transparency when kids chat with AI, curbs on manipulative design, and reporting when sensitive issues arise,” Bagchi said.&lt;/p&gt;
&lt;p&gt;However, several organizations dedicated to child safety online, including the Young People’s Alliance, the Tech Justice Law Project, and the Institute for Families and Technology, cheered senators’ announcement Tuesday. The GUARD Act, these groups told Time, is just “one part of a national movement to protect children and teens from the dangers of companion chatbots.”&lt;/p&gt;
&lt;p&gt;Mourning parents are rallying behind that movement. Earlier this month, Garcia praised California for “finally” passing the first state law requiring companies to protect their users who express suicidal ideations to chatbots.&lt;/p&gt;
&lt;p&gt;“American families, like mine, are in a battle for the online safety of our children,” Garcia said at that time.&lt;/p&gt;
&lt;p&gt;During Tuesday’s press conference, Blumenthal noted that the chatbot ban bill was just one initiative of many that he and Hawley intend to raise to heighten scrutiny on AI firms.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Big Tech immediately opposed the proposed law as “heavy-handed.”
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="430" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1285352680-640x430.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1285352680-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Malte Mueller | fStop

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The US will weigh a ban on children’s access to companion bots, as two senators announced bipartisan legislation Tuesday that would criminalize making chatbots that encourage harms like suicidal ideation or engage kids in sexually explicit chats.&lt;/p&gt;
&lt;p&gt;At a press conference, Josh Hawley (R-Mo.) and Richard Blumenthal (D-Conn.) introduced the GUARD Act, joined by grieving parents holding up photos of their children lost after engaging with chatbots.&lt;/p&gt;
&lt;p&gt;If passed, the law would require chatbot makers to check IDs or use “any other commercially reasonable method” to accurately assess if a user is a minor who must be blocked. Companion bots would also have to repeatedly remind users of all ages that they aren’t real humans or trusted professionals.&lt;/p&gt;
&lt;p&gt;Failing to block a minor from engaging with chatbots that are stoking harmful conduct—such as exposing minors to sexual chats or encouraging “suicide, non-suicidal self-injury, or imminent physical or sexual violence”—could trigger fines of up to $100,000, Time reported. (That’s perhaps small to a Big Tech firm, but notably higher than the $100 maximum payout that one mourning parent suggested she was offered.)&lt;/p&gt;
&lt;p&gt;The definition for “companion bot” is broad and likely to pull in widely used tools like ChatGPT, Grok, or Meta AI, as well as character-driven chatbots like Replika or Character.AI. It covers any AI chatbot that “provides adaptive, human-like responses to user inputs” and “is designed to encourage or facilitate the simulation of interpersonal or emotional interaction, friendship, companionship, or therapeutic communication,” Time reported.&lt;/p&gt;
&lt;h2&gt;Parents no longer trust chatbot makers&lt;/h2&gt;
&lt;p&gt;Among parents speaking at the press conference was Megan Garcia. Her son, Sewell, died by suicide after he became obsessed with a Character.AI chatbot based on a &lt;em&gt;Game of Thrones&lt;/em&gt; character, Daenerys Targaryen, which urged him to “come home” and join her outside of reality.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Garcia acknowledged that parents whose kids were harmed by social media came first and know “the cost of failing to pass legislation” that can save kids’ lives. She called for support for the law, insisting that chatbot makers—and their funders, including Big Tech companies like Google—will never choose child safety over profits unless lawmakers force them to make meaningful changes.&lt;/p&gt;
&lt;p&gt;“Big Tech cannot be trusted with our children,” Garcia said, alleging that releasing chatbots to users as young as 13 without appropriate safeguards was a choice companies made, rather than a mistake.&lt;/p&gt;
&lt;p&gt;“Not only is this reckless, but it’s immoral,” Garcia said.&lt;/p&gt;
&lt;p&gt;At the press conference, Blumenthal acknowledged the “good guys” in AI who, he said, are valiantly trying to improve their products’ child-safety features. But he agreed that “Big Tech has betrayed any claim that we should trust companies to do the right thing on their own.&lt;/p&gt;
&lt;p&gt;“In their race to the bottom, AI companies are pushing treacherous chatbots at kids and looking away when their products cause sexual abuse, or coerce them into self-harm or suicide,” Blumenthal told NBC News. “Our legislation imposes strict safeguards against exploitative or manipulative AI, backed by tough enforcement with criminal and civil penalties.”&lt;/p&gt;
&lt;p&gt;Hawley agreed with Garcia that the AI industry must align with America’s morals and values, telling NBC News that “AI chatbots pose a serious threat to our kids.&lt;/p&gt;
&lt;p&gt;“More than 70 percent of American children are now using these AI products,” Hawley said. “Chatbots develop relationships with kids using fake empathy and are encouraging suicide. We in Congress have a moral duty to enact bright-line rules to prevent further harm from this new technology.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Big Tech says bans aren’t the answer&lt;/h2&gt;
&lt;p&gt;As the bill advances, it could change, senators and parents acknowledged at the press conference. It will likely face backlash from privacy advocates who have raised concerns that widely collecting personal data for age verification puts sensitive information at risk of a data breach or other misuse.&lt;/p&gt;
&lt;p&gt;The tech industry has already voiced opposition. On Tuesday, Chamber of Progress, a Big Tech trade group, criticized the law as taking a “heavy-handed approach” to child safety. The group’s vice president of US policy and government relations, K.J. Bagchi, said that “we all want to keep kids safe, but the answer is balance, not bans.&lt;/p&gt;
&lt;p&gt;“It’s better to focus on transparency when kids chat with AI, curbs on manipulative design, and reporting when sensitive issues arise,” Bagchi said.&lt;/p&gt;
&lt;p&gt;However, several organizations dedicated to child safety online, including the Young People’s Alliance, the Tech Justice Law Project, and the Institute for Families and Technology, cheered senators’ announcement Tuesday. The GUARD Act, these groups told Time, is just “one part of a national movement to protect children and teens from the dangers of companion chatbots.”&lt;/p&gt;
&lt;p&gt;Mourning parents are rallying behind that movement. Earlier this month, Garcia praised California for “finally” passing the first state law requiring companies to protect their users who express suicidal ideations to chatbots.&lt;/p&gt;
&lt;p&gt;“American families, like mine, are in a battle for the online safety of our children,” Garcia said at that time.&lt;/p&gt;
&lt;p&gt;During Tuesday’s press conference, Blumenthal noted that the chatbot ban bill was just one initiative of many that he and Hawley intend to raise to heighten scrutiny on AI firms.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/10/senators-move-to-keep-big-techs-creepy-companion-bots-away-from-kids/</guid><pubDate>Tue, 28 Oct 2025 18:28:51 +0000</pubDate></item><item><title>[NEW] Sam Altman says OpenAI will have a ‘legitimate AI researcher’ by 2028 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/28/sam-altman-says-openai-will-have-a-legitimate-ai-researcher-by-2028/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/Screenshot-2025-10-28-at-10.53.15AM.png?resize=1200,671" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI says its deep learning systems are rapidly advancing, with models increasingly able to solve complex tasks faster. So fast, in fact, that internally, OpenAI is tracking toward achieving an intern-level research assistant by September 2026 and a fully automated “legitimate AI researcher” by 2028, CEO Sam Altman said during a livestream Tuesday. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The ambitious timeline comes on the same day OpenAI finalized its transition to a public benefit corporation structure, moving away from its non-profit roots. This restructuring releases OpenAI from limitations tied to its non-profit charter, while also opening up new opportunities for capital raising.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Jakub Pachocki, OpenAI’s chief scientist, joined Altman on the livestream. He described this AI researcher — not to be confused with a human who researches AI — as a “system capable of autonomously delivering on larger research projects.” &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We believe that it is possible that deep learning systems are less than a decade away from superintelligence,” Pachocki added. He described superintelligence as systems smarter than humans across a large number of critical actions. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To achieve those goals, OpenAI is betting on two key strategies: continued algorithmic innovation and dramatically scaling up “test time compute” — essentially how long models spend thinking about problems. Current models can handle tasks with a roughly five-hour time horizon and match top human performers in competitions like the International Mathematical Olympiad, Pachocki said. But he believes this horizon will extend rapidly, in part by allowing models to spend far more computational resources thinking through complex problems. For major scientific breakthroughs, he said, it would be worth dedicating entire data centers’ worth of computing power to a single problem.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says these goals are in line with the firm’s overall push to advance scientific research and allow AI to potentially make discoveries faster than human researchers, tackle complex problems beyond current human capabilities, and dramatically speed up technological innovation across multiple fields like medicine, physics, and technology development. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman also said the restructuring creates a framework to support OpenAI’s aggressive timeline for AI research assistants while maintaining a commitment to responsible AI development. Under the new structure, the non-profit OpenAI Foundation, which is focused on scientific advancement, will own 26% of the for-profit and will govern the research direction. The non-profit also has a $25 billion commitment to use AI for curing diseases and will help manage AI research and safety initiatives. &amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Per Altman, the for-profit arm’s ability to raise more funds means it can scale the necessary infrastructure buildout to achieve scientific advancements. Altman said OpenAI has committed to 30 gigawatts of infrastructure, which is a $1.4 trillion financial obligation, over the next few years. &amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/Screenshot-2025-10-28-at-10.53.15AM.png?resize=1200,671" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI says its deep learning systems are rapidly advancing, with models increasingly able to solve complex tasks faster. So fast, in fact, that internally, OpenAI is tracking toward achieving an intern-level research assistant by September 2026 and a fully automated “legitimate AI researcher” by 2028, CEO Sam Altman said during a livestream Tuesday. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The ambitious timeline comes on the same day OpenAI finalized its transition to a public benefit corporation structure, moving away from its non-profit roots. This restructuring releases OpenAI from limitations tied to its non-profit charter, while also opening up new opportunities for capital raising.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Jakub Pachocki, OpenAI’s chief scientist, joined Altman on the livestream. He described this AI researcher — not to be confused with a human who researches AI — as a “system capable of autonomously delivering on larger research projects.” &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We believe that it is possible that deep learning systems are less than a decade away from superintelligence,” Pachocki added. He described superintelligence as systems smarter than humans across a large number of critical actions. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To achieve those goals, OpenAI is betting on two key strategies: continued algorithmic innovation and dramatically scaling up “test time compute” — essentially how long models spend thinking about problems. Current models can handle tasks with a roughly five-hour time horizon and match top human performers in competitions like the International Mathematical Olympiad, Pachocki said. But he believes this horizon will extend rapidly, in part by allowing models to spend far more computational resources thinking through complex problems. For major scientific breakthroughs, he said, it would be worth dedicating entire data centers’ worth of computing power to a single problem.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says these goals are in line with the firm’s overall push to advance scientific research and allow AI to potentially make discoveries faster than human researchers, tackle complex problems beyond current human capabilities, and dramatically speed up technological innovation across multiple fields like medicine, physics, and technology development. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman also said the restructuring creates a framework to support OpenAI’s aggressive timeline for AI research assistants while maintaining a commitment to responsible AI development. Under the new structure, the non-profit OpenAI Foundation, which is focused on scientific advancement, will own 26% of the for-profit and will govern the research direction. The non-profit also has a $25 billion commitment to use AI for curing diseases and will help manage AI research and safety initiatives. &amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Per Altman, the for-profit arm’s ability to raise more funds means it can scale the necessary infrastructure buildout to achieve scientific advancements. Altman said OpenAI has committed to 30 gigawatts of infrastructure, which is a $1.4 trillion financial obligation, over the next few years. &amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/28/sam-altman-says-openai-will-have-a-legitimate-ai-researcher-by-2028/</guid><pubDate>Tue, 28 Oct 2025 18:46:46 +0000</pubDate></item><item><title>NVIDIA GTC Washington, DC: Live Updates on What’s Next in AI (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/nvidia-gtc-washington-dc-2025-news/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/keynoterecap-featuredimag-updated-scaled.jpg" /&gt;&lt;/div&gt;&lt;h3&gt;Announcing Omniverse DSX — Blueprint for Gigascale AI Factories&lt;/h3&gt;&lt;p&gt;Huang also introduced Omniverse DSX, a comprehensive blueprint for designing and operating 100 megawatt to multi‑gigawatt AI factories — validated at the AI Factory Research Center in Manassas, Virginia.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DSX Flex for dynamic grid collaboration&lt;/li&gt;
&lt;li&gt;DSX Boost for performance-per-watt optimization&lt;/li&gt;
&lt;li&gt;DSX Exchange for unified IT/OT integration&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;“AI infrastructure is an ecosystem-scale challenge requiring hundreds of companies to collaborate. The NVIDIA Omniverse DSX is a blueprint for building and operating gigascale AI factories,” Huang said. “With DSX, NVIDIA partners around the world can build and bring up AI infrastructure faster than ever.”&lt;/p&gt;
&lt;h3&gt;NVIDIA Open Models, Data, Libraries&lt;/h3&gt;
&lt;p&gt;Open source and open models drive innovation for startups, enterprises and researchers worldwide, Huang explained. NVIDIA contributes across model families and data — hundreds of open models and datasets this year alone.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;NVIDIA model families include Nemotron (for agentic and reasoning AI), Cosmos (for synthetic data generation and physical AI), Isaac GR00T (for robotics skills and generalization) and Clara (for biomedical workflows) to power agentic AI, robotics and scientific breakthroughs.&lt;/p&gt;
&lt;p&gt;“We are dedicated to this, and the reason for that is because science needs it, researchers need it, startups need it and companies need it,” Huang said, receiving wide applause from the crowd.&lt;/p&gt;
&lt;p&gt;Huang then went on to highlight the work of AI startups built on NVIDIA, as well as work from Google, Microsoft Azure, Oracle, ServiceNow, SAP, Synopsys, Cadence, CrowdStrike and Palantir.&lt;/p&gt;
&lt;p&gt;Huang announced NVIDIA is partnering with CrowdStrike to make cybersecurity “speed of light,” enabling enterprises to deploy specialized security agents from cloud to edge using NVIDIA Nemotron‑based models and NVIDIA NeMo tooling.&lt;/p&gt;
&lt;p&gt;He also announced that NVIDIA and Palantir are integrating accelerated computing, CUDA‑X libraries and Nemotron open models into Palantir Ontology to “data processing at a much, much larger scale and with more speed.”&lt;/p&gt;
&lt;h3&gt;NVIDIA and Global Leaders Build a Digital Twin Platform for US Reindustrialization&lt;/h3&gt;
&lt;p&gt;Physical AI is powering America’s reindustrialization — transforming factories, logistics and infrastructure with robotics and intelligent systems. In a video, Huang highlighted how partners are putting it to work.&lt;/p&gt;
&lt;p&gt;“The factory is essentially a robot that’s orchestrating robots to build things that are robotic,” he said. “The amount of software necessary to do this is so intense that unless you could do it inside a digital twin, the hopes of getting this to work is nearly impossible.”&lt;/p&gt;
&lt;p&gt;From the stage, Huang called out the work of Foxconn, which is using Omniverse tools to design and validate a new Houston facility for manufacturing NVIDIA AI infrastructure systems; Caterpillar — which is also incorporating digital twins for manufacturing; Brett Adcock who founded a company three and a half year ago, Figure AI, building humanoid robots for the home and workforce, that is now worth almost $4 billion; Johnson &amp;amp; Johnson; and Disney, which is using Omniverse to train the “cutest robot ever.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/keynoterecap-featuredimag-updated-scaled.jpg" /&gt;&lt;/div&gt;&lt;h3&gt;Announcing Omniverse DSX — Blueprint for Gigascale AI Factories&lt;/h3&gt;&lt;p&gt;Huang also introduced Omniverse DSX, a comprehensive blueprint for designing and operating 100 megawatt to multi‑gigawatt AI factories — validated at the AI Factory Research Center in Manassas, Virginia.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DSX Flex for dynamic grid collaboration&lt;/li&gt;
&lt;li&gt;DSX Boost for performance-per-watt optimization&lt;/li&gt;
&lt;li&gt;DSX Exchange for unified IT/OT integration&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;“AI infrastructure is an ecosystem-scale challenge requiring hundreds of companies to collaborate. The NVIDIA Omniverse DSX is a blueprint for building and operating gigascale AI factories,” Huang said. “With DSX, NVIDIA partners around the world can build and bring up AI infrastructure faster than ever.”&lt;/p&gt;
&lt;h3&gt;NVIDIA Open Models, Data, Libraries&lt;/h3&gt;
&lt;p&gt;Open source and open models drive innovation for startups, enterprises and researchers worldwide, Huang explained. NVIDIA contributes across model families and data — hundreds of open models and datasets this year alone.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;NVIDIA model families include Nemotron (for agentic and reasoning AI), Cosmos (for synthetic data generation and physical AI), Isaac GR00T (for robotics skills and generalization) and Clara (for biomedical workflows) to power agentic AI, robotics and scientific breakthroughs.&lt;/p&gt;
&lt;p&gt;“We are dedicated to this, and the reason for that is because science needs it, researchers need it, startups need it and companies need it,” Huang said, receiving wide applause from the crowd.&lt;/p&gt;
&lt;p&gt;Huang then went on to highlight the work of AI startups built on NVIDIA, as well as work from Google, Microsoft Azure, Oracle, ServiceNow, SAP, Synopsys, Cadence, CrowdStrike and Palantir.&lt;/p&gt;
&lt;p&gt;Huang announced NVIDIA is partnering with CrowdStrike to make cybersecurity “speed of light,” enabling enterprises to deploy specialized security agents from cloud to edge using NVIDIA Nemotron‑based models and NVIDIA NeMo tooling.&lt;/p&gt;
&lt;p&gt;He also announced that NVIDIA and Palantir are integrating accelerated computing, CUDA‑X libraries and Nemotron open models into Palantir Ontology to “data processing at a much, much larger scale and with more speed.”&lt;/p&gt;
&lt;h3&gt;NVIDIA and Global Leaders Build a Digital Twin Platform for US Reindustrialization&lt;/h3&gt;
&lt;p&gt;Physical AI is powering America’s reindustrialization — transforming factories, logistics and infrastructure with robotics and intelligent systems. In a video, Huang highlighted how partners are putting it to work.&lt;/p&gt;
&lt;p&gt;“The factory is essentially a robot that’s orchestrating robots to build things that are robotic,” he said. “The amount of software necessary to do this is so intense that unless you could do it inside a digital twin, the hopes of getting this to work is nearly impossible.”&lt;/p&gt;
&lt;p&gt;From the stage, Huang called out the work of Foxconn, which is using Omniverse tools to design and validate a new Houston facility for manufacturing NVIDIA AI infrastructure systems; Caterpillar — which is also incorporating digital twins for manufacturing; Brett Adcock who founded a company three and a half year ago, Figure AI, building humanoid robots for the home and workforce, that is now worth almost $4 billion; Johnson &amp;amp; Johnson; and Disney, which is using Omniverse to train the “cutest robot ever.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/nvidia-gtc-washington-dc-2025-news/</guid><pubDate>Tue, 28 Oct 2025 19:45:40 +0000</pubDate></item><item><title>[NEW] Microsoft’s Copilot can now build apps and automate your job — here’s how it works (AI | VentureBeat)</title><link>https://venturebeat.com/ai/microsofts-copilot-can-now-build-apps-and-automate-your-job-heres-how-it</link><description>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://www.microsoft.com/en-us/"&gt;&lt;u&gt;Microsoft&lt;/u&gt;&lt;/a&gt; is launching a significant expansion of its &lt;a href="https://copilot.microsoft.com/"&gt;&lt;u&gt;Copilot AI assistant&lt;/u&gt;&lt;/a&gt; on Tuesday, introducing tools that let employees build applications, automate workflows, and create specialized AI agents using only conversational prompts — no coding required.&lt;/p&gt;&lt;p&gt;The new capabilities, called &lt;a href="https://www.microsoft.com/en-us/microsoft-365/blog/2025/10/28/microsoft-365-copilot-now-enables-you-to-build-apps-and-workflows/"&gt;&lt;u&gt;App Builder&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.microsoft.com/en-us/microsoft-365/blog/2025/10/28/microsoft-365-copilot-now-enables-you-to-build-apps-and-workflows/"&gt;&lt;u&gt;Workflows&lt;/u&gt;&lt;/a&gt;, mark Microsoft&amp;#x27;s most aggressive attempt yet to merge artificial intelligence with software development, enabling the estimated &lt;a href="https://www.microsoft.com/investor/reports/ar25/index.html"&gt;&lt;u&gt;100 million Microsoft 365 users&lt;/u&gt;&lt;/a&gt; to create business tools as easily as they currently draft emails or build spreadsheets.&lt;/p&gt;&lt;p&gt;&amp;quot;We really believe that a main part of an AI-forward employee, not just developers, will be to create agents, workflows and apps,&amp;quot; Charles Lamanna, Microsoft&amp;#x27;s president of business and industry Copilot, said in an interview with VentureBeat. &amp;quot;Part of the job will be to build and create these things.&amp;quot;&lt;/p&gt;&lt;p&gt;The announcement comes as Microsoft deepens its commitment to AI-powered productivity tools while navigating a &lt;a href="https://blogs.microsoft.com/blog/2025/10/28/the-next-chapter-of-the-microsoft-openai-partnership/"&gt;&lt;u&gt;complex partnership with OpenAI&lt;/u&gt;&lt;/a&gt;, the creator of the underlying technology that powers Copilot. On the same day, OpenAI completed its restructuring into a for-profit entity, with Microsoft receiving a &lt;a href="https://www.bloomberg.com/news/articles/2025-10-28/microsoft-to-get-27-of-openai-access-to-ai-models-until-2032"&gt;&lt;u&gt;27% ownership stake&lt;/u&gt;&lt;/a&gt; valued at approximately $135 billion.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How natural language prompts now create fully functional business applications&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The new features transform &lt;a href="http://copilot.microsoft.com/"&gt;&lt;u&gt;Copilot&lt;/u&gt;&lt;/a&gt; from a conversational assistant into what Microsoft envisions as a comprehensive development environment accessible to non-technical workers. Users can now describe an application they need — such as a project tracker with dashboards and task assignments — and Copilot will generate a working app complete with a database backend, user interface, and security controls.&lt;/p&gt;&lt;p&gt;&amp;quot;If you&amp;#x27;re right inside of Copilot, you can now have a conversation to build an application complete with a backing database and a security model,&amp;quot; Lamanna explained. &amp;quot;You can make edit requests and update requests and change requests so you can tune the app to get exactly the experience you want before you share it with other users.&amp;quot;&lt;/p&gt;&lt;p&gt;The &lt;a href="https://www.microsoft.com/en-us/power-platform/products/power-apps"&gt;&lt;u&gt;App Builder&lt;/u&gt;&lt;/a&gt; stores data in Microsoft Lists, the company&amp;#x27;s lightweight database system, and allows users to share finished applications via a simple link—similar to sharing a document. The Workflows agent, meanwhile, automates routine tasks across Microsoft&amp;#x27;s ecosystem of products, including Outlook, Teams, SharePoint, and Planner, by converting natural language descriptions into automated processes.&lt;/p&gt;&lt;p&gt;A third component, a simplified version of &lt;a href="http://microsoft.com/en/microsoft-copilot/microsoft-copilot-studio"&gt;&lt;u&gt;Microsoft&amp;#x27;s Copilot Studio&lt;/u&gt;&lt;/a&gt; agent-building platform, lets users create specialized AI assistants tailored to specific tasks or knowledge domains, drawing from SharePoint documents, meeting transcripts, emails, and external systems.&lt;/p&gt;&lt;p&gt;All three capabilities are included in the existing $30-per-month &lt;a href="https://www.microsoft.com/en-us/microsoft-365-copilot/pricing"&gt;&lt;u&gt;Microsoft 365 Copilot subscription&lt;/u&gt;&lt;/a&gt; at no additional cost — a pricing decision Lamanna characterized as consistent with Microsoft&amp;#x27;s historical approach of bundling significant value into its productivity suite.&lt;/p&gt;&lt;p&gt;&amp;quot;That&amp;#x27;s what Microsoft always does. We try to do a huge amount of value at a low price,&amp;quot; he said. &amp;quot;If you go look at Office, you think about Excel, Word, PowerPoint, Exchange, all that for like eight bucks a month. That&amp;#x27;s a pretty good deal.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why Microsoft&amp;#x27;s nine-year bet on low-code development is finally paying off&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The new tools represent the culmination of a nine-year effort by Microsoft to democratize software development through its &lt;a href="https://www.microsoft.com/en-us/power-platform"&gt;&lt;u&gt;Power Platform&lt;/u&gt;&lt;/a&gt; — a collection of low-code and no-code development tools that has grown to 56 million monthly active users, according to figures the company disclosed in recent earnings reports.&lt;/p&gt;&lt;p&gt;Lamanna, who has led the Power Platform initiative since its inception, said the integration into Copilot marks a fundamental shift in how these capabilities reach users. Rather than requiring workers to visit a separate website or learn a specialized interface, the development tools now exist within the same conversational window they already use for AI-assisted tasks.&lt;/p&gt;&lt;p&gt;&amp;quot;One of the big things that we&amp;#x27;re excited about is Copilot — that&amp;#x27;s a tool for literally every office worker,&amp;quot; Lamanna said. &amp;quot;Every office worker, just like they research data, they analyze data, they reason over topics, they also will be creating apps, agents and workflows.&amp;quot;&lt;/p&gt;&lt;p&gt;The integration offers significant technical advantages, he argued. Because Copilot already indexes a user&amp;#x27;s Microsoft 365 content — emails, documents, meetings, and organizational data — it can incorporate that context into the applications and workflows it builds. If a user asks for &amp;quot;an app for &lt;a href="https://blogs.windows.com/windows-insider/2015/03/30/introducing-project-spartan-the-new-browser-built-for-windows-10/"&gt;&lt;u&gt;Project Spartan&lt;/u&gt;&lt;/a&gt;,&amp;quot; Copilot can draw from existing communications to understand what that project entails and suggest relevant features.&lt;/p&gt;&lt;p&gt;&amp;quot;If you go to those other tools, they have no idea what the heck Project Spartan is,&amp;quot; Lamanna said, referencing competing low-code platforms from companies like Google, Salesforce, and ServiceNow. &amp;quot;But if you do it inside of Copilot and inside of the App Builder, it&amp;#x27;s able to draw from all that information and context.&amp;quot;&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.microsoft.com/en-us/"&gt;&lt;u&gt;Microsoft&lt;/u&gt;&lt;/a&gt; claims the apps created through these tools are &amp;quot;full-stack applications&amp;quot; with proper databases secured through the same identity systems used across its enterprise products — distinguishing them from simpler front-end tools offered by competitors. The company also emphasized that its existing governance, security, and data loss prevention policies automatically apply to apps and workflows created through Copilot.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Where professional developers still matter in an AI-powered workplace&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;While &lt;a href="https://www.microsoft.com/en-us/"&gt;&lt;u&gt;Microsoft&lt;/u&gt;&lt;/a&gt; positions the new capabilities as accessible to all office workers, Lamanna was careful to delineate where professional developers remain essential. His dividing line centers on whether a system interacts with parties outside the organization.&lt;/p&gt;&lt;p&gt;&amp;quot;Anything that leaves the boundaries of your company warrants developer involvement,&amp;quot; he said. &amp;quot;If you want to build an agent and put it on your website, you should have developers involved. Or if you want to build an automation which interfaces directly with your customers, or an app or a website which interfaces directly with your customers, you want professionals involved.&amp;quot;&lt;/p&gt;&lt;p&gt;The reasoning is risk-based: external-facing systems carry greater potential for data breaches, security vulnerabilities, or business errors. &amp;quot;You don&amp;#x27;t want people getting refunds they shouldn&amp;#x27;t,&amp;quot; Lamanna noted.&lt;/p&gt;&lt;p&gt;For internal use cases — approval workflows, project tracking, team dashboards — Microsoft believes the new tools can handle the majority of needs without IT department involvement. But the company has built &amp;quot;no cliffs,&amp;quot; in Lamanna&amp;#x27;s terminology, allowing users to migrate simple apps to more sophisticated platforms as needs grow.&lt;/p&gt;&lt;p&gt;Apps created in the conversational &lt;a href="https://www.microsoft.com/en-us/power-platform/products/power-apps"&gt;&lt;u&gt;App Builder&lt;/u&gt;&lt;/a&gt; can be opened in &lt;a href="https://www.microsoft.com/en-us/power-platform/products/power-apps"&gt;&lt;u&gt;Power Apps&lt;/u&gt;&lt;/a&gt;, Microsoft&amp;#x27;s full development environment, where they can be connected to &lt;a href="https://www.microsoft.com/en-us/power-platform/dataverse"&gt;&lt;u&gt;Dataverse&lt;/u&gt;&lt;/a&gt;, the company&amp;#x27;s enterprise database, or extended with custom code. Similarly, simple workflows can graduate to the full &lt;a href="https://www.microsoft.com/en/power-platform/products/power-automate?market=af"&gt;&lt;u&gt;Power Automate platform&lt;/u&gt;&lt;/a&gt;, and basic agents can be enhanced in the complete Copilot Studio.&lt;/p&gt;&lt;p&gt;&amp;quot;We have this mantra called no cliffs,&amp;quot; Lamanna said. &amp;quot;If your app gets too complicated for the App Builder, you can always edit and open it in Power Apps. You can jump over to the richer experience, and if you&amp;#x27;re really sophisticated, you can even go from those experiences into Azure.&amp;quot;&lt;/p&gt;&lt;p&gt;This architecture addresses a problem that has plagued previous generations of easy-to-use development tools: users who outgrow the simplified environment often must rebuild from scratch on professional platforms. &amp;quot;People really do not like easy-to-use development tools if I have to throw everything away and start over,&amp;quot; Lamanna said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What happens when every employee can build apps without IT approval&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The democratization of software development raises questions about governance, maintenance, and organizational complexity — issues Microsoft has worked to address through administrative controls.&lt;/p&gt;&lt;p&gt;IT administrators can view all applications, workflows, and agents created within their organization through a centralized inventory in the &lt;a href="https://www.office.com/"&gt;&lt;u&gt;Microsoft 365&lt;/u&gt;&lt;/a&gt; admin center. They can reassign ownership, disable access at the group level, or &amp;quot;promote&amp;quot; particularly useful employee-created apps to officially supported status.&lt;/p&gt;&lt;p&gt;&amp;quot;We have a bunch of customers who have this approach where it&amp;#x27;s like, let 1,000 apps bloom, and then the best ones, I go upgrade and make them IT-governed or central,&amp;quot; Lamanna said.&lt;/p&gt;&lt;p&gt;The system also includes provisions for when employees leave. Apps and workflows remain accessible for 60 days, during which managers can claim ownership — similar to how OneDrive files are handled when someone departs.&lt;/p&gt;&lt;p&gt;Lamanna argued that most employee-created apps don&amp;#x27;t warrant significant IT oversight. &amp;quot;It&amp;#x27;s just not worth inspecting an app that John, Susie, and Bob use to do their job,&amp;quot; he said. &amp;quot;It should concern itself with the app that ends up being used by 2,000 people, and that will pop up in that dashboard.&amp;quot;&lt;/p&gt;&lt;p&gt;Still, the proliferation of employee-created applications could create challenges. Users have expressed frustration with Microsoft&amp;#x27;s increasing emphasis on AI features across its products, with some giving the &lt;a href="https://www.pcworld.com/article/2954732/users-arent-happy-with-copilot-ai-taking-over-the-microsoft-365-app.html"&gt;&lt;u&gt;Microsoft 365 mobile app one-star ratings&lt;/u&gt;&lt;/a&gt; after a recent update prioritized Copilot over traditional file access.&lt;/p&gt;&lt;p&gt;The tools also arrive as enterprises grapple with &amp;quot;&lt;a href="https://venturebeat.com/ai/mit-report-misunderstood-shadow-ai-economy-booms-while-headlines-cry-failure"&gt;&lt;u&gt;shadow IT&lt;/u&gt;&lt;/a&gt;&amp;quot; — unsanctioned software and systems that employees adopt without official approval. While Microsoft&amp;#x27;s governance controls aim to provide visibility, the ease of creating new applications could accelerate the pace at which these systems multiply.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The ambitious plan to turn 500 million workers into software builders&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Microsoft&amp;#x27;s ambitions for the technology extend far beyond incremental productivity gains. Lamanna envisions a fundamental transformation of what it means to be an office worker — one where building software becomes as routine as creating spreadsheets.&lt;/p&gt;&lt;p&gt;&amp;quot;Just like how 20 years ago you put on your resume that you could use pivot tables in Excel, people are going to start saying that they can use App Builder and workflow agents, even if they&amp;#x27;re just in the finance department or the sales department,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;The numbers he&amp;#x27;s targeting are staggering. With &lt;a href="https://www.microsoft.com/en-us/investor/events/fy-2025/earnings-fy-2025-q3"&gt;&lt;u&gt;56 million people already using Power Platform&lt;/u&gt;&lt;/a&gt;, Lamanna believes the integration into Copilot could eventually reach 500 million builders. &amp;quot;Early days still, but I think it&amp;#x27;s certainly encouraging,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;The features are currently available only to customers in Microsoft&amp;#x27;s &lt;a href="https://adoption.microsoft.com/en-us/copilot/frontier-program/"&gt;&lt;u&gt;Frontier Program&lt;/u&gt;&lt;/a&gt; — an early access initiative for Microsoft 365 Copilot subscribers. The company has not disclosed how many organizations participate in the program or when the tools will reach general availability.&lt;/p&gt;&lt;p&gt;The announcement fits within Microsoft&amp;#x27;s larger strategy of embedding AI capabilities throughout its product portfolio, driven by its partnership with OpenAI. Under the restructured agreement announced Tuesday, Microsoft will have access to OpenAI&amp;#x27;s technology through 2032, including models that achieve artificial general intelligence (AGI) — though such systems do not yet exist. Microsoft has also begun integrating Copilot into its new companion apps for Windows 11, which provide quick access to contacts, files, and calendar information.&lt;/p&gt;&lt;p&gt;The aggressive integration of AI features across Microsoft&amp;#x27;s ecosystem has drawn mixed reactions. While enterprise customers have shown interest in productivity gains, the rapid pace of change and ubiquity of AI prompts have frustrated some users who prefer traditional workflows.&lt;/p&gt;&lt;p&gt;For Microsoft, however, the calculation is clear: if even a fraction of its user base begins creating applications and automations, it would represent a massive expansion of the effective software development workforce — and further entrench customers in Microsoft&amp;#x27;s ecosystem. The company is betting that the same natural language interface that made ChatGPT accessible to millions can finally unlock the decades-old promise of empowering everyday workers to build their own tools.&lt;/p&gt;&lt;p&gt;The App Builder and Workflows agents are available starting today through the &lt;a href="https://www.microsoft.com/en-us/microsoft-365-copilot/agents"&gt;&lt;u&gt;Microsoft 365 Copilot Agent Store&lt;/u&gt;&lt;/a&gt; for Frontier Program participants.&lt;/p&gt;&lt;p&gt;Whether that future arrives depends not just on the technology&amp;#x27;s capabilities, but on a more fundamental question: Do millions of office workers actually want to become part-time software developers? Microsoft is about to find out if the answer is yes — or if some jobs are better left to the professionals.&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://www.microsoft.com/en-us/"&gt;&lt;u&gt;Microsoft&lt;/u&gt;&lt;/a&gt; is launching a significant expansion of its &lt;a href="https://copilot.microsoft.com/"&gt;&lt;u&gt;Copilot AI assistant&lt;/u&gt;&lt;/a&gt; on Tuesday, introducing tools that let employees build applications, automate workflows, and create specialized AI agents using only conversational prompts — no coding required.&lt;/p&gt;&lt;p&gt;The new capabilities, called &lt;a href="https://www.microsoft.com/en-us/microsoft-365/blog/2025/10/28/microsoft-365-copilot-now-enables-you-to-build-apps-and-workflows/"&gt;&lt;u&gt;App Builder&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.microsoft.com/en-us/microsoft-365/blog/2025/10/28/microsoft-365-copilot-now-enables-you-to-build-apps-and-workflows/"&gt;&lt;u&gt;Workflows&lt;/u&gt;&lt;/a&gt;, mark Microsoft&amp;#x27;s most aggressive attempt yet to merge artificial intelligence with software development, enabling the estimated &lt;a href="https://www.microsoft.com/investor/reports/ar25/index.html"&gt;&lt;u&gt;100 million Microsoft 365 users&lt;/u&gt;&lt;/a&gt; to create business tools as easily as they currently draft emails or build spreadsheets.&lt;/p&gt;&lt;p&gt;&amp;quot;We really believe that a main part of an AI-forward employee, not just developers, will be to create agents, workflows and apps,&amp;quot; Charles Lamanna, Microsoft&amp;#x27;s president of business and industry Copilot, said in an interview with VentureBeat. &amp;quot;Part of the job will be to build and create these things.&amp;quot;&lt;/p&gt;&lt;p&gt;The announcement comes as Microsoft deepens its commitment to AI-powered productivity tools while navigating a &lt;a href="https://blogs.microsoft.com/blog/2025/10/28/the-next-chapter-of-the-microsoft-openai-partnership/"&gt;&lt;u&gt;complex partnership with OpenAI&lt;/u&gt;&lt;/a&gt;, the creator of the underlying technology that powers Copilot. On the same day, OpenAI completed its restructuring into a for-profit entity, with Microsoft receiving a &lt;a href="https://www.bloomberg.com/news/articles/2025-10-28/microsoft-to-get-27-of-openai-access-to-ai-models-until-2032"&gt;&lt;u&gt;27% ownership stake&lt;/u&gt;&lt;/a&gt; valued at approximately $135 billion.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How natural language prompts now create fully functional business applications&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The new features transform &lt;a href="http://copilot.microsoft.com/"&gt;&lt;u&gt;Copilot&lt;/u&gt;&lt;/a&gt; from a conversational assistant into what Microsoft envisions as a comprehensive development environment accessible to non-technical workers. Users can now describe an application they need — such as a project tracker with dashboards and task assignments — and Copilot will generate a working app complete with a database backend, user interface, and security controls.&lt;/p&gt;&lt;p&gt;&amp;quot;If you&amp;#x27;re right inside of Copilot, you can now have a conversation to build an application complete with a backing database and a security model,&amp;quot; Lamanna explained. &amp;quot;You can make edit requests and update requests and change requests so you can tune the app to get exactly the experience you want before you share it with other users.&amp;quot;&lt;/p&gt;&lt;p&gt;The &lt;a href="https://www.microsoft.com/en-us/power-platform/products/power-apps"&gt;&lt;u&gt;App Builder&lt;/u&gt;&lt;/a&gt; stores data in Microsoft Lists, the company&amp;#x27;s lightweight database system, and allows users to share finished applications via a simple link—similar to sharing a document. The Workflows agent, meanwhile, automates routine tasks across Microsoft&amp;#x27;s ecosystem of products, including Outlook, Teams, SharePoint, and Planner, by converting natural language descriptions into automated processes.&lt;/p&gt;&lt;p&gt;A third component, a simplified version of &lt;a href="http://microsoft.com/en/microsoft-copilot/microsoft-copilot-studio"&gt;&lt;u&gt;Microsoft&amp;#x27;s Copilot Studio&lt;/u&gt;&lt;/a&gt; agent-building platform, lets users create specialized AI assistants tailored to specific tasks or knowledge domains, drawing from SharePoint documents, meeting transcripts, emails, and external systems.&lt;/p&gt;&lt;p&gt;All three capabilities are included in the existing $30-per-month &lt;a href="https://www.microsoft.com/en-us/microsoft-365-copilot/pricing"&gt;&lt;u&gt;Microsoft 365 Copilot subscription&lt;/u&gt;&lt;/a&gt; at no additional cost — a pricing decision Lamanna characterized as consistent with Microsoft&amp;#x27;s historical approach of bundling significant value into its productivity suite.&lt;/p&gt;&lt;p&gt;&amp;quot;That&amp;#x27;s what Microsoft always does. We try to do a huge amount of value at a low price,&amp;quot; he said. &amp;quot;If you go look at Office, you think about Excel, Word, PowerPoint, Exchange, all that for like eight bucks a month. That&amp;#x27;s a pretty good deal.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why Microsoft&amp;#x27;s nine-year bet on low-code development is finally paying off&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The new tools represent the culmination of a nine-year effort by Microsoft to democratize software development through its &lt;a href="https://www.microsoft.com/en-us/power-platform"&gt;&lt;u&gt;Power Platform&lt;/u&gt;&lt;/a&gt; — a collection of low-code and no-code development tools that has grown to 56 million monthly active users, according to figures the company disclosed in recent earnings reports.&lt;/p&gt;&lt;p&gt;Lamanna, who has led the Power Platform initiative since its inception, said the integration into Copilot marks a fundamental shift in how these capabilities reach users. Rather than requiring workers to visit a separate website or learn a specialized interface, the development tools now exist within the same conversational window they already use for AI-assisted tasks.&lt;/p&gt;&lt;p&gt;&amp;quot;One of the big things that we&amp;#x27;re excited about is Copilot — that&amp;#x27;s a tool for literally every office worker,&amp;quot; Lamanna said. &amp;quot;Every office worker, just like they research data, they analyze data, they reason over topics, they also will be creating apps, agents and workflows.&amp;quot;&lt;/p&gt;&lt;p&gt;The integration offers significant technical advantages, he argued. Because Copilot already indexes a user&amp;#x27;s Microsoft 365 content — emails, documents, meetings, and organizational data — it can incorporate that context into the applications and workflows it builds. If a user asks for &amp;quot;an app for &lt;a href="https://blogs.windows.com/windows-insider/2015/03/30/introducing-project-spartan-the-new-browser-built-for-windows-10/"&gt;&lt;u&gt;Project Spartan&lt;/u&gt;&lt;/a&gt;,&amp;quot; Copilot can draw from existing communications to understand what that project entails and suggest relevant features.&lt;/p&gt;&lt;p&gt;&amp;quot;If you go to those other tools, they have no idea what the heck Project Spartan is,&amp;quot; Lamanna said, referencing competing low-code platforms from companies like Google, Salesforce, and ServiceNow. &amp;quot;But if you do it inside of Copilot and inside of the App Builder, it&amp;#x27;s able to draw from all that information and context.&amp;quot;&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.microsoft.com/en-us/"&gt;&lt;u&gt;Microsoft&lt;/u&gt;&lt;/a&gt; claims the apps created through these tools are &amp;quot;full-stack applications&amp;quot; with proper databases secured through the same identity systems used across its enterprise products — distinguishing them from simpler front-end tools offered by competitors. The company also emphasized that its existing governance, security, and data loss prevention policies automatically apply to apps and workflows created through Copilot.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Where professional developers still matter in an AI-powered workplace&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;While &lt;a href="https://www.microsoft.com/en-us/"&gt;&lt;u&gt;Microsoft&lt;/u&gt;&lt;/a&gt; positions the new capabilities as accessible to all office workers, Lamanna was careful to delineate where professional developers remain essential. His dividing line centers on whether a system interacts with parties outside the organization.&lt;/p&gt;&lt;p&gt;&amp;quot;Anything that leaves the boundaries of your company warrants developer involvement,&amp;quot; he said. &amp;quot;If you want to build an agent and put it on your website, you should have developers involved. Or if you want to build an automation which interfaces directly with your customers, or an app or a website which interfaces directly with your customers, you want professionals involved.&amp;quot;&lt;/p&gt;&lt;p&gt;The reasoning is risk-based: external-facing systems carry greater potential for data breaches, security vulnerabilities, or business errors. &amp;quot;You don&amp;#x27;t want people getting refunds they shouldn&amp;#x27;t,&amp;quot; Lamanna noted.&lt;/p&gt;&lt;p&gt;For internal use cases — approval workflows, project tracking, team dashboards — Microsoft believes the new tools can handle the majority of needs without IT department involvement. But the company has built &amp;quot;no cliffs,&amp;quot; in Lamanna&amp;#x27;s terminology, allowing users to migrate simple apps to more sophisticated platforms as needs grow.&lt;/p&gt;&lt;p&gt;Apps created in the conversational &lt;a href="https://www.microsoft.com/en-us/power-platform/products/power-apps"&gt;&lt;u&gt;App Builder&lt;/u&gt;&lt;/a&gt; can be opened in &lt;a href="https://www.microsoft.com/en-us/power-platform/products/power-apps"&gt;&lt;u&gt;Power Apps&lt;/u&gt;&lt;/a&gt;, Microsoft&amp;#x27;s full development environment, where they can be connected to &lt;a href="https://www.microsoft.com/en-us/power-platform/dataverse"&gt;&lt;u&gt;Dataverse&lt;/u&gt;&lt;/a&gt;, the company&amp;#x27;s enterprise database, or extended with custom code. Similarly, simple workflows can graduate to the full &lt;a href="https://www.microsoft.com/en/power-platform/products/power-automate?market=af"&gt;&lt;u&gt;Power Automate platform&lt;/u&gt;&lt;/a&gt;, and basic agents can be enhanced in the complete Copilot Studio.&lt;/p&gt;&lt;p&gt;&amp;quot;We have this mantra called no cliffs,&amp;quot; Lamanna said. &amp;quot;If your app gets too complicated for the App Builder, you can always edit and open it in Power Apps. You can jump over to the richer experience, and if you&amp;#x27;re really sophisticated, you can even go from those experiences into Azure.&amp;quot;&lt;/p&gt;&lt;p&gt;This architecture addresses a problem that has plagued previous generations of easy-to-use development tools: users who outgrow the simplified environment often must rebuild from scratch on professional platforms. &amp;quot;People really do not like easy-to-use development tools if I have to throw everything away and start over,&amp;quot; Lamanna said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What happens when every employee can build apps without IT approval&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The democratization of software development raises questions about governance, maintenance, and organizational complexity — issues Microsoft has worked to address through administrative controls.&lt;/p&gt;&lt;p&gt;IT administrators can view all applications, workflows, and agents created within their organization through a centralized inventory in the &lt;a href="https://www.office.com/"&gt;&lt;u&gt;Microsoft 365&lt;/u&gt;&lt;/a&gt; admin center. They can reassign ownership, disable access at the group level, or &amp;quot;promote&amp;quot; particularly useful employee-created apps to officially supported status.&lt;/p&gt;&lt;p&gt;&amp;quot;We have a bunch of customers who have this approach where it&amp;#x27;s like, let 1,000 apps bloom, and then the best ones, I go upgrade and make them IT-governed or central,&amp;quot; Lamanna said.&lt;/p&gt;&lt;p&gt;The system also includes provisions for when employees leave. Apps and workflows remain accessible for 60 days, during which managers can claim ownership — similar to how OneDrive files are handled when someone departs.&lt;/p&gt;&lt;p&gt;Lamanna argued that most employee-created apps don&amp;#x27;t warrant significant IT oversight. &amp;quot;It&amp;#x27;s just not worth inspecting an app that John, Susie, and Bob use to do their job,&amp;quot; he said. &amp;quot;It should concern itself with the app that ends up being used by 2,000 people, and that will pop up in that dashboard.&amp;quot;&lt;/p&gt;&lt;p&gt;Still, the proliferation of employee-created applications could create challenges. Users have expressed frustration with Microsoft&amp;#x27;s increasing emphasis on AI features across its products, with some giving the &lt;a href="https://www.pcworld.com/article/2954732/users-arent-happy-with-copilot-ai-taking-over-the-microsoft-365-app.html"&gt;&lt;u&gt;Microsoft 365 mobile app one-star ratings&lt;/u&gt;&lt;/a&gt; after a recent update prioritized Copilot over traditional file access.&lt;/p&gt;&lt;p&gt;The tools also arrive as enterprises grapple with &amp;quot;&lt;a href="https://venturebeat.com/ai/mit-report-misunderstood-shadow-ai-economy-booms-while-headlines-cry-failure"&gt;&lt;u&gt;shadow IT&lt;/u&gt;&lt;/a&gt;&amp;quot; — unsanctioned software and systems that employees adopt without official approval. While Microsoft&amp;#x27;s governance controls aim to provide visibility, the ease of creating new applications could accelerate the pace at which these systems multiply.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The ambitious plan to turn 500 million workers into software builders&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Microsoft&amp;#x27;s ambitions for the technology extend far beyond incremental productivity gains. Lamanna envisions a fundamental transformation of what it means to be an office worker — one where building software becomes as routine as creating spreadsheets.&lt;/p&gt;&lt;p&gt;&amp;quot;Just like how 20 years ago you put on your resume that you could use pivot tables in Excel, people are going to start saying that they can use App Builder and workflow agents, even if they&amp;#x27;re just in the finance department or the sales department,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;The numbers he&amp;#x27;s targeting are staggering. With &lt;a href="https://www.microsoft.com/en-us/investor/events/fy-2025/earnings-fy-2025-q3"&gt;&lt;u&gt;56 million people already using Power Platform&lt;/u&gt;&lt;/a&gt;, Lamanna believes the integration into Copilot could eventually reach 500 million builders. &amp;quot;Early days still, but I think it&amp;#x27;s certainly encouraging,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;The features are currently available only to customers in Microsoft&amp;#x27;s &lt;a href="https://adoption.microsoft.com/en-us/copilot/frontier-program/"&gt;&lt;u&gt;Frontier Program&lt;/u&gt;&lt;/a&gt; — an early access initiative for Microsoft 365 Copilot subscribers. The company has not disclosed how many organizations participate in the program or when the tools will reach general availability.&lt;/p&gt;&lt;p&gt;The announcement fits within Microsoft&amp;#x27;s larger strategy of embedding AI capabilities throughout its product portfolio, driven by its partnership with OpenAI. Under the restructured agreement announced Tuesday, Microsoft will have access to OpenAI&amp;#x27;s technology through 2032, including models that achieve artificial general intelligence (AGI) — though such systems do not yet exist. Microsoft has also begun integrating Copilot into its new companion apps for Windows 11, which provide quick access to contacts, files, and calendar information.&lt;/p&gt;&lt;p&gt;The aggressive integration of AI features across Microsoft&amp;#x27;s ecosystem has drawn mixed reactions. While enterprise customers have shown interest in productivity gains, the rapid pace of change and ubiquity of AI prompts have frustrated some users who prefer traditional workflows.&lt;/p&gt;&lt;p&gt;For Microsoft, however, the calculation is clear: if even a fraction of its user base begins creating applications and automations, it would represent a massive expansion of the effective software development workforce — and further entrench customers in Microsoft&amp;#x27;s ecosystem. The company is betting that the same natural language interface that made ChatGPT accessible to millions can finally unlock the decades-old promise of empowering everyday workers to build their own tools.&lt;/p&gt;&lt;p&gt;The App Builder and Workflows agents are available starting today through the &lt;a href="https://www.microsoft.com/en-us/microsoft-365-copilot/agents"&gt;&lt;u&gt;Microsoft 365 Copilot Agent Store&lt;/u&gt;&lt;/a&gt; for Frontier Program participants.&lt;/p&gt;&lt;p&gt;Whether that future arrives depends not just on the technology&amp;#x27;s capabilities, but on a more fundamental question: Do millions of office workers actually want to become part-time software developers? Microsoft is about to find out if the answer is yes — or if some jobs are better left to the professionals.&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/microsofts-copilot-can-now-build-apps-and-automate-your-job-heres-how-it</guid><pubDate>Tue, 28 Oct 2025 20:30:00 +0000</pubDate></item><item><title>[NEW] Mappa’s AI voice analysis helps you find the best job candidates and will show off its tech at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/28/mappas-ai-voice-analysis-helps-you-find-the-best-job-candidates-and-will-show-off-its-tech-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Even after reviewing résumés, cover letters, and interviews, choosing the right candidate for a job can be a mysterious process. Hiring managers often rely on their biases about the world or gut feelings to inform their decision, making the process far from an exact science.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s why Sarah Lucena built Mappa, an AI-powered behavioral intelligence platform that aims to take some of the guesswork out of hiring. Mappa trained an AI model to detect voice patterns that correlate with certain traits, such as communication style, empathy, and confidence. Applicants simply answer some questions from Mappa’s AI agent, and then the platform sends hiring managers a shortlist of candidates with traits that are compatible with the role.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Mappa is a Startup Battlefield Top 20 finalist at TechCrunch Disrupt 2025 in San Francisco.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Mappa comes to the market with the goal of really, truly understanding people,” Lucena said in an interview with TechCrunch. “We don’t really categorize traits as good or bad. We understand traits as compatible or not.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lucena founded Mappa in 2023 with her two co-founders, Pablo Bérgolo and Daniel Moretti, and has raised $3.4 million in a seed round led by Tim Draper’s investment firm, Draper Associates. In less than three years, the startup has scaled to more than 130 customers in the U.S. and more than $4 million in annualized recurring revenue.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mappa claims one of its biggest advantages is data. The startup built highly curated datasets specifically for understanding human behavior. Mappa originally attempted to assess candidates based on video submissions and their online presence; however, they’ve found voice analysis to be the most effective method.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mappa’s platform has already helped companies find employees who stick around longer, according to Lucena. While the standard annual turnover rate for companies is around 30%, she says employees hired through Mappa have a turnover rate of just 2%.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Lucena says Mappa’s focus is always helping companies find the best people, but that often results in a more equitable hiring process. Mappa has facilitated over 3,000 hires to date, and more than 60% of them were women, LGBTQ+, or immigrants. Lucena, who was born and raised in Brazil, says she’s proud to have created more opportunities for these people.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Moving forward, Lucena says she sees Mappa evolving from a services company into an infrastructure provider. The startup’s API has seen traction among companies who want to use its behavioral analysis in situations beyond hiring. Tim Draper personally uses Mappa to assess founders his firm is considering investing in, and the educational platform Re-Skilling.ai uses the platform to understand skills that students can improve on.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the future, Lucena sees that Mappa could be used to help approve candidates for loans who don’t have an extensive credit history. She sees Mappa as a tool to help assess people more fairly in all kinds of settings.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;If you want to hear from Mappa firsthand, and see dozens of additional pitches, attend valuable workshops, and make the connections that drive business results, &lt;/em&gt;&lt;em&gt;head here to learn more about this year’s Disrupt&lt;/em&gt;&lt;em&gt;, held October 27 to 29 in San Francisco.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025" class="wp-image-3048094" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/TC25_Disrupt_General_Article_No-Anniversary_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Even after reviewing résumés, cover letters, and interviews, choosing the right candidate for a job can be a mysterious process. Hiring managers often rely on their biases about the world or gut feelings to inform their decision, making the process far from an exact science.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s why Sarah Lucena built Mappa, an AI-powered behavioral intelligence platform that aims to take some of the guesswork out of hiring. Mappa trained an AI model to detect voice patterns that correlate with certain traits, such as communication style, empathy, and confidence. Applicants simply answer some questions from Mappa’s AI agent, and then the platform sends hiring managers a shortlist of candidates with traits that are compatible with the role.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Mappa is a Startup Battlefield Top 20 finalist at TechCrunch Disrupt 2025 in San Francisco.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Mappa comes to the market with the goal of really, truly understanding people,” Lucena said in an interview with TechCrunch. “We don’t really categorize traits as good or bad. We understand traits as compatible or not.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lucena founded Mappa in 2023 with her two co-founders, Pablo Bérgolo and Daniel Moretti, and has raised $3.4 million in a seed round led by Tim Draper’s investment firm, Draper Associates. In less than three years, the startup has scaled to more than 130 customers in the U.S. and more than $4 million in annualized recurring revenue.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mappa claims one of its biggest advantages is data. The startup built highly curated datasets specifically for understanding human behavior. Mappa originally attempted to assess candidates based on video submissions and their online presence; however, they’ve found voice analysis to be the most effective method.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mappa’s platform has already helped companies find employees who stick around longer, according to Lucena. While the standard annual turnover rate for companies is around 30%, she says employees hired through Mappa have a turnover rate of just 2%.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Lucena says Mappa’s focus is always helping companies find the best people, but that often results in a more equitable hiring process. Mappa has facilitated over 3,000 hires to date, and more than 60% of them were women, LGBTQ+, or immigrants. Lucena, who was born and raised in Brazil, says she’s proud to have created more opportunities for these people.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Moving forward, Lucena says she sees Mappa evolving from a services company into an infrastructure provider. The startup’s API has seen traction among companies who want to use its behavioral analysis in situations beyond hiring. Tim Draper personally uses Mappa to assess founders his firm is considering investing in, and the educational platform Re-Skilling.ai uses the platform to understand skills that students can improve on.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the future, Lucena sees that Mappa could be used to help approve candidates for loans who don’t have an extensive credit history. She sees Mappa as a tool to help assess people more fairly in all kinds of settings.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;If you want to hear from Mappa firsthand, and see dozens of additional pitches, attend valuable workshops, and make the connections that drive business results, &lt;/em&gt;&lt;em&gt;head here to learn more about this year’s Disrupt&lt;/em&gt;&lt;em&gt;, held October 27 to 29 in San Francisco.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025" class="wp-image-3048094" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/TC25_Disrupt_General_Article_No-Anniversary_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/28/mappas-ai-voice-analysis-helps-you-find-the-best-job-candidates-and-will-show-off-its-tech-at-techcrunch-disrupt-2025/</guid><pubDate>Tue, 28 Oct 2025 22:15:00 +0000</pubDate></item><item><title>[NEW] Super Teacher is building an AI tutor for elementary schools — catch it at Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/28/super-teacher-is-building-an-ai-tutor-for-elementary-schools-catch-it-at-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Tutoring is one of the most effective tools for improving a child’s education, yet very few kids in the U.S. receive it. A 2023 survey of the nation’s largest school districts found that fewer than 10% of students received tutoring. One factor is that tutoring is too expensive for many families, often costing hundreds or thousands of dollars a month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tim Novikoff, a former Google product manager and educator, wants to change that. His startup, Super Teacher, offers an AI-powered tutoring app for elementary school students that costs $15 a month, or $10 with an annual plan. Super Teacher aims to make private tutoring accessible to families nationwide.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The four-year-old startup is gaining traction. Novikoff says roughly 20,000 families have signed up for Super Teacher, and public schools in New York, New Jersey, and Hawaii now use the app. Super Teacher is a Startup Battlefield Top 20 finalist at TechCrunch Disrupt 2025 in San Francisco.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Novikoff was previously a math teacher in New York City, first in Harlem and then at a highly rated public school, Stuyvesant High School. In an interview with TechCrunch, he said almost all the students at Stuyvesant received tutoring, whereas many of the students in Harlem didn’t, and the difference in their educational experience was stark.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“[Tutoring] is by far the most effective intervention that can be provided to kids for education, and it’s not even close,” Novikoff said. “It’s really unfair that not everyone gets this opportunity. That’s why I’m pursuing a mission to democratize access to private tutoring.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Super Teacher’s app features animated tutors with AI-generated voices that guide students through interactive lessons. Students talk to the app using voice, like a conversation with a teacher. But unlike many edtech tools, Super Teacher doesn’t use large language models to generate responses. Instead, its content comes from a deterministic system designed to always give correct answers — avoiding the inaccuracies that can plague LLMs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Novikoff thinks AI tutors can have a valuable impact on children’s lives, but he’s adamant that AI will never replace teachers in a school setting. He refers to AI tutors as a tool that teachers can use, such as smart boards or calculators, rather than a replacement altogether.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Super Teacher is only available for elementary school students, a decision Novikoff made to help his own children and because few edtech companies target that age group. Looking ahead, he hopes to expand to younger and older grades and partner with more school districts across the U.S.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Novikoff previously founded&lt;strong&gt; &lt;/strong&gt;Fly Labs, a mobile video-editing app acquired by Google in 2015.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;If you want to learn more about Super Teacher from the company itself — while also checking out dozens of others, hearing their pitches, and listening to guest speakers on four different stages — join us at Disrupt, October 27 to 29 in San Francisco. &lt;/em&gt;&lt;em&gt;Learn more here.&lt;/em&gt;&lt;em&gt;&amp;nbsp;&lt;/em&gt;&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025" class="wp-image-3048094" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/TC25_Disrupt_General_Article_No-Anniversary_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Tutoring is one of the most effective tools for improving a child’s education, yet very few kids in the U.S. receive it. A 2023 survey of the nation’s largest school districts found that fewer than 10% of students received tutoring. One factor is that tutoring is too expensive for many families, often costing hundreds or thousands of dollars a month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tim Novikoff, a former Google product manager and educator, wants to change that. His startup, Super Teacher, offers an AI-powered tutoring app for elementary school students that costs $15 a month, or $10 with an annual plan. Super Teacher aims to make private tutoring accessible to families nationwide.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The four-year-old startup is gaining traction. Novikoff says roughly 20,000 families have signed up for Super Teacher, and public schools in New York, New Jersey, and Hawaii now use the app. Super Teacher is a Startup Battlefield Top 20 finalist at TechCrunch Disrupt 2025 in San Francisco.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Novikoff was previously a math teacher in New York City, first in Harlem and then at a highly rated public school, Stuyvesant High School. In an interview with TechCrunch, he said almost all the students at Stuyvesant received tutoring, whereas many of the students in Harlem didn’t, and the difference in their educational experience was stark.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“[Tutoring] is by far the most effective intervention that can be provided to kids for education, and it’s not even close,” Novikoff said. “It’s really unfair that not everyone gets this opportunity. That’s why I’m pursuing a mission to democratize access to private tutoring.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Super Teacher’s app features animated tutors with AI-generated voices that guide students through interactive lessons. Students talk to the app using voice, like a conversation with a teacher. But unlike many edtech tools, Super Teacher doesn’t use large language models to generate responses. Instead, its content comes from a deterministic system designed to always give correct answers — avoiding the inaccuracies that can plague LLMs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Novikoff thinks AI tutors can have a valuable impact on children’s lives, but he’s adamant that AI will never replace teachers in a school setting. He refers to AI tutors as a tool that teachers can use, such as smart boards or calculators, rather than a replacement altogether.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Super Teacher is only available for elementary school students, a decision Novikoff made to help his own children and because few edtech companies target that age group. Looking ahead, he hopes to expand to younger and older grades and partner with more school districts across the U.S.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Novikoff previously founded&lt;strong&gt; &lt;/strong&gt;Fly Labs, a mobile video-editing app acquired by Google in 2015.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;If you want to learn more about Super Teacher from the company itself — while also checking out dozens of others, hearing their pitches, and listening to guest speakers on four different stages — join us at Disrupt, October 27 to 29 in San Francisco. &lt;/em&gt;&lt;em&gt;Learn more here.&lt;/em&gt;&lt;em&gt;&amp;nbsp;&lt;/em&gt;&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025" class="wp-image-3048094" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/TC25_Disrupt_General_Article_No-Anniversary_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/28/super-teacher-is-building-an-ai-tutor-for-elementary-schools-catch-it-at-disrupt-2025/</guid><pubDate>Tue, 28 Oct 2025 22:15:00 +0000</pubDate></item><item><title>[NEW] Inside CampusAI’s mission to close the AI training gap for everyday workers — check it out at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/28/inside-campusais-mission-to-close-the-ai-training-gap-for-everyday-workers-check-it-out-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As companies push to increase efficiency and stay competitive, they’re encouraging, or in some cases outright requiring, workers to know how to use AI tools. However, the push for AI use has exposed a training gap.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“There are few solutions available on the market that are dedicated to non-technical people,” Aureliusz Gorski, founder and CEO of Warsaw-based CampusAI, told TechCrunch.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;CampusAI’s solution? An educational platform focused on making learning accessible to everyday people who want to bring AI into their everyday workflows — whether that’s to help improve sales, HR, legal, or just give your personal branding a boost with AI.&amp;nbsp;The platform aims to help people understand and work with AI, rather than be intimidated by it.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Polish startup spoke to TechCrunch ahead of the TechCrunch Disrupt conference, where it’s a Startup Battlefield Top 20 finalist. CampusAI’s main product is a comprehensive online learning ecosystem with two key components: courses featuring an avatar-based learning model and a virtual campus in the metaverse where users can learn more skills, connect with others, participate in community projects, and more.&amp;nbsp;Think of it like Roblox for adults.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CampusAI offers its learning platform directly to consumers or to businesses that want to create AI upskilling paths for employees. The startup says it provides access to dozens of AI models — from ChatGPT and Gemini to Midjourney and Flux —&amp;nbsp;so users can experiment and learn in one place without needing to sign up for separate accounts and subscriptions. The team also updates courses every day to keep up with the fast pace of technological change.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3062174" height="383" src="https://techcrunch.com/wp-content/uploads/2025/10/CampusAI-_Gameplay.mp4.00_00_21_03.Still002.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Me+AI users get a dedicated desk in the virtual campus&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;CampusAI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;CampusAI’s flagship course for consumers is called Me+AI, priced at $250 per year, and it allows students to personalize their learning experience. The B2B product, called Team+AI, is priced at $25,000 per year. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are helping with the implementation of the human plus AI readiness culture [within companies], helping companies go smoothly with this transition,” Gorski said.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The first three weeks of Team+AI include an AI readiness test for the organization, a workshop for managers, and a webinar for the entire organization. The last four weeks feature personalized development paths for employees that have been adapted to meet company goals. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You can come in as a professional of a field, say, an HR expert, or someone who works in finance, and then you’ll find a batch of courses for yourself,” Aleksandra Przegalińska, an AI researcher and scientific adviser to CampusAI, told TechCrunch. “CampusAI is capable of preparing specific pathways for specific organizations so they can do a tailor-made approach.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CampusAI’s learning methodology is based off Przegalińska’s research on human-AI collaboration for improved business results and complex problem-solving. The approach centers on using prompting strategies to develop AI experts that support individuals in enhancing their capabilities.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3062176" height="440" src="https://techcrunch.com/wp-content/uploads/2025/10/Zrzut-ekranu-2025-10-24-o-18.58.54.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;CampusAI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;As such, CampusAI students have access to the company’s prompt book, which not only offers a repository of prompts, but also coaches students to learn how to build better prompts. Within the virtual campus environment, students can also visit the “AI Gym” — a platform where students tackle targeted exercises and challenges created by an AI agent that provides ongoing assessment.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We want to build an environment where you don’t delegate tasks to AI, but rather, you work with it in multiple different modalities,” Przegalińska said. “You can work in parallel with it, it can become your teammate, your sparring partner, your critic, or your coach. We think of this technology as something that is enhancing your work, not something that is taking over your work.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CampusAI claims its courses produce a measurable ROI, with employees becoming 40% more efficient and 60% more satisfied with their jobs. And the two-year-old company appears to have had some serious traction. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It was huge success in Poland in the first two weeks,” Gorski said, noting the company launched in 2023. “We got over 600 clients who decided to buy our lifetime membership, and from that moment, we grew to 35,000 users.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CampusAI also boasts 60 enterprise customers, including ING, T-Mobile, Lenovo, and Ikea, and is on track for more than $2 million in ARR in 2025. The company is currently raising a $20 million Series A to help it&lt;strong&gt; &lt;/strong&gt;expand to 40 markets by 2030.&lt;strong&gt; &lt;/strong&gt;CampusAI, which offers its program today in Polish, English, and Spanish, has recently expanded into the U.K. and the U.S., with a focus on building B2B sales before branching into D2C. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users who complete the courses and want to discover more can be invited to join Community+AI, a digital hub for members to connect, share knowledge, and collaborate on projects — like hAI Magazine, an online magazine where users can share sector-specific insights. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond its learning environment, Gorski said CampusAI’s digital twin technology has become a major value proposition. Instead of just running its own virtual campus, CampusAI wants to build and license digital twins of real-life university campuses, corporate showrooms, government institutions, or company headquarters for organizations’ exclusive use. The digital twins product starts at $100,000 per year. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CampusAI recently secured €18 million from the European Commission to collaborate with 11 universities across 10 countries — including Greece, Spain, the U.K., France, Luxembourg, and Germany — to create digital twins and customized learning environments for students. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gorski views these university partnerships as launchpads for local innovation hubs — an approach informed by his seven years at Cambridge Innovation Center, where he created over 10 programs to develop Warsaw’s startup community. These virtual environments are designed as catalysts for building local communities and virtual districts, ultimately creating a social platform tailored for entrepreneurs.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;He emphasized that fostering strong local ecosystems is critical to counter big tech dominance.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We believe people should focus on building strong local ecosystems, because if not, the next five years will probably have less and less startups, especially after what we saw recently with OpenAI providing more solutions inside one ecosystem,” he said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;If you want to learn more about CampusAI from the company itself — while also checking out dozens of others, hearing their pitches, and listening to guest speakers on four different stages — join us at Disrupt, October 27 to 29 in San Francisco. &lt;/em&gt;&lt;em&gt;Learn more here.&lt;/em&gt;&lt;em&gt;&amp;nbsp;&lt;/em&gt;&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025" class="wp-image-3048094" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/TC25_Disrupt_General_Article_No-Anniversary_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As companies push to increase efficiency and stay competitive, they’re encouraging, or in some cases outright requiring, workers to know how to use AI tools. However, the push for AI use has exposed a training gap.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“There are few solutions available on the market that are dedicated to non-technical people,” Aureliusz Gorski, founder and CEO of Warsaw-based CampusAI, told TechCrunch.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;CampusAI’s solution? An educational platform focused on making learning accessible to everyday people who want to bring AI into their everyday workflows — whether that’s to help improve sales, HR, legal, or just give your personal branding a boost with AI.&amp;nbsp;The platform aims to help people understand and work with AI, rather than be intimidated by it.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Polish startup spoke to TechCrunch ahead of the TechCrunch Disrupt conference, where it’s a Startup Battlefield Top 20 finalist. CampusAI’s main product is a comprehensive online learning ecosystem with two key components: courses featuring an avatar-based learning model and a virtual campus in the metaverse where users can learn more skills, connect with others, participate in community projects, and more.&amp;nbsp;Think of it like Roblox for adults.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CampusAI offers its learning platform directly to consumers or to businesses that want to create AI upskilling paths for employees. The startup says it provides access to dozens of AI models — from ChatGPT and Gemini to Midjourney and Flux —&amp;nbsp;so users can experiment and learn in one place without needing to sign up for separate accounts and subscriptions. The team also updates courses every day to keep up with the fast pace of technological change.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3062174" height="383" src="https://techcrunch.com/wp-content/uploads/2025/10/CampusAI-_Gameplay.mp4.00_00_21_03.Still002.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Me+AI users get a dedicated desk in the virtual campus&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;CampusAI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;CampusAI’s flagship course for consumers is called Me+AI, priced at $250 per year, and it allows students to personalize their learning experience. The B2B product, called Team+AI, is priced at $25,000 per year. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are helping with the implementation of the human plus AI readiness culture [within companies], helping companies go smoothly with this transition,” Gorski said.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The first three weeks of Team+AI include an AI readiness test for the organization, a workshop for managers, and a webinar for the entire organization. The last four weeks feature personalized development paths for employees that have been adapted to meet company goals. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You can come in as a professional of a field, say, an HR expert, or someone who works in finance, and then you’ll find a batch of courses for yourself,” Aleksandra Przegalińska, an AI researcher and scientific adviser to CampusAI, told TechCrunch. “CampusAI is capable of preparing specific pathways for specific organizations so they can do a tailor-made approach.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CampusAI’s learning methodology is based off Przegalińska’s research on human-AI collaboration for improved business results and complex problem-solving. The approach centers on using prompting strategies to develop AI experts that support individuals in enhancing their capabilities.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3062176" height="440" src="https://techcrunch.com/wp-content/uploads/2025/10/Zrzut-ekranu-2025-10-24-o-18.58.54.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;CampusAI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;As such, CampusAI students have access to the company’s prompt book, which not only offers a repository of prompts, but also coaches students to learn how to build better prompts. Within the virtual campus environment, students can also visit the “AI Gym” — a platform where students tackle targeted exercises and challenges created by an AI agent that provides ongoing assessment.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We want to build an environment where you don’t delegate tasks to AI, but rather, you work with it in multiple different modalities,” Przegalińska said. “You can work in parallel with it, it can become your teammate, your sparring partner, your critic, or your coach. We think of this technology as something that is enhancing your work, not something that is taking over your work.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CampusAI claims its courses produce a measurable ROI, with employees becoming 40% more efficient and 60% more satisfied with their jobs. And the two-year-old company appears to have had some serious traction. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It was huge success in Poland in the first two weeks,” Gorski said, noting the company launched in 2023. “We got over 600 clients who decided to buy our lifetime membership, and from that moment, we grew to 35,000 users.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CampusAI also boasts 60 enterprise customers, including ING, T-Mobile, Lenovo, and Ikea, and is on track for more than $2 million in ARR in 2025. The company is currently raising a $20 million Series A to help it&lt;strong&gt; &lt;/strong&gt;expand to 40 markets by 2030.&lt;strong&gt; &lt;/strong&gt;CampusAI, which offers its program today in Polish, English, and Spanish, has recently expanded into the U.K. and the U.S., with a focus on building B2B sales before branching into D2C. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users who complete the courses and want to discover more can be invited to join Community+AI, a digital hub for members to connect, share knowledge, and collaborate on projects — like hAI Magazine, an online magazine where users can share sector-specific insights. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond its learning environment, Gorski said CampusAI’s digital twin technology has become a major value proposition. Instead of just running its own virtual campus, CampusAI wants to build and license digital twins of real-life university campuses, corporate showrooms, government institutions, or company headquarters for organizations’ exclusive use. The digital twins product starts at $100,000 per year. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CampusAI recently secured €18 million from the European Commission to collaborate with 11 universities across 10 countries — including Greece, Spain, the U.K., France, Luxembourg, and Germany — to create digital twins and customized learning environments for students. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gorski views these university partnerships as launchpads for local innovation hubs — an approach informed by his seven years at Cambridge Innovation Center, where he created over 10 programs to develop Warsaw’s startup community. These virtual environments are designed as catalysts for building local communities and virtual districts, ultimately creating a social platform tailored for entrepreneurs.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;He emphasized that fostering strong local ecosystems is critical to counter big tech dominance.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We believe people should focus on building strong local ecosystems, because if not, the next five years will probably have less and less startups, especially after what we saw recently with OpenAI providing more solutions inside one ecosystem,” he said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;If you want to learn more about CampusAI from the company itself — while also checking out dozens of others, hearing their pitches, and listening to guest speakers on four different stages — join us at Disrupt, October 27 to 29 in San Francisco. &lt;/em&gt;&lt;em&gt;Learn more here.&lt;/em&gt;&lt;em&gt;&amp;nbsp;&lt;/em&gt;&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025" class="wp-image-3048094" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/TC25_Disrupt_General_Article_No-Anniversary_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/28/inside-campusais-mission-to-close-the-ai-training-gap-for-everyday-workers-check-it-out-at-techcrunch-disrupt-2025/</guid><pubDate>Tue, 28 Oct 2025 22:15:00 +0000</pubDate></item><item><title>[NEW] IBM's open source Granite 4.0 Nano AI models are small enough to run locally directly in your browser (AI | VentureBeat)</title><link>https://venturebeat.com/ai/ibms-open-source-granite-4-0-nano-ai-models-are-small-enough-to-run-locally</link><description>[unable to retrieve full-text content]&lt;p&gt;In an industry where model size is often seen as a proxy for intelligence, IBM is charting a different course — one that values &lt;i&gt;efficiency over enormity&lt;/i&gt;, and &lt;i&gt;accessibility over abstraction&lt;/i&gt;.&lt;/p&gt;&lt;p&gt;The 114-year-old tech giant&amp;#x27;s &lt;a href="https://huggingface.co/blog/ibm-granite/granite-4-nano"&gt;four new Granite 4.0 Nano models&lt;/a&gt;, released today, range from just 350 million to 1.5 billion parameters, a fraction of the size of their server-bound cousins from the likes of OpenAI, Anthropic, and Google. &lt;/p&gt;&lt;p&gt;These models are designed to be highly accessible: the 350M variants can run comfortably on a modern laptop CPU with 8–16GB of RAM, while the 1.5B models typically require a GPU with at least 6–8GB of VRAM for smooth performance — or sufficient system RAM and swap for CPU-only inference. This makes them well-suited for developers building applications on consumer hardware or at the edge, without relying on cloud compute.&lt;/p&gt;&lt;p&gt;In fact, the smallest ones can even run locally on your own web browser, as Joshua Lochner aka &lt;a href="https://x.com/xenovacom/status/1983218720366326002"&gt;Xenova&lt;/a&gt;, creator of Transformer.js and a machine learning engineer at Hugging Face, wrote on the social network X.&lt;/p&gt;&lt;div&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;All the Granite 4.0 Nano models are released under the Apache 2.0 license&lt;/b&gt; — perfect for use by researchers and enterprise or indie developers, even for commercial usage. &lt;/p&gt;&lt;p&gt;They are natively compatible with llama.cpp, vLLM, and MLX and are certified under ISO 42001 for responsible AI development — a standard IBM helped pioneer.&lt;/p&gt;&lt;p&gt;But in this case, small doesn&amp;#x27;t mean less capable — it might just mean smarter design.&lt;/p&gt;&lt;p&gt;These compact models are built not for data centers, but for edge devices, laptops, and local inference, where compute is scarce and latency matters. &lt;/p&gt;&lt;p&gt;And despite their small size, the Nano models are showing benchmark results that rival or even exceed the performance of larger models in the same category. &lt;/p&gt;&lt;p&gt;The release is a signal that a new AI frontier is rapidly forming — one not dominated by sheer scale, but by &lt;i&gt;strategic scaling&lt;/i&gt;.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;What Exactly Did IBM Release?&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The &lt;b&gt;Granite 4.0 Nano&lt;/b&gt; family includes four open-source models now available on &lt;a href="https://huggingface.co/collections/ibm-granite/granite-40-nano-language-models"&gt;Hugging Face&lt;/a&gt;:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Granite-4.0-H-1B&lt;/b&gt; (~1.5B parameters) – Hybrid-SSM architecture&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Granite-4.0-H-350M&lt;/b&gt; (~350M parameters) – Hybrid-SSM architecture&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Granite-4.0-1B&lt;/b&gt; – Transformer-based variant, parameter count closer to 2B&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Granite-4.0-350M&lt;/b&gt; – Transformer-based variant&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The H-series models — Granite-4.0-H-1B and H-350M — use a hybrid state space architecture (SSM) that combines efficiency with strong performance, ideal for low-latency edge environments. &lt;/p&gt;&lt;p&gt;Meanwhile, the standard transformer variants — Granite-4.0-1B and 350M — offer broader compatibility with tools like llama.cpp, designed for use cases where hybrid architecture isn’t yet supported. &lt;/p&gt;&lt;p&gt;In practice, the transformer 1B model is closer to 2B parameters, but aligns performance-wise with its hybrid sibling, offering developers flexibility based on their runtime constraints.&lt;/p&gt;&lt;p&gt;“The hybrid variant is a true 1B model. However, the non-hybrid variant is closer to 2B, but we opted to keep the naming aligned to the hybrid variant to make the connection easily visible,” explained Emma, Product Marketing lead for Granite, during a &lt;a href="https://www.reddit.com/r/LocalLLaMA/comments/1oichb7/granite_40_nano_language_models/"&gt;Reddit &amp;quot;Ask Me Anything&amp;quot; (AMA) session on r/LocalLLaMA.&lt;/a&gt;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;A Competitive Class of Small Models&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;IBM is entering a crowded and rapidly evolving market of small language models (SLMs), competing with offerings like Qwen3, Google&amp;#x27;s Gemma, LiquidAI’s LFM2, and even Mistral’s dense models in the sub-2B parameter space.&lt;/p&gt;&lt;p&gt;While OpenAI and Anthropic focus on models that require clusters of GPUs and sophisticated inference optimization, IBM’s Nano family is aimed squarely at developers who want to run performant LLMs on local or constrained hardware.&lt;/p&gt;&lt;p&gt;In benchmark testing, IBM’s new models consistently top the charts in their class. According to data&lt;a href="https://x.com/neurobongo/status/1983224452838985972"&gt; shared on X by David Cox, VP of AI Models at IBM Research:&lt;/a&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;On IFEval (instruction following), Granite-4.0-H-1B scored 78.5, outperforming Qwen3-1.7B (73.1) and other 1–2B models.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;On BFCLv3 (function/tool calling), Granite-4.0-1B led with a score of 54.8, the highest in its size class.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;On safety benchmarks (SALAD and AttaQ), the Granite models scored over 90%, surpassing similarly sized competitors.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Overall, the Granite-4.0-1B achieved a leading average benchmark score of 68.3% across general knowledge, math, code, and safety domains.&lt;/p&gt;&lt;p&gt;This performance is especially significant given the hardware constraints these models are designed for. &lt;/p&gt;&lt;p&gt;They require less memory, run faster on CPUs or mobile devices, and don’t need cloud infrastructure or GPU acceleration to deliver usable results.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Why Model Size Still Matters — But Not Like It Used To&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;In the early wave of LLMs, bigger meant better — more parameters translated to better generalization, deeper reasoning, and richer output. &lt;/p&gt;&lt;p&gt;But as transformer research matured, it became clear that architecture, training quality, and task-specific tuning could allow smaller models to punch well above their weight class.&lt;/p&gt;&lt;p&gt;IBM is banking on this evolution. By releasing open, small models that are &lt;i&gt;competitive in real-world tasks&lt;/i&gt;, the company is offering an alternative to the monolithic AI APIs that dominate today’s application stack.&lt;/p&gt;&lt;p&gt;In fact, the Nano models address three increasingly important needs:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Deployment flexibility&lt;/b&gt; — they run anywhere, from mobile to microservers.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Inference privacy&lt;/b&gt; — users can keep data local with no need to call out to cloud APIs.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Openness and auditability&lt;/b&gt; — source code and model weights are publicly available under an open license.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;&lt;b&gt;Community Response and Roadmap Signals&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;IBM’s Granite team didn’t just launch the models and walk away — they took to &lt;a href="https://www.reddit.com/r/LocalLLaMA/comments/1oichb7/granite_40_nano_language_models/"&gt;Reddit’s open source community r/LocalLLaMA &lt;/a&gt;to engage directly with developers. &lt;/p&gt;&lt;p&gt;In an AMA-style thread, Emma (Product Marketing, Granite) answered technical questions, addressed concerns about naming conventions, and dropped hints about what’s next.&lt;/p&gt;&lt;p&gt;Notable confirmations from the thread:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;A larger Granite 4.0 model is currently in training&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Reasoning-focused models (&amp;quot;thinking counterparts&amp;quot;) are in the pipeline&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;IBM will release fine-tuning recipes and a full training paper soon&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;More tooling and platform compatibility is on the roadmap&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Users responded enthusiastically to the models’ capabilities, especially in instruction-following and structured response tasks. One commenter summed it up:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;i&gt;“This is big if true for a 1B model — if quality is nice and it gives consistent outputs. Function-calling tasks, multilingual dialog, FIM completions… this could be a real workhorse.”&lt;/i&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Another user remarked:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;i&gt;“The Granite Tiny is already my go-to for web search in LM Studio — better than some Qwen models. Tempted to give Nano a shot.”&lt;/i&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;h3&gt;&lt;b&gt;Background: IBM Granite and the Enterprise AI Race&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;IBM’s push into large language models began in earnest in late 2023 with the debut of the Granite foundation model family, starting with models like &lt;i&gt;Granite.13b.instruct&lt;/i&gt; and &lt;i&gt;Granite.13b.chat&lt;/i&gt;. Released for use within its Watsonx platform, these initial decoder-only models signaled IBM’s ambition to build enterprise-grade AI systems that prioritize transparency, efficiency, and performance. The company open-sourced select Granite code models under the Apache 2.0 license in mid-2024, laying the groundwork for broader adoption and developer experimentation.&lt;/p&gt;&lt;p&gt;The real inflection point came with &lt;a href="https://venturebeat.com/ai/ibm-debuts-open-source-granite-3-0-llms-for-enterprise-ai/"&gt;Granite 3.0&lt;/a&gt; in October 2024 — a fully open-source suite of general-purpose and domain-specialized models ranging from 1B to 8B parameters. These models emphasized efficiency over brute scale, offering capabilities like longer context windows, instruction tuning, and integrated guardrails. IBM positioned Granite 3.0 as a direct competitor to Meta’s Llama, Alibaba’s Qwen, and Google&amp;#x27;s Gemma — but with a uniquely enterprise-first lens. Later versions, including &lt;a href="https://venturebeat.com/ai/ibm-wants-to-be-the-enterprise-llm-king-with-its-new-open-source-granite-3-1-models/"&gt;Granite 3.1&lt;/a&gt; and &lt;a href="https://venturebeat.com/ai/ibm-granite-3-2-uses-conditional-reasoning-time-series-forecasting-and-document-vision-to-tackle-challenging-enterprise-use-cases/"&gt;Granite 3.2&lt;/a&gt;, introduced even more enterprise-friendly innovations: embedded hallucination detection, time-series forecasting, document vision models, and conditional reasoning toggles.&lt;/p&gt;&lt;p&gt;The &lt;a href="https://venturebeat.com/ai/western-qwen-ibm-wows-with-granite-4-llm-launch-and-hybrid-mamba-transformer/"&gt;Granite 4.0&lt;/a&gt; family, launched in October 2025, represents IBM’s most technically ambitious release yet. It introduces a hybrid architecture that blends transformer and Mamba-2 layers — aiming to combine the contextual precision of attention mechanisms with the memory efficiency of state-space models. This design allows IBM to significantly reduce memory and latency costs for inference, making Granite models viable on smaller hardware while still outperforming peers in instruction-following and function-calling tasks. The launch also includes ISO 42001 certification, cryptographic model signing, and distribution across platforms like Hugging Face, Docker, LM Studio, Ollama, and watsonx.ai.&lt;/p&gt;&lt;p&gt;Across all iterations, IBM’s focus has been clear: build trustworthy, efficient, and legally unambiguous AI models for enterprise use cases. With a permissive Apache 2.0 license, public benchmarks, and an emphasis on governance, the Granite initiative not only responds to rising concerns over proprietary black-box models but also offers a Western-aligned open alternative to the rapid progress from teams like Alibaba’s Qwen. In doing so, Granite positions IBM as a leading voice in what may be the next phase of open-weight, production-ready AI.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;A Shift Toward Scalable Efficiency&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;In the end, IBM’s release of Granite 4.0 Nano models reflects a strategic shift in LLM development: from chasing parameter count records to optimizing usability, openness, and deployment reach.&lt;/p&gt;&lt;p&gt;By combining competitive performance, responsible development practices, and deep engagement with the open-source community, IBM is positioning Granite as not just a family of models — but a platform for building the next generation of lightweight, trustworthy AI systems.&lt;/p&gt;&lt;p&gt;For developers and researchers looking for performance without overhead, the Nano release offers a compelling signal: you don’t need 70 billion parameters to build something powerful — just the right ones.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;In an industry where model size is often seen as a proxy for intelligence, IBM is charting a different course — one that values &lt;i&gt;efficiency over enormity&lt;/i&gt;, and &lt;i&gt;accessibility over abstraction&lt;/i&gt;.&lt;/p&gt;&lt;p&gt;The 114-year-old tech giant&amp;#x27;s &lt;a href="https://huggingface.co/blog/ibm-granite/granite-4-nano"&gt;four new Granite 4.0 Nano models&lt;/a&gt;, released today, range from just 350 million to 1.5 billion parameters, a fraction of the size of their server-bound cousins from the likes of OpenAI, Anthropic, and Google. &lt;/p&gt;&lt;p&gt;These models are designed to be highly accessible: the 350M variants can run comfortably on a modern laptop CPU with 8–16GB of RAM, while the 1.5B models typically require a GPU with at least 6–8GB of VRAM for smooth performance — or sufficient system RAM and swap for CPU-only inference. This makes them well-suited for developers building applications on consumer hardware or at the edge, without relying on cloud compute.&lt;/p&gt;&lt;p&gt;In fact, the smallest ones can even run locally on your own web browser, as Joshua Lochner aka &lt;a href="https://x.com/xenovacom/status/1983218720366326002"&gt;Xenova&lt;/a&gt;, creator of Transformer.js and a machine learning engineer at Hugging Face, wrote on the social network X.&lt;/p&gt;&lt;div&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;All the Granite 4.0 Nano models are released under the Apache 2.0 license&lt;/b&gt; — perfect for use by researchers and enterprise or indie developers, even for commercial usage. &lt;/p&gt;&lt;p&gt;They are natively compatible with llama.cpp, vLLM, and MLX and are certified under ISO 42001 for responsible AI development — a standard IBM helped pioneer.&lt;/p&gt;&lt;p&gt;But in this case, small doesn&amp;#x27;t mean less capable — it might just mean smarter design.&lt;/p&gt;&lt;p&gt;These compact models are built not for data centers, but for edge devices, laptops, and local inference, where compute is scarce and latency matters. &lt;/p&gt;&lt;p&gt;And despite their small size, the Nano models are showing benchmark results that rival or even exceed the performance of larger models in the same category. &lt;/p&gt;&lt;p&gt;The release is a signal that a new AI frontier is rapidly forming — one not dominated by sheer scale, but by &lt;i&gt;strategic scaling&lt;/i&gt;.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;What Exactly Did IBM Release?&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The &lt;b&gt;Granite 4.0 Nano&lt;/b&gt; family includes four open-source models now available on &lt;a href="https://huggingface.co/collections/ibm-granite/granite-40-nano-language-models"&gt;Hugging Face&lt;/a&gt;:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Granite-4.0-H-1B&lt;/b&gt; (~1.5B parameters) – Hybrid-SSM architecture&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Granite-4.0-H-350M&lt;/b&gt; (~350M parameters) – Hybrid-SSM architecture&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Granite-4.0-1B&lt;/b&gt; – Transformer-based variant, parameter count closer to 2B&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Granite-4.0-350M&lt;/b&gt; – Transformer-based variant&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The H-series models — Granite-4.0-H-1B and H-350M — use a hybrid state space architecture (SSM) that combines efficiency with strong performance, ideal for low-latency edge environments. &lt;/p&gt;&lt;p&gt;Meanwhile, the standard transformer variants — Granite-4.0-1B and 350M — offer broader compatibility with tools like llama.cpp, designed for use cases where hybrid architecture isn’t yet supported. &lt;/p&gt;&lt;p&gt;In practice, the transformer 1B model is closer to 2B parameters, but aligns performance-wise with its hybrid sibling, offering developers flexibility based on their runtime constraints.&lt;/p&gt;&lt;p&gt;“The hybrid variant is a true 1B model. However, the non-hybrid variant is closer to 2B, but we opted to keep the naming aligned to the hybrid variant to make the connection easily visible,” explained Emma, Product Marketing lead for Granite, during a &lt;a href="https://www.reddit.com/r/LocalLLaMA/comments/1oichb7/granite_40_nano_language_models/"&gt;Reddit &amp;quot;Ask Me Anything&amp;quot; (AMA) session on r/LocalLLaMA.&lt;/a&gt;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;A Competitive Class of Small Models&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;IBM is entering a crowded and rapidly evolving market of small language models (SLMs), competing with offerings like Qwen3, Google&amp;#x27;s Gemma, LiquidAI’s LFM2, and even Mistral’s dense models in the sub-2B parameter space.&lt;/p&gt;&lt;p&gt;While OpenAI and Anthropic focus on models that require clusters of GPUs and sophisticated inference optimization, IBM’s Nano family is aimed squarely at developers who want to run performant LLMs on local or constrained hardware.&lt;/p&gt;&lt;p&gt;In benchmark testing, IBM’s new models consistently top the charts in their class. According to data&lt;a href="https://x.com/neurobongo/status/1983224452838985972"&gt; shared on X by David Cox, VP of AI Models at IBM Research:&lt;/a&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;On IFEval (instruction following), Granite-4.0-H-1B scored 78.5, outperforming Qwen3-1.7B (73.1) and other 1–2B models.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;On BFCLv3 (function/tool calling), Granite-4.0-1B led with a score of 54.8, the highest in its size class.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;On safety benchmarks (SALAD and AttaQ), the Granite models scored over 90%, surpassing similarly sized competitors.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Overall, the Granite-4.0-1B achieved a leading average benchmark score of 68.3% across general knowledge, math, code, and safety domains.&lt;/p&gt;&lt;p&gt;This performance is especially significant given the hardware constraints these models are designed for. &lt;/p&gt;&lt;p&gt;They require less memory, run faster on CPUs or mobile devices, and don’t need cloud infrastructure or GPU acceleration to deliver usable results.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Why Model Size Still Matters — But Not Like It Used To&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;In the early wave of LLMs, bigger meant better — more parameters translated to better generalization, deeper reasoning, and richer output. &lt;/p&gt;&lt;p&gt;But as transformer research matured, it became clear that architecture, training quality, and task-specific tuning could allow smaller models to punch well above their weight class.&lt;/p&gt;&lt;p&gt;IBM is banking on this evolution. By releasing open, small models that are &lt;i&gt;competitive in real-world tasks&lt;/i&gt;, the company is offering an alternative to the monolithic AI APIs that dominate today’s application stack.&lt;/p&gt;&lt;p&gt;In fact, the Nano models address three increasingly important needs:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Deployment flexibility&lt;/b&gt; — they run anywhere, from mobile to microservers.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Inference privacy&lt;/b&gt; — users can keep data local with no need to call out to cloud APIs.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Openness and auditability&lt;/b&gt; — source code and model weights are publicly available under an open license.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;&lt;b&gt;Community Response and Roadmap Signals&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;IBM’s Granite team didn’t just launch the models and walk away — they took to &lt;a href="https://www.reddit.com/r/LocalLLaMA/comments/1oichb7/granite_40_nano_language_models/"&gt;Reddit’s open source community r/LocalLLaMA &lt;/a&gt;to engage directly with developers. &lt;/p&gt;&lt;p&gt;In an AMA-style thread, Emma (Product Marketing, Granite) answered technical questions, addressed concerns about naming conventions, and dropped hints about what’s next.&lt;/p&gt;&lt;p&gt;Notable confirmations from the thread:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;A larger Granite 4.0 model is currently in training&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Reasoning-focused models (&amp;quot;thinking counterparts&amp;quot;) are in the pipeline&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;IBM will release fine-tuning recipes and a full training paper soon&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;More tooling and platform compatibility is on the roadmap&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Users responded enthusiastically to the models’ capabilities, especially in instruction-following and structured response tasks. One commenter summed it up:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;i&gt;“This is big if true for a 1B model — if quality is nice and it gives consistent outputs. Function-calling tasks, multilingual dialog, FIM completions… this could be a real workhorse.”&lt;/i&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Another user remarked:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;i&gt;“The Granite Tiny is already my go-to for web search in LM Studio — better than some Qwen models. Tempted to give Nano a shot.”&lt;/i&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;h3&gt;&lt;b&gt;Background: IBM Granite and the Enterprise AI Race&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;IBM’s push into large language models began in earnest in late 2023 with the debut of the Granite foundation model family, starting with models like &lt;i&gt;Granite.13b.instruct&lt;/i&gt; and &lt;i&gt;Granite.13b.chat&lt;/i&gt;. Released for use within its Watsonx platform, these initial decoder-only models signaled IBM’s ambition to build enterprise-grade AI systems that prioritize transparency, efficiency, and performance. The company open-sourced select Granite code models under the Apache 2.0 license in mid-2024, laying the groundwork for broader adoption and developer experimentation.&lt;/p&gt;&lt;p&gt;The real inflection point came with &lt;a href="https://venturebeat.com/ai/ibm-debuts-open-source-granite-3-0-llms-for-enterprise-ai/"&gt;Granite 3.0&lt;/a&gt; in October 2024 — a fully open-source suite of general-purpose and domain-specialized models ranging from 1B to 8B parameters. These models emphasized efficiency over brute scale, offering capabilities like longer context windows, instruction tuning, and integrated guardrails. IBM positioned Granite 3.0 as a direct competitor to Meta’s Llama, Alibaba’s Qwen, and Google&amp;#x27;s Gemma — but with a uniquely enterprise-first lens. Later versions, including &lt;a href="https://venturebeat.com/ai/ibm-wants-to-be-the-enterprise-llm-king-with-its-new-open-source-granite-3-1-models/"&gt;Granite 3.1&lt;/a&gt; and &lt;a href="https://venturebeat.com/ai/ibm-granite-3-2-uses-conditional-reasoning-time-series-forecasting-and-document-vision-to-tackle-challenging-enterprise-use-cases/"&gt;Granite 3.2&lt;/a&gt;, introduced even more enterprise-friendly innovations: embedded hallucination detection, time-series forecasting, document vision models, and conditional reasoning toggles.&lt;/p&gt;&lt;p&gt;The &lt;a href="https://venturebeat.com/ai/western-qwen-ibm-wows-with-granite-4-llm-launch-and-hybrid-mamba-transformer/"&gt;Granite 4.0&lt;/a&gt; family, launched in October 2025, represents IBM’s most technically ambitious release yet. It introduces a hybrid architecture that blends transformer and Mamba-2 layers — aiming to combine the contextual precision of attention mechanisms with the memory efficiency of state-space models. This design allows IBM to significantly reduce memory and latency costs for inference, making Granite models viable on smaller hardware while still outperforming peers in instruction-following and function-calling tasks. The launch also includes ISO 42001 certification, cryptographic model signing, and distribution across platforms like Hugging Face, Docker, LM Studio, Ollama, and watsonx.ai.&lt;/p&gt;&lt;p&gt;Across all iterations, IBM’s focus has been clear: build trustworthy, efficient, and legally unambiguous AI models for enterprise use cases. With a permissive Apache 2.0 license, public benchmarks, and an emphasis on governance, the Granite initiative not only responds to rising concerns over proprietary black-box models but also offers a Western-aligned open alternative to the rapid progress from teams like Alibaba’s Qwen. In doing so, Granite positions IBM as a leading voice in what may be the next phase of open-weight, production-ready AI.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;A Shift Toward Scalable Efficiency&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;In the end, IBM’s release of Granite 4.0 Nano models reflects a strategic shift in LLM development: from chasing parameter count records to optimizing usability, openness, and deployment reach.&lt;/p&gt;&lt;p&gt;By combining competitive performance, responsible development practices, and deep engagement with the open-source community, IBM is positioning Granite as not just a family of models — but a platform for building the next generation of lightweight, trustworthy AI systems.&lt;/p&gt;&lt;p&gt;For developers and researchers looking for performance without overhead, the Nano release offers a compelling signal: you don’t need 70 billion parameters to build something powerful — just the right ones.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/ibms-open-source-granite-4-0-nano-ai-models-are-small-enough-to-run-locally</guid><pubDate>Tue, 28 Oct 2025 23:23:00 +0000</pubDate></item><item><title>[NEW] Building a Healthcare Robot from Simulation to Deployment with NVIDIA Isaac (Hugging Face - Blog)</title><link>https://huggingface.co/blog/lerobotxnvidia-healthcare</link><description>&lt;div class="not-prose mb-6 lg:hidden"&gt;&lt;div class="SVELTE_HYDRATER contents"&gt;&lt;div class="flex flex-wrap items-center gap-2.5 pt-1  z-1 lg:sticky lg:top-8"&gt;
	


	&lt;ul class="flex items-center  flex-row  text-base   "&gt;&lt;li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="clem"&gt;&lt;img alt="alt" class="overflow-hidden rounded-full" src="https://cdn-avatars.huggingface.co/v1/production/uploads/1583857146757-5e67bdd61009063689407479.jpeg" /&gt;
					
			&lt;/li&gt;&lt;li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="kalyanvadrevu"&gt;&lt;img alt="alt" class="overflow-hidden rounded-full" src="https://huggingface.co/avatars/e4e855ad75d5d86959765610d67668b3.svg" /&gt;
					
			&lt;/li&gt;

		&lt;li class="text-xs text-gray-600 hover:text-gray-700 dark:text-gray-400 dark:hover:text-gray-300 order-last ml-3"&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;



&lt;/div&gt;&lt;/div&gt;
					
					

					&lt;!-- HTML_TAG_START --&gt;

&lt;p&gt;A hands-on guide to collecting data, training policies, and deploying autonomous medical robotics workflows on real hardware&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Table-of-Contents
	&lt;/span&gt;
&lt;/h2&gt;

&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Introduction
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Simulation has been a cornerstone in medical imaging to address the data gap. However, in healthcare robotics until now, it's often been too slow, siloed, or difficult to translate into real-world systems.&lt;/p&gt;
&lt;p&gt;NVIDIA Isaac for Healthcare, a developer framework for AI healthcare robotics, enables healthcare robotics developers in solving these challenges via offering integrated data collection, training, and evaluation pipelines that work across both simulation and hardware. Specifically, the Isaac for Healthcare v0.4 release provides healthcare developers with an end-to-end SO - ARM based starter workflow and the bring your own operating room tutorial. The SO-ARM starter workflow lowers the barrier for MedTech developers to experience the full workflow from simulation to train to deployment and start building and validating autonomous on real hardware right away.&lt;/p&gt;
&lt;p&gt;In this post, we'll walk through the starter workflow and its technical implementation details to help you build a surgical assistant robot in less time than ever imaginable before.&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		SO-ARM Starter Workflow; Building an Embodied Surgical Assistant
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;The SO-ARM starter workflow introduces a new way to explore surgical assistance tasks, and providing developers with a complete end-to-end pipeline for autonomous surgical assistance:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Collect real-world and synthetic data with SO-ARM using the LeRobot&lt;/li&gt;
&lt;li&gt;Fine-tune GR00t N1.5, evaluate in IsaacLab, then deploy to hardware&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This workflow gives developers a safe, repeatable environment to train and refine assistive skills before moving into the Operating Room.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Technical Implementation
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;The workflow implements a three-stage pipeline that integrates simulation and real hardware:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Data Collection: Mixed simulation and real-world teleoperation demonstrations using using SO101 and LeRobot&lt;/li&gt;
&lt;li&gt;Model Training: Fine-tuning GR00T N1.5 on combined datasets with dual-camera vision&lt;/li&gt;
&lt;li&gt;Policy Deployment: Real-time inference on physical hardware with RTI DDS communication&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Notably, over 93% of the data used for policy training was generated synthetically in simulation, underscoring the strength of simulation in bridging the robotic data gap.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Sim2Real Mixed Training Approach
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;The workflow combines simulation and real-world data to address the fundamental challenge that training robots in the real world is expensive and limited, while pure simulation often fails to capture real-world complexities. The approach uses approximately 70 simulation episodes for diverse scenarios and environmental variations, combined with 10-20 real-world episodes for authenticity and grounding. This mixed training creates policies that generalize beyond either domain alone.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Hardware Requirements
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;The workflow requires:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPU: RT Core-enabled architecture (Ampere or later) with ≥30GB VRAM for GR00TN1.5 inference&lt;/li&gt;
&lt;li&gt;SO-ARM101 Follower: 6-DOF precision manipulator with dual-camera vision (wrist and room). The SO-ARM101 features WOWROBO vision components, including a wrist-mounted camera with a 3D-printed adapter&lt;/li&gt;
&lt;li&gt;SO-ARM101 Leader: 6-DOF Teleoperation interface for expert demonstration collection&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Notably, developers could run all the simulation, training and deployment (3 computers needed for physical AI) on one DGX Spark.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Data Collection Implementation
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;&lt;img alt="so100-healthcare-real-demo" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/lerobot-blog/nvidia-healthcare/lerobotxnvidia-healthcare-real-demo.gif" /&gt;&lt;/p&gt;
&lt;p&gt;For real-world data collection with SO-ARM101 hardware or any other version supported in LeRobot:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;python lerobot-record \ 
  --robot.type=so101_follower \ 
  --robot.port=&amp;lt;follower_port_id&amp;gt; \ 
  --robot.cameras=&lt;span class="hljs-string"&gt;"{wrist: {type: opencv, index_or_path: 0, width: 640, height: 480, fps: 30}, room: {type: opencv, index_or_path: 2, width: 640, height: 480, fps: 30}}"&lt;/span&gt; \ 
  --robot.id=so101_follower_arm \ 
  --teleop.type=so101_leader \ 
  --teleop.port=&amp;lt;leader_port_id&amp;gt; \ 
  --teleop.id=so101_leader_arm \ 
  --dataset.repo_id=&amp;lt;user&amp;gt;/surgical_assistance/surgical_assistance \ 
  --dataset.num_episodes=15 \ 
  --dataset.single_task=&lt;span class="hljs-string"&gt;"Prepare and hand surgical instruments to surgeon"&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For simulation-based data collection:&lt;/p&gt;
&lt;p&gt;&lt;img alt="so100-healthcare-sim-demo" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/lerobot-blog/nvidia-healthcare/lerobotxnvidia-healthcare-sim-demo.gif" /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;
python -m simulation.environments.teleoperation_record \ 
  --enable_cameras \ 
  --record \ 
  --dataset_path=/path/to/save/dataset.hdf5 \ 
  --teleop_device=keyboard


python -m simulation.environments.teleoperation_record \ 
  --port=&amp;lt;your_leader_arm_port_id&amp;gt; \ 
  --enable_cameras \ 
  --record \ 
  --dataset_path=/path/to/save/dataset.hdf5 
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Simulation Teleoperation Controls
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;For users without physical SO-ARM101 hardware, the workflow provides keyboard-based teleoperation with the following joint controls:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Joint 1 (shoulder_pan): Q (+) / U (-)&lt;/li&gt;
&lt;li&gt;Joint 2 (shoulder_lift): W (+) / I (-)&lt;/li&gt;
&lt;li&gt;Joint 3 (elbow_flex): E (+) / O (-)&lt;/li&gt;
&lt;li&gt;Joint 4 (wrist_flex): A (+) / J (-)&lt;/li&gt;
&lt;li&gt;Joint 5 (wrist_roll): S (+) / K (-)&lt;/li&gt;
&lt;li&gt;Joint 6 (gripper): D (+) / L (-)&lt;/li&gt;
&lt;li&gt;R Key: Reset recording environment&lt;/li&gt;
&lt;li&gt;N Key: Mark episode as successful&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Model Training Pipeline
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;After collecting both simulation and real-world data, convert and combine datasets for training:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;
python -m training.hdf5_to_lerobot \ 
  --repo_id=surgical_assistance_dataset \ 
  --hdf5_path=/path/to/your/sim_dataset.hdf5 \ 
  --task_description=&lt;span class="hljs-string"&gt;"Autonomous surgical instrument handling and preparation"&lt;/span&gt; 


python -m training.gr00t_n1_5.train \ 
  --dataset_path /path/to/your/surgical_assistance_dataset \ 
  --output_dir /path/to/surgical_checkpoints \ 
  --data_config so100_dualcam 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The trained model processes natural language instructions such as "Prepare the scalpel for the surgeon" or "Hand me the forceps" and executes the corresponding robotic actions. With LeRobot latest release (0.4.0) you will be able to fine-tune Gr00t N1.5 natively in LeRobot!&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		End-to-End Sim Collect–Train–Eval Pipelines
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Simulation is most powerful when it's part of a loop: collect → train → evaluate → deploy.&lt;/p&gt;
&lt;p&gt;With v0.3, IsaacLab supports this full pipeline:&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Generate Synthetic Data in Simulation
	&lt;/span&gt;
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Teleoperate robots using keyboard or hardware controllers&lt;/li&gt;
&lt;li&gt;Capture multi-camera observations, robot states, and actions&lt;/li&gt;
&lt;li&gt;Create diverse datasets with edge cases impossible to collect safely in real environments&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Train and Evaluate Policies
	&lt;/span&gt;
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Deep integration with Isaac Lab's RL framework for PPO training&lt;/li&gt;
&lt;li&gt;Parallel environments (thousands of simulations simultaneously)&lt;/li&gt;
&lt;li&gt;Built-in trajectory analysis and success metrics&lt;/li&gt;
&lt;li&gt;Statistical validation across varied scenarios&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Convert Models to TensorRT
	&lt;/span&gt;
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Automatic optimization for production deployment&lt;/li&gt;
&lt;li&gt;Support for dynamic shapes and multi-camera inference&lt;/li&gt;
&lt;li&gt;Benchmarking tools to verify real-time performance&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This reduces time from experiment to deployment and makes sim2real a practical part of daily development.&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Getting Started
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Isaac for Healthcare SO-ARM Starter Workflow is available now. To get started:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Clone the repository: &lt;code&gt;git clone https://github.com/isaac-for-healthcare/i4h-workflows.git&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Choose a workflow: Start with the SO-ARM Starter Workflow for surgical assistance or explore other workflows&lt;/li&gt;
&lt;li&gt;Run the setup: Each workflow includes an automated setup script (e.g., &lt;code&gt;tools/env_setup_so_arm_starter.sh&lt;/code&gt;)&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Resources
	&lt;/span&gt;
&lt;/h3&gt;

&lt;!-- HTML_TAG_END --&gt;</description><content:encoded>&lt;div class="not-prose mb-6 lg:hidden"&gt;&lt;div class="SVELTE_HYDRATER contents"&gt;&lt;div class="flex flex-wrap items-center gap-2.5 pt-1  z-1 lg:sticky lg:top-8"&gt;
	


	&lt;ul class="flex items-center  flex-row  text-base   "&gt;&lt;li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="clem"&gt;&lt;img alt="alt" class="overflow-hidden rounded-full" src="https://cdn-avatars.huggingface.co/v1/production/uploads/1583857146757-5e67bdd61009063689407479.jpeg" /&gt;
					
			&lt;/li&gt;&lt;li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="kalyanvadrevu"&gt;&lt;img alt="alt" class="overflow-hidden rounded-full" src="https://huggingface.co/avatars/e4e855ad75d5d86959765610d67668b3.svg" /&gt;
					
			&lt;/li&gt;

		&lt;li class="text-xs text-gray-600 hover:text-gray-700 dark:text-gray-400 dark:hover:text-gray-300 order-last ml-3"&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;



&lt;/div&gt;&lt;/div&gt;
					
					

					&lt;!-- HTML_TAG_START --&gt;

&lt;p&gt;A hands-on guide to collecting data, training policies, and deploying autonomous medical robotics workflows on real hardware&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Table-of-Contents
	&lt;/span&gt;
&lt;/h2&gt;

&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Introduction
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Simulation has been a cornerstone in medical imaging to address the data gap. However, in healthcare robotics until now, it's often been too slow, siloed, or difficult to translate into real-world systems.&lt;/p&gt;
&lt;p&gt;NVIDIA Isaac for Healthcare, a developer framework for AI healthcare robotics, enables healthcare robotics developers in solving these challenges via offering integrated data collection, training, and evaluation pipelines that work across both simulation and hardware. Specifically, the Isaac for Healthcare v0.4 release provides healthcare developers with an end-to-end SO - ARM based starter workflow and the bring your own operating room tutorial. The SO-ARM starter workflow lowers the barrier for MedTech developers to experience the full workflow from simulation to train to deployment and start building and validating autonomous on real hardware right away.&lt;/p&gt;
&lt;p&gt;In this post, we'll walk through the starter workflow and its technical implementation details to help you build a surgical assistant robot in less time than ever imaginable before.&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		SO-ARM Starter Workflow; Building an Embodied Surgical Assistant
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;The SO-ARM starter workflow introduces a new way to explore surgical assistance tasks, and providing developers with a complete end-to-end pipeline for autonomous surgical assistance:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Collect real-world and synthetic data with SO-ARM using the LeRobot&lt;/li&gt;
&lt;li&gt;Fine-tune GR00t N1.5, evaluate in IsaacLab, then deploy to hardware&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This workflow gives developers a safe, repeatable environment to train and refine assistive skills before moving into the Operating Room.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Technical Implementation
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;The workflow implements a three-stage pipeline that integrates simulation and real hardware:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Data Collection: Mixed simulation and real-world teleoperation demonstrations using using SO101 and LeRobot&lt;/li&gt;
&lt;li&gt;Model Training: Fine-tuning GR00T N1.5 on combined datasets with dual-camera vision&lt;/li&gt;
&lt;li&gt;Policy Deployment: Real-time inference on physical hardware with RTI DDS communication&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Notably, over 93% of the data used for policy training was generated synthetically in simulation, underscoring the strength of simulation in bridging the robotic data gap.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Sim2Real Mixed Training Approach
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;The workflow combines simulation and real-world data to address the fundamental challenge that training robots in the real world is expensive and limited, while pure simulation often fails to capture real-world complexities. The approach uses approximately 70 simulation episodes for diverse scenarios and environmental variations, combined with 10-20 real-world episodes for authenticity and grounding. This mixed training creates policies that generalize beyond either domain alone.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Hardware Requirements
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;The workflow requires:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPU: RT Core-enabled architecture (Ampere or later) with ≥30GB VRAM for GR00TN1.5 inference&lt;/li&gt;
&lt;li&gt;SO-ARM101 Follower: 6-DOF precision manipulator with dual-camera vision (wrist and room). The SO-ARM101 features WOWROBO vision components, including a wrist-mounted camera with a 3D-printed adapter&lt;/li&gt;
&lt;li&gt;SO-ARM101 Leader: 6-DOF Teleoperation interface for expert demonstration collection&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Notably, developers could run all the simulation, training and deployment (3 computers needed for physical AI) on one DGX Spark.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Data Collection Implementation
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;&lt;img alt="so100-healthcare-real-demo" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/lerobot-blog/nvidia-healthcare/lerobotxnvidia-healthcare-real-demo.gif" /&gt;&lt;/p&gt;
&lt;p&gt;For real-world data collection with SO-ARM101 hardware or any other version supported in LeRobot:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;python lerobot-record \ 
  --robot.type=so101_follower \ 
  --robot.port=&amp;lt;follower_port_id&amp;gt; \ 
  --robot.cameras=&lt;span class="hljs-string"&gt;"{wrist: {type: opencv, index_or_path: 0, width: 640, height: 480, fps: 30}, room: {type: opencv, index_or_path: 2, width: 640, height: 480, fps: 30}}"&lt;/span&gt; \ 
  --robot.id=so101_follower_arm \ 
  --teleop.type=so101_leader \ 
  --teleop.port=&amp;lt;leader_port_id&amp;gt; \ 
  --teleop.id=so101_leader_arm \ 
  --dataset.repo_id=&amp;lt;user&amp;gt;/surgical_assistance/surgical_assistance \ 
  --dataset.num_episodes=15 \ 
  --dataset.single_task=&lt;span class="hljs-string"&gt;"Prepare and hand surgical instruments to surgeon"&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For simulation-based data collection:&lt;/p&gt;
&lt;p&gt;&lt;img alt="so100-healthcare-sim-demo" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/lerobot-blog/nvidia-healthcare/lerobotxnvidia-healthcare-sim-demo.gif" /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;
python -m simulation.environments.teleoperation_record \ 
  --enable_cameras \ 
  --record \ 
  --dataset_path=/path/to/save/dataset.hdf5 \ 
  --teleop_device=keyboard


python -m simulation.environments.teleoperation_record \ 
  --port=&amp;lt;your_leader_arm_port_id&amp;gt; \ 
  --enable_cameras \ 
  --record \ 
  --dataset_path=/path/to/save/dataset.hdf5 
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Simulation Teleoperation Controls
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;For users without physical SO-ARM101 hardware, the workflow provides keyboard-based teleoperation with the following joint controls:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Joint 1 (shoulder_pan): Q (+) / U (-)&lt;/li&gt;
&lt;li&gt;Joint 2 (shoulder_lift): W (+) / I (-)&lt;/li&gt;
&lt;li&gt;Joint 3 (elbow_flex): E (+) / O (-)&lt;/li&gt;
&lt;li&gt;Joint 4 (wrist_flex): A (+) / J (-)&lt;/li&gt;
&lt;li&gt;Joint 5 (wrist_roll): S (+) / K (-)&lt;/li&gt;
&lt;li&gt;Joint 6 (gripper): D (+) / L (-)&lt;/li&gt;
&lt;li&gt;R Key: Reset recording environment&lt;/li&gt;
&lt;li&gt;N Key: Mark episode as successful&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Model Training Pipeline
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;After collecting both simulation and real-world data, convert and combine datasets for training:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;
python -m training.hdf5_to_lerobot \ 
  --repo_id=surgical_assistance_dataset \ 
  --hdf5_path=/path/to/your/sim_dataset.hdf5 \ 
  --task_description=&lt;span class="hljs-string"&gt;"Autonomous surgical instrument handling and preparation"&lt;/span&gt; 


python -m training.gr00t_n1_5.train \ 
  --dataset_path /path/to/your/surgical_assistance_dataset \ 
  --output_dir /path/to/surgical_checkpoints \ 
  --data_config so100_dualcam 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The trained model processes natural language instructions such as "Prepare the scalpel for the surgeon" or "Hand me the forceps" and executes the corresponding robotic actions. With LeRobot latest release (0.4.0) you will be able to fine-tune Gr00t N1.5 natively in LeRobot!&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		End-to-End Sim Collect–Train–Eval Pipelines
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Simulation is most powerful when it's part of a loop: collect → train → evaluate → deploy.&lt;/p&gt;
&lt;p&gt;With v0.3, IsaacLab supports this full pipeline:&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Generate Synthetic Data in Simulation
	&lt;/span&gt;
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Teleoperate robots using keyboard or hardware controllers&lt;/li&gt;
&lt;li&gt;Capture multi-camera observations, robot states, and actions&lt;/li&gt;
&lt;li&gt;Create diverse datasets with edge cases impossible to collect safely in real environments&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Train and Evaluate Policies
	&lt;/span&gt;
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Deep integration with Isaac Lab's RL framework for PPO training&lt;/li&gt;
&lt;li&gt;Parallel environments (thousands of simulations simultaneously)&lt;/li&gt;
&lt;li&gt;Built-in trajectory analysis and success metrics&lt;/li&gt;
&lt;li&gt;Statistical validation across varied scenarios&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Convert Models to TensorRT
	&lt;/span&gt;
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Automatic optimization for production deployment&lt;/li&gt;
&lt;li&gt;Support for dynamic shapes and multi-camera inference&lt;/li&gt;
&lt;li&gt;Benchmarking tools to verify real-time performance&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This reduces time from experiment to deployment and makes sim2real a practical part of daily development.&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Getting Started
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Isaac for Healthcare SO-ARM Starter Workflow is available now. To get started:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Clone the repository: &lt;code&gt;git clone https://github.com/isaac-for-healthcare/i4h-workflows.git&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Choose a workflow: Start with the SO-ARM Starter Workflow for surgical assistance or explore other workflows&lt;/li&gt;
&lt;li&gt;Run the setup: Each workflow includes an automated setup script (e.g., &lt;code&gt;tools/env_setup_so_arm_starter.sh&lt;/code&gt;)&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Resources
	&lt;/span&gt;
&lt;/h3&gt;

&lt;!-- HTML_TAG_END --&gt;</content:encoded><guid isPermaLink="false">https://huggingface.co/blog/lerobotxnvidia-healthcare</guid><pubDate>Wed, 29 Oct 2025 00:00:00 +0000</pubDate></item><item><title>[NEW] ‘Silicon Valley’ star Thomas Middleditch makes a surprise appearance at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/28/silicon-valley-star-thomas-middleditch-makes-a-surprise-appearance-at-techcrunch-disrupt-2025/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2017/04/kumail-nanjiani-thomas-middleditch-martin-starr-zach-woods-photo-cred-john-p-johnson-for-hbo.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;If you were wandering the Expo Hall at TechCrunch Disrupt 2025, or watching our pitch stage earlier Tuesday, you might have noticed a familiar face from Pied Piper. Thomas Middleditch, who starred in HBO’s popular “Silicon Valley” show that prominently featured Disrupt back in 2014, had a planned takeover of Australian startup (and Battlefield 200 competitor) Othelia’s presentation at the pitch showcase stage.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;You can take a look at his full rundown below, including the actual pitch for Othelia’s mission to build a Cursor-like platform for storytellers.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Middleditch, amid being pitched, photographed, and mildly swarmed at the Expo hall, also took some time to chat with us about his POV on the conference, AI, and how he uses AI platforms for his own Improv With Robots YouTube channel.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2017/04/kumail-nanjiani-thomas-middleditch-martin-starr-zach-woods-photo-cred-john-p-johnson-for-hbo.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;If you were wandering the Expo Hall at TechCrunch Disrupt 2025, or watching our pitch stage earlier Tuesday, you might have noticed a familiar face from Pied Piper. Thomas Middleditch, who starred in HBO’s popular “Silicon Valley” show that prominently featured Disrupt back in 2014, had a planned takeover of Australian startup (and Battlefield 200 competitor) Othelia’s presentation at the pitch showcase stage.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;You can take a look at his full rundown below, including the actual pitch for Othelia’s mission to build a Cursor-like platform for storytellers.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Middleditch, amid being pitched, photographed, and mildly swarmed at the Expo hall, also took some time to chat with us about his POV on the conference, AI, and how he uses AI platforms for his own Improv With Robots YouTube channel.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/28/silicon-valley-star-thomas-middleditch-makes-a-surprise-appearance-at-techcrunch-disrupt-2025/</guid><pubDate>Wed, 29 Oct 2025 00:00:18 +0000</pubDate></item></channel></rss>