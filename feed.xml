<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 06 Nov 2025 18:32:43 +0000</lastBuildDate><item><title> ()</title><link>https://deepmind.com/blog/feed/basic/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://deepmind.com/blog/feed/basic/</guid></item><item><title>Apple plans big Siri update with help from Google AI (AI News)</title><link>https://www.artificialintelligence-news.com/news/apple-plans-big-siri-update-with-help-from-google-ai/</link><description>&lt;p&gt;Apple is planning to use a custom version of Google’s Gemini model to support a major upgrade to Siri, according to &lt;em&gt;Bloomberg’s&lt;/em&gt; Mark Gurman. The company may pay Google about $1 billion each year for access to technology that can create summaries and handle planning tasks.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Bloomberg&lt;/em&gt; says Apple will run the custom model on its Private Cloud Compute servers, while still relying on its own systems for some parts of Siri. Gurman reports that the Gemini model uses 1.2 trillion parameters, far more than the 150 billion parameters behind the current cloud-based version of Apple Intelligence.&lt;/p&gt;&lt;p&gt;Apple is preparing to spend about $1 billion each year on a powerful Google-built artificial intelligence model with 1.2 trillion parameters, according to people familiar with the matter, as reported by &lt;em&gt;Bloomberg&lt;/em&gt;. The system is expected to play a central role in a major update to Siri, a project the company has been working toward for years.&lt;/p&gt;&lt;p&gt;After months of testing, Apple and Google are close to a deal that would give Apple access to the technology. The people discussing the plans asked not to be named because the talks are private.&lt;/p&gt;&lt;p&gt;Apple is turning to Google to help rebuild Siri’s core technology, laying the groundwork for a broad refresh of features planned for next year. The size of Google’s model would far exceed the AI systems Apple uses today.&lt;/p&gt;&lt;p&gt;Apple tested other outside options — including Google’s Gemini, OpenAI’s ChatGPT, and Anthropic’s Claude — before deciding to move forward with Google earlier this year. The goal is to rely on Gemini as a temporary solution until Apple’s own work reaches the same level.&lt;/p&gt;&lt;p&gt;The updated Siri is planned for release next spring, &lt;em&gt;Bloomberg&lt;/em&gt; reported. Because months remain before launch, parts of the plan could still change. Apple and Google declined to comment.&lt;/p&gt;&lt;p&gt;Shares of both companies briefly rose after the news surfaced Wednesday. Apple’s stock gained less than 1% to $271.70, while Alphabet climbed as much as 3.2% to $286.42.&lt;/p&gt;&lt;p&gt;The custom Gemini model would be a major jump from the 150 billion parameter system Apple currently uses in the cloud for Apple Intelligence. The move is meant to increase Siri’s ability to process complex tasks and understand context at a deeper level.&lt;/p&gt;&lt;p&gt;The work is known internally as Glenwood and is led by Vision Pro headset creator Mike Rockwell and software chief Craig Federighi. The refreshed voice assistant, set to appear in iOS 26.4, is code-named Linwood.&lt;/p&gt;&lt;p&gt;Under the deal, Google’s model will support Siri’s summarizer and planner features — the parts that help the assistant understand information and decide on action steps. Apple’s own models will still handle some tools and responses.&lt;/p&gt;&lt;p&gt;The model will run on Apple’s Private Cloud Compute servers, keeping user data isolated from Google’s systems. Apple already set aside server hardware for the effort to support Siri’s new features.&lt;/p&gt;&lt;p&gt;Although the partnership is large, Apple is not expected to promote it to consumers. Google will act as a quiet technology provider, unlike the visible search agreement inside Safari. Siri’s improvements will likely appear without Google branding.&lt;/p&gt;&lt;p&gt;This deal is separate from earlier talks about placing Gemini directly inside Siri as a chatbot. Those conversations nearly turned into a product in both 2024 and again earlier this year, but never moved forward. The new agreement also does not place Google AI search features inside Apple’s operating systems, leaving Siri’s search behavior unchanged.&lt;/p&gt;&lt;p&gt;During Apple’s most recent earnings call, Chief Executive Officer Tim Cook said Siri may add more chatbot options in the future, beyond the current ChatGPT choice. Apple continues to look for ways to expand Siri without relying on one provider.&lt;/p&gt;&lt;p&gt;Other companies are also adopting Gemini. Snap and several major firms are building products using Google’s Vertex AI platform. For Apple, the move reflects how far behind it has fallen in AI — and how willing the company is to use outside tools to improve Siri.&lt;/p&gt;&lt;p&gt;Even so, Apple does not plan to use Gemini forever. The company has lost AI engineers in recent years, including the head of its models team, but Apple’s leadership still wants to develop its own technology and eventually replace Google’s system inside Siri.&lt;/p&gt;&lt;p&gt;Apple’s internal team is building its own cloud-based model with up to 1 trillion parameters, which could be ready for consumer use as early as next year. That work is expected to support Siri’s growth in the long run.&lt;/p&gt;&lt;p&gt;Executives believe they can match Google’s quality over time. But Google continues to improve Gemini, making the gap harder to close. Its 2.5 Pro version ranks near the top of most large language model comparisons, which affects how Apple plans Siri’s updates.&lt;/p&gt;&lt;p&gt;Apple also wants to bring Apple Intelligence and the updated Siri to China. Because Google services are banned in the country, the system used there will not rely on Gemini.&lt;/p&gt;&lt;p&gt;Instead, Apple plans to use its own models along with a content filter built by Alibaba Group Holding Ltd. That tool would adjust responses to meet government requirements. Apple has also explored a partnership with Baidu Inc. for AI features in the Chinese market, &lt;em&gt;Bloomberg&lt;/em&gt; reported earlier this year.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by omid armin)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Inside Tim Cook’s push to get Apple back in the AI race&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-110383" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/image-1.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Apple is planning to use a custom version of Google’s Gemini model to support a major upgrade to Siri, according to &lt;em&gt;Bloomberg’s&lt;/em&gt; Mark Gurman. The company may pay Google about $1 billion each year for access to technology that can create summaries and handle planning tasks.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Bloomberg&lt;/em&gt; says Apple will run the custom model on its Private Cloud Compute servers, while still relying on its own systems for some parts of Siri. Gurman reports that the Gemini model uses 1.2 trillion parameters, far more than the 150 billion parameters behind the current cloud-based version of Apple Intelligence.&lt;/p&gt;&lt;p&gt;Apple is preparing to spend about $1 billion each year on a powerful Google-built artificial intelligence model with 1.2 trillion parameters, according to people familiar with the matter, as reported by &lt;em&gt;Bloomberg&lt;/em&gt;. The system is expected to play a central role in a major update to Siri, a project the company has been working toward for years.&lt;/p&gt;&lt;p&gt;After months of testing, Apple and Google are close to a deal that would give Apple access to the technology. The people discussing the plans asked not to be named because the talks are private.&lt;/p&gt;&lt;p&gt;Apple is turning to Google to help rebuild Siri’s core technology, laying the groundwork for a broad refresh of features planned for next year. The size of Google’s model would far exceed the AI systems Apple uses today.&lt;/p&gt;&lt;p&gt;Apple tested other outside options — including Google’s Gemini, OpenAI’s ChatGPT, and Anthropic’s Claude — before deciding to move forward with Google earlier this year. The goal is to rely on Gemini as a temporary solution until Apple’s own work reaches the same level.&lt;/p&gt;&lt;p&gt;The updated Siri is planned for release next spring, &lt;em&gt;Bloomberg&lt;/em&gt; reported. Because months remain before launch, parts of the plan could still change. Apple and Google declined to comment.&lt;/p&gt;&lt;p&gt;Shares of both companies briefly rose after the news surfaced Wednesday. Apple’s stock gained less than 1% to $271.70, while Alphabet climbed as much as 3.2% to $286.42.&lt;/p&gt;&lt;p&gt;The custom Gemini model would be a major jump from the 150 billion parameter system Apple currently uses in the cloud for Apple Intelligence. The move is meant to increase Siri’s ability to process complex tasks and understand context at a deeper level.&lt;/p&gt;&lt;p&gt;The work is known internally as Glenwood and is led by Vision Pro headset creator Mike Rockwell and software chief Craig Federighi. The refreshed voice assistant, set to appear in iOS 26.4, is code-named Linwood.&lt;/p&gt;&lt;p&gt;Under the deal, Google’s model will support Siri’s summarizer and planner features — the parts that help the assistant understand information and decide on action steps. Apple’s own models will still handle some tools and responses.&lt;/p&gt;&lt;p&gt;The model will run on Apple’s Private Cloud Compute servers, keeping user data isolated from Google’s systems. Apple already set aside server hardware for the effort to support Siri’s new features.&lt;/p&gt;&lt;p&gt;Although the partnership is large, Apple is not expected to promote it to consumers. Google will act as a quiet technology provider, unlike the visible search agreement inside Safari. Siri’s improvements will likely appear without Google branding.&lt;/p&gt;&lt;p&gt;This deal is separate from earlier talks about placing Gemini directly inside Siri as a chatbot. Those conversations nearly turned into a product in both 2024 and again earlier this year, but never moved forward. The new agreement also does not place Google AI search features inside Apple’s operating systems, leaving Siri’s search behavior unchanged.&lt;/p&gt;&lt;p&gt;During Apple’s most recent earnings call, Chief Executive Officer Tim Cook said Siri may add more chatbot options in the future, beyond the current ChatGPT choice. Apple continues to look for ways to expand Siri without relying on one provider.&lt;/p&gt;&lt;p&gt;Other companies are also adopting Gemini. Snap and several major firms are building products using Google’s Vertex AI platform. For Apple, the move reflects how far behind it has fallen in AI — and how willing the company is to use outside tools to improve Siri.&lt;/p&gt;&lt;p&gt;Even so, Apple does not plan to use Gemini forever. The company has lost AI engineers in recent years, including the head of its models team, but Apple’s leadership still wants to develop its own technology and eventually replace Google’s system inside Siri.&lt;/p&gt;&lt;p&gt;Apple’s internal team is building its own cloud-based model with up to 1 trillion parameters, which could be ready for consumer use as early as next year. That work is expected to support Siri’s growth in the long run.&lt;/p&gt;&lt;p&gt;Executives believe they can match Google’s quality over time. But Google continues to improve Gemini, making the gap harder to close. Its 2.5 Pro version ranks near the top of most large language model comparisons, which affects how Apple plans Siri’s updates.&lt;/p&gt;&lt;p&gt;Apple also wants to bring Apple Intelligence and the updated Siri to China. Because Google services are banned in the country, the system used there will not rely on Gemini.&lt;/p&gt;&lt;p&gt;Instead, Apple plans to use its own models along with a content filter built by Alibaba Group Holding Ltd. That tool would adjust responses to meet government requirements. Apple has also explored a partnership with Baidu Inc. for AI features in the Chinese market, &lt;em&gt;Bloomberg&lt;/em&gt; reported earlier this year.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by omid armin)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Inside Tim Cook’s push to get Apple back in the AI race&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-110383" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/image-1.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/apple-plans-big-siri-update-with-help-from-google-ai/</guid><pubDate>Thu, 06 Nov 2025 08:00:00 +0000</pubDate></item><item><title>Stop worrying about your AI footprint. Look at the big picture instead. (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/11/06/1127579/ai-footprint/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/mit_ai_papercut-final.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Picture it: I’m minding my business at a party, parked by the snack table (of course). A friend of a friend wanders up, and we strike up a conversation. It quickly turns to work, and upon learning that I’m a climate technology reporter, my new acquaintance says something like: “Should I be using AI? I’ve heard it’s awful for the environment.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;This actually happens pretty often now. Generally, I tell people not to worry—let a chatbot plan your vacation, suggest recipe ideas, or write you a poem if you want.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;That response might surprise some people, but I promise I’m not living under a rock, and I have seen all the concerning projections about how much electricity AI is using. Data centers could consume up to 945 terawatt-hours annually by 2030. (That’s roughly as much as Japan.)&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But I feel strongly about not putting the onus on individuals, partly because AI concerns remind me so much of another question: “What should I do to reduce my carbon footprint?”&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;That one gets under my skin because of the context: BP helped popularize the concept of a carbon footprint in a marketing campaign in the early 2000s. That framing effectively shifts the burden of worrying about the environment from fossil-fuel companies to individuals.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The reality is, no one person can address climate change alone: Our entire society is built around burning fossil fuels. To address climate change, we need political action and public support for researching and scaling up climate technology. We need companies to innovate and take decisive action to reduce greenhouse-gas emissions. Focusing too much on individuals is a distraction from the real solutions on the table.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__container--08c53dd3bc9bd04e1e42e5f7ca641ab2"&gt;&lt;div class="whyItMatters__header--19f7f372f181cc6d4c06bc7362a44382"&gt;&lt;div class="whyItMatters__title--4af28c786a2bc93df05db111c6c30618"&gt;&lt;span class="whyItMatters__askAi--577f5fe6f54de43e37258d0f2aff4394"&gt;Ask AI&lt;/span&gt;&lt;div&gt;&lt;span class="whyItMatters__whyItMattersTitle--a3694998bb578e159bbd16690b8da390"&gt;Why it matters to you?&lt;/span&gt;&lt;span class="whyItMatters__betaBadge--9e84228b864d33d5b55479433fc91b8a"&gt;BETA&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__description--e1334886c092fa469388d7a24e1e1a55"&gt;&lt;span class="initial-description"&gt;Here’s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates—it might get weird&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="whyItMatters__questionContainer--ec1159210954852b9178c549600959a0"&gt;&lt;div&gt;&lt;button class="whyItMatters__actionButton--674934b6df433ac81e613372979cdb6c" type="button"&gt;Tell me why it matters&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;I see something similar today with AI. People are asking climate reporters at barbecues whether they should feel guilty about using chatbots too frequently when we need to focus on the bigger picture.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Big tech companies are playing into this narrative by providing energy-use estimates for their products at the user level. A couple of recent reports put the electricity used to query a chatbot at about 0.3 watt-hours, the same as powering a microwave for about a second. That’s so small as to be virtually insignificant.&lt;/p&gt;  &lt;p&gt;But stopping with the energy use of a single query obscures the full truth, which is that this industry is growing quickly, building energy-hungry infrastructure at a nearly incomprehensible scale to satisfy the AI appetites of society as a whole. Meta is currently building a data center in Louisiana with five gigawatts of computational power—about the same demand as the entire state of Maine at the summer peak.&amp;nbsp; (To learn more, read our Power Hungry series online.)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;Increasingly, there’s no getting away from AI, and it’s not as simple as choosing to use or not use the technology. Your favorite search engine likely gives you an AI summary at the top of your search results. Your email provider’s suggested replies? Probably AI. Same for chatting with customer service while you’re shopping online.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;Just as with climate change, we need to look at this as a system rather than a series of individual choices.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Massive tech companies using AI in their products should be disclosing their total energy and water use and going into detail about how they complete their calculations. Estimating the burden per query is a start, but we also deserve to see how these impacts add up for billions of users, and how that’s changing over time as companies (hopefully) make their products more efficient. Lawmakers should be mandating these disclosures, and we should be asking for them, too.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;That’s not to say there’s absolutely no individual action that you can take. Just as you could meaningfully reduce your individual greenhouse-gas emissions by taking fewer flights and eating less meat, there are some reasonable things that you can do to reduce your AI footprint. Generating videos tends to be especially energy-intensive, as does using reasoning models to engage with long prompts and produce long answers. Asking a chatbot to help plan your day, suggest fun activities to do with your family, or summarize a ridiculously long email has relatively minor impact.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Ultimately, as long as you aren’t relentlessly churning out AI slop, you shouldn’t be too worried about your individual AI footprint. But we should all be keeping our eye on what this industry will mean for our grid, our society, and our planet.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark, &lt;/em&gt;MIT Technology Review&lt;em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/mit_ai_papercut-final.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Picture it: I’m minding my business at a party, parked by the snack table (of course). A friend of a friend wanders up, and we strike up a conversation. It quickly turns to work, and upon learning that I’m a climate technology reporter, my new acquaintance says something like: “Should I be using AI? I’ve heard it’s awful for the environment.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;This actually happens pretty often now. Generally, I tell people not to worry—let a chatbot plan your vacation, suggest recipe ideas, or write you a poem if you want.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;That response might surprise some people, but I promise I’m not living under a rock, and I have seen all the concerning projections about how much electricity AI is using. Data centers could consume up to 945 terawatt-hours annually by 2030. (That’s roughly as much as Japan.)&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But I feel strongly about not putting the onus on individuals, partly because AI concerns remind me so much of another question: “What should I do to reduce my carbon footprint?”&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;That one gets under my skin because of the context: BP helped popularize the concept of a carbon footprint in a marketing campaign in the early 2000s. That framing effectively shifts the burden of worrying about the environment from fossil-fuel companies to individuals.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The reality is, no one person can address climate change alone: Our entire society is built around burning fossil fuels. To address climate change, we need political action and public support for researching and scaling up climate technology. We need companies to innovate and take decisive action to reduce greenhouse-gas emissions. Focusing too much on individuals is a distraction from the real solutions on the table.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__container--08c53dd3bc9bd04e1e42e5f7ca641ab2"&gt;&lt;div class="whyItMatters__header--19f7f372f181cc6d4c06bc7362a44382"&gt;&lt;div class="whyItMatters__title--4af28c786a2bc93df05db111c6c30618"&gt;&lt;span class="whyItMatters__askAi--577f5fe6f54de43e37258d0f2aff4394"&gt;Ask AI&lt;/span&gt;&lt;div&gt;&lt;span class="whyItMatters__whyItMattersTitle--a3694998bb578e159bbd16690b8da390"&gt;Why it matters to you?&lt;/span&gt;&lt;span class="whyItMatters__betaBadge--9e84228b864d33d5b55479433fc91b8a"&gt;BETA&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__description--e1334886c092fa469388d7a24e1e1a55"&gt;&lt;span class="initial-description"&gt;Here’s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates—it might get weird&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="whyItMatters__questionContainer--ec1159210954852b9178c549600959a0"&gt;&lt;div&gt;&lt;button class="whyItMatters__actionButton--674934b6df433ac81e613372979cdb6c" type="button"&gt;Tell me why it matters&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;I see something similar today with AI. People are asking climate reporters at barbecues whether they should feel guilty about using chatbots too frequently when we need to focus on the bigger picture.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Big tech companies are playing into this narrative by providing energy-use estimates for their products at the user level. A couple of recent reports put the electricity used to query a chatbot at about 0.3 watt-hours, the same as powering a microwave for about a second. That’s so small as to be virtually insignificant.&lt;/p&gt;  &lt;p&gt;But stopping with the energy use of a single query obscures the full truth, which is that this industry is growing quickly, building energy-hungry infrastructure at a nearly incomprehensible scale to satisfy the AI appetites of society as a whole. Meta is currently building a data center in Louisiana with five gigawatts of computational power—about the same demand as the entire state of Maine at the summer peak.&amp;nbsp; (To learn more, read our Power Hungry series online.)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;Increasingly, there’s no getting away from AI, and it’s not as simple as choosing to use or not use the technology. Your favorite search engine likely gives you an AI summary at the top of your search results. Your email provider’s suggested replies? Probably AI. Same for chatting with customer service while you’re shopping online.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;Just as with climate change, we need to look at this as a system rather than a series of individual choices.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Massive tech companies using AI in their products should be disclosing their total energy and water use and going into detail about how they complete their calculations. Estimating the burden per query is a start, but we also deserve to see how these impacts add up for billions of users, and how that’s changing over time as companies (hopefully) make their products more efficient. Lawmakers should be mandating these disclosures, and we should be asking for them, too.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;That’s not to say there’s absolutely no individual action that you can take. Just as you could meaningfully reduce your individual greenhouse-gas emissions by taking fewer flights and eating less meat, there are some reasonable things that you can do to reduce your AI footprint. Generating videos tends to be especially energy-intensive, as does using reasoning models to engage with long prompts and produce long answers. Asking a chatbot to help plan your day, suggest fun activities to do with your family, or summarize a ridiculously long email has relatively minor impact.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Ultimately, as long as you aren’t relentlessly churning out AI slop, you shouldn’t be too worried about your individual AI footprint. But we should all be keeping our eye on what this industry will mean for our grid, our society, and our planet.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark, &lt;/em&gt;MIT Technology Review&lt;em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/11/06/1127579/ai-footprint/</guid><pubDate>Thu, 06 Nov 2025 11:00:00 +0000</pubDate></item><item><title>Perplexity to pay Snap $400M to power search in Snapchat (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/06/perplexity-to-pay-snap-400m-to-power-search-in-snapchat/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/Snap-Inc-Perplexity-White-16x9-1.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Snap said on Thursday that it has signed a deal to integrate Perplexity’s AI search engine directly within Snapchat. As part of the deal, Perplexity will pay Snap $400 million in cash and equity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal gives Perplexity exposure to more than 940 million Snapchat users, who will get answers from its AI engine when they ask questions to the company’s My AI chatbot.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The new feature will be integrated into the app’s interface early next year. Snap said it will start recording revenue from this deal in 2026.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal was announced alongside Snap’s Q3 2025 results. The company reported revenue of $1.51 billion, up 10% from a year earlier, though it narrowed its loss to $104 million from $153 million a year ago. The company said its subscription tier, Snapchat+, now has more than 17 million users.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/Snap-Inc-Perplexity-White-16x9-1.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Snap said on Thursday that it has signed a deal to integrate Perplexity’s AI search engine directly within Snapchat. As part of the deal, Perplexity will pay Snap $400 million in cash and equity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal gives Perplexity exposure to more than 940 million Snapchat users, who will get answers from its AI engine when they ask questions to the company’s My AI chatbot.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The new feature will be integrated into the app’s interface early next year. Snap said it will start recording revenue from this deal in 2026.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal was announced alongside Snap’s Q3 2025 results. The company reported revenue of $1.51 billion, up 10% from a year earlier, though it narrowed its loss to $104 million from $153 million a year ago. The company said its subscription tier, Snapchat+, now has more than 17 million users.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/06/perplexity-to-pay-snap-400m-to-power-search-in-snapchat/</guid><pubDate>Thu, 06 Nov 2025 11:33:13 +0000</pubDate></item><item><title>Google Maps upgrades navigation in India with Gemini, safety alerts (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/06/google-maps-upgrades-navigation-in-india-with-gemini-safety-alerts/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is adding Gemini to Maps in India, along with road safety alerts and more information about routes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI integration, launched in the U.S. on Wednesday, brings hands-free AI assistance to Maps, as well as contextual suggestions while navigating and information about places of interest. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Miriam Daniel, vice president and head of Google Maps, said the rollout required significant localization.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When we say localizing for India, it’s not just the language,” she said at a virtual briefing. “It’s also adapting to how Indians use the product, how Indians will talk, how they will ask for questions, how they will identify places, the geopolitical places, the street names, you know, everything is sort of different in India.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gemini in Maps will be available to all Android and iOS users in India in the coming weeks, Google said. At launch, Gemini will support nine Indian languages.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google is also adding a set of India-specific navigation and commuting updates. Drivers will now get visual and audio alerts when they’re passing accident-prone stretches. Google said it is working on these alerts with local authorities, and the feature will roll out to Android users in Gurugram, the Cyberabad region of Hyderabad, Chandigarh, and Faridabad.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3065586" height="1400" src="https://techcrunch.com/wp-content/uploads/2025/11/google-maps-accident-prone-alerts.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Google has come under scrutiny in India over the reliability of some navigation routes, after a car drove off an unfinished bridge in Uttar Pradesh, killing three men, late last year.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“The real-world conditions can keep changing, and it’s very dynamic, and sometimes it changes in an instant. Maps can’t be accurate 100% of the time,” said Anal Ghosh, senior program manager for Google Maps, when asked about warnings for incomplete roads or unfinished bridges. “So we would encourage users to ensure that they’re keeping their eyes on the road.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google said it has partnered with the country’s highways regulator, National Highways Authority of India (NHAI), to receive near real-time data on road closures, diversions, and repair work. The company said the partnership will also allow Maps to show wayside amenities such as public restrooms, restaurants, and fuel stations along national highways.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other new features include proactive notifications about major disruptions or delays on routes, even when users are not navigating. These alerts are rolling out to Android users for highways and major roads in New Delhi, Mumbai, and Bengaluru.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3065587" height="1378" src="https://techcrunch.com/wp-content/uploads/2025/11/google-maps-speed-limit-alerts.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The app will also display speed limits during navigation, using data from local traffic authorities. This feature is rolling out to Android and iOS users in nine cities: Faridabad, Ghaziabad, Gurugram, Hyderabad (including the Cyberabad region), Jaipur, Kolkata, Lucknow, Mumbai, and Noida.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Building on the flyover navigation feature launched last year, Maps is now getting voice support for flyovers. This feature is rolling out to Android and iOS users over the coming weeks.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is adding Gemini to Maps in India, along with road safety alerts and more information about routes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI integration, launched in the U.S. on Wednesday, brings hands-free AI assistance to Maps, as well as contextual suggestions while navigating and information about places of interest. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Miriam Daniel, vice president and head of Google Maps, said the rollout required significant localization.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When we say localizing for India, it’s not just the language,” she said at a virtual briefing. “It’s also adapting to how Indians use the product, how Indians will talk, how they will ask for questions, how they will identify places, the geopolitical places, the street names, you know, everything is sort of different in India.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gemini in Maps will be available to all Android and iOS users in India in the coming weeks, Google said. At launch, Gemini will support nine Indian languages.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google is also adding a set of India-specific navigation and commuting updates. Drivers will now get visual and audio alerts when they’re passing accident-prone stretches. Google said it is working on these alerts with local authorities, and the feature will roll out to Android users in Gurugram, the Cyberabad region of Hyderabad, Chandigarh, and Faridabad.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3065586" height="1400" src="https://techcrunch.com/wp-content/uploads/2025/11/google-maps-accident-prone-alerts.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Google has come under scrutiny in India over the reliability of some navigation routes, after a car drove off an unfinished bridge in Uttar Pradesh, killing three men, late last year.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“The real-world conditions can keep changing, and it’s very dynamic, and sometimes it changes in an instant. Maps can’t be accurate 100% of the time,” said Anal Ghosh, senior program manager for Google Maps, when asked about warnings for incomplete roads or unfinished bridges. “So we would encourage users to ensure that they’re keeping their eyes on the road.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google said it has partnered with the country’s highways regulator, National Highways Authority of India (NHAI), to receive near real-time data on road closures, diversions, and repair work. The company said the partnership will also allow Maps to show wayside amenities such as public restrooms, restaurants, and fuel stations along national highways.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other new features include proactive notifications about major disruptions or delays on routes, even when users are not navigating. These alerts are rolling out to Android users for highways and major roads in New Delhi, Mumbai, and Bengaluru.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3065587" height="1378" src="https://techcrunch.com/wp-content/uploads/2025/11/google-maps-speed-limit-alerts.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The app will also display speed limits during navigation, using data from local traffic authorities. This feature is rolling out to Android and iOS users in nine cities: Faridabad, Ghaziabad, Gurugram, Hyderabad (including the Cyberabad region), Jaipur, Kolkata, Lucknow, Mumbai, and Noida.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Building on the flyover navigation feature launched last year, Maps is now getting voice support for flyovers. This feature is rolling out to Android and iOS users over the coming weeks.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/06/google-maps-upgrades-navigation-in-india-with-gemini-safety-alerts/</guid><pubDate>Thu, 06 Nov 2025 11:56:51 +0000</pubDate></item><item><title>[NEW] NVIDIA Founder and CEO Jensen Huang and Chief Scientist Bill Dally Awarded Prestigious Queen Elizabeth Prize for Engineering (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/nvidia-founder-and-ceo-jensen-huang-and-chief-scientist-bill-dally-awarded-prestigious-queen-elizabeth-prize-for-engineering/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;NVIDIA founder and CEO Jensen Huang and chief scientist Bill Dally were honored this week in the U.K. for their foundational work in AI and machine learning.&lt;/p&gt;
&lt;p&gt;They were among the seven recipients of the 2025 Queen Elizabeth Prize for Engineering, recognized for their contributions to modern machine learning.&lt;/p&gt;
&lt;p&gt;Presented by His Majesty King Charles III at St James’s Palace, the prize honored Huang and Dally for their leadership and vision in developing the GPU architectures that power today’s AI systems and machine learning algorithms.&lt;/p&gt;
&lt;p&gt;The award highlights their role in pioneering accelerated computing, driving a fundamental shift across the entire computer industry. It’s the breakthrough now revolutionizing every layer of technology, from chips and systems to algorithms and applications — sparking the big bang of AI.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87196"&gt;&lt;img alt="alt" class="wp-image-87196 size-medium" height="638" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/4476900-jhh-queen-elizabeth-award-4-1-960x638.jpg" width="960" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87196"&gt;Photo courtesy of Queen Elizabeth Prize for Engineering and Jason Alden&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;“To be recognized among the pioneers whose work has shaped the world we live in today is an extraordinary honor,” said Huang, acknowledging the visionaries behind technologies like the internet and GPS that have transformed industries and everyday life.&lt;/p&gt;
&lt;p&gt;Huang added, “We are living through the most profound transformation in computing since the invention of the microprocessor. AI has become essential infrastructure — as vital to future progress as electricity and the internet were to previous generations.”&lt;/p&gt;
&lt;figure class="wp-caption alignnone" id="attachment_87199"&gt;&lt;img alt="alt" class="wp-image-87199 size-medium" height="638" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/4476900-jhh-queen-elizabeth-award-3-960x638.jpg" width="960" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87199"&gt;Photo courtesy of Queen Elizabeth Prize for Engineering and Jason Alden&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Dally credited the foundations of AI to decades of progress in parallel computing and stream processing, adding, “We continue to apply engineering methods to refine AI hardware and software so that AI can empower people to achieve even greater things.”&lt;/p&gt;
&lt;p&gt;Together, Huang and Dally helped pioneer the accelerated computing architecture that makes modern AI possible — a platform that enables researchers to train large models, simulate physical systems, and advance science at unprecedented scale and speed.&lt;/p&gt;
&lt;p&gt;Their contributions, alongside those of the other laureates, have laid the groundwork for the widespread adoption of AI technologies. A rich tradition in the U.K., this recognition continues the nation’s lineage of nurturing thinkers whose ideas define new chapters in human ingenuity.&lt;/p&gt;
&lt;p&gt;Earlier that day, Huang and Dally also attended a roundtable at 10 Downing Street with Secretary of State for Science, Technology and Innovation Liz Kendall, and Minister for Science, Research, Innovation and Nuclear Lord Patrick Vallance to discuss how the U.K. can inspire future engineers.&lt;/p&gt;
&lt;p&gt;The roundtable also marked National Engineering Day in the U.K. — an annual celebration of engineers and their impact on everyday life.&lt;/p&gt;
&lt;p&gt;The discussion built on NVIDIA’s collaboration with the U.K. government, universities and industry to expand AI infrastructure, research and skills — ensuring the next generation of engineers has access to the computing power that fuels discovery.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Stephen Hawking Fellowship&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;In a further distinction, Huang also received the Professor Stephen Hawking Fellowship at the Cambridge Union, the world’s oldest debating society. The Cambridge Union Society and Lucy Hawking, daughter of Stephen Hawking, honored Huang for advancing science and inspiring future generations of technologists and researchers.&lt;/p&gt;
&lt;p&gt;“Professor Hawking’s life showed that intellect has no boundaries,” said Huang. “That curiosity — pursued with humor and grace — can expand the reach of humanity. He taught us that discovery is an act of optimism. And I can think of no higher compliment than to be associated with that spirit.”&lt;/p&gt;
&lt;p&gt;&lt;img alt="Lucy Hawking presents NVIDIA CEO Jensen Huang with the Professor Stephen Hawking Fellowship at Cambridge Union Society." class="alignnone size-medium wp-image-87188" height="540" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/4470864-jhh-hawking-fellowship-award-blog-1920x1080-3-960x540.jpg" width="960" /&gt;&lt;/p&gt;
&lt;p&gt;The Fellowship commends individuals who advance STEM and promote public understanding of these fields. Huang was presented with the Fellowship by Lucy Hawking before addressing the audience and joining a fireside chat with Union President Ivan Alexei Ampiah.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Main feature image courtesy of Queen Elizabeth Prize for Engineering and Jason Alden.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;NVIDIA founder and CEO Jensen Huang and chief scientist Bill Dally were honored this week in the U.K. for their foundational work in AI and machine learning.&lt;/p&gt;
&lt;p&gt;They were among the seven recipients of the 2025 Queen Elizabeth Prize for Engineering, recognized for their contributions to modern machine learning.&lt;/p&gt;
&lt;p&gt;Presented by His Majesty King Charles III at St James’s Palace, the prize honored Huang and Dally for their leadership and vision in developing the GPU architectures that power today’s AI systems and machine learning algorithms.&lt;/p&gt;
&lt;p&gt;The award highlights their role in pioneering accelerated computing, driving a fundamental shift across the entire computer industry. It’s the breakthrough now revolutionizing every layer of technology, from chips and systems to algorithms and applications — sparking the big bang of AI.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87196"&gt;&lt;img alt="alt" class="wp-image-87196 size-medium" height="638" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/4476900-jhh-queen-elizabeth-award-4-1-960x638.jpg" width="960" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87196"&gt;Photo courtesy of Queen Elizabeth Prize for Engineering and Jason Alden&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;“To be recognized among the pioneers whose work has shaped the world we live in today is an extraordinary honor,” said Huang, acknowledging the visionaries behind technologies like the internet and GPS that have transformed industries and everyday life.&lt;/p&gt;
&lt;p&gt;Huang added, “We are living through the most profound transformation in computing since the invention of the microprocessor. AI has become essential infrastructure — as vital to future progress as electricity and the internet were to previous generations.”&lt;/p&gt;
&lt;figure class="wp-caption alignnone" id="attachment_87199"&gt;&lt;img alt="alt" class="wp-image-87199 size-medium" height="638" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/4476900-jhh-queen-elizabeth-award-3-960x638.jpg" width="960" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87199"&gt;Photo courtesy of Queen Elizabeth Prize for Engineering and Jason Alden&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Dally credited the foundations of AI to decades of progress in parallel computing and stream processing, adding, “We continue to apply engineering methods to refine AI hardware and software so that AI can empower people to achieve even greater things.”&lt;/p&gt;
&lt;p&gt;Together, Huang and Dally helped pioneer the accelerated computing architecture that makes modern AI possible — a platform that enables researchers to train large models, simulate physical systems, and advance science at unprecedented scale and speed.&lt;/p&gt;
&lt;p&gt;Their contributions, alongside those of the other laureates, have laid the groundwork for the widespread adoption of AI technologies. A rich tradition in the U.K., this recognition continues the nation’s lineage of nurturing thinkers whose ideas define new chapters in human ingenuity.&lt;/p&gt;
&lt;p&gt;Earlier that day, Huang and Dally also attended a roundtable at 10 Downing Street with Secretary of State for Science, Technology and Innovation Liz Kendall, and Minister for Science, Research, Innovation and Nuclear Lord Patrick Vallance to discuss how the U.K. can inspire future engineers.&lt;/p&gt;
&lt;p&gt;The roundtable also marked National Engineering Day in the U.K. — an annual celebration of engineers and their impact on everyday life.&lt;/p&gt;
&lt;p&gt;The discussion built on NVIDIA’s collaboration with the U.K. government, universities and industry to expand AI infrastructure, research and skills — ensuring the next generation of engineers has access to the computing power that fuels discovery.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Stephen Hawking Fellowship&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;In a further distinction, Huang also received the Professor Stephen Hawking Fellowship at the Cambridge Union, the world’s oldest debating society. The Cambridge Union Society and Lucy Hawking, daughter of Stephen Hawking, honored Huang for advancing science and inspiring future generations of technologists and researchers.&lt;/p&gt;
&lt;p&gt;“Professor Hawking’s life showed that intellect has no boundaries,” said Huang. “That curiosity — pursued with humor and grace — can expand the reach of humanity. He taught us that discovery is an act of optimism. And I can think of no higher compliment than to be associated with that spirit.”&lt;/p&gt;
&lt;p&gt;&lt;img alt="Lucy Hawking presents NVIDIA CEO Jensen Huang with the Professor Stephen Hawking Fellowship at Cambridge Union Society." class="alignnone size-medium wp-image-87188" height="540" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/4470864-jhh-hawking-fellowship-award-blog-1920x1080-3-960x540.jpg" width="960" /&gt;&lt;/p&gt;
&lt;p&gt;The Fellowship commends individuals who advance STEM and promote public understanding of these fields. Huang was presented with the Fellowship by Lucy Hawking before addressing the audience and joining a fireside chat with Union President Ivan Alexei Ampiah.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Main feature image courtesy of Queen Elizabeth Prize for Engineering and Jason Alden.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/nvidia-founder-and-ceo-jensen-huang-and-chief-scientist-bill-dally-awarded-prestigious-queen-elizabeth-prize-for-engineering/</guid><pubDate>Thu, 06 Nov 2025 12:40:19 +0000</pubDate></item><item><title>[NEW] MIT researchers propose a new model for legible, modular software (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/mit-researchers-propose-new-model-for-legible-modular-software-1106</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202510/MIT-csail-AI-software.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr" id="docs-internal-guid-8faef2c5-7fff-2ff6-d2b4-9dd6f3d78997"&gt;Coding with large language models (LLMs) holds huge promise, but it also exposes some long-standing flaws in software: code that’s messy, hard to change safely, and often opaque about what’s really happening under the hood. Researchers at MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) are charting a more “modular” path ahead.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr" id="docs-internal-guid-8faef2c5-7fff-2ff6-d2b4-9dd6f3d78997"&gt;Their new approach breaks systems into “concepts,” separate pieces of a system, each designed to do one job well, and “synchronizations,” explicit rules that describe exactly how those pieces fit together. The result is software that’s more modular, transparent, and easier to understand. A small domain-specific language (DSL) makes it possible to express synchronizations simply, in a form that LLMs can reliably generate. In a real-world case study, the team showed how this method can bring together features that would otherwise be scattered across multiple services.&lt;/p&gt;&lt;p dir="ltr"&gt;The team, including Daniel Jackson, an MIT professor of electrical engineering and computer science (EECS) and CSAIL associate director, and Eagon Meng, an EECS PhD student, CSAIL affiliate, and designer of the new synchronization DSL, explore this approach in their paper “What You See Is What It Does: A Structural Pattern for Legible Software,” which they presented at the Splash Conference in Singapore in October.&amp;nbsp;The challenge, they explain, is that in most modern systems, a single feature is never fully self-contained. Adding a “share” button to a social platform like Instagram, for example, doesn’t live in just one service. Its functionality is split across code that handles posting, notification, authenticating users, and more. All these pieces, despite being scattered across the code, must be carefully aligned, and any change risks unintended side effects elsewhere.&lt;/p&gt;&lt;p dir="ltr"&gt;Jackson calls this “feature fragmentation,” a central obstacle to software reliability. “The way we build software today, the functionality is not localized. You want to understand how ‘sharing’ works, but you have to hunt for it in three or four different places, and when you find it, the connections are buried in low-level code,” says Jackson.&lt;/p&gt;&lt;p dir="ltr"&gt;Concepts and synchronizations are meant to tackle this problem. A concept bundles up a single, coherent piece of functionality, like sharing, liking, or following, along with its state and the actions it can take. Synchronizations, on the other hand, describe at a higher level how those concepts interact. Rather than writing messy low-level integration code, developers can use a small domain-specific language to spell out these connections directly. In this DSL, the rules are simple and clear: one concept’s action can trigger another, so that a change in one piece of state can be kept in sync with another.&lt;/p&gt;&lt;p dir="ltr"&gt;“Think of concepts as modules that are completely clean and independent. Synchronizations then act like contracts — they say exactly how concepts are supposed to interact. That’s powerful because it makes the system both easier for humans to understand and easier for tools like LLMs to generate correctly,” says Jackson. “Why can’t we read code like a book? We believe that software should be legible and written in terms of our understanding: our hope is that concepts map to familiar phenomena, and synchronizations represent our intuition about what happens when they come together,” says Meng.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;The benefits extend beyond clarity. Because synchronizations are explicit and declarative, they can be analyzed, verified, and of course generated by an LLM. This opens the door to safer, more automated software development, where AI assistants can propose new features without introducing hidden side effects.&lt;/p&gt;&lt;p dir="ltr"&gt;In their case study, the researchers assigned features like liking, commenting, and sharing each to a single concept — like a microservices architecture, but more modular. Without this pattern, these features were spread across many services, making them hard to locate and test. Using the concepts-and-synchronizations approach, each feature became centralized and legible, while the synchronizations spelled out exactly how the concepts interacted.&lt;/p&gt;&lt;p dir="ltr"&gt;The study also showed how synchronizations can factor out common concerns like error handling, response formatting, or persistent storage. Instead of embedding these details in every service, synchronization can handle them once, ensuring consistency across the system.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;More advanced directions are also possible. Synchronizations could coordinate distributed systems, keeping replicas on different servers in step, or allow shared databases to interact cleanly. Weakening synchronization semantics could enable eventual consistency while still preserving clarity at the architectural level.&lt;/p&gt;&lt;p dir="ltr"&gt;Jackson sees potential for a broader cultural shift in software development. One idea is the creation of “concept catalogs,” shared libraries of well-tested, domain-specific concepts. Application development could then become less about stitching code together from scratch and more about selecting the right concepts and writing the synchronizations between them. “Concepts could become a new kind of high-level programming language, with synchronizations as the programs written in that language.”&lt;/p&gt;&lt;p dir="ltr"&gt;“It’s a way of making the connections in software visible,” says Jackson. “Today, we hide those connections in code. But if you can see them explicitly, you can reason about the software at a much higher level. You still have to deal with the inherent complexity of features interacting. But now it’s out in the open, not scattered and obscured.”&lt;/p&gt;&lt;p dir="ltr"&gt;“Building software for human use on abstractions from underlying computing machines has burdened the world with software that is all too often costly, frustrating, even dangerous, to understand and use,” says University of Virginia Associate Professor Kevin Sullivan, who wasn’t involved in the research. “The impacts (such as in health care) have been devastating. Meng and Jackson flip the script and insist on building interactive software on abstractions from human understanding, which they call ‘concepts.’ They combine expressive mathematical logic and natural language to specify such purposeful abstractions, providing a basis for verifying their meanings, composing them into systems, and refining them into programs fit for human use. It’s a new and important direction in the theory and practice of software design that bears watching.”&lt;/p&gt;&lt;p&gt;"It’s been clear for many years that we need better ways to describe and specify what we want software to do,” adds Thomas Ball, Lancaster University honorary professor and University of Washington affiliate faculty, who also wasn’t involved in the research. “LLMs’ ability to generate code has only added fuel to the specification fire. Meng and Jackson’s work on concept design provides a promising way to describe what we want from software in a modular manner. Their concepts and specifications are well-suited to be paired with LLMs to achieve the designer's intent.”&lt;/p&gt;&lt;p&gt;Looking ahead, the researchers hope their work can influence how both industry and academia think about software architecture in the age of AI. “If software is to become more trustworthy, we need ways of writing it that make its intentions transparent,” says Jackson. “Concepts and synchronizations are one step toward that goal.”&lt;/p&gt;&lt;p&gt;This work was partially funded by the Machine Learning Applications (MLA) Initiative of CSAIL Alliances. At the time of funding, the initiative board was British Telecom, Cisco, and Ernst and Young.&amp;nbsp;&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202510/MIT-csail-AI-software.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr" id="docs-internal-guid-8faef2c5-7fff-2ff6-d2b4-9dd6f3d78997"&gt;Coding with large language models (LLMs) holds huge promise, but it also exposes some long-standing flaws in software: code that’s messy, hard to change safely, and often opaque about what’s really happening under the hood. Researchers at MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) are charting a more “modular” path ahead.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr" id="docs-internal-guid-8faef2c5-7fff-2ff6-d2b4-9dd6f3d78997"&gt;Their new approach breaks systems into “concepts,” separate pieces of a system, each designed to do one job well, and “synchronizations,” explicit rules that describe exactly how those pieces fit together. The result is software that’s more modular, transparent, and easier to understand. A small domain-specific language (DSL) makes it possible to express synchronizations simply, in a form that LLMs can reliably generate. In a real-world case study, the team showed how this method can bring together features that would otherwise be scattered across multiple services.&lt;/p&gt;&lt;p dir="ltr"&gt;The team, including Daniel Jackson, an MIT professor of electrical engineering and computer science (EECS) and CSAIL associate director, and Eagon Meng, an EECS PhD student, CSAIL affiliate, and designer of the new synchronization DSL, explore this approach in their paper “What You See Is What It Does: A Structural Pattern for Legible Software,” which they presented at the Splash Conference in Singapore in October.&amp;nbsp;The challenge, they explain, is that in most modern systems, a single feature is never fully self-contained. Adding a “share” button to a social platform like Instagram, for example, doesn’t live in just one service. Its functionality is split across code that handles posting, notification, authenticating users, and more. All these pieces, despite being scattered across the code, must be carefully aligned, and any change risks unintended side effects elsewhere.&lt;/p&gt;&lt;p dir="ltr"&gt;Jackson calls this “feature fragmentation,” a central obstacle to software reliability. “The way we build software today, the functionality is not localized. You want to understand how ‘sharing’ works, but you have to hunt for it in three or four different places, and when you find it, the connections are buried in low-level code,” says Jackson.&lt;/p&gt;&lt;p dir="ltr"&gt;Concepts and synchronizations are meant to tackle this problem. A concept bundles up a single, coherent piece of functionality, like sharing, liking, or following, along with its state and the actions it can take. Synchronizations, on the other hand, describe at a higher level how those concepts interact. Rather than writing messy low-level integration code, developers can use a small domain-specific language to spell out these connections directly. In this DSL, the rules are simple and clear: one concept’s action can trigger another, so that a change in one piece of state can be kept in sync with another.&lt;/p&gt;&lt;p dir="ltr"&gt;“Think of concepts as modules that are completely clean and independent. Synchronizations then act like contracts — they say exactly how concepts are supposed to interact. That’s powerful because it makes the system both easier for humans to understand and easier for tools like LLMs to generate correctly,” says Jackson. “Why can’t we read code like a book? We believe that software should be legible and written in terms of our understanding: our hope is that concepts map to familiar phenomena, and synchronizations represent our intuition about what happens when they come together,” says Meng.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;The benefits extend beyond clarity. Because synchronizations are explicit and declarative, they can be analyzed, verified, and of course generated by an LLM. This opens the door to safer, more automated software development, where AI assistants can propose new features without introducing hidden side effects.&lt;/p&gt;&lt;p dir="ltr"&gt;In their case study, the researchers assigned features like liking, commenting, and sharing each to a single concept — like a microservices architecture, but more modular. Without this pattern, these features were spread across many services, making them hard to locate and test. Using the concepts-and-synchronizations approach, each feature became centralized and legible, while the synchronizations spelled out exactly how the concepts interacted.&lt;/p&gt;&lt;p dir="ltr"&gt;The study also showed how synchronizations can factor out common concerns like error handling, response formatting, or persistent storage. Instead of embedding these details in every service, synchronization can handle them once, ensuring consistency across the system.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;More advanced directions are also possible. Synchronizations could coordinate distributed systems, keeping replicas on different servers in step, or allow shared databases to interact cleanly. Weakening synchronization semantics could enable eventual consistency while still preserving clarity at the architectural level.&lt;/p&gt;&lt;p dir="ltr"&gt;Jackson sees potential for a broader cultural shift in software development. One idea is the creation of “concept catalogs,” shared libraries of well-tested, domain-specific concepts. Application development could then become less about stitching code together from scratch and more about selecting the right concepts and writing the synchronizations between them. “Concepts could become a new kind of high-level programming language, with synchronizations as the programs written in that language.”&lt;/p&gt;&lt;p dir="ltr"&gt;“It’s a way of making the connections in software visible,” says Jackson. “Today, we hide those connections in code. But if you can see them explicitly, you can reason about the software at a much higher level. You still have to deal with the inherent complexity of features interacting. But now it’s out in the open, not scattered and obscured.”&lt;/p&gt;&lt;p dir="ltr"&gt;“Building software for human use on abstractions from underlying computing machines has burdened the world with software that is all too often costly, frustrating, even dangerous, to understand and use,” says University of Virginia Associate Professor Kevin Sullivan, who wasn’t involved in the research. “The impacts (such as in health care) have been devastating. Meng and Jackson flip the script and insist on building interactive software on abstractions from human understanding, which they call ‘concepts.’ They combine expressive mathematical logic and natural language to specify such purposeful abstractions, providing a basis for verifying their meanings, composing them into systems, and refining them into programs fit for human use. It’s a new and important direction in the theory and practice of software design that bears watching.”&lt;/p&gt;&lt;p&gt;"It’s been clear for many years that we need better ways to describe and specify what we want software to do,” adds Thomas Ball, Lancaster University honorary professor and University of Washington affiliate faculty, who also wasn’t involved in the research. “LLMs’ ability to generate code has only added fuel to the specification fire. Meng and Jackson’s work on concept design provides a promising way to describe what we want from software in a modular manner. Their concepts and specifications are well-suited to be paired with LLMs to achieve the designer's intent.”&lt;/p&gt;&lt;p&gt;Looking ahead, the researchers hope their work can influence how both industry and academia think about software architecture in the age of AI. “If software is to become more trustworthy, we need ways of writing it that make its intentions transparent,” says Jackson. “Concepts and synchronizations are one step toward that goal.”&lt;/p&gt;&lt;p&gt;This work was partially funded by the Machine Learning Applications (MLA) Initiative of CSAIL Alliances. At the time of funding, the initiative board was British Telecom, Cisco, and Ernst and Young.&amp;nbsp;&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/mit-researchers-propose-new-model-for-legible-modular-software-1106</guid><pubDate>Thu, 06 Nov 2025 13:00:00 +0000</pubDate></item><item><title>[NEW] When industry knowledge meets PIKE-RAG: The innovation behind Signify’s customer service boost (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/blog/when-industry-knowledge-meets-pike-rag-the-innovation-behind-signifys-customer-service-boost/</link><description>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Three white icons on a blue-to-purple gradient background: the first icon shows a node cluster, the second shows a person in front of a screen with another person, the third is a magnifying glass" class="wp-image-1154222" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/10/PIKERAG-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;p&gt;As a world leader in connected LED lighting products, systems, and services, Signify (formerly Philips Lighting) serves not only everyday consumers but also a large number of professional users who have stringent requirements for technical specifications and engineering compatibility. Faced with thousands of product models, complex component parameters, and technical documentation spanning multiple versions, delivering accurate, professional answers efficiently has become a core challenge for Signify’s knowledge management system.&lt;/p&gt;



&lt;p&gt;To address this challenge, Signify&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; collaborated with Microsoft Research Asia on a proof-of-concept (PoC) using PIKE-RAG technology, integrating it into their upgraded knowledge management system built on Microsoft Azure. The result: a 12% improvement in answer accuracy.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="challenges-of-applying-rag-in-lighting"&gt;Challenges of applying RAG in lighting&lt;/h2&gt;



&lt;p&gt;In an era where AI is rapidly transforming how enterprises manage information, Signify recognized the strategic importance of precise and efficient knowledge systems. It adopted large AI models and retrieval-augmented generation (RAG) techniques to better support its wide range of customer inquiries.&lt;/p&gt;




	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;Azure AI Foundry Labs&lt;/h2&gt;
				
								&lt;p class="large" id="azure-ai-foundry-labs"&gt;Get a glimpse of potential future directions for AI, with these experimental technologies from Microsoft Research.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;&lt;!-- promos injected --&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	&lt;p&gt;Yet applying RAG to lighting scenarios involving professional users presented unique challenges. Product data spanned multimodal documents, unstructured tables, and complex product parameters, demanding continuous customization that slowed development and limited scalability. Despite improvements through keyword tuning, system optimization, and refined prompts, Signify sought more advanced approaches to further raise accuracy and reliability.&lt;/p&gt;



&lt;p&gt;Seeking to unlock greater value from its knowledge management system, Signify began exploring more suitable technical solutions that are better aligned with their professional use cases. Upon learning that PIKE-RAG had been successfully applied in domains like healthcare and law, significantly improving information accuracy, Signify worked with Microsoft Research Asia on a PoC of PIKE-RAG on Microsoft Azure.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="how-pike-rag-addressed-signify-s-pain-points"&gt;How PIKE-RAG addressed Signify’s pain points&lt;/h2&gt;



&lt;p&gt;Compared to traditional RAG, PIKE-RAG efficiently retrieves textual information and also understands multimodal content like charts and tables. Its built-in domain adaptation module quickly learns reasoning patterns aligned with specific domains to generate responses that are consistent with engineering contexts. These differentiated advantages stem from PIKE-RAG’s unique approach to understanding and processing professional knowledge. In Signify’s use case, this manifests in three key areas:&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="multimodal-document-parsing-and-learning-of-industry-specific-reasoning-patterns"&gt;Multimodal document parsing and learning of industry-specific reasoning patterns&lt;/h3&gt;



&lt;p&gt;Signify’s product documentation includes diverse formats, such as nonstandard tables (e.g., comparison charts of voltage ranges under different currents) and circuit diagrams (e.g., driver power limits). Traditional systems often fail to process this information effectively—either ignoring it or extracting disorganized text fragments.&lt;/p&gt;



&lt;p&gt;PIKE-RAG integrates Microsoft Research Asia’s Document Intelligence technology with Microsoft Azure OpenAI models to accurately identify table structures and parse key parameters in circuit diagrams. For example, when a customer service agent queries, “What is the output voltage of a specific driver model at 0.15A current,” the system automatically locates the curve chart in the document and infers a range of 40–54V based on the current interval—an area where traditional systems frequently err, due to their inability to “read” diagrams.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="end-to-end-knowledge-loop-eliminating-reliance-on-erroneous-data-sources"&gt;End-to-end knowledge loop, eliminating reliance on erroneous data sources&lt;/h3&gt;



&lt;p&gt;Enterprise knowledge systems often integrate data from multiple sources, which can lead to discrepancies, especially when database updates are not fully synchronized. PIKE-RAG captures diverse information sources and establishes citation relationships, supporting complex reasoning tasks that rely on multi-source data.&lt;/p&gt;



&lt;p&gt;In other words, PIKE-RAG can directly use original documents as data sources, efficiently parsing and understanding product manuals and PDF charts. By extracting key information from these text- and graphic-rich documents, PIKE-RAG enables more efficient and trustworthy knowledge retrieval.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="dynamic-task-decomposition-and-multi-hop-reasoning-for-precise-answers-to-complex-questions"&gt;Dynamic task decomposition and multi-hop reasoning for precise answers to complex questions&lt;/h3&gt;



&lt;p&gt;Traditional RAG systems typically follow a “one question, one answer” model and struggle with multi-step reasoning. In Signify’s lighting domain, customer inquiries often involve multi-level associations. PIKE-RAG dynamically decomposes user questions into executable subtasks and solves them through multi-hop reasoning. For example, when asked, “List all bases compatible with the G8 series lamps,” if no document directly provides the answer, PIKE-RAG’s reasoning proceeds as follows:&lt;/p&gt;



&lt;p&gt;Step 1: The system identifies implicit knowledge. One document notes that the G7 and G8 series have identical dimensions and that all bases compatible with the G7 series are also compatible with the G8 series.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Step 2: Based on this, the system retrieves the base list for the G7 series.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Step 3: Since the list uses abbreviations, the system searches for a table that maps abbreviations to full names and generates a complete list of G8-compatible bases.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Through this automated multi-hop reasoning, the system delivers accurate and complete answers.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 1: A flowchart illustrating the PIKE-RAG framework for orchestrating and integrating heterogeneous information across multi-source and multimodal environments. At the center is a language model (LM) connected to PIKE-RAG, which performs iterative retrieval by tool calling. The process starts with a task (e.g., “What wireless drivers are available?”), followed by iterative task decomposition and retrieval from a tools repository. The tools repository includes similarity and keyword retrieval, Text2SQL, decomposers, VLMs, verifiers, and atomizers. Below, domain knowledge is shown in various forms: textual (terminology, specifications), multi-modal (figures, tables), structural (databases, knowledge graphs), and others (search engine, internal FAQ). The LM generates responses and updates memory while fetching context as needed." class="wp-image-1154223" height="451" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/10/PIKERAG_figure-1-new.png" width="865" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 1: PIKE-RAG orchestrates and integrates heterogeneous information in multi-source and multimodal environments. &lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Testing showed that the PIKE-RAG-powered knowledge management platform provided a significant advantage. It achieved a 12% improvement in performance compared with the original system.&lt;/p&gt;



&lt;p&gt;These results were achieved without any question-specific customization, only algorithmic optimization, demonstrating precise knowledge matching and generation. As the system continues to learn and integrate Signify’s proprietary knowledge, accuracy is expected to improve further.&lt;/p&gt;



&lt;p&gt;“In the PoC for our product specification insight tool, PIKE-RAG helped us significantly improve the original system’s performance. This will enhance overall customer satisfaction. We’re currently evaluating PIKE-RAG’s application path from multiple angles, including technical implementation, cost control, and future adaptability, and we look forward to deepening our collaboration with Microsoft Research Asia to drive further innovation,” said Haitao Liu, head of Signify Research China.&lt;/p&gt;



&lt;p&gt;“It’s also worth noting that the researchers at Microsoft Research Asia demonstrated strong industry knowledge and rigorous scientific methodology. They proactively studied and analyzed the issues, tracing and clarifying the root causes of our issues to make PIKE-RAG better suited to Signify’s real-world needs.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="beyond-lighting-generalization-across-industries"&gt;Beyond lighting: Generalization across industries&lt;/h2&gt;



&lt;p&gt;In Signify’s successful test, PIKE-RAG demonstrated strong generalization capabilities in complex industrial scenarios, enabling rapid cross-domain adaptation. Its three core strengths are:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Support for self-evolution and continuous learning&lt;/strong&gt;: PIKE-RAG continuously analyzes error cases in interaction logs and uses evolutionary algorithms to automatically optimize knowledge extraction strategies, such as trying different table parsing methods or adjusting multimodal content weights. Validated strategies are then solidified for future Q&amp;amp;A, allowing the system to adapt to new knowledge types without manual intervention.&amp;nbsp;&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Modular architecture driven by capability needs&lt;/strong&gt;: PIKE-RAG flexibly combines modules for document parsing, knowledge extraction, storage, retrieval, organization, knowledge-centered reasoning, and task decomposition. It dynamically adjusts focus areas based on scenario needs (e.g., fact retrieval, multi-hop reasoning, innovative generation) and flexibly builds RAG methods that adapt to real-world applications, efficiently handling various complex tasks.&amp;nbsp;&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Strong adaptation to domain-specific reasoning patterns&lt;/strong&gt;: With dynamic updates through the Domain Tips feature, enterprises can add domain-specific logic (e.g., “the maximum output voltage of an LED driver should be the maximum of the operating range, not the spec sheet’s max output”) in real time, enabling the system to process information according to professional engineering standards and follow industry conventions.&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 2: Diagram showing the PIKE-RAG framework overview. At the center is a language model (LM) connected to PIKE-RAG, which performs iterative retrieval by tool calling. The process begins with a task input, decomposes it into sub-tasks, retrieves information from a tools repository, and integrates domain knowledge from multiple modalities such as textual documents, diagrams, tables, relational databases, and knowledge graphs. The LM generates responses and updates memory while orchestrating heterogeneous information sources." class="wp-image-1154224" height="563" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/10/PIKERAG_figure-2.png" width="865" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 2: Overview of the PIKE-RAG framework&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;PIKE-RAG’s generalization capabilities have been validated not only in Signify’s knowledge management platform but also in pilot applications across industries like manufacturing, mining, and pharmaceuticals—significantly improving Q&amp;amp;A system accuracy.&lt;/p&gt;



&lt;p&gt;“A leader in lighting, Signify presents a complex industrial knowledge system with a highly challenging real-world scenario for PIKE-RAG. Through this collaboration, we validated that PIKE-RAG’s general approach can greatly improve the accuracy of professional knowledge Q&amp;amp;A and accelerate scenario customization. Our researchers also gained valuable experience in handling domain-specific data,” explained Jiang Bian, partner research manager at Microsoft Research Asia.&lt;/p&gt;



&lt;p&gt;“Our goal isn’t to build a universal chatbot but to create a professional assistant that aligns with domain-specific logic and performs rigorous knowledge reasoning. That’s the true driving force behind intelligent transformation in industrial knowledge management.”&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;&lt;!-- promos injected --&gt;</description><content:encoded>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Three white icons on a blue-to-purple gradient background: the first icon shows a node cluster, the second shows a person in front of a screen with another person, the third is a magnifying glass" class="wp-image-1154222" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/10/PIKERAG-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;p&gt;As a world leader in connected LED lighting products, systems, and services, Signify (formerly Philips Lighting) serves not only everyday consumers but also a large number of professional users who have stringent requirements for technical specifications and engineering compatibility. Faced with thousands of product models, complex component parameters, and technical documentation spanning multiple versions, delivering accurate, professional answers efficiently has become a core challenge for Signify’s knowledge management system.&lt;/p&gt;



&lt;p&gt;To address this challenge, Signify&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; collaborated with Microsoft Research Asia on a proof-of-concept (PoC) using PIKE-RAG technology, integrating it into their upgraded knowledge management system built on Microsoft Azure. The result: a 12% improvement in answer accuracy.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="challenges-of-applying-rag-in-lighting"&gt;Challenges of applying RAG in lighting&lt;/h2&gt;



&lt;p&gt;In an era where AI is rapidly transforming how enterprises manage information, Signify recognized the strategic importance of precise and efficient knowledge systems. It adopted large AI models and retrieval-augmented generation (RAG) techniques to better support its wide range of customer inquiries.&lt;/p&gt;




	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;Azure AI Foundry Labs&lt;/h2&gt;
				
								&lt;p class="large" id="azure-ai-foundry-labs"&gt;Get a glimpse of potential future directions for AI, with these experimental technologies from Microsoft Research.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;&lt;!-- promos injected --&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	&lt;p&gt;Yet applying RAG to lighting scenarios involving professional users presented unique challenges. Product data spanned multimodal documents, unstructured tables, and complex product parameters, demanding continuous customization that slowed development and limited scalability. Despite improvements through keyword tuning, system optimization, and refined prompts, Signify sought more advanced approaches to further raise accuracy and reliability.&lt;/p&gt;



&lt;p&gt;Seeking to unlock greater value from its knowledge management system, Signify began exploring more suitable technical solutions that are better aligned with their professional use cases. Upon learning that PIKE-RAG had been successfully applied in domains like healthcare and law, significantly improving information accuracy, Signify worked with Microsoft Research Asia on a PoC of PIKE-RAG on Microsoft Azure.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="how-pike-rag-addressed-signify-s-pain-points"&gt;How PIKE-RAG addressed Signify’s pain points&lt;/h2&gt;



&lt;p&gt;Compared to traditional RAG, PIKE-RAG efficiently retrieves textual information and also understands multimodal content like charts and tables. Its built-in domain adaptation module quickly learns reasoning patterns aligned with specific domains to generate responses that are consistent with engineering contexts. These differentiated advantages stem from PIKE-RAG’s unique approach to understanding and processing professional knowledge. In Signify’s use case, this manifests in three key areas:&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="multimodal-document-parsing-and-learning-of-industry-specific-reasoning-patterns"&gt;Multimodal document parsing and learning of industry-specific reasoning patterns&lt;/h3&gt;



&lt;p&gt;Signify’s product documentation includes diverse formats, such as nonstandard tables (e.g., comparison charts of voltage ranges under different currents) and circuit diagrams (e.g., driver power limits). Traditional systems often fail to process this information effectively—either ignoring it or extracting disorganized text fragments.&lt;/p&gt;



&lt;p&gt;PIKE-RAG integrates Microsoft Research Asia’s Document Intelligence technology with Microsoft Azure OpenAI models to accurately identify table structures and parse key parameters in circuit diagrams. For example, when a customer service agent queries, “What is the output voltage of a specific driver model at 0.15A current,” the system automatically locates the curve chart in the document and infers a range of 40–54V based on the current interval—an area where traditional systems frequently err, due to their inability to “read” diagrams.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="end-to-end-knowledge-loop-eliminating-reliance-on-erroneous-data-sources"&gt;End-to-end knowledge loop, eliminating reliance on erroneous data sources&lt;/h3&gt;



&lt;p&gt;Enterprise knowledge systems often integrate data from multiple sources, which can lead to discrepancies, especially when database updates are not fully synchronized. PIKE-RAG captures diverse information sources and establishes citation relationships, supporting complex reasoning tasks that rely on multi-source data.&lt;/p&gt;



&lt;p&gt;In other words, PIKE-RAG can directly use original documents as data sources, efficiently parsing and understanding product manuals and PDF charts. By extracting key information from these text- and graphic-rich documents, PIKE-RAG enables more efficient and trustworthy knowledge retrieval.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="dynamic-task-decomposition-and-multi-hop-reasoning-for-precise-answers-to-complex-questions"&gt;Dynamic task decomposition and multi-hop reasoning for precise answers to complex questions&lt;/h3&gt;



&lt;p&gt;Traditional RAG systems typically follow a “one question, one answer” model and struggle with multi-step reasoning. In Signify’s lighting domain, customer inquiries often involve multi-level associations. PIKE-RAG dynamically decomposes user questions into executable subtasks and solves them through multi-hop reasoning. For example, when asked, “List all bases compatible with the G8 series lamps,” if no document directly provides the answer, PIKE-RAG’s reasoning proceeds as follows:&lt;/p&gt;



&lt;p&gt;Step 1: The system identifies implicit knowledge. One document notes that the G7 and G8 series have identical dimensions and that all bases compatible with the G7 series are also compatible with the G8 series.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Step 2: Based on this, the system retrieves the base list for the G7 series.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Step 3: Since the list uses abbreviations, the system searches for a table that maps abbreviations to full names and generates a complete list of G8-compatible bases.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Through this automated multi-hop reasoning, the system delivers accurate and complete answers.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 1: A flowchart illustrating the PIKE-RAG framework for orchestrating and integrating heterogeneous information across multi-source and multimodal environments. At the center is a language model (LM) connected to PIKE-RAG, which performs iterative retrieval by tool calling. The process starts with a task (e.g., “What wireless drivers are available?”), followed by iterative task decomposition and retrieval from a tools repository. The tools repository includes similarity and keyword retrieval, Text2SQL, decomposers, VLMs, verifiers, and atomizers. Below, domain knowledge is shown in various forms: textual (terminology, specifications), multi-modal (figures, tables), structural (databases, knowledge graphs), and others (search engine, internal FAQ). The LM generates responses and updates memory while fetching context as needed." class="wp-image-1154223" height="451" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/10/PIKERAG_figure-1-new.png" width="865" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 1: PIKE-RAG orchestrates and integrates heterogeneous information in multi-source and multimodal environments. &lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Testing showed that the PIKE-RAG-powered knowledge management platform provided a significant advantage. It achieved a 12% improvement in performance compared with the original system.&lt;/p&gt;



&lt;p&gt;These results were achieved without any question-specific customization, only algorithmic optimization, demonstrating precise knowledge matching and generation. As the system continues to learn and integrate Signify’s proprietary knowledge, accuracy is expected to improve further.&lt;/p&gt;



&lt;p&gt;“In the PoC for our product specification insight tool, PIKE-RAG helped us significantly improve the original system’s performance. This will enhance overall customer satisfaction. We’re currently evaluating PIKE-RAG’s application path from multiple angles, including technical implementation, cost control, and future adaptability, and we look forward to deepening our collaboration with Microsoft Research Asia to drive further innovation,” said Haitao Liu, head of Signify Research China.&lt;/p&gt;



&lt;p&gt;“It’s also worth noting that the researchers at Microsoft Research Asia demonstrated strong industry knowledge and rigorous scientific methodology. They proactively studied and analyzed the issues, tracing and clarifying the root causes of our issues to make PIKE-RAG better suited to Signify’s real-world needs.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="beyond-lighting-generalization-across-industries"&gt;Beyond lighting: Generalization across industries&lt;/h2&gt;



&lt;p&gt;In Signify’s successful test, PIKE-RAG demonstrated strong generalization capabilities in complex industrial scenarios, enabling rapid cross-domain adaptation. Its three core strengths are:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Support for self-evolution and continuous learning&lt;/strong&gt;: PIKE-RAG continuously analyzes error cases in interaction logs and uses evolutionary algorithms to automatically optimize knowledge extraction strategies, such as trying different table parsing methods or adjusting multimodal content weights. Validated strategies are then solidified for future Q&amp;amp;A, allowing the system to adapt to new knowledge types without manual intervention.&amp;nbsp;&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Modular architecture driven by capability needs&lt;/strong&gt;: PIKE-RAG flexibly combines modules for document parsing, knowledge extraction, storage, retrieval, organization, knowledge-centered reasoning, and task decomposition. It dynamically adjusts focus areas based on scenario needs (e.g., fact retrieval, multi-hop reasoning, innovative generation) and flexibly builds RAG methods that adapt to real-world applications, efficiently handling various complex tasks.&amp;nbsp;&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Strong adaptation to domain-specific reasoning patterns&lt;/strong&gt;: With dynamic updates through the Domain Tips feature, enterprises can add domain-specific logic (e.g., “the maximum output voltage of an LED driver should be the maximum of the operating range, not the spec sheet’s max output”) in real time, enabling the system to process information according to professional engineering standards and follow industry conventions.&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 2: Diagram showing the PIKE-RAG framework overview. At the center is a language model (LM) connected to PIKE-RAG, which performs iterative retrieval by tool calling. The process begins with a task input, decomposes it into sub-tasks, retrieves information from a tools repository, and integrates domain knowledge from multiple modalities such as textual documents, diagrams, tables, relational databases, and knowledge graphs. The LM generates responses and updates memory while orchestrating heterogeneous information sources." class="wp-image-1154224" height="563" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/10/PIKERAG_figure-2.png" width="865" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 2: Overview of the PIKE-RAG framework&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;PIKE-RAG’s generalization capabilities have been validated not only in Signify’s knowledge management platform but also in pilot applications across industries like manufacturing, mining, and pharmaceuticals—significantly improving Q&amp;amp;A system accuracy.&lt;/p&gt;



&lt;p&gt;“A leader in lighting, Signify presents a complex industrial knowledge system with a highly challenging real-world scenario for PIKE-RAG. Through this collaboration, we validated that PIKE-RAG’s general approach can greatly improve the accuracy of professional knowledge Q&amp;amp;A and accelerate scenario customization. Our researchers also gained valuable experience in handling domain-specific data,” explained Jiang Bian, partner research manager at Microsoft Research Asia.&lt;/p&gt;



&lt;p&gt;“Our goal isn’t to build a universal chatbot but to create a professional assistant that aligns with domain-specific logic and performs rigorous knowledge reasoning. That’s the true driving force behind intelligent transformation in industrial knowledge management.”&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;&lt;!-- promos injected --&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/blog/when-industry-knowledge-meets-pike-rag-the-innovation-behind-signifys-customer-service-boost/</guid><pubDate>Thu, 06 Nov 2025 13:00:00 +0000</pubDate></item><item><title>[NEW] Google debuts AI chips with 4X performance boost, secures Anthropic megadeal worth billions (AI | VentureBeat)</title><link>https://venturebeat.com/ai/google-debuts-ai-chips-with-4x-performance-boost-secures-anthropic-megadeal</link><description>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://cloud.google.com/?hl=en"&gt;&lt;u&gt;Google Cloud&lt;/u&gt;&lt;/a&gt; is introducing what it calls its most powerful artificial intelligence infrastructure to date, unveiling a seventh-generation &lt;a href="https://cloud.google.com/tpu?hl=en"&gt;&lt;u&gt;Tensor Processing Unit&lt;/u&gt;&lt;/a&gt; and expanded &lt;a href="https://cloud.google.com/discover/what-are-arm-based-processors?hl=en"&gt;&lt;u&gt;Arm-based computing options&lt;/u&gt;&lt;/a&gt; designed to meet surging demand for AI model deployment — what the company characterizes as a fundamental industry shift from training models to serving them to billions of users.&lt;/p&gt;&lt;p&gt;The announcement, made Thursday, centers on &lt;a href="https://cloud.google.com/resources/ironwood-tpu-interest?utm_source=cgc-blog&amp;amp;utm_medium=blog&amp;amp;utm_campaign=FY25-Q2-global-ENT33820-website-cs-ironwood-tpu-interest&amp;amp;utm_content=ironwood_announcement_blog&amp;amp;utm_term=ironwood&amp;amp;hl=en"&gt;&lt;u&gt;Ironwood&lt;/u&gt;&lt;/a&gt;, Google&amp;#x27;s latest custom AI accelerator chip, which will become generally available in the coming weeks. In a striking validation of the technology, &lt;a href="https://www.anthropic.com/"&gt;&lt;u&gt;Anthropic&lt;/u&gt;&lt;/a&gt;, the AI safety company behind the Claude family of models, disclosed plans to access up to &lt;a href="https://www.googlecloudpresscorner.com/2025-10-23-Anthropic-to-Expand-Use-of-Google-Cloud-TPUs-and-Services"&gt;&lt;u&gt;one million of these TPU chips&lt;/u&gt;&lt;/a&gt; — a commitment worth tens of billions of dollars and among the largest known AI infrastructure deals to date.&lt;/p&gt;&lt;p&gt;The move underscores an intensifying competition among cloud providers to control the infrastructure layer powering artificial intelligence, even as questions mount about whether the industry can sustain its current pace of capital expenditure. Google&amp;#x27;s approach — building custom silicon rather than relying solely on &lt;a href="https://www.reuters.com/business/nvidia-poised-record-5-trillion-market-valuation-2025-10-29/"&gt;&lt;u&gt;Nvidia&amp;#x27;s dominant GPU chips&lt;/u&gt;&lt;/a&gt; — amounts to a long-term bet that vertical integration from chip design through software will deliver superior economics and performance.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Why companies are racing to serve AI models, not just train them&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Google executives framed the announcements around what they call &amp;quot;the age of inference&amp;quot; — a transition point where companies shift resources from training frontier AI models to deploying them in production applications serving millions or billions of requests daily.&lt;/p&gt;&lt;p&gt;&amp;quot;Today&amp;#x27;s frontier models, including Google&amp;#x27;s Gemini, Veo, and Imagen and Anthropic&amp;#x27;s Claude train and serve on Tensor Processing Units,&amp;quot; said Amin Vahdat, vice president and general manager of AI and Infrastructure at Google Cloud. &amp;quot;For many organizations, the focus is shifting from training these models to powering useful, responsive interactions with them.&amp;quot;&lt;/p&gt;&lt;p&gt;This transition has profound implications for infrastructure requirements. Where training workloads can often tolerate batch processing and longer completion times, inference — the process of actually running a trained model to generate responses — demands consistently low latency, high throughput, and unwavering reliability. A chatbot that takes 30 seconds to respond, or a coding assistant that frequently times out, becomes unusable regardless of the underlying model&amp;#x27;s capabilities.&lt;/p&gt;&lt;p&gt;Agentic workflows — where AI systems take autonomous actions rather than simply responding to prompts — create particularly complex infrastructure challenges, requiring tight coordination between specialized AI accelerators and general-purpose computing.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Inside Ironwood&amp;#x27;s architecture: 9,216 chips working as one supercomputer&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;&lt;a href="https://cloud.google.com/resources/ironwood-tpu-interest?utm_source=cgc-blog&amp;amp;utm_medium=blog&amp;amp;utm_campaign=FY25-Q2-global-ENT33820-website-cs-ironwood-tpu-interest&amp;amp;utm_content=ironwood_announcement_blog&amp;amp;utm_term=ironwood&amp;amp;hl=en"&gt;&lt;u&gt;Ironwood&lt;/u&gt;&lt;/a&gt; is more than incremental improvement over Google&amp;#x27;s sixth-generation TPUs. According to technical specifications shared by the company, it delivers more than four times better performance for both training and inference workloads compared to its predecessor — gains that Google attributes to a system-level co-design approach rather than simply increasing transistor counts.&lt;/p&gt;&lt;p&gt;The architecture&amp;#x27;s most striking feature is its scale. A single Ironwood &amp;quot;pod&amp;quot; — a tightly integrated unit of TPU chips functioning as one supercomputer — can connect up to 9,216 individual chips through Google&amp;#x27;s proprietary &lt;a href="https://blog.google/products/google-cloud/ironwood-tpu-age-of-inference/"&gt;&lt;u&gt;Inter-Chip Interconnect network&lt;/u&gt;&lt;/a&gt; operating at 9.6 terabits per second. To put that bandwidth in perspective, it&amp;#x27;s roughly equivalent to downloading the entire Library of Congress in under two seconds.&lt;/p&gt;&lt;p&gt;This massive interconnect fabric allows the 9,216 chips to share access to 1.77 petabytes of &lt;a href="https://blog.google/products/google-cloud/ironwood-tpu-age-of-inference/"&gt;&lt;u&gt;High Bandwidth Memory&lt;/u&gt;&lt;/a&gt; — memory fast enough to keep pace with the chips&amp;#x27; processing speeds. That&amp;#x27;s approximately 40,000 high-definition Blu-ray movies&amp;#x27; worth of working memory, instantly accessible by thousands of processors simultaneously. &amp;quot;For context, that means Ironwood Pods can deliver 118x more FP8 ExaFLOPS versus the next closest competitor,&amp;quot; Google stated in technical documentation.&lt;/p&gt;&lt;p&gt;The system employs &lt;a href="https://www.opencompute.org/projects/optical-circuit-switching"&gt;&lt;u&gt;Optical Circuit Switching&lt;/u&gt;&lt;/a&gt; technology that acts as a &amp;quot;dynamic, reconfigurable fabric.&amp;quot; When individual components fail or require maintenance — inevitable at this scale — the OCS technology automatically reroutes data traffic around the interruption within milliseconds, allowing workloads to continue running without user-visible disruption.&lt;/p&gt;&lt;p&gt;This reliability focus reflects lessons learned from deploying five previous TPU generations. Google reported that its fleet-wide uptime for liquid-cooled systems has maintained approximately 99.999% availability since 2020 — equivalent to less than six minutes of downtime per year.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Anthropic&amp;#x27;s billion-dollar bet validates Google&amp;#x27;s custom silicon strategy&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Perhaps the most significant external validation of Ironwood&amp;#x27;s capabilities comes from &lt;a href="https://www.googlecloudpresscorner.com/2025-10-23-Anthropic-to-Expand-Use-of-Google-Cloud-TPUs-and-Services"&gt;&lt;u&gt;Anthropic&amp;#x27;s commitment to access up to one million TPU chips&lt;/u&gt;&lt;/a&gt; — a staggering figure in an industry where even clusters of 10,000 to 50,000 accelerators are considered massive.&lt;/p&gt;&lt;p&gt;&amp;quot;Anthropic and Google have a longstanding partnership and this latest expansion will help us continue to grow the compute we need to define the frontier of AI,&amp;quot; said Krishna Rao, Anthropic&amp;#x27;s chief financial officer, in the official partnership agreement. &amp;quot;Our customers — from Fortune 500 companies to AI-native startups — depend on Claude for their most important work, and this expanded capacity ensures we can meet our exponentially growing demand.&amp;quot;&lt;/p&gt;&lt;p&gt;According to a separate statement, Anthropic will have access to &amp;quot;well over a gigawatt of capacity coming online in 2026&amp;quot; — enough electricity to power a small city. The company specifically cited TPUs&amp;#x27; &amp;quot;price-performance and efficiency&amp;quot; as key factors in the decision, along with &amp;quot;existing experience in training and serving its models with TPUs.&amp;quot;&lt;/p&gt;&lt;p&gt;Industry analysts estimate that a commitment to access one million TPU chips, with associated infrastructure, networking, power, and cooling, likely represents a &lt;a href="https://www.reuters.com/technology/anthropic-expand-use-google-clouds-tpu-chips-2025-10-23/"&gt;&lt;u&gt;multi-year contract worth tens of billions of dollars&lt;/u&gt;&lt;/a&gt; — among the largest known cloud infrastructure commitments in history.&lt;/p&gt;&lt;p&gt;James Bradbury, Anthropic&amp;#x27;s head of compute, elaborated on the inference focus: &amp;quot;Ironwood&amp;#x27;s improvements in both inference performance and training scalability will help us scale efficiently while maintaining the speed and reliability our customers expect.&amp;quot;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Google&amp;#x27;s Axion processors target the computing workloads that make AI possible&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Alongside &lt;a href="https://cloud.google.com/resources/ironwood-tpu-interest?utm_source=cgc-blog&amp;amp;utm_medium=blog&amp;amp;utm_campaign=FY25-Q2-global-ENT33820-website-cs-ironwood-tpu-interest&amp;amp;utm_content=ironwood_announcement_blog&amp;amp;utm_term=ironwood&amp;amp;hl=en"&gt;&lt;u&gt;Ironwood&lt;/u&gt;&lt;/a&gt;, Google introduced expanded options for its &lt;a href="https://cloud.google.com/products/axion?hl=en"&gt;&lt;u&gt;Axion processor family&lt;/u&gt;&lt;/a&gt; — custom Arm-based CPUs designed for general-purpose workloads that support AI applications but don&amp;#x27;t require specialized accelerators.&lt;/p&gt;&lt;p&gt;The &lt;a href="http://forms.gle/HYY5FWRKewYuDMB27"&gt;&lt;u&gt;N4A instance type&lt;/u&gt;&lt;/a&gt;, now entering preview, targets what Google describes as &amp;quot;microservices, containerized applications, open-source databases, batch, data analytics, development environments, experimentation, data preparation and web serving jobs that make AI applications possible.&amp;quot; The company claims N4A delivers up to 2X better price-performance than comparable current-generation x86-based virtual machines.&lt;/p&gt;&lt;p&gt;Google is also &lt;a href="https://docs.google.com/forms/d/e/1FAIpQLSd14sMYz79SeRI665dM7lnUbsAg7zilVPdDfK2_6u1vBmiUfg/viewform?usp=send_form"&gt;&lt;u&gt;previewing C4A metal&lt;/u&gt;&lt;/a&gt;, its first bare-metal Arm instance, which provides dedicated physical servers for specialized workloads such as Android development, automotive systems, and software with strict licensing requirements.&lt;/p&gt;&lt;p&gt;The Axion strategy reflects a growing conviction that the future of computing infrastructure requires both specialized AI accelerators and highly efficient general-purpose processors. While a TPU handles the computationally intensive task of running an AI model, Axion-class processors manage data ingestion, preprocessing, application logic, API serving, and countless other tasks in a modern AI application stack.&lt;/p&gt;&lt;p&gt;Early customer results suggest the approach delivers measurable economic benefits. Vimeo reported observing &amp;quot;a 30% improvement in performance for our core transcoding workload compared to comparable x86 VMs&amp;quot; in initial N4A tests. ZoomInfo measured &amp;quot;a 60% improvement in price-performance&amp;quot; for data processing pipelines running on Java services, according to Sergei Koren, the company&amp;#x27;s chief infrastructure architect.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Software tools turn raw silicon performance into developer productivity&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Hardware performance means little if developers cannot easily harness it. Google emphasized that &lt;a href="https://cloud.google.com/resources/ironwood-tpu-interest?utm_source=cgc-blog&amp;amp;utm_medium=blog&amp;amp;utm_campaign=FY25-Q2-global-ENT33820-website-cs-ironwood-tpu-interest&amp;amp;utm_content=ironwood_announcement_blog&amp;amp;utm_term=ironwood&amp;amp;hl=en"&gt;&lt;u&gt;Ironwood&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://cloud.google.com/products/axion?hl=en"&gt;&lt;u&gt;Axion&lt;/u&gt;&lt;/a&gt; are integrated into what it calls &lt;a href="https://cloud.google.com/solutions/ai-hypercomputer"&gt;&lt;u&gt;AI Hypercomputer&lt;/u&gt;&lt;/a&gt; — &amp;quot;an integrated supercomputing system that brings together compute, networking, storage, and software to improve system-level performance and efficiency.&amp;quot;&lt;/p&gt;&lt;p&gt;According to an October 2025 IDC Business Value Snapshot study, AI Hypercomputer customers achieved on average 353% three-year return on investment, 28% lower IT costs, and 55% more efficient IT teams.&lt;/p&gt;&lt;p&gt;Google disclosed several software enhancements designed to maximize Ironwood utilization. &lt;a href="https://cloud.google.com/kubernetes-engine?utm_source=google&amp;amp;utm_medium=cpc&amp;amp;utm_campaign=na-US-all-en-dr-bkws-all-all-trial-e-dr-1710134&amp;amp;utm_content=text-ad-none-any-DEV_c-CRE_772251321321-ADGP_Hybrid+%7C+BKWS+-+EXA+%7C+Txt-AppMod-GKE-Kubernetes+Engine-KWID_369526655975-kwd-369526655975&amp;amp;utm_term=KW_google+kubernetes+engine-ST_google+kubernetes+engine&amp;amp;gclsrc=aw.ds&amp;amp;gad_source=1&amp;amp;gad_campaignid=23052915519&amp;amp;gclid=Cj0KCQiAiKzIBhCOARIsAKpKLAMMFmNaZgmWnQ3CYrziXElfmMXmQphYqoSvICvf6jfUjLqR9XqFt3oaArkYEALw_wcB&amp;amp;hl=en"&gt;&lt;u&gt;Google Kubernetes Engine&lt;/u&gt;&lt;/a&gt; now offers advanced maintenance and topology awareness for TPU clusters, enabling intelligent scheduling and highly resilient deployments. The company&amp;#x27;s &lt;a href="https://github.com/AI-Hypercomputer/maxtext"&gt;&lt;u&gt;open-source MaxText framework&lt;/u&gt;&lt;/a&gt; now supports advanced training techniques including Supervised Fine-Tuning and Generative Reinforcement Policy Optimization.&lt;/p&gt;&lt;p&gt;Perhaps most significant for production deployments, Google&amp;#x27;s &lt;a href="https://docs.cloud.google.com/kubernetes-engine/docs/concepts/about-gke-inference-gateway"&gt;&lt;u&gt;Inference Gateway&lt;/u&gt;&lt;/a&gt; intelligently load-balances requests across model servers to optimize critical metrics. According to Google, it can reduce time-to-first-token latency by 96% and serving costs by up to 30% through techniques like prefix-cache-aware routing.&lt;/p&gt;&lt;p&gt;The &lt;a href="https://docs.cloud.google.com/kubernetes-engine/docs/concepts/about-gke-inference-gateway"&gt;&lt;u&gt;Inference Gateway&lt;/u&gt;&lt;/a&gt; monitors key metrics including KV cache hits, GPU or TPU utilization, and request queue length, then routes incoming requests to the optimal replica. For conversational AI applications where multiple requests might share context, routing requests with shared prefixes to the same server instance can dramatically reduce redundant computation.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;The hidden challenge: powering and cooling one-megawatt server racks&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Behind these announcements lies a massive physical infrastructure challenge that Google addressed at the recent &lt;a href="https://www.opencompute.org/summit/emea-summit"&gt;&lt;u&gt;Open Compute Project EMEA Summit&lt;/u&gt;&lt;/a&gt;. The company disclosed that it&amp;#x27;s implementing +/-400 volt direct current power delivery capable of supporting up to one megawatt per rack — a tenfold increase from typical deployments.&lt;/p&gt;&lt;p&gt;&amp;quot;The AI era requires even greater power delivery capabilities,&amp;quot; explained Madhusudan Iyengar and Amber Huffman, Google principal engineers, in an &lt;a href="https://cloud.google.com/blog/topics/systems/enabling-1-mw-it-racks-and-liquid-cooling-at-ocp-emea-summit"&gt;&lt;u&gt;April 2025 blog post&lt;/u&gt;&lt;/a&gt;. &amp;quot;ML will require more than 500 kW per IT rack before 2030.&amp;quot;&lt;/p&gt;&lt;p&gt;Google is collaborating with Meta and Microsoft to standardize electrical and mechanical interfaces for high-voltage DC distribution. The company selected &lt;a href="https://www.opencompute.org/files/OCP18-400VDC-Efficiency-02.pdf"&gt;&lt;u&gt;400 VDC&lt;/u&gt;&lt;/a&gt; specifically to leverage the supply chain established by electric vehicles, &amp;quot;for greater economies of scale, more efficient manufacturing, and improved quality and scale.&amp;quot;&lt;/p&gt;&lt;p&gt;On cooling, Google revealed it will contribute its fifth-generation cooling distribution unit design to the Open Compute Project. The company has deployed liquid cooling &amp;quot;at GigaWatt scale across more than 2,000 TPU Pods in the past seven years&amp;quot; with fleet-wide availability of approximately 99.999%.&lt;/p&gt;&lt;p&gt;Water can transport approximately 4,000 times more heat per unit volume than air for a given temperature change — critical as individual AI accelerator chips increasingly dissipate 1,000 watts or more.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Custom silicon gambit challenges Nvidia&amp;#x27;s AI accelerator dominance&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Google&amp;#x27;s announcements come as the AI infrastructure market reaches an inflection point. While Nvidia maintains overwhelming dominance in AI accelerators — holding an estimated 80-95% market share — cloud providers are increasingly investing in custom silicon to differentiate their offerings and improve unit economics.&lt;/p&gt;&lt;p&gt;Amazon Web Services pioneered this approach with &lt;a href="https://aws.amazon.com/ec2/graviton/"&gt;&lt;u&gt;Graviton Arm-based CPUs&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://aws.amazon.com/ai/machine-learning/inferentia/"&gt;&lt;u&gt;Inferentia&lt;/u&gt;&lt;/a&gt; / &lt;a href="https://aws.amazon.com/ai/machine-learning/trainium/"&gt;&lt;u&gt;Trainium&lt;/u&gt;&lt;/a&gt; AI chips. Microsoft has developed &lt;a href="https://learn.microsoft.com/en-us/azure/virtual-machines/sizes/cobalt-overview"&gt;&lt;u&gt;Cobalt processors&lt;/u&gt;&lt;/a&gt; and is reportedly working on AI accelerators. Google now offers the most comprehensive custom silicon portfolio among major cloud providers.&lt;/p&gt;&lt;p&gt;The strategy faces inherent challenges. Custom chip development requires enormous upfront investment — often billions of dollars. The software ecosystem for specialized accelerators lags behind Nvidia&amp;#x27;s &lt;a href="https://developer.nvidia.com/about-cuda"&gt;&lt;u&gt;CUDA platform&lt;/u&gt;&lt;/a&gt;, which benefits from 15+ years of developer tools. And rapid AI model architecture evolution creates risk that custom silicon optimized for today&amp;#x27;s models becomes less relevant as new techniques emerge.&lt;/p&gt;&lt;p&gt;Yet Google argues its approach delivers unique advantages. &amp;quot;This is how we built the first TPU ten years ago, which in turn unlocked the invention of the Transformer eight years ago — the very architecture that powers most of modern AI,&amp;quot; the company noted, referring to the seminal &lt;a href="https://arxiv.org/abs/1706.03762"&gt;&lt;u&gt;&amp;quot;Attention Is All You Need&amp;quot; paper&lt;/u&gt;&lt;/a&gt; from Google researchers in 2017.&lt;/p&gt;&lt;p&gt;The argument is that tight integration — &amp;quot;model research, software, and hardware development under one roof&amp;quot; — enables optimizations impossible with off-the-shelf components.&lt;/p&gt;&lt;p&gt;Beyond Anthropic, several other customers provided early feedback. Lightricks, which develops creative AI tools, reported that early Ironwood testing &amp;quot;makes us highly enthusiastic&amp;quot; about creating &amp;quot;more nuanced, precise, and higher-fidelity image and video generation for our millions of global customers,&amp;quot; said Yoav HaCohen, the company&amp;#x27;s research director.&lt;/p&gt;&lt;p&gt;Google&amp;#x27;s announcements raise questions that will play out over coming quarters. Can the industry sustain current infrastructure spending, with major AI companies collectively committing hundreds of billions of dollars? Will custom silicon prove economically superior to Nvidia GPUs? How will model architectures evolve?&lt;/p&gt;&lt;p&gt;For now, Google appears committed to a strategy that has defined the company for decades: building custom infrastructure to enable applications impossible on commodity hardware, then making that infrastructure available to customers who want similar capabilities without the capital investment.&lt;/p&gt;&lt;p&gt;As the AI industry transitions from research labs to production deployments serving billions of users, that infrastructure layer — the silicon, software, networking, power, and cooling that make it all run — may prove as important as the models themselves.&lt;/p&gt;&lt;p&gt;And if Anthropic&amp;#x27;s willingness to commit to accessing up to one million chips is any indication, Google&amp;#x27;s bet on custom silicon designed specifically for the age of inference may be paying off just as demand reaches its inflection point.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://cloud.google.com/?hl=en"&gt;&lt;u&gt;Google Cloud&lt;/u&gt;&lt;/a&gt; is introducing what it calls its most powerful artificial intelligence infrastructure to date, unveiling a seventh-generation &lt;a href="https://cloud.google.com/tpu?hl=en"&gt;&lt;u&gt;Tensor Processing Unit&lt;/u&gt;&lt;/a&gt; and expanded &lt;a href="https://cloud.google.com/discover/what-are-arm-based-processors?hl=en"&gt;&lt;u&gt;Arm-based computing options&lt;/u&gt;&lt;/a&gt; designed to meet surging demand for AI model deployment — what the company characterizes as a fundamental industry shift from training models to serving them to billions of users.&lt;/p&gt;&lt;p&gt;The announcement, made Thursday, centers on &lt;a href="https://cloud.google.com/resources/ironwood-tpu-interest?utm_source=cgc-blog&amp;amp;utm_medium=blog&amp;amp;utm_campaign=FY25-Q2-global-ENT33820-website-cs-ironwood-tpu-interest&amp;amp;utm_content=ironwood_announcement_blog&amp;amp;utm_term=ironwood&amp;amp;hl=en"&gt;&lt;u&gt;Ironwood&lt;/u&gt;&lt;/a&gt;, Google&amp;#x27;s latest custom AI accelerator chip, which will become generally available in the coming weeks. In a striking validation of the technology, &lt;a href="https://www.anthropic.com/"&gt;&lt;u&gt;Anthropic&lt;/u&gt;&lt;/a&gt;, the AI safety company behind the Claude family of models, disclosed plans to access up to &lt;a href="https://www.googlecloudpresscorner.com/2025-10-23-Anthropic-to-Expand-Use-of-Google-Cloud-TPUs-and-Services"&gt;&lt;u&gt;one million of these TPU chips&lt;/u&gt;&lt;/a&gt; — a commitment worth tens of billions of dollars and among the largest known AI infrastructure deals to date.&lt;/p&gt;&lt;p&gt;The move underscores an intensifying competition among cloud providers to control the infrastructure layer powering artificial intelligence, even as questions mount about whether the industry can sustain its current pace of capital expenditure. Google&amp;#x27;s approach — building custom silicon rather than relying solely on &lt;a href="https://www.reuters.com/business/nvidia-poised-record-5-trillion-market-valuation-2025-10-29/"&gt;&lt;u&gt;Nvidia&amp;#x27;s dominant GPU chips&lt;/u&gt;&lt;/a&gt; — amounts to a long-term bet that vertical integration from chip design through software will deliver superior economics and performance.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Why companies are racing to serve AI models, not just train them&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Google executives framed the announcements around what they call &amp;quot;the age of inference&amp;quot; — a transition point where companies shift resources from training frontier AI models to deploying them in production applications serving millions or billions of requests daily.&lt;/p&gt;&lt;p&gt;&amp;quot;Today&amp;#x27;s frontier models, including Google&amp;#x27;s Gemini, Veo, and Imagen and Anthropic&amp;#x27;s Claude train and serve on Tensor Processing Units,&amp;quot; said Amin Vahdat, vice president and general manager of AI and Infrastructure at Google Cloud. &amp;quot;For many organizations, the focus is shifting from training these models to powering useful, responsive interactions with them.&amp;quot;&lt;/p&gt;&lt;p&gt;This transition has profound implications for infrastructure requirements. Where training workloads can often tolerate batch processing and longer completion times, inference — the process of actually running a trained model to generate responses — demands consistently low latency, high throughput, and unwavering reliability. A chatbot that takes 30 seconds to respond, or a coding assistant that frequently times out, becomes unusable regardless of the underlying model&amp;#x27;s capabilities.&lt;/p&gt;&lt;p&gt;Agentic workflows — where AI systems take autonomous actions rather than simply responding to prompts — create particularly complex infrastructure challenges, requiring tight coordination between specialized AI accelerators and general-purpose computing.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Inside Ironwood&amp;#x27;s architecture: 9,216 chips working as one supercomputer&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;&lt;a href="https://cloud.google.com/resources/ironwood-tpu-interest?utm_source=cgc-blog&amp;amp;utm_medium=blog&amp;amp;utm_campaign=FY25-Q2-global-ENT33820-website-cs-ironwood-tpu-interest&amp;amp;utm_content=ironwood_announcement_blog&amp;amp;utm_term=ironwood&amp;amp;hl=en"&gt;&lt;u&gt;Ironwood&lt;/u&gt;&lt;/a&gt; is more than incremental improvement over Google&amp;#x27;s sixth-generation TPUs. According to technical specifications shared by the company, it delivers more than four times better performance for both training and inference workloads compared to its predecessor — gains that Google attributes to a system-level co-design approach rather than simply increasing transistor counts.&lt;/p&gt;&lt;p&gt;The architecture&amp;#x27;s most striking feature is its scale. A single Ironwood &amp;quot;pod&amp;quot; — a tightly integrated unit of TPU chips functioning as one supercomputer — can connect up to 9,216 individual chips through Google&amp;#x27;s proprietary &lt;a href="https://blog.google/products/google-cloud/ironwood-tpu-age-of-inference/"&gt;&lt;u&gt;Inter-Chip Interconnect network&lt;/u&gt;&lt;/a&gt; operating at 9.6 terabits per second. To put that bandwidth in perspective, it&amp;#x27;s roughly equivalent to downloading the entire Library of Congress in under two seconds.&lt;/p&gt;&lt;p&gt;This massive interconnect fabric allows the 9,216 chips to share access to 1.77 petabytes of &lt;a href="https://blog.google/products/google-cloud/ironwood-tpu-age-of-inference/"&gt;&lt;u&gt;High Bandwidth Memory&lt;/u&gt;&lt;/a&gt; — memory fast enough to keep pace with the chips&amp;#x27; processing speeds. That&amp;#x27;s approximately 40,000 high-definition Blu-ray movies&amp;#x27; worth of working memory, instantly accessible by thousands of processors simultaneously. &amp;quot;For context, that means Ironwood Pods can deliver 118x more FP8 ExaFLOPS versus the next closest competitor,&amp;quot; Google stated in technical documentation.&lt;/p&gt;&lt;p&gt;The system employs &lt;a href="https://www.opencompute.org/projects/optical-circuit-switching"&gt;&lt;u&gt;Optical Circuit Switching&lt;/u&gt;&lt;/a&gt; technology that acts as a &amp;quot;dynamic, reconfigurable fabric.&amp;quot; When individual components fail or require maintenance — inevitable at this scale — the OCS technology automatically reroutes data traffic around the interruption within milliseconds, allowing workloads to continue running without user-visible disruption.&lt;/p&gt;&lt;p&gt;This reliability focus reflects lessons learned from deploying five previous TPU generations. Google reported that its fleet-wide uptime for liquid-cooled systems has maintained approximately 99.999% availability since 2020 — equivalent to less than six minutes of downtime per year.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Anthropic&amp;#x27;s billion-dollar bet validates Google&amp;#x27;s custom silicon strategy&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Perhaps the most significant external validation of Ironwood&amp;#x27;s capabilities comes from &lt;a href="https://www.googlecloudpresscorner.com/2025-10-23-Anthropic-to-Expand-Use-of-Google-Cloud-TPUs-and-Services"&gt;&lt;u&gt;Anthropic&amp;#x27;s commitment to access up to one million TPU chips&lt;/u&gt;&lt;/a&gt; — a staggering figure in an industry where even clusters of 10,000 to 50,000 accelerators are considered massive.&lt;/p&gt;&lt;p&gt;&amp;quot;Anthropic and Google have a longstanding partnership and this latest expansion will help us continue to grow the compute we need to define the frontier of AI,&amp;quot; said Krishna Rao, Anthropic&amp;#x27;s chief financial officer, in the official partnership agreement. &amp;quot;Our customers — from Fortune 500 companies to AI-native startups — depend on Claude for their most important work, and this expanded capacity ensures we can meet our exponentially growing demand.&amp;quot;&lt;/p&gt;&lt;p&gt;According to a separate statement, Anthropic will have access to &amp;quot;well over a gigawatt of capacity coming online in 2026&amp;quot; — enough electricity to power a small city. The company specifically cited TPUs&amp;#x27; &amp;quot;price-performance and efficiency&amp;quot; as key factors in the decision, along with &amp;quot;existing experience in training and serving its models with TPUs.&amp;quot;&lt;/p&gt;&lt;p&gt;Industry analysts estimate that a commitment to access one million TPU chips, with associated infrastructure, networking, power, and cooling, likely represents a &lt;a href="https://www.reuters.com/technology/anthropic-expand-use-google-clouds-tpu-chips-2025-10-23/"&gt;&lt;u&gt;multi-year contract worth tens of billions of dollars&lt;/u&gt;&lt;/a&gt; — among the largest known cloud infrastructure commitments in history.&lt;/p&gt;&lt;p&gt;James Bradbury, Anthropic&amp;#x27;s head of compute, elaborated on the inference focus: &amp;quot;Ironwood&amp;#x27;s improvements in both inference performance and training scalability will help us scale efficiently while maintaining the speed and reliability our customers expect.&amp;quot;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Google&amp;#x27;s Axion processors target the computing workloads that make AI possible&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Alongside &lt;a href="https://cloud.google.com/resources/ironwood-tpu-interest?utm_source=cgc-blog&amp;amp;utm_medium=blog&amp;amp;utm_campaign=FY25-Q2-global-ENT33820-website-cs-ironwood-tpu-interest&amp;amp;utm_content=ironwood_announcement_blog&amp;amp;utm_term=ironwood&amp;amp;hl=en"&gt;&lt;u&gt;Ironwood&lt;/u&gt;&lt;/a&gt;, Google introduced expanded options for its &lt;a href="https://cloud.google.com/products/axion?hl=en"&gt;&lt;u&gt;Axion processor family&lt;/u&gt;&lt;/a&gt; — custom Arm-based CPUs designed for general-purpose workloads that support AI applications but don&amp;#x27;t require specialized accelerators.&lt;/p&gt;&lt;p&gt;The &lt;a href="http://forms.gle/HYY5FWRKewYuDMB27"&gt;&lt;u&gt;N4A instance type&lt;/u&gt;&lt;/a&gt;, now entering preview, targets what Google describes as &amp;quot;microservices, containerized applications, open-source databases, batch, data analytics, development environments, experimentation, data preparation and web serving jobs that make AI applications possible.&amp;quot; The company claims N4A delivers up to 2X better price-performance than comparable current-generation x86-based virtual machines.&lt;/p&gt;&lt;p&gt;Google is also &lt;a href="https://docs.google.com/forms/d/e/1FAIpQLSd14sMYz79SeRI665dM7lnUbsAg7zilVPdDfK2_6u1vBmiUfg/viewform?usp=send_form"&gt;&lt;u&gt;previewing C4A metal&lt;/u&gt;&lt;/a&gt;, its first bare-metal Arm instance, which provides dedicated physical servers for specialized workloads such as Android development, automotive systems, and software with strict licensing requirements.&lt;/p&gt;&lt;p&gt;The Axion strategy reflects a growing conviction that the future of computing infrastructure requires both specialized AI accelerators and highly efficient general-purpose processors. While a TPU handles the computationally intensive task of running an AI model, Axion-class processors manage data ingestion, preprocessing, application logic, API serving, and countless other tasks in a modern AI application stack.&lt;/p&gt;&lt;p&gt;Early customer results suggest the approach delivers measurable economic benefits. Vimeo reported observing &amp;quot;a 30% improvement in performance for our core transcoding workload compared to comparable x86 VMs&amp;quot; in initial N4A tests. ZoomInfo measured &amp;quot;a 60% improvement in price-performance&amp;quot; for data processing pipelines running on Java services, according to Sergei Koren, the company&amp;#x27;s chief infrastructure architect.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Software tools turn raw silicon performance into developer productivity&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Hardware performance means little if developers cannot easily harness it. Google emphasized that &lt;a href="https://cloud.google.com/resources/ironwood-tpu-interest?utm_source=cgc-blog&amp;amp;utm_medium=blog&amp;amp;utm_campaign=FY25-Q2-global-ENT33820-website-cs-ironwood-tpu-interest&amp;amp;utm_content=ironwood_announcement_blog&amp;amp;utm_term=ironwood&amp;amp;hl=en"&gt;&lt;u&gt;Ironwood&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://cloud.google.com/products/axion?hl=en"&gt;&lt;u&gt;Axion&lt;/u&gt;&lt;/a&gt; are integrated into what it calls &lt;a href="https://cloud.google.com/solutions/ai-hypercomputer"&gt;&lt;u&gt;AI Hypercomputer&lt;/u&gt;&lt;/a&gt; — &amp;quot;an integrated supercomputing system that brings together compute, networking, storage, and software to improve system-level performance and efficiency.&amp;quot;&lt;/p&gt;&lt;p&gt;According to an October 2025 IDC Business Value Snapshot study, AI Hypercomputer customers achieved on average 353% three-year return on investment, 28% lower IT costs, and 55% more efficient IT teams.&lt;/p&gt;&lt;p&gt;Google disclosed several software enhancements designed to maximize Ironwood utilization. &lt;a href="https://cloud.google.com/kubernetes-engine?utm_source=google&amp;amp;utm_medium=cpc&amp;amp;utm_campaign=na-US-all-en-dr-bkws-all-all-trial-e-dr-1710134&amp;amp;utm_content=text-ad-none-any-DEV_c-CRE_772251321321-ADGP_Hybrid+%7C+BKWS+-+EXA+%7C+Txt-AppMod-GKE-Kubernetes+Engine-KWID_369526655975-kwd-369526655975&amp;amp;utm_term=KW_google+kubernetes+engine-ST_google+kubernetes+engine&amp;amp;gclsrc=aw.ds&amp;amp;gad_source=1&amp;amp;gad_campaignid=23052915519&amp;amp;gclid=Cj0KCQiAiKzIBhCOARIsAKpKLAMMFmNaZgmWnQ3CYrziXElfmMXmQphYqoSvICvf6jfUjLqR9XqFt3oaArkYEALw_wcB&amp;amp;hl=en"&gt;&lt;u&gt;Google Kubernetes Engine&lt;/u&gt;&lt;/a&gt; now offers advanced maintenance and topology awareness for TPU clusters, enabling intelligent scheduling and highly resilient deployments. The company&amp;#x27;s &lt;a href="https://github.com/AI-Hypercomputer/maxtext"&gt;&lt;u&gt;open-source MaxText framework&lt;/u&gt;&lt;/a&gt; now supports advanced training techniques including Supervised Fine-Tuning and Generative Reinforcement Policy Optimization.&lt;/p&gt;&lt;p&gt;Perhaps most significant for production deployments, Google&amp;#x27;s &lt;a href="https://docs.cloud.google.com/kubernetes-engine/docs/concepts/about-gke-inference-gateway"&gt;&lt;u&gt;Inference Gateway&lt;/u&gt;&lt;/a&gt; intelligently load-balances requests across model servers to optimize critical metrics. According to Google, it can reduce time-to-first-token latency by 96% and serving costs by up to 30% through techniques like prefix-cache-aware routing.&lt;/p&gt;&lt;p&gt;The &lt;a href="https://docs.cloud.google.com/kubernetes-engine/docs/concepts/about-gke-inference-gateway"&gt;&lt;u&gt;Inference Gateway&lt;/u&gt;&lt;/a&gt; monitors key metrics including KV cache hits, GPU or TPU utilization, and request queue length, then routes incoming requests to the optimal replica. For conversational AI applications where multiple requests might share context, routing requests with shared prefixes to the same server instance can dramatically reduce redundant computation.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;The hidden challenge: powering and cooling one-megawatt server racks&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Behind these announcements lies a massive physical infrastructure challenge that Google addressed at the recent &lt;a href="https://www.opencompute.org/summit/emea-summit"&gt;&lt;u&gt;Open Compute Project EMEA Summit&lt;/u&gt;&lt;/a&gt;. The company disclosed that it&amp;#x27;s implementing +/-400 volt direct current power delivery capable of supporting up to one megawatt per rack — a tenfold increase from typical deployments.&lt;/p&gt;&lt;p&gt;&amp;quot;The AI era requires even greater power delivery capabilities,&amp;quot; explained Madhusudan Iyengar and Amber Huffman, Google principal engineers, in an &lt;a href="https://cloud.google.com/blog/topics/systems/enabling-1-mw-it-racks-and-liquid-cooling-at-ocp-emea-summit"&gt;&lt;u&gt;April 2025 blog post&lt;/u&gt;&lt;/a&gt;. &amp;quot;ML will require more than 500 kW per IT rack before 2030.&amp;quot;&lt;/p&gt;&lt;p&gt;Google is collaborating with Meta and Microsoft to standardize electrical and mechanical interfaces for high-voltage DC distribution. The company selected &lt;a href="https://www.opencompute.org/files/OCP18-400VDC-Efficiency-02.pdf"&gt;&lt;u&gt;400 VDC&lt;/u&gt;&lt;/a&gt; specifically to leverage the supply chain established by electric vehicles, &amp;quot;for greater economies of scale, more efficient manufacturing, and improved quality and scale.&amp;quot;&lt;/p&gt;&lt;p&gt;On cooling, Google revealed it will contribute its fifth-generation cooling distribution unit design to the Open Compute Project. The company has deployed liquid cooling &amp;quot;at GigaWatt scale across more than 2,000 TPU Pods in the past seven years&amp;quot; with fleet-wide availability of approximately 99.999%.&lt;/p&gt;&lt;p&gt;Water can transport approximately 4,000 times more heat per unit volume than air for a given temperature change — critical as individual AI accelerator chips increasingly dissipate 1,000 watts or more.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Custom silicon gambit challenges Nvidia&amp;#x27;s AI accelerator dominance&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Google&amp;#x27;s announcements come as the AI infrastructure market reaches an inflection point. While Nvidia maintains overwhelming dominance in AI accelerators — holding an estimated 80-95% market share — cloud providers are increasingly investing in custom silicon to differentiate their offerings and improve unit economics.&lt;/p&gt;&lt;p&gt;Amazon Web Services pioneered this approach with &lt;a href="https://aws.amazon.com/ec2/graviton/"&gt;&lt;u&gt;Graviton Arm-based CPUs&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://aws.amazon.com/ai/machine-learning/inferentia/"&gt;&lt;u&gt;Inferentia&lt;/u&gt;&lt;/a&gt; / &lt;a href="https://aws.amazon.com/ai/machine-learning/trainium/"&gt;&lt;u&gt;Trainium&lt;/u&gt;&lt;/a&gt; AI chips. Microsoft has developed &lt;a href="https://learn.microsoft.com/en-us/azure/virtual-machines/sizes/cobalt-overview"&gt;&lt;u&gt;Cobalt processors&lt;/u&gt;&lt;/a&gt; and is reportedly working on AI accelerators. Google now offers the most comprehensive custom silicon portfolio among major cloud providers.&lt;/p&gt;&lt;p&gt;The strategy faces inherent challenges. Custom chip development requires enormous upfront investment — often billions of dollars. The software ecosystem for specialized accelerators lags behind Nvidia&amp;#x27;s &lt;a href="https://developer.nvidia.com/about-cuda"&gt;&lt;u&gt;CUDA platform&lt;/u&gt;&lt;/a&gt;, which benefits from 15+ years of developer tools. And rapid AI model architecture evolution creates risk that custom silicon optimized for today&amp;#x27;s models becomes less relevant as new techniques emerge.&lt;/p&gt;&lt;p&gt;Yet Google argues its approach delivers unique advantages. &amp;quot;This is how we built the first TPU ten years ago, which in turn unlocked the invention of the Transformer eight years ago — the very architecture that powers most of modern AI,&amp;quot; the company noted, referring to the seminal &lt;a href="https://arxiv.org/abs/1706.03762"&gt;&lt;u&gt;&amp;quot;Attention Is All You Need&amp;quot; paper&lt;/u&gt;&lt;/a&gt; from Google researchers in 2017.&lt;/p&gt;&lt;p&gt;The argument is that tight integration — &amp;quot;model research, software, and hardware development under one roof&amp;quot; — enables optimizations impossible with off-the-shelf components.&lt;/p&gt;&lt;p&gt;Beyond Anthropic, several other customers provided early feedback. Lightricks, which develops creative AI tools, reported that early Ironwood testing &amp;quot;makes us highly enthusiastic&amp;quot; about creating &amp;quot;more nuanced, precise, and higher-fidelity image and video generation for our millions of global customers,&amp;quot; said Yoav HaCohen, the company&amp;#x27;s research director.&lt;/p&gt;&lt;p&gt;Google&amp;#x27;s announcements raise questions that will play out over coming quarters. Can the industry sustain current infrastructure spending, with major AI companies collectively committing hundreds of billions of dollars? Will custom silicon prove economically superior to Nvidia GPUs? How will model architectures evolve?&lt;/p&gt;&lt;p&gt;For now, Google appears committed to a strategy that has defined the company for decades: building custom infrastructure to enable applications impossible on commodity hardware, then making that infrastructure available to customers who want similar capabilities without the capital investment.&lt;/p&gt;&lt;p&gt;As the AI industry transitions from research labs to production deployments serving billions of users, that infrastructure layer — the silicon, software, networking, power, and cooling that make it all run — may prove as important as the models themselves.&lt;/p&gt;&lt;p&gt;And if Anthropic&amp;#x27;s willingness to commit to accessing up to one million chips is any indication, Google&amp;#x27;s bet on custom silicon designed specifically for the age of inference may be paying off just as demand reaches its inflection point.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/google-debuts-ai-chips-with-4x-performance-boost-secures-anthropic-megadeal</guid><pubDate>Thu, 06 Nov 2025 13:00:00 +0000</pubDate></item><item><title>[NEW] Inception raises $50 million to build diffusion models for code and text (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/06/inception-raises-50-million-to-build-diffusion-models-for-code-and-text/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/teamphoto.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;With so much money flooding into AI startups, it’s a good time to be an AI researcher with an idea to test out. And if the idea is novel enough, it might be easier to get the resources you need as an independent company instead of inside one of the big labs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s the story of Inception, a startup developing diffusion-based AI models that just raised $50 million in seed funding led by Menlo Ventures, with participation from Mayfield, Innovation Endeavors, Microsoft’s M12 fund, Snowflake Ventures, Databricks Investment, and Nvidia’s venture arm NVentures. Andrew Ng and Andrej Karpathy provided additional angel funding.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The leader of the project is Stanford professor Stefano Ermon, whose research focuses on diffusion models — which generate outputs through iterative refinement rather than word-by-word. These models power image-based AI systems like Stable Diffusion, Midjourney, and Sora. Having worked on those systems since before the AI boom made them exciting, Ermon is using Inception to apply the same models to a broader range of tasks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Together with the funding, the company released a new version of its Mercury model, designed for software development. Mercury has already been integrated into a number of development tools, including ProxyAI, Buildglare, and Kilo Code. Most importantly, Ermon says the diffusion approach will help Inception’s models conserve on two of the most important metrics: latency (response time) and compute cost.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“These diffusion-based LLMs are much faster and much more efficient than what everybody else is building today,” Ermon says. “It’s just a completely different approach where there is a lot of innovation that can still be brought to the table.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Understanding the technical difference requires a bit of background. Diffusion models are structurally different from auto-regression models, which dominate text-based AI services. Auto-regression models like GPT-5 and Gemini work sequentially, predicting each next word or word fragment based on the previously processed material. Diffusion models, trained for image generation, take a more holistic approach, modifying the overall structure of a response incrementally until it matches the desired result.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The conventional wisdom is to use auto-regression models for text applications, and that approach has been hugely successful for recent generations of AI models. But a growing body of research suggests diffusion models may perform better when a model is processing large quantities of text or managing data constraints. As Ermon tells it, those qualities become a real advantage when performing operations over large codebases.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Diffusion models also have more flexibility in how they utilize hardware, a particularly important advantage as the infrastructure demands of AI become clear. Where auto-regression models have to execute operations one after another, diffusion models can process many operations simultaneously, allowing for significantly lower latency in complex tasks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’ve been benchmarked at over 1,000 tokens per second, which is way higher than anything that’s possible using the existing autoregressive technologies,” Ermon says, “because our thing is built to be parallel. It’s built to be really, really fast.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/teamphoto.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;With so much money flooding into AI startups, it’s a good time to be an AI researcher with an idea to test out. And if the idea is novel enough, it might be easier to get the resources you need as an independent company instead of inside one of the big labs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s the story of Inception, a startup developing diffusion-based AI models that just raised $50 million in seed funding led by Menlo Ventures, with participation from Mayfield, Innovation Endeavors, Microsoft’s M12 fund, Snowflake Ventures, Databricks Investment, and Nvidia’s venture arm NVentures. Andrew Ng and Andrej Karpathy provided additional angel funding.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The leader of the project is Stanford professor Stefano Ermon, whose research focuses on diffusion models — which generate outputs through iterative refinement rather than word-by-word. These models power image-based AI systems like Stable Diffusion, Midjourney, and Sora. Having worked on those systems since before the AI boom made them exciting, Ermon is using Inception to apply the same models to a broader range of tasks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Together with the funding, the company released a new version of its Mercury model, designed for software development. Mercury has already been integrated into a number of development tools, including ProxyAI, Buildglare, and Kilo Code. Most importantly, Ermon says the diffusion approach will help Inception’s models conserve on two of the most important metrics: latency (response time) and compute cost.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“These diffusion-based LLMs are much faster and much more efficient than what everybody else is building today,” Ermon says. “It’s just a completely different approach where there is a lot of innovation that can still be brought to the table.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Understanding the technical difference requires a bit of background. Diffusion models are structurally different from auto-regression models, which dominate text-based AI services. Auto-regression models like GPT-5 and Gemini work sequentially, predicting each next word or word fragment based on the previously processed material. Diffusion models, trained for image generation, take a more holistic approach, modifying the overall structure of a response incrementally until it matches the desired result.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The conventional wisdom is to use auto-regression models for text applications, and that approach has been hugely successful for recent generations of AI models. But a growing body of research suggests diffusion models may perform better when a model is processing large quantities of text or managing data constraints. As Ermon tells it, those qualities become a real advantage when performing operations over large codebases.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Diffusion models also have more flexibility in how they utilize hardware, a particularly important advantage as the infrastructure demands of AI become clear. Where auto-regression models have to execute operations one after another, diffusion models can process many operations simultaneously, allowing for significantly lower latency in complex tasks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’ve been benchmarked at over 1,000 tokens per second, which is way higher than anything that’s possible using the existing autoregressive technologies,” Ermon says, “because our thing is built to be parallel. It’s built to be really, really fast.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/06/inception-raises-50-million-to-build-diffusion-models-for-code-and-text/</guid><pubDate>Thu, 06 Nov 2025 13:00:00 +0000</pubDate></item><item><title>[NEW] The Download: how doctors fight conspiracy theories, and your AI footprint (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/11/06/1127666/the-download-how-doctors-fight-conspiracy-theories-and-your-ai-footprint/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt; &lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;How conspiracy theories infiltrated the doctor’s office&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;As anyone who has googled their symptoms and convinced themselves that they’ve got a brain tumor will attest, the internet makes it very easy to self-(mis)diagnose your health problems. And although social media and other digital forums can be a lifeline for some people looking for a diagnosis or community, when that information is wrong, it can put their well-being and even lives in danger.&lt;/p&gt;&lt;p&gt;We spoke to a number of health-care professionals who told us how this modern impulse to “do your own research” is changing their profession. Read the full story.&lt;/p&gt;&lt;p&gt;&lt;em&gt;—Rhiannon Williams&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story is part of &lt;em&gt;MIT Technology Review&lt;/em&gt;’s series “&lt;/strong&gt;&lt;strong&gt;The New Conspiracy Age&lt;/strong&gt;&lt;strong&gt;,” on how the present boom in conspiracy theories is reshaping science and technology.&lt;/strong&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Stop worrying about your AI footprint. Look at the big picture instead.&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Casey Crownhart&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;As a climate technology reporter, I’m often asked by people whether they should be using AI, given how awful it is for the environment. Generally, I tell them not to worry—let a chatbot plan your vacation, suggest recipe ideas, or write you a poem if you want.&lt;/p&gt;&lt;p&gt;That response might surprise some. I promise I’m not living under a rock, and I have seen all the concerning projections about how much electricity AI is using. But I feel strongly about not putting the onus on individuals. Here’s why.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This article is from The Spark, MIT Technology Review’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;A new ion-based quantum computer makes error correction simpler&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;A company called Quantinuum has just unveiled Helios, its third-generation quantum computer, which includes expanded computing power and error correction capability.&lt;/p&gt;&lt;p&gt;Like all other existing quantum computers, Helios is not powerful enough to execute the industry’s dream money-making algorithms, such as those that would be useful for materials discovery or financial modeling.&lt;/p&gt;&lt;p&gt;But Quantinuum’s machines, which use individual ions as qubits, could be easier to scale up than quantum computers that use superconducting circuits as qubits, such as Google’s and IBM’s.&lt;strong&gt; &lt;/strong&gt;Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Sophia Chen&lt;/em&gt;&lt;/p&gt;   

 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 A new California law could change how all Americans browse online&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;It gives web users the chance to opt out of having their personal information sold or shared. (The Markup)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 The FDA has fast-tracked a pill to treat pancreatic cancer&lt;/strong&gt;&lt;br /&gt;The experimental drug appears promising, but experts worry corners may be cut. (WP $)&lt;br /&gt;+ &lt;em&gt;Demand for AstraZeneca’s cancer and diabetes drugs is pushing profits up. &lt;/em&gt;(Bloomberg $)&lt;br /&gt;+ &lt;em&gt;A new cancer treatment kills cells using localized heat. &lt;/em&gt;(Wired $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 AI pioneers claim it is already superior to humans in many tasks&lt;/strong&gt;&lt;br /&gt;But not all tasks are created equal. (FT $)&lt;br /&gt;+ &lt;em&gt;Are we all wandering into an AGI trap? &lt;/em&gt;(Vox)&lt;br /&gt;+ &lt;em&gt;How AGI became the most consequential conspiracy theory of our time. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;4 IBM is planning on cutting thousands of jobs&lt;/strong&gt;&lt;br /&gt;It’s shifting its focus to software and AI consulting, apparently. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;It’s keen to grow the number of its customers seeking AI advice. &lt;/em&gt;(NYT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 Big Tech’s data centers aren’t the job-generators we were promised&lt;/strong&gt;&lt;br /&gt;The jobs they do create are largely in security and cleaning. (Rest of World)&lt;br /&gt;+ &lt;em&gt;We did the math on AI’s energy footprint. Here’s the story you haven’t heard. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 Microsoft let AI shopping agents loose in a fake marketplace&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;They were easily manipulated into buying goods, it found. (TechCrunch)&lt;br /&gt;+ &lt;em&gt;When AIs bargain, a less advanced agent could cost you. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Sony has compiled a dataset to test the fairness of computer vision models&lt;br /&gt;&lt;/strong&gt;And it’s confident it’s been compiled in a fair and ethical way. (The Register)&lt;br /&gt;+ &lt;em&gt;These new tools could make AI vision systems less biased. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;8 The social network is no more&lt;br /&gt;&lt;/strong&gt;We’re living in an age of anti-social media. (The Atlantic $)&lt;br /&gt;+ &lt;em&gt;Scam ads are rife across platforms, but these former Meta workers have a plan. &lt;/em&gt;(Wired $)&lt;br /&gt;+ &lt;em&gt;The ultimate online flex? Having no followers. &lt;/em&gt;(New Yorker $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 Vibe coding is Collins dictionary’s word of 2025 📖&lt;/strong&gt;&lt;br /&gt;Beating stiff competition from “clanker.” (The Guardian)&lt;br /&gt;+ &lt;em&gt;What is vibe coding, exactly? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10 These people found romance with their chatbot companions&lt;/strong&gt;&lt;br /&gt;The AI may not be real, but the humans’ feelings certainly are. (NYT $)&lt;br /&gt;+ &lt;em&gt;It’s surprisingly easy to stumble into a relationship with an AI chatbot. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p class="has-large-font-size"&gt;&lt;strong&gt;“The opportunistic side of me is realizing that your average accountant won’t be doing this.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Sal Abdulla, founder of accounting-software startup NixSheets, tells the Wall Street Journal he’s using AI tools to gain an edge on his competitors.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; 
 &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1127669" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/image_78bbca.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Ethically sourced “spare” human bodies could revolutionize medicine&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Many challenges in medicine stem, in large part, from a common root cause: a severe shortage of ethically-sourced human bodies.&lt;/p&gt;&lt;p&gt;There might be a way to get out of this moral and scientific deadlock. Recent advances in biotechnology now provide a pathway to producing living human bodies without the neural components that allow us to think, be aware, or feel pain.&lt;/p&gt;&lt;p&gt;Many will find this possibility disturbing, but if researchers and policymakers can find a way to pull these technologies together, we may one day be able to create “spare” bodies, both human and nonhuman. Read the full story.&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;—Carsten T. Charlesworth, Henry T. Greely &amp;amp; Hiromitsu Nakauchi&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ Make sure to look up so you don’t miss November’s supermoon.&lt;br /&gt;+ If you keep finding yourself mindlessly scrolling (and who doesn’t?), maybe this whopping six-pound phone case could solve your addiction.&lt;br /&gt;+ Life lessons from a 101-year old who has no plans to retire.&lt;br /&gt;+ Are you a fan of movement snacking?&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt; &lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;How conspiracy theories infiltrated the doctor’s office&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;As anyone who has googled their symptoms and convinced themselves that they’ve got a brain tumor will attest, the internet makes it very easy to self-(mis)diagnose your health problems. And although social media and other digital forums can be a lifeline for some people looking for a diagnosis or community, when that information is wrong, it can put their well-being and even lives in danger.&lt;/p&gt;&lt;p&gt;We spoke to a number of health-care professionals who told us how this modern impulse to “do your own research” is changing their profession. Read the full story.&lt;/p&gt;&lt;p&gt;&lt;em&gt;—Rhiannon Williams&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story is part of &lt;em&gt;MIT Technology Review&lt;/em&gt;’s series “&lt;/strong&gt;&lt;strong&gt;The New Conspiracy Age&lt;/strong&gt;&lt;strong&gt;,” on how the present boom in conspiracy theories is reshaping science and technology.&lt;/strong&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Stop worrying about your AI footprint. Look at the big picture instead.&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Casey Crownhart&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;As a climate technology reporter, I’m often asked by people whether they should be using AI, given how awful it is for the environment. Generally, I tell them not to worry—let a chatbot plan your vacation, suggest recipe ideas, or write you a poem if you want.&lt;/p&gt;&lt;p&gt;That response might surprise some. I promise I’m not living under a rock, and I have seen all the concerning projections about how much electricity AI is using. But I feel strongly about not putting the onus on individuals. Here’s why.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This article is from The Spark, MIT Technology Review’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;A new ion-based quantum computer makes error correction simpler&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;A company called Quantinuum has just unveiled Helios, its third-generation quantum computer, which includes expanded computing power and error correction capability.&lt;/p&gt;&lt;p&gt;Like all other existing quantum computers, Helios is not powerful enough to execute the industry’s dream money-making algorithms, such as those that would be useful for materials discovery or financial modeling.&lt;/p&gt;&lt;p&gt;But Quantinuum’s machines, which use individual ions as qubits, could be easier to scale up than quantum computers that use superconducting circuits as qubits, such as Google’s and IBM’s.&lt;strong&gt; &lt;/strong&gt;Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Sophia Chen&lt;/em&gt;&lt;/p&gt;   

 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 A new California law could change how all Americans browse online&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;It gives web users the chance to opt out of having their personal information sold or shared. (The Markup)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 The FDA has fast-tracked a pill to treat pancreatic cancer&lt;/strong&gt;&lt;br /&gt;The experimental drug appears promising, but experts worry corners may be cut. (WP $)&lt;br /&gt;+ &lt;em&gt;Demand for AstraZeneca’s cancer and diabetes drugs is pushing profits up. &lt;/em&gt;(Bloomberg $)&lt;br /&gt;+ &lt;em&gt;A new cancer treatment kills cells using localized heat. &lt;/em&gt;(Wired $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 AI pioneers claim it is already superior to humans in many tasks&lt;/strong&gt;&lt;br /&gt;But not all tasks are created equal. (FT $)&lt;br /&gt;+ &lt;em&gt;Are we all wandering into an AGI trap? &lt;/em&gt;(Vox)&lt;br /&gt;+ &lt;em&gt;How AGI became the most consequential conspiracy theory of our time. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;4 IBM is planning on cutting thousands of jobs&lt;/strong&gt;&lt;br /&gt;It’s shifting its focus to software and AI consulting, apparently. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;It’s keen to grow the number of its customers seeking AI advice. &lt;/em&gt;(NYT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 Big Tech’s data centers aren’t the job-generators we were promised&lt;/strong&gt;&lt;br /&gt;The jobs they do create are largely in security and cleaning. (Rest of World)&lt;br /&gt;+ &lt;em&gt;We did the math on AI’s energy footprint. Here’s the story you haven’t heard. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 Microsoft let AI shopping agents loose in a fake marketplace&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;They were easily manipulated into buying goods, it found. (TechCrunch)&lt;br /&gt;+ &lt;em&gt;When AIs bargain, a less advanced agent could cost you. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Sony has compiled a dataset to test the fairness of computer vision models&lt;br /&gt;&lt;/strong&gt;And it’s confident it’s been compiled in a fair and ethical way. (The Register)&lt;br /&gt;+ &lt;em&gt;These new tools could make AI vision systems less biased. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;8 The social network is no more&lt;br /&gt;&lt;/strong&gt;We’re living in an age of anti-social media. (The Atlantic $)&lt;br /&gt;+ &lt;em&gt;Scam ads are rife across platforms, but these former Meta workers have a plan. &lt;/em&gt;(Wired $)&lt;br /&gt;+ &lt;em&gt;The ultimate online flex? Having no followers. &lt;/em&gt;(New Yorker $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 Vibe coding is Collins dictionary’s word of 2025 📖&lt;/strong&gt;&lt;br /&gt;Beating stiff competition from “clanker.” (The Guardian)&lt;br /&gt;+ &lt;em&gt;What is vibe coding, exactly? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10 These people found romance with their chatbot companions&lt;/strong&gt;&lt;br /&gt;The AI may not be real, but the humans’ feelings certainly are. (NYT $)&lt;br /&gt;+ &lt;em&gt;It’s surprisingly easy to stumble into a relationship with an AI chatbot. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p class="has-large-font-size"&gt;&lt;strong&gt;“The opportunistic side of me is realizing that your average accountant won’t be doing this.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Sal Abdulla, founder of accounting-software startup NixSheets, tells the Wall Street Journal he’s using AI tools to gain an edge on his competitors.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; 
 &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1127669" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/image_78bbca.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Ethically sourced “spare” human bodies could revolutionize medicine&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Many challenges in medicine stem, in large part, from a common root cause: a severe shortage of ethically-sourced human bodies.&lt;/p&gt;&lt;p&gt;There might be a way to get out of this moral and scientific deadlock. Recent advances in biotechnology now provide a pathway to producing living human bodies without the neural components that allow us to think, be aware, or feel pain.&lt;/p&gt;&lt;p&gt;Many will find this possibility disturbing, but if researchers and policymakers can find a way to pull these technologies together, we may one day be able to create “spare” bodies, both human and nonhuman. Read the full story.&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;—Carsten T. Charlesworth, Henry T. Greely &amp;amp; Hiromitsu Nakauchi&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ Make sure to look up so you don’t miss November’s supermoon.&lt;br /&gt;+ If you keep finding yourself mindlessly scrolling (and who doesn’t?), maybe this whopping six-pound phone case could solve your addiction.&lt;br /&gt;+ Life lessons from a 101-year old who has no plans to retire.&lt;br /&gt;+ Are you a fan of movement snacking?&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/11/06/1127666/the-download-how-doctors-fight-conspiracy-theories-and-your-ai-footprint/</guid><pubDate>Thu, 06 Nov 2025 13:10:00 +0000</pubDate></item><item><title>[NEW] Fall Into Gaming With 20+ Titles Joining GeForce NOW in November (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/geforce-now-thursday-november-2025-games/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;A crisp chill’s in the air — and so is the action. GeForce NOW is packing November with 23 games hitting the cloud, including the launch of the highly anticipated &lt;i&gt;Call of Duty: Black Ops 7&lt;/i&gt; on Friday, Nov. 14.&lt;/p&gt;
&lt;p&gt;Kicking off the six games available this week, &lt;i&gt;Virtua Fighter 5 R.E.V.O. World Stage&lt;/i&gt; enters the ring, bringing Sega’s legendary 3D fighter — rebuilt for a new generation — to the GeForce RTX cloud.&lt;/p&gt;
&lt;p&gt;It’s a knockout lineup for November — and the perfect time to fall into the cloud.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87158"&gt;&lt;img alt="Amsterdam and Monreal 5080 now live on GeForce NOW" class="size-large wp-image-87158" height="945" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/kv-3840x2160-cta-1680x945.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87158"&gt;&lt;em&gt;Phoenix will be the next region to light up with GeForce RTX 5080-class power.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Amsterdam is the latest region to get GeForce RTX 5080-class power, with Montreal going live today and Phoenix coming up next. Stay tuned to GFN Thursday for updates as more regions upgrade to Blackwell RTX. Follow along with the latest progress on the server rollout page.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Step Into the Cloud&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87150"&gt;&lt;img alt="Virtua Fighter 5 REVO World Stage on GeForce NOW" class="size-large wp-image-87150" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/GFN_Thursday-Virtua_Fighter_5_REVO_World_Stage-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87150"&gt;&lt;em&gt;Fight anywhere, play everywhere.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Sega’s iconic &lt;i&gt;Virtua Fighter&lt;/i&gt; franchise returns in &lt;i&gt;Virtua Fighter 5 R.E.V.O. World Stage&lt;/i&gt;, the latest evolution of the classic 3D fighter. Backed by decades of competitive history, the new entry refines the series’ precise mechanics with modern visuals, deeper customization and online features built for the next generation of fighters.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;R.E.V.O. World Stage&lt;/i&gt; brings players back into the dojos and arenas that made &lt;i&gt;Virtua Fighter &lt;/i&gt;legendary. With skills-based combat that rewards timing, reflexes and true mastery of each character’s martial art, every match tells its own story — whether a friendly spar or a global showdown on the world stage.&lt;/p&gt;
&lt;p&gt;GeForce NOW members can take the fight anywhere. Stream &lt;i&gt;Virtua Fighter 5 R.E.V.O. World Stage&lt;/i&gt; at ultralow latency across devices — without downloads or installs. It’s time to show the world what a real champion looks like.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;New-Game November&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87153"&gt;&lt;img alt="Europa Universalis V on GeForce NOW" class="size-large wp-image-87153" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/GFN_Thursday-Europa_Universalis_V-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87153"&gt;&lt;em&gt;Write the story of civilization.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Paradox Interactive’s &lt;i&gt;Europa Universalis V &lt;/i&gt;is a grand strategy game that brings centuries of diplomacy, warfare and exploration to life. Guide empires, shape cultures, form alliances and test ambition in a living world shaped by dramatic rivalries and changing alliances. Each campaign reveals a living, unpredictable world where ambition sparks dramatic rivalries and history is rewritten with every bold move. Launched on GeForce NOW, it’s optimized for GeForce RTX 5080-power, so every intricate standoff, sweeping campaign and chaotic twist of fate is rendered at up to 5K 120 frames per second, fully capturing the chaos of history as it unfolds in real time.&lt;/p&gt;
&lt;p&gt;In addition, members can look for the following to play this week:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;Europa Universalis V &lt;/i&gt;(New release on Steam, GeForce RTX 5080-ready, Nov. 4)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;7 Days Blood Moons&lt;/i&gt; (New release on Steam, Nov 4)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Whiskerwood &lt;/i&gt;(New release on Steam and Xbox, available on PC Game Pass, Nov. 6)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;The Last Caretaker &lt;/i&gt;(New release on Steam, Nov. 6)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Voidtrain &lt;/i&gt;(New release on Xbox, available on PC Game Pass, Nov. 7)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Virtua Fighter 5 R.E.V.O. World Stage &lt;/i&gt;(Steam)&lt;i&gt;&amp;nbsp;&lt;/i&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Catch the full list of games coming to the cloud in November:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;INAZUMA ELEVEN: Victory Road &lt;/i&gt;(New release on Steam, Nov. 10)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Surviving Mars: Relaunched &lt;/i&gt;(New release on Steam, Nov. 10)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Possessor(s) &lt;/i&gt;(New release on Steam, Nov. 11)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Rue Valley &lt;/i&gt;(New release on Steam, Nov. 11)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Anno 117: Pax Romana &lt;/i&gt;(New release on Steam and Ubisoft, Nov. 13)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Assetto Corsa Rally &lt;/i&gt;(New release on Steam, Nov. 13)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Where Winds Meet &lt;/i&gt;(New release on Epic Games Store, Nov. 14)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;SpongeBob SquarePants: Titans of the Tide&lt;/i&gt; (New release on Steam, Nov. 18)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Long Drive North &lt;/i&gt;(New release on Steam, Nov. 18)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Demonschool &lt;/i&gt;(New release on Steam, Nov. 19)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Monsters Are Coming! Rock &amp;amp; Road &lt;/i&gt;(New release on Steam and Xbox, available on PC Game Pass, Nov. 20)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Project Motor Racing &lt;/i&gt;(New release on Steam, Nov. 25)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Call of Duty: Black Ops 7 &lt;/i&gt;(New release on Steam, Battle.net and Xbox, available on PC Game Pass, Nov. 25)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Brotato &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;GODBREAKERS &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Megabonk &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;R.E.P.O. &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;b&gt;Overdrive October&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;In addition to the 18 games announced in October, an extra 20 joined over the month:&lt;/p&gt;

&lt;p&gt;&lt;i&gt;Fellowship &lt;/i&gt;didn’t make it in October. Stay tuned to GFN Thursday for updates.&lt;/p&gt;
&lt;p&gt;What are you planning to play this weekend? Let us know on X or in the comments below.&lt;/p&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p dir="ltr" lang="en"&gt;"just one more match" &lt;/p&gt;
&lt;p&gt;What's the one game that's been keeping you up all night? 😴&lt;/p&gt;
&lt;p&gt;— 🌩️ NVIDIA GeForce NOW (@NVIDIAGFN) November 4, 2025&lt;/p&gt;&lt;/blockquote&gt;



		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;A crisp chill’s in the air — and so is the action. GeForce NOW is packing November with 23 games hitting the cloud, including the launch of the highly anticipated &lt;i&gt;Call of Duty: Black Ops 7&lt;/i&gt; on Friday, Nov. 14.&lt;/p&gt;
&lt;p&gt;Kicking off the six games available this week, &lt;i&gt;Virtua Fighter 5 R.E.V.O. World Stage&lt;/i&gt; enters the ring, bringing Sega’s legendary 3D fighter — rebuilt for a new generation — to the GeForce RTX cloud.&lt;/p&gt;
&lt;p&gt;It’s a knockout lineup for November — and the perfect time to fall into the cloud.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87158"&gt;&lt;img alt="Amsterdam and Monreal 5080 now live on GeForce NOW" class="size-large wp-image-87158" height="945" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/kv-3840x2160-cta-1680x945.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87158"&gt;&lt;em&gt;Phoenix will be the next region to light up with GeForce RTX 5080-class power.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Amsterdam is the latest region to get GeForce RTX 5080-class power, with Montreal going live today and Phoenix coming up next. Stay tuned to GFN Thursday for updates as more regions upgrade to Blackwell RTX. Follow along with the latest progress on the server rollout page.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Step Into the Cloud&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87150"&gt;&lt;img alt="Virtua Fighter 5 REVO World Stage on GeForce NOW" class="size-large wp-image-87150" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/GFN_Thursday-Virtua_Fighter_5_REVO_World_Stage-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87150"&gt;&lt;em&gt;Fight anywhere, play everywhere.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Sega’s iconic &lt;i&gt;Virtua Fighter&lt;/i&gt; franchise returns in &lt;i&gt;Virtua Fighter 5 R.E.V.O. World Stage&lt;/i&gt;, the latest evolution of the classic 3D fighter. Backed by decades of competitive history, the new entry refines the series’ precise mechanics with modern visuals, deeper customization and online features built for the next generation of fighters.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;R.E.V.O. World Stage&lt;/i&gt; brings players back into the dojos and arenas that made &lt;i&gt;Virtua Fighter &lt;/i&gt;legendary. With skills-based combat that rewards timing, reflexes and true mastery of each character’s martial art, every match tells its own story — whether a friendly spar or a global showdown on the world stage.&lt;/p&gt;
&lt;p&gt;GeForce NOW members can take the fight anywhere. Stream &lt;i&gt;Virtua Fighter 5 R.E.V.O. World Stage&lt;/i&gt; at ultralow latency across devices — without downloads or installs. It’s time to show the world what a real champion looks like.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;New-Game November&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_87153"&gt;&lt;img alt="Europa Universalis V on GeForce NOW" class="size-large wp-image-87153" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/GFN_Thursday-Europa_Universalis_V-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-87153"&gt;&lt;em&gt;Write the story of civilization.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Paradox Interactive’s &lt;i&gt;Europa Universalis V &lt;/i&gt;is a grand strategy game that brings centuries of diplomacy, warfare and exploration to life. Guide empires, shape cultures, form alliances and test ambition in a living world shaped by dramatic rivalries and changing alliances. Each campaign reveals a living, unpredictable world where ambition sparks dramatic rivalries and history is rewritten with every bold move. Launched on GeForce NOW, it’s optimized for GeForce RTX 5080-power, so every intricate standoff, sweeping campaign and chaotic twist of fate is rendered at up to 5K 120 frames per second, fully capturing the chaos of history as it unfolds in real time.&lt;/p&gt;
&lt;p&gt;In addition, members can look for the following to play this week:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;Europa Universalis V &lt;/i&gt;(New release on Steam, GeForce RTX 5080-ready, Nov. 4)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;7 Days Blood Moons&lt;/i&gt; (New release on Steam, Nov 4)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Whiskerwood &lt;/i&gt;(New release on Steam and Xbox, available on PC Game Pass, Nov. 6)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;The Last Caretaker &lt;/i&gt;(New release on Steam, Nov. 6)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Voidtrain &lt;/i&gt;(New release on Xbox, available on PC Game Pass, Nov. 7)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Virtua Fighter 5 R.E.V.O. World Stage &lt;/i&gt;(Steam)&lt;i&gt;&amp;nbsp;&lt;/i&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Catch the full list of games coming to the cloud in November:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;INAZUMA ELEVEN: Victory Road &lt;/i&gt;(New release on Steam, Nov. 10)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Surviving Mars: Relaunched &lt;/i&gt;(New release on Steam, Nov. 10)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Possessor(s) &lt;/i&gt;(New release on Steam, Nov. 11)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Rue Valley &lt;/i&gt;(New release on Steam, Nov. 11)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Anno 117: Pax Romana &lt;/i&gt;(New release on Steam and Ubisoft, Nov. 13)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Assetto Corsa Rally &lt;/i&gt;(New release on Steam, Nov. 13)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Where Winds Meet &lt;/i&gt;(New release on Epic Games Store, Nov. 14)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;SpongeBob SquarePants: Titans of the Tide&lt;/i&gt; (New release on Steam, Nov. 18)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Long Drive North &lt;/i&gt;(New release on Steam, Nov. 18)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Demonschool &lt;/i&gt;(New release on Steam, Nov. 19)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Monsters Are Coming! Rock &amp;amp; Road &lt;/i&gt;(New release on Steam and Xbox, available on PC Game Pass, Nov. 20)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Project Motor Racing &lt;/i&gt;(New release on Steam, Nov. 25)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Call of Duty: Black Ops 7 &lt;/i&gt;(New release on Steam, Battle.net and Xbox, available on PC Game Pass, Nov. 25)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Brotato &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;GODBREAKERS &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Megabonk &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;R.E.P.O. &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;b&gt;Overdrive October&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;In addition to the 18 games announced in October, an extra 20 joined over the month:&lt;/p&gt;

&lt;p&gt;&lt;i&gt;Fellowship &lt;/i&gt;didn’t make it in October. Stay tuned to GFN Thursday for updates.&lt;/p&gt;
&lt;p&gt;What are you planning to play this weekend? Let us know on X or in the comments below.&lt;/p&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p dir="ltr" lang="en"&gt;"just one more match" &lt;/p&gt;
&lt;p&gt;What's the one game that's been keeping you up all night? 😴&lt;/p&gt;
&lt;p&gt;— 🌩️ NVIDIA GeForce NOW (@NVIDIAGFN) November 4, 2025&lt;/p&gt;&lt;/blockquote&gt;



		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/geforce-now-thursday-november-2025-games/</guid><pubDate>Thu, 06 Nov 2025 14:00:37 +0000</pubDate></item><item><title>[NEW] Is AI in a bubble? Succeed despite a market correction (AI News)</title><link>https://www.artificialintelligence-news.com/news/is-ai-in-a-bubble-succeed-despite-market-correction/</link><description>&lt;p&gt;Amid pressure to deploy generative and agentic solutions, a familiar question is surfacing: “Is there an AI bubble, and is it about to burst?”&lt;/p&gt;&lt;p&gt;For many organisations, this new wave of generative and agentic AI is still very much in experimental stages. The primary focus, and the low-hanging fruit, has been internal. Most businesses are looking to AI to increase efficiency gains, such as automating workflows or streamlining customer support. The trouble is, those gains are proving elusive.&lt;/p&gt;&lt;p&gt;Ben Gilbert, VP of 15gifts, points out that “those benefits often take years to show real returns and are hard to measure beyond time savings.”&lt;/p&gt;&lt;p&gt;This is where the cracks begin to show. The rush to deploy feels uncomfortably familiar and, for some, may give some feelings of PTSD.&lt;/p&gt;&lt;p&gt;“The trend of companies diving headfirst into AI projects or solutions mirrors patterns we have seen time and time again in previous tech bubbles, such as the dot-com era,” explains Gilbert.&lt;/p&gt;&lt;p&gt;This gap between experimental spending and measurable profit is precisely where the bubble is weakest.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Gilbert argues that AI projects which “focus on efficiency gains and deliver unclear or delayed ROI” will be the first to fail from any bubble pop. When investments “risk becoming costly experiments rather than profitable tools,” the pullback is inevitable.&lt;/p&gt;&lt;p&gt;“We could see budgets tighten, startups close, and large enterprises re-evaluate their AI strategies,” says Gilbert.&lt;/p&gt;&lt;p&gt;It’s a warning backed by data. Gartner has already predicted “that over 40% of agentic AI projects will fail by 2027 due to rising costs, governance challenges, and lack of ROI”.&lt;/p&gt;&lt;p&gt;So, what separates a viable AI strategy that could survive a burst bubble from a costly experiment? Gilbert suggests it comes down to human nuance; something many projects overlook in the rush to automate. There’s a curious discrepancy, he notes: “Why has AI been embraced so fully in efficiency gains and customer support, but not in sales?”.&lt;/p&gt;&lt;p&gt;The answer may be that algorithms are highly valuable for sifting through data to inform decision-making, but consumers want the engagement, intuitiveness, and fluidity of human interaction as well. Success, then, isn’t about replacing people but augmenting them.&lt;/p&gt;&lt;p&gt;Gilbert advocates that “AI should be taught by real people, so it can understand the nuances of human language, needs, and emotions”. This requires a transparent process, where “human annotation of AI-driven conversations can help to set clear benchmarks and refine a platform’s performance.”&lt;/p&gt;&lt;p&gt;A total AI bubble pop isn’t likely to be imminent. Gilbert explains we’re more likely to see a “market correction rather than a complete collapse” and the underlying potential of AI remains strong. However, the hype will deflate.&lt;/p&gt;&lt;p&gt;For enterprise leaders, the path forward requires a return to first principles. “AI projects, whether built on hype or business value, need to address a real human need in order to be successful,” Gilbert says.&lt;/p&gt;&lt;p&gt;Whether a bubble or healthy market correction, this cooling-off period might even be a good thing, offering a chance for businesses to focus on AI quality over hype and smarter ethics. For the CIOs and CFOs managing the budgets, Gilbert believes the brands that thrive “will be the ones using AI to enhance human capability; not automate it away.”&lt;/p&gt;&lt;p&gt;“Without empathy, transparency, and human insight, even the smartest AI is destined to fail.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Keep CALM: New model design could fix high enterprise AI costs&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-110077" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-10.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Amid pressure to deploy generative and agentic solutions, a familiar question is surfacing: “Is there an AI bubble, and is it about to burst?”&lt;/p&gt;&lt;p&gt;For many organisations, this new wave of generative and agentic AI is still very much in experimental stages. The primary focus, and the low-hanging fruit, has been internal. Most businesses are looking to AI to increase efficiency gains, such as automating workflows or streamlining customer support. The trouble is, those gains are proving elusive.&lt;/p&gt;&lt;p&gt;Ben Gilbert, VP of 15gifts, points out that “those benefits often take years to show real returns and are hard to measure beyond time savings.”&lt;/p&gt;&lt;p&gt;This is where the cracks begin to show. The rush to deploy feels uncomfortably familiar and, for some, may give some feelings of PTSD.&lt;/p&gt;&lt;p&gt;“The trend of companies diving headfirst into AI projects or solutions mirrors patterns we have seen time and time again in previous tech bubbles, such as the dot-com era,” explains Gilbert.&lt;/p&gt;&lt;p&gt;This gap between experimental spending and measurable profit is precisely where the bubble is weakest.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Gilbert argues that AI projects which “focus on efficiency gains and deliver unclear or delayed ROI” will be the first to fail from any bubble pop. When investments “risk becoming costly experiments rather than profitable tools,” the pullback is inevitable.&lt;/p&gt;&lt;p&gt;“We could see budgets tighten, startups close, and large enterprises re-evaluate their AI strategies,” says Gilbert.&lt;/p&gt;&lt;p&gt;It’s a warning backed by data. Gartner has already predicted “that over 40% of agentic AI projects will fail by 2027 due to rising costs, governance challenges, and lack of ROI”.&lt;/p&gt;&lt;p&gt;So, what separates a viable AI strategy that could survive a burst bubble from a costly experiment? Gilbert suggests it comes down to human nuance; something many projects overlook in the rush to automate. There’s a curious discrepancy, he notes: “Why has AI been embraced so fully in efficiency gains and customer support, but not in sales?”.&lt;/p&gt;&lt;p&gt;The answer may be that algorithms are highly valuable for sifting through data to inform decision-making, but consumers want the engagement, intuitiveness, and fluidity of human interaction as well. Success, then, isn’t about replacing people but augmenting them.&lt;/p&gt;&lt;p&gt;Gilbert advocates that “AI should be taught by real people, so it can understand the nuances of human language, needs, and emotions”. This requires a transparent process, where “human annotation of AI-driven conversations can help to set clear benchmarks and refine a platform’s performance.”&lt;/p&gt;&lt;p&gt;A total AI bubble pop isn’t likely to be imminent. Gilbert explains we’re more likely to see a “market correction rather than a complete collapse” and the underlying potential of AI remains strong. However, the hype will deflate.&lt;/p&gt;&lt;p&gt;For enterprise leaders, the path forward requires a return to first principles. “AI projects, whether built on hype or business value, need to address a real human need in order to be successful,” Gilbert says.&lt;/p&gt;&lt;p&gt;Whether a bubble or healthy market correction, this cooling-off period might even be a good thing, offering a chance for businesses to focus on AI quality over hype and smarter ethics. For the CIOs and CFOs managing the budgets, Gilbert believes the brands that thrive “will be the ones using AI to enhance human capability; not automate it away.”&lt;/p&gt;&lt;p&gt;“Without empathy, transparency, and human insight, even the smartest AI is destined to fail.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Keep CALM: New model design could fix high enterprise AI costs&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-110077" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-10.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/is-ai-in-a-bubble-succeed-despite-market-correction/</guid><pubDate>Thu, 06 Nov 2025 14:30:27 +0000</pubDate></item><item><title>[NEW] Exclusive: Dubai’s Digital Government chief says speed trumps spending in AI efficiency race (AI News)</title><link>https://www.artificialintelligence-news.com/news/dubai-ai-government-efficiency-speed-exclusive/</link><description>&lt;p&gt;When Dubai launched its&amp;nbsp;State of AI Report&amp;nbsp;in April 2025, revealing over 100 high-impact AI use cases, the emirate wasn’t just showcasing technological prowess—it was making a calculated bet that speed, not spending, would determine which cities win the global race for AI-powered governance.&lt;/p&gt;&lt;p&gt;In an exclusive interview, Matar Al Hemeiri, Chief Executive of Digital Dubai Government Establishment, revealed how Dubai’s approach to AI government efficiency differs fundamentally from both its regional competitors and established Asian tech hubs—and why the emirate believes its model of rapid deployment paired with binding ethical frameworks offers a blueprint other governments will eventually follow.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-dubaiai-advantage-180-services-one-virtual-assistant"&gt;The DubaiAI advantage: 180 services, one virtual assistant&lt;/h3&gt;&lt;p&gt;While neighbouring Abu Dhabi announced a $4.8 billion investment to become the world’s first fully AI-powered government by 2027, Dubai has taken a different path. “Abu Dhabi’s investment is focused on building an end-to-end AI-powered government infrastructure,” Al Hemeiri explained. “Dubai’s model is to embed AI ethics, interoperability, and explainability into a scalable governance framework.”&lt;/p&gt;&lt;p&gt;The results are already visible. DubaiAI, the citywide AI-powered virtual assistant, now provides information on more than 180 public services—a figure that represents one of the most comprehensive government AI chatbot deployments globally. The system handles 60% of routine government inquiries while cutting operational costs by 35%.&lt;/p&gt;&lt;p&gt;But Al Hemeiri pushed back against the narrative that AI automation inevitably means job losses. “Automation frees our workforce from repetitive, informational tasks,” he said. “Employees are being reskilled and redeployed into higher-value roles such as AI oversight, service design, and strategic policy work.”&lt;/p&gt;&lt;p&gt;The timing couldn’t be more critical. Dubai’s population growth has created an “immense spike in demand for government services,” according to Al Hemeiri, making AI-driven efficiency not just a competitive advantage but an operational necessity.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-speed-as-strategy-from-pilot-to-deployment-in-months"&gt;Speed as strategy: From pilot to deployment in months&lt;/h3&gt;&lt;p&gt;What sets Dubai apart in AI government efficiency isn’t just what it builds—it’s how quickly it deploys. “In Dubai, once an AI initiative is announced, it is swiftly activated, moving from pilot to deployment within months, far faster than the global norm,” Al Hemeiri emphasised.&lt;/p&gt;&lt;p&gt;The numbers back this claim. In 2025, over 96% of government entities had adopted at least one AI solution, and 60% of surveyed users preferred AI-supported services.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Dubai benchmarks itself against leading smart cities like Singapore, Berlin, Helsinki, and Tallinn, but argues its integration of AI ethics directly into procurement and deployment provides a decisive edge.&lt;/p&gt;&lt;p&gt;“Our competitive edge lies in the speed with which Dubai operationalises its ethics,” Al Hemeiri said, addressing a common criticism that AI governance frameworks are purely theoretical. “The AI Policy is not a theoretical framework; it is a binding set of principles and technical requirements applied to every AI deployment across government.”&lt;/p&gt;&lt;p&gt;This approach builds on the&amp;nbsp;Ethical AI Toolkit&amp;nbsp;launched in 2019, making Dubai one of the few cities globally where ethical compliance is embedded from procurement to performance evaluation.&lt;/p&gt;&lt;figure class="wp-block-image alignleft size-large"&gt;&lt;img alt="alt" class="wp-image-110387" height="753" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/PICTURE_H.E.-Matar-Al-Hemeiri-1024x753.jpg" width="1024" /&gt;&lt;/figure&gt;&lt;h3 class="wp-block-heading" id="h-beyond-chatbots-healthcare-energy-and-predictive-services"&gt;Beyond chatbots: Healthcare, energy, and predictive services&lt;/h3&gt;&lt;p&gt;While DubaiAI captures headlines, Al Hemeiri pointed to less-publicised implementations delivering measurable impact. AI models are now detecting chronic conditions such as diabetes at earlier stages, while predictive algorithms improve auditing systems within the Dubai Health Authority.&amp;nbsp;&lt;/p&gt;&lt;p&gt;In energy infrastructure, smart grids powered by real-time AI forecasting tools are optimising consumption and reducing environmental impact. The most ambitious project currently in development is Dubai’s predictive public services platform, which will use integrated data and AI to anticipate citizen needs—from automated license renewals to preventive healthcare notifications.&amp;nbsp;&lt;/p&gt;&lt;p&gt;“We have begun efforts on building this project, with full rollout targeted for the early 2030s,” Al Hemeiri revealed. Elements of this vision are already being tested through AI-enabled urban planning tools and citywide digital twins that simulate policy outcomes before implementation.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-data-sovereignty-a-hybrid-model-between-china-and-gdpr"&gt;Data sovereignty: A hybrid model between China and GDPR&lt;/h3&gt;&lt;p&gt;Dubai’s approach to data governance offers a middle path between China’s strict localisation requirements and the EU’s GDPR framework. “Dubai’s model offers a hybrid—anonymised citizen data remains within Dubai’s jurisdiction under robust sovereignty laws, but can be securely shared across entities with the user’s consent for government services, through the nation’s official digital identity platform: UAE PASS,” Al Hemeiri explained.&lt;/p&gt;&lt;p&gt;A key differentiator is Dubai’s embrace of synthetic data frameworks. “They allow us to develop and test AI systems at scale while preserving privacy and maintaining compliance with Dubai’s data sovereignty requirements,” he said. This approach enables faster innovation cycles while addressing privacy concerns that have hampered AI development in other jurisdictions.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-startup-sandbox-real-integration-not-just-regulatory-relief"&gt;The startup sandbox: Real integration, not just regulatory relief&lt;/h3&gt;&lt;p&gt;Dubai positions itself as a testing ground for AI startups, but Al Hemeiri argued the emirate offers more than regulatory flexibility. “Dubai’s AI sandboxes combine regulatory flexibility with direct access to government datasets and real-world testing environments,” he said.&lt;/p&gt;&lt;p&gt;One healthcare diagnostics startup piloted within Dubai’s sandbox has already integrated its AI triage tool into Dubai Health Authority services.&amp;nbsp;&lt;/p&gt;&lt;p&gt;“Because our ecosystem operates as an interconnected digital operating system, startups in our sandboxes can test solutions that seamlessly integrate with other city services, from mobility innovations like the Dubai Loop and eVTOL air taxis to healthcare AI diagnostics,” Al Hemeiri explained.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-converting-global-attention-into-economic-returns"&gt;Converting global attention into economic returns&lt;/h3&gt;&lt;p&gt;Dubai AI Week 2025 attracted participants from 100 countries and partnerships with Meta, Google, Microsoft, and OpenAI. But Al Hemeiri insisted the emirate is focused on converting attention into tangible outcomes.&amp;nbsp;&lt;/p&gt;&lt;p&gt;“We have established post-event working groups with each of these partners to identify and accelerate joint projects,” he said, citing AI upskilling programs, R&amp;amp;D collaborations, and pilot deployments in healthcare, mobility, and urban planning.&lt;/p&gt;&lt;p&gt;These partnerships feed directly into Dubai’s D33 Economic Agenda, which aims to generate AED 100 billion annually from digital innovation. The State of AI Report projects AI could contribute over AED 235 billion to Dubai’s economy by 2030—a figure that represents nearly 20% of the emirate’s targeted economic expansion.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-quiet-wins-and-future-risks"&gt;Quiet wins and future risks&lt;/h3&gt;&lt;p&gt;When pressed about initiatives that deliver value without media fanfare, Al Hemeiri highlighted the UN Citiverse Challenge, co-led by Digital Dubai and global partners, which brings together innovators to design AI-powered solutions for inclusive public services and sustainability.&amp;nbsp;&lt;/p&gt;&lt;p&gt;He also pointed to Dubai Future Foundation’s autonomous delivery robot, already being piloted on Dubai streets to improve last-mile delivery efficiency while reducing congestion and emissions.&lt;/p&gt;&lt;p&gt;On risks, Al Hemeiri was direct: “The greatest risk is scaling without sufficient oversight.” Dubai mitigates this through continuous system audits and a requirement for explainability in all public sector AI.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Al Hemeiri added that ensuring ROI “is crucial for us when deciding to build an AI use case. We calculate this when planning a project, and only move ahead once we are convinced we will be able to attain the expected ROI for the city.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-five-year-test"&gt;The five-year test&lt;/h3&gt;&lt;p&gt;Asked what would constitute failure five years from now, Al Hemeiri said that it “would mean fragmented AI adoption without improving citizen trust, efficiency, or quality of life.”&lt;/p&gt;&lt;p&gt;Success, conversely, would be “when AI-powered public services are seamless, anticipatory, and inclusive, easing the lives of citizens and residents, and naturally becoming a blueprint replicated by other governments globally.”&lt;/p&gt;&lt;p&gt;It’s an ambitious vision—one that positions Dubai not just as a fast follower in AI government efficiency, but as a potential model for how cities can deploy transformative technology at speed without sacrificing ethical oversight or public trust.&lt;/p&gt;&lt;p&gt;Whether that model proves replicable beyond Dubai’s unique governance structure and resources remains the central question. But with 96% of government entities already adopting AI solutions and deployment timelines measured in months rather than years, Dubai is testing that hypothesis in real-time—and betting that in the race to build AI-powered governments, velocity matters as much as vision.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by David Rodrigo)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: UAE to teach its children AI&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-110383" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/image-1.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;When Dubai launched its&amp;nbsp;State of AI Report&amp;nbsp;in April 2025, revealing over 100 high-impact AI use cases, the emirate wasn’t just showcasing technological prowess—it was making a calculated bet that speed, not spending, would determine which cities win the global race for AI-powered governance.&lt;/p&gt;&lt;p&gt;In an exclusive interview, Matar Al Hemeiri, Chief Executive of Digital Dubai Government Establishment, revealed how Dubai’s approach to AI government efficiency differs fundamentally from both its regional competitors and established Asian tech hubs—and why the emirate believes its model of rapid deployment paired with binding ethical frameworks offers a blueprint other governments will eventually follow.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-dubaiai-advantage-180-services-one-virtual-assistant"&gt;The DubaiAI advantage: 180 services, one virtual assistant&lt;/h3&gt;&lt;p&gt;While neighbouring Abu Dhabi announced a $4.8 billion investment to become the world’s first fully AI-powered government by 2027, Dubai has taken a different path. “Abu Dhabi’s investment is focused on building an end-to-end AI-powered government infrastructure,” Al Hemeiri explained. “Dubai’s model is to embed AI ethics, interoperability, and explainability into a scalable governance framework.”&lt;/p&gt;&lt;p&gt;The results are already visible. DubaiAI, the citywide AI-powered virtual assistant, now provides information on more than 180 public services—a figure that represents one of the most comprehensive government AI chatbot deployments globally. The system handles 60% of routine government inquiries while cutting operational costs by 35%.&lt;/p&gt;&lt;p&gt;But Al Hemeiri pushed back against the narrative that AI automation inevitably means job losses. “Automation frees our workforce from repetitive, informational tasks,” he said. “Employees are being reskilled and redeployed into higher-value roles such as AI oversight, service design, and strategic policy work.”&lt;/p&gt;&lt;p&gt;The timing couldn’t be more critical. Dubai’s population growth has created an “immense spike in demand for government services,” according to Al Hemeiri, making AI-driven efficiency not just a competitive advantage but an operational necessity.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-speed-as-strategy-from-pilot-to-deployment-in-months"&gt;Speed as strategy: From pilot to deployment in months&lt;/h3&gt;&lt;p&gt;What sets Dubai apart in AI government efficiency isn’t just what it builds—it’s how quickly it deploys. “In Dubai, once an AI initiative is announced, it is swiftly activated, moving from pilot to deployment within months, far faster than the global norm,” Al Hemeiri emphasised.&lt;/p&gt;&lt;p&gt;The numbers back this claim. In 2025, over 96% of government entities had adopted at least one AI solution, and 60% of surveyed users preferred AI-supported services.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Dubai benchmarks itself against leading smart cities like Singapore, Berlin, Helsinki, and Tallinn, but argues its integration of AI ethics directly into procurement and deployment provides a decisive edge.&lt;/p&gt;&lt;p&gt;“Our competitive edge lies in the speed with which Dubai operationalises its ethics,” Al Hemeiri said, addressing a common criticism that AI governance frameworks are purely theoretical. “The AI Policy is not a theoretical framework; it is a binding set of principles and technical requirements applied to every AI deployment across government.”&lt;/p&gt;&lt;p&gt;This approach builds on the&amp;nbsp;Ethical AI Toolkit&amp;nbsp;launched in 2019, making Dubai one of the few cities globally where ethical compliance is embedded from procurement to performance evaluation.&lt;/p&gt;&lt;figure class="wp-block-image alignleft size-large"&gt;&lt;img alt="alt" class="wp-image-110387" height="753" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/PICTURE_H.E.-Matar-Al-Hemeiri-1024x753.jpg" width="1024" /&gt;&lt;/figure&gt;&lt;h3 class="wp-block-heading" id="h-beyond-chatbots-healthcare-energy-and-predictive-services"&gt;Beyond chatbots: Healthcare, energy, and predictive services&lt;/h3&gt;&lt;p&gt;While DubaiAI captures headlines, Al Hemeiri pointed to less-publicised implementations delivering measurable impact. AI models are now detecting chronic conditions such as diabetes at earlier stages, while predictive algorithms improve auditing systems within the Dubai Health Authority.&amp;nbsp;&lt;/p&gt;&lt;p&gt;In energy infrastructure, smart grids powered by real-time AI forecasting tools are optimising consumption and reducing environmental impact. The most ambitious project currently in development is Dubai’s predictive public services platform, which will use integrated data and AI to anticipate citizen needs—from automated license renewals to preventive healthcare notifications.&amp;nbsp;&lt;/p&gt;&lt;p&gt;“We have begun efforts on building this project, with full rollout targeted for the early 2030s,” Al Hemeiri revealed. Elements of this vision are already being tested through AI-enabled urban planning tools and citywide digital twins that simulate policy outcomes before implementation.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-data-sovereignty-a-hybrid-model-between-china-and-gdpr"&gt;Data sovereignty: A hybrid model between China and GDPR&lt;/h3&gt;&lt;p&gt;Dubai’s approach to data governance offers a middle path between China’s strict localisation requirements and the EU’s GDPR framework. “Dubai’s model offers a hybrid—anonymised citizen data remains within Dubai’s jurisdiction under robust sovereignty laws, but can be securely shared across entities with the user’s consent for government services, through the nation’s official digital identity platform: UAE PASS,” Al Hemeiri explained.&lt;/p&gt;&lt;p&gt;A key differentiator is Dubai’s embrace of synthetic data frameworks. “They allow us to develop and test AI systems at scale while preserving privacy and maintaining compliance with Dubai’s data sovereignty requirements,” he said. This approach enables faster innovation cycles while addressing privacy concerns that have hampered AI development in other jurisdictions.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-startup-sandbox-real-integration-not-just-regulatory-relief"&gt;The startup sandbox: Real integration, not just regulatory relief&lt;/h3&gt;&lt;p&gt;Dubai positions itself as a testing ground for AI startups, but Al Hemeiri argued the emirate offers more than regulatory flexibility. “Dubai’s AI sandboxes combine regulatory flexibility with direct access to government datasets and real-world testing environments,” he said.&lt;/p&gt;&lt;p&gt;One healthcare diagnostics startup piloted within Dubai’s sandbox has already integrated its AI triage tool into Dubai Health Authority services.&amp;nbsp;&lt;/p&gt;&lt;p&gt;“Because our ecosystem operates as an interconnected digital operating system, startups in our sandboxes can test solutions that seamlessly integrate with other city services, from mobility innovations like the Dubai Loop and eVTOL air taxis to healthcare AI diagnostics,” Al Hemeiri explained.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-converting-global-attention-into-economic-returns"&gt;Converting global attention into economic returns&lt;/h3&gt;&lt;p&gt;Dubai AI Week 2025 attracted participants from 100 countries and partnerships with Meta, Google, Microsoft, and OpenAI. But Al Hemeiri insisted the emirate is focused on converting attention into tangible outcomes.&amp;nbsp;&lt;/p&gt;&lt;p&gt;“We have established post-event working groups with each of these partners to identify and accelerate joint projects,” he said, citing AI upskilling programs, R&amp;amp;D collaborations, and pilot deployments in healthcare, mobility, and urban planning.&lt;/p&gt;&lt;p&gt;These partnerships feed directly into Dubai’s D33 Economic Agenda, which aims to generate AED 100 billion annually from digital innovation. The State of AI Report projects AI could contribute over AED 235 billion to Dubai’s economy by 2030—a figure that represents nearly 20% of the emirate’s targeted economic expansion.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-quiet-wins-and-future-risks"&gt;Quiet wins and future risks&lt;/h3&gt;&lt;p&gt;When pressed about initiatives that deliver value without media fanfare, Al Hemeiri highlighted the UN Citiverse Challenge, co-led by Digital Dubai and global partners, which brings together innovators to design AI-powered solutions for inclusive public services and sustainability.&amp;nbsp;&lt;/p&gt;&lt;p&gt;He also pointed to Dubai Future Foundation’s autonomous delivery robot, already being piloted on Dubai streets to improve last-mile delivery efficiency while reducing congestion and emissions.&lt;/p&gt;&lt;p&gt;On risks, Al Hemeiri was direct: “The greatest risk is scaling without sufficient oversight.” Dubai mitigates this through continuous system audits and a requirement for explainability in all public sector AI.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Al Hemeiri added that ensuring ROI “is crucial for us when deciding to build an AI use case. We calculate this when planning a project, and only move ahead once we are convinced we will be able to attain the expected ROI for the city.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-five-year-test"&gt;The five-year test&lt;/h3&gt;&lt;p&gt;Asked what would constitute failure five years from now, Al Hemeiri said that it “would mean fragmented AI adoption without improving citizen trust, efficiency, or quality of life.”&lt;/p&gt;&lt;p&gt;Success, conversely, would be “when AI-powered public services are seamless, anticipatory, and inclusive, easing the lives of citizens and residents, and naturally becoming a blueprint replicated by other governments globally.”&lt;/p&gt;&lt;p&gt;It’s an ambitious vision—one that positions Dubai not just as a fast follower in AI government efficiency, but as a potential model for how cities can deploy transformative technology at speed without sacrificing ethical oversight or public trust.&lt;/p&gt;&lt;p&gt;Whether that model proves replicable beyond Dubai’s unique governance structure and resources remains the central question. But with 96% of government entities already adopting AI solutions and deployment timelines measured in months rather than years, Dubai is testing that hypothesis in real-time—and betting that in the race to build AI-powered governments, velocity matters as much as vision.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by David Rodrigo)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: UAE to teach its children AI&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-110383" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/image-1.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/dubai-ai-government-efficiency-speed-exclusive/</guid><pubDate>Thu, 06 Nov 2025 17:00:00 +0000</pubDate></item><item><title>[NEW] Google plans secret AI military outpost on tiny island overrun by crabs (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/11/google-plans-secret-ai-military-outpost-on-tiny-island-overrun-by-crabs/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Christmas Island facility would support naval surveillance in strategic Indo-Pacific waters.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="In this handout image provided by Parks Australia, thousands of red crabs are seen walking in a drain on November 23, 2021 in Christmas Island." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/crabs_hero-640x360.jpg" width="640" /&gt;
                  &lt;img alt="In this handout image provided by Parks Australia, thousands of red crabs are seen walking in a drain on November 23, 2021 in Christmas Island." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/crabs_hero-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      In this handout image provided by Parks Australia, thousands of red crabs are seen walking in a drain on November 23, 2021 in Christmas Island.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Parks Australia via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Wednesday, Reuters reported that Google is planning to build a large AI data center on Christmas Island, a 52-square-mile Australian territory in the Indian Ocean, following a cloud computing deal with Australia’s military. The previously undisclosed project will reportedly position advanced AI infrastructure a mere 220 miles south of Indonesia at a location military strategists consider critical for monitoring Chinese naval activity.&lt;/p&gt;
&lt;p&gt;Aside from its strategic military position, the island is famous for its massive annual crab migration, where over 100 million of red crabs make their way across the island to spawn in the ocean. That’s notable because the tech giant has applied for environmental approvals to build a subsea cable connecting the 135-square-kilometer island to Darwin, where US Marines are stationed for six months each year.&lt;/p&gt;
&lt;p&gt;The project follows a three-year cloud agreement Google signed with Australia’s military in July 2025, but many details about the new facility’s size, cost, and specific capabilities remain “secret,” according to Reuters. Both Google and Australia’s Department of Defense declined to comment when contacted by the news agency.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Sir David Attenborough examines the great Christmas Island red crab migration.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;Bryan Clark, a former US Navy strategist who ran recent war games featuring Christmas Island, told Reuters that the planned facility would enable AI-powered military command and control. Recent military exercises involving Australian, US, and Japanese forces show Christmas Island’s value as a forward defense position for launching uncrewed weapons systems. The island’s location allows the monitoring of traffic through the Sunda, Lombok, and Malacca straits, which are key waterways for global shipping and submarine movements.&lt;/p&gt;
&lt;p&gt;Christmas Island has reportedly struggled with poor telecommunications and limited economic opportunities in the past, but some of the island’s 1,600 human residents are cautiously optimistic about the project.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Christmas Island Shire President Steve Pereira told Reuters that the council is examining community impacts before approving construction. “There is support for it, providing this data center actually does put back into the community with infrastructure, employment, and adding economic value to the island,” Pereira said.&lt;/p&gt;
&lt;h2&gt;That’s great, but what about the crabs?&lt;/h2&gt;
&lt;p&gt;Christmas Island’s annual crab migration is a natural phenomenon that Sir David Attenborough reportedly once described as one of his greatest TV moments when he visited the site in 1990.&lt;/p&gt;
&lt;p&gt;Every year, millions of crabs emerge from the forest and swarm across roads, streams, rocks, and beaches to reach the ocean, where each female can produce up to 100,000 eggs. The tiny baby crabs that survive take about nine days to march back inland to the safety of the plateau.&lt;/p&gt;
&lt;p&gt;While Google is seeking environmental approvals for its subsea cables, the timing could prove delicate for Christmas Island’s most famous residents. According to Parks Australia, the island’s annual red crab migration has already begun for 2025, with a major spawning event expected in just a few weeks, around November 15–16.&lt;/p&gt;
&lt;p&gt;During peak migration times, sections of roads close at short notice as crabs move between forest and sea, and the island has built special crab bridges over roads to protect the migrating masses.&lt;/p&gt;
&lt;p&gt;Parks Australia notes that while the migration happens annually, few baby crabs survive the journey from sea to forest most years, as they’re often eaten by fish, manta rays, and whale sharks. The successful migrations that occur only once or twice per decade (when large numbers of babies actually survive) are critical for maintaining the island’s red crab population.&lt;/p&gt;
&lt;p&gt;How Google’s facility might coexist with 100 million marching crustaceans remains to be seen. But judging by the size of the event, it seems clear that it’s the crab’s world, and we’re just living in it.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Christmas Island facility would support naval surveillance in strategic Indo-Pacific waters.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="In this handout image provided by Parks Australia, thousands of red crabs are seen walking in a drain on November 23, 2021 in Christmas Island." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/crabs_hero-640x360.jpg" width="640" /&gt;
                  &lt;img alt="In this handout image provided by Parks Australia, thousands of red crabs are seen walking in a drain on November 23, 2021 in Christmas Island." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/crabs_hero-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      In this handout image provided by Parks Australia, thousands of red crabs are seen walking in a drain on November 23, 2021 in Christmas Island.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Parks Australia via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Wednesday, Reuters reported that Google is planning to build a large AI data center on Christmas Island, a 52-square-mile Australian territory in the Indian Ocean, following a cloud computing deal with Australia’s military. The previously undisclosed project will reportedly position advanced AI infrastructure a mere 220 miles south of Indonesia at a location military strategists consider critical for monitoring Chinese naval activity.&lt;/p&gt;
&lt;p&gt;Aside from its strategic military position, the island is famous for its massive annual crab migration, where over 100 million of red crabs make their way across the island to spawn in the ocean. That’s notable because the tech giant has applied for environmental approvals to build a subsea cable connecting the 135-square-kilometer island to Darwin, where US Marines are stationed for six months each year.&lt;/p&gt;
&lt;p&gt;The project follows a three-year cloud agreement Google signed with Australia’s military in July 2025, but many details about the new facility’s size, cost, and specific capabilities remain “secret,” according to Reuters. Both Google and Australia’s Department of Defense declined to comment when contacted by the news agency.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Sir David Attenborough examines the great Christmas Island red crab migration.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;Bryan Clark, a former US Navy strategist who ran recent war games featuring Christmas Island, told Reuters that the planned facility would enable AI-powered military command and control. Recent military exercises involving Australian, US, and Japanese forces show Christmas Island’s value as a forward defense position for launching uncrewed weapons systems. The island’s location allows the monitoring of traffic through the Sunda, Lombok, and Malacca straits, which are key waterways for global shipping and submarine movements.&lt;/p&gt;
&lt;p&gt;Christmas Island has reportedly struggled with poor telecommunications and limited economic opportunities in the past, but some of the island’s 1,600 human residents are cautiously optimistic about the project.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Christmas Island Shire President Steve Pereira told Reuters that the council is examining community impacts before approving construction. “There is support for it, providing this data center actually does put back into the community with infrastructure, employment, and adding economic value to the island,” Pereira said.&lt;/p&gt;
&lt;h2&gt;That’s great, but what about the crabs?&lt;/h2&gt;
&lt;p&gt;Christmas Island’s annual crab migration is a natural phenomenon that Sir David Attenborough reportedly once described as one of his greatest TV moments when he visited the site in 1990.&lt;/p&gt;
&lt;p&gt;Every year, millions of crabs emerge from the forest and swarm across roads, streams, rocks, and beaches to reach the ocean, where each female can produce up to 100,000 eggs. The tiny baby crabs that survive take about nine days to march back inland to the safety of the plateau.&lt;/p&gt;
&lt;p&gt;While Google is seeking environmental approvals for its subsea cables, the timing could prove delicate for Christmas Island’s most famous residents. According to Parks Australia, the island’s annual red crab migration has already begun for 2025, with a major spawning event expected in just a few weeks, around November 15–16.&lt;/p&gt;
&lt;p&gt;During peak migration times, sections of roads close at short notice as crabs move between forest and sea, and the island has built special crab bridges over roads to protect the migrating masses.&lt;/p&gt;
&lt;p&gt;Parks Australia notes that while the migration happens annually, few baby crabs survive the journey from sea to forest most years, as they’re often eaten by fish, manta rays, and whale sharks. The successful migrations that occur only once or twice per decade (when large numbers of babies actually survive) are critical for maintaining the island’s red crab population.&lt;/p&gt;
&lt;p&gt;How Google’s facility might coexist with 100 million marching crustaceans remains to be seen. But judging by the size of the event, it seems clear that it’s the crab’s world, and we’re just living in it.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/11/google-plans-secret-ai-military-outpost-on-tiny-island-overrun-by-crabs/</guid><pubDate>Thu, 06 Nov 2025 17:24:51 +0000</pubDate></item><item><title>[NEW] DS-STAR: A state-of-the-art versatile data science agent (The latest research from Google)</title><link>https://research.google/blog/ds-star-a-state-of-the-art-versatile-data-science-agent/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;In-depth analysis of DS-STAR&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;Next, we conducted ablation studies to verify the effectiveness of DS-STAR’s individual components and analyze the impact of the number of refinement rounds, specifically by measuring the iterations required to generate a sufficient plan.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Data File Analyzer&lt;/b&gt;: This agent is essential for high performance. Without the descriptions it generates (Variant 1), DS-STAR's accuracy on difficult tasks within the DABStep benchmark sharply dropped to 26.98%, underscoring the importance of rich data context for effective planning and implementation.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Router&lt;/b&gt;: The Router agent’s ability to determine if a new step is needed or to fix an incorrect step is vital. When we removed it (Variant 2), DS-STAR only added new steps sequentially, leading to worse performance on both easy and hard tasks. This demonstrated that it is more effective to correct mistakes in a plan than to keep adding potentially flawed steps.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Generalizability Across LLMs&lt;/b&gt;: We also tested DS-STAR's adaptability by using GPT-5 as the base model. This yielded promising results on the DABStep benchmark, indicating the framework's generalizability. Interestingly, DS-STAR with GPT-5 performed better on easy tasks, while the Gemini-2.5-Pro version performed better on hard tasks.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;In-depth analysis of DS-STAR&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;Next, we conducted ablation studies to verify the effectiveness of DS-STAR’s individual components and analyze the impact of the number of refinement rounds, specifically by measuring the iterations required to generate a sufficient plan.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Data File Analyzer&lt;/b&gt;: This agent is essential for high performance. Without the descriptions it generates (Variant 1), DS-STAR's accuracy on difficult tasks within the DABStep benchmark sharply dropped to 26.98%, underscoring the importance of rich data context for effective planning and implementation.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Router&lt;/b&gt;: The Router agent’s ability to determine if a new step is needed or to fix an incorrect step is vital. When we removed it (Variant 2), DS-STAR only added new steps sequentially, leading to worse performance on both easy and hard tasks. This demonstrated that it is more effective to correct mistakes in a plan than to keep adding potentially flawed steps.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Generalizability Across LLMs&lt;/b&gt;: We also tested DS-STAR's adaptability by using GPT-5 as the base model. This yielded promising results on the DABStep benchmark, indicating the framework's generalizability. Interestingly, DS-STAR with GPT-5 performed better on easy tasks, while the Gemini-2.5-Pro version performed better on hard tasks.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/ds-star-a-state-of-the-art-versatile-data-science-agent/</guid><pubDate>Thu, 06 Nov 2025 17:50:36 +0000</pubDate></item><item><title>[NEW] Subtle Computing’s voice isolation models help computers understand you in noisy environments (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/06/subtle-computings-voice-isolation-models-help-computers-understand-you-in-noisy-environments/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/Press-Release-Photo-Close-1.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;California-based startup Subtle Computing is tackling the problem of capturing people’s voices in noisy environments with its own voice isolation models — a technology that could benefit voice-based AI products and services. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Consumer apps using voice AI are today seeing tremendous growth. AI Meeting notetakers like Granola, Fireflies, Fathom, and Read AI have received both user and investor attention. Existing companies like OpenAI, ClickUp, and Notion have integrated voice transcription solutions. App makers like Wispr Flow and Willow are working on voice dictation. Then there are hardware companies like Plaud and Sandbar that are using devices as a medium to transcribe your voice, then use AI for insight generation and interaction.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;One of the challenges for these companies is capturing users’ voices in any kind of environment, such as loud cafes or offices. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To address this, Subtle Computing developed an end-to-end voice isolation model that can understand what you are saying even in noisy environments. Chen said that there are a lot of companies working on voice understanding. He noted that at times, device manufacturers send the voice to the cloud to get a clean output, but that’s not efficient.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup trains specific models to suit the acoustics of a particular device and adapt to the user’s voice instead of training one model that works across devices.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“What we found is that when we preserve the acoustic characteristics of a device, we get an order of magnitude better performance than generic solutions. This also means we can give personalized solutions to the user,” Chen said.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company was founded by Tyler Chen, David Harrison, Savannah Cofer, and Jackie Yang, who met at Stanford. Chen, Cofer, and Yang were pursuing their PhDs while Harrison was doing an MBA. They came together in Steve Blank’s Lean Launchpad course, where they worked on alternative interfaces for computing and started building Subtle Computing.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“As we are interacting more with AI, we are moving towards a future where we talk with our devices,” Chen said. “But the obvious question is how much our devices understand us, the users, in all the environments where we work day to day. Be it a super loud coffee shop or a shared office where there are other people around you, and you might be talking about something private — voice doesn’t work that way today,” he added. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup said it can run the model just for voice isolation on some devices, which is just a few megabytes in size and has 100ms of latency. The company can also run a different model to transcribe the voice and give text output for other devices. Chen said thanks to its isolation model, the company’s transcription model can understand users better, and in turn, creates a more accurate transcript.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Subtle Computing said that Qualcomm has selected the startup as a member of its voice and music extension program. This means that the startup’s tech would be compatible with Qualcomm’s chips and be available on devices produced by OEMs.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company has raised $6 million in seed funding led by Entrada Ventures, with participation from Amplify Partners, Abstract Ventures, and angel investors, including founders like Twitter’s Biz Stone, Pinterest’s Evan Sharp, and Perplexity’s Johnny Ho.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Karen Roter Davis, Managing Partner at Entrada Ventures and a former director of an early project at X (Alphabet), noted that voice AI is a noisy space, and though interactions through this medium are picking up, the overall voice experience is not great. She thinks that the startup’s focus on voice isolation brings a different perspective to the market.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“While you can debate whether AI will increase or decrease that time spent on a day-to-day basis, we can all agree that advances in compute power and machine learning / AI provide opportunities for voice interface breakthroughs – if done right,” Davis said. “Subtle Computing is meeting people where they are with voice interfaces that hold up in extreme noise and extreme quiet, providing a voice experience that is reliable, easy, and fun. It’s a game changer,” she added. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company said it has also partnered with a consumer hardware brand and an automotive brand — without naming them — to deploy its solutions. But Subtle Computing doesn’t want to be just a model supplier to other companies. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup also said it plans to announce a consumer product that spans both hardware and software next year, without offering details. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/Press-Release-Photo-Close-1.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;California-based startup Subtle Computing is tackling the problem of capturing people’s voices in noisy environments with its own voice isolation models — a technology that could benefit voice-based AI products and services. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Consumer apps using voice AI are today seeing tremendous growth. AI Meeting notetakers like Granola, Fireflies, Fathom, and Read AI have received both user and investor attention. Existing companies like OpenAI, ClickUp, and Notion have integrated voice transcription solutions. App makers like Wispr Flow and Willow are working on voice dictation. Then there are hardware companies like Plaud and Sandbar that are using devices as a medium to transcribe your voice, then use AI for insight generation and interaction.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;One of the challenges for these companies is capturing users’ voices in any kind of environment, such as loud cafes or offices. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To address this, Subtle Computing developed an end-to-end voice isolation model that can understand what you are saying even in noisy environments. Chen said that there are a lot of companies working on voice understanding. He noted that at times, device manufacturers send the voice to the cloud to get a clean output, but that’s not efficient.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup trains specific models to suit the acoustics of a particular device and adapt to the user’s voice instead of training one model that works across devices.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“What we found is that when we preserve the acoustic characteristics of a device, we get an order of magnitude better performance than generic solutions. This also means we can give personalized solutions to the user,” Chen said.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company was founded by Tyler Chen, David Harrison, Savannah Cofer, and Jackie Yang, who met at Stanford. Chen, Cofer, and Yang were pursuing their PhDs while Harrison was doing an MBA. They came together in Steve Blank’s Lean Launchpad course, where they worked on alternative interfaces for computing and started building Subtle Computing.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“As we are interacting more with AI, we are moving towards a future where we talk with our devices,” Chen said. “But the obvious question is how much our devices understand us, the users, in all the environments where we work day to day. Be it a super loud coffee shop or a shared office where there are other people around you, and you might be talking about something private — voice doesn’t work that way today,” he added. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup said it can run the model just for voice isolation on some devices, which is just a few megabytes in size and has 100ms of latency. The company can also run a different model to transcribe the voice and give text output for other devices. Chen said thanks to its isolation model, the company’s transcription model can understand users better, and in turn, creates a more accurate transcript.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Subtle Computing said that Qualcomm has selected the startup as a member of its voice and music extension program. This means that the startup’s tech would be compatible with Qualcomm’s chips and be available on devices produced by OEMs.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company has raised $6 million in seed funding led by Entrada Ventures, with participation from Amplify Partners, Abstract Ventures, and angel investors, including founders like Twitter’s Biz Stone, Pinterest’s Evan Sharp, and Perplexity’s Johnny Ho.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Karen Roter Davis, Managing Partner at Entrada Ventures and a former director of an early project at X (Alphabet), noted that voice AI is a noisy space, and though interactions through this medium are picking up, the overall voice experience is not great. She thinks that the startup’s focus on voice isolation brings a different perspective to the market.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“While you can debate whether AI will increase or decrease that time spent on a day-to-day basis, we can all agree that advances in compute power and machine learning / AI provide opportunities for voice interface breakthroughs – if done right,” Davis said. “Subtle Computing is meeting people where they are with voice interfaces that hold up in extreme noise and extreme quiet, providing a voice experience that is reliable, easy, and fun. It’s a game changer,” she added. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company said it has also partnered with a consumer hardware brand and an automotive brand — without naming them — to deploy its solutions. But Subtle Computing doesn’t want to be just a model supplier to other companies. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup also said it plans to announce a consumer product that spans both hardware and software next year, without offering details. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/06/subtle-computings-voice-isolation-models-help-computers-understand-you-in-noisy-environments/</guid><pubDate>Thu, 06 Nov 2025 17:57:51 +0000</pubDate></item><item><title>[NEW] Meta brings its short-form video feed of AI slop to Europe (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/06/meta-brings-its-short-form-video-feed-of-ai-slop-to-europe/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta announced on Thursday that Vibes, its short-form video feed of AI-generated videos, is launching in Europe in the Meta AI app. Think TikTok or Instagram Reels, but every single video you come across is AI-generated. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The rollout comes six weeks after Meta introduced the feed in the U.S. A few days after Meta’s launch, OpenAI released Sora, a social media platform for creating and sharing AI-generated videos.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With Vibes, you can create and share short-form AI-generated videos and access a dedicated feed that displays AI videos from others. Meta says your feed will become more personalized to your interests over time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When creating content, you can generate a video using prompts or remix someone else’s video. You can add new visuals, layer in music, or adjust styles to match your individual taste.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This is an inherently social and collaborative creation experience, where you’re encouraged to remix, co-create, and build stories together with friends,” Meta wrote in a blog post. “Videos and content can be shared and posted directly to the Vibes feed, sent to friends, or cross-posted to Instagram and Facebook Stories and Reels.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3065728" height="590" src="https://techcrunch.com/wp-content/uploads/2025/11/Screenshot-2025-11-06-at-1.13.31PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Meta&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;When Meta CEO Mark Zuckerberg first unveiled the feed in September, the user comments in response to his announcement post were about what you’d expect, especially since no one really wants an AI-generated version of TikTok. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of the top comments on the post read: “gang nobody wants this,” while another popular comment said: “Bro’s posting ai slop on his own app.” Another comment read: “I think I speak for everyone when I say: What….?”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;While Meta is embracing AI-generated content, companies like YouTube are&amp;nbsp;looking to crack down on the issue, as the rise of AI technology has caused social media platforms to become flooded with AI slop — a term meaning low-quality AI content. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s debut of Vibes is particularly puzzling, given that the company said earlier this year that it was&amp;nbsp;tackling “unoriginal” content&amp;nbsp;and advised creators to focus on “authentic storytelling,” rather than short videos offering little value.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite its earlier messaging, Meta is touting the launch of Vibes, stating that media generation in the Meta AI app has jumped more than tenfold since its launch.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta announced on Thursday that Vibes, its short-form video feed of AI-generated videos, is launching in Europe in the Meta AI app. Think TikTok or Instagram Reels, but every single video you come across is AI-generated. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The rollout comes six weeks after Meta introduced the feed in the U.S. A few days after Meta’s launch, OpenAI released Sora, a social media platform for creating and sharing AI-generated videos.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With Vibes, you can create and share short-form AI-generated videos and access a dedicated feed that displays AI videos from others. Meta says your feed will become more personalized to your interests over time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When creating content, you can generate a video using prompts or remix someone else’s video. You can add new visuals, layer in music, or adjust styles to match your individual taste.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This is an inherently social and collaborative creation experience, where you’re encouraged to remix, co-create, and build stories together with friends,” Meta wrote in a blog post. “Videos and content can be shared and posted directly to the Vibes feed, sent to friends, or cross-posted to Instagram and Facebook Stories and Reels.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3065728" height="590" src="https://techcrunch.com/wp-content/uploads/2025/11/Screenshot-2025-11-06-at-1.13.31PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Meta&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;When Meta CEO Mark Zuckerberg first unveiled the feed in September, the user comments in response to his announcement post were about what you’d expect, especially since no one really wants an AI-generated version of TikTok. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of the top comments on the post read: “gang nobody wants this,” while another popular comment said: “Bro’s posting ai slop on his own app.” Another comment read: “I think I speak for everyone when I say: What….?”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;While Meta is embracing AI-generated content, companies like YouTube are&amp;nbsp;looking to crack down on the issue, as the rise of AI technology has caused social media platforms to become flooded with AI slop — a term meaning low-quality AI content. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s debut of Vibes is particularly puzzling, given that the company said earlier this year that it was&amp;nbsp;tackling “unoriginal” content&amp;nbsp;and advised creators to focus on “authentic storytelling,” rather than short videos offering little value.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite its earlier messaging, Meta is touting the launch of Vibes, stating that media generation in the Meta AI app has jumped more than tenfold since its launch.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/06/meta-brings-its-short-form-video-feed-of-ai-slop-to-europe/</guid><pubDate>Thu, 06 Nov 2025 18:22:38 +0000</pubDate></item><item><title>[NEW] Moonshot's Kimi K2 Thinking emerges as leading open source AI, outperforming GPT-5, Claude Sonnet 4.5 on key benchmarks (AI | VentureBeat)</title><link>https://venturebeat.com/ai/moonshots-kimi-k2-thinking-emerges-as-leading-open-source-ai-outperforming</link><description>[unable to retrieve full-text content]&lt;p&gt;Even as &lt;a href="https://www.tomshardware.com/tech-industry/openai-walks-back-statement-it-wants-a-government-backstop-for-its-massive-loans-company-says-government-playing-its-part-critical-for-industrial-ai-capacity-increases"&gt;concern and skepticism&lt;/a&gt; grows over U.S. AI startup OpenAI&amp;#x27;s buildout strategy and high spending commitments, Chinese open source AI providers are escalating their competition and one has even caught up to OpenAI&amp;#x27;s flagship, paid proprietary model GPT-5 in key third-party performance benchmarks with a new, free model. &lt;/p&gt;&lt;p&gt;The Chinese AI startup &lt;a href="https://moonshotai.github.io/Kimi-K2/thinking.html"&gt;Moonshot AI’s new Kimi K2 Thinking model&lt;/a&gt;, released today, has vaulted past both proprietary and open-weight competitors to claim the top position in reasoning, coding, and agentic-tool benchmarks. &lt;/p&gt;&lt;p&gt;Despite being fully open-source, the model now outperforms OpenAI’s GPT-5, Anthropic’s Claude Sonnet 4.5 (Thinking mode), and xAI&amp;#x27;s Grok-4 on several standard evaluations — an inflection point for the competitiveness of open AI systems.&lt;/p&gt;&lt;p&gt;Developers can access the model via &lt;a href="https://platform.moonshot.ai"&gt;platform.moonshot.ai&lt;/a&gt; and &lt;a href="https://kimi.com"&gt;kimi.com&lt;/a&gt;; weights and code are hosted on &lt;a href="https://huggingface.co/moonshotai/Kimi-K2-Thinking/tree/main"&gt;Hugging Face&lt;/a&gt;. The open release includes APIs for chat, reasoning, and multi-tool workflows.&lt;/p&gt;&lt;p&gt;Users can try out Kimi K2 Thinking directly through its own &lt;a href="https://www.kimi.com/"&gt;ChatGPT-like website competitor&lt;/a&gt; and on &lt;a href="https://huggingface.co/spaces/moonshotai/Kimi-VL-A3B-Thinking"&gt;a Hugging Face space as well.  &lt;/a&gt;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Modified Standard Open Source License&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Moonshot AI has formally released Kimi K2 Thinking under a &lt;a href="https://huggingface.co/moonshotai/Kimi-K2-Thinking/blob/main/LICENSE"&gt;Modified MIT License&lt;/a&gt; on Hugging Face.&lt;/p&gt;&lt;p&gt;The license grants full commercial and derivative rights — meaning individual researchers and developers working on behalf of enterprise clients can access it freely and use it in commercial applications — but adds one restriction:&lt;/p&gt;&lt;p&gt;&lt;i&gt;&amp;quot;If the software or any derivative product serves &lt;/i&gt;&lt;b&gt;&lt;i&gt;over 100 million monthly active users or generates over $20 million USD per month in revenue,&lt;/i&gt;&lt;/b&gt;&lt;i&gt; the deployer must prominently display &amp;#x27;Kimi K2&amp;#x27; on the product’s user interface.&amp;quot;&lt;/i&gt;&lt;/p&gt;&lt;p&gt;For most research and enterprise applications, this clause functions as a light-touch attribution requirement while preserving the freedoms of standard MIT licensing. &lt;/p&gt;&lt;p&gt;It makes K2 Thinking one of the most permissively licensed frontier-class models currently available.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;A New Benchmark Leader&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Kimi K2 Thinking is a Mixture-of-Experts (MoE) model built around one trillion parameters, of which 32 billion activate per inference. &lt;/p&gt;&lt;p&gt;It combines long-horizon reasoning with structured tool use, executing up to 200–300 sequential tool calls without human intervention.&lt;/p&gt;&lt;p&gt;According to Moonshot’s published test results, K2 Thinking achieved:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;44.9 %&lt;/b&gt; on &lt;i&gt;Humanity’s Last Exam (HLE)&lt;/i&gt;, a state-of-the-art score;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;60.2 %&lt;/b&gt; on &lt;i&gt;BrowseComp&lt;/i&gt;, an agentic web-search and reasoning test;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;71.3 %&lt;/b&gt; on &lt;i&gt;SWE-Bench Verified&lt;/i&gt; and &lt;b&gt;83.1 %&lt;/b&gt; on &lt;i&gt;LiveCodeBench v6&lt;/i&gt;, key coding evaluations;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;56.3 %&lt;/b&gt; on &lt;i&gt;Seal-0&lt;/i&gt;, a benchmark for real-world information retrieval.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Across these tasks, K2 Thinking consistently outperforms GPT-5’s corresponding scores and &lt;a href="https://venturebeat.com/ai/minimax-m2-is-the-new-king-of-open-source-llms-especially-for-agentic-tool"&gt;surpasses the previous open-weight leader MiniMax-M2&lt;/a&gt;—released just weeks earlier by Chinese rival MiniMax AI.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Open Model Outperforms Proprietary Systems&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;GPT-5 and Claude Sonnet 4.5 Thinking remain the leading proprietary “thinking” models. &lt;/p&gt;&lt;p&gt;Yet in the same benchmark suite, &lt;b&gt;K2 Thinking’s agentic reasoning scores exceed both&lt;/b&gt;: for instance, on BrowseComp the open model’s 60.2 % decisively leads GPT-5’s 54.9 % and Claude 4.5’s 24.1 %.&lt;/p&gt;&lt;p&gt;K2 Thinking also edges GPT-5 in &lt;i&gt;GPQA Diamond&lt;/i&gt; (85.7 % vs 84.5 %) and matches it on mathematical reasoning tasks such as &lt;i&gt;AIME 2025&lt;/i&gt; and &lt;i&gt;HMMT 2025&lt;/i&gt;. &lt;/p&gt;&lt;p&gt;Only in certain heavy-mode configurations—where GPT-5 aggregates multiple trajectories—does the proprietary model regain parity.&lt;/p&gt;&lt;p&gt;That Moonshot’s fully open-weight release can meet or exceed GPT-5’s scores marks a turning point. The gap between closed frontier systems and publicly available models has effectively collapsed for high-end reasoning and coding.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Surpassing MiniMax-M2: The Previous Open-Source Benchmark&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;When &lt;a href="https://venturebeat.com/ai/minimax-m2-is-the-new-king-of-open-source-llms-especially-for-agentic-tool"&gt;VentureBeat profiled MiniMax-M2&lt;/a&gt; just a week and a half ago, it was hailed as the “new king of open-source LLMs,” achieving top scores among open-weight systems:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;τ²-Bench 77.2&lt;/i&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;BrowseComp 44.0&lt;/i&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;FinSearchComp-global 65.5&lt;/i&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;SWE-Bench Verified 69.4&lt;/i&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Those results placed MiniMax-M2 near GPT-5-level capability in agentic tool use. Yet&lt;b&gt; Kimi K2 Thinking now eclipses them by wide margins.&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Its BrowseComp result of 60.2 % exceeds M2’s 44.0 %, and its SWE-Bench Verified 71.3 % edges out M2’s 69.4 %. Even on financial-reasoning tasks such as FinSearchComp-T3 (47.4 %), K2 Thinking performs comparably while maintaining superior general-purpose reasoning.&lt;/p&gt;&lt;p&gt;Technically, both models adopt sparse Mixture-of-Experts architectures for compute efficiency, but Moonshot’s network activates more experts and deploys advanced quantization-aware training (INT4 QAT). &lt;/p&gt;&lt;p&gt;This design doubles inference speed relative to standard precision without degrading accuracy—critical for long “thinking-token” sessions reaching 256 k context windows.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Agentic Reasoning and Tool Use&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;K2 Thinking’s defining capability lies in its explicit reasoning trace. The model outputs an auxiliary field, reasoning_content, revealing intermediate logic before each final response. This transparency preserves coherence across long multi-turn tasks and multi-step tool calls.&lt;/p&gt;&lt;p&gt;A reference implementation published by Moonshot demonstrates how the model autonomously conducts a “daily news report” workflow: invoking date and web-search tools, analyzing retrieved content, and composing structured output—all while maintaining internal reasoning state.&lt;/p&gt;&lt;p&gt;This end-to-end autonomy enables the model to plan, search, execute, and synthesize evidence across hundreds of steps, mirroring the emerging class of “agentic AI” systems that operate with minimal supervision.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Efficiency and Access&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Despite its trillion-parameter scale, K2 Thinking’s runtime cost remains modest. Moonshot lists usage at:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;$0.15 / 1 M tokens (cache hit)&lt;/b&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;$0.60 / 1 M tokens (cache miss)&lt;/b&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;$2.50 / 1 M tokens output&lt;/b&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;These rates are competitive even against MiniMax-M2’s $0.30 input / $1.20 output pricing—and an order of magnitude below GPT-5 ($1.25 input / $10 output).&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Comparative Context: Open-Weight Acceleration&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The rapid succession of M2 and K2 Thinking illustrates how quickly open-source research is catching frontier systems. MiniMax-M2 demonstrated that open models could approach GPT-5-class agentic capability at a fraction of the compute cost. Moonshot has now advanced that frontier further, pushing open weights beyond parity into outright leadership.&lt;/p&gt;&lt;p&gt;Both models rely on sparse activation for efficiency, but K2 Thinking’s higher activation count (32 B vs 10 B active parameters) yields stronger reasoning fidelity across domains. Its test-time scaling—expanding “thinking tokens” and tool-calling turns—provides measurable performance gains without retraining, a feature not yet observed in MiniMax-M2.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Technical Outlook&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Moonshot reports that K2 Thinking supports &lt;b&gt;native INT4 inference&lt;/b&gt; and &lt;b&gt;256 k-token contexts&lt;/b&gt; with minimal performance degradation. Its architecture integrates quantization, parallel trajectory aggregation (“heavy mode”), and Mixture-of-Experts routing tuned for reasoning tasks.&lt;/p&gt;&lt;p&gt;In practice, these optimizations allow K2 Thinking to sustain complex planning loops—code compile–test–fix, search–analyze–summarize—over hundreds of tool calls. This capability underpins its superior results on BrowseComp and SWE-Bench, where reasoning continuity is decisive.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Enormous Implications for the AI Ecosystem&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The convergence of open and closed models at the high end signals a structural shift in the AI landscape. Enterprises that once relied exclusively on proprietary APIs can now deploy open alternatives matching GPT-5-level reasoning while retaining full control of weights, data, and compliance.&lt;/p&gt;&lt;p&gt;Moonshot’s open publication strategy follows the precedent set by DeepSeek R1, Qwen3, GLM-4.6 and MiniMax-M2 but extends it to full agentic reasoning. &lt;/p&gt;&lt;p&gt;For academic and enterprise developers, K2 Thinking provides both transparency and interoperability—the ability to inspect reasoning traces and fine-tune performance for domain-specific agents.&lt;/p&gt;&lt;p&gt;The arrival of K2 Thinking signals that Moonshot — a &lt;a href="https://techcrunch.com/2024/02/21/moonshot-ai-funding-china/"&gt;young startup founded in 2023&lt;/a&gt; with investment from some of China&amp;#x27;s biggest apps and tech companies — is here to play in an intensifying competition, and comes amid growing scrutiny of the financial sustainability of AI’s largest players. &lt;/p&gt;&lt;p&gt;Just a day ago, OpenAI CFO Sarah Friar sparked controversy after &lt;a href="https://www.wsj.com/tech/ai/openai-isnt-yet-working-toward-an-ipo-cfo-says-58037472?gaa_at=eafs&amp;amp;gaa_n=AWEtsqfPSJ91IQIG678OHyyBAwXqBLDfUb01-yZGSGU-uiYZq5Oudu3hFs6HuIdk-2A%3D&amp;amp;gaa_ts=690cdeaf&amp;amp;gaa_sig=vcfYpYv-Y0bP8WOkElUbVMCF-MAssgO9v2J34nzp5c7Mr0hs2x6WddR6gK12PW2xhfZiNCQrUUQCrRizxbFkMA%3D%3D"&gt;suggesting at WSJ Tech Live&lt;/a&gt; event that the U.S. government might eventually need to provide a “backstop” for the company’s more than $1.4 trillion in compute and data-center commitments — a comment widely interpreted as a call for taxpayer-backed loan guarantees.&lt;/p&gt;&lt;p&gt;Although &lt;a href="https://www.cnbc.com/2025/11/06/openai-cfo-sarah-friar-says-company-is-not-seeking-government-backstop.html"&gt;Friar later clarified that OpenAI&lt;/a&gt; was not seeking direct federal support, the episode reignited debate about the scale and concentration of AI capital spending. &lt;/p&gt;&lt;p&gt;With OpenAI, Microsoft, Meta, and Google all racing to secure long-term chip supply, critics warn of an unsustainable investment bubble and “AI arms race” driven more by strategic fear than commercial returns — one that could &amp;quot;blow up&amp;quot; and take down the entire global economy with it if there is hesitation or market uncertainty, as so many trades and valuations have now been made in anticipation of continued hefty AI investment and massive returns. &lt;/p&gt;&lt;p&gt;Against that backdrop, Moonshot AI’s and MiniMax’s open-weight releases put more pressure on U.S. proprietary AI firms and their backers to justify the size of the investments and paths to profitability. &lt;/p&gt;&lt;p&gt;If an enterprise customer can just as easily get comparable or better performance from a free, open source Chinese AI model than they do with paid, proprietary AI solutions like OpenAI&amp;#x27;s GPT-5, Anthropic&amp;#x27;s Claude Sonnet 4.5, or Google&amp;#x27;s Gemini 2.5 Pro — why would they continue paying to access the proprietary models? Already, Silicon Valley stalwarts like Airbnb have raised eyebrows for admitting to heavily &lt;a href="https://www.scmp.com/tech/tech-trends/article/3329921/airbnb-picks-alibabas-qwen-over-chatgpt-win-chinese-open-source-ai"&gt;using Chinese open source alternatives like Alibaba&amp;#x27;s Qwen over OpenAI&amp;#x27;s proprietary offerings&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;For investors and enterprises, these developments suggest that high-end AI capability is no longer synonymous with high-end capital expenditure. The most advanced reasoning systems may now come not from companies building gigascale data centers, but from research groups optimizing architectures and quantization for efficiency.&lt;/p&gt;&lt;p&gt;In that sense, K2 Thinking’s benchmark dominance is not just a technical milestone—it’s a strategic one, arriving at a moment when the AI market’s biggest question has shifted from &lt;i&gt;how powerful models can become&lt;/i&gt; to &lt;i&gt;who can afford to sustain them&lt;/i&gt;.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;What It Means for Enterprises Going Forward&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Within weeks of MiniMax-M2’s ascent, Kimi K2 Thinking has overtaken it—along with GPT-5 and Claude 4.5—across nearly every reasoning and agentic benchmark. &lt;/p&gt;&lt;p&gt;The model demonstrates that open-weight systems can &lt;b&gt;now meet or surpass proprietary frontier models&lt;/b&gt; in both capability and efficiency.&lt;/p&gt;&lt;p&gt;For the AI research community, K2 Thinking represents more than another open model: it is evidence that the frontier has become collaborative. &lt;/p&gt;&lt;p&gt;The best-performing reasoning model available today is not a closed commercial product but an open-source system accessible to anyone.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;Even as &lt;a href="https://www.tomshardware.com/tech-industry/openai-walks-back-statement-it-wants-a-government-backstop-for-its-massive-loans-company-says-government-playing-its-part-critical-for-industrial-ai-capacity-increases"&gt;concern and skepticism&lt;/a&gt; grows over U.S. AI startup OpenAI&amp;#x27;s buildout strategy and high spending commitments, Chinese open source AI providers are escalating their competition and one has even caught up to OpenAI&amp;#x27;s flagship, paid proprietary model GPT-5 in key third-party performance benchmarks with a new, free model. &lt;/p&gt;&lt;p&gt;The Chinese AI startup &lt;a href="https://moonshotai.github.io/Kimi-K2/thinking.html"&gt;Moonshot AI’s new Kimi K2 Thinking model&lt;/a&gt;, released today, has vaulted past both proprietary and open-weight competitors to claim the top position in reasoning, coding, and agentic-tool benchmarks. &lt;/p&gt;&lt;p&gt;Despite being fully open-source, the model now outperforms OpenAI’s GPT-5, Anthropic’s Claude Sonnet 4.5 (Thinking mode), and xAI&amp;#x27;s Grok-4 on several standard evaluations — an inflection point for the competitiveness of open AI systems.&lt;/p&gt;&lt;p&gt;Developers can access the model via &lt;a href="https://platform.moonshot.ai"&gt;platform.moonshot.ai&lt;/a&gt; and &lt;a href="https://kimi.com"&gt;kimi.com&lt;/a&gt;; weights and code are hosted on &lt;a href="https://huggingface.co/moonshotai/Kimi-K2-Thinking/tree/main"&gt;Hugging Face&lt;/a&gt;. The open release includes APIs for chat, reasoning, and multi-tool workflows.&lt;/p&gt;&lt;p&gt;Users can try out Kimi K2 Thinking directly through its own &lt;a href="https://www.kimi.com/"&gt;ChatGPT-like website competitor&lt;/a&gt; and on &lt;a href="https://huggingface.co/spaces/moonshotai/Kimi-VL-A3B-Thinking"&gt;a Hugging Face space as well.  &lt;/a&gt;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Modified Standard Open Source License&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Moonshot AI has formally released Kimi K2 Thinking under a &lt;a href="https://huggingface.co/moonshotai/Kimi-K2-Thinking/blob/main/LICENSE"&gt;Modified MIT License&lt;/a&gt; on Hugging Face.&lt;/p&gt;&lt;p&gt;The license grants full commercial and derivative rights — meaning individual researchers and developers working on behalf of enterprise clients can access it freely and use it in commercial applications — but adds one restriction:&lt;/p&gt;&lt;p&gt;&lt;i&gt;&amp;quot;If the software or any derivative product serves &lt;/i&gt;&lt;b&gt;&lt;i&gt;over 100 million monthly active users or generates over $20 million USD per month in revenue,&lt;/i&gt;&lt;/b&gt;&lt;i&gt; the deployer must prominently display &amp;#x27;Kimi K2&amp;#x27; on the product’s user interface.&amp;quot;&lt;/i&gt;&lt;/p&gt;&lt;p&gt;For most research and enterprise applications, this clause functions as a light-touch attribution requirement while preserving the freedoms of standard MIT licensing. &lt;/p&gt;&lt;p&gt;It makes K2 Thinking one of the most permissively licensed frontier-class models currently available.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;A New Benchmark Leader&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Kimi K2 Thinking is a Mixture-of-Experts (MoE) model built around one trillion parameters, of which 32 billion activate per inference. &lt;/p&gt;&lt;p&gt;It combines long-horizon reasoning with structured tool use, executing up to 200–300 sequential tool calls without human intervention.&lt;/p&gt;&lt;p&gt;According to Moonshot’s published test results, K2 Thinking achieved:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;44.9 %&lt;/b&gt; on &lt;i&gt;Humanity’s Last Exam (HLE)&lt;/i&gt;, a state-of-the-art score;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;60.2 %&lt;/b&gt; on &lt;i&gt;BrowseComp&lt;/i&gt;, an agentic web-search and reasoning test;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;71.3 %&lt;/b&gt; on &lt;i&gt;SWE-Bench Verified&lt;/i&gt; and &lt;b&gt;83.1 %&lt;/b&gt; on &lt;i&gt;LiveCodeBench v6&lt;/i&gt;, key coding evaluations;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;56.3 %&lt;/b&gt; on &lt;i&gt;Seal-0&lt;/i&gt;, a benchmark for real-world information retrieval.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Across these tasks, K2 Thinking consistently outperforms GPT-5’s corresponding scores and &lt;a href="https://venturebeat.com/ai/minimax-m2-is-the-new-king-of-open-source-llms-especially-for-agentic-tool"&gt;surpasses the previous open-weight leader MiniMax-M2&lt;/a&gt;—released just weeks earlier by Chinese rival MiniMax AI.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Open Model Outperforms Proprietary Systems&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;GPT-5 and Claude Sonnet 4.5 Thinking remain the leading proprietary “thinking” models. &lt;/p&gt;&lt;p&gt;Yet in the same benchmark suite, &lt;b&gt;K2 Thinking’s agentic reasoning scores exceed both&lt;/b&gt;: for instance, on BrowseComp the open model’s 60.2 % decisively leads GPT-5’s 54.9 % and Claude 4.5’s 24.1 %.&lt;/p&gt;&lt;p&gt;K2 Thinking also edges GPT-5 in &lt;i&gt;GPQA Diamond&lt;/i&gt; (85.7 % vs 84.5 %) and matches it on mathematical reasoning tasks such as &lt;i&gt;AIME 2025&lt;/i&gt; and &lt;i&gt;HMMT 2025&lt;/i&gt;. &lt;/p&gt;&lt;p&gt;Only in certain heavy-mode configurations—where GPT-5 aggregates multiple trajectories—does the proprietary model regain parity.&lt;/p&gt;&lt;p&gt;That Moonshot’s fully open-weight release can meet or exceed GPT-5’s scores marks a turning point. The gap between closed frontier systems and publicly available models has effectively collapsed for high-end reasoning and coding.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Surpassing MiniMax-M2: The Previous Open-Source Benchmark&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;When &lt;a href="https://venturebeat.com/ai/minimax-m2-is-the-new-king-of-open-source-llms-especially-for-agentic-tool"&gt;VentureBeat profiled MiniMax-M2&lt;/a&gt; just a week and a half ago, it was hailed as the “new king of open-source LLMs,” achieving top scores among open-weight systems:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;τ²-Bench 77.2&lt;/i&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;BrowseComp 44.0&lt;/i&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;FinSearchComp-global 65.5&lt;/i&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;i&gt;SWE-Bench Verified 69.4&lt;/i&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Those results placed MiniMax-M2 near GPT-5-level capability in agentic tool use. Yet&lt;b&gt; Kimi K2 Thinking now eclipses them by wide margins.&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Its BrowseComp result of 60.2 % exceeds M2’s 44.0 %, and its SWE-Bench Verified 71.3 % edges out M2’s 69.4 %. Even on financial-reasoning tasks such as FinSearchComp-T3 (47.4 %), K2 Thinking performs comparably while maintaining superior general-purpose reasoning.&lt;/p&gt;&lt;p&gt;Technically, both models adopt sparse Mixture-of-Experts architectures for compute efficiency, but Moonshot’s network activates more experts and deploys advanced quantization-aware training (INT4 QAT). &lt;/p&gt;&lt;p&gt;This design doubles inference speed relative to standard precision without degrading accuracy—critical for long “thinking-token” sessions reaching 256 k context windows.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Agentic Reasoning and Tool Use&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;K2 Thinking’s defining capability lies in its explicit reasoning trace. The model outputs an auxiliary field, reasoning_content, revealing intermediate logic before each final response. This transparency preserves coherence across long multi-turn tasks and multi-step tool calls.&lt;/p&gt;&lt;p&gt;A reference implementation published by Moonshot demonstrates how the model autonomously conducts a “daily news report” workflow: invoking date and web-search tools, analyzing retrieved content, and composing structured output—all while maintaining internal reasoning state.&lt;/p&gt;&lt;p&gt;This end-to-end autonomy enables the model to plan, search, execute, and synthesize evidence across hundreds of steps, mirroring the emerging class of “agentic AI” systems that operate with minimal supervision.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Efficiency and Access&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Despite its trillion-parameter scale, K2 Thinking’s runtime cost remains modest. Moonshot lists usage at:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;$0.15 / 1 M tokens (cache hit)&lt;/b&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;$0.60 / 1 M tokens (cache miss)&lt;/b&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;$2.50 / 1 M tokens output&lt;/b&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;These rates are competitive even against MiniMax-M2’s $0.30 input / $1.20 output pricing—and an order of magnitude below GPT-5 ($1.25 input / $10 output).&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Comparative Context: Open-Weight Acceleration&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The rapid succession of M2 and K2 Thinking illustrates how quickly open-source research is catching frontier systems. MiniMax-M2 demonstrated that open models could approach GPT-5-class agentic capability at a fraction of the compute cost. Moonshot has now advanced that frontier further, pushing open weights beyond parity into outright leadership.&lt;/p&gt;&lt;p&gt;Both models rely on sparse activation for efficiency, but K2 Thinking’s higher activation count (32 B vs 10 B active parameters) yields stronger reasoning fidelity across domains. Its test-time scaling—expanding “thinking tokens” and tool-calling turns—provides measurable performance gains without retraining, a feature not yet observed in MiniMax-M2.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Technical Outlook&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Moonshot reports that K2 Thinking supports &lt;b&gt;native INT4 inference&lt;/b&gt; and &lt;b&gt;256 k-token contexts&lt;/b&gt; with minimal performance degradation. Its architecture integrates quantization, parallel trajectory aggregation (“heavy mode”), and Mixture-of-Experts routing tuned for reasoning tasks.&lt;/p&gt;&lt;p&gt;In practice, these optimizations allow K2 Thinking to sustain complex planning loops—code compile–test–fix, search–analyze–summarize—over hundreds of tool calls. This capability underpins its superior results on BrowseComp and SWE-Bench, where reasoning continuity is decisive.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Enormous Implications for the AI Ecosystem&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The convergence of open and closed models at the high end signals a structural shift in the AI landscape. Enterprises that once relied exclusively on proprietary APIs can now deploy open alternatives matching GPT-5-level reasoning while retaining full control of weights, data, and compliance.&lt;/p&gt;&lt;p&gt;Moonshot’s open publication strategy follows the precedent set by DeepSeek R1, Qwen3, GLM-4.6 and MiniMax-M2 but extends it to full agentic reasoning. &lt;/p&gt;&lt;p&gt;For academic and enterprise developers, K2 Thinking provides both transparency and interoperability—the ability to inspect reasoning traces and fine-tune performance for domain-specific agents.&lt;/p&gt;&lt;p&gt;The arrival of K2 Thinking signals that Moonshot — a &lt;a href="https://techcrunch.com/2024/02/21/moonshot-ai-funding-china/"&gt;young startup founded in 2023&lt;/a&gt; with investment from some of China&amp;#x27;s biggest apps and tech companies — is here to play in an intensifying competition, and comes amid growing scrutiny of the financial sustainability of AI’s largest players. &lt;/p&gt;&lt;p&gt;Just a day ago, OpenAI CFO Sarah Friar sparked controversy after &lt;a href="https://www.wsj.com/tech/ai/openai-isnt-yet-working-toward-an-ipo-cfo-says-58037472?gaa_at=eafs&amp;amp;gaa_n=AWEtsqfPSJ91IQIG678OHyyBAwXqBLDfUb01-yZGSGU-uiYZq5Oudu3hFs6HuIdk-2A%3D&amp;amp;gaa_ts=690cdeaf&amp;amp;gaa_sig=vcfYpYv-Y0bP8WOkElUbVMCF-MAssgO9v2J34nzp5c7Mr0hs2x6WddR6gK12PW2xhfZiNCQrUUQCrRizxbFkMA%3D%3D"&gt;suggesting at WSJ Tech Live&lt;/a&gt; event that the U.S. government might eventually need to provide a “backstop” for the company’s more than $1.4 trillion in compute and data-center commitments — a comment widely interpreted as a call for taxpayer-backed loan guarantees.&lt;/p&gt;&lt;p&gt;Although &lt;a href="https://www.cnbc.com/2025/11/06/openai-cfo-sarah-friar-says-company-is-not-seeking-government-backstop.html"&gt;Friar later clarified that OpenAI&lt;/a&gt; was not seeking direct federal support, the episode reignited debate about the scale and concentration of AI capital spending. &lt;/p&gt;&lt;p&gt;With OpenAI, Microsoft, Meta, and Google all racing to secure long-term chip supply, critics warn of an unsustainable investment bubble and “AI arms race” driven more by strategic fear than commercial returns — one that could &amp;quot;blow up&amp;quot; and take down the entire global economy with it if there is hesitation or market uncertainty, as so many trades and valuations have now been made in anticipation of continued hefty AI investment and massive returns. &lt;/p&gt;&lt;p&gt;Against that backdrop, Moonshot AI’s and MiniMax’s open-weight releases put more pressure on U.S. proprietary AI firms and their backers to justify the size of the investments and paths to profitability. &lt;/p&gt;&lt;p&gt;If an enterprise customer can just as easily get comparable or better performance from a free, open source Chinese AI model than they do with paid, proprietary AI solutions like OpenAI&amp;#x27;s GPT-5, Anthropic&amp;#x27;s Claude Sonnet 4.5, or Google&amp;#x27;s Gemini 2.5 Pro — why would they continue paying to access the proprietary models? Already, Silicon Valley stalwarts like Airbnb have raised eyebrows for admitting to heavily &lt;a href="https://www.scmp.com/tech/tech-trends/article/3329921/airbnb-picks-alibabas-qwen-over-chatgpt-win-chinese-open-source-ai"&gt;using Chinese open source alternatives like Alibaba&amp;#x27;s Qwen over OpenAI&amp;#x27;s proprietary offerings&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;For investors and enterprises, these developments suggest that high-end AI capability is no longer synonymous with high-end capital expenditure. The most advanced reasoning systems may now come not from companies building gigascale data centers, but from research groups optimizing architectures and quantization for efficiency.&lt;/p&gt;&lt;p&gt;In that sense, K2 Thinking’s benchmark dominance is not just a technical milestone—it’s a strategic one, arriving at a moment when the AI market’s biggest question has shifted from &lt;i&gt;how powerful models can become&lt;/i&gt; to &lt;i&gt;who can afford to sustain them&lt;/i&gt;.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;What It Means for Enterprises Going Forward&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Within weeks of MiniMax-M2’s ascent, Kimi K2 Thinking has overtaken it—along with GPT-5 and Claude 4.5—across nearly every reasoning and agentic benchmark. &lt;/p&gt;&lt;p&gt;The model demonstrates that open-weight systems can &lt;b&gt;now meet or surpass proprietary frontier models&lt;/b&gt; in both capability and efficiency.&lt;/p&gt;&lt;p&gt;For the AI research community, K2 Thinking represents more than another open model: it is evidence that the frontier has become collaborative. &lt;/p&gt;&lt;p&gt;The best-performing reasoning model available today is not a closed commercial product but an open-source system accessible to anyone.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/moonshots-kimi-k2-thinking-emerges-as-leading-open-source-ai-outperforming</guid><pubDate>Thu, 06 Nov 2025 18:27:00 +0000</pubDate></item></channel></rss>