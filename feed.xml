<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 11 Dec 2025 18:34:42 +0000</lastBuildDate><item><title>Harness hits $5.5B valuation with $240M raise to automate AI’s ‘after-code’ gap (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/11/harness-hits-5-5b-valuation-with-240m-to-automate-ais-after-code-gap/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI DevOps tool Harness, founded in 2017 by serial entrepreneur Jyoti Bansal, is on track to exceed $250 million in annual recurring revenue in 2025, Bansal tells TechCrunch. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup just raised a fresh $240 million Series E funding round that values the company at $5.5 billion post-money.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The round includes a $200 million primary investment led by Goldman Sachs and a planned $40 million tender offer with participation from IVP, Menlo Ventures, and Unusual Ventures. The tender offer is intended to provide some liquidity to its long-term employees, Bansal said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new valuation is a 49% jump from its $3.7 billion valuation in a $230 million round in April 2022. With this funding, the startup has raised $570 million of equity to date.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As AI accelerates code production, it is widening a bottleneck in the far larger “after-code” phase of software development — the testing, security checks, and deployment work that still consumes nearly 70% of engineering time. Harness’s tools help automate this sprawling, error-prone layer, even as enterprises grapple with rising AI code volume and the risks of shipping even a single line of faulty software into production systems.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bansal is well known among developers for building and selling app performance company AppDynamics to Cisco for $3.7 billion in 2017. So the post-coding world is an area Bansal knows well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Harness uses AI agents to automate functions like testing, verification, security, and governance. It is built on a software delivery knowledge graph that maps code changes, services, deployments, tests, environments, incidents, policies, and costs. The knowledge graph helps differentiate Harness from other AI platforms, Bansal said, because it gives the system a deep understanding of each customer’s software delivery processes and architecture.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“This knowledge graph is the context that our AI agents use,” he told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The purpose-built agents draw on that context to generate pipelines that match each customer’s specific policies, architecture, and operational requirements.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Harness also uses an orchestration engine that turns the AI’s recommendations into automated actions, with checks in place to make sure those changes are applied safely.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3074986" height="1049" src="https://techcrunch.com/wp-content/uploads/2025/12/harness-ai.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Harness&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;As AI is not foolproof, Bansal said the system is designed with human oversight, noting that AI-generated tests or fixes are reviewed by engineers, compliance teams, or auditors before being put into use.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Microsoft’s GitHub, GitLab, Jenkins, and CloudBees are among the key competitors for Harness. But Harness has plenty of traction, claiming more than 1,000 enterprise customers, including United Airlines, Morningstar, Keller Williams, and National Australia Bank. So far, the startup has handled 128 million deployments, 81 million builds, protected 1.2 trillion API calls, and helped customers optimize $1.9 billion in cloud spending over the past year, Bansal touts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The San Francisco–based company employs over 1,200 people across 14 offices worldwide, including in Europe and the U.K. Around 33% of its workforce is in India, where it has a large engineering team in Bengaluru and a corporate office in Gurugram. Moreover, the Bengaluru site is Harness’s biggest development center outside the U.S.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Harness plans to use the new funding to expand its R&amp;amp;D efforts, hire “hundreds of engineers” at its Bengaluru office, and build out additional automated testing, deployment, and security capabilities while improving the accuracy of its AI systems. The company also intends to strengthen its U.S. go-to-market operations and significantly expand its presence in international markets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It should also be noted that earlier this year, Bansal merged his software observability firm Traceable with Harness, and that move has helped the startup grow its ARR projection.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We brought the two companies together because we started to see that DevOps and application security are coming together in a very, very deep way,” said Bansal. “We have seen that turned out to be a very, very successful thesis this year&amp;nbsp;… that’s driving a lot of growth for both of our DevOps and application security set of products.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While this raise has allowed some employees to cash out a bit,  Bansal still plans on taking Harness public one day, he said, though he did not share a specific timeline.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“That’s what our goals and plans depend on,” he said of an eventual IPO. “Our business is very, very healthy, very strong, high growth and margins, and it will be a great public company when the timing is right.”&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI DevOps tool Harness, founded in 2017 by serial entrepreneur Jyoti Bansal, is on track to exceed $250 million in annual recurring revenue in 2025, Bansal tells TechCrunch. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup just raised a fresh $240 million Series E funding round that values the company at $5.5 billion post-money.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The round includes a $200 million primary investment led by Goldman Sachs and a planned $40 million tender offer with participation from IVP, Menlo Ventures, and Unusual Ventures. The tender offer is intended to provide some liquidity to its long-term employees, Bansal said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new valuation is a 49% jump from its $3.7 billion valuation in a $230 million round in April 2022. With this funding, the startup has raised $570 million of equity to date.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As AI accelerates code production, it is widening a bottleneck in the far larger “after-code” phase of software development — the testing, security checks, and deployment work that still consumes nearly 70% of engineering time. Harness’s tools help automate this sprawling, error-prone layer, even as enterprises grapple with rising AI code volume and the risks of shipping even a single line of faulty software into production systems.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bansal is well known among developers for building and selling app performance company AppDynamics to Cisco for $3.7 billion in 2017. So the post-coding world is an area Bansal knows well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Harness uses AI agents to automate functions like testing, verification, security, and governance. It is built on a software delivery knowledge graph that maps code changes, services, deployments, tests, environments, incidents, policies, and costs. The knowledge graph helps differentiate Harness from other AI platforms, Bansal said, because it gives the system a deep understanding of each customer’s software delivery processes and architecture.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“This knowledge graph is the context that our AI agents use,” he told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The purpose-built agents draw on that context to generate pipelines that match each customer’s specific policies, architecture, and operational requirements.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Harness also uses an orchestration engine that turns the AI’s recommendations into automated actions, with checks in place to make sure those changes are applied safely.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3074986" height="1049" src="https://techcrunch.com/wp-content/uploads/2025/12/harness-ai.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Harness&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;As AI is not foolproof, Bansal said the system is designed with human oversight, noting that AI-generated tests or fixes are reviewed by engineers, compliance teams, or auditors before being put into use.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Microsoft’s GitHub, GitLab, Jenkins, and CloudBees are among the key competitors for Harness. But Harness has plenty of traction, claiming more than 1,000 enterprise customers, including United Airlines, Morningstar, Keller Williams, and National Australia Bank. So far, the startup has handled 128 million deployments, 81 million builds, protected 1.2 trillion API calls, and helped customers optimize $1.9 billion in cloud spending over the past year, Bansal touts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The San Francisco–based company employs over 1,200 people across 14 offices worldwide, including in Europe and the U.K. Around 33% of its workforce is in India, where it has a large engineering team in Bengaluru and a corporate office in Gurugram. Moreover, the Bengaluru site is Harness’s biggest development center outside the U.S.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Harness plans to use the new funding to expand its R&amp;amp;D efforts, hire “hundreds of engineers” at its Bengaluru office, and build out additional automated testing, deployment, and security capabilities while improving the accuracy of its AI systems. The company also intends to strengthen its U.S. go-to-market operations and significantly expand its presence in international markets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It should also be noted that earlier this year, Bansal merged his software observability firm Traceable with Harness, and that move has helped the startup grow its ARR projection.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We brought the two companies together because we started to see that DevOps and application security are coming together in a very, very deep way,” said Bansal. “We have seen that turned out to be a very, very successful thesis this year&amp;nbsp;… that’s driving a lot of growth for both of our DevOps and application security set of products.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While this raise has allowed some employees to cash out a bit,  Bansal still plans on taking Harness public one day, he said, though he did not share a specific timeline.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“That’s what our goals and plans depend on,” he said of an eventual IPO. “Our business is very, very healthy, very strong, high growth and margins, and it will be a great public company when the timing is right.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/11/harness-hits-5-5b-valuation-with-240m-to-automate-ais-after-code-gap/</guid><pubDate>Thu, 11 Dec 2025 10:30:00 +0000</pubDate></item><item><title>Solar geoengineering startups are getting serious (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/12/11/1129239/solar-geoengineering-startups-are-getting-serious/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/12/GettyImages-2155252547.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Solar geoengineering aims to manipulate the climate by bouncing sunlight back into space. In theory, it could ease global warming. But as interest in the idea grows, so do concerns about potential consequences.&lt;/p&gt;  &lt;p&gt;A startup called Stardust Solutions recently raised a $60 million funding round, the largest known to date for a geoengineering startup. My colleague James Temple has a new story out about the company, and how its emergence is making some researchers nervous.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;So far, the field has been limited to debates, proposed academic research, and—sure—a few fringe actors to keep an eye on. Now things are getting more serious. What does it mean for geoengineering, and for the climate?&lt;/p&gt;  &lt;p&gt;Researchers have considered the possibility of addressing planetary warming this way for decades. We already know that volcanic eruptions, which spew sulfur dioxide into the atmosphere, can reduce temperatures. The thought is that we could mimic that natural process by spraying particles up there ourselves.&lt;/p&gt; 
 &lt;p&gt;The prospect is a controversial one, to put it lightly. Many have concerns about unintended consequences and uneven benefits. Even public research led by top institutions has faced barriers—one famous Harvard research program was officially canceled last year after years of debate.&lt;/p&gt;  &lt;p&gt;One of the difficulties of geoengineering is that in theory a single entity, like a startup company, could make decisions that have a widespread effect on the planet. And in the last few years, we’ve seen more interest in geoengineering from the private sector.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Three years ago, James broke the story that Make Sunsets, a California-based company, was already releasing particles into the atmosphere in an effort to tweak the climate.&lt;/p&gt;  &lt;p&gt;The company’s CEO Luke Iseman went to Baja California in Mexico, stuck some sulfur dioxide into a weather balloon, and sent it skyward. The amount of material was tiny, and it’s not clear that it even made it into the right part of the atmosphere to reflect any sunlight.&lt;/p&gt;  &lt;p&gt;But fears that this group or others could go rogue and do their own geoengineering led to widespread backlash. Mexico announced plans to restrict geoengineering experiments in the country a few weeks after that news broke.&lt;/p&gt;  &lt;p&gt;You can still buy cooling credits from Make Sunsets, and the company was just granted a patent for its system. But the startup is seen as something of a fringe actor.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__container--08c53dd3bc9bd04e1e42e5f7ca641ab2"&gt;&lt;div class="whyItMatters__header--19f7f372f181cc6d4c06bc7362a44382"&gt;&lt;div class="whyItMatters__title--4af28c786a2bc93df05db111c6c30618"&gt;&lt;span class="whyItMatters__askAi--577f5fe6f54de43e37258d0f2aff4394"&gt;Ask AI&lt;/span&gt;&lt;div&gt;&lt;span class="whyItMatters__whyItMattersTitle--a3694998bb578e159bbd16690b8da390"&gt;Why it matters to you?&lt;/span&gt;&lt;span class="whyItMatters__betaBadge--9e84228b864d33d5b55479433fc91b8a"&gt;BETA&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__description--e1334886c092fa469388d7a24e1e1a55"&gt;&lt;span class="initial-description"&gt;Here’s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates—it might get weird&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="whyItMatters__questionContainer--ec1159210954852b9178c549600959a0"&gt;&lt;div&gt;&lt;button class="whyItMatters__actionButton--674934b6df433ac81e613372979cdb6c" type="button"&gt;Tell me why it matters&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Enter Stardust Solutions. The company has been working under the radar for a few years, but it has started talking about its work more publicly this year. In October, it announced a significant funding round, led by some top names in climate investing. “Stardust is serious, and now it’s raised serious money from serious people,” as James puts it in his new story.&lt;/p&gt;  &lt;p&gt;That’s making some experts nervous. Even those who believe we should be researching geoengineering are concerned about what it means for private companies to do so.&lt;/p&gt;  &lt;p&gt;“Adding business interests, profit motives, and rich investors into this situation just creates more cause for concern, complicating the ability of responsible scientists and engineers to carry out the work needed to advance our understanding,” write David Keith and Daniele Visioni, two leading figures in geoengineering research, in a recent opinion piece for &lt;em&gt;MIT Technology Review&lt;/em&gt;.&lt;/p&gt;  &lt;p&gt;Stardust insists that it won’t move forward with any geoengineering until and unless it’s commissioned to do so by governments and there are rules and bodies in place to govern use of the technology.&lt;/p&gt; 

 &lt;p&gt;But there’s no telling how financial pressure might change that, down the road. And we’re already seeing some of the challenges faced by a private company in this space: the need to keep trade secrets.&lt;/p&gt;  &lt;p&gt;Stardust is currently not sharing information about the particles it intends to release into the sky, though it says it plans to do so once it secures a patent, which could happen as soon as next year. The company argues that its proprietary particles will be safe, cheap to manufacture, and easier to track than the already abundant sulfur dioxide. But at this point, there’s no way for external experts to evaluate those claims.&lt;/p&gt;  &lt;p&gt;As Keith and Visioni put it: “Research won’t be useful unless it’s trusted, and trust depends on transparency.”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark, &lt;/em&gt;MIT Technology Review&lt;em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/12/GettyImages-2155252547.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Solar geoengineering aims to manipulate the climate by bouncing sunlight back into space. In theory, it could ease global warming. But as interest in the idea grows, so do concerns about potential consequences.&lt;/p&gt;  &lt;p&gt;A startup called Stardust Solutions recently raised a $60 million funding round, the largest known to date for a geoengineering startup. My colleague James Temple has a new story out about the company, and how its emergence is making some researchers nervous.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;So far, the field has been limited to debates, proposed academic research, and—sure—a few fringe actors to keep an eye on. Now things are getting more serious. What does it mean for geoengineering, and for the climate?&lt;/p&gt;  &lt;p&gt;Researchers have considered the possibility of addressing planetary warming this way for decades. We already know that volcanic eruptions, which spew sulfur dioxide into the atmosphere, can reduce temperatures. The thought is that we could mimic that natural process by spraying particles up there ourselves.&lt;/p&gt; 
 &lt;p&gt;The prospect is a controversial one, to put it lightly. Many have concerns about unintended consequences and uneven benefits. Even public research led by top institutions has faced barriers—one famous Harvard research program was officially canceled last year after years of debate.&lt;/p&gt;  &lt;p&gt;One of the difficulties of geoengineering is that in theory a single entity, like a startup company, could make decisions that have a widespread effect on the planet. And in the last few years, we’ve seen more interest in geoengineering from the private sector.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Three years ago, James broke the story that Make Sunsets, a California-based company, was already releasing particles into the atmosphere in an effort to tweak the climate.&lt;/p&gt;  &lt;p&gt;The company’s CEO Luke Iseman went to Baja California in Mexico, stuck some sulfur dioxide into a weather balloon, and sent it skyward. The amount of material was tiny, and it’s not clear that it even made it into the right part of the atmosphere to reflect any sunlight.&lt;/p&gt;  &lt;p&gt;But fears that this group or others could go rogue and do their own geoengineering led to widespread backlash. Mexico announced plans to restrict geoengineering experiments in the country a few weeks after that news broke.&lt;/p&gt;  &lt;p&gt;You can still buy cooling credits from Make Sunsets, and the company was just granted a patent for its system. But the startup is seen as something of a fringe actor.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__container--08c53dd3bc9bd04e1e42e5f7ca641ab2"&gt;&lt;div class="whyItMatters__header--19f7f372f181cc6d4c06bc7362a44382"&gt;&lt;div class="whyItMatters__title--4af28c786a2bc93df05db111c6c30618"&gt;&lt;span class="whyItMatters__askAi--577f5fe6f54de43e37258d0f2aff4394"&gt;Ask AI&lt;/span&gt;&lt;div&gt;&lt;span class="whyItMatters__whyItMattersTitle--a3694998bb578e159bbd16690b8da390"&gt;Why it matters to you?&lt;/span&gt;&lt;span class="whyItMatters__betaBadge--9e84228b864d33d5b55479433fc91b8a"&gt;BETA&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__description--e1334886c092fa469388d7a24e1e1a55"&gt;&lt;span class="initial-description"&gt;Here’s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates—it might get weird&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="whyItMatters__questionContainer--ec1159210954852b9178c549600959a0"&gt;&lt;div&gt;&lt;button class="whyItMatters__actionButton--674934b6df433ac81e613372979cdb6c" type="button"&gt;Tell me why it matters&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Enter Stardust Solutions. The company has been working under the radar for a few years, but it has started talking about its work more publicly this year. In October, it announced a significant funding round, led by some top names in climate investing. “Stardust is serious, and now it’s raised serious money from serious people,” as James puts it in his new story.&lt;/p&gt;  &lt;p&gt;That’s making some experts nervous. Even those who believe we should be researching geoengineering are concerned about what it means for private companies to do so.&lt;/p&gt;  &lt;p&gt;“Adding business interests, profit motives, and rich investors into this situation just creates more cause for concern, complicating the ability of responsible scientists and engineers to carry out the work needed to advance our understanding,” write David Keith and Daniele Visioni, two leading figures in geoengineering research, in a recent opinion piece for &lt;em&gt;MIT Technology Review&lt;/em&gt;.&lt;/p&gt;  &lt;p&gt;Stardust insists that it won’t move forward with any geoengineering until and unless it’s commissioned to do so by governments and there are rules and bodies in place to govern use of the technology.&lt;/p&gt; 

 &lt;p&gt;But there’s no telling how financial pressure might change that, down the road. And we’re already seeing some of the challenges faced by a private company in this space: the need to keep trade secrets.&lt;/p&gt;  &lt;p&gt;Stardust is currently not sharing information about the particles it intends to release into the sky, though it says it plans to do so once it secures a patent, which could happen as soon as next year. The company argues that its proprietary particles will be safe, cheap to manufacture, and easier to track than the already abundant sulfur dioxide. But at this point, there’s no way for external experts to evaluate those claims.&lt;/p&gt;  &lt;p&gt;As Keith and Visioni put it: “Research won’t be useful unless it’s trusted, and trust depends on transparency.”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark, &lt;/em&gt;MIT Technology Review&lt;em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/12/11/1129239/solar-geoengineering-startups-are-getting-serious/</guid><pubDate>Thu, 11 Dec 2025 11:00:00 +0000</pubDate></item><item><title>Port raises $100M at $800M valuation to take on Spotify’s Backstage (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/11/port-raises-100m-at-800m-valuation-to-take-on-spotifys-backstage/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/12/Port-founders-e1764962616421.jpg?resize=1200,579" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Spotify may be synonymous with music streaming, but it’s also got a wildly popular developer-tool side hustle called Backstage.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Backstage is an open source project that helps companies build their own internal developer portals: a catalog of their developer tools along with quick visualizations of the work the tools have done, and other metrics. But like many open source projects, Backstage is a build-it-yourself option.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Israeli startup Port has been gaining big-name customers like GitHub, British Telecom, and LG with a proprietary Backstage competitor: a dev tool portal that’s also now been geared to manage AI agents.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Thursday, Port, founded in 2022, said it raised a fresh $100 million Series C round led by General Atlantic, with participation from Accel, Bessemer Venture Partners, and Team8. The round values Port at $800 million and brings its total funding to date to $158 million. This Series C follows the company’s $35 million Series B led by Accel and Bessemer, announced in May.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of all the industries that LLM-based tech has infiltrated, coding is where it has the deepest roots. So, not surprisingly, developers are also on the cutting edge of building and adopting agents that can automate entire repeated processes — work far beyond asking AI to write some code.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the problem here, according to Port co-founder and CEO Zohar Einy, it’s the Wild West right now for such dev tool agents at companies: finding them, sharing them, ensuring their work follows company standards, and so on.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Developers “want to take AI beyond just coding. They want it to resolve incidents, resolve security issues. They want it to take care of the release management,” Einy told TechCrunch.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;But if agents are connected to all kinds of different tools and data sources, if the data is scattered among them, if they have no way to collaborate, and have no corporate standards and guardrails, “it creates chaos,” his product pitch goes.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Port therefore offers more than just a catalog of dev and agent tools (although it does offer those). It supplies a layer of orchestration&amp;nbsp;with features that measure agent performance and&amp;nbsp;add a human in the loop, as desired, to approval processes. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A feature called “context lake” defines the&amp;nbsp;data sources, context memory, and guardrails for agents. “It’s where you manage what agents ‘need to know’ to do their job safely and correctly,” Einy explained.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In addition to using Port&amp;nbsp;to catalog agents devs have already created using other tools, they can use Port to create new agents. Plus, Port also offers a few of its own ready-made agents, which can do things like resolving help desk tickets and dealing with provisioning.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Einy describes his product as handling the other 90% of what software programmers do that isn’t writing code. “It gives the engineers a user interface to control the agent, to iterate with the agent, to approve what it does that is not coding, that is all the 90%.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With its giant new war chest of cash, big name customers and tier-one VCs, Port looks like an agentic management startup to watch. But to say it faces competition is an understatement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The entire category of agentic management and orchestration is flooded with hopefuls, from Big Tech companies to startups, and they’re all coming at the various new problems in the space from different angles. A few of these include&amp;nbsp;LangChain, UiPath, Cortex, and more.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/12/Port-founders-e1764962616421.jpg?resize=1200,579" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Spotify may be synonymous with music streaming, but it’s also got a wildly popular developer-tool side hustle called Backstage.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Backstage is an open source project that helps companies build their own internal developer portals: a catalog of their developer tools along with quick visualizations of the work the tools have done, and other metrics. But like many open source projects, Backstage is a build-it-yourself option.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Israeli startup Port has been gaining big-name customers like GitHub, British Telecom, and LG with a proprietary Backstage competitor: a dev tool portal that’s also now been geared to manage AI agents.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Thursday, Port, founded in 2022, said it raised a fresh $100 million Series C round led by General Atlantic, with participation from Accel, Bessemer Venture Partners, and Team8. The round values Port at $800 million and brings its total funding to date to $158 million. This Series C follows the company’s $35 million Series B led by Accel and Bessemer, announced in May.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of all the industries that LLM-based tech has infiltrated, coding is where it has the deepest roots. So, not surprisingly, developers are also on the cutting edge of building and adopting agents that can automate entire repeated processes — work far beyond asking AI to write some code.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the problem here, according to Port co-founder and CEO Zohar Einy, it’s the Wild West right now for such dev tool agents at companies: finding them, sharing them, ensuring their work follows company standards, and so on.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Developers “want to take AI beyond just coding. They want it to resolve incidents, resolve security issues. They want it to take care of the release management,” Einy told TechCrunch.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;But if agents are connected to all kinds of different tools and data sources, if the data is scattered among them, if they have no way to collaborate, and have no corporate standards and guardrails, “it creates chaos,” his product pitch goes.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Port therefore offers more than just a catalog of dev and agent tools (although it does offer those). It supplies a layer of orchestration&amp;nbsp;with features that measure agent performance and&amp;nbsp;add a human in the loop, as desired, to approval processes. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A feature called “context lake” defines the&amp;nbsp;data sources, context memory, and guardrails for agents. “It’s where you manage what agents ‘need to know’ to do their job safely and correctly,” Einy explained.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In addition to using Port&amp;nbsp;to catalog agents devs have already created using other tools, they can use Port to create new agents. Plus, Port also offers a few of its own ready-made agents, which can do things like resolving help desk tickets and dealing with provisioning.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Einy describes his product as handling the other 90% of what software programmers do that isn’t writing code. “It gives the engineers a user interface to control the agent, to iterate with the agent, to approve what it does that is not coding, that is all the 90%.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With its giant new war chest of cash, big name customers and tier-one VCs, Port looks like an agentic management startup to watch. But to say it faces competition is an understatement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The entire category of agentic management and orchestration is flooded with hopefuls, from Big Tech companies to startups, and they’re all coming at the various new problems in the space from different angles. A few of these include&amp;nbsp;LangChain, UiPath, Cortex, and more.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/11/port-raises-100m-at-800m-valuation-to-take-on-spotifys-backstage/</guid><pubDate>Thu, 11 Dec 2025 11:00:00 +0000</pubDate></item><item><title>[NEW] Interest in Spoor’s bird-monitoring AI software is soaring (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/11/interest-in-spoors-bird-monitoring-ai-software-is-soaring/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Spoor launched in 2021 with the goal of using computer vision to help reduce the impact of wind turbines on local bird populations. Now the startup has proven its technology works and is seeing demand from wind farms and beyond.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Oslo, Norway-based Spoor has built software that uses computer vision to track and identify bird populations and migration patterns. The software can detect birds within a 2.5-kilometer radius (about 1.5 miles) and can work with any off-the-shelf high-resolution camera.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Wind farm operators can use this information to better plan where wind farms should be located and to help them better navigate migration patterns. For example, a wind farm could slow down its turbines, or even stop them entirely, during heavy periods of local migration.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ask Helseth (pictured above left), the co-founder and CEO of Spoor, told TechCrunch last year that he got interested in this space after learning that wind farms lacked effective tracking methods, despite many countries having strict rules around where wind farms can be built and how they can operate due to local bird populations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The expectations from the regulators are growing but the industry doesn’t have a great tool,” Helseth said at the time. “A lot of people [go out] in the field with binoculars and trained dogs to find out how many birds are colliding with the turbines.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Helseth told TechCrunch last week that since then, the company has proven the need for this technology and worked to make it better.&lt;/p&gt;

&lt;figure class="wp-block-image alignleft size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3074781" height="432" src="https://techcrunch.com/wp-content/uploads/2025/12/Spoor-photo-1.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Spoor&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;At the time of its seed raise in 2024, Spoor was able to track birds in a 1-kilometer range, which has since doubled. As the company has collected more data to feed into its AI model, it has been able to improve its bird identification accuracy to about 96%.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“Identifying the species of the bird for some of the clients, you add another layer,” Helseth said. “Is it a bird or not a bird? We have an in-house ornithologist to help train the model to train the new types of birds or a new type of species. Having deployment in other countries [means] having rare species in the database.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Spoor now works across three continents and with more than 20 of the world’s largest energy companies. It has also started to see interest from other industries such as airports and aquaculture farms. Spoor has a partnership with Rio Tinto, a London-based mining giant, to track bats.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has also received interest in using its tech to track other objects of similar size — but Helseth said they aren’t thinking of pivoting into those areas quite yet.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Drones are of course a plastic bird in our mind,” Helseth joked. “They move in a different way and have a different shape and size. Currently we are discarding that data but we are getting interest in it.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Spoor recently raised an €8 million ($9.3 million) Series A round led by SET Ventures with participation from Ørsted Ventures and Superorganism in addition to strategic investors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Helseth predicts that interest in this type of technology will only grow as regulators continue to crack down on wind farms. For example, French regulators shut down a wind farm in April due to its impact on the local bird population and imposed hundreds of millions of fines.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our mission is to enable industry and nature to coexist,” Helseth said. “We have started on that journey, but we are still a small startup with a lot to prove. In the coming years, we want to really cement our position in the wind industry and become a global leader to tackle these challenges. At the same time, we want to build some proof points that this technology has value beyond that main category.”&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Spoor launched in 2021 with the goal of using computer vision to help reduce the impact of wind turbines on local bird populations. Now the startup has proven its technology works and is seeing demand from wind farms and beyond.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Oslo, Norway-based Spoor has built software that uses computer vision to track and identify bird populations and migration patterns. The software can detect birds within a 2.5-kilometer radius (about 1.5 miles) and can work with any off-the-shelf high-resolution camera.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Wind farm operators can use this information to better plan where wind farms should be located and to help them better navigate migration patterns. For example, a wind farm could slow down its turbines, or even stop them entirely, during heavy periods of local migration.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ask Helseth (pictured above left), the co-founder and CEO of Spoor, told TechCrunch last year that he got interested in this space after learning that wind farms lacked effective tracking methods, despite many countries having strict rules around where wind farms can be built and how they can operate due to local bird populations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The expectations from the regulators are growing but the industry doesn’t have a great tool,” Helseth said at the time. “A lot of people [go out] in the field with binoculars and trained dogs to find out how many birds are colliding with the turbines.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Helseth told TechCrunch last week that since then, the company has proven the need for this technology and worked to make it better.&lt;/p&gt;

&lt;figure class="wp-block-image alignleft size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3074781" height="432" src="https://techcrunch.com/wp-content/uploads/2025/12/Spoor-photo-1.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Spoor&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;At the time of its seed raise in 2024, Spoor was able to track birds in a 1-kilometer range, which has since doubled. As the company has collected more data to feed into its AI model, it has been able to improve its bird identification accuracy to about 96%.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“Identifying the species of the bird for some of the clients, you add another layer,” Helseth said. “Is it a bird or not a bird? We have an in-house ornithologist to help train the model to train the new types of birds or a new type of species. Having deployment in other countries [means] having rare species in the database.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Spoor now works across three continents and with more than 20 of the world’s largest energy companies. It has also started to see interest from other industries such as airports and aquaculture farms. Spoor has a partnership with Rio Tinto, a London-based mining giant, to track bats.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has also received interest in using its tech to track other objects of similar size — but Helseth said they aren’t thinking of pivoting into those areas quite yet.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Drones are of course a plastic bird in our mind,” Helseth joked. “They move in a different way and have a different shape and size. Currently we are discarding that data but we are getting interest in it.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Spoor recently raised an €8 million ($9.3 million) Series A round led by SET Ventures with participation from Ørsted Ventures and Superorganism in addition to strategic investors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Helseth predicts that interest in this type of technology will only grow as regulators continue to crack down on wind farms. For example, French regulators shut down a wind farm in April due to its impact on the local bird population and imposed hundreds of millions of fines.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our mission is to enable industry and nature to coexist,” Helseth said. “We have started on that journey, but we are still a small startup with a lot to prove. In the coming years, we want to really cement our position in the wind industry and become a global leader to tackle these challenges. At the same time, we want to build some proof points that this technology has value beyond that main category.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/11/interest-in-spoors-bird-monitoring-ai-software-is-soaring/</guid><pubDate>Thu, 11 Dec 2025 13:00:00 +0000</pubDate></item><item><title>[NEW] Opera wants you to pay $20 a month to use its AI-powered browser Neon (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/11/opera-wants-you-to-pay-20-a-month-to-use-its-ai-powered-browser-neon/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Following a couple of months’ testing, Norway-based browser company Opera has finally made its AI-powered browser, Neon, available to the public — though you’ll have to shell out $19.90 per month to use it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Opera first unveiled Neon earlier this year in May and launched it in early access to select users in October. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Similar to other AI-first browsers like Perplexity’s Comet, OpenAI’s Atlas, and The Browser Company’s Dia, Neon bakes in an AI chatbot into its interface, letting you ask it answers about pages, use it to create mini apps and videos, and get it to do tasks for you. The browser uses your browsing history as context, so you can do things like ask it to fetch details from a YouTube video you watched last week or the post that you read yesterday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;You can also build “Cards” for repeatable tasks using prompts, and the browser offers a deep research agent that can get you detailed information about any topic. The browser also has a new tab organizational feature called Tasks, which are contained workspaces of AI chats and tabs. This feature is more like Tab Groups combined with Arc Browser’s Spaces feature, which has its own context for AI.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to the AI features, the subscription gives users access to top models like Gemini 3 Pro, GPT-5.1, Veo 3.1, and Nano Banana Pro. Subscribers will also get access to Opera’s Discord community and direct access to its developers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Opera Neon is a product for people who like to be the first to the newest AI tech. It’s a rapidly evolving project with significant updates released every week. We’ve been shaping it with our Founders community for a while and are now excited to share the early access to it with a larger audience,”&amp;nbsp;Krystian Kolondra, EVP of browsers at Opera, said in a statement.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3075110" height="383" src="https://techcrunch.com/wp-content/uploads/2025/12/Cards.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Image Credits: Opera&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company noted that its other products, like Opera One, Opera GX, and Opera Air, also have free AI features, like a chat-based assistant.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, browser incumbents are taking a slower approach to adding AI features to their products. Earlier this week, Google detailed the security work it is doing to protect users against different attack surfaces that agentic features are prone to, and Brave said on Wednesday it is previewing its agentic features in a nightly build, and provides an isolated browsing profile for using AI features so users can keep their regular, non-AI usage separate.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Following a couple of months’ testing, Norway-based browser company Opera has finally made its AI-powered browser, Neon, available to the public — though you’ll have to shell out $19.90 per month to use it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Opera first unveiled Neon earlier this year in May and launched it in early access to select users in October. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Similar to other AI-first browsers like Perplexity’s Comet, OpenAI’s Atlas, and The Browser Company’s Dia, Neon bakes in an AI chatbot into its interface, letting you ask it answers about pages, use it to create mini apps and videos, and get it to do tasks for you. The browser uses your browsing history as context, so you can do things like ask it to fetch details from a YouTube video you watched last week or the post that you read yesterday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;You can also build “Cards” for repeatable tasks using prompts, and the browser offers a deep research agent that can get you detailed information about any topic. The browser also has a new tab organizational feature called Tasks, which are contained workspaces of AI chats and tabs. This feature is more like Tab Groups combined with Arc Browser’s Spaces feature, which has its own context for AI.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to the AI features, the subscription gives users access to top models like Gemini 3 Pro, GPT-5.1, Veo 3.1, and Nano Banana Pro. Subscribers will also get access to Opera’s Discord community and direct access to its developers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Opera Neon is a product for people who like to be the first to the newest AI tech. It’s a rapidly evolving project with significant updates released every week. We’ve been shaping it with our Founders community for a while and are now excited to share the early access to it with a larger audience,”&amp;nbsp;Krystian Kolondra, EVP of browsers at Opera, said in a statement.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3075110" height="383" src="https://techcrunch.com/wp-content/uploads/2025/12/Cards.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Image Credits: Opera&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company noted that its other products, like Opera One, Opera GX, and Opera Air, also have free AI features, like a chat-based assistant.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, browser incumbents are taking a slower approach to adding AI features to their products. Earlier this week, Google detailed the security work it is doing to protect users against different attack surfaces that agentic features are prone to, and Brave said on Wednesday it is previewing its agentic features in a nightly build, and provides an isolated browsing profile for using AI features so users can keep their regular, non-AI usage separate.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/11/opera-wants-you-to-pay-20-a-month-to-use-its-ai-powered-browser-neon/</guid><pubDate>Thu, 11 Dec 2025 13:00:00 +0000</pubDate></item><item><title>[NEW] The Download: solar geoengineering’s future, and OpenAI is being sued (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/12/11/1129288/the-download-solar-geoengineerings-future-and-openai-is-being-sued/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Solar geoengineering startups are getting serious&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Solar geoengineering aims to manipulate the climate by bouncing sunlight back into space. In theory, it could ease global warming. But as interest in the idea grows, so do concerns about potential consequences.&lt;/p&gt;&lt;p&gt;A startup called Stardust Solutions recently raised a $60 million funding round, the largest known to date for a geoengineering startup. My colleague James Temple has a new story out about the company, and how its emergence is making some researchers nervous.&lt;/p&gt;&lt;p&gt;So far, the field has been limited to debates, proposed academic research, and—sure—a few fringe actors to keep an eye on. Now things are getting more serious. So what does it mean for geoengineering, and for the climate? Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Casey Crownhart&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;This article is from The Spark, MIT Technology Review’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;If you’re interested in reading more about solar geoengineering, check out:&lt;/p&gt; 
 &lt;p&gt;+ Why the for-profit race into solar geoengineering is bad for science and public trust. Read the full story.&lt;/p&gt;&lt;p&gt;+ Why we need more research—including outdoor experiments—to make better-informed decisions about such climate interventions.&lt;/p&gt;&lt;p&gt;+ The hard lessons of Harvard’s failed geoengineering experiment, which was officially terminated last year. Read the full story.&lt;/p&gt;&lt;p&gt;+ How this London nonprofit became one of the biggest backers of geoengineering research.&lt;/p&gt;&lt;p&gt;+ The technology could alter the entire planet. These groups want every nation to have a say.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;strong&gt;1 OpenAI is being sued for wrongful death&lt;/strong&gt;&lt;br /&gt;By the estate of a woman killed by her son after he engaged in delusion-filled conversations with ChatGPT. (WSJ $)&lt;br /&gt;+ &lt;em&gt;The chatbot appeared to validate Stein-Erik Soelberg’s conspiratorial ideas. &lt;/em&gt;(WP $)&lt;br /&gt;+ &lt;em&gt;It’s the latest in a string of wrongful death legal actions filed against chatbot makers. &lt;/em&gt;(ABC News)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 ICE is tracking pregnant immigrants through specifically-developed smartwatches&lt;br /&gt;&lt;/strong&gt;They’re unable to take the devices off, even during labor. (The Guardian)&lt;br /&gt;+ &lt;em&gt;Pregnant and postpartum women say they’ve been detained in solitary confinement. &lt;/em&gt;(Slate $)&lt;br /&gt;+ &lt;em&gt;Another effort to track ICE raids has been taken offline. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 Meta’s new AI hires aren’t making friends with the rest of the company&lt;/strong&gt;&lt;br /&gt;Tensions are rife between the AGI team and other divisions. (NYT $)&lt;br /&gt;+ &lt;em&gt;Mark Zuckerberg is keen to make money off the company’s AI ambitions. &lt;/em&gt;(Bloomberg $)&lt;br /&gt;+ &lt;em&gt;Meanwhile, what’s life like for the remaining Scale AI team? &lt;/em&gt;(Insider $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 Google DeepMind is building its first materials science lab in the UK&lt;br /&gt;&lt;/strong&gt;It’ll focus on developing new materials to build superconductors and solar cells. (FT $)&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 The new space race is to build orbital data centers&lt;/strong&gt;&lt;br /&gt;And Blue Origin is winning, apparently. (WSJ $)&lt;br /&gt;+ &lt;em&gt;Plenty of companies are jostling for their slice of the pie. &lt;/em&gt;(The Verge)&lt;br /&gt;+ &lt;em&gt;Should we be moving data centers to space? &lt;/em&gt;(MIT Technology Review)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;6 Inside the quest to find out what causes Parkinson’s&lt;br /&gt;A growing body of work suggests it may not be purely genetic after all. (Wired $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Are you in TikTok’s cat niche?&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;If so, you’re likely to be in these other niches too. (WP $)&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;&lt;br /&gt;&lt;strong&gt;8 Why do our brains get tired? 🧠💤&lt;br /&gt;&lt;/strong&gt;Researchers are trying to get to the bottom of it.&amp;nbsp; (Nature $)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;9 Microsoft’s boss has built his own cricket app 🏏&lt;/strong&gt;&lt;br /&gt;Satya Nadella can’t get enough of the sound of leather on willow. (Bloomberg $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 How much vibe coding is too much vibe coding?&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;One journalist’s journey into the heart of darkness. (Rest of World)&lt;br /&gt;+ &lt;em&gt;What is vibe coding, exactly? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“I feel so much pain seeing his sad face…I hope for a New Year’s miracle.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—A child in Russia sends a message to the Kremlin-aligned Safe Internet League explaining the impact of the country’s decision to block access to the wildly popular gaming platform Roblox on their brother, the Washington Post reports.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&amp;nbsp;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; 
 &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1129291" src="https://wp.technologyreview.com/wp-content/uploads/2025/12/image_192fc5.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Why it’s so hard to stop tech-facilitated abuse&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;After Gioia had her first child with her then husband, he installed baby monitors throughout their home—to “watch what we were doing,” she says, while he went to work. She’d turn them off; he’d get angry. By the time their third child turned seven, Gioia and her husband had divorced, but he still found ways to monitor her behavior.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;One Christmas, he gave their youngest a smartwatch. Gioia showed it to a tech-savvy friend, who found that the watch had a tracking feature turned on. It could be turned off only by the watch’s owner—her ex.&lt;/p&gt; 
 &lt;p&gt;Gioia is far from alone. In fact, tech-facilitated abuse now occurs in most cases of intimate partner violence—and we’re doing shockingly little to prevent it. Read the full story.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Jessica Klein&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Solar geoengineering startups are getting serious&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Solar geoengineering aims to manipulate the climate by bouncing sunlight back into space. In theory, it could ease global warming. But as interest in the idea grows, so do concerns about potential consequences.&lt;/p&gt;&lt;p&gt;A startup called Stardust Solutions recently raised a $60 million funding round, the largest known to date for a geoengineering startup. My colleague James Temple has a new story out about the company, and how its emergence is making some researchers nervous.&lt;/p&gt;&lt;p&gt;So far, the field has been limited to debates, proposed academic research, and—sure—a few fringe actors to keep an eye on. Now things are getting more serious. So what does it mean for geoengineering, and for the climate? Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Casey Crownhart&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;This article is from The Spark, MIT Technology Review’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;If you’re interested in reading more about solar geoengineering, check out:&lt;/p&gt; 
 &lt;p&gt;+ Why the for-profit race into solar geoengineering is bad for science and public trust. Read the full story.&lt;/p&gt;&lt;p&gt;+ Why we need more research—including outdoor experiments—to make better-informed decisions about such climate interventions.&lt;/p&gt;&lt;p&gt;+ The hard lessons of Harvard’s failed geoengineering experiment, which was officially terminated last year. Read the full story.&lt;/p&gt;&lt;p&gt;+ How this London nonprofit became one of the biggest backers of geoengineering research.&lt;/p&gt;&lt;p&gt;+ The technology could alter the entire planet. These groups want every nation to have a say.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;strong&gt;1 OpenAI is being sued for wrongful death&lt;/strong&gt;&lt;br /&gt;By the estate of a woman killed by her son after he engaged in delusion-filled conversations with ChatGPT. (WSJ $)&lt;br /&gt;+ &lt;em&gt;The chatbot appeared to validate Stein-Erik Soelberg’s conspiratorial ideas. &lt;/em&gt;(WP $)&lt;br /&gt;+ &lt;em&gt;It’s the latest in a string of wrongful death legal actions filed against chatbot makers. &lt;/em&gt;(ABC News)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 ICE is tracking pregnant immigrants through specifically-developed smartwatches&lt;br /&gt;&lt;/strong&gt;They’re unable to take the devices off, even during labor. (The Guardian)&lt;br /&gt;+ &lt;em&gt;Pregnant and postpartum women say they’ve been detained in solitary confinement. &lt;/em&gt;(Slate $)&lt;br /&gt;+ &lt;em&gt;Another effort to track ICE raids has been taken offline. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 Meta’s new AI hires aren’t making friends with the rest of the company&lt;/strong&gt;&lt;br /&gt;Tensions are rife between the AGI team and other divisions. (NYT $)&lt;br /&gt;+ &lt;em&gt;Mark Zuckerberg is keen to make money off the company’s AI ambitions. &lt;/em&gt;(Bloomberg $)&lt;br /&gt;+ &lt;em&gt;Meanwhile, what’s life like for the remaining Scale AI team? &lt;/em&gt;(Insider $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 Google DeepMind is building its first materials science lab in the UK&lt;br /&gt;&lt;/strong&gt;It’ll focus on developing new materials to build superconductors and solar cells. (FT $)&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 The new space race is to build orbital data centers&lt;/strong&gt;&lt;br /&gt;And Blue Origin is winning, apparently. (WSJ $)&lt;br /&gt;+ &lt;em&gt;Plenty of companies are jostling for their slice of the pie. &lt;/em&gt;(The Verge)&lt;br /&gt;+ &lt;em&gt;Should we be moving data centers to space? &lt;/em&gt;(MIT Technology Review)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;6 Inside the quest to find out what causes Parkinson’s&lt;br /&gt;A growing body of work suggests it may not be purely genetic after all. (Wired $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Are you in TikTok’s cat niche?&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;If so, you’re likely to be in these other niches too. (WP $)&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;&lt;br /&gt;&lt;strong&gt;8 Why do our brains get tired? 🧠💤&lt;br /&gt;&lt;/strong&gt;Researchers are trying to get to the bottom of it.&amp;nbsp; (Nature $)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;9 Microsoft’s boss has built his own cricket app 🏏&lt;/strong&gt;&lt;br /&gt;Satya Nadella can’t get enough of the sound of leather on willow. (Bloomberg $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 How much vibe coding is too much vibe coding?&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;One journalist’s journey into the heart of darkness. (Rest of World)&lt;br /&gt;+ &lt;em&gt;What is vibe coding, exactly? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“I feel so much pain seeing his sad face…I hope for a New Year’s miracle.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—A child in Russia sends a message to the Kremlin-aligned Safe Internet League explaining the impact of the country’s decision to block access to the wildly popular gaming platform Roblox on their brother, the Washington Post reports.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&amp;nbsp;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; 
 &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1129291" src="https://wp.technologyreview.com/wp-content/uploads/2025/12/image_192fc5.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Why it’s so hard to stop tech-facilitated abuse&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;After Gioia had her first child with her then husband, he installed baby monitors throughout their home—to “watch what we were doing,” she says, while he went to work. She’d turn them off; he’d get angry. By the time their third child turned seven, Gioia and her husband had divorced, but he still found ways to monitor her behavior.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;One Christmas, he gave their youngest a smartwatch. Gioia showed it to a tech-savvy friend, who found that the watch had a tracking feature turned on. It could be turned off only by the watch’s owner—her ex.&lt;/p&gt; 
 &lt;p&gt;Gioia is far from alone. In fact, tech-facilitated abuse now occurs in most cases of intimate partner violence—and we’re doing shockingly little to prevent it. Read the full story.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Jessica Klein&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/12/11/1129288/the-download-solar-geoengineerings-future-and-openai-is-being-sued/</guid><pubDate>Thu, 11 Dec 2025 13:10:00 +0000</pubDate></item><item><title>[NEW] Marble enters the race to bring AI to tax work, armed with $9 million and a free research tool (AI | VentureBeat)</title><link>https://venturebeat.com/ai/marble-enters-the-race-to-bring-ai-to-tax-work-armed-with-usd9-million-and-a</link><description>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="http://marble.ai/"&gt;Marble&lt;/a&gt;, a startup building artificial intelligence agents for tax professionals, has raised $9 million in seed funding as the accounting industry grapples with a deepening labor shortage and mounting regulatory complexity.&lt;/p&gt;&lt;p&gt;The round, led by &lt;a href="https://www.susaventures.com/"&gt;Susa Ventures&lt;/a&gt; with participation from &lt;a href="https://mxv.vc/"&gt;MXV Capital&lt;/a&gt; and Konrad Capital, positions Marble to compete in a market where AI adoption has lagged significantly behind other knowledge industries like law and software development.&lt;/p&gt;&lt;p&gt;&amp;quot;When we looked at the economy and asked ourselves where AI is going to transform the way businesses operate, we focused on knowledge industries — specifically businesses with hourly fee-based service models,&amp;quot; said Bhavin Shah, Marble&amp;#x27;s chief executive officer, in an exclusive interview with VentureBeat. &amp;quot;Accounting generates $250 billion in fee-based billing in the US every year. There&amp;#x27;s a tremendous opportunity to increase efficiency and improve margins for accounting firms.&amp;quot;&lt;/p&gt;&lt;p&gt;The company has launched a &lt;a href="https://marble.ai/"&gt;free AI-powered tax research tool&lt;/a&gt; on its website that converts complex government tax data into accessible, citation-backed answers for practitioners. Marble plans to expand into AI agents that can analyze compliance scenarios and eventually automate portions of tax preparation workflows.&lt;/p&gt;&lt;p&gt;Marble&amp;#x27;s backers share Shah&amp;#x27;s conviction about the market. &amp;quot;Marble is rethinking the accounting system from the ground up. Accounting is one of the biggest — and most overlooked — markets in professional services,&amp;quot; Chad Byers, general partner at Susa Ventures, told VentureBeat. &amp;quot;We&amp;#x27;ve known Bhavin from his time as an executive in the Susa portfolio, and have seen firsthand how sharp and execution-driven he is. He and Geordie bring the perfect mix of operational depth and product instinct to a space long overdue for change — and they see the same massive opportunity we do.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The accounting industry lost 340,000 workers in four years — and replacements aren&amp;#x27;t coming&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Marble enters a market shaped by structural forces that have fundamentally altered the economics of professional accounting.&lt;/p&gt;&lt;p&gt;The accounting profession has &lt;a href="https://www.bls.gov/ooh/office-and-administrative-support/bookkeeping-accounting-and-auditing-clerks.htm"&gt;shed roughly 340,000 workers since 2019&lt;/a&gt;, a 17% decline that has left firms scrambling to meet client demands. First-time candidates for the Certified Public Accountant exam dropped 33% between 2016 and 2021, according to &lt;a href="https://www.cpajournal.com/2025/08/15/the-accounting-profession-is-in-crisis-3/"&gt;AICPA data&lt;/a&gt;, and 2022 saw the lowest number of exam takers in 17 years.&lt;/p&gt;&lt;p&gt;The exodus comes as baby boomers exit en masse. The American Institute of CPAs estimates that approximately &lt;a href="https://www.forbes.com/councils/forbesfinancecouncil/2025/05/12/disruption-in-accounting-the-cpa-shortage-meets-the-rise-of-ai/"&gt;75% of all licensed CPAs&lt;/a&gt; reached retirement age by 2019, creating a demographic cliff that the profession has struggled to address.&lt;/p&gt;&lt;p&gt;“Fewer CPAs are getting certified year over year,&amp;quot; Shah said. &amp;quot;The industry is compressing at the same time that there&amp;#x27;s more work to be done and the tax code is getting more complicated.&amp;quot;&lt;/p&gt;&lt;p&gt;The &lt;a href="https://www.accountingpipeline.org/"&gt;National Pipeline Advisory Group&lt;/a&gt;, a multi-stakeholder body formed by the AICPA in July 2023, released a report identifying the &lt;a href="https://sc.cpa/2025/01/10/national-pipeline-advisory-group-npag-releases-official-report/"&gt;150-hour education requirement&lt;/a&gt; for CPA licensure as a significant barrier to entry. A separate &lt;a href="https://www.thecaq.org/increasing-diversity-in-the-accounting-profession-pipeline-2022"&gt;survey&lt;/a&gt; by the Center for Audit Quality found that 57% of business majors who chose not to pursue accounting cited the additional credit hours as a deterrent.&lt;/p&gt;&lt;p&gt;Recent legislative changes reflect the urgency. Ohio now offers alternatives to the 150-hour requirement, signaling that states are willing to experiment with pathways that could reverse enrollment declines.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why AI transformed law and software development but left accounting behind&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Despite the profession&amp;#x27;s challenges, AI adoption in accounting has moved more slowly than in adjacent knowledge industries. &lt;a href="https://www.harvey.ai/"&gt;Harvey&lt;/a&gt; and &lt;a href="https://legora.com/"&gt;Legora&lt;/a&gt; have raised hundreds of millions to bring AI to legal work. &lt;a href="https://cursor.com/agents"&gt;Cursor&lt;/a&gt; and other coding assistants have transformed software development. Accounting, by contrast, remains largely dependent on legacy research platforms and manual processes.&lt;/p&gt;&lt;p&gt;Geordie Konrad, Marble&amp;#x27;s executive chairman and a co-founder of restaurant software company TouchBistro, attributes the gap to how people conceptualize AI&amp;#x27;s capabilities.&lt;/p&gt;&lt;p&gt;“It was obvious to many people that LLMs could do meaningful work by manipulating code for software developers and manipulating words for lawyers. In the accounting industry, LLMs are going to be used as reasoning agents,&amp;quot; Konrad said. &amp;quot; That requires a bit more of a two-step analysis to see why it&amp;#x27;s a big opportunity.&amp;quot;&lt;/p&gt;&lt;p&gt;The technical challenge is substantial. Tax regulations form one of the most complex, interconnected information systems that humans have created — tens of thousands of interlocking rules, guidance documents, and jurisdiction-specific requirements that frequently overlap or conflict.&lt;/p&gt;&lt;p&gt;&amp;quot;If you want to put AI through its paces and ask how far it&amp;#x27;s come in replicating cognitive functions, this is an unbelievable playground to work in,&amp;quot; Konrad said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;A dramatic shift: AI adoption among tax and finance teams doubles in one year&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Recent data suggests the accounting profession&amp;#x27;s stance toward AI is shifting rapidly.&lt;/p&gt;&lt;p&gt;A 2025 survey from &lt;a href="https://www.avalara.com/us/en/learn/ai-reinventing-finance-and-tax-state-of-finance-report.html"&gt;Hanover Research and Avalara&lt;/a&gt; found that 84% of finance and tax teams now use AI heavily in their operations, up from 47% in 2024. The 2025 Generative AI in Professional Services Report from &lt;a href="https://www.cpapracticeadvisor.com/2025/04/15/79-of-tax-and-accounting-firms-expect-significant-genai-integration-by-2027/159172/"&gt;Thomson Reuters Institute&lt;/a&gt; found that 21% of tax firms already use generative AI technology, with 53% either planning to adopt it or actively considering it.&lt;/p&gt;&lt;p&gt;Large accounting firms have invested heavily in AI infrastructure. &lt;a href="https://www.deloitte.com/us/en/what-we-do/capabilities/applied-artificial-intelligence/articles/agentic-ai-enterprise-2028.html?id=us:2ps:3gl:aisgm26:awa:CONS:nonem:K0218784:111725:kwd-2025710122928:188372336109:784136672833::Brand_AI-SGO_BU_K0218784_Google:Brand_AI-SGO-Advisory:deloitte-generative-ai:&amp;amp;gclsrc=aw.ds&amp;amp;gad_source=1&amp;amp;gad_campaignid=23269751515&amp;amp;gbraid=0AAAAADenGPA6ZvC8cLRrT031O1up6RiOj&amp;amp;gclid=Cj0KCQiAi9rJBhCYARIsALyPDtudMaZrpHm8026n16yuyeM0sYKCTm24yHqR4Dyg_s6yZBgPnxfjDOwaAvN5EALw_wcB"&gt;Deloitte&lt;/a&gt; has developed generative AI capabilities within its audit platform. &lt;a href="https://www.bdo.com/insights/press-releases/bdo-usa-unveils-comprehensive-artificial-intelligence-strategy-fusing-practical-innovation"&gt;BDO&lt;/a&gt; announced a $1B investment in AI over the next five years. &lt;a href="https://www.ey.com/en_gl/newsroom/2025/11/ey-unveils-suite-of-powerful-ai-capabilities-to-accelerate-tax-transformation-and-deliver-strategic-value"&gt;EY&lt;/a&gt; launched an AI platform combining technology with strategy, transactions, and tax services. &lt;a href="https://www.pwc.com/us/en/tech-effect/ai-analytics/ai-predictions.html"&gt;PwC&lt;/a&gt; estimates a complete AI-driven audit solution will launch by 2026.&lt;/p&gt;&lt;p&gt;But adoption at smaller firms remains uneven. According to &lt;a href="http://thomsonreuters.com/en-us/posts/technology/genai-professional-services-report-2025/"&gt;Thomson Reuters research&lt;/a&gt;, 52% of tax firm respondents who use generative AI rely on open-source tools like ChatGPT rather than industry-specific solutions—a pattern that could shift as purpose-built alternatives emerge.&lt;/p&gt;&lt;p&gt;Marble&amp;#x27;s founders believe the hesitance stems not from technophobia but from a lack of compelling options.&lt;/p&gt;&lt;p&gt;“Firms want to embrace AI,&amp;quot; Shah said. “They just haven&amp;#x27;t seen great software and tooling made for them. That&amp;#x27;s part of the opportunity — to work with them and build something they&amp;#x27;re excited to use on a day-to-day basis.”&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Can artificial intelligence rescue accounting&amp;#x27;s billable-hour business model?&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;AI&amp;#x27;s arrival in accounting raises questions about the profession&amp;#x27;s billing structure.&lt;/p&gt;&lt;p&gt;Accounting firms have traditionally generated profits by billing clients for staff time, often at multiples of employee compensation costs. Junior associates performing compliance work represent a significant revenue stream. If AI can automate that work, does it undercut the business model firms depend on?&lt;/p&gt;&lt;p&gt;Marble&amp;#x27;s founders argue the opposite. The chronic staffing shortage has already constrained firms&amp;#x27; ability to capture available revenue. Advisory and consulting work — higher-margin services that clients actively want — goes undone because practitioners are buried in compliance tasks.&lt;/p&gt;&lt;p&gt;&amp;quot;Everyone in the industry agrees that an enormous amount of advisory work simply isn&amp;#x27;t getting done,&amp;quot; Konrad said. &amp;quot;Customers want it. Firms want to do it because it&amp;#x27;s high-margin, great work. But nobody gets to it.&amp;quot;&lt;/p&gt;&lt;p&gt;The &lt;a href="https://www.aicpa-cima.com/news/article/cpa-firms-report-steady-growth-in-revenue-and-profit-aicpa-research-finds"&gt;2025 AICPA National Management of an Accounting Practice Survey&lt;/a&gt; supports this view. Firms reported a median 6.7% increase in net client fees over the prior year, with growth in audit, assurance, tax services, and client accounting advisory. Net remaining per partner climbed 11.9% from fiscal year 2022 to fiscal year 2024, reaching $252,663.&lt;/p&gt;&lt;p&gt;The survey also found growing interest in AI adoption, though most firms have yet to allocate formal budgets or develop structured training programs. Continued adoption, the survey suggested, could help expand services and fuel continued growth.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Accountants won&amp;#x27;t adopt AI tools they can&amp;#x27;t trust with sensitive client data&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;For AI to succeed in accounting, it must clear a high bar for data security. Accounting firms handle some of the most sensitive financial information in the economy. Practitioners cannot adopt tools that create compliance or confidentiality risks.&lt;/p&gt;&lt;p&gt;According to &lt;a href="https://www.avalara.com/us/en/learn/ai-reinventing-finance-and-tax-state-of-finance-report.html"&gt;Avalara&amp;#x27;s survey&lt;/a&gt;, 63% of respondents cited data security and privacy concerns as the top barriers to automating tax and finance functions. The concern persists throughout the adoption lifecycle, from initial selection through implementation and ongoing use.&lt;/p&gt;&lt;p&gt;&lt;a href="https://marble.ai/"&gt;Marble&lt;/a&gt; has made security a foundational priority. The company obtained software compliance certification before releasing any product and maintains that data privacy is embedded in its operational culture from day one.&lt;/p&gt;&lt;p&gt;&amp;quot;Security is at the core of what we are building,&amp;quot; Shah said. &amp;quot;Every employee knows that security is critical. It&amp;#x27;s a part of our onboarding and something that we consider in everything we do.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;From number crunchers to strategic advisors: How AI could reshape accounting careers&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Marble&amp;#x27;s founders reject the narrative that AI will only take away from accounting jobs. They propose instead that AI will result in accounting jobs becoming more strategic and less characterized by repetitive execution. &lt;/p&gt;&lt;p&gt;They draw an analogy to architecture, where computer-aided design replaced laborious manual drafting. Architects did not disappear — they gained tools that let them spend more time on creative design and less on mechanical reproduction.&lt;/p&gt;&lt;p&gt;&amp;quot;If you take some of the hours-intensive, less creative work out of what being a junior or intermediate accountant is, and you replace it with a role where you&amp;#x27;re a professional who is being creative, synthesizing ideas, and able to delegate a lot of tasks to AI assistant platform solutions, you end up with an industry that&amp;#x27;s just a lot more fun to operate in,&amp;quot; Konrad said.&lt;/p&gt;&lt;p&gt;The shift could also improve client outcomes. When accountants spend less time on compliance, they can invest more in the strategic advisory work that clients value.&lt;/p&gt;&lt;p&gt;&amp;quot;Not only does the work become more enjoyable because of what you can focus on, but that&amp;#x27;s also what your clients are going to value more from you,&amp;quot; Shah said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The competitive landscape: Marble faces well-funded rivals and legacy giants&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;a href="http://marble.ai/"&gt;Marble&lt;/a&gt; enters a market with formidable incumbents and well-funded competitors. &lt;a href="https://venturebeat.com/ai/how-ai-tax-startup-blue-j-torched-its-entire-business-model-for-chatgpt-and"&gt;BlueJ&lt;/a&gt;, a global tax research platform, has raised over $100 million. &lt;a href="https://www.thomsonreuters.com/en"&gt;Thomson Reuters&lt;/a&gt;, &lt;a href="https://www.cch.com/"&gt;CCH&lt;/a&gt;, and &lt;a href="https://www.intuit.com/"&gt;Intuit&lt;/a&gt; have deep customer relationships built over decades.&lt;/p&gt;&lt;p&gt;But the founders see opportunity in the transition moment.&lt;/p&gt;&lt;p&gt;&amp;quot;AI has changed what’s possible in the industry,&amp;quot; Shah said. &amp;quot;We are going to work with and integrate with some technology players in the industry and also compete with other players with new products powered by AI. In some cases we are going to forget about the existing technology solution for doing things and go back to the task itself. We have totally new technological capabilities — how would you design something from a blank canvas that works with humans to accomplish that task?&amp;quot;&amp;quot;&lt;/p&gt;&lt;p&gt;The decision to offer a free research tool reflects Marble&amp;#x27;s go-to-market philosophy. By giving practitioners access without a paywall, the company aims to build trust and demonstrate capability.&lt;/p&gt;&lt;p&gt;&amp;quot;It allows us to expose a really compelling product that is purpose-built to those that are worried about how to use AI or question how to adopt it.  Now they don’t have to think about purchasing something that is cost-prohibitive when they don&amp;#x27;t know how to integrate it into their workflow,&amp;quot; Shah said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The $250 billion question: Can a startup transform how America does its taxes?&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Marble&amp;#x27;s roadmap extends beyond research. The company plans to develop AI agents capable of analyzing complex tax scenarios, identifying compliance issues, and eventually automating significant portions of compliance workflows — all while keeping practitioners in control.&lt;/p&gt;&lt;p&gt;The founders frame success not in terms of disruption but rebalancing. Today&amp;#x27;s tax work skews heavily toward compliance, leaving the strategic advisory services that clients crave — and that generate higher margins—perpetually undone. Marble&amp;#x27;s bet is that AI can flip that equation.&lt;/p&gt;&lt;p&gt;&amp;quot;Everyone wants it to look more like compliance is done simpler, and you spend time talking about strategy and planning,&amp;quot; Konrad said. &amp;quot;How do we change that blend of compliance versus strategy and planning to strategy and planning first—with compliance as something that has been made dramatically simpler?&amp;quot;&lt;/p&gt;&lt;p&gt;Whether Marble can execute on that vision remains to be seen. The company faces entrenched competitors, a profession that has historically resisted technological change, and the inherent unpredictability of building AI systems for high-stakes financial work.&lt;/p&gt;&lt;p&gt;But the founders are betting that the industry&amp;#x27;s demographic shift will accelerate adoption in ways that previous technology waves could not. With fewer accountants entering the profession each year and client demands only growing, firms may have an increased appetite to embrace tools that let their remaining staff do more.&lt;/p&gt;&lt;p&gt;&amp;quot;AI is going to change every industry — in some cases in ways that will help business models and in some cases in ways that will challenge them. We believe AI is ultimately going to make accounting firms’ businesses better and more profitable and at the same time end clients will get better services at better prices,&amp;quot; Shah said.&lt;/p&gt;&lt;p&gt;The accounting profession, it seems, is about to find out which side of that equation it lands on.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="http://marble.ai/"&gt;Marble&lt;/a&gt;, a startup building artificial intelligence agents for tax professionals, has raised $9 million in seed funding as the accounting industry grapples with a deepening labor shortage and mounting regulatory complexity.&lt;/p&gt;&lt;p&gt;The round, led by &lt;a href="https://www.susaventures.com/"&gt;Susa Ventures&lt;/a&gt; with participation from &lt;a href="https://mxv.vc/"&gt;MXV Capital&lt;/a&gt; and Konrad Capital, positions Marble to compete in a market where AI adoption has lagged significantly behind other knowledge industries like law and software development.&lt;/p&gt;&lt;p&gt;&amp;quot;When we looked at the economy and asked ourselves where AI is going to transform the way businesses operate, we focused on knowledge industries — specifically businesses with hourly fee-based service models,&amp;quot; said Bhavin Shah, Marble&amp;#x27;s chief executive officer, in an exclusive interview with VentureBeat. &amp;quot;Accounting generates $250 billion in fee-based billing in the US every year. There&amp;#x27;s a tremendous opportunity to increase efficiency and improve margins for accounting firms.&amp;quot;&lt;/p&gt;&lt;p&gt;The company has launched a &lt;a href="https://marble.ai/"&gt;free AI-powered tax research tool&lt;/a&gt; on its website that converts complex government tax data into accessible, citation-backed answers for practitioners. Marble plans to expand into AI agents that can analyze compliance scenarios and eventually automate portions of tax preparation workflows.&lt;/p&gt;&lt;p&gt;Marble&amp;#x27;s backers share Shah&amp;#x27;s conviction about the market. &amp;quot;Marble is rethinking the accounting system from the ground up. Accounting is one of the biggest — and most overlooked — markets in professional services,&amp;quot; Chad Byers, general partner at Susa Ventures, told VentureBeat. &amp;quot;We&amp;#x27;ve known Bhavin from his time as an executive in the Susa portfolio, and have seen firsthand how sharp and execution-driven he is. He and Geordie bring the perfect mix of operational depth and product instinct to a space long overdue for change — and they see the same massive opportunity we do.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The accounting industry lost 340,000 workers in four years — and replacements aren&amp;#x27;t coming&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Marble enters a market shaped by structural forces that have fundamentally altered the economics of professional accounting.&lt;/p&gt;&lt;p&gt;The accounting profession has &lt;a href="https://www.bls.gov/ooh/office-and-administrative-support/bookkeeping-accounting-and-auditing-clerks.htm"&gt;shed roughly 340,000 workers since 2019&lt;/a&gt;, a 17% decline that has left firms scrambling to meet client demands. First-time candidates for the Certified Public Accountant exam dropped 33% between 2016 and 2021, according to &lt;a href="https://www.cpajournal.com/2025/08/15/the-accounting-profession-is-in-crisis-3/"&gt;AICPA data&lt;/a&gt;, and 2022 saw the lowest number of exam takers in 17 years.&lt;/p&gt;&lt;p&gt;The exodus comes as baby boomers exit en masse. The American Institute of CPAs estimates that approximately &lt;a href="https://www.forbes.com/councils/forbesfinancecouncil/2025/05/12/disruption-in-accounting-the-cpa-shortage-meets-the-rise-of-ai/"&gt;75% of all licensed CPAs&lt;/a&gt; reached retirement age by 2019, creating a demographic cliff that the profession has struggled to address.&lt;/p&gt;&lt;p&gt;“Fewer CPAs are getting certified year over year,&amp;quot; Shah said. &amp;quot;The industry is compressing at the same time that there&amp;#x27;s more work to be done and the tax code is getting more complicated.&amp;quot;&lt;/p&gt;&lt;p&gt;The &lt;a href="https://www.accountingpipeline.org/"&gt;National Pipeline Advisory Group&lt;/a&gt;, a multi-stakeholder body formed by the AICPA in July 2023, released a report identifying the &lt;a href="https://sc.cpa/2025/01/10/national-pipeline-advisory-group-npag-releases-official-report/"&gt;150-hour education requirement&lt;/a&gt; for CPA licensure as a significant barrier to entry. A separate &lt;a href="https://www.thecaq.org/increasing-diversity-in-the-accounting-profession-pipeline-2022"&gt;survey&lt;/a&gt; by the Center for Audit Quality found that 57% of business majors who chose not to pursue accounting cited the additional credit hours as a deterrent.&lt;/p&gt;&lt;p&gt;Recent legislative changes reflect the urgency. Ohio now offers alternatives to the 150-hour requirement, signaling that states are willing to experiment with pathways that could reverse enrollment declines.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why AI transformed law and software development but left accounting behind&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Despite the profession&amp;#x27;s challenges, AI adoption in accounting has moved more slowly than in adjacent knowledge industries. &lt;a href="https://www.harvey.ai/"&gt;Harvey&lt;/a&gt; and &lt;a href="https://legora.com/"&gt;Legora&lt;/a&gt; have raised hundreds of millions to bring AI to legal work. &lt;a href="https://cursor.com/agents"&gt;Cursor&lt;/a&gt; and other coding assistants have transformed software development. Accounting, by contrast, remains largely dependent on legacy research platforms and manual processes.&lt;/p&gt;&lt;p&gt;Geordie Konrad, Marble&amp;#x27;s executive chairman and a co-founder of restaurant software company TouchBistro, attributes the gap to how people conceptualize AI&amp;#x27;s capabilities.&lt;/p&gt;&lt;p&gt;“It was obvious to many people that LLMs could do meaningful work by manipulating code for software developers and manipulating words for lawyers. In the accounting industry, LLMs are going to be used as reasoning agents,&amp;quot; Konrad said. &amp;quot; That requires a bit more of a two-step analysis to see why it&amp;#x27;s a big opportunity.&amp;quot;&lt;/p&gt;&lt;p&gt;The technical challenge is substantial. Tax regulations form one of the most complex, interconnected information systems that humans have created — tens of thousands of interlocking rules, guidance documents, and jurisdiction-specific requirements that frequently overlap or conflict.&lt;/p&gt;&lt;p&gt;&amp;quot;If you want to put AI through its paces and ask how far it&amp;#x27;s come in replicating cognitive functions, this is an unbelievable playground to work in,&amp;quot; Konrad said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;A dramatic shift: AI adoption among tax and finance teams doubles in one year&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Recent data suggests the accounting profession&amp;#x27;s stance toward AI is shifting rapidly.&lt;/p&gt;&lt;p&gt;A 2025 survey from &lt;a href="https://www.avalara.com/us/en/learn/ai-reinventing-finance-and-tax-state-of-finance-report.html"&gt;Hanover Research and Avalara&lt;/a&gt; found that 84% of finance and tax teams now use AI heavily in their operations, up from 47% in 2024. The 2025 Generative AI in Professional Services Report from &lt;a href="https://www.cpapracticeadvisor.com/2025/04/15/79-of-tax-and-accounting-firms-expect-significant-genai-integration-by-2027/159172/"&gt;Thomson Reuters Institute&lt;/a&gt; found that 21% of tax firms already use generative AI technology, with 53% either planning to adopt it or actively considering it.&lt;/p&gt;&lt;p&gt;Large accounting firms have invested heavily in AI infrastructure. &lt;a href="https://www.deloitte.com/us/en/what-we-do/capabilities/applied-artificial-intelligence/articles/agentic-ai-enterprise-2028.html?id=us:2ps:3gl:aisgm26:awa:CONS:nonem:K0218784:111725:kwd-2025710122928:188372336109:784136672833::Brand_AI-SGO_BU_K0218784_Google:Brand_AI-SGO-Advisory:deloitte-generative-ai:&amp;amp;gclsrc=aw.ds&amp;amp;gad_source=1&amp;amp;gad_campaignid=23269751515&amp;amp;gbraid=0AAAAADenGPA6ZvC8cLRrT031O1up6RiOj&amp;amp;gclid=Cj0KCQiAi9rJBhCYARIsALyPDtudMaZrpHm8026n16yuyeM0sYKCTm24yHqR4Dyg_s6yZBgPnxfjDOwaAvN5EALw_wcB"&gt;Deloitte&lt;/a&gt; has developed generative AI capabilities within its audit platform. &lt;a href="https://www.bdo.com/insights/press-releases/bdo-usa-unveils-comprehensive-artificial-intelligence-strategy-fusing-practical-innovation"&gt;BDO&lt;/a&gt; announced a $1B investment in AI over the next five years. &lt;a href="https://www.ey.com/en_gl/newsroom/2025/11/ey-unveils-suite-of-powerful-ai-capabilities-to-accelerate-tax-transformation-and-deliver-strategic-value"&gt;EY&lt;/a&gt; launched an AI platform combining technology with strategy, transactions, and tax services. &lt;a href="https://www.pwc.com/us/en/tech-effect/ai-analytics/ai-predictions.html"&gt;PwC&lt;/a&gt; estimates a complete AI-driven audit solution will launch by 2026.&lt;/p&gt;&lt;p&gt;But adoption at smaller firms remains uneven. According to &lt;a href="http://thomsonreuters.com/en-us/posts/technology/genai-professional-services-report-2025/"&gt;Thomson Reuters research&lt;/a&gt;, 52% of tax firm respondents who use generative AI rely on open-source tools like ChatGPT rather than industry-specific solutions—a pattern that could shift as purpose-built alternatives emerge.&lt;/p&gt;&lt;p&gt;Marble&amp;#x27;s founders believe the hesitance stems not from technophobia but from a lack of compelling options.&lt;/p&gt;&lt;p&gt;“Firms want to embrace AI,&amp;quot; Shah said. “They just haven&amp;#x27;t seen great software and tooling made for them. That&amp;#x27;s part of the opportunity — to work with them and build something they&amp;#x27;re excited to use on a day-to-day basis.”&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Can artificial intelligence rescue accounting&amp;#x27;s billable-hour business model?&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;AI&amp;#x27;s arrival in accounting raises questions about the profession&amp;#x27;s billing structure.&lt;/p&gt;&lt;p&gt;Accounting firms have traditionally generated profits by billing clients for staff time, often at multiples of employee compensation costs. Junior associates performing compliance work represent a significant revenue stream. If AI can automate that work, does it undercut the business model firms depend on?&lt;/p&gt;&lt;p&gt;Marble&amp;#x27;s founders argue the opposite. The chronic staffing shortage has already constrained firms&amp;#x27; ability to capture available revenue. Advisory and consulting work — higher-margin services that clients actively want — goes undone because practitioners are buried in compliance tasks.&lt;/p&gt;&lt;p&gt;&amp;quot;Everyone in the industry agrees that an enormous amount of advisory work simply isn&amp;#x27;t getting done,&amp;quot; Konrad said. &amp;quot;Customers want it. Firms want to do it because it&amp;#x27;s high-margin, great work. But nobody gets to it.&amp;quot;&lt;/p&gt;&lt;p&gt;The &lt;a href="https://www.aicpa-cima.com/news/article/cpa-firms-report-steady-growth-in-revenue-and-profit-aicpa-research-finds"&gt;2025 AICPA National Management of an Accounting Practice Survey&lt;/a&gt; supports this view. Firms reported a median 6.7% increase in net client fees over the prior year, with growth in audit, assurance, tax services, and client accounting advisory. Net remaining per partner climbed 11.9% from fiscal year 2022 to fiscal year 2024, reaching $252,663.&lt;/p&gt;&lt;p&gt;The survey also found growing interest in AI adoption, though most firms have yet to allocate formal budgets or develop structured training programs. Continued adoption, the survey suggested, could help expand services and fuel continued growth.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Accountants won&amp;#x27;t adopt AI tools they can&amp;#x27;t trust with sensitive client data&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;For AI to succeed in accounting, it must clear a high bar for data security. Accounting firms handle some of the most sensitive financial information in the economy. Practitioners cannot adopt tools that create compliance or confidentiality risks.&lt;/p&gt;&lt;p&gt;According to &lt;a href="https://www.avalara.com/us/en/learn/ai-reinventing-finance-and-tax-state-of-finance-report.html"&gt;Avalara&amp;#x27;s survey&lt;/a&gt;, 63% of respondents cited data security and privacy concerns as the top barriers to automating tax and finance functions. The concern persists throughout the adoption lifecycle, from initial selection through implementation and ongoing use.&lt;/p&gt;&lt;p&gt;&lt;a href="https://marble.ai/"&gt;Marble&lt;/a&gt; has made security a foundational priority. The company obtained software compliance certification before releasing any product and maintains that data privacy is embedded in its operational culture from day one.&lt;/p&gt;&lt;p&gt;&amp;quot;Security is at the core of what we are building,&amp;quot; Shah said. &amp;quot;Every employee knows that security is critical. It&amp;#x27;s a part of our onboarding and something that we consider in everything we do.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;From number crunchers to strategic advisors: How AI could reshape accounting careers&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Marble&amp;#x27;s founders reject the narrative that AI will only take away from accounting jobs. They propose instead that AI will result in accounting jobs becoming more strategic and less characterized by repetitive execution. &lt;/p&gt;&lt;p&gt;They draw an analogy to architecture, where computer-aided design replaced laborious manual drafting. Architects did not disappear — they gained tools that let them spend more time on creative design and less on mechanical reproduction.&lt;/p&gt;&lt;p&gt;&amp;quot;If you take some of the hours-intensive, less creative work out of what being a junior or intermediate accountant is, and you replace it with a role where you&amp;#x27;re a professional who is being creative, synthesizing ideas, and able to delegate a lot of tasks to AI assistant platform solutions, you end up with an industry that&amp;#x27;s just a lot more fun to operate in,&amp;quot; Konrad said.&lt;/p&gt;&lt;p&gt;The shift could also improve client outcomes. When accountants spend less time on compliance, they can invest more in the strategic advisory work that clients value.&lt;/p&gt;&lt;p&gt;&amp;quot;Not only does the work become more enjoyable because of what you can focus on, but that&amp;#x27;s also what your clients are going to value more from you,&amp;quot; Shah said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The competitive landscape: Marble faces well-funded rivals and legacy giants&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;&lt;/b&gt;&lt;a href="http://marble.ai/"&gt;Marble&lt;/a&gt; enters a market with formidable incumbents and well-funded competitors. &lt;a href="https://venturebeat.com/ai/how-ai-tax-startup-blue-j-torched-its-entire-business-model-for-chatgpt-and"&gt;BlueJ&lt;/a&gt;, a global tax research platform, has raised over $100 million. &lt;a href="https://www.thomsonreuters.com/en"&gt;Thomson Reuters&lt;/a&gt;, &lt;a href="https://www.cch.com/"&gt;CCH&lt;/a&gt;, and &lt;a href="https://www.intuit.com/"&gt;Intuit&lt;/a&gt; have deep customer relationships built over decades.&lt;/p&gt;&lt;p&gt;But the founders see opportunity in the transition moment.&lt;/p&gt;&lt;p&gt;&amp;quot;AI has changed what’s possible in the industry,&amp;quot; Shah said. &amp;quot;We are going to work with and integrate with some technology players in the industry and also compete with other players with new products powered by AI. In some cases we are going to forget about the existing technology solution for doing things and go back to the task itself. We have totally new technological capabilities — how would you design something from a blank canvas that works with humans to accomplish that task?&amp;quot;&amp;quot;&lt;/p&gt;&lt;p&gt;The decision to offer a free research tool reflects Marble&amp;#x27;s go-to-market philosophy. By giving practitioners access without a paywall, the company aims to build trust and demonstrate capability.&lt;/p&gt;&lt;p&gt;&amp;quot;It allows us to expose a really compelling product that is purpose-built to those that are worried about how to use AI or question how to adopt it.  Now they don’t have to think about purchasing something that is cost-prohibitive when they don&amp;#x27;t know how to integrate it into their workflow,&amp;quot; Shah said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The $250 billion question: Can a startup transform how America does its taxes?&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Marble&amp;#x27;s roadmap extends beyond research. The company plans to develop AI agents capable of analyzing complex tax scenarios, identifying compliance issues, and eventually automating significant portions of compliance workflows — all while keeping practitioners in control.&lt;/p&gt;&lt;p&gt;The founders frame success not in terms of disruption but rebalancing. Today&amp;#x27;s tax work skews heavily toward compliance, leaving the strategic advisory services that clients crave — and that generate higher margins—perpetually undone. Marble&amp;#x27;s bet is that AI can flip that equation.&lt;/p&gt;&lt;p&gt;&amp;quot;Everyone wants it to look more like compliance is done simpler, and you spend time talking about strategy and planning,&amp;quot; Konrad said. &amp;quot;How do we change that blend of compliance versus strategy and planning to strategy and planning first—with compliance as something that has been made dramatically simpler?&amp;quot;&lt;/p&gt;&lt;p&gt;Whether Marble can execute on that vision remains to be seen. The company faces entrenched competitors, a profession that has historically resisted technological change, and the inherent unpredictability of building AI systems for high-stakes financial work.&lt;/p&gt;&lt;p&gt;But the founders are betting that the industry&amp;#x27;s demographic shift will accelerate adoption in ways that previous technology waves could not. With fewer accountants entering the profession each year and client demands only growing, firms may have an increased appetite to embrace tools that let their remaining staff do more.&lt;/p&gt;&lt;p&gt;&amp;quot;AI is going to change every industry — in some cases in ways that will help business models and in some cases in ways that will challenge them. We believe AI is ultimately going to make accounting firms’ businesses better and more profitable and at the same time end clients will get better services at better prices,&amp;quot; Shah said.&lt;/p&gt;&lt;p&gt;The accounting profession, it seems, is about to find out which side of that equation it lands on.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/marble-enters-the-race-to-bring-ai-to-tax-work-armed-with-usd9-million-and-a</guid><pubDate>Thu, 11 Dec 2025 14:00:00 +0000</pubDate></item><item><title>[NEW] Ride Into Adventure With Capcom’s ‘Monster Hunter Stories’ Series in the Cloud (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/geforce-now-thursday-monster-hunter-stories/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Hunters, saddle up — adventure awaits in the cloud.&lt;/p&gt;
&lt;p&gt;Journey into the world of &lt;i&gt;Monster Hunter Stories&lt;/i&gt; as Capcom’s acclaimed role-playing classics join GeForce NOW.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Monster Hunter Stories &lt;/i&gt;and &lt;i&gt;Monster Hunter Stories 2: Wings of Ruin&lt;/i&gt; are soaring into the cloud this week, bringing colorful worlds, charming companions and turn-based monster battles across devices.&lt;/p&gt;
&lt;p&gt;They lead seven new games joining the cloud this week, on top of an &lt;i&gt;ARC Raiders&lt;/i&gt; “Electrician Backpack: Emerald Wave Variant” reward for Ultimate members who want to drop into battle in style.&lt;/p&gt;
&lt;p&gt;It’s also been a big year for games, and this year’s major gaming awards nominees show just how strong gaming is right now — with many of those fan-favorite titles playable on GeForce NOW, no downloads required.&lt;/p&gt;
&lt;p&gt;Look for the “The Game Awards” row in the GeForce NOW app to dive in instantly.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Saddle Up&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Capcom’s &lt;i&gt;Monster Hunter Stories&lt;/i&gt; and &lt;i&gt;Monster Hunter Stories 2: Wings of Ruin&lt;/i&gt; arrive in the cloud this week. Members can explore vibrant worlds, bond with quirky monsters and experience turn-based role-playing game (RPG) adventures across devices.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_88239"&gt;&lt;img alt="Monster Hunter Stories on GeForce NOW" class="size-large wp-image-88239" height="945" src="https://blogs.nvidia.com/wp-content/uploads/2025/12/GFN_Thursday-Monster_Hunter_Stories-1680x945.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-88239"&gt;&lt;em&gt;Saddle up for egg-citement.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;In &lt;i&gt;Monster Hunter Stories,&lt;/i&gt; an RPG that expands the &lt;i&gt;Monster Hunter &lt;/i&gt;world, players are no longer hunting monsters but raising them. In this story featuring heroes known as Monster Riders, players live alongside monsters and form lifelong bonds with them.&lt;/p&gt;
&lt;p&gt;The first installment of the &lt;i&gt;Monster Hunter Stories&lt;/i&gt; series returns, fully voiced in Japanese and English, with additional features such as a new museum mode where players can listen to music and view concept art — offering an even deeper dive into the world of &lt;i&gt;Monster Hunter Stories.&lt;/i&gt;&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_88245"&gt;&lt;img alt="monster hunster stories 2 on gfn" class="size-large wp-image-88245" height="945" src="https://blogs.nvidia.com/wp-content/uploads/2025/12/09_NL_Rush_ScreenShot_00-1-1680x945.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-88245"&gt;&lt;em&gt;When fate calls, answer on a dragon’s back.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;A new adventure awaits in &lt;i&gt;Monster Hunter Stories 2: Wings of Ruin: &lt;/i&gt;the second installment of the turn-based RPG series. Become a Monster Rider and form bonds with friendly monsters known as Monsties to fight alongside them in the game’s epic story.&lt;/p&gt;
&lt;p&gt;These adventures can be enjoyed on almost any device, powered by high-performance GeForce RTX technology. Seamlessly switch between phones, laptops and desktops, and experience every lush landscape and thrilling battle with cloud-streamed visuals and smooth gameplay — no downloads, installs or upgrades required.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;And the Cloud Goes to … GeForce NOW&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;It’s a big month for games, and this year’s major gaming awards make it an especially great time to be a gamer. Many of the buzziest nominees and fan-favorite titles are playable on GeForce NOW, where it’s easy to jump into the action, catch up on the hits and see what the hype’s all about — all instantly, no downloads required.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_88233"&gt;&lt;img alt="Clair Obscure on GeForce NOW" class="size-large wp-image-88233" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/12/GFN_Thursday-Clair_Obscur_Expedition_33-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-88233"&gt;&lt;em&gt;What a game.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;A stack of nominated titles are available in the cloud through GeForce NOW, including a majority of Game of the Year (GOTY) contenders like &lt;i&gt;Clair Obscur: Expedition 33&lt;/i&gt;, &lt;i&gt;Hollow Knight: Silksong&lt;/i&gt; and &lt;i&gt;Kingdom Come: Deliverance II&lt;/i&gt;.&lt;/p&gt;
&lt;p&gt;RPG fans can marathon some of the year’s best titles in the genre through the cloud. &lt;i&gt;Avowed, Clair Obscur: Expedition 33, Kingdom Come: Deliverance II, Monster Hunter Wilds &lt;/i&gt;and &lt;i&gt;The Outer Worlds 2&lt;/i&gt; are all streamable on GeForce NOW.​&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_88242"&gt;&lt;img alt="Silksong on GeForce NOW" class="size-large wp-image-88242" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/12/GFN_Thursday-Silksong-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-88242"&gt;&lt;em&gt;A masterpiece.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Members can also dive into other nominated favorites such as &lt;i&gt;Battlefield 6&lt;/i&gt; and &lt;i&gt;DOOM: The Dark Ages&lt;/i&gt; for Best Action, &lt;i&gt;Indiana Jones and the Ancient Circle&lt;/i&gt; and &lt;i&gt;Split Fiction&lt;/i&gt; for Best Adventure, &lt;i&gt;The Alters&lt;/i&gt; and &lt;i&gt;Sid Meier’s Civilization VII&lt;/i&gt; for Best Sim/Strategy,&lt;i&gt; ARC Raiders&lt;/i&gt; and &lt;i&gt;PEAK &lt;/i&gt;for Best Multiplayer, plus esports staples like &lt;i&gt;Counter-Strike 2 and DOTA 2&lt;/i&gt;.&lt;/p&gt;
&lt;p&gt;Whether chasing GOTY, exploring indies like &lt;i&gt;Blue Prince&lt;/i&gt; and &lt;i&gt;Hollow Knight: Silksong&lt;/i&gt;, or sticking to long-running hits like &lt;i&gt;Fortnite &lt;/i&gt;and&lt;i&gt; No Man’s Sky&lt;/i&gt;, gamers can always find a top title ready to stream.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Loot, Shoot and Look Good Doing It&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_88236"&gt;&lt;img alt="ARC Raiders reward on GeForce NOW" class="size-large wp-image-88236" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/12/GFN_Thursday-ARC_Raiders_GFN_Members_Reward-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-88236"&gt;&lt;em&gt;Pack up and stand out.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Ultimate members can claim the &lt;i&gt;ARC Raiders&lt;/i&gt; “Electrician Backpack: Emerald Wave Variant” — an in-game cosmetic item that adds a distinct look. The Emerald Wave design offers a clean, modern touch for Raiders ready to stand out during extraction missions.​​&lt;/p&gt;
&lt;p&gt;Jump into battle with style, powered by GeForce RTX 5080-class servers on GeForce NOW, delivering up to 2.8x higher frame rates and a new Cinematic-Quality Streaming mode that makes every firefight shine.&lt;/p&gt;
&lt;p&gt;The reward is available to Ultimate members through Sunday, Jan. 4, 2026, or while supplies last. Keep an eye on email for instructions to redeem this stylish advantage for the journey ahead. Once claimed, navigate to the Electrician Backpack and select the Emerald Wave color variant to equip it and head off in style.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Fresh Crop of Games&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_88227"&gt;&lt;img alt="Everdream village on GeForce NOW" class="size-large wp-image-88227" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/12/GFN_Thursday-Everdream_Village-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-88227"&gt;&lt;em&gt;Where the cows know your name.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;i&gt;Everdream Village&lt;/i&gt;, a cozy farming adventure from publisher Untold Tales, lets players turn a sleepy island settlement into a thriving, story-filled village. Tend crops, befriend quirky villagers and wrangle a menagerie of charming animals while terraforming the land and sail off to discover new magical islands — all while shaping a laid-back little paradise.&lt;/p&gt;
&lt;p&gt;In addition, members can look for the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;Skate Story &lt;/i&gt;(New release on Steam, Dec. 8)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Dome Keeper &lt;/i&gt;(New release on Xbox, available on Game Pass, Dec. 9)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Death Howl &lt;/i&gt;(New release on Steam and Xbox, available on Game Pass, Dec. 9)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;RuneQuest: Warlords&lt;/i&gt; (New release on Steam, Dec. 9)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Everdream Village &lt;/i&gt;(New release on Steam, Dec. 12)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Monster Hunter Stories &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Monster Hunter Stories 2 &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;GeForce RTX 5080-ready games:&lt;/p&gt;

&lt;p&gt;What are you planning to play this weekend? Let us know on X or in the comments below.&lt;/p&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p dir="ltr" lang="en"&gt;What's on the top of your gaming wishlist this holiday? ✍️❄️&lt;/p&gt;
&lt;p&gt;— 🌩️ NVIDIA GeForce NOW (@NVIDIAGFN) December 10, 2025&lt;/p&gt;&lt;/blockquote&gt;


		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Hunters, saddle up — adventure awaits in the cloud.&lt;/p&gt;
&lt;p&gt;Journey into the world of &lt;i&gt;Monster Hunter Stories&lt;/i&gt; as Capcom’s acclaimed role-playing classics join GeForce NOW.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Monster Hunter Stories &lt;/i&gt;and &lt;i&gt;Monster Hunter Stories 2: Wings of Ruin&lt;/i&gt; are soaring into the cloud this week, bringing colorful worlds, charming companions and turn-based monster battles across devices.&lt;/p&gt;
&lt;p&gt;They lead seven new games joining the cloud this week, on top of an &lt;i&gt;ARC Raiders&lt;/i&gt; “Electrician Backpack: Emerald Wave Variant” reward for Ultimate members who want to drop into battle in style.&lt;/p&gt;
&lt;p&gt;It’s also been a big year for games, and this year’s major gaming awards nominees show just how strong gaming is right now — with many of those fan-favorite titles playable on GeForce NOW, no downloads required.&lt;/p&gt;
&lt;p&gt;Look for the “The Game Awards” row in the GeForce NOW app to dive in instantly.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Saddle Up&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Capcom’s &lt;i&gt;Monster Hunter Stories&lt;/i&gt; and &lt;i&gt;Monster Hunter Stories 2: Wings of Ruin&lt;/i&gt; arrive in the cloud this week. Members can explore vibrant worlds, bond with quirky monsters and experience turn-based role-playing game (RPG) adventures across devices.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_88239"&gt;&lt;img alt="Monster Hunter Stories on GeForce NOW" class="size-large wp-image-88239" height="945" src="https://blogs.nvidia.com/wp-content/uploads/2025/12/GFN_Thursday-Monster_Hunter_Stories-1680x945.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-88239"&gt;&lt;em&gt;Saddle up for egg-citement.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;In &lt;i&gt;Monster Hunter Stories,&lt;/i&gt; an RPG that expands the &lt;i&gt;Monster Hunter &lt;/i&gt;world, players are no longer hunting monsters but raising them. In this story featuring heroes known as Monster Riders, players live alongside monsters and form lifelong bonds with them.&lt;/p&gt;
&lt;p&gt;The first installment of the &lt;i&gt;Monster Hunter Stories&lt;/i&gt; series returns, fully voiced in Japanese and English, with additional features such as a new museum mode where players can listen to music and view concept art — offering an even deeper dive into the world of &lt;i&gt;Monster Hunter Stories.&lt;/i&gt;&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_88245"&gt;&lt;img alt="monster hunster stories 2 on gfn" class="size-large wp-image-88245" height="945" src="https://blogs.nvidia.com/wp-content/uploads/2025/12/09_NL_Rush_ScreenShot_00-1-1680x945.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-88245"&gt;&lt;em&gt;When fate calls, answer on a dragon’s back.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;A new adventure awaits in &lt;i&gt;Monster Hunter Stories 2: Wings of Ruin: &lt;/i&gt;the second installment of the turn-based RPG series. Become a Monster Rider and form bonds with friendly monsters known as Monsties to fight alongside them in the game’s epic story.&lt;/p&gt;
&lt;p&gt;These adventures can be enjoyed on almost any device, powered by high-performance GeForce RTX technology. Seamlessly switch between phones, laptops and desktops, and experience every lush landscape and thrilling battle with cloud-streamed visuals and smooth gameplay — no downloads, installs or upgrades required.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;And the Cloud Goes to … GeForce NOW&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;It’s a big month for games, and this year’s major gaming awards make it an especially great time to be a gamer. Many of the buzziest nominees and fan-favorite titles are playable on GeForce NOW, where it’s easy to jump into the action, catch up on the hits and see what the hype’s all about — all instantly, no downloads required.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_88233"&gt;&lt;img alt="Clair Obscure on GeForce NOW" class="size-large wp-image-88233" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/12/GFN_Thursday-Clair_Obscur_Expedition_33-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-88233"&gt;&lt;em&gt;What a game.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;A stack of nominated titles are available in the cloud through GeForce NOW, including a majority of Game of the Year (GOTY) contenders like &lt;i&gt;Clair Obscur: Expedition 33&lt;/i&gt;, &lt;i&gt;Hollow Knight: Silksong&lt;/i&gt; and &lt;i&gt;Kingdom Come: Deliverance II&lt;/i&gt;.&lt;/p&gt;
&lt;p&gt;RPG fans can marathon some of the year’s best titles in the genre through the cloud. &lt;i&gt;Avowed, Clair Obscur: Expedition 33, Kingdom Come: Deliverance II, Monster Hunter Wilds &lt;/i&gt;and &lt;i&gt;The Outer Worlds 2&lt;/i&gt; are all streamable on GeForce NOW.​&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_88242"&gt;&lt;img alt="Silksong on GeForce NOW" class="size-large wp-image-88242" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/12/GFN_Thursday-Silksong-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-88242"&gt;&lt;em&gt;A masterpiece.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Members can also dive into other nominated favorites such as &lt;i&gt;Battlefield 6&lt;/i&gt; and &lt;i&gt;DOOM: The Dark Ages&lt;/i&gt; for Best Action, &lt;i&gt;Indiana Jones and the Ancient Circle&lt;/i&gt; and &lt;i&gt;Split Fiction&lt;/i&gt; for Best Adventure, &lt;i&gt;The Alters&lt;/i&gt; and &lt;i&gt;Sid Meier’s Civilization VII&lt;/i&gt; for Best Sim/Strategy,&lt;i&gt; ARC Raiders&lt;/i&gt; and &lt;i&gt;PEAK &lt;/i&gt;for Best Multiplayer, plus esports staples like &lt;i&gt;Counter-Strike 2 and DOTA 2&lt;/i&gt;.&lt;/p&gt;
&lt;p&gt;Whether chasing GOTY, exploring indies like &lt;i&gt;Blue Prince&lt;/i&gt; and &lt;i&gt;Hollow Knight: Silksong&lt;/i&gt;, or sticking to long-running hits like &lt;i&gt;Fortnite &lt;/i&gt;and&lt;i&gt; No Man’s Sky&lt;/i&gt;, gamers can always find a top title ready to stream.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Loot, Shoot and Look Good Doing It&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_88236"&gt;&lt;img alt="ARC Raiders reward on GeForce NOW" class="size-large wp-image-88236" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/12/GFN_Thursday-ARC_Raiders_GFN_Members_Reward-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-88236"&gt;&lt;em&gt;Pack up and stand out.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Ultimate members can claim the &lt;i&gt;ARC Raiders&lt;/i&gt; “Electrician Backpack: Emerald Wave Variant” — an in-game cosmetic item that adds a distinct look. The Emerald Wave design offers a clean, modern touch for Raiders ready to stand out during extraction missions.​​&lt;/p&gt;
&lt;p&gt;Jump into battle with style, powered by GeForce RTX 5080-class servers on GeForce NOW, delivering up to 2.8x higher frame rates and a new Cinematic-Quality Streaming mode that makes every firefight shine.&lt;/p&gt;
&lt;p&gt;The reward is available to Ultimate members through Sunday, Jan. 4, 2026, or while supplies last. Keep an eye on email for instructions to redeem this stylish advantage for the journey ahead. Once claimed, navigate to the Electrician Backpack and select the Emerald Wave color variant to equip it and head off in style.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Fresh Crop of Games&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_88227"&gt;&lt;img alt="Everdream village on GeForce NOW" class="size-large wp-image-88227" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/12/GFN_Thursday-Everdream_Village-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-88227"&gt;&lt;em&gt;Where the cows know your name.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;i&gt;Everdream Village&lt;/i&gt;, a cozy farming adventure from publisher Untold Tales, lets players turn a sleepy island settlement into a thriving, story-filled village. Tend crops, befriend quirky villagers and wrangle a menagerie of charming animals while terraforming the land and sail off to discover new magical islands — all while shaping a laid-back little paradise.&lt;/p&gt;
&lt;p&gt;In addition, members can look for the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;Skate Story &lt;/i&gt;(New release on Steam, Dec. 8)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Dome Keeper &lt;/i&gt;(New release on Xbox, available on Game Pass, Dec. 9)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Death Howl &lt;/i&gt;(New release on Steam and Xbox, available on Game Pass, Dec. 9)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;RuneQuest: Warlords&lt;/i&gt; (New release on Steam, Dec. 9)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Everdream Village &lt;/i&gt;(New release on Steam, Dec. 12)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Monster Hunter Stories &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Monster Hunter Stories 2 &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;GeForce RTX 5080-ready games:&lt;/p&gt;

&lt;p&gt;What are you planning to play this weekend? Let us know on X or in the comments below.&lt;/p&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p dir="ltr" lang="en"&gt;What's on the top of your gaming wishlist this holiday? ✍️❄️&lt;/p&gt;
&lt;p&gt;— 🌩️ NVIDIA GeForce NOW (@NVIDIAGFN) December 10, 2025&lt;/p&gt;&lt;/blockquote&gt;


		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/geforce-now-thursday-monster-hunter-stories/</guid><pubDate>Thu, 11 Dec 2025 14:00:09 +0000</pubDate></item><item><title>[NEW] Microsoft ‘Promptions’ fix AI prompts failing to deliver (AI News)</title><link>https://www.artificialintelligence-news.com/news/microsoft-promptions-fix-ai-prompts-failing-to-deliver/</link><description>&lt;p&gt;Microsoft believes it has a fix for AI prompts being given, the response missing the mark, and the cycle repeating.&lt;/p&gt;&lt;p&gt;This inefficiency is a drain on resources. The “trial-and-error loop can feel unpredictable and discouraging,” turning what should be a productivity booster into a time sink. Knowledge workers often spend more time managing the interaction itself than understanding the material they hoped to learn.&lt;/p&gt;&lt;p&gt;Microsoft has released Promptions (prompt + options), a UI framework designed to address this friction by replacing vague natural language requests with precise, dynamic interface controls. The open-source tool offers a method to standardise how workforces interact with large language models (LLMs), moving away from unstructured chat toward guided and reliable workflows.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-comprehension-bottleneck"&gt;The comprehension bottleneck&lt;/h3&gt;&lt;p&gt;Public attention often centres on AI producing text or images, but a massive component of enterprise usage involves understanding—asking AI to explain, clarify, or teach. This distinction is vital for internal tooling.&lt;/p&gt;&lt;p&gt;Consider a spreadsheet formula: one user may want a simple syntax breakdown, another a debugging guide, and another an explanation suitable for teaching colleagues. The same formula can require entirely different explanations depending on the user’s role, expertise, and goals.&lt;/p&gt;&lt;p&gt;Current chat interfaces rarely capture this intent effectively. Users often find that the way they phrase a question doesn’t match the level of detail the AI needs. “Clarifying what they really want can require long, carefully worded prompts that are tiring to produce,” Microsoft explains.&lt;/p&gt;&lt;p&gt;Promptions operates as a middleware layer to fix this familiar issue with AI prompts. Instead of forcing users to type lengthy specifications, the system analyses the intent and conversation history to generate clickable options – such as explanation length, tone, or specific focus areas – in real-time.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-efficiency-vs-complexity"&gt;Efficiency vs complexity&lt;/h3&gt;&lt;p&gt;Microsoft researchers tested this approach by comparing static controls against the new dynamic system. The findings offer a realistic view of how such tools function in a live environment.&lt;/p&gt;&lt;p&gt;Participants consistently reported that dynamic controls made it easier to express the specifics of their tasks without repeatedly rephrasing their prompts. This reduced the effort of prompt engineering and allowed users to focus more on understanding content than managing the mechanics of phrasing. By surfacing options like “Learning Objective” and “Response Format,” the system prompted participants to think more deliberately about their goals.&lt;/p&gt;&lt;p&gt;Yet, adoption brings trade-offs. Participants valued adaptability but also found the system more difficult to interpret. Some struggled to anticipate how a selected option would influence the response, noting that the controls seemed opaque because the effect became evident only after the output appeared.&lt;/p&gt;&lt;p&gt;This highlights a balance to strike. Dynamic interfaces can streamline complex tasks but may introduce a learning curve where the connection between a checkbox and the final output requires user adaptation.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-promptions-the-solution-to-fix-ai-prompts"&gt;Promptions: The solution to fix AI prompts?&lt;/h3&gt;&lt;p&gt;Promptions is designed to be lightweight, functioning as a middleware layer sitting between the user and the underlying language model.&lt;/p&gt;&lt;p&gt;The architecture consists of two primary components:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Option Module:&lt;/strong&gt; Reviews the user’s prompt and conversation history to generate relevant UI elements.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Chat Module:&lt;/strong&gt; Incorporates these selections to produce the AI’s response.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Of particular note for security teams, “there’s no need to store data between sessions, which keeps implementation simple.” This stateless design mitigates data governance concerns typically associated with complex AI overlays.&lt;/p&gt;&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt; [embedded content]&lt;/p&gt;&lt;/figure&gt;&lt;p&gt;Moving from “prompt engineering” to “prompt selection” offers a pathway to more consistent AI outputs across an organisation. By implementing UI frameworks that guide user intent, technology leaders can reduce the variability of AI responses and improve workforce efficiency.&lt;/p&gt;&lt;p&gt;Success depends on calibration. Usability challenges remain regarding how dynamic options affect AI output and managing the complexity of multiple controls. Leaders should view this not as a complete solution to fix the results of AI prompts, but as a design pattern to test within their internal developer platforms and support tools.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Perplexity: AI agents are taking over complex enterprise tasks&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-111183" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/12/image-3.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Microsoft believes it has a fix for AI prompts being given, the response missing the mark, and the cycle repeating.&lt;/p&gt;&lt;p&gt;This inefficiency is a drain on resources. The “trial-and-error loop can feel unpredictable and discouraging,” turning what should be a productivity booster into a time sink. Knowledge workers often spend more time managing the interaction itself than understanding the material they hoped to learn.&lt;/p&gt;&lt;p&gt;Microsoft has released Promptions (prompt + options), a UI framework designed to address this friction by replacing vague natural language requests with precise, dynamic interface controls. The open-source tool offers a method to standardise how workforces interact with large language models (LLMs), moving away from unstructured chat toward guided and reliable workflows.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-comprehension-bottleneck"&gt;The comprehension bottleneck&lt;/h3&gt;&lt;p&gt;Public attention often centres on AI producing text or images, but a massive component of enterprise usage involves understanding—asking AI to explain, clarify, or teach. This distinction is vital for internal tooling.&lt;/p&gt;&lt;p&gt;Consider a spreadsheet formula: one user may want a simple syntax breakdown, another a debugging guide, and another an explanation suitable for teaching colleagues. The same formula can require entirely different explanations depending on the user’s role, expertise, and goals.&lt;/p&gt;&lt;p&gt;Current chat interfaces rarely capture this intent effectively. Users often find that the way they phrase a question doesn’t match the level of detail the AI needs. “Clarifying what they really want can require long, carefully worded prompts that are tiring to produce,” Microsoft explains.&lt;/p&gt;&lt;p&gt;Promptions operates as a middleware layer to fix this familiar issue with AI prompts. Instead of forcing users to type lengthy specifications, the system analyses the intent and conversation history to generate clickable options – such as explanation length, tone, or specific focus areas – in real-time.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-efficiency-vs-complexity"&gt;Efficiency vs complexity&lt;/h3&gt;&lt;p&gt;Microsoft researchers tested this approach by comparing static controls against the new dynamic system. The findings offer a realistic view of how such tools function in a live environment.&lt;/p&gt;&lt;p&gt;Participants consistently reported that dynamic controls made it easier to express the specifics of their tasks without repeatedly rephrasing their prompts. This reduced the effort of prompt engineering and allowed users to focus more on understanding content than managing the mechanics of phrasing. By surfacing options like “Learning Objective” and “Response Format,” the system prompted participants to think more deliberately about their goals.&lt;/p&gt;&lt;p&gt;Yet, adoption brings trade-offs. Participants valued adaptability but also found the system more difficult to interpret. Some struggled to anticipate how a selected option would influence the response, noting that the controls seemed opaque because the effect became evident only after the output appeared.&lt;/p&gt;&lt;p&gt;This highlights a balance to strike. Dynamic interfaces can streamline complex tasks but may introduce a learning curve where the connection between a checkbox and the final output requires user adaptation.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-promptions-the-solution-to-fix-ai-prompts"&gt;Promptions: The solution to fix AI prompts?&lt;/h3&gt;&lt;p&gt;Promptions is designed to be lightweight, functioning as a middleware layer sitting between the user and the underlying language model.&lt;/p&gt;&lt;p&gt;The architecture consists of two primary components:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Option Module:&lt;/strong&gt; Reviews the user’s prompt and conversation history to generate relevant UI elements.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Chat Module:&lt;/strong&gt; Incorporates these selections to produce the AI’s response.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Of particular note for security teams, “there’s no need to store data between sessions, which keeps implementation simple.” This stateless design mitigates data governance concerns typically associated with complex AI overlays.&lt;/p&gt;&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt; [embedded content]&lt;/p&gt;&lt;/figure&gt;&lt;p&gt;Moving from “prompt engineering” to “prompt selection” offers a pathway to more consistent AI outputs across an organisation. By implementing UI frameworks that guide user intent, technology leaders can reduce the variability of AI responses and improve workforce efficiency.&lt;/p&gt;&lt;p&gt;Success depends on calibration. Usability challenges remain regarding how dynamic options affect AI output and managing the complexity of multiple controls. Leaders should view this not as a complete solution to fix the results of AI prompts, but as a design pattern to test within their internal developer platforms and support tools.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Perplexity: AI agents are taking over complex enterprise tasks&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-111183" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/12/image-3.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/microsoft-promptions-fix-ai-prompts-failing-to-deliver/</guid><pubDate>Thu, 11 Dec 2025 14:11:36 +0000</pubDate></item><item><title>[NEW] TIME names ‘Architects of AI’ its Person of the Year (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/11/time-names-architects-of-ai-its-person-of-the-year/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/12/TIME-person-of-the-year.png?resize=1200,769" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Each December, TIME Magazine names a person of the year — someone who has most influenced the news and world, for good or ill. Last year, TIME chose President Donald Trump for the second time. The year before that, it was Taylor Swift, who many claimed saved the economy from a recession with her Eras Tour. In 1938, the magazine chose Adolf Hitler.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This year, TIME has chosen to bestow its award on not just one person, but a group of people: the so-called “Architects of AI,” comprising the CEOs shaping the global AI race from the U.S.&amp;nbsp;With AI on everyone’s minds, embodying hope for a small minority and economic anxiety for a majority, per recent Edelman data, this tracks.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“For decades, humankind steeled itself for the rise of thinking machines,” the article reads. “Leaders striving to develop the technology, including Sam Altman and Elon Musk, warned that the pursuit of its powers could create unforeseen catastrophe […] This year, the debate about how to wield AI responsibly gave way to a sprint to deploy it as fast as possible.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Based on one of TIME’s two cover photos, some of those people appear to be Nvidia’s Jensen Huang, Tesla’s Elon Musk, OpenAI’s Sam Altman, Meta’s Mark Zuckerberg, AMD’s Lisa Su, Anthropic’s Dario Amodei, Google DeepMind’s Demis Hassabis, and World Labs’ Fei-Fei Li — all individuals who raced “both beside and against each other.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TIME writes that these individuals, through their multibillion-dollar bets on “one of the biggest physical infrastructure projects of all time,” have reshaped government policy, turned up the heat on geopolitical competition, and pushed AI adoption forward.&amp;nbsp;&lt;/p&gt;

&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;
&lt;p class="wp-block-paragraph"&gt;This is the story of how AI changed our world in 2025, in new and exciting and sometimes frightening ways. It is the story of how Huang and other tech titans grabbed the wheel of history, developing technology and making decisions that are reshaping the information landscape, the climate, and our livelihoods… AI emerged as arguably the most consequential tool in great-power competition since the advent of nuclear weapons.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p class="wp-block-paragraph"&gt;TIME only announced the news on Thursday morning, but images of the cover photo were leaked on prediction market Polymarket on Wednesday evening.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/12/TIME-person-of-the-year.png?resize=1200,769" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Each December, TIME Magazine names a person of the year — someone who has most influenced the news and world, for good or ill. Last year, TIME chose President Donald Trump for the second time. The year before that, it was Taylor Swift, who many claimed saved the economy from a recession with her Eras Tour. In 1938, the magazine chose Adolf Hitler.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This year, TIME has chosen to bestow its award on not just one person, but a group of people: the so-called “Architects of AI,” comprising the CEOs shaping the global AI race from the U.S.&amp;nbsp;With AI on everyone’s minds, embodying hope for a small minority and economic anxiety for a majority, per recent Edelman data, this tracks.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“For decades, humankind steeled itself for the rise of thinking machines,” the article reads. “Leaders striving to develop the technology, including Sam Altman and Elon Musk, warned that the pursuit of its powers could create unforeseen catastrophe […] This year, the debate about how to wield AI responsibly gave way to a sprint to deploy it as fast as possible.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Based on one of TIME’s two cover photos, some of those people appear to be Nvidia’s Jensen Huang, Tesla’s Elon Musk, OpenAI’s Sam Altman, Meta’s Mark Zuckerberg, AMD’s Lisa Su, Anthropic’s Dario Amodei, Google DeepMind’s Demis Hassabis, and World Labs’ Fei-Fei Li — all individuals who raced “both beside and against each other.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TIME writes that these individuals, through their multibillion-dollar bets on “one of the biggest physical infrastructure projects of all time,” have reshaped government policy, turned up the heat on geopolitical competition, and pushed AI adoption forward.&amp;nbsp;&lt;/p&gt;

&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;
&lt;p class="wp-block-paragraph"&gt;This is the story of how AI changed our world in 2025, in new and exciting and sometimes frightening ways. It is the story of how Huang and other tech titans grabbed the wheel of history, developing technology and making decisions that are reshaping the information landscape, the climate, and our livelihoods… AI emerged as arguably the most consequential tool in great-power competition since the advent of nuclear weapons.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p class="wp-block-paragraph"&gt;TIME only announced the news on Thursday morning, but images of the cover photo were leaked on prediction market Polymarket on Wednesday evening.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/11/time-names-architects-of-ai-its-person-of-the-year/</guid><pubDate>Thu, 11 Dec 2025 14:38:06 +0000</pubDate></item><item><title>[NEW] Oracle shares slide on $15B increase in data center spending (AI – Ars Technica)</title><link>https://arstechnica.com/information-technology/2025/12/oracle-shares-slide-on-15b-increase-in-data-center-spending/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Company raises its capital expenditure forecast as it doubles down on AI infrastructure bet.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-1867844462-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-1867844462-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Mesut Dogan

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Oracle stock dropped after it reported disappointing revenues on Wednesday alongside a $15 billion increase in its planned spending on data centers this year to serve artificial intelligence groups.&lt;/p&gt;
&lt;p&gt;Shares in Larry Ellison’s database company fell 11 percent in pre-market trading on Thursday after it reported revenues of $16.1 billion in the last quarter, up 14 percent from the previous year, but below analysts’ estimates.&lt;/p&gt;
&lt;p&gt;Oracle raised its forecast for capital expenditure this financial year by more than 40 percent to $50 billion. The outlay, largely directed to building data centers, climbed to $12 billion in the quarter, above expectations of $8.4 billion.&lt;/p&gt;
&lt;p&gt;Its long-term debt increased to $99.9 billion, up 25 percent from a year ago.&lt;/p&gt;
&lt;p&gt;Oracle has launched an aggressive bid to catch up to much larger cloud players such as Google, Amazon, and Microsoft in the race to supply the vast amount of computing power that AI groups including OpenAI and Anthropic need to train and run their models.&lt;/p&gt;
&lt;p&gt;Clay Magouyrk, Oracle’s co-chief executive, said its cloud contracts would “quickly add revenue and margin to our infrastructure business” as he defended the vast investments.&lt;/p&gt;
&lt;p&gt;Yet the company said it expected full-year revenues to remain unchanged from its previous forecast of $67 billion. It expected to generate $4 billion more in revenue the following fiscal year.&lt;/p&gt;
&lt;p&gt;Total bookings for future revenue, known as remaining performance obligations, rose 15 percent to $523 billion in the three months to the end of November, supported by deals with Meta and Nvidia.&lt;/p&gt;
&lt;p&gt;Investors initially welcomed the push into AI from Oracle. Shares surged after its last earnings in September when it disclosed it had added more than $300 billion in bookings, largely driven by data center contracts with OpenAI.&lt;/p&gt;
&lt;p&gt;But the stock has given up its gains since then as investors worry about the large amounts Oracle will have to borrow and spend on infrastructure for the ChatGPT maker—and concerns over the start-up’s ability to pay for these contracts in the years ahead. OpenAI has struck deals to spend $1.4 trillion over the next eight years on computing power.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Oracle’s Big Tech rivals such as Amazon, Microsoft, and Google have helped reassure investors about their large capital investments by posting strong earnings from their vast cloud units.&lt;/p&gt;
&lt;p&gt;But in the last quarter, Oracle’s cloud infrastructure business, which includes its data centers, posted worse than expected revenues of $4.1 billion. Ellison’s company is also relying more heavily on debt to fuel its expansion.&lt;/p&gt;
&lt;p&gt;Net income rose to $6.1 billion in the quarter, boosted by a $2.7 billion pre-tax gain from the sale of semiconductor company Ampere to SoftBank.&lt;/p&gt;
&lt;p&gt;The company added an additional 400 MW of data center capacity in the quarter, Magouyrk told investors. Construction was on track at its large data center cluster in Abilene, Texas, which is being built for OpenAI, he added.&lt;/p&gt;
&lt;p&gt;Magouyrk, who took over from Safra Catz in September, said there was ample demand from other clients for Oracle’s data centers if OpenAI did not take up the full amount it had contracted for.&lt;/p&gt;
&lt;p&gt;“We have a customer base with a lot of demand such that whenever we find ourselves [with] capacity that’s not being used, it very quickly gets allocated,” he said.&lt;/p&gt;
&lt;p&gt;Co-founded by Ellison as a business software provider, Oracle was slow to pivot to cloud computing. The billionaire remains chair and its largest shareholder.&lt;/p&gt;
&lt;p&gt;Investors and analysts have raised concerns in recent months about the upfront spending required by Oracle to honor its AI infrastructure contracts. Moody’s in September flagged the company’s reliance on a small number of large customers such as OpenAI.&lt;/p&gt;
&lt;p&gt;Morgan Stanley forecasts that Oracle’s net debt will soar to about $290 billion by 2028. The company sold $18 billion of bonds in September and is in talks to raise $38 billion in debt financing through a number of US banks.&lt;/p&gt;
&lt;p&gt;Brent Thill, an analyst at Jefferies, said Oracle’s software business—which generated $5.9 billion in the quarter—provided some buffer amid accelerated spending. “But the timing mismatch between upfront capex and delayed monetization creates near-term pressure.”&lt;/p&gt;
&lt;p&gt;Doug Kehring, principal financial officer, said the company was renting capacity from data center specialists to reduce its direct borrowing.&lt;/p&gt;
&lt;p&gt;The debt to build the Abilene site was raised by start-up Crusoe and investment group Blue Owl Capital, and Oracle has signed a 15-year lease for the site.&lt;/p&gt;
&lt;p&gt;“Oracle does not pay for these leases until the completed data centers… are delivered to us,” Kehring said, adding that the company was “committed to maintaining our investment-grade debt ratings.”&lt;/p&gt;
&lt;p&gt;&lt;em&gt;© 2025 The Financial Times Ltd. All rights reserved. Not to be redistributed, copied, or modified in any way.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Company raises its capital expenditure forecast as it doubles down on AI infrastructure bet.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-1867844462-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-1867844462-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Mesut Dogan

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Oracle stock dropped after it reported disappointing revenues on Wednesday alongside a $15 billion increase in its planned spending on data centers this year to serve artificial intelligence groups.&lt;/p&gt;
&lt;p&gt;Shares in Larry Ellison’s database company fell 11 percent in pre-market trading on Thursday after it reported revenues of $16.1 billion in the last quarter, up 14 percent from the previous year, but below analysts’ estimates.&lt;/p&gt;
&lt;p&gt;Oracle raised its forecast for capital expenditure this financial year by more than 40 percent to $50 billion. The outlay, largely directed to building data centers, climbed to $12 billion in the quarter, above expectations of $8.4 billion.&lt;/p&gt;
&lt;p&gt;Its long-term debt increased to $99.9 billion, up 25 percent from a year ago.&lt;/p&gt;
&lt;p&gt;Oracle has launched an aggressive bid to catch up to much larger cloud players such as Google, Amazon, and Microsoft in the race to supply the vast amount of computing power that AI groups including OpenAI and Anthropic need to train and run their models.&lt;/p&gt;
&lt;p&gt;Clay Magouyrk, Oracle’s co-chief executive, said its cloud contracts would “quickly add revenue and margin to our infrastructure business” as he defended the vast investments.&lt;/p&gt;
&lt;p&gt;Yet the company said it expected full-year revenues to remain unchanged from its previous forecast of $67 billion. It expected to generate $4 billion more in revenue the following fiscal year.&lt;/p&gt;
&lt;p&gt;Total bookings for future revenue, known as remaining performance obligations, rose 15 percent to $523 billion in the three months to the end of November, supported by deals with Meta and Nvidia.&lt;/p&gt;
&lt;p&gt;Investors initially welcomed the push into AI from Oracle. Shares surged after its last earnings in September when it disclosed it had added more than $300 billion in bookings, largely driven by data center contracts with OpenAI.&lt;/p&gt;
&lt;p&gt;But the stock has given up its gains since then as investors worry about the large amounts Oracle will have to borrow and spend on infrastructure for the ChatGPT maker—and concerns over the start-up’s ability to pay for these contracts in the years ahead. OpenAI has struck deals to spend $1.4 trillion over the next eight years on computing power.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Oracle’s Big Tech rivals such as Amazon, Microsoft, and Google have helped reassure investors about their large capital investments by posting strong earnings from their vast cloud units.&lt;/p&gt;
&lt;p&gt;But in the last quarter, Oracle’s cloud infrastructure business, which includes its data centers, posted worse than expected revenues of $4.1 billion. Ellison’s company is also relying more heavily on debt to fuel its expansion.&lt;/p&gt;
&lt;p&gt;Net income rose to $6.1 billion in the quarter, boosted by a $2.7 billion pre-tax gain from the sale of semiconductor company Ampere to SoftBank.&lt;/p&gt;
&lt;p&gt;The company added an additional 400 MW of data center capacity in the quarter, Magouyrk told investors. Construction was on track at its large data center cluster in Abilene, Texas, which is being built for OpenAI, he added.&lt;/p&gt;
&lt;p&gt;Magouyrk, who took over from Safra Catz in September, said there was ample demand from other clients for Oracle’s data centers if OpenAI did not take up the full amount it had contracted for.&lt;/p&gt;
&lt;p&gt;“We have a customer base with a lot of demand such that whenever we find ourselves [with] capacity that’s not being used, it very quickly gets allocated,” he said.&lt;/p&gt;
&lt;p&gt;Co-founded by Ellison as a business software provider, Oracle was slow to pivot to cloud computing. The billionaire remains chair and its largest shareholder.&lt;/p&gt;
&lt;p&gt;Investors and analysts have raised concerns in recent months about the upfront spending required by Oracle to honor its AI infrastructure contracts. Moody’s in September flagged the company’s reliance on a small number of large customers such as OpenAI.&lt;/p&gt;
&lt;p&gt;Morgan Stanley forecasts that Oracle’s net debt will soar to about $290 billion by 2028. The company sold $18 billion of bonds in September and is in talks to raise $38 billion in debt financing through a number of US banks.&lt;/p&gt;
&lt;p&gt;Brent Thill, an analyst at Jefferies, said Oracle’s software business—which generated $5.9 billion in the quarter—provided some buffer amid accelerated spending. “But the timing mismatch between upfront capex and delayed monetization creates near-term pressure.”&lt;/p&gt;
&lt;p&gt;Doug Kehring, principal financial officer, said the company was renting capacity from data center specialists to reduce its direct borrowing.&lt;/p&gt;
&lt;p&gt;The debt to build the Abilene site was raised by start-up Crusoe and investment group Blue Owl Capital, and Oracle has signed a 15-year lease for the site.&lt;/p&gt;
&lt;p&gt;“Oracle does not pay for these leases until the completed data centers… are delivered to us,” Kehring said, adding that the company was “committed to maintaining our investment-grade debt ratings.”&lt;/p&gt;
&lt;p&gt;&lt;em&gt;© 2025 The Financial Times Ltd. All rights reserved. Not to be redistributed, copied, or modified in any way.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/information-technology/2025/12/oracle-shares-slide-on-15b-increase-in-data-center-spending/</guid><pubDate>Thu, 11 Dec 2025 14:39:21 +0000</pubDate></item><item><title>[NEW] Disney signs deal with OpenAI to allow Sora to generate AI videos featuring its characters (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/11/disney-signs-deal-with-openai-to-allow-sora-to-generate-ai-videos-featuring-its-characters/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/GettyImages-1387623215.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The Walt Disney Company announced on Thursday that it has signed a three-year partnership with OpenAI that will bring its iconic characters to the company’s Sora AI video generator. Disney is also making a $1 billion equity investment in OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Launched in September, Sora allows users to create short videos using simple prompts. With this new agreement, users will be able to draw on more than 200 animated, masked, and creature characters from Disney, Marvel, Pixar, and Star Wars, including costumes, props, vehicles, and more.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;These characters include iconic faces like Mickey Mouse, Ariel, Belle, Cinderella, Baymax, and Simba, as well as characters from Encanto, Frozen, Inside Out, Moana, Monsters, Inc., Toy Story, Up, and Zootopia. Users will also be able to draw on animated or illustrated versions of Marvel and Lucasfilm characters like Black Panther, Captain America, Deadpool, Groot, Iron Man, Darth Vader, Han Solo, Stormtroopers, and more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users will also be able to draw on these characters while using ChatGPT Images, the feature in ChatGPT that allows users to create visuals using text prompts. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The agreement does not include any talent likenesses or voices, Disney says. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The rapid advancement of artificial intelligence marks an important moment for our industry, and through this collaboration with OpenAI we will thoughtfully and responsibly extend the reach of our storytelling through generative AI, while respecting and protecting creators and their works,” said Disney CEO Bob Iger in a statement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Disney says that alongside the agreement, it will “become a major customer of OpenAI,” as it will use&amp;nbsp;its APIs to build new products, tools, and experiences, including for Disney+.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“Disney is the global gold standard for storytelling, and we’re excited to partner to allow Sora and ChatGPT Images to expand the way people create and experience great content,” said Sam Altman, co-founder and CEO of OpenAI, in a statement. “This agreement shows how AI companies and creative leaders can work together responsibly to promote innovation that benefits society, respect the importance of creativity, and help works reach vast new audiences.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s worth noting that Disney has sued the generative AI platform Midjourney for ignoring requests to stop violating its intellectual property rights. Disney also sent a cease-and-desist letter to Character.AI, urging the chatbot company to remove Disney characters from among the millions of AI companions on its platform.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Disney’s agreement with OpenAI indicates the company isn’t fully closing the door on AI platforms.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/GettyImages-1387623215.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The Walt Disney Company announced on Thursday that it has signed a three-year partnership with OpenAI that will bring its iconic characters to the company’s Sora AI video generator. Disney is also making a $1 billion equity investment in OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Launched in September, Sora allows users to create short videos using simple prompts. With this new agreement, users will be able to draw on more than 200 animated, masked, and creature characters from Disney, Marvel, Pixar, and Star Wars, including costumes, props, vehicles, and more.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;These characters include iconic faces like Mickey Mouse, Ariel, Belle, Cinderella, Baymax, and Simba, as well as characters from Encanto, Frozen, Inside Out, Moana, Monsters, Inc., Toy Story, Up, and Zootopia. Users will also be able to draw on animated or illustrated versions of Marvel and Lucasfilm characters like Black Panther, Captain America, Deadpool, Groot, Iron Man, Darth Vader, Han Solo, Stormtroopers, and more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users will also be able to draw on these characters while using ChatGPT Images, the feature in ChatGPT that allows users to create visuals using text prompts. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The agreement does not include any talent likenesses or voices, Disney says. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The rapid advancement of artificial intelligence marks an important moment for our industry, and through this collaboration with OpenAI we will thoughtfully and responsibly extend the reach of our storytelling through generative AI, while respecting and protecting creators and their works,” said Disney CEO Bob Iger in a statement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Disney says that alongside the agreement, it will “become a major customer of OpenAI,” as it will use&amp;nbsp;its APIs to build new products, tools, and experiences, including for Disney+.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“Disney is the global gold standard for storytelling, and we’re excited to partner to allow Sora and ChatGPT Images to expand the way people create and experience great content,” said Sam Altman, co-founder and CEO of OpenAI, in a statement. “This agreement shows how AI companies and creative leaders can work together responsibly to promote innovation that benefits society, respect the importance of creativity, and help works reach vast new audiences.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s worth noting that Disney has sued the generative AI platform Midjourney for ignoring requests to stop violating its intellectual property rights. Disney also sent a cease-and-desist letter to Character.AI, urging the chatbot company to remove Disney characters from among the millions of AI companions on its platform.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Disney’s agreement with OpenAI indicates the company isn’t fully closing the door on AI platforms.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/11/disney-signs-deal-with-openai-to-allow-sora-to-generate-ai-videos-featuring-its-characters/</guid><pubDate>Thu, 11 Dec 2025 15:21:05 +0000</pubDate></item><item><title>[NEW] New in llama.cpp: Model Management (Hugging Face - Blog)</title><link>https://huggingface.co/blog/ggml-org/model-management-in-llamacpp</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://cdn-uploads.huggingface.co/production/uploads/5f17f0a0925b9863e28ad517/wGWbyTyYFKKGDMaAnTz7M.png" /&gt;&lt;/div&gt;&lt;!-- HTML_TAG_START --&gt;
llama.cpp server now ships with &lt;strong&gt;router mode&lt;/strong&gt;, which lets you dynamically load, unload, and switch between multiple models without restarting.
&lt;blockquote&gt;
&lt;p&gt;Reminder: llama.cpp server is a lightweight, OpenAI-compatible HTTP server for running LLMs locally.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This feature was a popular request to bring Ollama-style model management to llama.cpp. It uses a multi-process architecture where each model runs in its own process, so if one model crashes, others remain unaffected.&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Quick Start
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Start the server in router mode by &lt;strong&gt;not specifying a model&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;llama-server
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This auto-discovers models from your llama.cpp cache (&lt;code&gt;LLAMA_CACHE&lt;/code&gt; or &lt;code&gt;~/.cache/llama.cpp&lt;/code&gt;). If you've previously downloaded models via &lt;code&gt;llama-server -hf user/model&lt;/code&gt;, they'll be available automatically.&lt;/p&gt;
&lt;p&gt;You can also point to a local directory of GGUF files:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;llama-server --models-dir ./my-models
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Features
	&lt;/span&gt;
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Auto-discovery&lt;/strong&gt;: Scans your llama.cpp cache (default) or a custom &lt;code&gt;--models-dir&lt;/code&gt; folder for GGUF files&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;On-demand loading&lt;/strong&gt;: Models load automatically when first requested&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LRU eviction&lt;/strong&gt;: When you hit &lt;code&gt;--models-max&lt;/code&gt; (default: 4), the least-recently-used model unloads&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Request routing&lt;/strong&gt;: The &lt;code&gt;model&lt;/code&gt; field in your request determines which model handles it&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Examples
	&lt;/span&gt;
&lt;/h2&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Chat with a specific model
	&lt;/span&gt;
&lt;/h3&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;curl http://localhost:8080/v1/chat/completions \
  -H &lt;span class="hljs-string"&gt;"Content-Type: application/json"&lt;/span&gt; \
  -d &lt;span class="hljs-string"&gt;'{&lt;/span&gt;
&lt;span class="hljs-string"&gt;    "model": "ggml-org/gemma-3-4b-it-GGUF:Q4_K_M",&lt;/span&gt;
&lt;span class="hljs-string"&gt;    "messages": [{"role": "user", "content": "Hello!"}]&lt;/span&gt;
&lt;span class="hljs-string"&gt;  }'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;On the first request, the server automatically loads the model into memory (loading time depends on model size). Subsequent requests to the same model are instant since it's already loaded.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		List available models
	&lt;/span&gt;
&lt;/h3&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;curl http://localhost:8080/models
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Returns all discovered models with their status (&lt;code&gt;loaded&lt;/code&gt;, &lt;code&gt;loading&lt;/code&gt;, or &lt;code&gt;unloaded&lt;/code&gt;).&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Manually load a model
	&lt;/span&gt;
&lt;/h3&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -X POST http://localhost:8080/models/load \
  -H &lt;span class="hljs-string"&gt;"Content-Type: application/json"&lt;/span&gt; \
  -d &lt;span class="hljs-string"&gt;'{"model": "my-model.gguf"}'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Unload a model to free VRAM
	&lt;/span&gt;
&lt;/h3&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -X POST http://localhost:8080/models/unload \
  -H &lt;span class="hljs-string"&gt;"Content-Type: application/json"&lt;/span&gt; \
  -d &lt;span class="hljs-string"&gt;'{"model": "my-model.gguf"}'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Key Options
	&lt;/span&gt;
&lt;/h2&gt;
&lt;div class="max-w-full overflow-auto"&gt;
	&lt;table&gt;
		&lt;thead&gt;&lt;tr&gt;
&lt;th&gt;Flag&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;

		&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;&lt;code&gt;--models-dir PATH&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Directory containing your GGUF files&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;--models-max N&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Max models loaded simultaneously (default: 4)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;--no-models-autoload&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Disable auto-loading; require explicit &lt;code&gt;/models/load&lt;/code&gt; calls&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
	&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;All model instances inherit settings from the router:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;llama-server --models-dir ./models -c 8192 -ngl 99
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All loaded models will use 8192 context and full GPU offload. You can also define per-model settings using presets:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;llama-server --models-preset config.ini
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class="language-ini"&gt;&lt;span class="hljs-section"&gt;[my-model]&lt;/span&gt;
&lt;span class="hljs-attr"&gt;model&lt;/span&gt; = /path/to/model.gguf
&lt;span class="hljs-attr"&gt;ctx-size&lt;/span&gt; = &lt;span class="hljs-number"&gt;65536&lt;/span&gt;
&lt;span class="hljs-attr"&gt;temp&lt;/span&gt; = &lt;span class="hljs-number"&gt;0.7&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Also available in the Web UI
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;The built-in web UI also supports model switching. Just select a model from the dropdown and it loads automatically.&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Join the Conversation
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;We hope this feature makes it easier to A/B test different model versions, run multi-tenant deployments, or simply switch models during development without restarting the server.&lt;/p&gt;
&lt;p&gt;Have questions or feedback? Drop a comment below or open an issue on GitHub.&lt;/p&gt;
&lt;!-- HTML_TAG_END --&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://cdn-uploads.huggingface.co/production/uploads/5f17f0a0925b9863e28ad517/wGWbyTyYFKKGDMaAnTz7M.png" /&gt;&lt;/div&gt;&lt;!-- HTML_TAG_START --&gt;
llama.cpp server now ships with &lt;strong&gt;router mode&lt;/strong&gt;, which lets you dynamically load, unload, and switch between multiple models without restarting.
&lt;blockquote&gt;
&lt;p&gt;Reminder: llama.cpp server is a lightweight, OpenAI-compatible HTTP server for running LLMs locally.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This feature was a popular request to bring Ollama-style model management to llama.cpp. It uses a multi-process architecture where each model runs in its own process, so if one model crashes, others remain unaffected.&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Quick Start
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Start the server in router mode by &lt;strong&gt;not specifying a model&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;llama-server
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This auto-discovers models from your llama.cpp cache (&lt;code&gt;LLAMA_CACHE&lt;/code&gt; or &lt;code&gt;~/.cache/llama.cpp&lt;/code&gt;). If you've previously downloaded models via &lt;code&gt;llama-server -hf user/model&lt;/code&gt;, they'll be available automatically.&lt;/p&gt;
&lt;p&gt;You can also point to a local directory of GGUF files:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;llama-server --models-dir ./my-models
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Features
	&lt;/span&gt;
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Auto-discovery&lt;/strong&gt;: Scans your llama.cpp cache (default) or a custom &lt;code&gt;--models-dir&lt;/code&gt; folder for GGUF files&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;On-demand loading&lt;/strong&gt;: Models load automatically when first requested&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LRU eviction&lt;/strong&gt;: When you hit &lt;code&gt;--models-max&lt;/code&gt; (default: 4), the least-recently-used model unloads&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Request routing&lt;/strong&gt;: The &lt;code&gt;model&lt;/code&gt; field in your request determines which model handles it&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Examples
	&lt;/span&gt;
&lt;/h2&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Chat with a specific model
	&lt;/span&gt;
&lt;/h3&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;curl http://localhost:8080/v1/chat/completions \
  -H &lt;span class="hljs-string"&gt;"Content-Type: application/json"&lt;/span&gt; \
  -d &lt;span class="hljs-string"&gt;'{&lt;/span&gt;
&lt;span class="hljs-string"&gt;    "model": "ggml-org/gemma-3-4b-it-GGUF:Q4_K_M",&lt;/span&gt;
&lt;span class="hljs-string"&gt;    "messages": [{"role": "user", "content": "Hello!"}]&lt;/span&gt;
&lt;span class="hljs-string"&gt;  }'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;On the first request, the server automatically loads the model into memory (loading time depends on model size). Subsequent requests to the same model are instant since it's already loaded.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		List available models
	&lt;/span&gt;
&lt;/h3&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;curl http://localhost:8080/models
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Returns all discovered models with their status (&lt;code&gt;loaded&lt;/code&gt;, &lt;code&gt;loading&lt;/code&gt;, or &lt;code&gt;unloaded&lt;/code&gt;).&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Manually load a model
	&lt;/span&gt;
&lt;/h3&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -X POST http://localhost:8080/models/load \
  -H &lt;span class="hljs-string"&gt;"Content-Type: application/json"&lt;/span&gt; \
  -d &lt;span class="hljs-string"&gt;'{"model": "my-model.gguf"}'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Unload a model to free VRAM
	&lt;/span&gt;
&lt;/h3&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -X POST http://localhost:8080/models/unload \
  -H &lt;span class="hljs-string"&gt;"Content-Type: application/json"&lt;/span&gt; \
  -d &lt;span class="hljs-string"&gt;'{"model": "my-model.gguf"}'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Key Options
	&lt;/span&gt;
&lt;/h2&gt;
&lt;div class="max-w-full overflow-auto"&gt;
	&lt;table&gt;
		&lt;thead&gt;&lt;tr&gt;
&lt;th&gt;Flag&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;

		&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;&lt;code&gt;--models-dir PATH&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Directory containing your GGUF files&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;--models-max N&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Max models loaded simultaneously (default: 4)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;--no-models-autoload&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Disable auto-loading; require explicit &lt;code&gt;/models/load&lt;/code&gt; calls&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
	&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;All model instances inherit settings from the router:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;llama-server --models-dir ./models -c 8192 -ngl 99
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All loaded models will use 8192 context and full GPU offload. You can also define per-model settings using presets:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;llama-server --models-preset config.ini
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class="language-ini"&gt;&lt;span class="hljs-section"&gt;[my-model]&lt;/span&gt;
&lt;span class="hljs-attr"&gt;model&lt;/span&gt; = /path/to/model.gguf
&lt;span class="hljs-attr"&gt;ctx-size&lt;/span&gt; = &lt;span class="hljs-number"&gt;65536&lt;/span&gt;
&lt;span class="hljs-attr"&gt;temp&lt;/span&gt; = &lt;span class="hljs-number"&gt;0.7&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Also available in the Web UI
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;The built-in web UI also supports model switching. Just select a model from the dropdown and it loads automatically.&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Join the Conversation
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;We hope this feature makes it easier to A/B test different model versions, run multi-tenant deployments, or simply switch models during development without restarting the server.&lt;/p&gt;
&lt;p&gt;Have questions or feedback? Drop a comment below or open an issue on GitHub.&lt;/p&gt;
&lt;!-- HTML_TAG_END --&gt;</content:encoded><guid isPermaLink="false">https://huggingface.co/blog/ggml-org/model-management-in-llamacpp</guid><pubDate>Thu, 11 Dec 2025 15:47:44 +0000</pubDate></item><item><title>[NEW] Disney invests $1 billion in OpenAI, licenses 200 characters for AI video app Sora (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/12/disney-invests-1-billion-in-openai-licenses-200-characters-for-ai-video-app-sora/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Three-year deal lets users create AI videos of Mickey Mouse, Darth Vader, and more.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A visitor examines a sculpture at &amp;quot;Mickey: The True Original &amp;amp; Ever Curious&amp;quot; exhibition on July 26, 2022 in Beijing, China." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/disney_1-640x360.jpg" width="640" /&gt;
                  &lt;img alt="A visitor examines a sculpture at &amp;quot;Mickey: The True Original &amp;amp; Ever Curious&amp;quot; exhibition on July 26, 2022 in Beijing, China." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/disney_1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A visitor examines a sculpture at "Mickey: The True Original &amp;amp; Ever Curious" exhibition on July 26, 2022, in Beijing, China.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          China News Service via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Thursday, The Walt Disney Company announced a $1 billion investment in OpenAI and a three-year licensing agreement that will allow users of OpenAI’s Sora video generator to create short clips featuring more than 200 Disney, Marvel, Pixar, and Star Wars characters. It’s the first major content licensing partnership between a Hollywood studio related to the most recent version of OpenAI’s AI video platform, which drew criticism from some parts of the entertainment industry when it launched in late September.&lt;/p&gt;
&lt;p&gt;“Technological innovation has continually shaped the evolution of entertainment, bringing with it new ways to create and share great stories with the world,” said Disney CEO Robert A. Iger in the announcement. “The rapid advancement of artificial intelligence marks an important moment for our industry, and through this collaboration with OpenAI we will thoughtfully and responsibly extend the reach of our storytelling through generative AI, while respecting and protecting creators and their works.”&lt;/p&gt;
&lt;p&gt;The deal creates interesting bedfellows between a company that basically defined modern US copyright policy through congressional lobbying back in the 1990s and one that has argued in a submission to the UK House of Lords that useful AI models cannot be created without copyrighted material.&lt;/p&gt;
&lt;p&gt;Tech companies that build AI models traditionally gather those materials without rightsholder permission due to the sheer number of examples needed to train a reasonably useful generative AI model. However, since breaking out with the mainstream success of ChatGPT and becoming flush with investment cash (and facing some gnarly lawsuits), OpenAI in particular has taken steps to license content from IP owners after the fact.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2120254 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="An AI-generated version of OpenAI CEO Sam Altman, seen in a still capture from a video generated by Sora 2." class="center large" height="623" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/fake_altman-1024x623.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      An AI-generated version of OpenAI CEO Sam Altman seen in a still capture from a video generated by Sora 2.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Under the new agreement with Disney, Sora users will be able to generate short videos using characters such as Mickey Mouse, Darth Vader, Iron Man, Simba, and characters from franchises including &lt;em&gt;Frozen&lt;/em&gt;, &lt;em&gt;Inside Out&lt;/em&gt;, &lt;em&gt;Toy Story&lt;/em&gt;, and &lt;em&gt;The Mandalorian&lt;/em&gt;, along with costumes, props, vehicles, and environments.&lt;/p&gt;
&lt;p&gt;The ChatGPT image generator will also gain official access to the same intellectual property, although that information was trained into these AI models long ago. What’s changing is that OpenAI will allow Disney-related content generated by its AI models to officially pass through its content moderation filters and reach the user, sanctioned by Disney.&lt;/p&gt;
&lt;p&gt;On Disney’s end of the deal, the company plans to deploy ChatGPT for its employees and use OpenAI’s technology to build new features for Disney+. A curated selection of fan-made Sora videos will stream on the Disney+ platform starting in early 2026.&lt;/p&gt;
&lt;p&gt;The agreement does not include any talent likenesses or voices. Disney and OpenAI said they have committed to “maintaining robust controls to prevent the generation of illegal or harmful content” and to “respect the rights of individuals to appropriately control the use of their voice and likeness.”&lt;/p&gt;
&lt;p&gt;OpenAI CEO Sam Altman called the deal a model for collaboration between AI companies and studios. “This agreement shows how AI companies and creative leaders can work together responsibly to promote innovation that benefits society, respect the importance of creativity, and help works reach vast new audiences,” Altman said.&lt;/p&gt;
&lt;h2&gt;From adversary to partner&lt;/h2&gt;
&lt;p&gt;Money opens all kinds of doors, and the new partnership represents a dramatic reversal in Disney’s approach to OpenAI from just a few months ago. At that time, Disney and other major studios refused to participate in Sora 2 following its launch on September 30.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;OpenAI’s initial policy allowed copyrighted characters to appear in user-generated videos unless rights holders explicitly opted out. The LA Times reported that OpenAI had contacted talent agencies and studios before the launch, telling them that IP holders “would have to explicitly ask OpenAI not to include their copyright material in videos the tool creates.”&lt;/p&gt;
&lt;p&gt;Hollywood’s response to Sora 2 was swift and generally negative. According to CNBC, the Creative Artists Agency called it a “significant risk” to its clients, while United Talent Agency labeled it “exploitation, not innovation.” The WME talent agency sent a memo to agents notifying OpenAI that all of the agency’s clients were opted out of Sora. The Motion Picture Association also demanded “immediate and decisive action” from OpenAI.&lt;/p&gt;
&lt;p&gt;OpenAI CEO Sam Altman reversed course within days of the reaction, promising to give rights holders “more granular control” and floating a potential revenue-sharing model. The company also partnered with actor Bryan Cranston and SAG-AFTRA in October to implement new safety guardrails around likeness rights.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2131491 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="OpenAI and Disney announcement graphic." class="center large" height="576" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/OAI_Disney_Hero_16x9-1024x576.webp" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          OpenAI

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;While Disney and OpenAI are apparently friends now, the company has simultaneously taken an aggressive stance against some AI companies it has not partnered with.&lt;/p&gt;
&lt;p&gt;On Wednesday, Disney sent a cease-and-desist letter to Google, accusing the company of “infringing Disney’s copyrights on a massive scale” through its AI services, including YouTube. Disney has also sent similar letters to Meta and Character.AI and filed lawsuits against image-synthesis service Midjourney alongside NBCUniversal and Warner Bros. Discovery.&lt;/p&gt;
&lt;p&gt;A few major questions about the deal remain unanswered, including the actual licensing fees, whether Disney content will be used to train future OpenAI models, and whether this deal is even finalized. The announcement also notes it remains “subject to negotiation of definitive agreements,” so expect potential updates or clarifications ahead.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Three-year deal lets users create AI videos of Mickey Mouse, Darth Vader, and more.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A visitor examines a sculpture at &amp;quot;Mickey: The True Original &amp;amp; Ever Curious&amp;quot; exhibition on July 26, 2022 in Beijing, China." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/disney_1-640x360.jpg" width="640" /&gt;
                  &lt;img alt="A visitor examines a sculpture at &amp;quot;Mickey: The True Original &amp;amp; Ever Curious&amp;quot; exhibition on July 26, 2022 in Beijing, China." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/disney_1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A visitor examines a sculpture at "Mickey: The True Original &amp;amp; Ever Curious" exhibition on July 26, 2022, in Beijing, China.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          China News Service via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Thursday, The Walt Disney Company announced a $1 billion investment in OpenAI and a three-year licensing agreement that will allow users of OpenAI’s Sora video generator to create short clips featuring more than 200 Disney, Marvel, Pixar, and Star Wars characters. It’s the first major content licensing partnership between a Hollywood studio related to the most recent version of OpenAI’s AI video platform, which drew criticism from some parts of the entertainment industry when it launched in late September.&lt;/p&gt;
&lt;p&gt;“Technological innovation has continually shaped the evolution of entertainment, bringing with it new ways to create and share great stories with the world,” said Disney CEO Robert A. Iger in the announcement. “The rapid advancement of artificial intelligence marks an important moment for our industry, and through this collaboration with OpenAI we will thoughtfully and responsibly extend the reach of our storytelling through generative AI, while respecting and protecting creators and their works.”&lt;/p&gt;
&lt;p&gt;The deal creates interesting bedfellows between a company that basically defined modern US copyright policy through congressional lobbying back in the 1990s and one that has argued in a submission to the UK House of Lords that useful AI models cannot be created without copyrighted material.&lt;/p&gt;
&lt;p&gt;Tech companies that build AI models traditionally gather those materials without rightsholder permission due to the sheer number of examples needed to train a reasonably useful generative AI model. However, since breaking out with the mainstream success of ChatGPT and becoming flush with investment cash (and facing some gnarly lawsuits), OpenAI in particular has taken steps to license content from IP owners after the fact.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2120254 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="An AI-generated version of OpenAI CEO Sam Altman, seen in a still capture from a video generated by Sora 2." class="center large" height="623" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/fake_altman-1024x623.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      An AI-generated version of OpenAI CEO Sam Altman seen in a still capture from a video generated by Sora 2.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Under the new agreement with Disney, Sora users will be able to generate short videos using characters such as Mickey Mouse, Darth Vader, Iron Man, Simba, and characters from franchises including &lt;em&gt;Frozen&lt;/em&gt;, &lt;em&gt;Inside Out&lt;/em&gt;, &lt;em&gt;Toy Story&lt;/em&gt;, and &lt;em&gt;The Mandalorian&lt;/em&gt;, along with costumes, props, vehicles, and environments.&lt;/p&gt;
&lt;p&gt;The ChatGPT image generator will also gain official access to the same intellectual property, although that information was trained into these AI models long ago. What’s changing is that OpenAI will allow Disney-related content generated by its AI models to officially pass through its content moderation filters and reach the user, sanctioned by Disney.&lt;/p&gt;
&lt;p&gt;On Disney’s end of the deal, the company plans to deploy ChatGPT for its employees and use OpenAI’s technology to build new features for Disney+. A curated selection of fan-made Sora videos will stream on the Disney+ platform starting in early 2026.&lt;/p&gt;
&lt;p&gt;The agreement does not include any talent likenesses or voices. Disney and OpenAI said they have committed to “maintaining robust controls to prevent the generation of illegal or harmful content” and to “respect the rights of individuals to appropriately control the use of their voice and likeness.”&lt;/p&gt;
&lt;p&gt;OpenAI CEO Sam Altman called the deal a model for collaboration between AI companies and studios. “This agreement shows how AI companies and creative leaders can work together responsibly to promote innovation that benefits society, respect the importance of creativity, and help works reach vast new audiences,” Altman said.&lt;/p&gt;
&lt;h2&gt;From adversary to partner&lt;/h2&gt;
&lt;p&gt;Money opens all kinds of doors, and the new partnership represents a dramatic reversal in Disney’s approach to OpenAI from just a few months ago. At that time, Disney and other major studios refused to participate in Sora 2 following its launch on September 30.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;OpenAI’s initial policy allowed copyrighted characters to appear in user-generated videos unless rights holders explicitly opted out. The LA Times reported that OpenAI had contacted talent agencies and studios before the launch, telling them that IP holders “would have to explicitly ask OpenAI not to include their copyright material in videos the tool creates.”&lt;/p&gt;
&lt;p&gt;Hollywood’s response to Sora 2 was swift and generally negative. According to CNBC, the Creative Artists Agency called it a “significant risk” to its clients, while United Talent Agency labeled it “exploitation, not innovation.” The WME talent agency sent a memo to agents notifying OpenAI that all of the agency’s clients were opted out of Sora. The Motion Picture Association also demanded “immediate and decisive action” from OpenAI.&lt;/p&gt;
&lt;p&gt;OpenAI CEO Sam Altman reversed course within days of the reaction, promising to give rights holders “more granular control” and floating a potential revenue-sharing model. The company also partnered with actor Bryan Cranston and SAG-AFTRA in October to implement new safety guardrails around likeness rights.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2131491 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="OpenAI and Disney announcement graphic." class="center large" height="576" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/OAI_Disney_Hero_16x9-1024x576.webp" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          OpenAI

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;While Disney and OpenAI are apparently friends now, the company has simultaneously taken an aggressive stance against some AI companies it has not partnered with.&lt;/p&gt;
&lt;p&gt;On Wednesday, Disney sent a cease-and-desist letter to Google, accusing the company of “infringing Disney’s copyrights on a massive scale” through its AI services, including YouTube. Disney has also sent similar letters to Meta and Character.AI and filed lawsuits against image-synthesis service Midjourney alongside NBCUniversal and Warner Bros. Discovery.&lt;/p&gt;
&lt;p&gt;A few major questions about the deal remain unanswered, including the actual licensing fees, whether Disney content will be used to train future OpenAI models, and whether this deal is even finalized. The announcement also notes it remains “subject to negotiation of definitive agreements,” so expect potential updates or clarifications ahead.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/12/disney-invests-1-billion-in-openai-licenses-200-characters-for-ai-video-app-sora/</guid><pubDate>Thu, 11 Dec 2025 16:43:30 +0000</pubDate></item><item><title>[NEW] Agent Lightning: Adding reinforcement learning to AI agents without code rewrites (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/blog/agent-lightning-adding-reinforcement-learning-to-ai-agents-without-code-rewrites/</link><description>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Three white line icons on a blue-to-purple gradient background: the first icon shows a simple flowchart with connected squares and a diamond, the second icon shows a network of interconnected circles, and the third icon shows three user profile symbols linked together." class="wp-image-1158206" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/12/AgentLightning-BlogHeroFeature-1400x788_NEW.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;p&gt;AI agents are reshaping software development, from writing code to carrying out complex instructions. Yet LLM-based agents are prone to errors and often perform poorly on complicated, multi-step tasks. Reinforcement learning (RL) is an approach where AI systems learn to make optimal decisions by receiving rewards or penalties for their actions, improving through trial and error. RL can help agents improve, but it typically requires developers to extensively rewrite their code. This discourages adoption, even though the data these agents generate could significantly boost performance through RL training.&lt;/p&gt;



&lt;p&gt;To address this, a research team from Microsoft Research Asia – Shanghai has introduced Agent Lightning. This open-source&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; framework makes AI agents trainable through RL by separating how agents execute tasks from model training, allowing developers to add RL capabilities with virtually no code modification.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="capturing-agent-behavior-for-training"&gt;Capturing agent behavior for training&lt;/h2&gt;



&lt;p&gt;Agent Lightning converts an agent’s experience into a format that RL can use by treating the agent’s execution as a sequence of states and actions, where each state captures the agent’s status and each LLM call is an action that moves the agent to a new state.&lt;/p&gt;



&lt;p&gt;This approach works for any workflow, no matter how complex. Whether it involves multiple collaborating agents or dynamic tool use, Agent Lightning breaks it down into a sequence of transitions. Each transition captures the LLM’s input, output, and reward (Figure 1). This standardized format means the data can be used for training without any&amp;nbsp;additional&amp;nbsp;steps.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 1: Diagram illustrating Agent Lightning’s unified data interface for a retrieval-augmented generation (RAG) agent. On the left, four states (state₀ to state₃) show the agent’s execution flow, where semantic variables—UserInput, Query, Passages, and Answer—are updated after each component call (LLM or Search). Green blocks represent populated variables; gray blocks indicate empty ones. On the right, the unified data interface converts these transitions into a trajectory format containing prompt, generation, and immediate reward for RL training. " class="wp-image-1158102" height="891" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/12/figure-1-scaled.jpg" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 1. An illustration of Agent Lightning’s standardized format using a retrieval-augmented generation (RAG) agent. Left: The full agent workflow, where the agent’s state updates after each component step. The green blocks show assigned variables, and the gray blocks indicate variables without content. Right: The collected transitions are based on the standardized format for the RL training process, with each transition corresponding to one LLM step that contains its prompt, result, and immediate reward.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="hierarchical-reinforcement-learning"&gt;Hierarchical reinforcement learning&lt;/h2&gt;



&lt;p&gt;Traditional RL training for agents that make multiple LLM requests involves stitching together all content into one long sequence and then identifying which parts should be learned and which ignored during training. This approach is difficult to implement and can create excessively long sequences that degrade model performance.&lt;/p&gt;



&lt;p&gt;Instead, Agent Lightning’s LightningRL algorithm takes a hierarchical approach. After a task completes, a credit assignment module determines how much each LLM request contributed to the outcome and assigns it a corresponding reward. These independent steps, now paired with their own reward scores, can be used with any existing single-step RL algorithm, such as Proximal Policy Optimization (PPO) or Group Relative Policy Optimization (GRPO) (Figure 2).&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 2: Comparison of three reinforcement learning approaches for LLM tasks. (a) Single-step GRPO: The model completes the task in one call, and multiple outputs for the same task are compared with associated rewards. (b) Previous multi-step GRPO: The task spans multiple LLM calls, forming trajectories; non-LLM tokens (gray boxes) are ignored during training, and entire multi-step runs are compared. (c) LightningRL: Breaks multi-step runs into individual LLM calls, each including input, context, output, and reward assigned by a credit assignment module. Calls from the same task are grouped for reinforcement. " class="wp-image-1158259" height="835" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/12/figure-2-new-scaled.jpg" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 2. (a) Single-step GRPO: The LLM completes the task in one call. Multiple responses for the same task are compared to determine how strongly each should be reinforced. (b) Previous multi-step GRPO: The task involves multiple LLM calls. Multiple multi-step runs of the same task are compared, with non-LLM generated tokens (grey boxes) ignored during training. (c) LightningRL: The multi-step run is divided into individual LLM calls. Calls from the same task are compared to determine how strongly each should be reinforced. Each call includes its input, context, output, and reward, assigned by the credit assignment module.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;This design offers several benefits. It remains fully compatible with widely used single-step RL algorithms, allowing existing training methods to be applied without modification. Organizing data as a sequence of independent transitions lets developers flexibly construct the LLM input as needed, supporting complex behaviors like agents that use multiple tools or&amp;nbsp;work&amp;nbsp;with other agents. Additionally, by keeping sequences short, the approach scales cleanly and keeps training efficient.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="agent-lightning-as-middleware"&gt;Agent Lightning as middleware&lt;/h2&gt;



&lt;p&gt;Agent Lightning serves as middleware between RL algorithms and agent environments, providing modular components that enable scalable RL through standardized protocols and well-defined interfaces.&lt;/p&gt;



&lt;p&gt;An &lt;strong&gt;agent runner&lt;/strong&gt; manages the agents as they complete tasks. It distributes work and collects and stores the results and progress data. It operates separately from the LLMs, enabling them to run on different resources and scale to support multiple agents running concurrently.&lt;/p&gt;



&lt;p&gt;An &lt;strong&gt;algorithm&lt;/strong&gt; trains the models and hosts the LLMs used for inference and training. It orchestrates the overall RL cycle, managing which tasks are assigned, how agents complete them, and how models are updated based on what the agents learn. It typically runs on GPU resources and communicates with the agent runner through shared protocols.&lt;/p&gt;



&lt;p&gt;The LightningStore&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; serves as the central repository for all data exchanges within the system. It provides standardized interfaces and a shared format, ensuring that the different components can work together and enabling the algorithm and agent runner to communicate effectively.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 3: Diagram showing the architecture of Agent Lightning (AGL). On the left, the AGL Algorithm block includes an inference engine (e.g., vLLM), an algorithm iteration loop, and an adapter for trainable data and weights update. In the center, the AGL Core contains LightningStore, which manages tasks, resources, spans, and LLM calls. On the right, the AGL Agent Runner &amp;amp; Tracer includes a user-defined agent using OpenAI chat completion and agl.emit(). Arrows indicate flows of prompts, responses, tasks, resources, spans, and datasets between components, with roles for algorithm researchers and agent developers highlighted. " class="wp-image-1158104" height="942" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/12/figure-3-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 3. The Agent Lightning framework&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;All RL cycles follow two steps: (1) Agent Lightning collects agent execution data (called “spans”) and store them in the data store; (2) it then retrieves the required data and sends it to the algorithm for training. Through this design, the algorithm can delegate tasks asynchronously to the agent runner, which completes them and reports the results back (Figure 4).&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Figure 4: Diagram of the training loop in Agent Lightning. The central element is ‘Trainer,’ with arrows forming a cycle between three components: Agent on the left, Algorithm on the right, and Trainer in the middle. The top arrow labeled ‘Tasks’ flows from Algorithm to Agent, while the bottom arrow labeled ‘Spans’ flows from Agent to Algorithm. ‘Prompt Templates’ is noted above the cycle, indicating its role in task generation. " class="wp-image-1158290" height="840" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/12/figure-4-new.png" width="2347" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 4. Agent Lightning’s RL cycle&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;One key advantage of this approach is its algorithmic flexibility. The system makes it easy for developers to customize how agents learn, whether they’re defining different rewards, capturing intermediate data, or experimenting with different training approaches.&lt;/p&gt;



&lt;p&gt;Another advantage is resource efficiency. Agentic RL systems are complex, integrating agentic systems, LLM inference engines, and training frameworks. By separating these components, Agent Lightning makes this complexity manageable and allows each part to be optimized independently&lt;/p&gt;



&lt;p&gt;A decoupled design allows each component to use the hardware that suits it best. The agent runner can use CPUs while model training uses GPUs. Each component can also scale independently, improving efficiency and making the system easier to maintain. In practice, developers can keep their existing agent frameworks and switch model calls to the Agent Lightning API without changing their agent code (Figure 5). &lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 5: Side-by-side code comparison showing agent implementation before and after integrating Agent Lightning. The left panel (dark background) displays the original agent code written by the developer, including logic for LLM calls, tool usage, and reward assignment. The right panel (light background) shows the modified version using Agent Lightning, where most of the agent logic remains unchanged but includes additional imports and calls to Agent Lightning components such as agl.PromptTemplate, agl.emit(), and agl.Trainer for training and credit assignment. A stylized lightning icon is centered between the two panels. " class="wp-image-1158107" height="1024" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/12/figure-5-new.png" width="1238" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 5. On the left, the developer implements the agent code. On the bottom right is the code required for Agent Lightning. The main body of the agent code is unchanged.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="evaluation-across-three-real-world-scenarios"&gt;Evaluation across three real-world scenarios&lt;/h2&gt;



&lt;p&gt;Agent Lightning was tested on three distinct tasks, achieving consistent performance improvements across all scenarios (Figure 6):&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Text-to-SQL (LangChain):&lt;/strong&gt; In a system with three agents handling SQL generation, checking, and rewriting, Agent Lightning simultaneously optimized two of them, significantly improving the accuracy of generating executable SQL from natural language queries.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Retrieval-augmented generation (OpenAI Agents SDK implementation):&lt;/strong&gt; On the multi-hop question-answering dataset MuSiQue, which requires querying a large Wikipedia database, Agent Lightning helped the agent generate more effective search queries and reason better from retrieved content.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Mathematical QA and tool use (AutoGen implementation):&lt;/strong&gt; For complex math problems, Agent Lightning trained LLMs to more accurately determine when and how to call the tool and integrate the results into its reasoning, increasing accuracy.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 6: Figure with six line charts showing reward curves across three evaluation scenarios (Spider, MuSiQue, Calculator) for train and test splits. Top row: Train Rewards on Spider, MuSiQue, and Calculator—each plot shows a blue line with noisy upward trend over steps, indicating increasing rewards; Spider and Calculator rise faster with more variance, MuSiQue climbs more gradually. Bottom row: Test Rewards on Spider, MuSiQue, and Calculator—each plot shows a blue line that increases and then stabilizes at higher rewards; Calculator reaches near-plateau earliest, Spider shows steady gains with minor fluctuations, MuSiQue improves more slowly. All plots use ‘Steps’ on the x‑axis and ‘Rewards’ on the y‑axis, with a legend labeled ‘ours’ and light gridlines. " class="wp-image-1158109" height="1169" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/12/figure-6-scaled.jpg" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 6. Reward curves across the three evaluation scenarios&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="enabling-continuous-agent-improvement"&gt;Enabling continuous agent improvement&lt;/h2&gt;



&lt;p&gt;By simplifying RL integration, Agent Lightning can make it easier for developers to build, iterate, and deploy high-performance agents. We plan to expand Agent Lightning’s capabilities to include automatic prompt optimization and additional RL algorithms.&lt;/p&gt;



&lt;p&gt;The framework is designed to serve as an open platform where any AI agent can improve through real-world practice. By bridging existing agentic&amp;nbsp;systems with reinforcement learning, Agent Lightning aims to help create AI systems that learn from experience and improve over time.&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Three white line icons on a blue-to-purple gradient background: the first icon shows a simple flowchart with connected squares and a diamond, the second icon shows a network of interconnected circles, and the third icon shows three user profile symbols linked together." class="wp-image-1158206" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/12/AgentLightning-BlogHeroFeature-1400x788_NEW.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;p&gt;AI agents are reshaping software development, from writing code to carrying out complex instructions. Yet LLM-based agents are prone to errors and often perform poorly on complicated, multi-step tasks. Reinforcement learning (RL) is an approach where AI systems learn to make optimal decisions by receiving rewards or penalties for their actions, improving through trial and error. RL can help agents improve, but it typically requires developers to extensively rewrite their code. This discourages adoption, even though the data these agents generate could significantly boost performance through RL training.&lt;/p&gt;



&lt;p&gt;To address this, a research team from Microsoft Research Asia – Shanghai has introduced Agent Lightning. This open-source&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; framework makes AI agents trainable through RL by separating how agents execute tasks from model training, allowing developers to add RL capabilities with virtually no code modification.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="capturing-agent-behavior-for-training"&gt;Capturing agent behavior for training&lt;/h2&gt;



&lt;p&gt;Agent Lightning converts an agent’s experience into a format that RL can use by treating the agent’s execution as a sequence of states and actions, where each state captures the agent’s status and each LLM call is an action that moves the agent to a new state.&lt;/p&gt;



&lt;p&gt;This approach works for any workflow, no matter how complex. Whether it involves multiple collaborating agents or dynamic tool use, Agent Lightning breaks it down into a sequence of transitions. Each transition captures the LLM’s input, output, and reward (Figure 1). This standardized format means the data can be used for training without any&amp;nbsp;additional&amp;nbsp;steps.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 1: Diagram illustrating Agent Lightning’s unified data interface for a retrieval-augmented generation (RAG) agent. On the left, four states (state₀ to state₃) show the agent’s execution flow, where semantic variables—UserInput, Query, Passages, and Answer—are updated after each component call (LLM or Search). Green blocks represent populated variables; gray blocks indicate empty ones. On the right, the unified data interface converts these transitions into a trajectory format containing prompt, generation, and immediate reward for RL training. " class="wp-image-1158102" height="891" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/12/figure-1-scaled.jpg" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 1. An illustration of Agent Lightning’s standardized format using a retrieval-augmented generation (RAG) agent. Left: The full agent workflow, where the agent’s state updates after each component step. The green blocks show assigned variables, and the gray blocks indicate variables without content. Right: The collected transitions are based on the standardized format for the RL training process, with each transition corresponding to one LLM step that contains its prompt, result, and immediate reward.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="hierarchical-reinforcement-learning"&gt;Hierarchical reinforcement learning&lt;/h2&gt;



&lt;p&gt;Traditional RL training for agents that make multiple LLM requests involves stitching together all content into one long sequence and then identifying which parts should be learned and which ignored during training. This approach is difficult to implement and can create excessively long sequences that degrade model performance.&lt;/p&gt;



&lt;p&gt;Instead, Agent Lightning’s LightningRL algorithm takes a hierarchical approach. After a task completes, a credit assignment module determines how much each LLM request contributed to the outcome and assigns it a corresponding reward. These independent steps, now paired with their own reward scores, can be used with any existing single-step RL algorithm, such as Proximal Policy Optimization (PPO) or Group Relative Policy Optimization (GRPO) (Figure 2).&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 2: Comparison of three reinforcement learning approaches for LLM tasks. (a) Single-step GRPO: The model completes the task in one call, and multiple outputs for the same task are compared with associated rewards. (b) Previous multi-step GRPO: The task spans multiple LLM calls, forming trajectories; non-LLM tokens (gray boxes) are ignored during training, and entire multi-step runs are compared. (c) LightningRL: Breaks multi-step runs into individual LLM calls, each including input, context, output, and reward assigned by a credit assignment module. Calls from the same task are grouped for reinforcement. " class="wp-image-1158259" height="835" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/12/figure-2-new-scaled.jpg" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 2. (a) Single-step GRPO: The LLM completes the task in one call. Multiple responses for the same task are compared to determine how strongly each should be reinforced. (b) Previous multi-step GRPO: The task involves multiple LLM calls. Multiple multi-step runs of the same task are compared, with non-LLM generated tokens (grey boxes) ignored during training. (c) LightningRL: The multi-step run is divided into individual LLM calls. Calls from the same task are compared to determine how strongly each should be reinforced. Each call includes its input, context, output, and reward, assigned by the credit assignment module.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;This design offers several benefits. It remains fully compatible with widely used single-step RL algorithms, allowing existing training methods to be applied without modification. Organizing data as a sequence of independent transitions lets developers flexibly construct the LLM input as needed, supporting complex behaviors like agents that use multiple tools or&amp;nbsp;work&amp;nbsp;with other agents. Additionally, by keeping sequences short, the approach scales cleanly and keeps training efficient.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="agent-lightning-as-middleware"&gt;Agent Lightning as middleware&lt;/h2&gt;



&lt;p&gt;Agent Lightning serves as middleware between RL algorithms and agent environments, providing modular components that enable scalable RL through standardized protocols and well-defined interfaces.&lt;/p&gt;



&lt;p&gt;An &lt;strong&gt;agent runner&lt;/strong&gt; manages the agents as they complete tasks. It distributes work and collects and stores the results and progress data. It operates separately from the LLMs, enabling them to run on different resources and scale to support multiple agents running concurrently.&lt;/p&gt;



&lt;p&gt;An &lt;strong&gt;algorithm&lt;/strong&gt; trains the models and hosts the LLMs used for inference and training. It orchestrates the overall RL cycle, managing which tasks are assigned, how agents complete them, and how models are updated based on what the agents learn. It typically runs on GPU resources and communicates with the agent runner through shared protocols.&lt;/p&gt;



&lt;p&gt;The LightningStore&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; serves as the central repository for all data exchanges within the system. It provides standardized interfaces and a shared format, ensuring that the different components can work together and enabling the algorithm and agent runner to communicate effectively.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 3: Diagram showing the architecture of Agent Lightning (AGL). On the left, the AGL Algorithm block includes an inference engine (e.g., vLLM), an algorithm iteration loop, and an adapter for trainable data and weights update. In the center, the AGL Core contains LightningStore, which manages tasks, resources, spans, and LLM calls. On the right, the AGL Agent Runner &amp;amp; Tracer includes a user-defined agent using OpenAI chat completion and agl.emit(). Arrows indicate flows of prompts, responses, tasks, resources, spans, and datasets between components, with roles for algorithm researchers and agent developers highlighted. " class="wp-image-1158104" height="942" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/12/figure-3-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 3. The Agent Lightning framework&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;All RL cycles follow two steps: (1) Agent Lightning collects agent execution data (called “spans”) and store them in the data store; (2) it then retrieves the required data and sends it to the algorithm for training. Through this design, the algorithm can delegate tasks asynchronously to the agent runner, which completes them and reports the results back (Figure 4).&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Figure 4: Diagram of the training loop in Agent Lightning. The central element is ‘Trainer,’ with arrows forming a cycle between three components: Agent on the left, Algorithm on the right, and Trainer in the middle. The top arrow labeled ‘Tasks’ flows from Algorithm to Agent, while the bottom arrow labeled ‘Spans’ flows from Agent to Algorithm. ‘Prompt Templates’ is noted above the cycle, indicating its role in task generation. " class="wp-image-1158290" height="840" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/12/figure-4-new.png" width="2347" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 4. Agent Lightning’s RL cycle&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;One key advantage of this approach is its algorithmic flexibility. The system makes it easy for developers to customize how agents learn, whether they’re defining different rewards, capturing intermediate data, or experimenting with different training approaches.&lt;/p&gt;



&lt;p&gt;Another advantage is resource efficiency. Agentic RL systems are complex, integrating agentic systems, LLM inference engines, and training frameworks. By separating these components, Agent Lightning makes this complexity manageable and allows each part to be optimized independently&lt;/p&gt;



&lt;p&gt;A decoupled design allows each component to use the hardware that suits it best. The agent runner can use CPUs while model training uses GPUs. Each component can also scale independently, improving efficiency and making the system easier to maintain. In practice, developers can keep their existing agent frameworks and switch model calls to the Agent Lightning API without changing their agent code (Figure 5). &lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 5: Side-by-side code comparison showing agent implementation before and after integrating Agent Lightning. The left panel (dark background) displays the original agent code written by the developer, including logic for LLM calls, tool usage, and reward assignment. The right panel (light background) shows the modified version using Agent Lightning, where most of the agent logic remains unchanged but includes additional imports and calls to Agent Lightning components such as agl.PromptTemplate, agl.emit(), and agl.Trainer for training and credit assignment. A stylized lightning icon is centered between the two panels. " class="wp-image-1158107" height="1024" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/12/figure-5-new.png" width="1238" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 5. On the left, the developer implements the agent code. On the bottom right is the code required for Agent Lightning. The main body of the agent code is unchanged.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="evaluation-across-three-real-world-scenarios"&gt;Evaluation across three real-world scenarios&lt;/h2&gt;



&lt;p&gt;Agent Lightning was tested on three distinct tasks, achieving consistent performance improvements across all scenarios (Figure 6):&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Text-to-SQL (LangChain):&lt;/strong&gt; In a system with three agents handling SQL generation, checking, and rewriting, Agent Lightning simultaneously optimized two of them, significantly improving the accuracy of generating executable SQL from natural language queries.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Retrieval-augmented generation (OpenAI Agents SDK implementation):&lt;/strong&gt; On the multi-hop question-answering dataset MuSiQue, which requires querying a large Wikipedia database, Agent Lightning helped the agent generate more effective search queries and reason better from retrieved content.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Mathematical QA and tool use (AutoGen implementation):&lt;/strong&gt; For complex math problems, Agent Lightning trained LLMs to more accurately determine when and how to call the tool and integrate the results into its reasoning, increasing accuracy.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 6: Figure with six line charts showing reward curves across three evaluation scenarios (Spider, MuSiQue, Calculator) for train and test splits. Top row: Train Rewards on Spider, MuSiQue, and Calculator—each plot shows a blue line with noisy upward trend over steps, indicating increasing rewards; Spider and Calculator rise faster with more variance, MuSiQue climbs more gradually. Bottom row: Test Rewards on Spider, MuSiQue, and Calculator—each plot shows a blue line that increases and then stabilizes at higher rewards; Calculator reaches near-plateau earliest, Spider shows steady gains with minor fluctuations, MuSiQue improves more slowly. All plots use ‘Steps’ on the x‑axis and ‘Rewards’ on the y‑axis, with a legend labeled ‘ours’ and light gridlines. " class="wp-image-1158109" height="1169" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/12/figure-6-scaled.jpg" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 6. Reward curves across the three evaluation scenarios&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="enabling-continuous-agent-improvement"&gt;Enabling continuous agent improvement&lt;/h2&gt;



&lt;p&gt;By simplifying RL integration, Agent Lightning can make it easier for developers to build, iterate, and deploy high-performance agents. We plan to expand Agent Lightning’s capabilities to include automatic prompt optimization and additional RL algorithms.&lt;/p&gt;



&lt;p&gt;The framework is designed to serve as an open platform where any AI agent can improve through real-world practice. By bridging existing agentic&amp;nbsp;systems with reinforcement learning, Agent Lightning aims to help create AI systems that learn from experience and improve over time.&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/blog/agent-lightning-adding-reinforcement-learning-to-ai-agents-without-code-rewrites/</guid><pubDate>Thu, 11 Dec 2025 17:00:00 +0000</pubDate></item><item><title>[NEW] Runway releases its first world model, adds native audio to latest video model (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/11/runway-releases-its-first-world-model-adds-native-audio-to-latest-video-model/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The race to release world models is on as AI image and video generation company Runway joins an increasing number of startups and big tech companies by launching its first one. Dubbed GWM-1, the model works through frame-by-frame prediction, creating a simulation with an understanding of physics and how the world actually behaves over time, the company said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A world model is an AI system that learns an internal simulation of how the world works so it can reason, plan, and act without needing to be trained on every scenario possible in real life. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Runway, which earlier this month launched its Gen 4.5 video model that surpassed both Google and OpenAI on the Video Arena leaderboard, said its GWM-1 world model is more “general” than Google’s Genie-3 and other competitors. The firm is pitching it as a model that can create simulations to train agents in different domains like robotics and life sciences. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“To build a world model. We first needed to build a really great video model. We believe that the right path to building a world model is teaching models to predict pixels directly is the best way to achieve general-purpose simulation. At sufficient scale and with the right data, you can build a model that has sufficient understanding of how the world works,” the company’s CTO Anastasis Germanidis said during the live stream.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Runway released specific slants or versions to the new world model called GWM-Worlds, GWM-Robotics, and GWM-Avatars.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3075175" height="380" src="https://techcrunch.com/wp-content/uploads/2025/12/Worlds.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Image Credits: Runway&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Runway&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;GWM-Worlds is an app for the model that lets you create an interactive project. Users can set a scene through a prompt or an image reference, and as you explore the space, the model generates the world with an understanding of geometry, physics, and lighting. The company mentioned that the simulation runs at 24 fps and 720p resolution. Runway said that while Worlds could be useful for gaming, it’s also well-positioned to teach agents how to navigate and behave in the physical world.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With GWM-Robotics, the company aims to use synthetic data enriched with new parameters like changing  weather conditions or obstacles. Runway says this method could also reveal when and how robots might violate policies and instructions in different scenarios.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Runway is also building realistic avatars under GWM-Avatars to simulate human behavior. Companies like D-ID, Synthesia, Soul Machines, and even Google have worked on creating human avatars that look real and work in areas like communication and training.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company noted that technically Worlds, Robotics, and Avatars are separate models, but eventually it plans to merge all these into one model.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Besides releasing a new world model, the company is also updating its foundational Gen 4.5 model released earlier in the month. The new update brings native audio and long-form, multi-shot generation capabilities to the model. The company said that with this model, users can generate one-minute videos with character consistency, native dialogue, background audio, and complex shots from various angles. The company said that you can also edit existing audio and add dialogues. Plus, you can edit multi-shot videos of any length.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The Gen 4.5 update nudges Runway closer to competitor Kling’s all-in-one video suite, which also launched earlier this month, particularly around native audio and multi-shot storytelling. It also signals that video generation models are moving from prototype to production-ready tools. Runway’s updated Gen 4.5 model is available to all paid plan users. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3075176" height="383" src="https://techcrunch.com/wp-content/uploads/2025/12/G4p5.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Image Credits: Runway&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Runway&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company said that it will make GWM-Robotics available through an SDK. It added that it is in active conversation with several robotics firms and enterprises for the use of GWM-Robotics and GWM-Avatars.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The race to release world models is on as AI image and video generation company Runway joins an increasing number of startups and big tech companies by launching its first one. Dubbed GWM-1, the model works through frame-by-frame prediction, creating a simulation with an understanding of physics and how the world actually behaves over time, the company said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A world model is an AI system that learns an internal simulation of how the world works so it can reason, plan, and act without needing to be trained on every scenario possible in real life. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Runway, which earlier this month launched its Gen 4.5 video model that surpassed both Google and OpenAI on the Video Arena leaderboard, said its GWM-1 world model is more “general” than Google’s Genie-3 and other competitors. The firm is pitching it as a model that can create simulations to train agents in different domains like robotics and life sciences. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“To build a world model. We first needed to build a really great video model. We believe that the right path to building a world model is teaching models to predict pixels directly is the best way to achieve general-purpose simulation. At sufficient scale and with the right data, you can build a model that has sufficient understanding of how the world works,” the company’s CTO Anastasis Germanidis said during the live stream.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Runway released specific slants or versions to the new world model called GWM-Worlds, GWM-Robotics, and GWM-Avatars.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3075175" height="380" src="https://techcrunch.com/wp-content/uploads/2025/12/Worlds.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Image Credits: Runway&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Runway&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;GWM-Worlds is an app for the model that lets you create an interactive project. Users can set a scene through a prompt or an image reference, and as you explore the space, the model generates the world with an understanding of geometry, physics, and lighting. The company mentioned that the simulation runs at 24 fps and 720p resolution. Runway said that while Worlds could be useful for gaming, it’s also well-positioned to teach agents how to navigate and behave in the physical world.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With GWM-Robotics, the company aims to use synthetic data enriched with new parameters like changing  weather conditions or obstacles. Runway says this method could also reveal when and how robots might violate policies and instructions in different scenarios.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Runway is also building realistic avatars under GWM-Avatars to simulate human behavior. Companies like D-ID, Synthesia, Soul Machines, and even Google have worked on creating human avatars that look real and work in areas like communication and training.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company noted that technically Worlds, Robotics, and Avatars are separate models, but eventually it plans to merge all these into one model.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Besides releasing a new world model, the company is also updating its foundational Gen 4.5 model released earlier in the month. The new update brings native audio and long-form, multi-shot generation capabilities to the model. The company said that with this model, users can generate one-minute videos with character consistency, native dialogue, background audio, and complex shots from various angles. The company said that you can also edit existing audio and add dialogues. Plus, you can edit multi-shot videos of any length.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The Gen 4.5 update nudges Runway closer to competitor Kling’s all-in-one video suite, which also launched earlier this month, particularly around native audio and multi-shot storytelling. It also signals that video generation models are moving from prototype to production-ready tools. Runway’s updated Gen 4.5 model is available to all paid plan users. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3075176" height="383" src="https://techcrunch.com/wp-content/uploads/2025/12/G4p5.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Image Credits: Runway&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Runway&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company said that it will make GWM-Robotics available through an SDK. It added that it is in active conversation with several robotics firms and enterprises for the use of GWM-Robotics and GWM-Avatars.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/11/runway-releases-its-first-world-model-adds-native-audio-to-latest-video-model/</guid><pubDate>Thu, 11 Dec 2025 17:00:00 +0000</pubDate></item><item><title>[NEW] Google debuts ‘Disco,’ a Gemini-powered tool for making web apps from browser tabs (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/11/google-debuts-disco-a-gemini-powered-tool-for-making-web-apps-from-browser-tabs/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google on Thursday introduced a new AI experiment for the web browser: the Gemini-powered product, “Disco,” which helps to turn your open tabs into custom applications. With Disco, you can create what Google is calling “GenTabs,” a tool that proactively suggests interactive web apps that can help you complete tasks related to what you’re browsing, and allows you to build your own apps via written prompts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, if you’re studying a particular subject, GenTabs might suggest building a web app to visualize the information, which could help you better understand the core principles. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3075230" height="377" src="https://techcrunch.com/wp-content/uploads/2025/12/1_Solar-System.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Or, in a less academic scenario, you could use GenTabs to help you create a meal plan from a series of online recipes or help you plan a trip when you’re researching travel.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;These are things that you can already do today with some AI-powered chatbots, but GenTabs builds these custom experiences on the fly using Gemini 3, using the information in your browser and in your Gemini chat history. After the app is built, you can also continue to refine it using natural language commands.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The resulting generative elements in the GenTabs experience will link back to the original sources, Google notes. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3075228" height="377" src="https://techcrunch.com/wp-content/uploads/2025/12/3_Meal-Plan.gif?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Like others in the AI market, Google has been experimenting with bringing AI deeper into the web browsing experience. Instead of building its own standalone AI browser, like Perplexity’s Comet or ChatGPT Atlas, Google integrated its AI assistant Gemini into the Chrome browser, where it can optionally be used to ask questions about the web page you’re on.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With GenTabs, the focus is not only on what you’re currently viewing, but your overall browsing task spanning multiple tabs — whether that’s research, learning, or something else. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;However, the feature is only initially going to be available to a small number of testers through Google Labs, who will offer feedback about the experience. The company says that interesting ideas that are developed through Disco may one day find their way into other, larger Google products. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It also suggests that GenTabs will be one of many Disco features to come over time, noting that GenTabs is the “first feature” being tested. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To access Disco, users will need to join a waitlist to download the app, starting on macOS. &lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google on Thursday introduced a new AI experiment for the web browser: the Gemini-powered product, “Disco,” which helps to turn your open tabs into custom applications. With Disco, you can create what Google is calling “GenTabs,” a tool that proactively suggests interactive web apps that can help you complete tasks related to what you’re browsing, and allows you to build your own apps via written prompts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, if you’re studying a particular subject, GenTabs might suggest building a web app to visualize the information, which could help you better understand the core principles. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3075230" height="377" src="https://techcrunch.com/wp-content/uploads/2025/12/1_Solar-System.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Or, in a less academic scenario, you could use GenTabs to help you create a meal plan from a series of online recipes or help you plan a trip when you’re researching travel.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;These are things that you can already do today with some AI-powered chatbots, but GenTabs builds these custom experiences on the fly using Gemini 3, using the information in your browser and in your Gemini chat history. After the app is built, you can also continue to refine it using natural language commands.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The resulting generative elements in the GenTabs experience will link back to the original sources, Google notes. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3075228" height="377" src="https://techcrunch.com/wp-content/uploads/2025/12/3_Meal-Plan.gif?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Like others in the AI market, Google has been experimenting with bringing AI deeper into the web browsing experience. Instead of building its own standalone AI browser, like Perplexity’s Comet or ChatGPT Atlas, Google integrated its AI assistant Gemini into the Chrome browser, where it can optionally be used to ask questions about the web page you’re on.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With GenTabs, the focus is not only on what you’re currently viewing, but your overall browsing task spanning multiple tabs — whether that’s research, learning, or something else. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;However, the feature is only initially going to be available to a small number of testers through Google Labs, who will offer feedback about the experience. The company says that interesting ideas that are developed through Disco may one day find their way into other, larger Google products. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It also suggests that GenTabs will be one of many Disco features to come over time, noting that GenTabs is the “first feature” being tested. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To access Disco, users will need to join a waitlist to download the app, starting on macOS. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/11/google-debuts-disco-a-gemini-powered-tool-for-making-web-apps-from-browser-tabs/</guid><pubDate>Thu, 11 Dec 2025 18:00:00 +0000</pubDate></item><item><title>[NEW] OpenAI fires back at Google with GPT-5.2 after ‘code red’ memo (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/11/openai-fires-back-at-google-with-gpt-5-2-after-code-red-memo/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/GettyImages-2213399157.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI launched its latest frontier model, GPT-5.2, on Thursday amid increasing competition from Google, pitching it as its most advanced model yet and one designed for developers and everyday professional use.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s GPT-5.2 is coming to ChatGPT paid users and developers via the API in three flavors: Instant, a speed-optimized model for routine queries like information-seeking, writing, and translation; Thinking, which excels at complex structured work like coding, analyzing long documents, math, and planning; and Pro, the top-end model aimed at delivering maximum accuracy and reliability for difficult problems.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We designed 5.2 to unlock even more economic value for people,” Fidji Simo, OpenAI’s chief product officer, said Thursday during a briefing with journalists. “It’s better at creating spreadsheets, building presentations, writing code, perceiving images, understanding long context, using tools and then linking complex, multi-step projects.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;GPT-5.2 lands in the middle of an arms race with Google’s Gemini 3, which is topping LMArena’s leaderboard across most benchmarks (apart from coding – which Anthropic’s Claude Opus-4.5 still has on lock).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Early this month, The Information reported that CEO Sam Altman released an internal “code red” memo to staff amid ChatGPT traffic decline and concerns that it is losing consumer market share to Google. The code red called for a shift in priorities, including stalling on commitments like introducing ads and instead focusing on creating a better ChatGPT experience.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;GPT-5.2 is OpenAI’s push to reclaim leadership, even as some employees reportedly asked for the model release to be pushed back so the company could have more time to improve it. And despite indications that OpenAI would focus its attention on consumer use cases by adding more personalization and customization to ChatGPT, the launch of GPT-5.2 looks to beef up its enterprise opportunities.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is specifically targeting developers and the tooling ecosystem, aiming to become the default foundation for building AI-powered applications. Earlier this week, OpenAI released new data showing enterprise usage of its AI tools has surged dramatically over the past year.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;This comes as Gemini 3 has become tightly integrated into Google’s product and cloud ecosystem for multimodal and agentic workflows. Google this week launched managed MCP servers that make its Google and Cloud services like Maps and BigQuery easier for agents to plug into. (MCPs are the connectors between AI systems and data and tools.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says GPT-5.2 sets new benchmark scores in coding, math, science, vision, long-context reasoning, and tool-use, which the company claims could lead to “more reliable agentic workflows, production-grade code, and complex systems that operate across large contexts and real-world data.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Those capabilities put it in direct competition with Gemini 3’s Deep Think mode, which has been touted as a major reasoning advancement targeting math, logic, and science. On OpenAI’s own benchmark chart, GPT-5.2 Thinking edges out Gemini 3 and Anthropic’s Claude Opus 4.5 in nearly every listed reasoning test, from real-world software engineering tasks (SWE-Bench Pro) and doctoral-level science knowledge (GPQA Diamond) to abstract reasoning and pattern discovery (ARC-AGI suites).&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Research lead Adain Clark said that stronger math scores aren’t just about solving equations. Mathematical reasoning, he explained, is a proxy for whether a model can follow multi-step logic, keep numbers consistent over time, and avoid subtle errors that could compound over time.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“These are all properties that really matter across a wide range of different workloads,” Clark said. “Things like financial modeling, forecasting, doing an analysis of data.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;During the briefing, OpenAI product lead Max Schwarzer said GPT-5.2 “makes substantial improvements to code generation and debugging” and can walk through complex math and logic step-by-step. Coding startups like Windsurf and CharlieCode, he added, report “state-of-the-art agent coding performance” and measurable gains on complex multi-step workflows. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond coding, Schwarzer said that GPT-5.2 Thinking responses contain 38% fewer errors than its predecessor, making the model more dependable for day-to-day decision-making, research, and writing.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;GPT-5.2 appears to be less a reinvention and more of a consolidation of OpenAI’s last two upgrades. GPT-5, which dropped in August, was a reset that laid the groundwork for a unified system with a router to toggle the model between a fast default model and a deeper “Thinking” mode. November’s GPT-5.1 focused on making that system warmer, more conversational, and better suited to agentic and coding tasks. The latest model, GPT-5.2, seems to turn up the dial on all of those advancements, making it a more reliable foundation for production use.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For OpenAI, the stakes have never been higher. The company has made commitments to the tune of $1.4 trillion for AI infrastructure buildouts over the next few years to support its growth – commitments it made when it still had the first-mover advantage among AI companies. But now that Google, which lagged behind at the start, is pushing ahead, that bet might be what’s driving Altman’s ‘code red.’&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s renewed focus on reasoning models is also a risky flex. The systems behind its Thinking and Deep Research modes are more expensive to run than standard chatbots because they chew through more compute. By doubling down on that kind of model with GPT-5.2, OpenAI may be setting up a vicious cycle: spend more on compute to win the leaderboard, then spend even more to keep those high-cost models running at scale.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is already reportedly spending more on compute than it had previously let on. As TechCrunch reported recently, most of OpenAI’s inference spend – the money it spends on compute to run a trained AI model – is being paid in cash rather than through cloud credits, suggesting the company’s compute costs have grown beyond what partnerships and credits can subsidize.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For all its focus on reasoning, one thing that’s absent from today’s launch is a new image generator. Altman reportedly said in his code red memo that image generation would be a key priority moving forward, particularly after Google’s Nano Banana (the nickname for Google’s Gemini 2.5 Flash Image model) had a viral moment following its August release.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last month, Google launched Nano Banana Pro (AKA Gemini 3 Pro Image), an upgraded version with even better text rendering, world knowledge, and an eerie, real-life, unedited vibe to its photos. It also integrates better across Google’s products, as demonstrated over the past week as it pops up in tools and workflows like Google Labs Mixboard for automated presentation generation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI reportedly plans to release another new model in January with better images, improved speed, and better personality, though the company didn’t confirm these plans Thursday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI also said Thursday it’s rolling out new safety measures around mental health use and age verification for teens, but didn’t spend much of the launch pitching those changes.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/GettyImages-2213399157.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI launched its latest frontier model, GPT-5.2, on Thursday amid increasing competition from Google, pitching it as its most advanced model yet and one designed for developers and everyday professional use.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s GPT-5.2 is coming to ChatGPT paid users and developers via the API in three flavors: Instant, a speed-optimized model for routine queries like information-seeking, writing, and translation; Thinking, which excels at complex structured work like coding, analyzing long documents, math, and planning; and Pro, the top-end model aimed at delivering maximum accuracy and reliability for difficult problems.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We designed 5.2 to unlock even more economic value for people,” Fidji Simo, OpenAI’s chief product officer, said Thursday during a briefing with journalists. “It’s better at creating spreadsheets, building presentations, writing code, perceiving images, understanding long context, using tools and then linking complex, multi-step projects.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;GPT-5.2 lands in the middle of an arms race with Google’s Gemini 3, which is topping LMArena’s leaderboard across most benchmarks (apart from coding – which Anthropic’s Claude Opus-4.5 still has on lock).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Early this month, The Information reported that CEO Sam Altman released an internal “code red” memo to staff amid ChatGPT traffic decline and concerns that it is losing consumer market share to Google. The code red called for a shift in priorities, including stalling on commitments like introducing ads and instead focusing on creating a better ChatGPT experience.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;GPT-5.2 is OpenAI’s push to reclaim leadership, even as some employees reportedly asked for the model release to be pushed back so the company could have more time to improve it. And despite indications that OpenAI would focus its attention on consumer use cases by adding more personalization and customization to ChatGPT, the launch of GPT-5.2 looks to beef up its enterprise opportunities.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is specifically targeting developers and the tooling ecosystem, aiming to become the default foundation for building AI-powered applications. Earlier this week, OpenAI released new data showing enterprise usage of its AI tools has surged dramatically over the past year.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;This comes as Gemini 3 has become tightly integrated into Google’s product and cloud ecosystem for multimodal and agentic workflows. Google this week launched managed MCP servers that make its Google and Cloud services like Maps and BigQuery easier for agents to plug into. (MCPs are the connectors between AI systems and data and tools.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says GPT-5.2 sets new benchmark scores in coding, math, science, vision, long-context reasoning, and tool-use, which the company claims could lead to “more reliable agentic workflows, production-grade code, and complex systems that operate across large contexts and real-world data.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Those capabilities put it in direct competition with Gemini 3’s Deep Think mode, which has been touted as a major reasoning advancement targeting math, logic, and science. On OpenAI’s own benchmark chart, GPT-5.2 Thinking edges out Gemini 3 and Anthropic’s Claude Opus 4.5 in nearly every listed reasoning test, from real-world software engineering tasks (SWE-Bench Pro) and doctoral-level science knowledge (GPQA Diamond) to abstract reasoning and pattern discovery (ARC-AGI suites).&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Research lead Adain Clark said that stronger math scores aren’t just about solving equations. Mathematical reasoning, he explained, is a proxy for whether a model can follow multi-step logic, keep numbers consistent over time, and avoid subtle errors that could compound over time.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“These are all properties that really matter across a wide range of different workloads,” Clark said. “Things like financial modeling, forecasting, doing an analysis of data.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;During the briefing, OpenAI product lead Max Schwarzer said GPT-5.2 “makes substantial improvements to code generation and debugging” and can walk through complex math and logic step-by-step. Coding startups like Windsurf and CharlieCode, he added, report “state-of-the-art agent coding performance” and measurable gains on complex multi-step workflows. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond coding, Schwarzer said that GPT-5.2 Thinking responses contain 38% fewer errors than its predecessor, making the model more dependable for day-to-day decision-making, research, and writing.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;GPT-5.2 appears to be less a reinvention and more of a consolidation of OpenAI’s last two upgrades. GPT-5, which dropped in August, was a reset that laid the groundwork for a unified system with a router to toggle the model between a fast default model and a deeper “Thinking” mode. November’s GPT-5.1 focused on making that system warmer, more conversational, and better suited to agentic and coding tasks. The latest model, GPT-5.2, seems to turn up the dial on all of those advancements, making it a more reliable foundation for production use.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For OpenAI, the stakes have never been higher. The company has made commitments to the tune of $1.4 trillion for AI infrastructure buildouts over the next few years to support its growth – commitments it made when it still had the first-mover advantage among AI companies. But now that Google, which lagged behind at the start, is pushing ahead, that bet might be what’s driving Altman’s ‘code red.’&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s renewed focus on reasoning models is also a risky flex. The systems behind its Thinking and Deep Research modes are more expensive to run than standard chatbots because they chew through more compute. By doubling down on that kind of model with GPT-5.2, OpenAI may be setting up a vicious cycle: spend more on compute to win the leaderboard, then spend even more to keep those high-cost models running at scale.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is already reportedly spending more on compute than it had previously let on. As TechCrunch reported recently, most of OpenAI’s inference spend – the money it spends on compute to run a trained AI model – is being paid in cash rather than through cloud credits, suggesting the company’s compute costs have grown beyond what partnerships and credits can subsidize.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For all its focus on reasoning, one thing that’s absent from today’s launch is a new image generator. Altman reportedly said in his code red memo that image generation would be a key priority moving forward, particularly after Google’s Nano Banana (the nickname for Google’s Gemini 2.5 Flash Image model) had a viral moment following its August release.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last month, Google launched Nano Banana Pro (AKA Gemini 3 Pro Image), an upgraded version with even better text rendering, world knowledge, and an eerie, real-life, unedited vibe to its photos. It also integrates better across Google’s products, as demonstrated over the past week as it pops up in tools and workflows like Google Labs Mixboard for automated presentation generation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI reportedly plans to release another new model in January with better images, improved speed, and better personality, though the company didn’t confirm these plans Thursday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI also said Thursday it’s rolling out new safety measures around mental health use and age verification for teens, but didn’t spend much of the launch pitching those changes.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/11/openai-fires-back-at-google-with-gpt-5-2-after-code-red-memo/</guid><pubDate>Thu, 11 Dec 2025 18:02:44 +0000</pubDate></item><item><title>[NEW] Google’s AI try-on feature for clothes now works with just a selfie (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/11/googles-ai-try-on-feature-for-clothes-now-works-with-just-a-selfie/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is updating its AI try-on feature to let you virtually try on clothes using just a selfie, the company announced on Thursday. In the past, users had to upload a full-body picture of themselves to virtually try on a piece of clothing. Now, they can use a selfie and&amp;nbsp;Nano Banana, Google’s Gemini 2.5 Flash Image model, to generate a full-body digital version of themselves for virtual try-ons.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users can select their usual clothing size, and the feature will then generate several images. From there, users can choose one to make it their default try-on photo.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;If desired, users still have the option to use a full-body photo or select from a range of models with diverse body types.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new capability is launching in the United States today.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3075274" height="680" src="https://techcrunch.com/wp-content/uploads/2025/12/Screenshot-2025-12-11-at-12.55.46-PM.png?w=446" width="446" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Google first launched the try-on feature in July, allowing users to try on apparel items from its Shopping Graph across Search, Google Shopping, and Google Images. To use the feature, users need to tap on a product listing or apparel product result and select the “try it on” icon.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The move comes as Google has been investing in the virtual AI try-on space, as the company has a separate app dedicated specifically to that purpose. The app, called Doppl, is designed to help visualize how different outfits might look on you using AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Earlier this week, the tech giant updated it with a shoppable discovery feed that displays recommendations so users can discover and virtually try on new items. Nearly everything in the feed is shoppable, with direct links to merchants.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The discovery feed features AI-generated videos of real products and suggests outfits based on your personalized style. While some may not be fond of an AI-generated feed, Google likely views it as a way to showcase products in a format that people are already familiar with, thanks to platforms like TikTok and Instagram.&lt;br /&gt;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is updating its AI try-on feature to let you virtually try on clothes using just a selfie, the company announced on Thursday. In the past, users had to upload a full-body picture of themselves to virtually try on a piece of clothing. Now, they can use a selfie and&amp;nbsp;Nano Banana, Google’s Gemini 2.5 Flash Image model, to generate a full-body digital version of themselves for virtual try-ons.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users can select their usual clothing size, and the feature will then generate several images. From there, users can choose one to make it their default try-on photo.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;If desired, users still have the option to use a full-body photo or select from a range of models with diverse body types.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new capability is launching in the United States today.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3075274" height="680" src="https://techcrunch.com/wp-content/uploads/2025/12/Screenshot-2025-12-11-at-12.55.46-PM.png?w=446" width="446" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Google first launched the try-on feature in July, allowing users to try on apparel items from its Shopping Graph across Search, Google Shopping, and Google Images. To use the feature, users need to tap on a product listing or apparel product result and select the “try it on” icon.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The move comes as Google has been investing in the virtual AI try-on space, as the company has a separate app dedicated specifically to that purpose. The app, called Doppl, is designed to help visualize how different outfits might look on you using AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Earlier this week, the tech giant updated it with a shoppable discovery feed that displays recommendations so users can discover and virtually try on new items. Nearly everything in the feed is shoppable, with direct links to merchants.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The discovery feed features AI-generated videos of real products and suggests outfits based on your personalized style. While some may not be fond of an AI-generated feed, Google likely views it as a way to showcase products in a format that people are already familiar with, thanks to platforms like TikTok and Instagram.&lt;br /&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/11/googles-ai-try-on-feature-for-clothes-now-works-with-just-a-selfie/</guid><pubDate>Thu, 11 Dec 2025 18:09:27 +0000</pubDate></item><item><title>[NEW] OpenAI's GPT-5.2 is here: what enterprises need to know (AI | VentureBeat)</title><link>https://venturebeat.com/ai/openais-gpt-5-2-is-here-what-enterprises-need-to-know</link><description>[unable to retrieve full-text content]&lt;p&gt;The rumors were true, and the &amp;quot;&lt;a href="https://www.theinformation.com/articles/openai-ceo-declares-code-red-combat-threats-chatgpt-delays-ads-effort"&gt;Code Red&lt;/a&gt;&amp;quot; is over: OpenAI today announced the release of its new frontier large language model (LLM) family: &lt;a href="https://platform.openai.com/docs/models/gpt-5.2"&gt;&lt;b&gt;GPT-5.2&lt;/b&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;It comes at a pivotal moment for the AI pioneer, which has faced intensifying pressure since rival &lt;a href="https://venturebeat.com/ai/google-unveils-gemini-3-claiming-the-lead-in-math-science-multimodal-and"&gt;Google’s Gemini 3 LLM seized the top spot&lt;/a&gt; on major third-party performance leaderboards and many key benchmarks last month, though OpenAI leaders stressed in a press briefing that the timing of this release had been discussed and worked on well in advance of the release of Gemini 3.&lt;/p&gt;&lt;p&gt;OpenAI describes GPT-5.2 as its &amp;quot;most capable model series yet for professional knowledge work,&amp;quot; aiming to reclaim the performance crown with significant gains in reasoning, coding, and agentic workflows.&lt;/p&gt;&lt;p&gt;&amp;quot;It’s our most advanced frontier model and the strongest yet in the market for professional use,&amp;quot; Fidji Simo, OpenAI’s CEO of Applications, said during a press briefing today. &amp;quot;We designed 5.2 to unlock even more economic value for people. It&amp;#x27;s better at creating spreadsheets, building presentations, writing code, perceiving images, understanding long context, using tools, and handling complex, multi-step projects.&amp;quot;&lt;/p&gt;&lt;p&gt;GPT-5.2 features a massive 400,000-token context window — allowing it to ingest hundreds of documents or large code repositories at once — and a 128,000 max output token limit, enabling it to generate extensive reports or full applications in a single go.&lt;/p&gt;&lt;p&gt;The model also features a knowledge cutoff of August 31, 2025, ensuring it is up-to-date with relatively recent world events and technical documentation. It explicitly includes &amp;quot;Reasoning token support,&amp;quot; confirming the underlying architecture uses the chain-of-thought processing popularized by the &amp;quot;o1&amp;quot; series.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;The &amp;#x27;Code Red&amp;#x27; Reality Check&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The release arrives following&lt;i&gt; &lt;/i&gt;&lt;a href="https://www.theinformation.com/articles/openai-ceo-declares-code-red-combat-threats-chatgpt-delays-ads-effort"&gt;&lt;i&gt;The Information&lt;/i&gt;&amp;#x27;s report&lt;/a&gt; of an emergency &amp;quot;Code Red&amp;quot; directive to OpenAI staff from CEO Sam Altman — a move reportedly designed to mobilize resources following the &amp;quot;quality gap&amp;quot; exposed by Gemini 3.&lt;a href="https://www.theverge.com/report/838857/openai-gpt-5-2-release-date-code-red-google-response"&gt;&lt;i&gt; The Verge&lt;/i&gt;&lt;/a&gt; similarly reported on the timing of GPT-5.2&amp;#x27;s release ahead of the official announcement. &lt;/p&gt;&lt;p&gt;During the briefing, OpenAI executives acknowledged the directive but pushed back on the narrative that the model was rushed solely to answer Google.&lt;/p&gt;&lt;p&gt;&amp;quot;It is important to note this has been in the works for many, many months,&amp;quot; Simo told reporters. She clarified that while the &amp;quot;Code Red&amp;quot; helped focus the company, it wasn&amp;#x27;t the sole driver of the timeline. &lt;/p&gt;&lt;p&gt;&amp;quot;We announced this Code Red to really signal to the company that we want to marshal resources in one particular area... but that&amp;#x27;s not the reason it&amp;#x27;s coming out this week in particular.&amp;quot;&lt;/p&gt;&lt;p&gt;Max Schwarzer, lead of OpenAI&amp;#x27;s post-training team, echoed this sentiment to dispel the idea of a panic launch. &amp;quot;We&amp;#x27;ve been planning for this release since a very long time ago... this specific week we talked about many months ago.&amp;quot;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Under the Hood: Instant, Thinking, and Pro&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;OpenAI is segmenting the GPT-5.2 release into three distinct tiers within ChatGPT, a strategy likely designed to balance the massive compute costs of &amp;quot;reasoning&amp;quot; models with user demand for speed:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;GPT-5.2 Instant:&lt;/b&gt; Optimized for speed and daily tasks like writing, translation, and information seeking.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;GPT-5.2 Thinking:&lt;/b&gt; Designed for &amp;quot;complex, structured work&amp;quot; and long-running agents, this model leverages deeper reasoning chains to handle coding, math, and multi-step projects.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;GPT-5.2 Pro:&lt;/b&gt; The new heavyweight champion. OpenAI describes this as its &amp;quot;smartest and most trustworthy option,&amp;quot; delivering the highest accuracy for difficult questions where quality outweighs latency.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;For developers, the models are available immediately in the API as &lt;code&gt;gpt-5.2&lt;/code&gt;, &lt;code&gt;gpt-5.2-chat-latest&lt;/code&gt; (Instant), and &lt;code&gt;gpt-5.2-pro&lt;/code&gt;.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;The Numbers: Beating the Benchmarks&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Unlike previous launches that often focused on creative capabilities or &amp;quot;vibes,&amp;quot; this release is all about hard metrics—specifically those that target the &amp;quot;professional knowledge work&amp;quot; gap where competitors have recently gained ground.&lt;/p&gt;&lt;p&gt;OpenAI highlighted a new benchmark called GDPval, which measures performance on &amp;quot;well-specified knowledge work tasks&amp;quot; across 44 occupations. &lt;/p&gt;&lt;p&gt;&amp;quot;GPT-5.2 Thinking is now state-of-the-art on that benchmark... and beats or ties top industry professionals on 70.9% of well-specified professional tasks like spreadsheets, presentations, and document creation, according to expert human judges,&amp;quot; Simo said.&lt;/p&gt;&lt;p&gt;In the critical arena of coding, OpenAI is claiming a decisive lead. Schwarzer noted that on SWE-bench Pro, a rigorous evaluation of real-world software engineering, GPT-5.2 Thinking sets a new state-of-the-art score of 55.6%. &lt;/p&gt;&lt;p&gt;He emphasized that this benchmark is &amp;quot;more contamination resistant, challenging, diverse, and industrially relevant than previous benchmarks like SWE-bench Verified.&amp;quot;Other key benchmark results include:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;GPQA Diamond (Science):&lt;/b&gt; GPT-5.2 Pro scored 93.2%, edging out GPT-5.2 Thinking (92.4%) and surpassing GPT-5.1 Thinking (88.1%).&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;FrontierMath:&lt;/b&gt; On Tier 1-3 problems, GPT-5.2 Thinking solved 40.3%, a significant jump from the 31.0% achieved by its predecessor.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;ARC-AGI-1:&lt;/b&gt; GPT-5.2 Pro is reportedly the first model to cross the 90% threshold on this general reasoning benchmark, scoring &lt;b&gt;90.5%&lt;/b&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;The Price of Intelligence&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Performance comes at a premium. While ChatGPT subscription pricing remains unchanged for now, the API costs for the new flagship models are steep compared to previous generations, reflecting the high compute demands of &amp;quot;thinking&amp;quot; models.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;GPT-5.2 (Thinking):&lt;/b&gt; Priced at &lt;b&gt;$1.75&lt;/b&gt; per 1 million input tokens and &lt;b&gt;$14&lt;/b&gt; per 1 million output tokens.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;GPT-5.2 Pro:&lt;/b&gt; The costs jump significantly to &lt;b&gt;$21&lt;/b&gt; per 1 million input tokens and &lt;b&gt;$168&lt;/b&gt; per 1 million output tokens.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;OpenAI argues that despite the higher per-token cost, the model’s &amp;quot;greater token efficiency&amp;quot; and ability to solve tasks in fewer turns make it economically viable for high-value enterprise workflows.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Image Generation: Nothing New Yet...But &amp;#x27;More to Come&amp;#x27;&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;During the briefing, VentureBeat asked the OpenAI participants if the new release included any boost to image generation capabilities, noting the excitement around similar features in recent competitor launches like Google&amp;#x27;s Gemini 3 Image aka Nano Banana Pro. &lt;/p&gt;&lt;p&gt;Unfortunately for those seeking to recreate the kind of text-and-information heavy graphics and image editing capabilities, OpenAI executives clarified that GPT-5.2 comes with no current image improvements over the prior GPT-5.1 and OpenAI&amp;#x27;s integrated DALL-E 3 and gpt-4o native image generation models.&lt;/p&gt;&lt;p&gt;&amp;quot;On image Gen, nothing to announce today, but more to come,&amp;quot; Simo said. She acknowledged the popularity of the feature, adding, &amp;quot;We know this is a very important use case that people love, that we introduced [to] the market, and so definitely more to come there.&amp;quot; &lt;/p&gt;&lt;p&gt;Aidan Clark, OpenAI&amp;#x27;s lead of training, also declined to comment on visual generation specifics, stating simply, &amp;quot;I can&amp;#x27;t really speak to image Gen myself.&amp;quot; &lt;/p&gt;&lt;h3&gt;&lt;b&gt;The &amp;#x27;Mega-Agent&amp;#x27; Era&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Beyond raw scores, OpenAI is positioning GPT-5.2 as the engine for a new generation of &amp;quot;long-running agents&amp;quot; capable of executing multi-step workflows without human hand-holding.&amp;quot;&lt;/p&gt;&lt;p&gt;Box found that 5.2 can extract information from long, complex documents about 40% faster, and also saw a 40% boost in reasoning accuracy for Life Sciences and healthcare,&amp;quot; Simo said. &lt;/p&gt;&lt;p&gt;She also noted that Notion reported the model &amp;quot;outperforms 5.1 across every dimension... and it excels at the kind of really ambiguous, longer rising tasks that define real knowledge work.&amp;quot;Schwarzer added that coding startups like Augment Code found the model &amp;quot;delivered substantially stronger deep code capabilities than any prior model,&amp;quot; which is why it was selected to power their new code review agent.Visual capabilities have also seen an upgrade. &lt;/p&gt;&lt;p&gt;A new evaluation called ScreenSpot-Pro, which tests a model&amp;#x27;s ability to understand GUI screenshots, shows GPT-5.2 Thinking achieving 86.3% accuracy, compared to just 64.2% for GPT-5.1.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Science and Reliability&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;OpenAI leaders also stressed the model&amp;#x27;s utility for scientific research, attempting to move the conversation beyond simple chatbots to research assistants. &lt;/p&gt;&lt;p&gt;Aidan Clark, lead of the training team, shared an example of a senior immunology researcher testing the model.&lt;/p&gt;&lt;p&gt;&amp;quot;They tested it by asking it to generate the most important unanswered questions about the immune system,&amp;quot; Clark said. &amp;quot;That immunology researcher reported that GPT-5.2 produced sharper questions and stronger explanations for why those questions... matter compared to any previous pro model.&lt;/p&gt;&lt;p&gt;&amp;quot;Reliability was another key focus. Schwarzer claimed the new model &amp;quot;hallucinates substantially less than GPT-5.1,&amp;quot; noting that on a set of de-identified queries, &amp;quot;responses contained errors 38% less often.&amp;quot;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;The &amp;#x27;Vibe&amp;#x27; Shift&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Interestingly, OpenAI acknowledged that not every user might immediately prefer the new models. &lt;/p&gt;&lt;p&gt;When asked why legacy models like GPT-5.1 would remain available, Schwarzer admitted that &amp;quot;models change a little bit every time.&lt;/p&gt;&lt;p&gt;&amp;quot;Some users may find that they prefer the vibes of the previous model, even though we think the latest one is across the board generally much better,&amp;quot; Schwarzer said. He also noted that for some enterprise customers who have &amp;quot;really fine-tuned a prompt for a specific model,&amp;quot; there might be &amp;quot;small regressions,&amp;quot; necessitating access to the older versions.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Safety, &amp;#x27;Adult Mode,&amp;#x27; and Future Roadmap&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Addressing safety concerns, Simo confirmed that the company is preparing to roll out an &amp;quot;Adult Mode&amp;quot; in the first quarter of next year, following the implementation of a new age prediction system.&lt;/p&gt;&lt;p&gt;&amp;quot;We&amp;#x27;re in the process of improving that,&amp;quot; Simo said regarding the age prediction technology. &lt;/p&gt;&lt;p&gt;&amp;quot;We want to do that ahead of launching adult mode.&amp;quot;Looking further ahead, industry reports suggest OpenAI is working on a more fundamental architectural shift under the codename &amp;quot;Project Garlic,&amp;quot; targeting a flagship release in early 2026. &lt;/p&gt;&lt;p&gt;While executives did not comment on specific future roadmaps during the briefing, Simo remained optimistic about the economics of their current trajectory.&lt;/p&gt;&lt;p&gt;&amp;quot;If you look at historical trends, compute has increased about 3x every year for the last three years,&amp;quot; she explained. &amp;quot;Revenue has also increased at the same pace... creating this virtuous cycle.&amp;quot;&lt;/p&gt;&lt;p&gt;Clark added that efficiency is improving rapidly: &amp;quot;The model we&amp;#x27;re releasing today achieves an even better score [on ARC-AGI] with almost 400 times less cost and less compute associated with it&amp;quot; compared to models from a year ago.&lt;/p&gt;&lt;p&gt;GPT-5.2 Instant, Thinking, and Pro begin rolling out in ChatGPT today to paid users (Plus, Pro, Team, and Enterprise). The company notes the rollout will be gradual to maintain stability.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;The rumors were true, and the &amp;quot;&lt;a href="https://www.theinformation.com/articles/openai-ceo-declares-code-red-combat-threats-chatgpt-delays-ads-effort"&gt;Code Red&lt;/a&gt;&amp;quot; is over: OpenAI today announced the release of its new frontier large language model (LLM) family: &lt;a href="https://platform.openai.com/docs/models/gpt-5.2"&gt;&lt;b&gt;GPT-5.2&lt;/b&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;It comes at a pivotal moment for the AI pioneer, which has faced intensifying pressure since rival &lt;a href="https://venturebeat.com/ai/google-unveils-gemini-3-claiming-the-lead-in-math-science-multimodal-and"&gt;Google’s Gemini 3 LLM seized the top spot&lt;/a&gt; on major third-party performance leaderboards and many key benchmarks last month, though OpenAI leaders stressed in a press briefing that the timing of this release had been discussed and worked on well in advance of the release of Gemini 3.&lt;/p&gt;&lt;p&gt;OpenAI describes GPT-5.2 as its &amp;quot;most capable model series yet for professional knowledge work,&amp;quot; aiming to reclaim the performance crown with significant gains in reasoning, coding, and agentic workflows.&lt;/p&gt;&lt;p&gt;&amp;quot;It’s our most advanced frontier model and the strongest yet in the market for professional use,&amp;quot; Fidji Simo, OpenAI’s CEO of Applications, said during a press briefing today. &amp;quot;We designed 5.2 to unlock even more economic value for people. It&amp;#x27;s better at creating spreadsheets, building presentations, writing code, perceiving images, understanding long context, using tools, and handling complex, multi-step projects.&amp;quot;&lt;/p&gt;&lt;p&gt;GPT-5.2 features a massive 400,000-token context window — allowing it to ingest hundreds of documents or large code repositories at once — and a 128,000 max output token limit, enabling it to generate extensive reports or full applications in a single go.&lt;/p&gt;&lt;p&gt;The model also features a knowledge cutoff of August 31, 2025, ensuring it is up-to-date with relatively recent world events and technical documentation. It explicitly includes &amp;quot;Reasoning token support,&amp;quot; confirming the underlying architecture uses the chain-of-thought processing popularized by the &amp;quot;o1&amp;quot; series.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;The &amp;#x27;Code Red&amp;#x27; Reality Check&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The release arrives following&lt;i&gt; &lt;/i&gt;&lt;a href="https://www.theinformation.com/articles/openai-ceo-declares-code-red-combat-threats-chatgpt-delays-ads-effort"&gt;&lt;i&gt;The Information&lt;/i&gt;&amp;#x27;s report&lt;/a&gt; of an emergency &amp;quot;Code Red&amp;quot; directive to OpenAI staff from CEO Sam Altman — a move reportedly designed to mobilize resources following the &amp;quot;quality gap&amp;quot; exposed by Gemini 3.&lt;a href="https://www.theverge.com/report/838857/openai-gpt-5-2-release-date-code-red-google-response"&gt;&lt;i&gt; The Verge&lt;/i&gt;&lt;/a&gt; similarly reported on the timing of GPT-5.2&amp;#x27;s release ahead of the official announcement. &lt;/p&gt;&lt;p&gt;During the briefing, OpenAI executives acknowledged the directive but pushed back on the narrative that the model was rushed solely to answer Google.&lt;/p&gt;&lt;p&gt;&amp;quot;It is important to note this has been in the works for many, many months,&amp;quot; Simo told reporters. She clarified that while the &amp;quot;Code Red&amp;quot; helped focus the company, it wasn&amp;#x27;t the sole driver of the timeline. &lt;/p&gt;&lt;p&gt;&amp;quot;We announced this Code Red to really signal to the company that we want to marshal resources in one particular area... but that&amp;#x27;s not the reason it&amp;#x27;s coming out this week in particular.&amp;quot;&lt;/p&gt;&lt;p&gt;Max Schwarzer, lead of OpenAI&amp;#x27;s post-training team, echoed this sentiment to dispel the idea of a panic launch. &amp;quot;We&amp;#x27;ve been planning for this release since a very long time ago... this specific week we talked about many months ago.&amp;quot;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Under the Hood: Instant, Thinking, and Pro&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;OpenAI is segmenting the GPT-5.2 release into three distinct tiers within ChatGPT, a strategy likely designed to balance the massive compute costs of &amp;quot;reasoning&amp;quot; models with user demand for speed:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;GPT-5.2 Instant:&lt;/b&gt; Optimized for speed and daily tasks like writing, translation, and information seeking.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;GPT-5.2 Thinking:&lt;/b&gt; Designed for &amp;quot;complex, structured work&amp;quot; and long-running agents, this model leverages deeper reasoning chains to handle coding, math, and multi-step projects.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;GPT-5.2 Pro:&lt;/b&gt; The new heavyweight champion. OpenAI describes this as its &amp;quot;smartest and most trustworthy option,&amp;quot; delivering the highest accuracy for difficult questions where quality outweighs latency.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;For developers, the models are available immediately in the API as &lt;code&gt;gpt-5.2&lt;/code&gt;, &lt;code&gt;gpt-5.2-chat-latest&lt;/code&gt; (Instant), and &lt;code&gt;gpt-5.2-pro&lt;/code&gt;.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;The Numbers: Beating the Benchmarks&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Unlike previous launches that often focused on creative capabilities or &amp;quot;vibes,&amp;quot; this release is all about hard metrics—specifically those that target the &amp;quot;professional knowledge work&amp;quot; gap where competitors have recently gained ground.&lt;/p&gt;&lt;p&gt;OpenAI highlighted a new benchmark called GDPval, which measures performance on &amp;quot;well-specified knowledge work tasks&amp;quot; across 44 occupations. &lt;/p&gt;&lt;p&gt;&amp;quot;GPT-5.2 Thinking is now state-of-the-art on that benchmark... and beats or ties top industry professionals on 70.9% of well-specified professional tasks like spreadsheets, presentations, and document creation, according to expert human judges,&amp;quot; Simo said.&lt;/p&gt;&lt;p&gt;In the critical arena of coding, OpenAI is claiming a decisive lead. Schwarzer noted that on SWE-bench Pro, a rigorous evaluation of real-world software engineering, GPT-5.2 Thinking sets a new state-of-the-art score of 55.6%. &lt;/p&gt;&lt;p&gt;He emphasized that this benchmark is &amp;quot;more contamination resistant, challenging, diverse, and industrially relevant than previous benchmarks like SWE-bench Verified.&amp;quot;Other key benchmark results include:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;GPQA Diamond (Science):&lt;/b&gt; GPT-5.2 Pro scored 93.2%, edging out GPT-5.2 Thinking (92.4%) and surpassing GPT-5.1 Thinking (88.1%).&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;FrontierMath:&lt;/b&gt; On Tier 1-3 problems, GPT-5.2 Thinking solved 40.3%, a significant jump from the 31.0% achieved by its predecessor.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;ARC-AGI-1:&lt;/b&gt; GPT-5.2 Pro is reportedly the first model to cross the 90% threshold on this general reasoning benchmark, scoring &lt;b&gt;90.5%&lt;/b&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;The Price of Intelligence&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Performance comes at a premium. While ChatGPT subscription pricing remains unchanged for now, the API costs for the new flagship models are steep compared to previous generations, reflecting the high compute demands of &amp;quot;thinking&amp;quot; models.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;GPT-5.2 (Thinking):&lt;/b&gt; Priced at &lt;b&gt;$1.75&lt;/b&gt; per 1 million input tokens and &lt;b&gt;$14&lt;/b&gt; per 1 million output tokens.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;GPT-5.2 Pro:&lt;/b&gt; The costs jump significantly to &lt;b&gt;$21&lt;/b&gt; per 1 million input tokens and &lt;b&gt;$168&lt;/b&gt; per 1 million output tokens.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;OpenAI argues that despite the higher per-token cost, the model’s &amp;quot;greater token efficiency&amp;quot; and ability to solve tasks in fewer turns make it economically viable for high-value enterprise workflows.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Image Generation: Nothing New Yet...But &amp;#x27;More to Come&amp;#x27;&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;During the briefing, VentureBeat asked the OpenAI participants if the new release included any boost to image generation capabilities, noting the excitement around similar features in recent competitor launches like Google&amp;#x27;s Gemini 3 Image aka Nano Banana Pro. &lt;/p&gt;&lt;p&gt;Unfortunately for those seeking to recreate the kind of text-and-information heavy graphics and image editing capabilities, OpenAI executives clarified that GPT-5.2 comes with no current image improvements over the prior GPT-5.1 and OpenAI&amp;#x27;s integrated DALL-E 3 and gpt-4o native image generation models.&lt;/p&gt;&lt;p&gt;&amp;quot;On image Gen, nothing to announce today, but more to come,&amp;quot; Simo said. She acknowledged the popularity of the feature, adding, &amp;quot;We know this is a very important use case that people love, that we introduced [to] the market, and so definitely more to come there.&amp;quot; &lt;/p&gt;&lt;p&gt;Aidan Clark, OpenAI&amp;#x27;s lead of training, also declined to comment on visual generation specifics, stating simply, &amp;quot;I can&amp;#x27;t really speak to image Gen myself.&amp;quot; &lt;/p&gt;&lt;h3&gt;&lt;b&gt;The &amp;#x27;Mega-Agent&amp;#x27; Era&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Beyond raw scores, OpenAI is positioning GPT-5.2 as the engine for a new generation of &amp;quot;long-running agents&amp;quot; capable of executing multi-step workflows without human hand-holding.&amp;quot;&lt;/p&gt;&lt;p&gt;Box found that 5.2 can extract information from long, complex documents about 40% faster, and also saw a 40% boost in reasoning accuracy for Life Sciences and healthcare,&amp;quot; Simo said. &lt;/p&gt;&lt;p&gt;She also noted that Notion reported the model &amp;quot;outperforms 5.1 across every dimension... and it excels at the kind of really ambiguous, longer rising tasks that define real knowledge work.&amp;quot;Schwarzer added that coding startups like Augment Code found the model &amp;quot;delivered substantially stronger deep code capabilities than any prior model,&amp;quot; which is why it was selected to power their new code review agent.Visual capabilities have also seen an upgrade. &lt;/p&gt;&lt;p&gt;A new evaluation called ScreenSpot-Pro, which tests a model&amp;#x27;s ability to understand GUI screenshots, shows GPT-5.2 Thinking achieving 86.3% accuracy, compared to just 64.2% for GPT-5.1.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Science and Reliability&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;OpenAI leaders also stressed the model&amp;#x27;s utility for scientific research, attempting to move the conversation beyond simple chatbots to research assistants. &lt;/p&gt;&lt;p&gt;Aidan Clark, lead of the training team, shared an example of a senior immunology researcher testing the model.&lt;/p&gt;&lt;p&gt;&amp;quot;They tested it by asking it to generate the most important unanswered questions about the immune system,&amp;quot; Clark said. &amp;quot;That immunology researcher reported that GPT-5.2 produced sharper questions and stronger explanations for why those questions... matter compared to any previous pro model.&lt;/p&gt;&lt;p&gt;&amp;quot;Reliability was another key focus. Schwarzer claimed the new model &amp;quot;hallucinates substantially less than GPT-5.1,&amp;quot; noting that on a set of de-identified queries, &amp;quot;responses contained errors 38% less often.&amp;quot;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;The &amp;#x27;Vibe&amp;#x27; Shift&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Interestingly, OpenAI acknowledged that not every user might immediately prefer the new models. &lt;/p&gt;&lt;p&gt;When asked why legacy models like GPT-5.1 would remain available, Schwarzer admitted that &amp;quot;models change a little bit every time.&lt;/p&gt;&lt;p&gt;&amp;quot;Some users may find that they prefer the vibes of the previous model, even though we think the latest one is across the board generally much better,&amp;quot; Schwarzer said. He also noted that for some enterprise customers who have &amp;quot;really fine-tuned a prompt for a specific model,&amp;quot; there might be &amp;quot;small regressions,&amp;quot; necessitating access to the older versions.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Safety, &amp;#x27;Adult Mode,&amp;#x27; and Future Roadmap&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Addressing safety concerns, Simo confirmed that the company is preparing to roll out an &amp;quot;Adult Mode&amp;quot; in the first quarter of next year, following the implementation of a new age prediction system.&lt;/p&gt;&lt;p&gt;&amp;quot;We&amp;#x27;re in the process of improving that,&amp;quot; Simo said regarding the age prediction technology. &lt;/p&gt;&lt;p&gt;&amp;quot;We want to do that ahead of launching adult mode.&amp;quot;Looking further ahead, industry reports suggest OpenAI is working on a more fundamental architectural shift under the codename &amp;quot;Project Garlic,&amp;quot; targeting a flagship release in early 2026. &lt;/p&gt;&lt;p&gt;While executives did not comment on specific future roadmaps during the briefing, Simo remained optimistic about the economics of their current trajectory.&lt;/p&gt;&lt;p&gt;&amp;quot;If you look at historical trends, compute has increased about 3x every year for the last three years,&amp;quot; she explained. &amp;quot;Revenue has also increased at the same pace... creating this virtuous cycle.&amp;quot;&lt;/p&gt;&lt;p&gt;Clark added that efficiency is improving rapidly: &amp;quot;The model we&amp;#x27;re releasing today achieves an even better score [on ARC-AGI] with almost 400 times less cost and less compute associated with it&amp;quot; compared to models from a year ago.&lt;/p&gt;&lt;p&gt;GPT-5.2 Instant, Thinking, and Pro begin rolling out in ChatGPT today to paid users (Plus, Pro, Team, and Enterprise). The company notes the rollout will be gradual to maintain stability.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/openais-gpt-5-2-is-here-what-enterprises-need-to-know</guid><pubDate>Thu, 11 Dec 2025 18:16:00 +0000</pubDate></item></channel></rss>