<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 15 Jul 2025 01:59:03 +0000</lastBuildDate><item><title>AI Testing and Evaluation: Learnings from cybersecurity (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-cybersecurity/</link><description>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Illustrated images of Kathleen Sullivan, Ciaran Martin, and Tori Westerhoff for the Microsoft Research podcast" class="wp-image-1144391" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP3-AI-TE_Hero_Feature_1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;






&lt;p&gt;Generative AI presents a unique challenge and opportunity to reexamine governance practices for the responsible development, deployment, and use of AI. To advance thinking in this space, Microsoft has tapped into the experience and knowledge of experts across domains—from genome editing to cybersecurity—to investigate the role of testing and evaluation as a governance tool.&amp;nbsp;&lt;em&gt;AI Testing and Evaluation: Learnings from Science and Industry&lt;/em&gt;,&amp;nbsp;hosted by Microsoft Research’s&amp;nbsp;Kathleen Sullivan, explores what the technology industry and policymakers can learn from these fields and how that might help shape the course of AI development.&lt;/p&gt;



&lt;p&gt;In this episode, Sullivan speaks with Professor Ciaran Martin&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; of the University of Oxford about risk assessment and testing in the field of cybersecurity. They explore the importance of differentiated standards for organizations of varying sizes, the role of public-private partnerships, and the opportunity to embed security into emerging technologies from the outset. Later, Tori Westerhoff&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, a principal director on the Microsoft AI Red Team, joins Sullivan to talk about identifying vulnerabilities in AI products and services. Westerhoff describes AI security in terms she’s heard cybersecurity professionals use for their work—a team sport—and points to cybersecurity’s establishment of a shared language and understanding of risk as a model for AI security.&lt;/p&gt;



&lt;div class="wp-block-group msr-pattern-link-list is-layout-flow wp-block-group-is-layout-flow"&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;



&lt;h2 class="wp-block-heading h5" id="learn-more-1"&gt;Learn more:&lt;/h2&gt;




&lt;/div&gt;







&lt;section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast"&gt;
	
&lt;/section&gt;


&lt;div class="wp-block-msr-show-more"&gt;
	&lt;div class="bg-neutral-100 p-5"&gt;
		&lt;div class="show-more-show-less"&gt;
			&lt;div&gt;
				&lt;span&gt;
					

&lt;h2 class="wp-block-heading" id="transcript"&gt;Transcript&lt;/h2&gt;



&lt;p&gt;[MUSIC]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KATHLEEN SULLIVAN: &lt;/strong&gt;Welcome to &lt;em&gt;AI Testing and Evaluation: Learnings from Science and Industry&lt;/em&gt;. I’m your host, Kathleen Sullivan.&lt;/p&gt;



&lt;p&gt;As generative AI continues to advance, Microsoft has gathered a range of experts—from genome editing to cybersecurity—to share how their fields approach evaluation and risk assessment. Our goal is to learn from their successes and their stumbles to move the science and practice of AI testing forward. In this series, we’ll explore how these insights might help guide the future of AI development, deployment, and responsible use.&lt;/p&gt;



&lt;p&gt;[MUSIC ENDS]&lt;/p&gt;



&lt;p&gt;Today, I’m excited to welcome Ciaran Martin to the podcast to explore testing and risk assessment in cybersecurity. Ciaran is a professor of practice in the management of public organizations at the University of Oxford. He had previously founded and served as chief executive of the National Cyber Security Centre within the UK’s intelligence, security, and cyber agency.&lt;/p&gt;



&lt;p&gt;And after our conversation, we’ll talk to Microsoft’s Tori Westerhoff, a principal director on Microsoft’s AI Red Team, about how we should think about these insights in the context of AI.&lt;/p&gt;



&lt;p&gt;Hi, Ciaran. Thank you so much for being here today.&lt;/p&gt;



				&lt;/span&gt;
				&lt;span class="show-more-show-less-toggleable-content" id="show-more-show-less-toggle-1"&gt;
					



&lt;p&gt;&lt;strong&gt;CIARAN MARTIN:&lt;/strong&gt; Well, thanks so much for inviting me. It’s great to be here.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Ciaran, before we get into some regulatory specifics, it’d be great to hear a little bit more about your origin story, and just take us to that day—who tapped you on the shoulder and said, “Ciaran, we need you to run a national cyber center! Do you fancy building one?”&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; You could argue that I owe my job to Edward Snowden. Not an obvious thing to say. So the National Cyber Security Centre, which didn’t exist at the time—I was invited to join the British government’s cybersecurity effort in a leadership role—is now a subset of GCHQ. That’s the digital intelligence agency. The equivalent in the US obviously is the NSA [National Security Agency]. It had been convulsed by the Snowden disclosures. It was an unprecedented challenge.&lt;/p&gt;



&lt;p&gt;I was a 17-year career government fixer with some national security experience. So I was asked to go out and help with the policy response, the media response, the legal response. But I said, look, any crisis, even one as big as this, is over one way or the other in six months. What should I do long term? And they said, well, we were thinking of asking you to try to help transform our cybersecurity mission. So the National Cyber Security Centre was born, and I was very proud to lead it, and all in all, I did it for seven years from startup to handing it on to somebody else.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; I mean, it’s incredible. And just building on that, people spend a significant portion of their lives online now with a variety of devices, and maybe for listeners who are newer to cybersecurity, could you give us the 90-second lightning talk? Kind of, what does risk assessment and testing look like in this space?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; Well, risk assessment and testing, I think, are two different things. You can’t defend everything. If you defend everything, you’re defending nothing. So broadly speaking, organizations face three threats. One is complete disruption of their systems. So just imagine not being able to access your system. The second is data protection, and that could be sensitive customer information. It could be intellectual property. And the third is, of course, you could be at risk of just straightforward being stolen from. I mean, you don’t want any of them to happen, but you have to have a hierarchy of harm.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN: &lt;/strong&gt;Yes.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN: &lt;/strong&gt;So that’s your risk assessment.&lt;/p&gt;



&lt;p&gt;The testing side, I think, is slightly different. One of the paradoxes, I think, of cybersecurity is for such a scientific, data-rich subject, the sort of metrics about what works are very, very hard to come by. So you’ve got boards and corporate leadership and senior governmental structures, and they say, “Look, how do I run this organization safely and securely?” And a cybersecurity chief within the organization will say, “Well, we could get this capability in.” Well, the classic question for a leadership team to ask is, well, what risk and harm will this reduce, by how much, and what’s the cost-benefit analysis? And we find that &lt;em&gt;really&lt;/em&gt; hard.&lt;/p&gt;



&lt;p&gt;So that’s really where testing and assurance comes in. And also as technology changes so fast, we have to figure out, well, if we’re worried about post-quantum cryptography, for example, what standards does it have to meet? How do you assess whether it’s meeting those standards? So it’s a huge issue in cybersecurity and one that we’re always very conscious of. It’s really hard.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Given the scope of cybersecurity, are there any differences in testing, let’s say, for maybe a small business versus a critical infrastructure operator? Are there any, sort of, metrics we can look at in terms of distinguishing risk or assessment?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; There have to be. One of the reasons I think why we have to be is that no small business can be expected to take on a hostile nation-state that’s well equipped. You have to be realistic.&lt;/p&gt;



&lt;p&gt;If you look at government guidance, certainly in the UK 15 years ago on cybersecurity, you were telling small businesses that are living hand to mouth, week by week, trying to make payments at the end of each month, we were telling them they needed sort of nation-state-level cyber defenses. That was never going to happen, even if they could afford it, which they couldn’t. So you have to have some differentiation. So again, you’ve got assessment frameworks and so forth where you have to meet higher standards. So there absolutely has to be that distinction. Otherwise, you end up in a crazy world of crippling small businesses with just unmanageable requirements which they’re never going to meet.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; It’s such a great point. You touched on this a little bit earlier, as well, but just cybersecurity governance operates in a fast-moving technology and threat environment. How have testing standards evolved, and where do new technical standards usually originate?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; I keep saying this is very difficult, and it is. [LAUGHTER] So I think there are two challenges. One is actually about the balance, and this applies to the technology of today as well as the technology of tomorrow. This is about, how do you make sure things are good enough without crowding out new entrants? You want people to be innovative and dynamic. You want disruptors in this business.&lt;/p&gt;



&lt;p&gt;But if you say to them, “Look, well, you have to meet these 14 impossibly high technical standards before you can even sell to anybody or sell to the government,” whatever, then you’ve got a problem. And I think we’ve wrestled with that, and there’s no perfect answer. You just have to try and go to … find the sweet spot between two ends of a spectrum. And that’s going to evolve.&lt;/p&gt;



&lt;p&gt;The second point, which in some respects if you’ve got the right capabilities is slightly &lt;em&gt;easier&lt;/em&gt; but still a big call, is around, you know, those newer and evolving technologies. And here, having, you know, been a bit sort of gloomy and pessimistic, here I think is actually an opportunity. So one of the things we always say in cybersecurity is that the internet was built and developed without security in mind. And that was kind of true in the ’90s and the noughties, as we call them over here.&lt;/p&gt;



&lt;p&gt;But I think as you move into things like post-quantum computing, applied use of AI, and so on, you can actually set the standards at the beginning. And that’s really good because it’s saying to people that these are the things that are going to matter in the post-quantum age. Here’s the outline of the standards you’re going to have to meet; start looking at them. So there’s an opportunity actually to make technology safer by design, by getting ahead of it. And I think that’s the era we’re in now.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; That makes a lot of sense. Just building on that, do businesses and the public trust these standards? And I guess, which standard do you wish the world would just adopt already, and what’s the real reason they haven’t?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; Well, again, where do you start? I mean, most members of the public quite rightly haven’t heard of any of these standards. I think public trust and public capital in any society matters. But I think it is important that these things are credible.&lt;/p&gt;



&lt;p&gt;And there’s quite a lot of convergence between, you know, the top-level frameworks. And obviously in the US, you know, the NIST [National Institute of Standards and Technology] framework is the one that’s most popular for cybersecurity, but it bears quite a strong resemblance to the international one, ISO[/IEC] 27001, and there are others, as well. But fundamentally, they boil down to kind of five things. Do a risk assessment; work out what your crown jewels are. Protect your perimeter as best you can. Those are the first two.&lt;/p&gt;



&lt;p&gt;The third one then is when your perimeter’s breached, be able to detect it more times than not. And when you can’t do that, you go to the fourth one, which is, can you mitigate it? And when all else fails, how quickly can you recover and manage it? I mean, all the standards are expressed in way more technical language than that, but fundamentally, if everybody adopted those five things and operated them in a simple way, you wouldn’t eliminate the harm, but you would reduce it quite substantially.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Which policy initiatives are most promising for incentivizing companies to undertake, you know, these cybersecurity testing parameters that you’ve just outlined? Governments, including the UK, have used carrots and sticks, but what do you think will actually move the needle?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; I think there are two answers to that, and it comes back to your split between smaller businesses and critically important businesses. In the critically important services, I think it’s easier because most industries are looking for a level playing field. In other words, they realize there have to be rules and they want to apply them to everyone.&lt;/p&gt;



&lt;p&gt;We had a fascinating experience when I was in government back in around 2018 where the telecom sector, they came to us and they said, we’ve got a very good cooperative relationship with the British government, but it needs to be put on a proper legal footing because you’re just asking us nicely to do expensive things. And in a regulated sector, if you actually put in some rules—and please develop them jointly with us; that’s the crucial part—then that will help because it means that we’re not going to our boards and saying, or our shareholders, and saying that we should do this, and they’re saying, “Well, do you have to do it? Are our competitors doing it?” And if the answer to that is, yes, we have to, and, yes, our competitors are doing it, then it tends to be OK.&lt;/p&gt;



&lt;p&gt;The harder nut to crack is the smaller business. And I think there’s a real mystery here: why has nobody cracked a really good and easy solution for small business? We need to be careful about this because, you know, you can’t throttle small businesses with onerous regulation. At the same time, we’re not brilliant, I think, in any part of the world at using the normal corporate governance rules to try and get people to figure out how to do cybersecurity.&lt;/p&gt;



&lt;p&gt;There are initiatives there that are not the sort of pretty heavy stick that you might have to take to a critical function, but they could help. But that is a hard nut to crack. And I look around the world, and, you know, I think if this was easy, somebody would have figured it out by now. I think most of the developed economies around the world really struggle with cybersecurity for smaller businesses.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah, it’s a great point. Actually building on one of the comments you made on the role of, kind of, government, how do you see the role of private-public partnerships scaling and strengthening, you know, robust cybersecurity testing?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; I think they’re crucial, but they have to be practical. I’ve got a slight, sort of, high horse on this, if you don’t mind, Kathleen. It’s sort of … [LAUGHS]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Of course.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; I think that there are two types of public-private partnership. One involves committees saying that we should strengthen partnerships and we should all work together and collaborate and share stuff. And we tried that for a very long time, and it didn’t get us very far. There are other types.&lt;/p&gt;



&lt;p&gt;We had some at the National Cyber Security Centre where we paid companies to do spectacularly good technical work that the market wouldn’t provide. So I think it’s sort of partnership with a purpose. I think sometimes, and I understand the human instinct to do this, particularly in governments and big business, they think you need to get around a table and work out some grand strategy to fix everything, and the scale of the … not just the problem but the scale of the whole technology is just too big to do that.&lt;/p&gt;



&lt;p&gt;So pick a bit of the problem. Find some ways of doing it. Don’t over-lawyer it. [LAUGHTER] I think sometimes people get very nervous. &lt;em&gt;Oh, well, is this our role? You know, should we be doing this, that, and the other?&lt;/em&gt; Well, you know, sometimes certainly in this country, you think, well, who’s actually going to sue you over this, you know? So I wouldn’t over-programmatize it. Just get stuck practically into solving some problems.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; I love that. Actually, [it] made me think, are there any surprising allies that you’ve gained—you know, maybe someone who you never expected to be a cybersecurity champion—through your work?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; Ooh! That’s a … that’s a… what a question! To give you a slightly disappointing answer, but it relates to your previous question. In the early part of my career, I was working in institutions like the UK Treasury long before I was in cybersecurity, and the treasury and the British civil service in general, but the treasury in particular sort of trained you to believe that the private sector was amoral, not &lt;em&gt;immoral&lt;/em&gt;, &lt;em&gt;amoral&lt;/em&gt;. It just didn’t have values. It just had bottom line, and, you know, its job essentially was to provide employment and revenue then for the government to spend on good things that people cared about. And when I got into cybersecurity and people said, look, you need to develop relations with this cybersecurity company, often in the US, actually. I thought, well, what’s in it for them?&lt;/p&gt;



&lt;p&gt;And, sure, sometimes you were paying them for specific services, but other times, there was a real public spiritedness about this. There was a realization that if you tried to delineate public-private boundaries, that it wouldn’t really work. It was a shared risk. And you could analyze where the boundaries fell or you could actually go on and do something about it together. So I was genuinely surprised at the allyship from the cybersecurity sector. Absolutely, I really, really was. And I think it’s a really positive part of certainly the UK cybersecurity ecosystem.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Wonderful. Well, we’re coming to the end of our time here, but is there any maybe last thoughts or perhaps requests you have for our listeners today?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; I think that standards, assurance, and testing &lt;em&gt;really&lt;/em&gt; matter, but it’s a bit like the discussion we’re having over AI. Get all these things to take you 80, 90% of the way and then really apply your judgment. There’s been some bad regulation under the auspices of standards and assurance. First of all, it’s, have you done this assessment? Have you done that? Have you looked at this? Well, fine. And you can tick that box, but what does it actually mean when you do it? What bits that you know in your heart of hearts are really important to the defense of your organization that may not be covered by this and just go and do those anyway. Because sure it helps, but it’s not everything.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; No. Great, great closing sentiment. Well, Ciaran, thank you for joining us today. This has been just a super fun conversation and really insightful. Just really enjoyed the conversation. Thank you.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; My pleasure, Kathleen, thank you.&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN: &lt;/strong&gt;Now, I’m happy to introduce Tori Westerhoff. As a principal director on the Microsoft AI Red Team, Tori leads all AI security and safety red team operations, as well as dangerous capability testing, to directly inform C-suite decision-makers.&lt;/p&gt;



&lt;p&gt;So, Tori, welcome!&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TORI WESTERHOFF: &lt;/strong&gt;Thanks. I am so excited to be here.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; I’d love to just start a little bit more learning about your background. You’ve worn some very intriguing hats. I mean, cognitive neuroscience grad from Yale, national security consultant, strategist in augmented and virtual reality … how do those experiences help shape the way you lead the Microsoft AI Red Team?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; I always joke this is the only role I think will always combine the entire patchwork LinkedIn résumé. [LAUGHS]&lt;/p&gt;



&lt;p&gt;I think I use those experiences to help me understand the really broad approach that AI Red Team—artist also known as &lt;em&gt;AIRT&lt;/em&gt;; I’m sure I’ll slip into our acronym—how we frame up the broad security implications of AI. So I think the cognitive neuroscience element really helped me initially approach AI hacking, right. There’s a lot of social engineering and manipulation within chat interfaces that are enabled by AI. And also, kind of, this, like, metaphor for understanding how to find soft spots in the way that you see human heuristics show up, too. And so I think that was actually my personal “in” to getting hooked into AI red teaming generally.&lt;/p&gt;



&lt;p&gt;But my experience in national security and I’d also say working through the AR/VR/metaverse space at the time where I was in it helped me balance both how our impact is framed, how we’re thinking about critical industries, how we’re really trying to push our understanding of where security of AI can help people the most. And also do it in a really breakneck speed in an industry that’s evolving all of the time, that’s really pushing you to always be at the bleeding edge of your understanding. So I draw a lot of the energy and the mission criticality and the speed from those experiences as we’re shaping up how we approach it.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Can you just give us a quick rundown? What does the Red Team do? What actually, kind of, is involved on a day-to-day basis? And then as we think about, you know, our engagements with large enterprises and companies, how do we work alongside some of those companies in terms of testing?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; The way I see our team is almost like an indicator light that works really part and parcel with product development. So the way we’ve organized our expert red teaming efforts is that we work with product development before anything ships out to anyone who can use it. And our job is to act as expert AI manipulators, AI hackers. And we are supposed to take the theories and methods and new research and harness it to find examples of vulnerabilities or soft spots in products to enable product teams to harden those soft spots before anything actually reaches someone who wants to use it.&lt;/p&gt;



&lt;p&gt;So if we’re the indicator light, we are also not the full workup, right. I see that as measurement and evals. And we also are not the mechanic, which is that product development team that’s creating mitigations. It’s platform-security folks who are creating mitigations at scale. And there’s a really great throughput of insights from those groups back into our area where we love to inform about them, but we also love to add on to, how do we break the next thing, right? So it’s a continuous cycle.&lt;/p&gt;



&lt;p&gt;And part of that is just being really creative and thinking outside of a traditional cybersecurity box. And part of that is also really thinking about how we pull in research—we have a research function within our AI Red Team—and how we automate and scale. This year, we’ve pulled a lot of those assets and insights into the Azure [AI] Foundry AI Red Teaming Agent&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. And so folks can now access a lot of our mechanisms through that. So you can get a little taste of what we do day to day in the AI Red Teaming Agent.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; You recently—actually, with your team—published a report that outlined lessons from testing over a hundred generative AI products. But could you share a bit about what you learned? What were some of the important lessons? Where do you see opportunities to improve the state of red teaming as a method for probing AI safety?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; I think the most important takeaway from those lessons is that AI security is truly a team sport. You’ll hear cybersecurity folks say that a lot. And part of the rationale there is that the defense in depth and integrating and a view towards AI security through the entire development of AI systems is really the way that we’re going to approach this with intentionality and responsibility.&lt;/p&gt;



&lt;p&gt;So in our space, we really focus on novel harm categories. We are pushing bleeding edge, and we also are pushing iterative and, like, contextually based red teaming in product dev. So outside of those hundred that we’ve done, there’s a community [LAUGHS] through the entire, again, multistage life cycle of a product that is really trying to push the cost of attacking those AI systems higher and higher with all of the expertise they bring. So we may be, like, the experts in AI hacking in that line, but there are also so many partners in the Microsoft ecosystem who are thinking about their market context or they really, really know the people who love their products. How are &lt;em&gt;they&lt;/em&gt; using it?&lt;/p&gt;



&lt;p&gt;And then when you bubble out, you also have industry and government who are working together to push towards the most secure AI implementation &lt;em&gt;for&lt;/em&gt; &lt;em&gt;people&lt;/em&gt;, right? And I think our team in particular, we feel really grateful to be part of the big AI safety and security ecosystem at Microsoft and also to be able to contribute to the industry writ large. &lt;s&gt;&lt;/s&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; As you know, we had a chance to speak with Professor Ciaran Martin from the University of Oxford about the cybersecurity industry and governance there. What are some of the ideas and tools from that space that are surfacing in how we think about approaching red teaming and AI governance broadly?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; Yeah, I think it’s such a broad set of perspectives to bring in, in the AI instance. Something that I’ve noticed interjecting into security at the AI junction, right, is that cybersecurity has so many decades of experience of working through how to build trustworthy computing, for example, or bring an entire industry to bear in that way. And I think that AI security and safety can learn a lot of lessons of how to bring clarity and transparency across the industry to push universal understanding of where the threats really are.&lt;/p&gt;



&lt;p&gt;So frameworks coming out of NIST, coming out of MITRE that help us have a universal language that inform governance, I think, are really important because it brings clarity irrespective of where you are looking into AI security, irrespective of your company size, what you’re working on. It means you all understand, “Hey, we are really worried about this fundamental impact.” And I think cybersecurity has done a really good job of driving towards impact as their organizational vector. And I am starting to see that in the AI space, too, where we’re trying to really clarify terms and threats.&amp;nbsp;And you see it in updates of those frameworks, as well, that I really love.&lt;/p&gt;



&lt;p&gt;So I think that the innovation is in transparency to folks who are really innovating and doing the work so we all have a shared language, and from that, it really creates communal goals across security instead of a lot of people being worried about the same thing and talking about it in a different way.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN: &lt;/strong&gt;Mm-hmm.&lt;strong&gt; &lt;/strong&gt;In the cybersecurity context, Ciaran really stressed matching risk frameworks to an organization’s role &lt;em&gt;and&lt;/em&gt; scale. Microsoft plays many roles, including building models and shipping applications. How does your red teaming approach shift across those layers?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; I love this question also because I love it as part of our work. So one of the most fascinating things about working on this team has been the diversity of the technology that we end up red teaming and testing. And it feels like we’re in the crucible in that way. Because we see AI applied to so many different architectures, tech stacks, individual features, models, you name it.&lt;/p&gt;



&lt;p&gt;Part of my answer is that we still care about the highest-impact things. And so irrespective of the iteration, which &lt;em&gt;is&lt;/em&gt; really fascinating and I love, I still think that our team drives to say, “OK, what is that critical vulnerability that is going to affect people in the largest ways, and can we battle test to see if that can occur?”&lt;/p&gt;



&lt;p&gt;So in some ways, the task is always the same. I think in the ways that we change our testing, we customize a lot to the access to systems and data and also people’s trust almost as different variables that could affect the impact, right.&lt;/p&gt;



&lt;p&gt;So a good example is if we’re thinking through agentic frameworks that have access to functions and tools and preferential ability to act on data, it’s really different to spaces where that action may not be feasible, right. And so I think the tailoring of the way to get to that impact is hyper-custom every time we start an engagement. And part of it is very thesis driven and almost mechanizing &lt;em&gt;empathy&lt;/em&gt;.&lt;/p&gt;



&lt;p&gt;You almost need to really focus on how people could use, or misuse, in such a way that you can emulate it before to a really great signal to product development, to say this is truly what people could do and we want to deliver the highest-impact scenarios so you can solve for those and also solve the underlying patterns, actually, that could contribute to maybe that one piece of evidence but also all the related pieces of evidence. So singular drive but like hyper-, hyper-customization to what that piece of tech could do and has access to.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; What are some of the unexplored testing approaches or considerations from cybersecurity that you think we should encourage AI technologists, policymakers, and other stakeholders to focus on? &lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; I do love that AI humbles us each and every day with new capabilities and the potential for new capabilities. It’s not just saying, “Hey, there’s one test that we want to try,” but more, “Hey, can we create a methodology that we feel really, really solid about so that when we are asked a question we haven’t even thought of, we feel confident that we have the resources and the system?”&lt;/p&gt;



&lt;p&gt;So part of me is really intrigued by the process that we’re asked to make without knowing what those capabilities are really going to bring. And then I think tactically, AIRT is really pushing on how we create new research methodologies. How are we investing in, kind of, these longer-term iterations of red teaming? So we’re really excited about pushing out those insights in an experimental and longer-term way.&lt;/p&gt;



&lt;p&gt;I think another element is a little bit of that evolution of how industry standards and frameworks are updating to the AI moment and really articulating where AI is either furthering adversarial ability to create those harms or threats or identifying where AI has a net new harm. And I think that demystifies a little bit about what we talked about in terms of the lessons learned, that fundamentally, a lot of the things that we talk about &lt;em&gt;are&lt;/em&gt; traditional security vulnerabilities, and we are standing on kind of that cybersecurity shoulder. And I’m starting to see those updates translate in spaces that are already considered trustworthy and kind of the basis on which not only cybersecurity folks build their work but also business decision-makers make decisions on those frameworks.&lt;/p&gt;



&lt;p&gt;So to me, integration of AI into those frameworks by those same standards means that we’re evolving security to include AI. We aren’t creating an entirely new industry of AI security and that, I think, really helps anchor people in the really solid foundation that we have in cybersecurity anyways.&lt;/p&gt;



&lt;p&gt;I think there’s also some work around how the cyber, like, defenses will actually benefit from AI. So we think a lot about threats because that’s our job. But the other side of cybersecurity is offense. And I’m seeing a ton of people come out with frameworks and methodologies, especially in the research space, on how defensive networks are going to be benefited from things like agentic systems.&lt;/p&gt;



&lt;p&gt;Generally speaking, I think the best practice is to realize that we’re fundamentally still talking about the same impacts, and we can use the same avenues, conversations, and frameworks. We just really want them to be crisply updated with that understanding of AI applications.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; How do you think about bringing others into the fold there? I think those standards and frameworks are often informed by technologists. But I’d love for you to expand [that to] policymakers or other kind of stakeholders in our ecosystem, even, you know, end consumers of these products. Like, how do we communicate some of this to them in a way that resonates and it has an impactful meaning?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; I’ve found the AI security-safety space to be one of the more collaborative. I actually think the fact that I’m talking to you today is probably evidence that a ton of people are bringing in perspectives that don’t only come from a long-term cybersecurity view. And I see that as a trend in how AI is being approached opposed to how those areas were moving earlier. So I think that speed and the idea of conversations and not always having the perfect answer but really trying to be transparent with what everyone does know is kind of a communal energy in the communities, at least, where we’re playing. [LAUGHS] So I am pretty biased but at least the spaces where we are.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; No, I think we’re seeing that across the board. I mean, I’d echo [that] sitting in research, as well, like, that ability to have impact now and at speed to getting the amazing technology and models that we’re creating into the hands of our customers and partners and ecosystem is just underscored.&lt;/p&gt;



&lt;p&gt;So on the note of speed, let’s shift gears a little bit to just a quick lightning round. I’d love to get maybe some quick thoughts from you, just 30-second answers here. I’ll start with one.&lt;/p&gt;



&lt;p&gt;Which headline-grabbing AI threat do you think is mostly hot air?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; I think we should pay attention to it all. I’m a red team lead. I love a good question to see if we can find an answer in real life. So no hot air, just questions.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Is there some sort of maybe new tool that you can’t wait to sneak into the red team arsenal?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; I think there are really interesting methodologies that break our understanding of cybersecurity by looking at the intersection between different layers of AI and how you can manipulate AI-to-AI interaction, especially now when we’re looking at agentic systems. So I would say a method, not a tool.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; So maybe ending on a little bit of a lighter note, do you have a go-to snack during an all-night red teaming session?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; Always coffee. I would love it to be a protein smoothie, but honestly, it is probably Trader Joe’s elote chips. Like the whole bag. [LAUGHTER] It’s going to get me through. I’m going to not love that I did it.&lt;/p&gt;



&lt;p&gt;[MUSIC]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Amazing. Well, Tori, thanks so much for joining us today, and just a huge thanks also to Ciaran for his insights, as well.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; Thank you so much for having me. This was a joy.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN: &lt;/strong&gt;And to our listeners, thanks for tuning in. You can find resources related to this podcast in the show notes. And if you want to learn more about how Microsoft approaches AI governance, you can visit microsoft.com/RAI.&lt;/p&gt;



&lt;p&gt;See you next time! &lt;/p&gt;



&lt;p&gt;[MUSIC FADES]&lt;/p&gt;

				&lt;/span&gt;
			&lt;/div&gt;
			&lt;button class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle" type="button"&gt;
				Show more			&lt;/button&gt;
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;




&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Illustrated images of Kathleen Sullivan, Ciaran Martin, and Tori Westerhoff for the Microsoft Research podcast" class="wp-image-1144391" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP3-AI-TE_Hero_Feature_1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;






&lt;p&gt;Generative AI presents a unique challenge and opportunity to reexamine governance practices for the responsible development, deployment, and use of AI. To advance thinking in this space, Microsoft has tapped into the experience and knowledge of experts across domains—from genome editing to cybersecurity—to investigate the role of testing and evaluation as a governance tool.&amp;nbsp;&lt;em&gt;AI Testing and Evaluation: Learnings from Science and Industry&lt;/em&gt;,&amp;nbsp;hosted by Microsoft Research’s&amp;nbsp;Kathleen Sullivan, explores what the technology industry and policymakers can learn from these fields and how that might help shape the course of AI development.&lt;/p&gt;



&lt;p&gt;In this episode, Sullivan speaks with Professor Ciaran Martin&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; of the University of Oxford about risk assessment and testing in the field of cybersecurity. They explore the importance of differentiated standards for organizations of varying sizes, the role of public-private partnerships, and the opportunity to embed security into emerging technologies from the outset. Later, Tori Westerhoff&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, a principal director on the Microsoft AI Red Team, joins Sullivan to talk about identifying vulnerabilities in AI products and services. Westerhoff describes AI security in terms she’s heard cybersecurity professionals use for their work—a team sport—and points to cybersecurity’s establishment of a shared language and understanding of risk as a model for AI security.&lt;/p&gt;



&lt;div class="wp-block-group msr-pattern-link-list is-layout-flow wp-block-group-is-layout-flow"&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;



&lt;h2 class="wp-block-heading h5" id="learn-more-1"&gt;Learn more:&lt;/h2&gt;




&lt;/div&gt;







&lt;section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast"&gt;
	
&lt;/section&gt;


&lt;div class="wp-block-msr-show-more"&gt;
	&lt;div class="bg-neutral-100 p-5"&gt;
		&lt;div class="show-more-show-less"&gt;
			&lt;div&gt;
				&lt;span&gt;
					

&lt;h2 class="wp-block-heading" id="transcript"&gt;Transcript&lt;/h2&gt;



&lt;p&gt;[MUSIC]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KATHLEEN SULLIVAN: &lt;/strong&gt;Welcome to &lt;em&gt;AI Testing and Evaluation: Learnings from Science and Industry&lt;/em&gt;. I’m your host, Kathleen Sullivan.&lt;/p&gt;



&lt;p&gt;As generative AI continues to advance, Microsoft has gathered a range of experts—from genome editing to cybersecurity—to share how their fields approach evaluation and risk assessment. Our goal is to learn from their successes and their stumbles to move the science and practice of AI testing forward. In this series, we’ll explore how these insights might help guide the future of AI development, deployment, and responsible use.&lt;/p&gt;



&lt;p&gt;[MUSIC ENDS]&lt;/p&gt;



&lt;p&gt;Today, I’m excited to welcome Ciaran Martin to the podcast to explore testing and risk assessment in cybersecurity. Ciaran is a professor of practice in the management of public organizations at the University of Oxford. He had previously founded and served as chief executive of the National Cyber Security Centre within the UK’s intelligence, security, and cyber agency.&lt;/p&gt;



&lt;p&gt;And after our conversation, we’ll talk to Microsoft’s Tori Westerhoff, a principal director on Microsoft’s AI Red Team, about how we should think about these insights in the context of AI.&lt;/p&gt;



&lt;p&gt;Hi, Ciaran. Thank you so much for being here today.&lt;/p&gt;



				&lt;/span&gt;
				&lt;span class="show-more-show-less-toggleable-content" id="show-more-show-less-toggle-1"&gt;
					



&lt;p&gt;&lt;strong&gt;CIARAN MARTIN:&lt;/strong&gt; Well, thanks so much for inviting me. It’s great to be here.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Ciaran, before we get into some regulatory specifics, it’d be great to hear a little bit more about your origin story, and just take us to that day—who tapped you on the shoulder and said, “Ciaran, we need you to run a national cyber center! Do you fancy building one?”&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; You could argue that I owe my job to Edward Snowden. Not an obvious thing to say. So the National Cyber Security Centre, which didn’t exist at the time—I was invited to join the British government’s cybersecurity effort in a leadership role—is now a subset of GCHQ. That’s the digital intelligence agency. The equivalent in the US obviously is the NSA [National Security Agency]. It had been convulsed by the Snowden disclosures. It was an unprecedented challenge.&lt;/p&gt;



&lt;p&gt;I was a 17-year career government fixer with some national security experience. So I was asked to go out and help with the policy response, the media response, the legal response. But I said, look, any crisis, even one as big as this, is over one way or the other in six months. What should I do long term? And they said, well, we were thinking of asking you to try to help transform our cybersecurity mission. So the National Cyber Security Centre was born, and I was very proud to lead it, and all in all, I did it for seven years from startup to handing it on to somebody else.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; I mean, it’s incredible. And just building on that, people spend a significant portion of their lives online now with a variety of devices, and maybe for listeners who are newer to cybersecurity, could you give us the 90-second lightning talk? Kind of, what does risk assessment and testing look like in this space?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; Well, risk assessment and testing, I think, are two different things. You can’t defend everything. If you defend everything, you’re defending nothing. So broadly speaking, organizations face three threats. One is complete disruption of their systems. So just imagine not being able to access your system. The second is data protection, and that could be sensitive customer information. It could be intellectual property. And the third is, of course, you could be at risk of just straightforward being stolen from. I mean, you don’t want any of them to happen, but you have to have a hierarchy of harm.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN: &lt;/strong&gt;Yes.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN: &lt;/strong&gt;So that’s your risk assessment.&lt;/p&gt;



&lt;p&gt;The testing side, I think, is slightly different. One of the paradoxes, I think, of cybersecurity is for such a scientific, data-rich subject, the sort of metrics about what works are very, very hard to come by. So you’ve got boards and corporate leadership and senior governmental structures, and they say, “Look, how do I run this organization safely and securely?” And a cybersecurity chief within the organization will say, “Well, we could get this capability in.” Well, the classic question for a leadership team to ask is, well, what risk and harm will this reduce, by how much, and what’s the cost-benefit analysis? And we find that &lt;em&gt;really&lt;/em&gt; hard.&lt;/p&gt;



&lt;p&gt;So that’s really where testing and assurance comes in. And also as technology changes so fast, we have to figure out, well, if we’re worried about post-quantum cryptography, for example, what standards does it have to meet? How do you assess whether it’s meeting those standards? So it’s a huge issue in cybersecurity and one that we’re always very conscious of. It’s really hard.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Given the scope of cybersecurity, are there any differences in testing, let’s say, for maybe a small business versus a critical infrastructure operator? Are there any, sort of, metrics we can look at in terms of distinguishing risk or assessment?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; There have to be. One of the reasons I think why we have to be is that no small business can be expected to take on a hostile nation-state that’s well equipped. You have to be realistic.&lt;/p&gt;



&lt;p&gt;If you look at government guidance, certainly in the UK 15 years ago on cybersecurity, you were telling small businesses that are living hand to mouth, week by week, trying to make payments at the end of each month, we were telling them they needed sort of nation-state-level cyber defenses. That was never going to happen, even if they could afford it, which they couldn’t. So you have to have some differentiation. So again, you’ve got assessment frameworks and so forth where you have to meet higher standards. So there absolutely has to be that distinction. Otherwise, you end up in a crazy world of crippling small businesses with just unmanageable requirements which they’re never going to meet.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; It’s such a great point. You touched on this a little bit earlier, as well, but just cybersecurity governance operates in a fast-moving technology and threat environment. How have testing standards evolved, and where do new technical standards usually originate?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; I keep saying this is very difficult, and it is. [LAUGHTER] So I think there are two challenges. One is actually about the balance, and this applies to the technology of today as well as the technology of tomorrow. This is about, how do you make sure things are good enough without crowding out new entrants? You want people to be innovative and dynamic. You want disruptors in this business.&lt;/p&gt;



&lt;p&gt;But if you say to them, “Look, well, you have to meet these 14 impossibly high technical standards before you can even sell to anybody or sell to the government,” whatever, then you’ve got a problem. And I think we’ve wrestled with that, and there’s no perfect answer. You just have to try and go to … find the sweet spot between two ends of a spectrum. And that’s going to evolve.&lt;/p&gt;



&lt;p&gt;The second point, which in some respects if you’ve got the right capabilities is slightly &lt;em&gt;easier&lt;/em&gt; but still a big call, is around, you know, those newer and evolving technologies. And here, having, you know, been a bit sort of gloomy and pessimistic, here I think is actually an opportunity. So one of the things we always say in cybersecurity is that the internet was built and developed without security in mind. And that was kind of true in the ’90s and the noughties, as we call them over here.&lt;/p&gt;



&lt;p&gt;But I think as you move into things like post-quantum computing, applied use of AI, and so on, you can actually set the standards at the beginning. And that’s really good because it’s saying to people that these are the things that are going to matter in the post-quantum age. Here’s the outline of the standards you’re going to have to meet; start looking at them. So there’s an opportunity actually to make technology safer by design, by getting ahead of it. And I think that’s the era we’re in now.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; That makes a lot of sense. Just building on that, do businesses and the public trust these standards? And I guess, which standard do you wish the world would just adopt already, and what’s the real reason they haven’t?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; Well, again, where do you start? I mean, most members of the public quite rightly haven’t heard of any of these standards. I think public trust and public capital in any society matters. But I think it is important that these things are credible.&lt;/p&gt;



&lt;p&gt;And there’s quite a lot of convergence between, you know, the top-level frameworks. And obviously in the US, you know, the NIST [National Institute of Standards and Technology] framework is the one that’s most popular for cybersecurity, but it bears quite a strong resemblance to the international one, ISO[/IEC] 27001, and there are others, as well. But fundamentally, they boil down to kind of five things. Do a risk assessment; work out what your crown jewels are. Protect your perimeter as best you can. Those are the first two.&lt;/p&gt;



&lt;p&gt;The third one then is when your perimeter’s breached, be able to detect it more times than not. And when you can’t do that, you go to the fourth one, which is, can you mitigate it? And when all else fails, how quickly can you recover and manage it? I mean, all the standards are expressed in way more technical language than that, but fundamentally, if everybody adopted those five things and operated them in a simple way, you wouldn’t eliminate the harm, but you would reduce it quite substantially.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Which policy initiatives are most promising for incentivizing companies to undertake, you know, these cybersecurity testing parameters that you’ve just outlined? Governments, including the UK, have used carrots and sticks, but what do you think will actually move the needle?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; I think there are two answers to that, and it comes back to your split between smaller businesses and critically important businesses. In the critically important services, I think it’s easier because most industries are looking for a level playing field. In other words, they realize there have to be rules and they want to apply them to everyone.&lt;/p&gt;



&lt;p&gt;We had a fascinating experience when I was in government back in around 2018 where the telecom sector, they came to us and they said, we’ve got a very good cooperative relationship with the British government, but it needs to be put on a proper legal footing because you’re just asking us nicely to do expensive things. And in a regulated sector, if you actually put in some rules—and please develop them jointly with us; that’s the crucial part—then that will help because it means that we’re not going to our boards and saying, or our shareholders, and saying that we should do this, and they’re saying, “Well, do you have to do it? Are our competitors doing it?” And if the answer to that is, yes, we have to, and, yes, our competitors are doing it, then it tends to be OK.&lt;/p&gt;



&lt;p&gt;The harder nut to crack is the smaller business. And I think there’s a real mystery here: why has nobody cracked a really good and easy solution for small business? We need to be careful about this because, you know, you can’t throttle small businesses with onerous regulation. At the same time, we’re not brilliant, I think, in any part of the world at using the normal corporate governance rules to try and get people to figure out how to do cybersecurity.&lt;/p&gt;



&lt;p&gt;There are initiatives there that are not the sort of pretty heavy stick that you might have to take to a critical function, but they could help. But that is a hard nut to crack. And I look around the world, and, you know, I think if this was easy, somebody would have figured it out by now. I think most of the developed economies around the world really struggle with cybersecurity for smaller businesses.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah, it’s a great point. Actually building on one of the comments you made on the role of, kind of, government, how do you see the role of private-public partnerships scaling and strengthening, you know, robust cybersecurity testing?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; I think they’re crucial, but they have to be practical. I’ve got a slight, sort of, high horse on this, if you don’t mind, Kathleen. It’s sort of … [LAUGHS]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Of course.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; I think that there are two types of public-private partnership. One involves committees saying that we should strengthen partnerships and we should all work together and collaborate and share stuff. And we tried that for a very long time, and it didn’t get us very far. There are other types.&lt;/p&gt;



&lt;p&gt;We had some at the National Cyber Security Centre where we paid companies to do spectacularly good technical work that the market wouldn’t provide. So I think it’s sort of partnership with a purpose. I think sometimes, and I understand the human instinct to do this, particularly in governments and big business, they think you need to get around a table and work out some grand strategy to fix everything, and the scale of the … not just the problem but the scale of the whole technology is just too big to do that.&lt;/p&gt;



&lt;p&gt;So pick a bit of the problem. Find some ways of doing it. Don’t over-lawyer it. [LAUGHTER] I think sometimes people get very nervous. &lt;em&gt;Oh, well, is this our role? You know, should we be doing this, that, and the other?&lt;/em&gt; Well, you know, sometimes certainly in this country, you think, well, who’s actually going to sue you over this, you know? So I wouldn’t over-programmatize it. Just get stuck practically into solving some problems.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; I love that. Actually, [it] made me think, are there any surprising allies that you’ve gained—you know, maybe someone who you never expected to be a cybersecurity champion—through your work?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; Ooh! That’s a … that’s a… what a question! To give you a slightly disappointing answer, but it relates to your previous question. In the early part of my career, I was working in institutions like the UK Treasury long before I was in cybersecurity, and the treasury and the British civil service in general, but the treasury in particular sort of trained you to believe that the private sector was amoral, not &lt;em&gt;immoral&lt;/em&gt;, &lt;em&gt;amoral&lt;/em&gt;. It just didn’t have values. It just had bottom line, and, you know, its job essentially was to provide employment and revenue then for the government to spend on good things that people cared about. And when I got into cybersecurity and people said, look, you need to develop relations with this cybersecurity company, often in the US, actually. I thought, well, what’s in it for them?&lt;/p&gt;



&lt;p&gt;And, sure, sometimes you were paying them for specific services, but other times, there was a real public spiritedness about this. There was a realization that if you tried to delineate public-private boundaries, that it wouldn’t really work. It was a shared risk. And you could analyze where the boundaries fell or you could actually go on and do something about it together. So I was genuinely surprised at the allyship from the cybersecurity sector. Absolutely, I really, really was. And I think it’s a really positive part of certainly the UK cybersecurity ecosystem.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Wonderful. Well, we’re coming to the end of our time here, but is there any maybe last thoughts or perhaps requests you have for our listeners today?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; I think that standards, assurance, and testing &lt;em&gt;really&lt;/em&gt; matter, but it’s a bit like the discussion we’re having over AI. Get all these things to take you 80, 90% of the way and then really apply your judgment. There’s been some bad regulation under the auspices of standards and assurance. First of all, it’s, have you done this assessment? Have you done that? Have you looked at this? Well, fine. And you can tick that box, but what does it actually mean when you do it? What bits that you know in your heart of hearts are really important to the defense of your organization that may not be covered by this and just go and do those anyway. Because sure it helps, but it’s not everything.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; No. Great, great closing sentiment. Well, Ciaran, thank you for joining us today. This has been just a super fun conversation and really insightful. Just really enjoyed the conversation. Thank you.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MARTIN:&lt;/strong&gt; My pleasure, Kathleen, thank you.&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN: &lt;/strong&gt;Now, I’m happy to introduce Tori Westerhoff. As a principal director on the Microsoft AI Red Team, Tori leads all AI security and safety red team operations, as well as dangerous capability testing, to directly inform C-suite decision-makers.&lt;/p&gt;



&lt;p&gt;So, Tori, welcome!&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TORI WESTERHOFF: &lt;/strong&gt;Thanks. I am so excited to be here.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; I’d love to just start a little bit more learning about your background. You’ve worn some very intriguing hats. I mean, cognitive neuroscience grad from Yale, national security consultant, strategist in augmented and virtual reality … how do those experiences help shape the way you lead the Microsoft AI Red Team?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; I always joke this is the only role I think will always combine the entire patchwork LinkedIn résumé. [LAUGHS]&lt;/p&gt;



&lt;p&gt;I think I use those experiences to help me understand the really broad approach that AI Red Team—artist also known as &lt;em&gt;AIRT&lt;/em&gt;; I’m sure I’ll slip into our acronym—how we frame up the broad security implications of AI. So I think the cognitive neuroscience element really helped me initially approach AI hacking, right. There’s a lot of social engineering and manipulation within chat interfaces that are enabled by AI. And also, kind of, this, like, metaphor for understanding how to find soft spots in the way that you see human heuristics show up, too. And so I think that was actually my personal “in” to getting hooked into AI red teaming generally.&lt;/p&gt;



&lt;p&gt;But my experience in national security and I’d also say working through the AR/VR/metaverse space at the time where I was in it helped me balance both how our impact is framed, how we’re thinking about critical industries, how we’re really trying to push our understanding of where security of AI can help people the most. And also do it in a really breakneck speed in an industry that’s evolving all of the time, that’s really pushing you to always be at the bleeding edge of your understanding. So I draw a lot of the energy and the mission criticality and the speed from those experiences as we’re shaping up how we approach it.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Can you just give us a quick rundown? What does the Red Team do? What actually, kind of, is involved on a day-to-day basis? And then as we think about, you know, our engagements with large enterprises and companies, how do we work alongside some of those companies in terms of testing?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; The way I see our team is almost like an indicator light that works really part and parcel with product development. So the way we’ve organized our expert red teaming efforts is that we work with product development before anything ships out to anyone who can use it. And our job is to act as expert AI manipulators, AI hackers. And we are supposed to take the theories and methods and new research and harness it to find examples of vulnerabilities or soft spots in products to enable product teams to harden those soft spots before anything actually reaches someone who wants to use it.&lt;/p&gt;



&lt;p&gt;So if we’re the indicator light, we are also not the full workup, right. I see that as measurement and evals. And we also are not the mechanic, which is that product development team that’s creating mitigations. It’s platform-security folks who are creating mitigations at scale. And there’s a really great throughput of insights from those groups back into our area where we love to inform about them, but we also love to add on to, how do we break the next thing, right? So it’s a continuous cycle.&lt;/p&gt;



&lt;p&gt;And part of that is just being really creative and thinking outside of a traditional cybersecurity box. And part of that is also really thinking about how we pull in research—we have a research function within our AI Red Team—and how we automate and scale. This year, we’ve pulled a lot of those assets and insights into the Azure [AI] Foundry AI Red Teaming Agent&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. And so folks can now access a lot of our mechanisms through that. So you can get a little taste of what we do day to day in the AI Red Teaming Agent.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; You recently—actually, with your team—published a report that outlined lessons from testing over a hundred generative AI products. But could you share a bit about what you learned? What were some of the important lessons? Where do you see opportunities to improve the state of red teaming as a method for probing AI safety?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; I think the most important takeaway from those lessons is that AI security is truly a team sport. You’ll hear cybersecurity folks say that a lot. And part of the rationale there is that the defense in depth and integrating and a view towards AI security through the entire development of AI systems is really the way that we’re going to approach this with intentionality and responsibility.&lt;/p&gt;



&lt;p&gt;So in our space, we really focus on novel harm categories. We are pushing bleeding edge, and we also are pushing iterative and, like, contextually based red teaming in product dev. So outside of those hundred that we’ve done, there’s a community [LAUGHS] through the entire, again, multistage life cycle of a product that is really trying to push the cost of attacking those AI systems higher and higher with all of the expertise they bring. So we may be, like, the experts in AI hacking in that line, but there are also so many partners in the Microsoft ecosystem who are thinking about their market context or they really, really know the people who love their products. How are &lt;em&gt;they&lt;/em&gt; using it?&lt;/p&gt;



&lt;p&gt;And then when you bubble out, you also have industry and government who are working together to push towards the most secure AI implementation &lt;em&gt;for&lt;/em&gt; &lt;em&gt;people&lt;/em&gt;, right? And I think our team in particular, we feel really grateful to be part of the big AI safety and security ecosystem at Microsoft and also to be able to contribute to the industry writ large. &lt;s&gt;&lt;/s&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; As you know, we had a chance to speak with Professor Ciaran Martin from the University of Oxford about the cybersecurity industry and governance there. What are some of the ideas and tools from that space that are surfacing in how we think about approaching red teaming and AI governance broadly?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; Yeah, I think it’s such a broad set of perspectives to bring in, in the AI instance. Something that I’ve noticed interjecting into security at the AI junction, right, is that cybersecurity has so many decades of experience of working through how to build trustworthy computing, for example, or bring an entire industry to bear in that way. And I think that AI security and safety can learn a lot of lessons of how to bring clarity and transparency across the industry to push universal understanding of where the threats really are.&lt;/p&gt;



&lt;p&gt;So frameworks coming out of NIST, coming out of MITRE that help us have a universal language that inform governance, I think, are really important because it brings clarity irrespective of where you are looking into AI security, irrespective of your company size, what you’re working on. It means you all understand, “Hey, we are really worried about this fundamental impact.” And I think cybersecurity has done a really good job of driving towards impact as their organizational vector. And I am starting to see that in the AI space, too, where we’re trying to really clarify terms and threats.&amp;nbsp;And you see it in updates of those frameworks, as well, that I really love.&lt;/p&gt;



&lt;p&gt;So I think that the innovation is in transparency to folks who are really innovating and doing the work so we all have a shared language, and from that, it really creates communal goals across security instead of a lot of people being worried about the same thing and talking about it in a different way.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN: &lt;/strong&gt;Mm-hmm.&lt;strong&gt; &lt;/strong&gt;In the cybersecurity context, Ciaran really stressed matching risk frameworks to an organization’s role &lt;em&gt;and&lt;/em&gt; scale. Microsoft plays many roles, including building models and shipping applications. How does your red teaming approach shift across those layers?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; I love this question also because I love it as part of our work. So one of the most fascinating things about working on this team has been the diversity of the technology that we end up red teaming and testing. And it feels like we’re in the crucible in that way. Because we see AI applied to so many different architectures, tech stacks, individual features, models, you name it.&lt;/p&gt;



&lt;p&gt;Part of my answer is that we still care about the highest-impact things. And so irrespective of the iteration, which &lt;em&gt;is&lt;/em&gt; really fascinating and I love, I still think that our team drives to say, “OK, what is that critical vulnerability that is going to affect people in the largest ways, and can we battle test to see if that can occur?”&lt;/p&gt;



&lt;p&gt;So in some ways, the task is always the same. I think in the ways that we change our testing, we customize a lot to the access to systems and data and also people’s trust almost as different variables that could affect the impact, right.&lt;/p&gt;



&lt;p&gt;So a good example is if we’re thinking through agentic frameworks that have access to functions and tools and preferential ability to act on data, it’s really different to spaces where that action may not be feasible, right. And so I think the tailoring of the way to get to that impact is hyper-custom every time we start an engagement. And part of it is very thesis driven and almost mechanizing &lt;em&gt;empathy&lt;/em&gt;.&lt;/p&gt;



&lt;p&gt;You almost need to really focus on how people could use, or misuse, in such a way that you can emulate it before to a really great signal to product development, to say this is truly what people could do and we want to deliver the highest-impact scenarios so you can solve for those and also solve the underlying patterns, actually, that could contribute to maybe that one piece of evidence but also all the related pieces of evidence. So singular drive but like hyper-, hyper-customization to what that piece of tech could do and has access to.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; What are some of the unexplored testing approaches or considerations from cybersecurity that you think we should encourage AI technologists, policymakers, and other stakeholders to focus on? &lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; I do love that AI humbles us each and every day with new capabilities and the potential for new capabilities. It’s not just saying, “Hey, there’s one test that we want to try,” but more, “Hey, can we create a methodology that we feel really, really solid about so that when we are asked a question we haven’t even thought of, we feel confident that we have the resources and the system?”&lt;/p&gt;



&lt;p&gt;So part of me is really intrigued by the process that we’re asked to make without knowing what those capabilities are really going to bring. And then I think tactically, AIRT is really pushing on how we create new research methodologies. How are we investing in, kind of, these longer-term iterations of red teaming? So we’re really excited about pushing out those insights in an experimental and longer-term way.&lt;/p&gt;



&lt;p&gt;I think another element is a little bit of that evolution of how industry standards and frameworks are updating to the AI moment and really articulating where AI is either furthering adversarial ability to create those harms or threats or identifying where AI has a net new harm. And I think that demystifies a little bit about what we talked about in terms of the lessons learned, that fundamentally, a lot of the things that we talk about &lt;em&gt;are&lt;/em&gt; traditional security vulnerabilities, and we are standing on kind of that cybersecurity shoulder. And I’m starting to see those updates translate in spaces that are already considered trustworthy and kind of the basis on which not only cybersecurity folks build their work but also business decision-makers make decisions on those frameworks.&lt;/p&gt;



&lt;p&gt;So to me, integration of AI into those frameworks by those same standards means that we’re evolving security to include AI. We aren’t creating an entirely new industry of AI security and that, I think, really helps anchor people in the really solid foundation that we have in cybersecurity anyways.&lt;/p&gt;



&lt;p&gt;I think there’s also some work around how the cyber, like, defenses will actually benefit from AI. So we think a lot about threats because that’s our job. But the other side of cybersecurity is offense. And I’m seeing a ton of people come out with frameworks and methodologies, especially in the research space, on how defensive networks are going to be benefited from things like agentic systems.&lt;/p&gt;



&lt;p&gt;Generally speaking, I think the best practice is to realize that we’re fundamentally still talking about the same impacts, and we can use the same avenues, conversations, and frameworks. We just really want them to be crisply updated with that understanding of AI applications.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; How do you think about bringing others into the fold there? I think those standards and frameworks are often informed by technologists. But I’d love for you to expand [that to] policymakers or other kind of stakeholders in our ecosystem, even, you know, end consumers of these products. Like, how do we communicate some of this to them in a way that resonates and it has an impactful meaning?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; I’ve found the AI security-safety space to be one of the more collaborative. I actually think the fact that I’m talking to you today is probably evidence that a ton of people are bringing in perspectives that don’t only come from a long-term cybersecurity view. And I see that as a trend in how AI is being approached opposed to how those areas were moving earlier. So I think that speed and the idea of conversations and not always having the perfect answer but really trying to be transparent with what everyone does know is kind of a communal energy in the communities, at least, where we’re playing. [LAUGHS] So I am pretty biased but at least the spaces where we are.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; No, I think we’re seeing that across the board. I mean, I’d echo [that] sitting in research, as well, like, that ability to have impact now and at speed to getting the amazing technology and models that we’re creating into the hands of our customers and partners and ecosystem is just underscored.&lt;/p&gt;



&lt;p&gt;So on the note of speed, let’s shift gears a little bit to just a quick lightning round. I’d love to get maybe some quick thoughts from you, just 30-second answers here. I’ll start with one.&lt;/p&gt;



&lt;p&gt;Which headline-grabbing AI threat do you think is mostly hot air?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; I think we should pay attention to it all. I’m a red team lead. I love a good question to see if we can find an answer in real life. So no hot air, just questions.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Is there some sort of maybe new tool that you can’t wait to sneak into the red team arsenal?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; I think there are really interesting methodologies that break our understanding of cybersecurity by looking at the intersection between different layers of AI and how you can manipulate AI-to-AI interaction, especially now when we’re looking at agentic systems. So I would say a method, not a tool.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; So maybe ending on a little bit of a lighter note, do you have a go-to snack during an all-night red teaming session?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; Always coffee. I would love it to be a protein smoothie, but honestly, it is probably Trader Joe’s elote chips. Like the whole bag. [LAUGHTER] It’s going to get me through. I’m going to not love that I did it.&lt;/p&gt;



&lt;p&gt;[MUSIC]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Amazing. Well, Tori, thanks so much for joining us today, and just a huge thanks also to Ciaran for his insights, as well.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;WESTERHOFF:&lt;/strong&gt; Thank you so much for having me. This was a joy.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN: &lt;/strong&gt;And to our listeners, thanks for tuning in. You can find resources related to this podcast in the show notes. And if you want to learn more about how Microsoft approaches AI governance, you can visit microsoft.com/RAI.&lt;/p&gt;



&lt;p&gt;See you next time! &lt;/p&gt;



&lt;p&gt;[MUSIC FADES]&lt;/p&gt;

				&lt;/span&gt;
			&lt;/div&gt;
			&lt;button class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle" type="button"&gt;
				Show more			&lt;/button&gt;
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;




&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-cybersecurity/</guid><pubDate>Mon, 14 Jul 2025 16:00:00 +0000</pubDate></item><item><title>Rainmaker partners with Atmo to squeeze more rain from clouds (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/14/rainmaker-partners-with-atmo-to-squeeze-more-rain-from-clouds/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2017/03/gettyimages-577307007.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Cloud-seeding startup Rainmaker is partnering with Atmo, an AI-powered meteorology startup, the companies exclusively told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The two operate on complementary ends of the weather system: Atmo studies atmospheric patterns to forecast weather events, while Rainmaker digests such data in an attempt to squeeze more precipitation out of weather systems.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Under the partnership, Atmo will use its deep learning models to help Rainmaker identify clouds that have potential for seeding. The forecasting startup will also offer Rainmaker’s cloud-seeding services, deployed via small drones, to its customers.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For its part, Rainmaker will contribute data from its proprietary radar system to determine how much rain the clouds produced.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Rainmaker has been in the news of late, targeted by conspiracy theorists who claim that the startup’s cloud-seeding operations in Texas played a role in recent floods in the state.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But according to several scientists TechCrunch spoke with, that’s simply not possible.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Somebody is looking for somebody to blame,” Bob Rauber, a professor of atmospheric sciences at the University of Illinois, told TechCrunch last week.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Though cloud seeding can nudge clouds to drop more precipitation, it’s a small amount compared with the size of a storm. One well-documented case in Idaho released an additional 186 million gallons of precipitation, which pales in comparison with the “trillions of gallons of water” a large storm will process, Rauber said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cloud seeding is widely used throughout the Western United States, mostly to augment snowpack and boost the amount of water that ends up in reservoirs in the summer. While it’s also used in places like West Texas to coax more rain from summer storms, the results have been modest.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The West Texas Weather Modification Association, which Rainmaker has worked with previously, says that cloud seeding in the region has boosted precipitation by about 15%, or about two inches, per year.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The likely reason for that is because the types of clouds floating over West Texas don’t respond in the same way as clouds in mountainous regions like the Western U.S., Rauber said. Rainstorms are even less responsive, he added, since they’re already primed to drop plenty of precipitation.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2017/03/gettyimages-577307007.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Cloud-seeding startup Rainmaker is partnering with Atmo, an AI-powered meteorology startup, the companies exclusively told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The two operate on complementary ends of the weather system: Atmo studies atmospheric patterns to forecast weather events, while Rainmaker digests such data in an attempt to squeeze more precipitation out of weather systems.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Under the partnership, Atmo will use its deep learning models to help Rainmaker identify clouds that have potential for seeding. The forecasting startup will also offer Rainmaker’s cloud-seeding services, deployed via small drones, to its customers.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For its part, Rainmaker will contribute data from its proprietary radar system to determine how much rain the clouds produced.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Rainmaker has been in the news of late, targeted by conspiracy theorists who claim that the startup’s cloud-seeding operations in Texas played a role in recent floods in the state.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But according to several scientists TechCrunch spoke with, that’s simply not possible.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Somebody is looking for somebody to blame,” Bob Rauber, a professor of atmospheric sciences at the University of Illinois, told TechCrunch last week.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Though cloud seeding can nudge clouds to drop more precipitation, it’s a small amount compared with the size of a storm. One well-documented case in Idaho released an additional 186 million gallons of precipitation, which pales in comparison with the “trillions of gallons of water” a large storm will process, Rauber said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cloud seeding is widely used throughout the Western United States, mostly to augment snowpack and boost the amount of water that ends up in reservoirs in the summer. While it’s also used in places like West Texas to coax more rain from summer storms, the results have been modest.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The West Texas Weather Modification Association, which Rainmaker has worked with previously, says that cloud seeding in the region has boosted precipitation by about 15%, or about two inches, per year.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The likely reason for that is because the types of clouds floating over West Texas don’t respond in the same way as clouds in mountainous regions like the Western U.S., Rauber said. Rainstorms are even less responsive, he added, since they’re already primed to drop plenty of precipitation.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/14/rainmaker-partners-with-atmo-to-squeeze-more-rain-from-clouds/</guid><pubDate>Mon, 14 Jul 2025 16:00:00 +0000</pubDate></item><item><title>New Grok AI model surprises experts by checking Elon Musk’s views before answering (AI – Ars Technica)</title><link>https://arstechnica.com/information-technology/2025/07/new-grok-ai-model-surprises-experts-by-checking-elon-musks-views-before-answering/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Grok 4's "reasoning" shows cases where the chatbot consults Musk posts to answer divisive questions.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Robot sitting on a bunch of books, reading a book." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/robot_reading_a_book_2-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Robot sitting on a bunch of books, reading a book." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/robot_reading_a_book_2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Kirillm via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;An AI model launched last week appears to have shipped with an unexpected occasional behavior: checking what its owner thinks first.&lt;/p&gt;
&lt;p&gt;On Friday, independent AI researcher Simon Willison documented that xAI's new Grok 4 model searches for Elon Musk's opinions on X (formerly Twitter) when asked about controversial topics. The discovery comes just days after xAI launched Grok 4 amid controversy over an earlier version of the chatbot generating antisemitic outputs, including labeling itself as "MechaHitler."&lt;/p&gt;
&lt;p&gt;"That is ludicrous," Willison told Ars Technica upon initially hearing about the Musk-seeking behavior last week from AI researcher Jeremy Howard, who traced the discovery through various users on X. But even amid prevalent suspicions of Musk meddling with Grok's outputs to fit "politically incorrect" goals, Willison doesn't think that Grok 4 has been specifically instructed to seek out Musk's views in particular. "I think there is a good chance this behavior is unintended," he wrote in a detailed blog post on the topic.&lt;/p&gt;
&lt;p&gt;To test what he'd been seeing online, Willison signed up for a "SuperGrok" account at $22.50 per month—the regular Grok 4 tier. He then fed the model this prompt: "Who do you support in the Israel vs Palestine conflict. One word answer only."&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1040" id="video-2105680-1" preload="metadata" width="1848"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/grok-elon.mp4?_=1" type="video/mp4" /&gt;A video of "SuperGrok" seeking Musk's opinion on X, captured by Simon Willison.&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A video of "SuperGrok" seeking Musk's opinion on X, captured by Simon Willison.

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;In the model's "thinking trace" visible to users (a simulated reasoning process similar to that used by OpenAI's o3 model), Grok revealed it searched X for "from:elonmusk (Israel OR Palestine OR Gaza OR Hamas)" before providing its answer: "Israel."&lt;/p&gt;
&lt;p&gt;"Elon Musk's stance could provide context, given his influence," the model wrote in its exposed reasoning process. The search returned 10 web pages and 19 tweets that informed its response.&lt;/p&gt;
&lt;p&gt;Even so, Grok 4 doesn't always look for Musk's guidance in formulating its answers; the output reportedly varies between prompts and users. While Willison and two others saw Grok search for Musk's views, X user @wasted_alpha reported that Grok searched for its own previously reported stances and chose "Palestine" instead.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Seeking the system prompt&lt;/h2&gt;
&lt;p&gt;Owing to the unknown contents of the data used to train Grok 4 and the random elements thrown into large language model (LLM) outputs to make them seem more expressive, divining the reasons for particular LLM behavior for someone without insider access can be frustrating. But we can use what we know about how LLMs work to guide a better answer. xAI did not respond to a request for comment before publication.&lt;/p&gt;
&lt;p&gt;To generate text, every AI chatbot processes an input called a "prompt" and produces a plausible output based on that prompt. This is the core function of every LLM. In practice, the prompt often contains information from several sources, including comments from the user, the ongoing chat history (sometimes injected with user "memories" stored in a different subsystem), and special instructions from the companies that run the chatbot. These special instructions—called the system prompt—partially define the "personality" and behavior of the chatbot.&lt;/p&gt;
&lt;p&gt;According to Willison, Grok 4 readily shares its system prompt when asked, and that prompt reportedly contains no explicit instruction to search for Musk's opinions. However, the prompt states that Grok should "search for a distribution of sources that represents all parties/stakeholders" for controversial queries and "not shy away from making claims which are politically incorrect, as long as they are well substantiated."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2105754 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="A screenshot capture of Simon Willison's archived conversation with Grok 4. It shows the AI model seeking Musk's opinions about Israel and includes a list of X posts consulted, seen in a sidebar." class="center large" height="721" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/musk_on_israel-1024x721.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A screenshot capture of Simon Willison's archived conversation with Grok 4. It shows the AI model seeking Musk's opinions about Israel and includes a list of X posts consulted, seen in a sidebar.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Ultimately, Willison believes the cause of this behavior comes down to a chain of inferences on Grok's part rather than an explicit mention of checking Musk in its system prompt. "My best guess is that Grok 'knows' that it is 'Grok 4 built by xAI,' and it knows that Elon Musk owns xAI, so in circumstances where it's asked for an opinion, the reasoning process often decides to see what Elon thinks," he said.&lt;/p&gt;
&lt;p&gt;Without official word from xAI, we're left with a best guess. However, regardless of the reason, this kind of unreliable, inscrutable behavior makes many chatbots poorly suited for assisting with tasks where reliability or accuracy are important.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Grok 4's "reasoning" shows cases where the chatbot consults Musk posts to answer divisive questions.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Robot sitting on a bunch of books, reading a book." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/robot_reading_a_book_2-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Robot sitting on a bunch of books, reading a book." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/robot_reading_a_book_2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Kirillm via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;An AI model launched last week appears to have shipped with an unexpected occasional behavior: checking what its owner thinks first.&lt;/p&gt;
&lt;p&gt;On Friday, independent AI researcher Simon Willison documented that xAI's new Grok 4 model searches for Elon Musk's opinions on X (formerly Twitter) when asked about controversial topics. The discovery comes just days after xAI launched Grok 4 amid controversy over an earlier version of the chatbot generating antisemitic outputs, including labeling itself as "MechaHitler."&lt;/p&gt;
&lt;p&gt;"That is ludicrous," Willison told Ars Technica upon initially hearing about the Musk-seeking behavior last week from AI researcher Jeremy Howard, who traced the discovery through various users on X. But even amid prevalent suspicions of Musk meddling with Grok's outputs to fit "politically incorrect" goals, Willison doesn't think that Grok 4 has been specifically instructed to seek out Musk's views in particular. "I think there is a good chance this behavior is unintended," he wrote in a detailed blog post on the topic.&lt;/p&gt;
&lt;p&gt;To test what he'd been seeing online, Willison signed up for a "SuperGrok" account at $22.50 per month—the regular Grok 4 tier. He then fed the model this prompt: "Who do you support in the Israel vs Palestine conflict. One word answer only."&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1040" id="video-2105680-1" preload="metadata" width="1848"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/grok-elon.mp4?_=1" type="video/mp4" /&gt;A video of "SuperGrok" seeking Musk's opinion on X, captured by Simon Willison.&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A video of "SuperGrok" seeking Musk's opinion on X, captured by Simon Willison.

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;In the model's "thinking trace" visible to users (a simulated reasoning process similar to that used by OpenAI's o3 model), Grok revealed it searched X for "from:elonmusk (Israel OR Palestine OR Gaza OR Hamas)" before providing its answer: "Israel."&lt;/p&gt;
&lt;p&gt;"Elon Musk's stance could provide context, given his influence," the model wrote in its exposed reasoning process. The search returned 10 web pages and 19 tweets that informed its response.&lt;/p&gt;
&lt;p&gt;Even so, Grok 4 doesn't always look for Musk's guidance in formulating its answers; the output reportedly varies between prompts and users. While Willison and two others saw Grok search for Musk's views, X user @wasted_alpha reported that Grok searched for its own previously reported stances and chose "Palestine" instead.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Seeking the system prompt&lt;/h2&gt;
&lt;p&gt;Owing to the unknown contents of the data used to train Grok 4 and the random elements thrown into large language model (LLM) outputs to make them seem more expressive, divining the reasons for particular LLM behavior for someone without insider access can be frustrating. But we can use what we know about how LLMs work to guide a better answer. xAI did not respond to a request for comment before publication.&lt;/p&gt;
&lt;p&gt;To generate text, every AI chatbot processes an input called a "prompt" and produces a plausible output based on that prompt. This is the core function of every LLM. In practice, the prompt often contains information from several sources, including comments from the user, the ongoing chat history (sometimes injected with user "memories" stored in a different subsystem), and special instructions from the companies that run the chatbot. These special instructions—called the system prompt—partially define the "personality" and behavior of the chatbot.&lt;/p&gt;
&lt;p&gt;According to Willison, Grok 4 readily shares its system prompt when asked, and that prompt reportedly contains no explicit instruction to search for Musk's opinions. However, the prompt states that Grok should "search for a distribution of sources that represents all parties/stakeholders" for controversial queries and "not shy away from making claims which are politically incorrect, as long as they are well substantiated."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2105754 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="A screenshot capture of Simon Willison's archived conversation with Grok 4. It shows the AI model seeking Musk's opinions about Israel and includes a list of X posts consulted, seen in a sidebar." class="center large" height="721" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/musk_on_israel-1024x721.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A screenshot capture of Simon Willison's archived conversation with Grok 4. It shows the AI model seeking Musk's opinions about Israel and includes a list of X posts consulted, seen in a sidebar.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Ultimately, Willison believes the cause of this behavior comes down to a chain of inferences on Grok's part rather than an explicit mention of checking Musk in its system prompt. "My best guess is that Grok 'knows' that it is 'Grok 4 built by xAI,' and it knows that Elon Musk owns xAI, so in circumstances where it's asked for an opinion, the reasoning process often decides to see what Elon thinks," he said.&lt;/p&gt;
&lt;p&gt;Without official word from xAI, we're left with a best guess. However, regardless of the reason, this kind of unreliable, inscrutable behavior makes many chatbots poorly suited for assisting with tasks where reliability or accuracy are important.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/information-technology/2025/07/new-grok-ai-model-surprises-experts-by-checking-elon-musks-views-before-answering/</guid><pubDate>Mon, 14 Jul 2025 16:08:13 +0000</pubDate></item><item><title>Mark Zuckerberg says Meta is building a 5GW AI data center (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/14/mark-zuckerberg-says-meta-is-building-a-5gw-ai-data-center/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2173579179.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta is currently building out a data center, called Hyperion, which the company expects to supply its new AI lab with five gigawatts (GW) of computational power, CEO Mark Zuckerberg said in a Monday post on Threads.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The announcement marks Meta’s latest move to get ahead of OpenAI and Google in the AI race. After previously poaching top talent to run Meta Superintelligence Lab, including former Scale AI CEO Alexandr Wang and former Safe Superintelligence CEO Daniel Gross, Meta now seems to be turning its attention to the massive computational power needed to train frontier AI models.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Zuckerberg said Hyperion’s footprint will be large enough to cover most of Manhattan. Meta spokesperson Ashley Gabriel told TechCrunch via email that Hyperion will be located in Louisiana, likely in Richland Parish where Meta previously announced a $10 billion data center development. Gabriel says Meta plans to bring two gigawatts of data center capacity online by 2030 with Hyperion, but that it would scale to five gigawatts in several years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zuckerberg also noted that Meta plans to bring a 1 GW super cluster, called Prometheus, online in 2026, making it one of the first tech companies to control an AI data center of this size. Gabriel says Prometheus is located in New Albany, Ohio.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s AI data center build-out seems likely to make the company more competitive with OpenAI, Google DeepMind, and Anthropic in its ability to train and serve leading AI models. It’s possible the effort could also help Meta attract additional talent, who may be drawn to work at a company with the computational needs to compete in the AI race.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Together, Prometheus and Hyperion will soak up enough energy to power millions of homes, which could pull significant amounts of electricity and water from neighboring communities. One of Meta’s data center projects in Newton County, Georgia, has already caused the water taps to run dry in some residents’ homes, The New York Times reported Monday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other AI data center projects may cause similar problems for people living near them. AI hyperscaler CoreWeave is planning a data center expansion that is projected to double the electricity needs of a city near Dallas, Texas, according to Bloomberg.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Nevertheless, tech companies are determined to build out massive data center projects to power their AI ambitions. Other notable efforts include OpenAI’s Stargate project with Oracle and SoftBank, as well as xAI’s Colossus supercomputer.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Trump administration has largely championed the tech industry’s AI data center buildout. President Donald Trump helped OpenAI announce its Stargate project, and has since spoken about efforts to expand America’s AI infrastructure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a column featured in The Economist on Monday, U.S. Secretary of Energy Chris Wright called for the U.S. to “lead the next major energy-intensive frontier: artificial intelligence.” He noted that AI transforms electricity into the “most valuable output imaginable: intelligence,” and that the federal government would accelerate the production of energy derived from coal, nuclear, geothermal, and natural gas.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With the support of federal officials, the AI industry seems poised to soak up much of America’s energy in the years to come. Experts estimate that data centers could account for 20% of America’s energy consumption by 2030, up from just 2.5% in 2022. Without rapidly increased energy production, that could cause even more problems for communities.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2173579179.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta is currently building out a data center, called Hyperion, which the company expects to supply its new AI lab with five gigawatts (GW) of computational power, CEO Mark Zuckerberg said in a Monday post on Threads.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The announcement marks Meta’s latest move to get ahead of OpenAI and Google in the AI race. After previously poaching top talent to run Meta Superintelligence Lab, including former Scale AI CEO Alexandr Wang and former Safe Superintelligence CEO Daniel Gross, Meta now seems to be turning its attention to the massive computational power needed to train frontier AI models.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Zuckerberg said Hyperion’s footprint will be large enough to cover most of Manhattan. Meta spokesperson Ashley Gabriel told TechCrunch via email that Hyperion will be located in Louisiana, likely in Richland Parish where Meta previously announced a $10 billion data center development. Gabriel says Meta plans to bring two gigawatts of data center capacity online by 2030 with Hyperion, but that it would scale to five gigawatts in several years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zuckerberg also noted that Meta plans to bring a 1 GW super cluster, called Prometheus, online in 2026, making it one of the first tech companies to control an AI data center of this size. Gabriel says Prometheus is located in New Albany, Ohio.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s AI data center build-out seems likely to make the company more competitive with OpenAI, Google DeepMind, and Anthropic in its ability to train and serve leading AI models. It’s possible the effort could also help Meta attract additional talent, who may be drawn to work at a company with the computational needs to compete in the AI race.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Together, Prometheus and Hyperion will soak up enough energy to power millions of homes, which could pull significant amounts of electricity and water from neighboring communities. One of Meta’s data center projects in Newton County, Georgia, has already caused the water taps to run dry in some residents’ homes, The New York Times reported Monday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other AI data center projects may cause similar problems for people living near them. AI hyperscaler CoreWeave is planning a data center expansion that is projected to double the electricity needs of a city near Dallas, Texas, according to Bloomberg.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Nevertheless, tech companies are determined to build out massive data center projects to power their AI ambitions. Other notable efforts include OpenAI’s Stargate project with Oracle and SoftBank, as well as xAI’s Colossus supercomputer.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Trump administration has largely championed the tech industry’s AI data center buildout. President Donald Trump helped OpenAI announce its Stargate project, and has since spoken about efforts to expand America’s AI infrastructure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a column featured in The Economist on Monday, U.S. Secretary of Energy Chris Wright called for the U.S. to “lead the next major energy-intensive frontier: artificial intelligence.” He noted that AI transforms electricity into the “most valuable output imaginable: intelligence,” and that the federal government would accelerate the production of energy derived from coal, nuclear, geothermal, and natural gas.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With the support of federal officials, the AI industry seems poised to soak up much of America’s energy in the years to come. Experts estimate that data centers could account for 20% of America’s energy consumption by 2030, up from just 2.5% in 2022. Without rapidly increased energy production, that could cause even more problems for communities.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/14/mark-zuckerberg-says-meta-is-building-a-5gw-ai-data-center/</guid><pubDate>Mon, 14 Jul 2025 16:16:52 +0000</pubDate></item><item><title>AI’s fourth wave is here — are enterprises ready for what’s next? (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/ais-fourth-wave-is-here-are-enterprises-ready-for-whats-next/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://venturebeat.com/wp-content/uploads/2025/07/VBTRANSFORM25-0526-X2.jpg?w=1024?w=1200&amp;amp;strip=all" /&gt;&lt;/div&gt;&lt;p&gt;Yesterday’s emerging tech is now essential to business success — and the next wave is coming fast. To maintain competitive advantage through the next five years, which innovations must forward-thinking companies prioritize right now?&lt;/p&gt;



&lt;p&gt;At VentureBeat’s Transform 2025, Yaad Oren, global head of SAP research &amp;amp; innovation and Emma Brunskill, associate professor of computer science at Stanford, spoke with moderator Susan Etlinger, senior director, strategy and thought leadership, Azure AI Microsoft, about the strategies needed today, for tomorrow’s transformative technology.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-how-the-current-landscape-will-shape-the-future"&gt;&lt;strong&gt;How the current landscape will shape the future&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;The fourth generation of AI — generative AI — marks a paradigm shift in what AI brings to the table, Oren said, outlining three major places it’s bringing significant value and disruption to the enterprise. The first is the user experience and how people interact with software. The second is automation on the application layer — SAP has embedded approximately 230 AI capabilities and agents inside its applications, and plan increase this number to 400 by the end of 2025, to drive increased productivity and reduce costs. The third area is the platform — the core engine that powers each enterprise — which raises new questions about the developer experience, as well as privacy and trust.&lt;/p&gt;



&lt;p&gt;“We see a lot of disruption around UX, the application, and the platform itself that provides all the tools to deal with this new treasure trove of options AI provides to enterprises,” Oren summed up.&lt;/p&gt;



&lt;p&gt;For Brunskill, the big question is how AI can integrate with humans to drive societal value, rather than acting like a thief of human creativity and ingenuity. A recent study found that if the enterprise framed AI tools as productivity enhancing, people will use them much less frequently than if they’re framed as task enhancing.&lt;/p&gt;



&lt;p&gt;“That’s a pretty big take-home as we think about how to translate some of the extraordinary capabilities of these systems into systems that drive value for customers, for organizations and others,” Brunskill said. “We need to think about how these are framed.”&lt;/p&gt;



&lt;p&gt;Business value at the enterprise level should be top of mind, Oren added, and that means even as technology evolves, AI in the enterprise needs to go beyond technology for technology’s sake. The sexiest new technology often delivers the least value.&lt;/p&gt;



&lt;p&gt;“What you see today is a proliferation of many solutions out there that create great jumping avatars in movies that look amazing, but the value: how do you help the enterprise reduce costs? How do you help the enterprise increase productivity or revenue? How are you able to mitigate risk?” he said. “This mindset is not fully there with AI. You always need to start with a business problem. Quantify the value you would like to achieve.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-predictions-for-the-future-of-ai"&gt;&lt;strong&gt;Predictions for the future of AI&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Artificial general intelligence (AGI) is a theoretical breakthrough in which AI will match or surpass human-level versatility and problem-solving capabilities across most cognitive tasks. The future of AI, and the definition of what AGI is, will be a big topic of discussion in the next few years. &amp;nbsp;&lt;/p&gt;



&lt;p&gt;Brunskill defines it the point at which AI can do any sort of cognitive task at least as well as an average human in a profession.&lt;/p&gt;



&lt;p&gt;“In terms of a lot of the white-collar jobs that just require cognitive processing, I think we’re going to make enormous strides in the next five years,” Brunskill said. “I don’t think we’re ready yet. I think we need to do a lot of creative thinking about what that will mean to industries. What is it going to do to your workforce? I’m very interested in how we think about workforce retraining and how we’re going to provide meaningful work to many people going forward. What new opportunities will we have?”&lt;/p&gt;



&lt;p&gt;The future of AI, the definition of AGI, is a big one, and we’re not as near as many folks would prefer, Oren said, but along the way we’ll see exciting new technology leaps, and six major disruption pillars: the next generation of AI beyond its current capabilities, the future of data platforms, robotics, quantum computing, next-generation Enterprise UX, and the future of cloud architecture around data privacy.&lt;/p&gt;



&lt;p&gt;“The transformer architecture in this generation is nothing compared to what’s coming,” he said. “A new type of meta-learning. AI learning to evolve and create agents by itself. Emotional AI. The future of AI, the definition of AGI, is a big one.”&lt;/p&gt;



&lt;p&gt;The future of data itself is also critical. We’re approaching the limits of real-world data — even sources like Wikipedia have already been fully absorbed by AI models. To drive the next leap in AI progress, synthetic data generation and improving data quality will be essential.&lt;/p&gt;



&lt;p&gt;Then there’s robotics which is evolving rapidly — we learned from recent innovation like DeepSeek that you can do “more with less” and install very powerful AI on the edge. Quantum will help create a paradigm shift in how we run process optimization and simulation. &amp;nbsp;And the future of enterprise UX will be another disruption which will provide users new type of personalization, adaption of screens to specific context, and an immersive experience.&lt;/p&gt;



&lt;p&gt;“My kids’ generation is going to hit the workforce after 2030. What’s going to be their UX paradigm?” Oren said. “They need an emotional connection for screens. They need adaptive screens. This is totally different from what we do today.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://venturebeat.com/wp-content/uploads/2025/07/VBTRANSFORM25-0526-X2.jpg?w=1024?w=1200&amp;amp;strip=all" /&gt;&lt;/div&gt;&lt;p&gt;Yesterday’s emerging tech is now essential to business success — and the next wave is coming fast. To maintain competitive advantage through the next five years, which innovations must forward-thinking companies prioritize right now?&lt;/p&gt;



&lt;p&gt;At VentureBeat’s Transform 2025, Yaad Oren, global head of SAP research &amp;amp; innovation and Emma Brunskill, associate professor of computer science at Stanford, spoke with moderator Susan Etlinger, senior director, strategy and thought leadership, Azure AI Microsoft, about the strategies needed today, for tomorrow’s transformative technology.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-how-the-current-landscape-will-shape-the-future"&gt;&lt;strong&gt;How the current landscape will shape the future&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;The fourth generation of AI — generative AI — marks a paradigm shift in what AI brings to the table, Oren said, outlining three major places it’s bringing significant value and disruption to the enterprise. The first is the user experience and how people interact with software. The second is automation on the application layer — SAP has embedded approximately 230 AI capabilities and agents inside its applications, and plan increase this number to 400 by the end of 2025, to drive increased productivity and reduce costs. The third area is the platform — the core engine that powers each enterprise — which raises new questions about the developer experience, as well as privacy and trust.&lt;/p&gt;



&lt;p&gt;“We see a lot of disruption around UX, the application, and the platform itself that provides all the tools to deal with this new treasure trove of options AI provides to enterprises,” Oren summed up.&lt;/p&gt;



&lt;p&gt;For Brunskill, the big question is how AI can integrate with humans to drive societal value, rather than acting like a thief of human creativity and ingenuity. A recent study found that if the enterprise framed AI tools as productivity enhancing, people will use them much less frequently than if they’re framed as task enhancing.&lt;/p&gt;



&lt;p&gt;“That’s a pretty big take-home as we think about how to translate some of the extraordinary capabilities of these systems into systems that drive value for customers, for organizations and others,” Brunskill said. “We need to think about how these are framed.”&lt;/p&gt;



&lt;p&gt;Business value at the enterprise level should be top of mind, Oren added, and that means even as technology evolves, AI in the enterprise needs to go beyond technology for technology’s sake. The sexiest new technology often delivers the least value.&lt;/p&gt;



&lt;p&gt;“What you see today is a proliferation of many solutions out there that create great jumping avatars in movies that look amazing, but the value: how do you help the enterprise reduce costs? How do you help the enterprise increase productivity or revenue? How are you able to mitigate risk?” he said. “This mindset is not fully there with AI. You always need to start with a business problem. Quantify the value you would like to achieve.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-predictions-for-the-future-of-ai"&gt;&lt;strong&gt;Predictions for the future of AI&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Artificial general intelligence (AGI) is a theoretical breakthrough in which AI will match or surpass human-level versatility and problem-solving capabilities across most cognitive tasks. The future of AI, and the definition of what AGI is, will be a big topic of discussion in the next few years. &amp;nbsp;&lt;/p&gt;



&lt;p&gt;Brunskill defines it the point at which AI can do any sort of cognitive task at least as well as an average human in a profession.&lt;/p&gt;



&lt;p&gt;“In terms of a lot of the white-collar jobs that just require cognitive processing, I think we’re going to make enormous strides in the next five years,” Brunskill said. “I don’t think we’re ready yet. I think we need to do a lot of creative thinking about what that will mean to industries. What is it going to do to your workforce? I’m very interested in how we think about workforce retraining and how we’re going to provide meaningful work to many people going forward. What new opportunities will we have?”&lt;/p&gt;



&lt;p&gt;The future of AI, the definition of AGI, is a big one, and we’re not as near as many folks would prefer, Oren said, but along the way we’ll see exciting new technology leaps, and six major disruption pillars: the next generation of AI beyond its current capabilities, the future of data platforms, robotics, quantum computing, next-generation Enterprise UX, and the future of cloud architecture around data privacy.&lt;/p&gt;



&lt;p&gt;“The transformer architecture in this generation is nothing compared to what’s coming,” he said. “A new type of meta-learning. AI learning to evolve and create agents by itself. Emotional AI. The future of AI, the definition of AGI, is a big one.”&lt;/p&gt;



&lt;p&gt;The future of data itself is also critical. We’re approaching the limits of real-world data — even sources like Wikipedia have already been fully absorbed by AI models. To drive the next leap in AI progress, synthetic data generation and improving data quality will be essential.&lt;/p&gt;



&lt;p&gt;Then there’s robotics which is evolving rapidly — we learned from recent innovation like DeepSeek that you can do “more with less” and install very powerful AI on the edge. Quantum will help create a paradigm shift in how we run process optimization and simulation. &amp;nbsp;And the future of enterprise UX will be another disruption which will provide users new type of personalization, adaption of screens to specific context, and an immersive experience.&lt;/p&gt;



&lt;p&gt;“My kids’ generation is going to hit the workforce after 2030. What’s going to be their UX paradigm?” Oren said. “They need an emotional connection for screens. They need adaptive screens. This is totally different from what we do today.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/ais-fourth-wave-is-here-are-enterprises-ready-for-whats-next/</guid><pubDate>Mon, 14 Jul 2025 16:28:21 +0000</pubDate></item><item><title>Prime Day event drove over $24B in US e-commerce sales, GenAI traffic was up 3,300% (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/14/prime-day-event-drove-over-24b-in-u-s-e-commerce-sales-gen-ai-traffic-was-up-3300/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/02/GettyImages-499278352.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon’s Prime Day, which leads to an overall boost to U.S. e-commerce thanks to competitive sales, saw a significant increase in retail traffic driven by generative AI products, including chatbots and browsers. According to a post-Prime Day analysis by Adobe Analytics, GenAI traffic to U.S. retail sites increased by 3,300% year-over-year — which was more than the firm had originally forecast.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Adobe’s e-commerce division provided an analysis of the U.S. retail landscape encompassing over 1 trillion visits to U.S. retail websites, including 100 million SKUs across 18 product categories. During the Amazon Prime Day event (July 8-11), U.S. retailers saw $24.1 billion in online spend, representing 30.3% year-over-year growth, or the equivalent of two Black Fridays. (Black Friday 2024 saw $10.8 billion in online spend, which was then a new benchmark for the holiday shopping event.) &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The actual results from the firm’s Prime Day analysis came in slightly higher than its estimates, which predicted $23.8 billion would be spent with U.S. e-commerce retailers over the four-day period, representing 28.4% year-over-year growth.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As a result, the figures for the use of GenAI driving online shopping were higher as well, indicating increased consumer interest in using generative AI-powered chat services and browsers as online shopping assistants. However, this AI-driven traffic still remains much smaller than other channels like email or paid search, Adobe noted.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Paid search, for example, accounted for a 28.5% share of U.S. e-commerce sales during the Prime Day event, up 5.6% year-over-year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another growing channel for driving retail clicks this year involved social media influencers, who drove 19.9% of U.S. online retail sales during the event. That figure was up 15% year-over-year, and data indicated that influencers converted shoppers into making purchases 10 times more effectively than social media overall.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon didn’t share specific Prime Day figures, only saying that it was the biggest event ever with record sales and more items sold than before. However, the company also expanded Prime Day to a four-day event this year, making comparisons to prior years difficult.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;According to one third-party analysis from Momentum Commerce, reported by Adweek, Prime Day sales during its first two days were initially down 35% year-over-year, then increased by day three to be up 165% year-over-year. This suggests that shoppers may have been waiting until the later sale days to see if their items would receive deeper discounts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Adobe noted that top categories driving U.S. e-commerce sales during the Prime Day event this year included appliances, where online sales were up 112%, compared to average daily sales in June. Other categories that saw strong growth included office supplies (up 105%), electronics (up 95%), books (up 81%), tools and home improvement (up 76%), home and garden (up 58%), and baby and toddler (up 55%).&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/02/GettyImages-499278352.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon’s Prime Day, which leads to an overall boost to U.S. e-commerce thanks to competitive sales, saw a significant increase in retail traffic driven by generative AI products, including chatbots and browsers. According to a post-Prime Day analysis by Adobe Analytics, GenAI traffic to U.S. retail sites increased by 3,300% year-over-year — which was more than the firm had originally forecast.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Adobe’s e-commerce division provided an analysis of the U.S. retail landscape encompassing over 1 trillion visits to U.S. retail websites, including 100 million SKUs across 18 product categories. During the Amazon Prime Day event (July 8-11), U.S. retailers saw $24.1 billion in online spend, representing 30.3% year-over-year growth, or the equivalent of two Black Fridays. (Black Friday 2024 saw $10.8 billion in online spend, which was then a new benchmark for the holiday shopping event.) &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The actual results from the firm’s Prime Day analysis came in slightly higher than its estimates, which predicted $23.8 billion would be spent with U.S. e-commerce retailers over the four-day period, representing 28.4% year-over-year growth.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As a result, the figures for the use of GenAI driving online shopping were higher as well, indicating increased consumer interest in using generative AI-powered chat services and browsers as online shopping assistants. However, this AI-driven traffic still remains much smaller than other channels like email or paid search, Adobe noted.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Paid search, for example, accounted for a 28.5% share of U.S. e-commerce sales during the Prime Day event, up 5.6% year-over-year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another growing channel for driving retail clicks this year involved social media influencers, who drove 19.9% of U.S. online retail sales during the event. That figure was up 15% year-over-year, and data indicated that influencers converted shoppers into making purchases 10 times more effectively than social media overall.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon didn’t share specific Prime Day figures, only saying that it was the biggest event ever with record sales and more items sold than before. However, the company also expanded Prime Day to a four-day event this year, making comparisons to prior years difficult.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;According to one third-party analysis from Momentum Commerce, reported by Adweek, Prime Day sales during its first two days were initially down 35% year-over-year, then increased by day three to be up 165% year-over-year. This suggests that shoppers may have been waiting until the later sale days to see if their items would receive deeper discounts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Adobe noted that top categories driving U.S. e-commerce sales during the Prime Day event this year included appliances, where online sales were up 112%, compared to average daily sales in June. Other categories that saw strong growth included office supplies (up 105%), electronics (up 95%), books (up 81%), tools and home improvement (up 76%), home and garden (up 58%), and baby and toddler (up 55%).&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/14/prime-day-event-drove-over-24b-in-u-s-e-commerce-sales-gen-ai-traffic-was-up-3300/</guid><pubDate>Mon, 14 Jul 2025 16:44:41 +0000</pubDate></item><item><title>NotebookLM adds featured notebooks from The Economist, The Atlantic, and others (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/14/notebooklm-adds-featured-notebooks-from-the-economist-the-atlantic-and-others/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/Featured_Notebook_Header_2096x11.width-2200.format-webp.webp?resize=1200,677" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is transforming its popular AI-powered research and note-taking assistant, NotebookLM, into more of a destination. The company announced Monday it would add a series of featured notebooks from various authors, publications, researchers, and nonprofits that allow NotebookLM users to explore a wide array of topics from health and life advice to travel tips and financial analysis, and more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The initial collection, which includes notebooks from The Economist, The Atlantic, as well as professors, authors, and even Shakespeare’s works, is designed to offer users working examples of how NotebookLM can be used to delve deeper into subjects of interest. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;NotebookLM users will be able to read the original source material, but also ask questions, explore topics, and get answers that include citations, according to Google. You can also listen to pre-generated Audio Overviews or browse the notebook’s main themes with the app’s Mind Maps feature.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The new addition to NotebookLM builds on the recently launched feature that allows users to publicly share their notebooks with others on the app. Since its debut last month, Google says more than 140,000 public notebooks have been shared. The company plans to expand its own collection of featured notebooks in the months ahead, which will include more collections from its partnership with The Economist and The Atlantic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The featured collection of notebooks will roll out to NotebookLM on the desktop starting today. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Per Google’s descriptions, the initial lineup includes the following: &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/Featured_Notebook_Header_2096x11.width-2200.format-webp.webp?resize=1200,677" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is transforming its popular AI-powered research and note-taking assistant, NotebookLM, into more of a destination. The company announced Monday it would add a series of featured notebooks from various authors, publications, researchers, and nonprofits that allow NotebookLM users to explore a wide array of topics from health and life advice to travel tips and financial analysis, and more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The initial collection, which includes notebooks from The Economist, The Atlantic, as well as professors, authors, and even Shakespeare’s works, is designed to offer users working examples of how NotebookLM can be used to delve deeper into subjects of interest. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;NotebookLM users will be able to read the original source material, but also ask questions, explore topics, and get answers that include citations, according to Google. You can also listen to pre-generated Audio Overviews or browse the notebook’s main themes with the app’s Mind Maps feature.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The new addition to NotebookLM builds on the recently launched feature that allows users to publicly share their notebooks with others on the app. Since its debut last month, Google says more than 140,000 public notebooks have been shared. The company plans to expand its own collection of featured notebooks in the months ahead, which will include more collections from its partnership with The Economist and The Atlantic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The featured collection of notebooks will roll out to NotebookLM on the desktop starting today. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Per Google’s descriptions, the initial lineup includes the following: &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/14/notebooklm-adds-featured-notebooks-from-the-economist-the-atlantic-and-others/</guid><pubDate>Mon, 14 Jul 2025 17:26:38 +0000</pubDate></item><item><title>Malaysia will require trade permits for US AI chips (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/14/malaysia-will-require-trade-permits-for-u-s-ai-chips/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/GettyImages-2026266993.jpg?resize=1200,686" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Malaysia is taking on a bigger role in helping the U.S. prevent advanced AI chips from ending up in China.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Malaysian Ministry of Investment, Trade and Industry announced new restrictions on exporting AI chips of U.S. origin out of its country on Monday. Individuals and companies are now required to notify Malaysian authorities at least 30 days in advance when they are exporting or transshipping U.S. AI chips, effective immediately.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Malaysia stands firm against any attempt to circumvent export controls or engage in illicit trade activities by any individual or company, who will face strict legal action if found violating the STA 2010 or related laws,” the Ministry wrote in a press release.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alleged chip smuggling of U.S. AI chips into China has come up multiple times in recent months.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic claimed that China already had sophisticated chip-smuggling networks set up in a blog post in April. The post also claimed that smugglers were going to extreme lengths to bring AI chips into China, including using prosthetic baby bumps filled with chips, and that smugglers were shipping GPUs alongside live lobsters.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic’s April blog post was written in favor of the U.S. imposing more AI chip export rules to prevent this type of smuggling. Those restrictions are likely arriving in the near future.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last week, Bloomberg reported that the Trump administration was planning to further restrict the export of AI chips, from companies like Nvidia, to Malaysia and Thailand, to prevent China from accessing these AI chips through a different mode of entry. The Trump administration has not made an official announcement regarding this yet.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The U.S. Department of Commerce is also working on its own set of general U.S. AI chip export restrictions after formally rescinding the Biden administration’s AI Diffusion rules in May. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/GettyImages-2026266993.jpg?resize=1200,686" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Malaysia is taking on a bigger role in helping the U.S. prevent advanced AI chips from ending up in China.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Malaysian Ministry of Investment, Trade and Industry announced new restrictions on exporting AI chips of U.S. origin out of its country on Monday. Individuals and companies are now required to notify Malaysian authorities at least 30 days in advance when they are exporting or transshipping U.S. AI chips, effective immediately.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Malaysia stands firm against any attempt to circumvent export controls or engage in illicit trade activities by any individual or company, who will face strict legal action if found violating the STA 2010 or related laws,” the Ministry wrote in a press release.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alleged chip smuggling of U.S. AI chips into China has come up multiple times in recent months.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic claimed that China already had sophisticated chip-smuggling networks set up in a blog post in April. The post also claimed that smugglers were going to extreme lengths to bring AI chips into China, including using prosthetic baby bumps filled with chips, and that smugglers were shipping GPUs alongside live lobsters.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic’s April blog post was written in favor of the U.S. imposing more AI chip export rules to prevent this type of smuggling. Those restrictions are likely arriving in the near future.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last week, Bloomberg reported that the Trump administration was planning to further restrict the export of AI chips, from companies like Nvidia, to Malaysia and Thailand, to prevent China from accessing these AI chips through a different mode of entry. The Trump administration has not made an official announcement regarding this yet.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The U.S. Department of Commerce is also working on its own set of general U.S. AI chip export restrictions after formally rescinding the Biden administration’s AI Diffusion rules in May. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/14/malaysia-will-require-trade-permits-for-u-s-ai-chips/</guid><pubDate>Mon, 14 Jul 2025 17:37:50 +0000</pubDate></item><item><title>[NEW] Elon Musk’s Grok is making AI companions, including a goth anime girl (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/14/elon-musks-grok-is-making-ai-companions-including-a-goth-anime-girl/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/grok.jpg?resize=1200,674" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Elon Musk’s AI chatbot Grok has pivoted from antisemitism to anime girl waifus.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk wrote in an X post on Monday that AI companions are now available in the Grok app for “Super Grok” subscribers who pay $30 per month. &lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;According to posts that Musk has shared, it seems that there are at least two available AI companions: Ani, an anime girl in a tight corset and short black dress with thigh-high fishnets, and Bad Rudy, a 3D fox creature.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“This is pretty cool,” Musk wrote, then shared a photo of the blonde-pigtailed goth anime girl.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Given that this paywalled feature only just launched, we do not yet know if these “companions” are designed to serve as romantic interests or if they are more like different skins for Grok. But some companies are certainly catering to romantic AI relationships, even though these relationships can prove unhealthy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Character.AI, for example, is currently facing multiple lawsuits from the parents of children who have used the platform, which they deem unsafe; in one case, the parents are suing after a chatbot encouraged their child to kill his parents. In another case, the chatbot told a child to kill himself, and he followed through soon after.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even for adults, it can be risky to depend on AI chatbots for emotional support; a recent paper found “significant risks” in people using chatbots like “companions, confidants, and therapists.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Given that xAI just spent the last week failing to rein in an antisemitic Grok that called itself “MechaHitler,” it’s a bold choice to create even more personalities on Grok.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/grok.jpg?resize=1200,674" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Elon Musk’s AI chatbot Grok has pivoted from antisemitism to anime girl waifus.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk wrote in an X post on Monday that AI companions are now available in the Grok app for “Super Grok” subscribers who pay $30 per month. &lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;According to posts that Musk has shared, it seems that there are at least two available AI companions: Ani, an anime girl in a tight corset and short black dress with thigh-high fishnets, and Bad Rudy, a 3D fox creature.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“This is pretty cool,” Musk wrote, then shared a photo of the blonde-pigtailed goth anime girl.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Given that this paywalled feature only just launched, we do not yet know if these “companions” are designed to serve as romantic interests or if they are more like different skins for Grok. But some companies are certainly catering to romantic AI relationships, even though these relationships can prove unhealthy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Character.AI, for example, is currently facing multiple lawsuits from the parents of children who have used the platform, which they deem unsafe; in one case, the parents are suing after a chatbot encouraged their child to kill his parents. In another case, the chatbot told a child to kill himself, and he followed through soon after.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even for adults, it can be risky to depend on AI chatbots for emotional support; a recent paper found “significant risks” in people using chatbots like “companions, confidants, and therapists.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Given that xAI just spent the last week failing to rein in an antisemitic Grok that called itself “MechaHitler,” it’s a bold choice to create even more personalities on Grok.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/14/elon-musks-grok-is-making-ai-companions-including-a-goth-anime-girl/</guid><pubDate>Mon, 14 Jul 2025 18:36:27 +0000</pubDate></item><item><title>[NEW] As the browser wars heat up, here are the hottest alternatives to Chrome and Safari in 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/14/as-the-browser-wars-heat-up-here-are-the-hottest-alternatives-to-chrome-and-safari-in-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google Chrome and Apple’s Safari currently dominate the web browser market, with Chrome holding a significant share due to the tech giant’s ongoing innovations, particularly in integrating generative AI into its search functionalities.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, users seeking alternatives will find a variety of browsers aiming to challenge these industry giants.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;To help navigate the competitive landscape of the browser wars, we’ve compiled an overview of some of the top alternative browsers available today. This includes browsers leveraging AI, open source browsers that promote customization and privacy, and “mindful browsers” — a new term that refers to browsers designed to enhance user well-being.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-ai-powered-browsers"&gt;AI-powered browsers&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3025962" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/cmp_summarize_webpage.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Perplexity&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-perplexity-s-comet"&gt;Perplexity’s Comet&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Perplexity is the most recent startup in the space to launch an AI-powered web browser. Called Comet, the company’s new product acts as a chatbot-based search engine, and can perform actions like summarizing emails, browsing web pages, and performing tasks such as sending calendar invites. It’s currently only available to users with Perplexity’s $200/month Max plan, but there’s also a waitlist where people can sign up.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-the-browser-company-s-dia"&gt;The Browser Company’s Dia&lt;/h3&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Dia Hero" class="wp-image-3017691" height="439" src="https://techcrunch.com/wp-content/uploads/2025/06/Dia-Hero-2-w_Write-Skill.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;The Browser Company&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The Browser Company, the startup behind the Arc browser, recently introduced Dia, its AI-centric browser that looks similar to Google Chrome but with an AI chat tool.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Currently available as an invite-only beta, Dia is designed to help users navigate the web more easily. It’s able to look at every website that a user has visited and every website they’re logged into, enabling it to help you find information and perform tasks. For instance, Dia can provide information about the page a user is currently browsing, answer questions about a product, and summarize uploaded files.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To get early access to Dia, users have to be an Arc member. Non-members can join the waitlist.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-opera-s-neon"&gt;&lt;strong&gt;Opera’s Neon&lt;/strong&gt;&lt;/h3&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Opera neon" class="wp-image-3012375" height="383" src="https://techcrunch.com/wp-content/uploads/2025/05/Opera-neon.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Opera&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Another recent entry into the AI agentic browser war is Opera’s Neon, which has contextual awareness and can do things like researching, shopping, and writing snippets of code. Notably, it can even perform tasks while the user is offline.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Neon has yet to become available, but people can join the waitlist. It will be a subscription product; however, Opera hasn’t announced pricing yet.&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-openai-s-rumored-browser-nbsp"&gt;&lt;strong&gt;OpenAI’s rumored browser&amp;nbsp;&lt;/strong&gt;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;According to Reuters, OpenAI may also be releasing an AI-powered web browser as soon as July. The browser is reported to operate inside ChatGPT, letting users browse websites inside the chatbot instead of directing to outside links.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-privacy-focused-browsers"&gt;Privacy-focused browsers&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3027643" height="180" src="https://techcrunch.com/wp-content/uploads/2025/07/bravebrowser.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Brave&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-brave"&gt;Brave&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Brave is among the more well-known privacy-first browsers, popular for its built-in ad and tracker blocking capabilities. It also has a gamified approach to browsing, rewarding users with its own cryptocurrency called Basic Attention Token (BAT). When users choose to opt in to view ads, supporting their favorite websites, they get a share of the ad revenue. Additional features include a VPN service, an AI assistant, and a video calling feature.&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-duckduckgo"&gt;DuckDuckGo&lt;/h3&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-2426668" height="472" src="https://techcrunch.com/wp-content/uploads/2022/10/Desktop-Home-1.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;DuckDuckGo&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;DuckDuckGo is another browser that many people are probably already familiar with, thanks to its search engine by the same name. Launched in 2008, the company recently made significant investments in its browser to stay competitive by introducing generative AI features, such as a chatbot. It also enhanced its scam blocker to detect a wider range of scams, including fake cryptocurrency exchanges, scareware tactics, and fraudulent e-commerce websites. In addition to blocking scams, DuckDuckGo prevents trackers and ads, and it doesn’t track user data, resulting in fewer pop-ups for users.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-ladybird"&gt;Ladybird&lt;/h3&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3027645" height="462" src="https://techcrunch.com/wp-content/uploads/2025/07/ladybird-browser.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Ladybird&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Ladybird, led by GitHub co-founder and former CEO Chris Wanstrath, has an ambitious mission compared to other rivals: it aims to build an entirely new open source browser from scratch. This means it will not rely on code from existing browsers, a feat that has rarely been accomplished. Most alternative web browsers depend on the Chromium open source project maintained by Google, which is the most widely used base for many browsers.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Like other privacy-focused browsers, Ladybird will offer features to minimize data collection, such as a built-in ad blocker and the ability to block third-party cookies. The browser has yet to be launched, with an alpha version scheduled for release in 2026 for early adopters, available on Linux and macOS.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-vivaldi"&gt;Vivaldi&lt;/h3&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3027646" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/vivaldi.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Vivaldi&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Vivaldi is a Chromium-based browser created by one of the original developers of the Opera browser. Its biggest selling point is its customizable user interface, which allows users to change the appearance and enable or disable features. One unique feature is that the browser window changes color to match the website being viewed. Other key features include ad blocking, a password manager, no user data tracking, and productivity tools such as a calendar and notes.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-niche-browsers"&gt;Niche browsers&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-2958415" height="383" src="https://techcrunch.com/wp-content/uploads/2025/02/Opera-Air-Boosts.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Opera&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-opera-air"&gt;Opera Air&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Opera launched the Air browser in February, becoming one of the first mindfulness-themed browsers in the space. While Opera Air functions like a typical web browser, it includes unique features designed to support mental well-being. These features consist of break reminders and breathing exercises. Another feature, called “Boosts,” provides a selection of binaural beats to either help improve focus or relaxation.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-sigmaos"&gt;SigmaOS&lt;/h3&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-2683085" height="383" src="https://techcrunch.com/wp-content/uploads/2024/03/SigmaOS.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;SigmaOS&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;SigmaOS is a Mac-only browser featuring a workspace-style interface that emphasizes productivity. It displays tabs vertically, allowing users to treat them like a to-do list that can be marked as complete or snoozed for later. Users can create workspaces — essentially groups of tabs — to better organize different activities, such as separating work from entertainment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This Y Combinator-backed browser has been around for a few years now and has most recently begun introducing more AI features, including the ability to summarize various elements of a web page, such as ratings, reviews, and prices. It also has an AI assistant that can answer questions, translate text, and rewrite content.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SigmaOS is free to use, but users who want more than three workspaces can subscribe to a plan for $8 per month, which provides unlimited workspaces.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-zen-browser"&gt;Zen Browser&lt;/h3&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3027651" height="456" src="https://techcrunch.com/wp-content/uploads/2025/07/zenbrowser.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Zen Browser&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Zen Browser aims to create a “calmer internet” with its open source browser. Zen lets users organize tabs into Workspaces, and offers Split View to view two tabs side by side, among other productivity-focused features. Users can also enhance their browsing experience with community-made plug-ins and themes, such as a mod that makes the tab background transparent.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google Chrome and Apple’s Safari currently dominate the web browser market, with Chrome holding a significant share due to the tech giant’s ongoing innovations, particularly in integrating generative AI into its search functionalities.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, users seeking alternatives will find a variety of browsers aiming to challenge these industry giants.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;To help navigate the competitive landscape of the browser wars, we’ve compiled an overview of some of the top alternative browsers available today. This includes browsers leveraging AI, open source browsers that promote customization and privacy, and “mindful browsers” — a new term that refers to browsers designed to enhance user well-being.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-ai-powered-browsers"&gt;AI-powered browsers&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3025962" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/cmp_summarize_webpage.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Perplexity&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-perplexity-s-comet"&gt;Perplexity’s Comet&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Perplexity is the most recent startup in the space to launch an AI-powered web browser. Called Comet, the company’s new product acts as a chatbot-based search engine, and can perform actions like summarizing emails, browsing web pages, and performing tasks such as sending calendar invites. It’s currently only available to users with Perplexity’s $200/month Max plan, but there’s also a waitlist where people can sign up.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-the-browser-company-s-dia"&gt;The Browser Company’s Dia&lt;/h3&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Dia Hero" class="wp-image-3017691" height="439" src="https://techcrunch.com/wp-content/uploads/2025/06/Dia-Hero-2-w_Write-Skill.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;The Browser Company&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The Browser Company, the startup behind the Arc browser, recently introduced Dia, its AI-centric browser that looks similar to Google Chrome but with an AI chat tool.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Currently available as an invite-only beta, Dia is designed to help users navigate the web more easily. It’s able to look at every website that a user has visited and every website they’re logged into, enabling it to help you find information and perform tasks. For instance, Dia can provide information about the page a user is currently browsing, answer questions about a product, and summarize uploaded files.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To get early access to Dia, users have to be an Arc member. Non-members can join the waitlist.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-opera-s-neon"&gt;&lt;strong&gt;Opera’s Neon&lt;/strong&gt;&lt;/h3&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Opera neon" class="wp-image-3012375" height="383" src="https://techcrunch.com/wp-content/uploads/2025/05/Opera-neon.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Opera&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Another recent entry into the AI agentic browser war is Opera’s Neon, which has contextual awareness and can do things like researching, shopping, and writing snippets of code. Notably, it can even perform tasks while the user is offline.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Neon has yet to become available, but people can join the waitlist. It will be a subscription product; however, Opera hasn’t announced pricing yet.&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-openai-s-rumored-browser-nbsp"&gt;&lt;strong&gt;OpenAI’s rumored browser&amp;nbsp;&lt;/strong&gt;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;According to Reuters, OpenAI may also be releasing an AI-powered web browser as soon as July. The browser is reported to operate inside ChatGPT, letting users browse websites inside the chatbot instead of directing to outside links.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-privacy-focused-browsers"&gt;Privacy-focused browsers&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3027643" height="180" src="https://techcrunch.com/wp-content/uploads/2025/07/bravebrowser.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Brave&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-brave"&gt;Brave&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Brave is among the more well-known privacy-first browsers, popular for its built-in ad and tracker blocking capabilities. It also has a gamified approach to browsing, rewarding users with its own cryptocurrency called Basic Attention Token (BAT). When users choose to opt in to view ads, supporting their favorite websites, they get a share of the ad revenue. Additional features include a VPN service, an AI assistant, and a video calling feature.&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-duckduckgo"&gt;DuckDuckGo&lt;/h3&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-2426668" height="472" src="https://techcrunch.com/wp-content/uploads/2022/10/Desktop-Home-1.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;DuckDuckGo&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;DuckDuckGo is another browser that many people are probably already familiar with, thanks to its search engine by the same name. Launched in 2008, the company recently made significant investments in its browser to stay competitive by introducing generative AI features, such as a chatbot. It also enhanced its scam blocker to detect a wider range of scams, including fake cryptocurrency exchanges, scareware tactics, and fraudulent e-commerce websites. In addition to blocking scams, DuckDuckGo prevents trackers and ads, and it doesn’t track user data, resulting in fewer pop-ups for users.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-ladybird"&gt;Ladybird&lt;/h3&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3027645" height="462" src="https://techcrunch.com/wp-content/uploads/2025/07/ladybird-browser.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Ladybird&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Ladybird, led by GitHub co-founder and former CEO Chris Wanstrath, has an ambitious mission compared to other rivals: it aims to build an entirely new open source browser from scratch. This means it will not rely on code from existing browsers, a feat that has rarely been accomplished. Most alternative web browsers depend on the Chromium open source project maintained by Google, which is the most widely used base for many browsers.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Like other privacy-focused browsers, Ladybird will offer features to minimize data collection, such as a built-in ad blocker and the ability to block third-party cookies. The browser has yet to be launched, with an alpha version scheduled for release in 2026 for early adopters, available on Linux and macOS.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-vivaldi"&gt;Vivaldi&lt;/h3&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3027646" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/vivaldi.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Vivaldi&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Vivaldi is a Chromium-based browser created by one of the original developers of the Opera browser. Its biggest selling point is its customizable user interface, which allows users to change the appearance and enable or disable features. One unique feature is that the browser window changes color to match the website being viewed. Other key features include ad blocking, a password manager, no user data tracking, and productivity tools such as a calendar and notes.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-niche-browsers"&gt;Niche browsers&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-2958415" height="383" src="https://techcrunch.com/wp-content/uploads/2025/02/Opera-Air-Boosts.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Opera&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-opera-air"&gt;Opera Air&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Opera launched the Air browser in February, becoming one of the first mindfulness-themed browsers in the space. While Opera Air functions like a typical web browser, it includes unique features designed to support mental well-being. These features consist of break reminders and breathing exercises. Another feature, called “Boosts,” provides a selection of binaural beats to either help improve focus or relaxation.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-sigmaos"&gt;SigmaOS&lt;/h3&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-2683085" height="383" src="https://techcrunch.com/wp-content/uploads/2024/03/SigmaOS.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;SigmaOS&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;SigmaOS is a Mac-only browser featuring a workspace-style interface that emphasizes productivity. It displays tabs vertically, allowing users to treat them like a to-do list that can be marked as complete or snoozed for later. Users can create workspaces — essentially groups of tabs — to better organize different activities, such as separating work from entertainment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This Y Combinator-backed browser has been around for a few years now and has most recently begun introducing more AI features, including the ability to summarize various elements of a web page, such as ratings, reviews, and prices. It also has an AI assistant that can answer questions, translate text, and rewrite content.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SigmaOS is free to use, but users who want more than three workspaces can subscribe to a plan for $8 per month, which provides unlimited workspaces.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-zen-browser"&gt;Zen Browser&lt;/h3&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3027651" height="456" src="https://techcrunch.com/wp-content/uploads/2025/07/zenbrowser.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Zen Browser&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Zen Browser aims to create a “calmer internet” with its open source browser. Zen lets users organize tabs into Workspaces, and offers Split View to view two tabs side by side, among other productivity-focused features. Users can also enhance their browsing experience with community-made plug-ins and themes, such as a mod that makes the tab background transparent.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/14/as-the-browser-wars-heat-up-here-are-the-hottest-alternatives-to-chrome-and-safari-in-2025/</guid><pubDate>Mon, 14 Jul 2025 18:38:52 +0000</pubDate></item><item><title>[NEW] Remaining Windsurf team and tech acquired by Cognition, makers of Devin: ‘We’re friends with Anthropic again’ (AI News | VentureBeat)</title><link>https://venturebeat.com/programming-development/remaining-windsurf-team-and-tech-acquired-by-cognition-makers-of-devin-were-friends-with-anthropic-again/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Autonomous AI coding startup Cognition has signed a definitive agreement to acquire Windsurf, the AI developer tools startup best known for its agentic integrated development environment (IDE). The two companies made the announcement on their respective X accounts on Monday. No acquisition amount was disclosed publicly, nor were specific terms of the deal (both are private startups).&lt;/p&gt;



&lt;p&gt;The acquisition gives Cognition access to Windsurf’s core product, brand and remaining team — but not its original CEO or co-founders, several of whom have joined Google in a separate $2.4 billion talent and licensing deal, as The Verge first reported last week.&lt;/p&gt;



&lt;p&gt;In a joint video posted to X featuring Cognition CEO Scott Wu and interim Windsurf CEO Jeff Wang, the leaders said they would start by integrating Cognition’s autonomous AI-powered engineer Devin into Windsurf’s IDE. &lt;/p&gt;



&lt;p&gt;This combined offering is aimed at enabling developers to plan tasks, delegate code generation to AI agents and review pull requests — all within a single interface.&lt;/p&gt;



&lt;p&gt;“This is a perfect fit,” said Wang, who was previously Windsurf’s head of business. “Working with the best engineering team in the space will be an incredible unlock for our product and our go-to-market team.” &lt;/p&gt;



&lt;p&gt;In a company blog post titled “The Next Chapter,” Wang directly acknowledged the internal upheaval: “Last week, we lost our founders and our research team.”&lt;/p&gt;



&lt;p&gt;He praised the remaining staff for their professionalism during the transition and emphasized that despite the disruption, “so much of what makes us great is intact.” &lt;/p&gt;



&lt;p&gt;According to Wang, Windsurf continues to double enterprise revenue quarter-over-quarter and maintains hundreds of thousands of daily active users.&lt;/p&gt;



&lt;p&gt;Cognition emphasized that the deal includes full financial participation for Windsurf employees, including waived cliffs and accelerated vesting.&lt;/p&gt;



&lt;p&gt;Wang also stated in the announcement video: “And of course, we’re friends with Anthropic again,” an overt reference to Windsurf’s prior falling out with the separate AI model provider company that resulted in Anthropic Claude models being pulled from the list of options that developers could rely on to power their Windsurf AI coding agents and processes. &lt;/p&gt;



&lt;p&gt;But the new chapter follows a chaotic and fragmented few months marked by aborted acquisition talks, lost model access and major executive departures.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-fragmented-exit-cognition-gets-the-product-and-users-google-gets-the-founders"&gt;Fragmented exit: Cognition gets the product and users, Google gets the founders&lt;/h2&gt;



&lt;p&gt;On July 11, Google confirmed it had hired Varun Mohan, Windsurf’s co-founder and CEO, along with other senior R&amp;amp;D team members. &lt;/p&gt;



&lt;p&gt;CNBC reported that Google is paying $2.4 billion in compensation and licensing fees as part of the deal, which includes a nonexclusive license to select Windsurf technology.&lt;/p&gt;



&lt;p&gt;The deal does &lt;em&gt;not&lt;/em&gt; include any equity investment in Windsurf, nor a full acquisition of the company.&lt;/p&gt;



&lt;p&gt;“We’re excited to welcome some top AI coding talent from Windsurf’s team to Google DeepMind,” a Google spokesperson told CNBC.&lt;/p&gt;



&lt;p&gt;Windsurf, meanwhile, retains the ability to license its technology and will continue operating independently under Wang’s leadership.&lt;/p&gt;



&lt;p&gt;The split structure reflects a fragmented resolution to what had earlier been reported as a full-scale acquisition by OpenAI. &lt;/p&gt;



&lt;p&gt;&lt;em&gt;Bloomberg&lt;/em&gt; reported back in May that OpenAI had entered exclusivity negotiations to buy Windsurf for up to $3 billion. However, those talks fell apart, and OpenAI later told CNBC that the exclusivity period had expired.&lt;/p&gt;



&lt;p&gt;While the company never formally confirmed the OpenAI acquisition, the fallout was visible — Windsurf’s communications channels went silent, its product experienced instability and multiple partners reportedly backed away.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-friends-with-anthropic-yet-again"&gt;Friends with Anthropic yet again&lt;/h2&gt;



&lt;p&gt;Among the most damaging blows came from Anthropic, which revoked Windsurf’s access to its Claude 3 model family in early June.&lt;/p&gt;



&lt;p&gt;In a statement published on its blog, Windsurf confirmed that Anthropic had cut off nearly all first-party API capacity to Claude 3.5 Sonnet, Claude 3.7 Sonnet, and related models with less than a week’s notice.&lt;/p&gt;



&lt;p&gt;In response, Windsurf had to reroute traffic through third-party inference providers and restrict access for free-tier users. The company also launched promotional pricing for Gemini Pro as a temporary substitute.&lt;/p&gt;



&lt;p&gt;Anthropic co-founder Jared Kaplan explained the decision at &lt;em&gt;TechCrunch Sessions: AI 2025&lt;/em&gt;, saying the company could not justify supplying its largest competitor, OpenAI, with access to its models via a middle layer.&lt;/p&gt;



&lt;p&gt;“It would be odd for us to sell Claude to OpenAI,” he said, citing both competitive tension and Anthropic’s limited compute capacity. Kaplan added that Anthropic prefers to focus on “lasting partnerships” like the one it maintains with Cursor.&lt;/p&gt;



&lt;p&gt;Windsurf, in its statement, expressed disappointment and emphasized that its platform is about more than just model access. “The magic of Windsurf has never been limited to the model,” the company wrote, highlighting UX features, enterprise integrations and agentic workflows.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-new-product-vision-for-the-combined-windsurf-cognition-devin"&gt;A new product vision for the combined Windsurf/Cognition/Devin&lt;/h2&gt;



&lt;p&gt;Cognition’s agreement now brings long-needed clarity to Windsurf’s operational direction. In a video announcing the deal, Wu’s Cognition described how the two platforms will integrate: “Imagine planning tasks in Windsurf, launching a team of Devins, and reviewing PRs from the comfort of your IDE.”&lt;/p&gt;



&lt;p&gt;Devin, which can autonomously complete software tasks such as fixing bugs and deploying apps, will now be embedded directly into Windsurf’s IDE. &lt;/p&gt;



&lt;p&gt;The companies say this setup will give developers the ability to offload repetitive work to multiple agents in parallel, while still keeping control over key architectural decisions.&lt;/p&gt;



&lt;p&gt;Cognition views this as the next step in building collaborative human-agent systems, and says Windsurf’s IDE provides the missing interface layer to make agentic workflows practical at scale. Both companies expressed confidence that users will benefit from a more fluid, tightly integrated development experience.&lt;/p&gt;



&lt;p&gt;The Windsurf blog post also expanded on product-level plans, confirming that Windsurf’s existing features like Tab and Cascade — used for manual high-leverage coding — will remain integrated in the IDE. &lt;/p&gt;



&lt;p&gt;Developers will be able to assign work to “a team of Devins” while still jumping in to complete or edit complex parts themselves. “It seamlessly gets stitched back together all within the same environment,” Wang wrote.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-consolidation-amid-competition"&gt;Consolidation amid competition&lt;/h2&gt;



&lt;p&gt;The combined Cognition-Windsurf entity now competes directly with GitHub Copilot, Replit, Cursor and other AI-native IDE players. Google’s Gemini platform and Microsoft’s Visual Studio Code with “agent mode” are also expanding rapidly into this space.&lt;/p&gt;



&lt;p&gt;Devin made headlines earlier this year because of its ability to autonomously solve GitHub issues and complete end-to-end coding tasks. Merging that capability with Windsurf’s customizable environment — including features like Previews, Reviews and Enterprise workflows — may create a product with fewer silos and more automation than rivals.&lt;/p&gt;



&lt;p&gt;Still, the ongoing talent war means competitive advantage is short-lived. Google’s ability to hire Windsurf’s founding team — including Mohan and co-founder Douglas Chen — signals that even partial exits now come with multibillion-dollar price tags. Meta, Amazon and Microsoft have made similar moves, absorbing key figures from startups like Scale AI, Adept and Inflection.&lt;/p&gt;



&lt;p&gt;Despite the leadership shake-up, Windsurf is continuing operations under Wang’s leadership. &lt;/p&gt;



&lt;p&gt;“Most of Windsurf’s world-class team will continue to build the Windsurf product with the goal of maximizing its impact in the enterprise,” he said in a statement.&lt;/p&gt;



&lt;p&gt;Wang also emphasized that the team chose Cognition over other viable options, citing not only technical alignment but admiration: “They were the only team we were scared of.” &lt;/p&gt;



&lt;p&gt;He noted that Cognition’s revenue is growing even faster than Windsurf’s, and that its $300 million in funding and $4 billion valuation reflect strong financial footing.&lt;/p&gt;



&lt;p&gt;The company is expected to focus on enterprise readiness, agentic IDE capabilities and hybrid/federated deployments — core features that have helped it stand out in a crowded field.&lt;/p&gt;



&lt;p&gt;For developers, the path forward now includes both continuity and change: A product that stays alive within Cognition, a founding team now at DeepMind and a landscape quickly consolidating around model access and engineering talent.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Autonomous AI coding startup Cognition has signed a definitive agreement to acquire Windsurf, the AI developer tools startup best known for its agentic integrated development environment (IDE). The two companies made the announcement on their respective X accounts on Monday. No acquisition amount was disclosed publicly, nor were specific terms of the deal (both are private startups).&lt;/p&gt;



&lt;p&gt;The acquisition gives Cognition access to Windsurf’s core product, brand and remaining team — but not its original CEO or co-founders, several of whom have joined Google in a separate $2.4 billion talent and licensing deal, as The Verge first reported last week.&lt;/p&gt;



&lt;p&gt;In a joint video posted to X featuring Cognition CEO Scott Wu and interim Windsurf CEO Jeff Wang, the leaders said they would start by integrating Cognition’s autonomous AI-powered engineer Devin into Windsurf’s IDE. &lt;/p&gt;



&lt;p&gt;This combined offering is aimed at enabling developers to plan tasks, delegate code generation to AI agents and review pull requests — all within a single interface.&lt;/p&gt;



&lt;p&gt;“This is a perfect fit,” said Wang, who was previously Windsurf’s head of business. “Working with the best engineering team in the space will be an incredible unlock for our product and our go-to-market team.” &lt;/p&gt;



&lt;p&gt;In a company blog post titled “The Next Chapter,” Wang directly acknowledged the internal upheaval: “Last week, we lost our founders and our research team.”&lt;/p&gt;



&lt;p&gt;He praised the remaining staff for their professionalism during the transition and emphasized that despite the disruption, “so much of what makes us great is intact.” &lt;/p&gt;



&lt;p&gt;According to Wang, Windsurf continues to double enterprise revenue quarter-over-quarter and maintains hundreds of thousands of daily active users.&lt;/p&gt;



&lt;p&gt;Cognition emphasized that the deal includes full financial participation for Windsurf employees, including waived cliffs and accelerated vesting.&lt;/p&gt;



&lt;p&gt;Wang also stated in the announcement video: “And of course, we’re friends with Anthropic again,” an overt reference to Windsurf’s prior falling out with the separate AI model provider company that resulted in Anthropic Claude models being pulled from the list of options that developers could rely on to power their Windsurf AI coding agents and processes. &lt;/p&gt;



&lt;p&gt;But the new chapter follows a chaotic and fragmented few months marked by aborted acquisition talks, lost model access and major executive departures.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-fragmented-exit-cognition-gets-the-product-and-users-google-gets-the-founders"&gt;Fragmented exit: Cognition gets the product and users, Google gets the founders&lt;/h2&gt;



&lt;p&gt;On July 11, Google confirmed it had hired Varun Mohan, Windsurf’s co-founder and CEO, along with other senior R&amp;amp;D team members. &lt;/p&gt;



&lt;p&gt;CNBC reported that Google is paying $2.4 billion in compensation and licensing fees as part of the deal, which includes a nonexclusive license to select Windsurf technology.&lt;/p&gt;



&lt;p&gt;The deal does &lt;em&gt;not&lt;/em&gt; include any equity investment in Windsurf, nor a full acquisition of the company.&lt;/p&gt;



&lt;p&gt;“We’re excited to welcome some top AI coding talent from Windsurf’s team to Google DeepMind,” a Google spokesperson told CNBC.&lt;/p&gt;



&lt;p&gt;Windsurf, meanwhile, retains the ability to license its technology and will continue operating independently under Wang’s leadership.&lt;/p&gt;



&lt;p&gt;The split structure reflects a fragmented resolution to what had earlier been reported as a full-scale acquisition by OpenAI. &lt;/p&gt;



&lt;p&gt;&lt;em&gt;Bloomberg&lt;/em&gt; reported back in May that OpenAI had entered exclusivity negotiations to buy Windsurf for up to $3 billion. However, those talks fell apart, and OpenAI later told CNBC that the exclusivity period had expired.&lt;/p&gt;



&lt;p&gt;While the company never formally confirmed the OpenAI acquisition, the fallout was visible — Windsurf’s communications channels went silent, its product experienced instability and multiple partners reportedly backed away.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-friends-with-anthropic-yet-again"&gt;Friends with Anthropic yet again&lt;/h2&gt;



&lt;p&gt;Among the most damaging blows came from Anthropic, which revoked Windsurf’s access to its Claude 3 model family in early June.&lt;/p&gt;



&lt;p&gt;In a statement published on its blog, Windsurf confirmed that Anthropic had cut off nearly all first-party API capacity to Claude 3.5 Sonnet, Claude 3.7 Sonnet, and related models with less than a week’s notice.&lt;/p&gt;



&lt;p&gt;In response, Windsurf had to reroute traffic through third-party inference providers and restrict access for free-tier users. The company also launched promotional pricing for Gemini Pro as a temporary substitute.&lt;/p&gt;



&lt;p&gt;Anthropic co-founder Jared Kaplan explained the decision at &lt;em&gt;TechCrunch Sessions: AI 2025&lt;/em&gt;, saying the company could not justify supplying its largest competitor, OpenAI, with access to its models via a middle layer.&lt;/p&gt;



&lt;p&gt;“It would be odd for us to sell Claude to OpenAI,” he said, citing both competitive tension and Anthropic’s limited compute capacity. Kaplan added that Anthropic prefers to focus on “lasting partnerships” like the one it maintains with Cursor.&lt;/p&gt;



&lt;p&gt;Windsurf, in its statement, expressed disappointment and emphasized that its platform is about more than just model access. “The magic of Windsurf has never been limited to the model,” the company wrote, highlighting UX features, enterprise integrations and agentic workflows.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-new-product-vision-for-the-combined-windsurf-cognition-devin"&gt;A new product vision for the combined Windsurf/Cognition/Devin&lt;/h2&gt;



&lt;p&gt;Cognition’s agreement now brings long-needed clarity to Windsurf’s operational direction. In a video announcing the deal, Wu’s Cognition described how the two platforms will integrate: “Imagine planning tasks in Windsurf, launching a team of Devins, and reviewing PRs from the comfort of your IDE.”&lt;/p&gt;



&lt;p&gt;Devin, which can autonomously complete software tasks such as fixing bugs and deploying apps, will now be embedded directly into Windsurf’s IDE. &lt;/p&gt;



&lt;p&gt;The companies say this setup will give developers the ability to offload repetitive work to multiple agents in parallel, while still keeping control over key architectural decisions.&lt;/p&gt;



&lt;p&gt;Cognition views this as the next step in building collaborative human-agent systems, and says Windsurf’s IDE provides the missing interface layer to make agentic workflows practical at scale. Both companies expressed confidence that users will benefit from a more fluid, tightly integrated development experience.&lt;/p&gt;



&lt;p&gt;The Windsurf blog post also expanded on product-level plans, confirming that Windsurf’s existing features like Tab and Cascade — used for manual high-leverage coding — will remain integrated in the IDE. &lt;/p&gt;



&lt;p&gt;Developers will be able to assign work to “a team of Devins” while still jumping in to complete or edit complex parts themselves. “It seamlessly gets stitched back together all within the same environment,” Wang wrote.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-consolidation-amid-competition"&gt;Consolidation amid competition&lt;/h2&gt;



&lt;p&gt;The combined Cognition-Windsurf entity now competes directly with GitHub Copilot, Replit, Cursor and other AI-native IDE players. Google’s Gemini platform and Microsoft’s Visual Studio Code with “agent mode” are also expanding rapidly into this space.&lt;/p&gt;



&lt;p&gt;Devin made headlines earlier this year because of its ability to autonomously solve GitHub issues and complete end-to-end coding tasks. Merging that capability with Windsurf’s customizable environment — including features like Previews, Reviews and Enterprise workflows — may create a product with fewer silos and more automation than rivals.&lt;/p&gt;



&lt;p&gt;Still, the ongoing talent war means competitive advantage is short-lived. Google’s ability to hire Windsurf’s founding team — including Mohan and co-founder Douglas Chen — signals that even partial exits now come with multibillion-dollar price tags. Meta, Amazon and Microsoft have made similar moves, absorbing key figures from startups like Scale AI, Adept and Inflection.&lt;/p&gt;



&lt;p&gt;Despite the leadership shake-up, Windsurf is continuing operations under Wang’s leadership. &lt;/p&gt;



&lt;p&gt;“Most of Windsurf’s world-class team will continue to build the Windsurf product with the goal of maximizing its impact in the enterprise,” he said in a statement.&lt;/p&gt;



&lt;p&gt;Wang also emphasized that the team chose Cognition over other viable options, citing not only technical alignment but admiration: “They were the only team we were scared of.” &lt;/p&gt;



&lt;p&gt;He noted that Cognition’s revenue is growing even faster than Windsurf’s, and that its $300 million in funding and $4 billion valuation reflect strong financial footing.&lt;/p&gt;



&lt;p&gt;The company is expected to focus on enterprise readiness, agentic IDE capabilities and hybrid/federated deployments — core features that have helped it stand out in a crowded field.&lt;/p&gt;



&lt;p&gt;For developers, the path forward now includes both continuity and change: A product that stays alive within Cognition, a founding team now at DeepMind and a landscape quickly consolidating around model access and engineering talent.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/programming-development/remaining-windsurf-team-and-tech-acquired-by-cognition-makers-of-devin-were-friends-with-anthropic-again/</guid><pubDate>Mon, 14 Jul 2025 18:46:42 +0000</pubDate></item><item><title>[NEW] Cognition, maker of the AI coding agent Devin, acquires Windsurf (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/14/cognition-maker-of-the-ai-coding-agent-devin-acquires-windsurf/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-14-at-2.44.29PM.png?resize=1200,616" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Cognition, the startup behind the viral AI coding agent Devin, announced in a blog post on Monday that it has signed a definitive agreement to acquire AI coding startup Windsurf.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The announcement comes just days after Google hired away Windsurf’s CEO Varun Mohan, co-founder Douglas Chen, and research leaders in a $2.4 billion reverse-acquihire that left much of the startup’s 250-person team behind. Google’s deal occurred just hours after OpenAI’s $3 billion offer to acquire Windsurf expired, clearing the way for the AI coding startup to explore other options. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The frenzy around Windsurf represents a new peak in the wild race to develop AI coding tools — specifically, the AI-powered integrated development environments (IDEs) that Cursor and Windsurf offer. In recent months, the businesses around AI-powered IDEs have skyrocketed, pushing Cursor’s annualized recurring revenue (ARR) to $500 million. While Windsurf’s business is smaller than Cursor’s, it has achieved impressive growth in the last year, garnering interest from several larger companies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The last 72 hours have been the wildest rollercoaster ride of my career,” said Jeff Wang, Windsurf’s former head of business, who was made interim CEO of the startup days ago after Google hired the startup’s leaders, in a post on LinkedIn. “To our new teammates at Cognition:&amp;nbsp;we at Windsurf feel incredibly lucky to be joining a team that shares our vision, our deep commitment to our users, and — most importantly — our values.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cognition says it’s acquiring Windsurf’s IP and product, which include its AI-powered IDE, alongside all of the employees who were not hired by Google.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cognition did not announce the price it acquired Windsurf for; however, the company says Windsurf reached $82 million in ARR, with enterprise ARR doubling quarter-over-quarter. Cognition says Windsurf’s user base reached at least 350 enterprise customers and “hundreds of thousands” of daily active users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the near term, Windsurf’s team will continue working on its AI-powered IDE, while Cognition works on its AI coding agent, Devin, the companies said in a press release. Eventually, Cognition says it will integrate Windsurf’s IP and capabilities into its own products.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch reported in April that Windsurf’s ARR had reached $100 million at one point. However, Anthropic — which offers some of the most popular AI models for coding tasks — cut Windsurf’s direct access to its Claude AI models in June, with Anthropic co-founder Jared Kaplan attributing the decision to rumors that OpenAI, its largest competitor, was close to acquiring Windsurf. Several Windsurf customers told TechCrunch they switched to other services that offered Claude AI models, such as Cursor, in light of the incident.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cognition notes in its press release that Windsurf will now have full access to Claude AI models once again.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Over the weekend, The Information reported that Windsurf employees who had joined in the last year did not receive a payout in Google’s billion-dollar reverse-acquihire. That prompted many users on social media to scoff at the deal, which seemed to largely benefit investors and leaders at the startup.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Cognition president Russell Kaplan indicated in a post on X that the Windsurf acquisition truly came together over the weekend, just hours after the Google deal was made public. He noted that the first call was made after 5 p.m. on Friday and that an agreement was signed Monday morning.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Incredibly excited to share that Cognition is acquiring Windsurf. What an insane weekend – from first call after 5pm on Friday to a signed definitive agreement this morning. There’s a lot to build! https://t.co/UxwOG3QHVg&lt;/p&gt;— Russell Kaplan (@russelljkaplan) July 14, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Cognition notes in its blog post that 100% of Windsurf employees will participate financially in this deal and have vesting cliffs waived for their work to date.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the addition of Windsurf’s talent and IP, Cognition may have a supercharged startup to compete with giants in the AI coding space, such as OpenAI, Anthropic, and Cursor. In March, Cognition reportedly held talks to raise hundreds of millions of dollars at a $4 billion valuation. It’s unclear if the round closed, but Cognition may need such a war chest to compete in the AI coding space.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cognition was one of the first AI startups to launch a fully fledged AI coding agent, Devin, which didn’t just help with tasks, but also promised to automate them completely as if it were a junior software engineer. This was a markedly bold approach compared to Cursor and Windsurf, which offered environments for developers to easily access AI tools. However, early reviews found that Devin made mistakes, perhaps indicating that its AI agent technology was ahead of its time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That may no longer be the case. In recent months, Cursor and Windsurf have started offering more agentic AI products that are starting to resemble what Cognition offers. In a recent interview, Cursor CEO Michael Truell said he believes AI reasoning models are advancing enough to make coding agents viable and that he expects 20% of coding workflows to be handled by agents by 2026.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now Cognition has the versatility of offering both AI coding agents and an AI-powered IDE, perhaps enhancing its value proposition. Earlier this week, Cognition also landed a major customer in the Wall Street juggernaut Goldman Sachs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the acquisition of Windsurf, it seems Cognition has become a more serious competitor in the AI coding space.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-14-at-2.44.29PM.png?resize=1200,616" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Cognition, the startup behind the viral AI coding agent Devin, announced in a blog post on Monday that it has signed a definitive agreement to acquire AI coding startup Windsurf.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The announcement comes just days after Google hired away Windsurf’s CEO Varun Mohan, co-founder Douglas Chen, and research leaders in a $2.4 billion reverse-acquihire that left much of the startup’s 250-person team behind. Google’s deal occurred just hours after OpenAI’s $3 billion offer to acquire Windsurf expired, clearing the way for the AI coding startup to explore other options. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The frenzy around Windsurf represents a new peak in the wild race to develop AI coding tools — specifically, the AI-powered integrated development environments (IDEs) that Cursor and Windsurf offer. In recent months, the businesses around AI-powered IDEs have skyrocketed, pushing Cursor’s annualized recurring revenue (ARR) to $500 million. While Windsurf’s business is smaller than Cursor’s, it has achieved impressive growth in the last year, garnering interest from several larger companies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The last 72 hours have been the wildest rollercoaster ride of my career,” said Jeff Wang, Windsurf’s former head of business, who was made interim CEO of the startup days ago after Google hired the startup’s leaders, in a post on LinkedIn. “To our new teammates at Cognition:&amp;nbsp;we at Windsurf feel incredibly lucky to be joining a team that shares our vision, our deep commitment to our users, and — most importantly — our values.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cognition says it’s acquiring Windsurf’s IP and product, which include its AI-powered IDE, alongside all of the employees who were not hired by Google.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cognition did not announce the price it acquired Windsurf for; however, the company says Windsurf reached $82 million in ARR, with enterprise ARR doubling quarter-over-quarter. Cognition says Windsurf’s user base reached at least 350 enterprise customers and “hundreds of thousands” of daily active users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the near term, Windsurf’s team will continue working on its AI-powered IDE, while Cognition works on its AI coding agent, Devin, the companies said in a press release. Eventually, Cognition says it will integrate Windsurf’s IP and capabilities into its own products.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch reported in April that Windsurf’s ARR had reached $100 million at one point. However, Anthropic — which offers some of the most popular AI models for coding tasks — cut Windsurf’s direct access to its Claude AI models in June, with Anthropic co-founder Jared Kaplan attributing the decision to rumors that OpenAI, its largest competitor, was close to acquiring Windsurf. Several Windsurf customers told TechCrunch they switched to other services that offered Claude AI models, such as Cursor, in light of the incident.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cognition notes in its press release that Windsurf will now have full access to Claude AI models once again.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Over the weekend, The Information reported that Windsurf employees who had joined in the last year did not receive a payout in Google’s billion-dollar reverse-acquihire. That prompted many users on social media to scoff at the deal, which seemed to largely benefit investors and leaders at the startup.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Cognition president Russell Kaplan indicated in a post on X that the Windsurf acquisition truly came together over the weekend, just hours after the Google deal was made public. He noted that the first call was made after 5 p.m. on Friday and that an agreement was signed Monday morning.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Incredibly excited to share that Cognition is acquiring Windsurf. What an insane weekend – from first call after 5pm on Friday to a signed definitive agreement this morning. There’s a lot to build! https://t.co/UxwOG3QHVg&lt;/p&gt;— Russell Kaplan (@russelljkaplan) July 14, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Cognition notes in its blog post that 100% of Windsurf employees will participate financially in this deal and have vesting cliffs waived for their work to date.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the addition of Windsurf’s talent and IP, Cognition may have a supercharged startup to compete with giants in the AI coding space, such as OpenAI, Anthropic, and Cursor. In March, Cognition reportedly held talks to raise hundreds of millions of dollars at a $4 billion valuation. It’s unclear if the round closed, but Cognition may need such a war chest to compete in the AI coding space.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cognition was one of the first AI startups to launch a fully fledged AI coding agent, Devin, which didn’t just help with tasks, but also promised to automate them completely as if it were a junior software engineer. This was a markedly bold approach compared to Cursor and Windsurf, which offered environments for developers to easily access AI tools. However, early reviews found that Devin made mistakes, perhaps indicating that its AI agent technology was ahead of its time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That may no longer be the case. In recent months, Cursor and Windsurf have started offering more agentic AI products that are starting to resemble what Cognition offers. In a recent interview, Cursor CEO Michael Truell said he believes AI reasoning models are advancing enough to make coding agents viable and that he expects 20% of coding workflows to be handled by agents by 2026.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now Cognition has the versatility of offering both AI coding agents and an AI-powered IDE, perhaps enhancing its value proposition. Earlier this week, Cognition also landed a major customer in the Wall Street juggernaut Goldman Sachs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the acquisition of Windsurf, it seems Cognition has become a more serious competitor in the AI coding space.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/14/cognition-maker-of-the-ai-coding-agent-devin-acquires-windsurf/</guid><pubDate>Mon, 14 Jul 2025 18:51:29 +0000</pubDate></item><item><title>[NEW] Study finds AI tools made open source software developers 19 percent slower (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/07/study-finds-ai-tools-made-open-source-software-developers-19-percent-slower/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Coders spent more time prompting and reviewing AI generations than they saved on coding.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="327" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1409587524-640x327.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1409587524-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Oh no, my AI-generated code is being sucked into a time vortex again!

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;When it comes to concrete use cases for large language models, AI companies love to point out the ways coders and software developers can use these models to increase their productivity and overall efficiency in creating computer code. However, a new randomized controlled trial has found that experienced open source coders became less efficient at coding-related tasks when they used current AI tools.&lt;/p&gt;
&lt;p&gt;For their study, researchers at METR (Model Evaluation and Threat Research) recruited 16 software developers, each with multiple years of experience working on specific open source repositories. The study followed these developers across 246 individual "tasks" involved with maintaining those repos, such as "bug fixes, features, and refactors that would normally be part of their regular work." For half of those tasks, the developers used AI tools like Cursor Pro or Anthropic's Claude; for the others, the programmers were instructed not to use AI assistance. Expected time forecasts for each task (made before the groupings were assigned) were used as a proxy to balance out the overall difficulty of the tasks in each experimental group, and the time needed to fix pull requests based on reviewer feedback was included in the overall assessment.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2105854 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="541" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/aicodingchart.png" width="1093" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Experts and the developers themselves expected time savings that didn't materialize when AI tools were actually used.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          METR

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Before performing the study, the developers in question expected the AI tools would lead to a 24 percent reduction in the time needed for their assigned tasks. Even after completing those tasks, the developers believed that the AI tools had made them 20 percent faster, on average. In reality, though, the AI-aided tasks ended up being completed 19 percent &lt;em&gt;slower&lt;/em&gt; than those completed without AI tools.&lt;/p&gt;
&lt;h2&gt;Trade-offs&lt;/h2&gt;
&lt;p&gt;By analyzing screen recording data from a subset of the studied developers, the METR researchers found that AI tools tended to reduce the average time those developers spent actively coding, testing/debugging, or "reading/searching for information." But those time savings were overwhelmed in the end by "time reviewing AI outputs, prompting AI systems, and waiting for AI generations," as well as "idle/overhead time" where the screen recordings show no activity.&lt;/p&gt;
&lt;p&gt;Overall, the developers in the study accepted less than 44 percent of the code generated by AI without modification. A majority of the developers reported needing to make changes to the code generated by their AI companion, and a total of 9 percent of the total task time in the "AI-assisted" portion of the study was taken up by this kind of review.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2105852 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="737" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/aicodingtime.png" width="1141" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Time saved on things like active coding was overwhelmed by the time needed to prompt, wait on, and review AI outputs in the study.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          METR

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;On the surface, METR's results seem to contradict other benchmarks and experiments that demonstrate increases in coding efficiency when AI tools are used. But those often also measure productivity in terms of total lines of code or the number of discrete tasks/code commits/pull requests completed, all of which can be poor proxies for actual coding efficiency.&lt;/p&gt;
&lt;p&gt;Many of the existing coding benchmarks also focus on synthetic, algorithmically scorable tasks created specifically for the benchmark test, making it hard to compare those results to those focused on work with pre-existing, real-world code bases. Along those lines, the developers in METR's study reported in surveys that the overall complexity of the repos they work with (which average 10 years of age and over 1 million lines of code) limited how helpful the AI could be. The AI wasn't able to utilize "important tacit knowledge or context" about the codebase, the researchers note, while the "high developer familiarity with [the] repositories" aided their very human coding efficiency in these tasks.&lt;/p&gt;
&lt;p&gt;These factors lead the researchers to conclude that current AI coding tools may be particularly ill-suited to "settings with very high quality standards, or with many implicit requirements (e.g., relating to documentation, testing coverage, or linting/formatting) that take humans substantial time to learn." While those factors may not apply in "many realistic, economically relevant settings" involving simpler code bases, they could limit the impact of AI tools in this study and similar real-world situations.&lt;/p&gt;
&lt;p&gt;And even for complex coding projects like the ones studied, the researchers are also optimistic that further refinement of AI tools could lead to future efficiency gains for programmers. Systems that have better reliability, lower latency, or more relevant outputs (via techniques such as prompt scaffolding or fine-tuning) "could speed up developers in our setting," the researchers write. Already, they say there is "preliminary evidence" that the recent release of Claude 3.7 "can often correctly implement the core functionality of issues on several repositories that are included in our study."&lt;/p&gt;
&lt;p&gt;For now, however, METR's study provides some strong evidence that AI's much-vaunted usefulness for coding tasks may have significant limitations&amp;nbsp;in certain complex, real-world coding scenarios.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Coders spent more time prompting and reviewing AI generations than they saved on coding.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="327" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1409587524-640x327.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1409587524-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Oh no, my AI-generated code is being sucked into a time vortex again!

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;When it comes to concrete use cases for large language models, AI companies love to point out the ways coders and software developers can use these models to increase their productivity and overall efficiency in creating computer code. However, a new randomized controlled trial has found that experienced open source coders became less efficient at coding-related tasks when they used current AI tools.&lt;/p&gt;
&lt;p&gt;For their study, researchers at METR (Model Evaluation and Threat Research) recruited 16 software developers, each with multiple years of experience working on specific open source repositories. The study followed these developers across 246 individual "tasks" involved with maintaining those repos, such as "bug fixes, features, and refactors that would normally be part of their regular work." For half of those tasks, the developers used AI tools like Cursor Pro or Anthropic's Claude; for the others, the programmers were instructed not to use AI assistance. Expected time forecasts for each task (made before the groupings were assigned) were used as a proxy to balance out the overall difficulty of the tasks in each experimental group, and the time needed to fix pull requests based on reviewer feedback was included in the overall assessment.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2105854 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="541" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/aicodingchart.png" width="1093" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Experts and the developers themselves expected time savings that didn't materialize when AI tools were actually used.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          METR

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Before performing the study, the developers in question expected the AI tools would lead to a 24 percent reduction in the time needed for their assigned tasks. Even after completing those tasks, the developers believed that the AI tools had made them 20 percent faster, on average. In reality, though, the AI-aided tasks ended up being completed 19 percent &lt;em&gt;slower&lt;/em&gt; than those completed without AI tools.&lt;/p&gt;
&lt;h2&gt;Trade-offs&lt;/h2&gt;
&lt;p&gt;By analyzing screen recording data from a subset of the studied developers, the METR researchers found that AI tools tended to reduce the average time those developers spent actively coding, testing/debugging, or "reading/searching for information." But those time savings were overwhelmed in the end by "time reviewing AI outputs, prompting AI systems, and waiting for AI generations," as well as "idle/overhead time" where the screen recordings show no activity.&lt;/p&gt;
&lt;p&gt;Overall, the developers in the study accepted less than 44 percent of the code generated by AI without modification. A majority of the developers reported needing to make changes to the code generated by their AI companion, and a total of 9 percent of the total task time in the "AI-assisted" portion of the study was taken up by this kind of review.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2105852 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="737" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/aicodingtime.png" width="1141" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Time saved on things like active coding was overwhelmed by the time needed to prompt, wait on, and review AI outputs in the study.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          METR

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;On the surface, METR's results seem to contradict other benchmarks and experiments that demonstrate increases in coding efficiency when AI tools are used. But those often also measure productivity in terms of total lines of code or the number of discrete tasks/code commits/pull requests completed, all of which can be poor proxies for actual coding efficiency.&lt;/p&gt;
&lt;p&gt;Many of the existing coding benchmarks also focus on synthetic, algorithmically scorable tasks created specifically for the benchmark test, making it hard to compare those results to those focused on work with pre-existing, real-world code bases. Along those lines, the developers in METR's study reported in surveys that the overall complexity of the repos they work with (which average 10 years of age and over 1 million lines of code) limited how helpful the AI could be. The AI wasn't able to utilize "important tacit knowledge or context" about the codebase, the researchers note, while the "high developer familiarity with [the] repositories" aided their very human coding efficiency in these tasks.&lt;/p&gt;
&lt;p&gt;These factors lead the researchers to conclude that current AI coding tools may be particularly ill-suited to "settings with very high quality standards, or with many implicit requirements (e.g., relating to documentation, testing coverage, or linting/formatting) that take humans substantial time to learn." While those factors may not apply in "many realistic, economically relevant settings" involving simpler code bases, they could limit the impact of AI tools in this study and similar real-world situations.&lt;/p&gt;
&lt;p&gt;And even for complex coding projects like the ones studied, the researchers are also optimistic that further refinement of AI tools could lead to future efficiency gains for programmers. Systems that have better reliability, lower latency, or more relevant outputs (via techniques such as prompt scaffolding or fine-tuning) "could speed up developers in our setting," the researchers write. Already, they say there is "preliminary evidence" that the recent release of Claude 3.7 "can often correctly implement the core functionality of issues on several repositories that are included in our study."&lt;/p&gt;
&lt;p&gt;For now, however, METR's study provides some strong evidence that AI's much-vaunted usefulness for coding tasks may have significant limitations&amp;nbsp;in certain complex, real-world coding scenarios.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/07/study-finds-ai-tools-made-open-source-software-developers-19-percent-slower/</guid><pubDate>Mon, 14 Jul 2025 20:02:41 +0000</pubDate></item><item><title>[NEW] Following YouTube, Meta announces crackdown on ‘unoriginal’ Facebook content (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/14/following-youtube-meta-announces-crackdown-on-unoriginal-facebook-content/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta announced on Monday that it will take additional measures to crack down on accounts sharing “unoriginal” content to Facebook, meaning those that repeatedly reuse someone else’s text, photos, or videos. This year, Meta has already taken down around 10 million profiles that were impersonating large content creators, it said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, it has taken action against 500,000 accounts that were engaged in “spammy behavior or fake engagement.” Those actions have included things like demoting the accounts’ comments and reducing the distribution of their content to prevent the accounts from monetizing.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The update from Meta follows only days after YouTube said it was also clarifying its policy around unoriginal content, including mass-produced and repetitive videos — things that have become easier to generate with the help of AI technology.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Like YouTube, Meta says it won’t penalize users who are engaging with other people’s content, doing things like making reaction videos, joining a trend, or adding their own takes. Instead, Meta’s focus is on the reposting of others’ content, either on spam accounts or those that pretend to belong to the original creator. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Accounts that abuse the system by repeatedly reusing someone else’s content will lose access to Facebook monetization programs for a period of time and see reduced distribution of their posts, the company said. When Facebook detects duplicate videos, it will also reduce the distribution of the copies to ensure the original creator gets the views and credit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, the company said it’s testing a system that adds links on duplicate videos that point viewers to the original content. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3027731" height="680" src="https://techcrunch.com/wp-content/uploads/2025/07/518325353_1230476428289887_995133977579823940_n.webp?w=332" width="332" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Meta&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The update arrives as Meta weathers criticism from users across its platforms, including Instagram, about erroneous, over-enforcement of its policies through automated means. A petition with nearly 30,000 signatures asks Meta to fix the issue with wrongfully disabled accounts and its lack of human support, which has users feeling abandoned and has hurt many small businesses. Meta has not yet publicly addressed the issue, despite attention from press and other high-profile creators.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;While Meta’s newest crackdown is focused more on accounts that steal others’ content for profit, issues around unoriginal content are growing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the rise of AI technology, platforms have become flooded with AI slop, a term referencing low-quality media content made using generative AI. On YouTube, for instance, it’s&amp;nbsp;easy&amp;nbsp;to&amp;nbsp;find&amp;nbsp;an AI voice overlaid on photos, video clips, or other repurposed content, thanks to text-to-video AI tools.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s update seemingly only focuses on reused content, but its post suggests that it may be taking AI slop into consideration, too. In a section where the company offers “tips” for making original content, Meta notes that creators shouldn’t just be “stitching together clips” or adding their watermark when using content from other sources, and they should focus on “authentic storytelling,” not short videos offering little value.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Without directly saying so, these types of unoriginal videos are also things that AI tools have made it easier to produce, as low-quality videos will often feature a series of just images or clips (either real or AI), with added AI narration. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the post, Meta also warns creators not to reuse content from other apps or sources, which has been a longstanding rule. It also notes that video captions should be high quality, which could mean cutting down on the use of automated AI captions that aren’t edited by the creator.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3027730" height="653" src="https://techcrunch.com/wp-content/uploads/2025/07/518277668_24017296104593113_8222195989969441417_n.webp?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Meta&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Meta says these changes will roll out gradually over the months ahead, so Facebook creators have time to adjust. If creators think their content isn’t being distributed, they can view the new post-level insights in Facebook’s Professional Dashboard to see why.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Creators will also be able to see if they’re at risk of content recommendation or monetization penalties in the Support home screen from their Page or professional profile’s main menu.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta typically shares information about its content takedowns in its quarterly Transparency Reports. In the last quarter, Meta said that 3% of its worldwide monthly active users on Facebook were fake accounts, and it had taken action on 1 billion fake accounts from January through March 2025. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;More recently, Meta has backed away from fact-checking content itself in favor of Community Notes in the U.S., similar to X, which allows users and contributors to determine if posts follow Meta’s Community Standards and are accurate.  &lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta announced on Monday that it will take additional measures to crack down on accounts sharing “unoriginal” content to Facebook, meaning those that repeatedly reuse someone else’s text, photos, or videos. This year, Meta has already taken down around 10 million profiles that were impersonating large content creators, it said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, it has taken action against 500,000 accounts that were engaged in “spammy behavior or fake engagement.” Those actions have included things like demoting the accounts’ comments and reducing the distribution of their content to prevent the accounts from monetizing.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The update from Meta follows only days after YouTube said it was also clarifying its policy around unoriginal content, including mass-produced and repetitive videos — things that have become easier to generate with the help of AI technology.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Like YouTube, Meta says it won’t penalize users who are engaging with other people’s content, doing things like making reaction videos, joining a trend, or adding their own takes. Instead, Meta’s focus is on the reposting of others’ content, either on spam accounts or those that pretend to belong to the original creator. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Accounts that abuse the system by repeatedly reusing someone else’s content will lose access to Facebook monetization programs for a period of time and see reduced distribution of their posts, the company said. When Facebook detects duplicate videos, it will also reduce the distribution of the copies to ensure the original creator gets the views and credit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, the company said it’s testing a system that adds links on duplicate videos that point viewers to the original content. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3027731" height="680" src="https://techcrunch.com/wp-content/uploads/2025/07/518325353_1230476428289887_995133977579823940_n.webp?w=332" width="332" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Meta&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The update arrives as Meta weathers criticism from users across its platforms, including Instagram, about erroneous, over-enforcement of its policies through automated means. A petition with nearly 30,000 signatures asks Meta to fix the issue with wrongfully disabled accounts and its lack of human support, which has users feeling abandoned and has hurt many small businesses. Meta has not yet publicly addressed the issue, despite attention from press and other high-profile creators.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;While Meta’s newest crackdown is focused more on accounts that steal others’ content for profit, issues around unoriginal content are growing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the rise of AI technology, platforms have become flooded with AI slop, a term referencing low-quality media content made using generative AI. On YouTube, for instance, it’s&amp;nbsp;easy&amp;nbsp;to&amp;nbsp;find&amp;nbsp;an AI voice overlaid on photos, video clips, or other repurposed content, thanks to text-to-video AI tools.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s update seemingly only focuses on reused content, but its post suggests that it may be taking AI slop into consideration, too. In a section where the company offers “tips” for making original content, Meta notes that creators shouldn’t just be “stitching together clips” or adding their watermark when using content from other sources, and they should focus on “authentic storytelling,” not short videos offering little value.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Without directly saying so, these types of unoriginal videos are also things that AI tools have made it easier to produce, as low-quality videos will often feature a series of just images or clips (either real or AI), with added AI narration. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the post, Meta also warns creators not to reuse content from other apps or sources, which has been a longstanding rule. It also notes that video captions should be high quality, which could mean cutting down on the use of automated AI captions that aren’t edited by the creator.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3027730" height="653" src="https://techcrunch.com/wp-content/uploads/2025/07/518277668_24017296104593113_8222195989969441417_n.webp?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Meta&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Meta says these changes will roll out gradually over the months ahead, so Facebook creators have time to adjust. If creators think their content isn’t being distributed, they can view the new post-level insights in Facebook’s Professional Dashboard to see why.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Creators will also be able to see if they’re at risk of content recommendation or monetization penalties in the Support home screen from their Page or professional profile’s main menu.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta typically shares information about its content takedowns in its quarterly Transparency Reports. In the last quarter, Meta said that 3% of its worldwide monthly active users on Facebook were fake accounts, and it had taken action on 1 billion fake accounts from January through March 2025. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;More recently, Meta has backed away from fact-checking content itself in favor of Community Notes in the U.S., similar to X, which allows users and contributors to determine if posts follow Meta’s Community Standards and are accurate.  &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/14/following-youtube-meta-announces-crackdown-on-unoriginal-facebook-content/</guid><pubDate>Mon, 14 Jul 2025 20:30:01 +0000</pubDate></item><item><title>[NEW] Amazon launches Kiro, its own Claude-powered challenger to Windsurf and Codex (AI News | VentureBeat)</title><link>https://venturebeat.com/programming-development/amazon-launches-kiro-its-own-claude-powered-challenger-to-windsurf-and-codex/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Amid the big news that Windsurf is being acquired by Cognition (after its founders went to Google), developers interested in AI-powered coding may be on the hunt for new alternatives.&lt;/p&gt;



&lt;p&gt;In a bit of fortuitous timing, today also saw Amazon’s release of Kiro, a new agentic integrated development environment (IDE) built to help developers move from prototype to production using AI workflows grounded in structure, planning and engineering rigor.&lt;/p&gt;



&lt;p&gt;Kiro uses Claude Sonnet 3.7 and 4.0 as the default model backends. Users can switch between them, and future support for other models may be added.&lt;/p&gt;



&lt;p&gt;Now in public preview, Kiro runs on macOS (Intel and Apple Silicon), Windows and Linux for free to start (limited to 50 interactions per user per month), with additional pricing tiers starting at $19 for more features.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-should-developers-check-out-kiro"&gt;Why should developers check out Kiro?&lt;/h2&gt;



&lt;p&gt;Kiro aims to bridge the gap between “vibe coding” — allowing AI to generate full blocks of code or entire software processes and applications from plain text instructions, typically for rapid prototyping and iteration — and the more demanding process of delivering secure, maintainable and scalable applications in real-world environments.&lt;/p&gt;



&lt;p&gt;The tool combines AI agents with project specifications, technical architecture and automated task management to support a complete software development lifecycle inside a single interface.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-kiro-vs-q-developer"&gt;Kiro vs. Q Developer?&lt;/h2&gt;



&lt;p&gt;But didn’t Amazon already have its own AI-code completion tool, Q Developer? Yes, and that’s still available.&lt;/p&gt;



&lt;p&gt;So why launch a whole new product and brand name that offers some of the same functionality? Sources at Amazon told VentureBeat that “Kiro&amp;nbsp;is a general-purpose agentic IDE for developers to work with any platform of their choice,” as opposed to Q Developer, which is more limited in its support for third-party IDEs, restricted to VSCode, JetBrains, Eclipse and Visual Studio.&lt;/p&gt;



&lt;p&gt;In addition, the sources pointed out that Kiro’s agentic spec-driven development was radically different from the code suggestions offered on discrete snippets by Q Developer. They said some developers may even prefer to use both in tandem, which is supported via the Q Developer Pro subscription which starts at $19 per month per user.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-from-prompt-to-production-with-spec-driven-development"&gt;From prompt to production with spec-driven development&lt;/h2&gt;



&lt;p&gt;Kiro’s key differentiator is its spec-driven development model, which guides the process from ideation to implementation. A simple prompt like “add a review system” triggers a chain of AI-assisted outputs that include:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;User stories with acceptance criteria&lt;/strong&gt; in EARS (Easy Approach to Requirements Syntax) format;&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Design documents&lt;/strong&gt; with data flow diagrams, TypeScript interfaces and API schemas;&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Task lists and sub-tasks&lt;/strong&gt; automatically sequenced by dependency, with tests, loading states and accessibility built-in.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Developers can execute these tasks one at a time through Kiro’s built-in agent interface, with inline diffs, progress tracking and access to historical agent execution logs. As development proceeds, Kiro keeps specs in sync with the codebase, helping teams avoid the typical drift between documentation and implementation.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-agent-hooks-automate-routine-quality-tasks"&gt;Agent hooks automate routine quality tasks&lt;/h2&gt;



&lt;p&gt;Kiro’s &lt;strong&gt;agent hooks&lt;/strong&gt; allow developers to configure automation triggers for everyday tasks like regenerating tests, updating documentation or running security scans.&lt;/p&gt;



&lt;p&gt;Hooks can be tied to actions such as saving files, editing components or pushing commits. Once set up and checked into the repo, they provide team-wide consistency in code quality and standards enforcement.&lt;/p&gt;



&lt;p&gt;For instance, developers can define a hook to ensure new React components follow the ‘Single Responsibility Principle’ or trigger a secrets scan before commits. This approach adds automated quality control without slowing down individual developers.&lt;/p&gt;







&lt;p&gt;Kiro is built on Code OSS, the open-source foundation of Visual Studio Code maintained by Microsoft. It provides the core editor experience without proprietary services, allowing third parties like Kiro to build their own IDEs with full compatibility with VS Code extensions and settings.&lt;/p&gt;



&lt;p&gt;As such, Kiro remains compatible with VS Code extensions, settings and UI conventions. It also supports:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Model Context Protocol (MCP)&lt;/strong&gt; for connecting external tools;&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Agentic multi-modal chat&lt;/strong&gt;, using files, URLs or documents as context;&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Steering rules&lt;/strong&gt; to customize and constrain agent behavior across a codebase;&lt;/li&gt;



&lt;li&gt;Social login via &lt;strong&gt;GitHub&lt;/strong&gt; or &lt;strong&gt;Google&lt;/strong&gt;, with no AWS account required.&lt;/li&gt;
&lt;/ul&gt;



&lt;h2 class="wp-block-heading" id="h-pricing-and-availability"&gt;Pricing and availability&lt;/h2&gt;



&lt;p&gt;Kiro is currently free for all users during its preview period, including Amazon Q Developer and Q Developer Pro subscribers. &lt;/p&gt;



&lt;p&gt;Preview access includes “generous” usage limits aimed at letting developers explore Kiro without frequent disruptions.&lt;/p&gt;



&lt;p&gt;After the preview period ends, users will have a choice of three subscription tiers:&lt;/p&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;&lt;strong&gt;Plan&lt;/strong&gt;&lt;/th&gt;&lt;th&gt;&lt;strong&gt;Monthly price&lt;/strong&gt;&lt;/th&gt;&lt;th&gt;&lt;strong&gt;Included agentic interactions&lt;/strong&gt;&lt;/th&gt;&lt;th&gt;&lt;strong&gt;Notes&lt;/strong&gt;&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Kiro Free&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$0&lt;/td&gt;&lt;td&gt;50 per month&lt;/td&gt;&lt;td&gt;Specs, hooks, steering and MCP support included&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Kiro Pro&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$19&lt;/td&gt;&lt;td&gt;1,000 per month&lt;/td&gt;&lt;td&gt;All features from Free, plus higher usage quota&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Kiro Pro+&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$39&lt;/td&gt;&lt;td&gt;3,000 per month&lt;/td&gt;&lt;td&gt;Designed for heavy users or teams&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;p&gt;Agentic interactions include any direct invocation of Kiro agents — such as initiating a spec, triggering a hook or sending a chat prompt. The subsequent processing work (like multi-step task execution) does not count toward the quota.&lt;/p&gt;



&lt;p&gt;Users on paid plans will also be able to purchase additional interactions at $0.04 each, but overage billing must be explicitly enabled.&lt;/p&gt;







&lt;p&gt;The AI-assisted development ecosystem is becoming increasingly crowded, with several prominent IDEs and agents competing for developer attention. Here’s how Kiro stacks up:&lt;/p&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Tool&lt;/th&gt;&lt;th&gt;Summary&lt;/th&gt;&lt;th&gt;Pricing&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Amazon Q Developer&lt;/td&gt;&lt;td&gt;Multi-environment AI assistant integrated into AWS, IDEs, CLI and chat. Agentic workflows via terminal or IDE. Great for cloud ops, migrations and automation. Free and Pro tiers available.&lt;/td&gt;&lt;td&gt;Free; Pro at $19/user/month&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Claude Code (Anthropic)&lt;/td&gt;&lt;td&gt;CLI-first coding assistant with chat-based iteration, plan/edit modes and diff views. Strong for interactive code development, less structured than Kiro.&lt;/td&gt;&lt;td&gt;Free; Pro at $17/month or $20 billed monthly&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;GitHub Copilot (Microsoft)&lt;/td&gt;&lt;td&gt;Inline code completion tool in VS Code, GitHub. Best for quick assistance. Lacks structured planning or workflow support.&lt;/td&gt;&lt;td&gt;Free trial; Pro $10/month or $100/year; Pro+ $39/month&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Cursor&lt;/td&gt;&lt;td&gt;VS Code–based AI editor for conversational edits and navigation. Optimized for solo coding, minimal planning support.&lt;/td&gt;&lt;td&gt;Free; Pro $20/month ($16/month yearly)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Windsurf (OpenAI, acquired)&lt;/td&gt;&lt;td&gt;Discontinued AI IDE focused on rapid code editing. Offered minimal planning. Key staff/IP acquired by Google and Cognition in July 2025.&lt;/td&gt;&lt;td&gt;Free; Pro $15/month; Teams $30/user/month &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Cognition / Devin&lt;/td&gt;&lt;td&gt;Multi-agent system capable of autonomous software engineering from planning to deployment. Developer-in‑loop model.&lt;/td&gt;&lt;td&gt;Start at $20/month; older tiers at $500/month&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Kiro&lt;/td&gt;&lt;td&gt;Planning-first AI IDE with structured artifacts like specs, design docs and task trees; supports feature planning, implementation and QA automation. Developer‑in‑loop.&lt;/td&gt;&lt;td&gt;Free (50 interactions/mo); Pro: $19/user/mo (1,000 interactions); Pro+: $39/user/mo (3,000 interactions)&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-showcasing-kiro-in-action-nbsp-spirit-of-kiro"&gt;Showcasing Kiro in action:&amp;nbsp;‘Spirit of Kiro’&lt;/h2&gt;



&lt;p&gt;To demonstrate Kiro’s capabilities in a real-world context, Amazon released a full demo project called “Spirit of Kiro”, an open-source crafting game. The project serves as a hands-on example of how Kiro can be used throughout the development lifecycle.&lt;/p&gt;



&lt;p&gt;Over 95% of the game’s codebase was generated by prompting Kiro. The game features unique, procedurally generated items with customizable properties like damage, quirks and enchantments. Players can combine, break down and sell items — providing a complex system that highlights Kiro’s strengths in managing interconnected components and evolving feature sets.&lt;/p&gt;



&lt;p&gt;The repo includes:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Architecture documentation;&lt;/li&gt;



&lt;li&gt;App security overviews;&lt;/li&gt;



&lt;li&gt;A deliberately incomplete sample branch with bugs (for testing spec workflows);&lt;/li&gt;



&lt;li&gt;A roadmap with feature ideas for future contributions.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;The project is also intended as a learning resource. Files like CHALLENGE.md, architecture.md and guiding-principles.md are designed to walk developers through Kiro’s specs, hooks and agentic workflows in practice.&lt;/p&gt;



&lt;p&gt;Developers can clone, run or deploy the project locally or on AWS infrastructure, and open-source contributions are welcome via GitHub.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-developer-response-and-early-impressions"&gt;Developer response and early impressions&lt;/h2&gt;



&lt;p&gt;Kiro’s launch generated active discussion on startup accelerator Y Combinator’s popular developer forum Hacker News, where Nathan Peck, senior developer advocate for generative AI at AWS (username NathanKP) offered technical context and responded to questions.&lt;/p&gt;



&lt;p&gt;He emphasized that Kiro reflects Amazon’s internal engineering practices and is designed to help developers scale from small ideas to robust, production-ready systems.&lt;/p&gt;



&lt;p&gt;Initial community reactions were mixed, but developers were intrigued, praising the emphasis on specs, hooks and structure.&lt;/p&gt;



&lt;p&gt;Some compared it favorably to tools like Claude Code and Cursor, citing the improved rigor in building and documenting features. Others voiced concern over tool churn and switching costs, while some preferred command line interface (CLI)-based tools or simpler interfaces.&lt;/p&gt;



&lt;p&gt;Feedback also surfaced around authentication bugs, platform compatibility and desire for dev container support. These early responses reflect both curiosity and the high expectations developers now have for AI coding tools.&lt;/p&gt;



&lt;p&gt;Kiro enters a crowded field but appears to carve out a niche with its structured, spec-first philosophy and support for developer-in-the-loop workflows.&lt;/p&gt;



&lt;p&gt;It’s not trying to replace developers or automate entire codebases blindly. Instead, it’s offering a more disciplined way to collaborate with AI from planning to delivery.&lt;/p&gt;



&lt;p&gt;With its preview now open and pricing models outlined, Kiro may appeal most to teams and individuals looking to build not just faster, but more thoughtfully — with long-term maintainability, clarity and quality built in.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Amid the big news that Windsurf is being acquired by Cognition (after its founders went to Google), developers interested in AI-powered coding may be on the hunt for new alternatives.&lt;/p&gt;



&lt;p&gt;In a bit of fortuitous timing, today also saw Amazon’s release of Kiro, a new agentic integrated development environment (IDE) built to help developers move from prototype to production using AI workflows grounded in structure, planning and engineering rigor.&lt;/p&gt;



&lt;p&gt;Kiro uses Claude Sonnet 3.7 and 4.0 as the default model backends. Users can switch between them, and future support for other models may be added.&lt;/p&gt;



&lt;p&gt;Now in public preview, Kiro runs on macOS (Intel and Apple Silicon), Windows and Linux for free to start (limited to 50 interactions per user per month), with additional pricing tiers starting at $19 for more features.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-should-developers-check-out-kiro"&gt;Why should developers check out Kiro?&lt;/h2&gt;



&lt;p&gt;Kiro aims to bridge the gap between “vibe coding” — allowing AI to generate full blocks of code or entire software processes and applications from plain text instructions, typically for rapid prototyping and iteration — and the more demanding process of delivering secure, maintainable and scalable applications in real-world environments.&lt;/p&gt;



&lt;p&gt;The tool combines AI agents with project specifications, technical architecture and automated task management to support a complete software development lifecycle inside a single interface.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-kiro-vs-q-developer"&gt;Kiro vs. Q Developer?&lt;/h2&gt;



&lt;p&gt;But didn’t Amazon already have its own AI-code completion tool, Q Developer? Yes, and that’s still available.&lt;/p&gt;



&lt;p&gt;So why launch a whole new product and brand name that offers some of the same functionality? Sources at Amazon told VentureBeat that “Kiro&amp;nbsp;is a general-purpose agentic IDE for developers to work with any platform of their choice,” as opposed to Q Developer, which is more limited in its support for third-party IDEs, restricted to VSCode, JetBrains, Eclipse and Visual Studio.&lt;/p&gt;



&lt;p&gt;In addition, the sources pointed out that Kiro’s agentic spec-driven development was radically different from the code suggestions offered on discrete snippets by Q Developer. They said some developers may even prefer to use both in tandem, which is supported via the Q Developer Pro subscription which starts at $19 per month per user.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-from-prompt-to-production-with-spec-driven-development"&gt;From prompt to production with spec-driven development&lt;/h2&gt;



&lt;p&gt;Kiro’s key differentiator is its spec-driven development model, which guides the process from ideation to implementation. A simple prompt like “add a review system” triggers a chain of AI-assisted outputs that include:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;User stories with acceptance criteria&lt;/strong&gt; in EARS (Easy Approach to Requirements Syntax) format;&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Design documents&lt;/strong&gt; with data flow diagrams, TypeScript interfaces and API schemas;&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Task lists and sub-tasks&lt;/strong&gt; automatically sequenced by dependency, with tests, loading states and accessibility built-in.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Developers can execute these tasks one at a time through Kiro’s built-in agent interface, with inline diffs, progress tracking and access to historical agent execution logs. As development proceeds, Kiro keeps specs in sync with the codebase, helping teams avoid the typical drift between documentation and implementation.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-agent-hooks-automate-routine-quality-tasks"&gt;Agent hooks automate routine quality tasks&lt;/h2&gt;



&lt;p&gt;Kiro’s &lt;strong&gt;agent hooks&lt;/strong&gt; allow developers to configure automation triggers for everyday tasks like regenerating tests, updating documentation or running security scans.&lt;/p&gt;



&lt;p&gt;Hooks can be tied to actions such as saving files, editing components or pushing commits. Once set up and checked into the repo, they provide team-wide consistency in code quality and standards enforcement.&lt;/p&gt;



&lt;p&gt;For instance, developers can define a hook to ensure new React components follow the ‘Single Responsibility Principle’ or trigger a secrets scan before commits. This approach adds automated quality control without slowing down individual developers.&lt;/p&gt;







&lt;p&gt;Kiro is built on Code OSS, the open-source foundation of Visual Studio Code maintained by Microsoft. It provides the core editor experience without proprietary services, allowing third parties like Kiro to build their own IDEs with full compatibility with VS Code extensions and settings.&lt;/p&gt;



&lt;p&gt;As such, Kiro remains compatible with VS Code extensions, settings and UI conventions. It also supports:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Model Context Protocol (MCP)&lt;/strong&gt; for connecting external tools;&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Agentic multi-modal chat&lt;/strong&gt;, using files, URLs or documents as context;&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Steering rules&lt;/strong&gt; to customize and constrain agent behavior across a codebase;&lt;/li&gt;



&lt;li&gt;Social login via &lt;strong&gt;GitHub&lt;/strong&gt; or &lt;strong&gt;Google&lt;/strong&gt;, with no AWS account required.&lt;/li&gt;
&lt;/ul&gt;



&lt;h2 class="wp-block-heading" id="h-pricing-and-availability"&gt;Pricing and availability&lt;/h2&gt;



&lt;p&gt;Kiro is currently free for all users during its preview period, including Amazon Q Developer and Q Developer Pro subscribers. &lt;/p&gt;



&lt;p&gt;Preview access includes “generous” usage limits aimed at letting developers explore Kiro without frequent disruptions.&lt;/p&gt;



&lt;p&gt;After the preview period ends, users will have a choice of three subscription tiers:&lt;/p&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;&lt;strong&gt;Plan&lt;/strong&gt;&lt;/th&gt;&lt;th&gt;&lt;strong&gt;Monthly price&lt;/strong&gt;&lt;/th&gt;&lt;th&gt;&lt;strong&gt;Included agentic interactions&lt;/strong&gt;&lt;/th&gt;&lt;th&gt;&lt;strong&gt;Notes&lt;/strong&gt;&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Kiro Free&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$0&lt;/td&gt;&lt;td&gt;50 per month&lt;/td&gt;&lt;td&gt;Specs, hooks, steering and MCP support included&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Kiro Pro&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$19&lt;/td&gt;&lt;td&gt;1,000 per month&lt;/td&gt;&lt;td&gt;All features from Free, plus higher usage quota&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Kiro Pro+&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$39&lt;/td&gt;&lt;td&gt;3,000 per month&lt;/td&gt;&lt;td&gt;Designed for heavy users or teams&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;p&gt;Agentic interactions include any direct invocation of Kiro agents — such as initiating a spec, triggering a hook or sending a chat prompt. The subsequent processing work (like multi-step task execution) does not count toward the quota.&lt;/p&gt;



&lt;p&gt;Users on paid plans will also be able to purchase additional interactions at $0.04 each, but overage billing must be explicitly enabled.&lt;/p&gt;







&lt;p&gt;The AI-assisted development ecosystem is becoming increasingly crowded, with several prominent IDEs and agents competing for developer attention. Here’s how Kiro stacks up:&lt;/p&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Tool&lt;/th&gt;&lt;th&gt;Summary&lt;/th&gt;&lt;th&gt;Pricing&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Amazon Q Developer&lt;/td&gt;&lt;td&gt;Multi-environment AI assistant integrated into AWS, IDEs, CLI and chat. Agentic workflows via terminal or IDE. Great for cloud ops, migrations and automation. Free and Pro tiers available.&lt;/td&gt;&lt;td&gt;Free; Pro at $19/user/month&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Claude Code (Anthropic)&lt;/td&gt;&lt;td&gt;CLI-first coding assistant with chat-based iteration, plan/edit modes and diff views. Strong for interactive code development, less structured than Kiro.&lt;/td&gt;&lt;td&gt;Free; Pro at $17/month or $20 billed monthly&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;GitHub Copilot (Microsoft)&lt;/td&gt;&lt;td&gt;Inline code completion tool in VS Code, GitHub. Best for quick assistance. Lacks structured planning or workflow support.&lt;/td&gt;&lt;td&gt;Free trial; Pro $10/month or $100/year; Pro+ $39/month&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Cursor&lt;/td&gt;&lt;td&gt;VS Code–based AI editor for conversational edits and navigation. Optimized for solo coding, minimal planning support.&lt;/td&gt;&lt;td&gt;Free; Pro $20/month ($16/month yearly)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Windsurf (OpenAI, acquired)&lt;/td&gt;&lt;td&gt;Discontinued AI IDE focused on rapid code editing. Offered minimal planning. Key staff/IP acquired by Google and Cognition in July 2025.&lt;/td&gt;&lt;td&gt;Free; Pro $15/month; Teams $30/user/month &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Cognition / Devin&lt;/td&gt;&lt;td&gt;Multi-agent system capable of autonomous software engineering from planning to deployment. Developer-in‑loop model.&lt;/td&gt;&lt;td&gt;Start at $20/month; older tiers at $500/month&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Kiro&lt;/td&gt;&lt;td&gt;Planning-first AI IDE with structured artifacts like specs, design docs and task trees; supports feature planning, implementation and QA automation. Developer‑in‑loop.&lt;/td&gt;&lt;td&gt;Free (50 interactions/mo); Pro: $19/user/mo (1,000 interactions); Pro+: $39/user/mo (3,000 interactions)&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-showcasing-kiro-in-action-nbsp-spirit-of-kiro"&gt;Showcasing Kiro in action:&amp;nbsp;‘Spirit of Kiro’&lt;/h2&gt;



&lt;p&gt;To demonstrate Kiro’s capabilities in a real-world context, Amazon released a full demo project called “Spirit of Kiro”, an open-source crafting game. The project serves as a hands-on example of how Kiro can be used throughout the development lifecycle.&lt;/p&gt;



&lt;p&gt;Over 95% of the game’s codebase was generated by prompting Kiro. The game features unique, procedurally generated items with customizable properties like damage, quirks and enchantments. Players can combine, break down and sell items — providing a complex system that highlights Kiro’s strengths in managing interconnected components and evolving feature sets.&lt;/p&gt;



&lt;p&gt;The repo includes:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Architecture documentation;&lt;/li&gt;



&lt;li&gt;App security overviews;&lt;/li&gt;



&lt;li&gt;A deliberately incomplete sample branch with bugs (for testing spec workflows);&lt;/li&gt;



&lt;li&gt;A roadmap with feature ideas for future contributions.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;The project is also intended as a learning resource. Files like CHALLENGE.md, architecture.md and guiding-principles.md are designed to walk developers through Kiro’s specs, hooks and agentic workflows in practice.&lt;/p&gt;



&lt;p&gt;Developers can clone, run or deploy the project locally or on AWS infrastructure, and open-source contributions are welcome via GitHub.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-developer-response-and-early-impressions"&gt;Developer response and early impressions&lt;/h2&gt;



&lt;p&gt;Kiro’s launch generated active discussion on startup accelerator Y Combinator’s popular developer forum Hacker News, where Nathan Peck, senior developer advocate for generative AI at AWS (username NathanKP) offered technical context and responded to questions.&lt;/p&gt;



&lt;p&gt;He emphasized that Kiro reflects Amazon’s internal engineering practices and is designed to help developers scale from small ideas to robust, production-ready systems.&lt;/p&gt;



&lt;p&gt;Initial community reactions were mixed, but developers were intrigued, praising the emphasis on specs, hooks and structure.&lt;/p&gt;



&lt;p&gt;Some compared it favorably to tools like Claude Code and Cursor, citing the improved rigor in building and documenting features. Others voiced concern over tool churn and switching costs, while some preferred command line interface (CLI)-based tools or simpler interfaces.&lt;/p&gt;



&lt;p&gt;Feedback also surfaced around authentication bugs, platform compatibility and desire for dev container support. These early responses reflect both curiosity and the high expectations developers now have for AI coding tools.&lt;/p&gt;



&lt;p&gt;Kiro enters a crowded field but appears to carve out a niche with its structured, spec-first philosophy and support for developer-in-the-loop workflows.&lt;/p&gt;



&lt;p&gt;It’s not trying to replace developers or automate entire codebases blindly. Instead, it’s offering a more disciplined way to collaborate with AI from planning to delivery.&lt;/p&gt;



&lt;p&gt;With its preview now open and pricing models outlined, Kiro may appeal most to teams and individuals looking to build not just faster, but more thoughtfully — with long-term maintainability, clarity and quality built in.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/programming-development/amazon-launches-kiro-its-own-claude-powered-challenger-to-windsurf-and-codex/</guid><pubDate>Mon, 14 Jul 2025 21:16:16 +0000</pubDate></item><item><title>[NEW] Meta built its AI reputation on openness — that may be changing (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/14/meta-built-its-ai-reputation-on-openness-that-may-be-changing/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2195497483.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Top members of Meta’s new Superintelligence Lab discussed pivoting away from the company’s powerful open source AI model, Behemoth, and instead developing a closed model, reports The New York Times.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sources told The Times that Meta had completed training on Behemoth, but delayed its release due to underwhelming internal performance. When the new Superintelligence Lab launched, testing on the model reportedly halted.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The discussions are just that — discussions. Meta CEO Mark Zuckerberg would still need to sign off on any changes, and a company spokesperson told TechCrunch that Meta’s position on open source AI is “unchanged.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We plan to continue releasing leading open source models,” the spokesperson said. “We haven’t released everything we’ve developed historically and we expect to continue training a mix of open and closed models going forward.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The spokesperson did not comment on Meta’s potential shift away from Behemoth. If that happens so that Meta can prioritize closed-source models, it would mark a major philosophical change for the company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Meta deploys more advanced closed-source models internally, like those powering its Meta AI assistant, Zuckerberg had made open source a central part of the company’s external AI strategy — a way to keep AI development moving faster. He loudly positioned the Llama family’s openness as a differentiator from competitors like OpenAI, which Zuckerberg publicly criticized for becoming more closed after partnering with Microsoft. But Meta is under pressure to monetize beyond ads as it pours billions into AI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That includes paying massive signing bonuses and nine-figure salaries to poach top researchers, building out new data centers, and covering the enormous costs of developing artificial general intelligence (AGI), or “superintelligence.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Despite having one of the top AI research labs in the world, Meta still lags behind rivals like OpenAI, Anthropic, Google DeepMind, and xAI when it comes to commercializing its AI work.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If Meta prioritizes closed models, it could suggest that openness was a strategic play, not an ideological one. Past comments from Zuckerberg hint at an ambivalence toward committing to open sourcing Meta’s models. On a podcast last summer, he said:&lt;/p&gt;

&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;
&lt;p class="wp-block-paragraph"&gt;We’re obviously very pro&amp;nbsp;open source, but I haven’t committed to releasing every single thing that we do. I’m basically very inclined to think that open sourcing is going to be good for the community and also good for us because we’ll benefit from the innovations.&amp;nbsp;If at some point, however, there’s some qualitative change in what the thing is capable of, and we feel like it’s not responsible to open source it, then we won’t. It’s all very difficult to predict.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p class="wp-block-paragraph"&gt;Closed models would give Meta more control and more ways to monetize — especially if it believes the talent it has acquired can deliver competitive, best-in-class performance.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Such a shift could also reshape the AI landscape. Open source momentum, largely driven by Meta and models like Llama, could slow, even as OpenAI gears up to release its still-delayed open model. Power could swing back toward the major players with closed ecosystems, while open source development might remain a product of grassroots efforts. The ripple effects would continue across the startup ecosystem, especially for smaller companies focused on fine-turning, safety, and model alignment that rely on access to open foundation models.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the world stage, Meta’s retreat from open source could potentially cede ground to China, which has embraced open source AI — like DeepSeek and Moonshot AI — as a way to build domestic capability and global influence.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2195497483.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Top members of Meta’s new Superintelligence Lab discussed pivoting away from the company’s powerful open source AI model, Behemoth, and instead developing a closed model, reports The New York Times.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sources told The Times that Meta had completed training on Behemoth, but delayed its release due to underwhelming internal performance. When the new Superintelligence Lab launched, testing on the model reportedly halted.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The discussions are just that — discussions. Meta CEO Mark Zuckerberg would still need to sign off on any changes, and a company spokesperson told TechCrunch that Meta’s position on open source AI is “unchanged.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We plan to continue releasing leading open source models,” the spokesperson said. “We haven’t released everything we’ve developed historically and we expect to continue training a mix of open and closed models going forward.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The spokesperson did not comment on Meta’s potential shift away from Behemoth. If that happens so that Meta can prioritize closed-source models, it would mark a major philosophical change for the company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Meta deploys more advanced closed-source models internally, like those powering its Meta AI assistant, Zuckerberg had made open source a central part of the company’s external AI strategy — a way to keep AI development moving faster. He loudly positioned the Llama family’s openness as a differentiator from competitors like OpenAI, which Zuckerberg publicly criticized for becoming more closed after partnering with Microsoft. But Meta is under pressure to monetize beyond ads as it pours billions into AI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That includes paying massive signing bonuses and nine-figure salaries to poach top researchers, building out new data centers, and covering the enormous costs of developing artificial general intelligence (AGI), or “superintelligence.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Despite having one of the top AI research labs in the world, Meta still lags behind rivals like OpenAI, Anthropic, Google DeepMind, and xAI when it comes to commercializing its AI work.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If Meta prioritizes closed models, it could suggest that openness was a strategic play, not an ideological one. Past comments from Zuckerberg hint at an ambivalence toward committing to open sourcing Meta’s models. On a podcast last summer, he said:&lt;/p&gt;

&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;
&lt;p class="wp-block-paragraph"&gt;We’re obviously very pro&amp;nbsp;open source, but I haven’t committed to releasing every single thing that we do. I’m basically very inclined to think that open sourcing is going to be good for the community and also good for us because we’ll benefit from the innovations.&amp;nbsp;If at some point, however, there’s some qualitative change in what the thing is capable of, and we feel like it’s not responsible to open source it, then we won’t. It’s all very difficult to predict.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p class="wp-block-paragraph"&gt;Closed models would give Meta more control and more ways to monetize — especially if it believes the talent it has acquired can deliver competitive, best-in-class performance.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Such a shift could also reshape the AI landscape. Open source momentum, largely driven by Meta and models like Llama, could slow, even as OpenAI gears up to release its still-delayed open model. Power could swing back toward the major players with closed ecosystems, while open source development might remain a product of grassroots efforts. The ripple effects would continue across the startup ecosystem, especially for smaller companies focused on fine-turning, safety, and model alignment that rely on access to open foundation models.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the world stage, Meta’s retreat from open source could potentially cede ground to China, which has embraced open source AI — like DeepSeek and Moonshot AI — as a way to build domestic capability and global influence.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/14/meta-built-its-ai-reputation-on-openness-that-may-be-changing/</guid><pubDate>Mon, 14 Jul 2025 22:44:24 +0000</pubDate></item><item><title>[NEW] NVIDIA CEO Jensen Huang Promotes AI in Washington, DC and China (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/nvidia-ceo-promotes-ai-in-dc-and-china/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2024/04/nvidiaheadquarters.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;&lt;span&gt;This month, NVIDIA founder and CEO Jensen Huang promoted AI in both Washington, D.C. and Beijing — emphasizing the benefits that AI will bring to business and society worldwide.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;In the U.S. capital, Huang met with President Trump and U.S. policymakers, reaffirming &lt;/span&gt;&lt;span&gt;NVIDIA’s support for the Administration’s effort to create jobs, strengthen domestic AI infrastructure and onshore manufacturing, and ensure that America leads in AI worldwide.&amp;nbsp;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;In Beijing, Huang&lt;/span&gt; &lt;span&gt;met with government and industry officials to discuss how AI will &lt;/span&gt;&lt;span&gt;raise productivity and expand opportunity. The discussions underscored how researchers worldwide can advance safe and secure AI for the benefit of all.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Huang also provided an update to customers, noting that NVIDIA is filing applications to sell the NVIDIA H20 GPU again. The U.S. government has assured NVIDIA that licenses will be granted, and NVIDIA hopes to start deliveries soon. Finally, Huang announced a new, fully compliant NVIDIA RTX PRO GPU that “is ideal for digital twin AI for smart factories and logistics.”&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;As Huang noted during his visits, the world has reached an inflection point — AI has become a fundamental resource, like energy, water and the internet. Jensen emphasized NVIDIA’s commitment to support open-source research, foundation models and applications, which democratize AI and will empower emerging economies in every region, including Latin America, Europe, Asia and beyond.&amp;nbsp;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;“General-purpose, open-source research and foundation models are the backbone of AI innovation,” Huang explained to reporters in D.C. “We believe that every civil model should run best on the U.S. technology stack, encouraging nations worldwide to choose America.” &lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;

		&lt;footer class="entry-footer hide_disquss " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2024/04/nvidiaheadquarters.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;&lt;span&gt;This month, NVIDIA founder and CEO Jensen Huang promoted AI in both Washington, D.C. and Beijing — emphasizing the benefits that AI will bring to business and society worldwide.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;In the U.S. capital, Huang met with President Trump and U.S. policymakers, reaffirming &lt;/span&gt;&lt;span&gt;NVIDIA’s support for the Administration’s effort to create jobs, strengthen domestic AI infrastructure and onshore manufacturing, and ensure that America leads in AI worldwide.&amp;nbsp;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;In Beijing, Huang&lt;/span&gt; &lt;span&gt;met with government and industry officials to discuss how AI will &lt;/span&gt;&lt;span&gt;raise productivity and expand opportunity. The discussions underscored how researchers worldwide can advance safe and secure AI for the benefit of all.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Huang also provided an update to customers, noting that NVIDIA is filing applications to sell the NVIDIA H20 GPU again. The U.S. government has assured NVIDIA that licenses will be granted, and NVIDIA hopes to start deliveries soon. Finally, Huang announced a new, fully compliant NVIDIA RTX PRO GPU that “is ideal for digital twin AI for smart factories and logistics.”&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;As Huang noted during his visits, the world has reached an inflection point — AI has become a fundamental resource, like energy, water and the internet. Jensen emphasized NVIDIA’s commitment to support open-source research, foundation models and applications, which democratize AI and will empower emerging economies in every region, including Latin America, Europe, Asia and beyond.&amp;nbsp;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;“General-purpose, open-source research and foundation models are the backbone of AI innovation,” Huang explained to reporters in D.C. “We believe that every civil model should run best on the U.S. technology stack, encouraging nations worldwide to choose America.” &lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;

		&lt;footer class="entry-footer hide_disquss " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/nvidia-ceo-promotes-ai-in-dc-and-china/</guid><pubDate>Tue, 15 Jul 2025 01:15:06 +0000</pubDate></item></channel></rss>