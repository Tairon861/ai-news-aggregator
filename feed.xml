<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 09 Oct 2025 06:32:19 +0000</lastBuildDate><item><title>Here’s what Jony Ive and Sam Altman revealed about their secretive AI hardware project at OpenAI’s Dev Day (AI | VentureBeat)</title><link>https://venturebeat.com/ai/heres-what-jony-ive-and-sam-altman-revealed-about-their-secretive-ai</link><description>[unable to retrieve full-text content]&lt;p&gt;In a packed theater at Fort Mason, after a whirlwind keynote of product announcements, &lt;a href="https://openai.com/"&gt;&lt;u&gt;OpenAI&lt;/u&gt;&lt;/a&gt; CEO Sam Altman sat down with Sir Jony Ive, the legendary designer behind Apple&amp;#x27;s most iconic products. The conversation, held exclusively for the 1,500 developers in attendance and not part of the public livestream, offered the clearest glimpse yet into the philosophy and ambition behind their secretive collaboration to build a new &amp;quot;family&amp;quot; of AI-powered devices.&lt;/p&gt;&lt;p&gt;The partnership, solidified by OpenAI&amp;#x27;s &lt;a href="https://www.nytimes.com/2025/05/21/technology/openai-jony-ive-deal.html"&gt;&lt;u&gt;staggering $6.5 billion acquisition&lt;/u&gt;&lt;/a&gt; of Ive&amp;#x27;s hardware startup Io in May, has been the subject of intense speculation.While concrete product details remained under wraps, the discussion pivoted away from specifications and toward a profound, almost therapeutic mission: to fix our broken relationship with technology.&lt;/p&gt;&lt;p&gt;For nearly 45 minutes, Ive, in his signature thoughtful cadence, articulated a vision that feels like both a continuation of and a repentance for his life&amp;#x27;s work. The man who designed the iPhone, a device that arguably defined the modern era of personal computing, is now on a quest to cure the very anxieties it helped create.&lt;/p&gt;&lt;h2&gt;Jony Ive&amp;#x27;s post-Apple mission, clarified by ChatGPT&lt;/h2&gt;&lt;p&gt;The collaboration, Ive explained, was years in the making, but it was the launch of ChatGPT that provided a sudden, clarifying purpose for his post-Apple design collective, &lt;a href="https://www.lovefrom.com/"&gt;&lt;u&gt;LoveFrom&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&amp;quot;With the launch of ChatGPT, it felt like our purpose for the last six years became clear,&amp;quot; Ive said. &amp;quot;We were starting to develop some ideas for an interface based on the capability of the technology these guys were developing... I&amp;#x27;ve never in my career come across anything vaguely like the affordance, like the capability that we&amp;#x27;re now starting to sense.&amp;quot;&lt;/p&gt;&lt;p&gt;This capability, he argued, demands a fundamental rethinking of the devices we use, which he described as &amp;quot;legacy products&amp;quot; from a bygone era. The core motivation, he stressed, is not about corporate agendas but about a sense of duty to humanity.&lt;/p&gt;&lt;p&gt;&amp;quot;The reason we&amp;#x27;re doing this is we love our species and we want to be useful,&amp;quot; Ive said. &amp;quot;We think that humanity deserves much better than humanity generally is given.&amp;quot;&lt;/p&gt;&lt;h2&gt;An &amp;#x27;obscene understatement&amp;#x27;: Jony Ive&amp;#x27;s quest to cure our tech anxiety&lt;/h2&gt;&lt;p&gt;The most striking theme of the conversation was Ive&amp;#x27;s candid critique of the current state of technology — the very ecosystem he was instrumental in building. He described our current dynamic with our devices as deeply flawed, a problem he now sees AI as the solution to, not an extension of.&lt;/p&gt;&lt;p&gt;&amp;quot;I don&amp;#x27;t think we have an easy relationship with our technology at the moment,&amp;quot; Ive began, before adding, &amp;quot;When I said we have an uncomfortable relationship with our technology, I mean, that&amp;#x27;s the most obscene understatement.&amp;quot;&lt;/p&gt;&lt;p&gt;Instead of chasing productivity, the primary goal for this new family of devices is emotional well-being. It&amp;#x27;s a radical departure from the efficiency-obsessed ethos that dominates Silicon Valley.&lt;/p&gt;&lt;p&gt;When asked about his ambitions for the new devices, Ive prioritized emotional well-being over simple productivity. &amp;quot;I know I should care about productivity, and I do,&amp;quot; he said, but his ultimate goal is that the tools &amp;quot;make us happy and fulfilled, and more peaceful and less anxious, and less disconnected.&amp;quot;&lt;/p&gt;&lt;p&gt;He framed it as a chance to reject the current, fraught relationship people have with their technology. &amp;quot;We have a chance to... absolutely change the situation that we find ourselves in,&amp;quot; he stated. &amp;quot;We don&amp;#x27;t accept this has to be the norm.&amp;quot;&lt;/p&gt;&lt;h2&gt;Buried in brilliance: why &amp;#x27;15 to 20 compelling ideas&amp;#x27; have become Ive&amp;#x27;s biggest challenge&lt;/h2&gt;&lt;p&gt;While the vision is clear, the path is fraught with challenges. Reports have surfaced about &lt;a href="https://www.ft.com/content/58b078be-e0ab-492f-9dbf-c2fe67298dd3"&gt;&lt;u&gt;technical hurdles and philosophical debates&lt;/u&gt;&lt;/a&gt; delaying the project. Ive himself gave voice to this struggle, admitting the sheer pace of AI&amp;#x27;s progress has been overwhelming. The rapid advancement has generated a torrent of possibilities, making the crucial act of focusing incredibly difficult.&lt;/p&gt;&lt;p&gt;&amp;quot;The momentum is so extraordinary... it has led us to generate 15 to 20 really compelling product ideas. And the challenge is trying to focus,&amp;quot; Ive confessed.&amp;quot;I used to be good at that, and I&amp;#x27;ve lost some confidence, because the choices are, it&amp;#x27;ll be easy if you really knew there were three good ones... it&amp;#x27;s just not like that.&amp;quot;&lt;/p&gt;&lt;p&gt;This admission provides context to reports that the team is grappling with unresolved issues around the device&amp;#x27;s &amp;quot;personality&amp;quot; and computing infrastructure. The goal, according to one source, is to create an AI companion that is &amp;quot;accessible but not intrusive,&amp;quot; avoiding the pitfalls of a &amp;quot;&lt;a href="https://www.ft.com/content/58b078be-e0ab-492f-9dbf-c2fe67298dd3"&gt;&lt;u&gt;weird AI girlfriend&lt;/u&gt;&lt;/a&gt;.&amp;quot;&lt;/p&gt;&lt;h2&gt;Beyond the screen: Ive&amp;#x27;s design philosophy for an &amp;#x27;inevitable&amp;#x27; AI device&lt;/h2&gt;&lt;p&gt;While no devices were shown, the conversation and prior reports offer clues. The project involves a &amp;quot;&lt;a href="https://fortune.com/2025/10/07/legendary-apple-designer-jony-ive-wants-to-fix-our-relationships-with-technology-openai/"&gt;&lt;u&gt;family of devices&lt;/u&gt;&lt;/a&gt;,&amp;quot; not a single gadget.It will likely be a departure from the screen-centric world we inhabit. Reports suggest a &amp;quot;&lt;a href="https://www.ft.com/content/58b078be-e0ab-492f-9dbf-c2fe67298dd3"&gt;&lt;u&gt;palm-sized device without a screen&lt;/u&gt;&lt;/a&gt;&amp;quot; that relies on cameras and microphones to perceive its environment.&lt;/p&gt;&lt;p&gt;Ive argued that it would be &amp;quot;absurd&amp;quot; to assume that today&amp;#x27;s breathtaking AI technology should be delivered through &amp;quot;products that are decades old.&amp;quot; The goal is to create something that feels entirely new, yet completely natural.&lt;/p&gt;&lt;p&gt;&amp;quot;It should seem inevitable. It should seem obvious, as if there wasn&amp;#x27;t possibly another rational solution to the problem,&amp;quot; Ive said, echoing a design philosophy often attributed to his time with Steve Jobs.&lt;/p&gt;&lt;p&gt;He also spoke of bringing a sense of joy and whimsy back to technology, pushing back against a culture he feels has become overly serious.&lt;/p&gt;&lt;p&gt;&amp;quot;In terms of the interfaces we design, if we can&amp;#x27;t smile honestly, if it&amp;#x27;s just another deeply serious sort of exclusive thing, I think that would do us all a huge disservice,&amp;quot; he remarked.&lt;/p&gt;&lt;p&gt;The chat concluded without a product reveal, leaving the audience with a philosophical blueprint rather than a technical one. The central narrative is clear: &lt;a href="https://openai.com/sam-and-jony/"&gt;&lt;u&gt;Jony Ive&lt;/u&gt;&lt;/a&gt;, the designer who put a screen in every pocket, is now betting on a screenless future, powered by OpenAI&amp;#x27;s formidable intelligence, to make us all a little less anxious and a little more human.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;In a packed theater at Fort Mason, after a whirlwind keynote of product announcements, &lt;a href="https://openai.com/"&gt;&lt;u&gt;OpenAI&lt;/u&gt;&lt;/a&gt; CEO Sam Altman sat down with Sir Jony Ive, the legendary designer behind Apple&amp;#x27;s most iconic products. The conversation, held exclusively for the 1,500 developers in attendance and not part of the public livestream, offered the clearest glimpse yet into the philosophy and ambition behind their secretive collaboration to build a new &amp;quot;family&amp;quot; of AI-powered devices.&lt;/p&gt;&lt;p&gt;The partnership, solidified by OpenAI&amp;#x27;s &lt;a href="https://www.nytimes.com/2025/05/21/technology/openai-jony-ive-deal.html"&gt;&lt;u&gt;staggering $6.5 billion acquisition&lt;/u&gt;&lt;/a&gt; of Ive&amp;#x27;s hardware startup Io in May, has been the subject of intense speculation.While concrete product details remained under wraps, the discussion pivoted away from specifications and toward a profound, almost therapeutic mission: to fix our broken relationship with technology.&lt;/p&gt;&lt;p&gt;For nearly 45 minutes, Ive, in his signature thoughtful cadence, articulated a vision that feels like both a continuation of and a repentance for his life&amp;#x27;s work. The man who designed the iPhone, a device that arguably defined the modern era of personal computing, is now on a quest to cure the very anxieties it helped create.&lt;/p&gt;&lt;h2&gt;Jony Ive&amp;#x27;s post-Apple mission, clarified by ChatGPT&lt;/h2&gt;&lt;p&gt;The collaboration, Ive explained, was years in the making, but it was the launch of ChatGPT that provided a sudden, clarifying purpose for his post-Apple design collective, &lt;a href="https://www.lovefrom.com/"&gt;&lt;u&gt;LoveFrom&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&amp;quot;With the launch of ChatGPT, it felt like our purpose for the last six years became clear,&amp;quot; Ive said. &amp;quot;We were starting to develop some ideas for an interface based on the capability of the technology these guys were developing... I&amp;#x27;ve never in my career come across anything vaguely like the affordance, like the capability that we&amp;#x27;re now starting to sense.&amp;quot;&lt;/p&gt;&lt;p&gt;This capability, he argued, demands a fundamental rethinking of the devices we use, which he described as &amp;quot;legacy products&amp;quot; from a bygone era. The core motivation, he stressed, is not about corporate agendas but about a sense of duty to humanity.&lt;/p&gt;&lt;p&gt;&amp;quot;The reason we&amp;#x27;re doing this is we love our species and we want to be useful,&amp;quot; Ive said. &amp;quot;We think that humanity deserves much better than humanity generally is given.&amp;quot;&lt;/p&gt;&lt;h2&gt;An &amp;#x27;obscene understatement&amp;#x27;: Jony Ive&amp;#x27;s quest to cure our tech anxiety&lt;/h2&gt;&lt;p&gt;The most striking theme of the conversation was Ive&amp;#x27;s candid critique of the current state of technology — the very ecosystem he was instrumental in building. He described our current dynamic with our devices as deeply flawed, a problem he now sees AI as the solution to, not an extension of.&lt;/p&gt;&lt;p&gt;&amp;quot;I don&amp;#x27;t think we have an easy relationship with our technology at the moment,&amp;quot; Ive began, before adding, &amp;quot;When I said we have an uncomfortable relationship with our technology, I mean, that&amp;#x27;s the most obscene understatement.&amp;quot;&lt;/p&gt;&lt;p&gt;Instead of chasing productivity, the primary goal for this new family of devices is emotional well-being. It&amp;#x27;s a radical departure from the efficiency-obsessed ethos that dominates Silicon Valley.&lt;/p&gt;&lt;p&gt;When asked about his ambitions for the new devices, Ive prioritized emotional well-being over simple productivity. &amp;quot;I know I should care about productivity, and I do,&amp;quot; he said, but his ultimate goal is that the tools &amp;quot;make us happy and fulfilled, and more peaceful and less anxious, and less disconnected.&amp;quot;&lt;/p&gt;&lt;p&gt;He framed it as a chance to reject the current, fraught relationship people have with their technology. &amp;quot;We have a chance to... absolutely change the situation that we find ourselves in,&amp;quot; he stated. &amp;quot;We don&amp;#x27;t accept this has to be the norm.&amp;quot;&lt;/p&gt;&lt;h2&gt;Buried in brilliance: why &amp;#x27;15 to 20 compelling ideas&amp;#x27; have become Ive&amp;#x27;s biggest challenge&lt;/h2&gt;&lt;p&gt;While the vision is clear, the path is fraught with challenges. Reports have surfaced about &lt;a href="https://www.ft.com/content/58b078be-e0ab-492f-9dbf-c2fe67298dd3"&gt;&lt;u&gt;technical hurdles and philosophical debates&lt;/u&gt;&lt;/a&gt; delaying the project. Ive himself gave voice to this struggle, admitting the sheer pace of AI&amp;#x27;s progress has been overwhelming. The rapid advancement has generated a torrent of possibilities, making the crucial act of focusing incredibly difficult.&lt;/p&gt;&lt;p&gt;&amp;quot;The momentum is so extraordinary... it has led us to generate 15 to 20 really compelling product ideas. And the challenge is trying to focus,&amp;quot; Ive confessed.&amp;quot;I used to be good at that, and I&amp;#x27;ve lost some confidence, because the choices are, it&amp;#x27;ll be easy if you really knew there were three good ones... it&amp;#x27;s just not like that.&amp;quot;&lt;/p&gt;&lt;p&gt;This admission provides context to reports that the team is grappling with unresolved issues around the device&amp;#x27;s &amp;quot;personality&amp;quot; and computing infrastructure. The goal, according to one source, is to create an AI companion that is &amp;quot;accessible but not intrusive,&amp;quot; avoiding the pitfalls of a &amp;quot;&lt;a href="https://www.ft.com/content/58b078be-e0ab-492f-9dbf-c2fe67298dd3"&gt;&lt;u&gt;weird AI girlfriend&lt;/u&gt;&lt;/a&gt;.&amp;quot;&lt;/p&gt;&lt;h2&gt;Beyond the screen: Ive&amp;#x27;s design philosophy for an &amp;#x27;inevitable&amp;#x27; AI device&lt;/h2&gt;&lt;p&gt;While no devices were shown, the conversation and prior reports offer clues. The project involves a &amp;quot;&lt;a href="https://fortune.com/2025/10/07/legendary-apple-designer-jony-ive-wants-to-fix-our-relationships-with-technology-openai/"&gt;&lt;u&gt;family of devices&lt;/u&gt;&lt;/a&gt;,&amp;quot; not a single gadget.It will likely be a departure from the screen-centric world we inhabit. Reports suggest a &amp;quot;&lt;a href="https://www.ft.com/content/58b078be-e0ab-492f-9dbf-c2fe67298dd3"&gt;&lt;u&gt;palm-sized device without a screen&lt;/u&gt;&lt;/a&gt;&amp;quot; that relies on cameras and microphones to perceive its environment.&lt;/p&gt;&lt;p&gt;Ive argued that it would be &amp;quot;absurd&amp;quot; to assume that today&amp;#x27;s breathtaking AI technology should be delivered through &amp;quot;products that are decades old.&amp;quot; The goal is to create something that feels entirely new, yet completely natural.&lt;/p&gt;&lt;p&gt;&amp;quot;It should seem inevitable. It should seem obvious, as if there wasn&amp;#x27;t possibly another rational solution to the problem,&amp;quot; Ive said, echoing a design philosophy often attributed to his time with Steve Jobs.&lt;/p&gt;&lt;p&gt;He also spoke of bringing a sense of joy and whimsy back to technology, pushing back against a culture he feels has become overly serious.&lt;/p&gt;&lt;p&gt;&amp;quot;In terms of the interfaces we design, if we can&amp;#x27;t smile honestly, if it&amp;#x27;s just another deeply serious sort of exclusive thing, I think that would do us all a huge disservice,&amp;quot; he remarked.&lt;/p&gt;&lt;p&gt;The chat concluded without a product reveal, leaving the audience with a philosophical blueprint rather than a technical one. The central narrative is clear: &lt;a href="https://openai.com/sam-and-jony/"&gt;&lt;u&gt;Jony Ive&lt;/u&gt;&lt;/a&gt;, the designer who put a screen in every pocket, is now betting on a screenless future, powered by OpenAI&amp;#x27;s formidable intelligence, to make us all a little less anxious and a little more human.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/heres-what-jony-ive-and-sam-altman-revealed-about-their-secretive-ai</guid><pubDate>Wed, 08 Oct 2025 18:40:00 +0000</pubDate></item><item><title>MIT Schwarzman College of Computing and MBZUAI launch international collaboration to shape the future of AI (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/mit-schwarzman-college-computing-mbzuai-launch-collaboration-shape-future-ai-1008</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202510/mit-mbzuai.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;The MIT Schwarzman College of Computing and the Mohamed bin Zayed University of Artificial Intelligence (MBZUAI) recently celebrated the launch of the MIT–MBZUAI Collaborative Research Program, a new effort to strengthen the building blocks of artificial intelligence and accelerate its use in pressing scientific and societal challenges.&lt;/p&gt;&lt;p&gt;Under the five-year agreement, faculty, students, and research staff from both institutions will collaborate on fundamental research projects to advance the technological foundations of AI and its applications in three core areas: scientific discovery, human thriving, and the health of the planet.&lt;/p&gt;&lt;p&gt;“Artificial intelligence is transforming nearly every aspect of human endeavor. MIT’s leadership in AI is greatly enriched through collaborations with leading academic institutions in the U.S. and around the world,” says Dan Huttenlocher, dean of the MIT Schwarzman College of Computing and the Henry Ellis Warren Professor of Electrical Engineering and Computer Science. “Our collaboration with MBZUAI reflects a shared commitment to advancing AI in ways that are responsible, inclusive, and globally impactful. Together, we can explore new horizons in AI and bring broad benefits to society.”&lt;/p&gt;&lt;p&gt;“This agreement will unite the efforts of researchers at two world-class institutions to advance frontier AI research across scientific discovery, human thriving, and the health of the planet. By combining MBZUAI’s focus on foundational models and real-world deployment with MIT’s depth in computing and interdisciplinary innovation, we are creating a transcontinental bridge for discovery. Together, we will not only expand the boundaries of AI science, but also ensure that these breakthroughs are pursued responsibly and applied where they matter most — improving human health, enabling intelligent robotics, and driving sustainable AI at scale,” says Eric Xing, president and university professor at MBZUAI.&lt;/p&gt;&lt;p&gt;Each institution has appointed an academic director to oversee the program on its campus. At MIT, Philip Isola, the Class of 1948 Career Development Professor in the Department of Electrical Engineering and Computer Science, will serve as program lead. At MBZUAI, Le Song, professor of machine learning, will take on the role.&lt;/p&gt;&lt;p&gt;Supported by MBZUAI — the first university dedicated entirely to advancing science through AI, and based in Abu Dhabi, U.A.E. — the collaboration will fund a number of joint research projects per year. The findings will be openly publishable, and each project will be led by a principal investigator from MIT and one from MBZUAI, with project selections made by a steering committee composed of representatives from both institutions.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202510/mit-mbzuai.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;The MIT Schwarzman College of Computing and the Mohamed bin Zayed University of Artificial Intelligence (MBZUAI) recently celebrated the launch of the MIT–MBZUAI Collaborative Research Program, a new effort to strengthen the building blocks of artificial intelligence and accelerate its use in pressing scientific and societal challenges.&lt;/p&gt;&lt;p&gt;Under the five-year agreement, faculty, students, and research staff from both institutions will collaborate on fundamental research projects to advance the technological foundations of AI and its applications in three core areas: scientific discovery, human thriving, and the health of the planet.&lt;/p&gt;&lt;p&gt;“Artificial intelligence is transforming nearly every aspect of human endeavor. MIT’s leadership in AI is greatly enriched through collaborations with leading academic institutions in the U.S. and around the world,” says Dan Huttenlocher, dean of the MIT Schwarzman College of Computing and the Henry Ellis Warren Professor of Electrical Engineering and Computer Science. “Our collaboration with MBZUAI reflects a shared commitment to advancing AI in ways that are responsible, inclusive, and globally impactful. Together, we can explore new horizons in AI and bring broad benefits to society.”&lt;/p&gt;&lt;p&gt;“This agreement will unite the efforts of researchers at two world-class institutions to advance frontier AI research across scientific discovery, human thriving, and the health of the planet. By combining MBZUAI’s focus on foundational models and real-world deployment with MIT’s depth in computing and interdisciplinary innovation, we are creating a transcontinental bridge for discovery. Together, we will not only expand the boundaries of AI science, but also ensure that these breakthroughs are pursued responsibly and applied where they matter most — improving human health, enabling intelligent robotics, and driving sustainable AI at scale,” says Eric Xing, president and university professor at MBZUAI.&lt;/p&gt;&lt;p&gt;Each institution has appointed an academic director to oversee the program on its campus. At MIT, Philip Isola, the Class of 1948 Career Development Professor in the Department of Electrical Engineering and Computer Science, will serve as program lead. At MBZUAI, Le Song, professor of machine learning, will take on the role.&lt;/p&gt;&lt;p&gt;Supported by MBZUAI — the first university dedicated entirely to advancing science through AI, and based in Abu Dhabi, U.A.E. — the collaboration will fund a number of joint research projects per year. The findings will be openly publishable, and each project will be led by a principal investigator from MIT and one from MBZUAI, with project selections made by a steering committee composed of representatives from both institutions.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/mit-schwarzman-college-computing-mbzuai-launch-collaboration-shape-future-ai-1008</guid><pubDate>Wed, 08 Oct 2025 19:10:00 +0000</pubDate></item><item><title>OpenAI’s Nick Turley on transforming ChatGPT into an operating system (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/08/openais-nick-turley-on-transforming-chatgpt-into-an-operating-system/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;When Nick Turley joined OpenAI in 2022 as the head of ChatGPT, he was tasked with commercializing the company’s research. He has made great strides toward that goal, growing the product to 800 million weekly active users. Now Turley wants to take an even bigger swing: transforming ChatGPT into a new type of operating system full of third-party apps.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I sat down with Turley this week on the outskirts of San Francisco’s Fort Mason, a former U.S. military post where OpenAI held its third annual developer conference, to discuss how he’s thinking about ChatGPT’s future. You can find a transcript of our conversation at the bottom of this article.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;To turn ChatGPT into an operating system, Turley tells me he’s drawing inspiration from web browsers. Over the last decade, browsers have emerged as a new kind of operating system — not in the literal sense like macOS or Windows — because they’ve become the main place people work on computers thanks to a variety of web applications. Turley sees ChatGPT evolving in a similar way: a platform that could change how people interact with software.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is reportedly developing a browser too. Turley doesn’t confirm or deny this, but he does say browsers are “really interesting.” The company is also working with Jony Ive and a team of longtime Apple designers on a family of hardware devices. Given these efforts, it’s easy to see how a ChatGPT operating system full of apps could become a central component of OpenAI’s consumer ecosystem.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has been chasing this idea for a while. In 2023, the company launched an array of “AI app store” efforts such as ChatGPT plugins and the GPT Store. Those products didn’t exactly take off, but OpenAI seems to have a better approach this time around.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch of apps aligns with OpenAI’s desire to turn ChatGPT into an e-commerce destination. Apps from Expedia, DoorDash, and Uber could lead to more transactions in ChatGPT, something OpenAI can now facilitate and capture some of the revenue from. Having a product featured in ChatGPT could be a major source of business for both third parties and OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This might also be OpenAI’s most compelling pitch to developers yet. Third parties can now reach ChatGPT’s 800 million users during their everyday conversations. Apps are part of ChatGPT’s core experience, rather than in a separate store of widgets. Developers can also build more interactive experiences in ChatGPT, beyond just chatbots connected to their company’s data.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;However, the business of running an operating system also comes with lots of messy problems, such as how to promote certain apps over others. Turley says OpenAI isn’t ruling out letting some companies pay for their apps to have priority placement in ChatGPT, but the company is figuring out how to do this without hurting the user experience.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Third-party developers likely also want access to ChatGPT user data. In a set of guidelines, OpenAI says app developers must “gather only the minimum data required to perform the tool’s function,” but it’s unclear what that means in practice. Turley says OpenAI may build out new features — such as a partitioned memory in ChatGPT — that could let users give fine-grained data access to developers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One standout comment from our conversation was how Turley views ChatGPT as the “delivery vehicle” for OpenAI’s nonprofit mission: to develop and distribute artificial general intelligence (AGI) — highly autonomous AI systems — in a way that benefits humanity. Some OpenAI researchers worry that the company’s consumer business could overpower its nonprofit mission. But according to Turley, ChatGPT is how OpenAI will distribute AGI to the masses. How’s that for a spin?&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Here’s my conversation with Nick Turley, head of ChatGPT, which has been edited for clarity and brevity. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3055345" height="678" src="https://techcrunch.com/wp-content/uploads/2025/10/Nick-Turley.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;OpenAI’s Head of ChatGPT, Nick Turley.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;OpenAI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;How are you thinking about ChatGPT as a platform for other companies?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I think we’re gonna look back at ChatGPT in a couple years and feel like the current product is in the command line era. It’s really powerful, but it’s lacking something very important, which is affordances.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the classic operating system world, that’s obvious. We prefer going to Mac or Windows and opening applications versus remembering all the commands. It’s kind of bonkers to me that we’ve scaled the product to 800 million weekly active users with the form factor we have. This is a weird and hard [way] to grow category, and yet it’s growing like crazy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The evolution we’re trying to make over the next few years is one where ChatGPT itself is more like an operating system where you can come and use applications. If you want to write, there’s an app for that. If you want to code, there’s an app for that. If you want to interact with goods and services, there are applications for you.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But we can’t build everything ourselves. We’re not going to have a music streaming service, or replicate Coursera’s catalog of educational materials. We’re not going to get into the business that Expedia and Booking.com are in. And for that reason, it makes sense to partner.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There’s also a whole generation of apps that people are going to build that wouldn’t have been possible previously. The Ubers of the world only exist because of the mobile platform, and I’m really excited about what those might be for ChatGPT.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We also want to give developers, who have been with us since the beginning, access to ChatGPT’s 800 million weekly users. If they’re able to enhance ChatGPT and build real businesses on top of that, it creates more winners in the ecosystem.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Where do you draw inspiration from when building ChatGPT?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;You can’t go to one spot. I often tell job candidates they need to have first principles thinking, and if they’re gonna try to run a playbook they saw at Meta or Google, you’re actually gonna run out of competitors to copy. When it comes to [ChatGPT] or Sora, there’s just zero precedent. So you kind of have to get your analogies from different places.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I think browsers are really interesting because, in some ways, they’ve become the operating system in the last 10 years. How many of us actually use desktop apps? You might use Excel or PowerPoint, but most of what we do actually happens in the browser via application-like things.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I also spent some time looking at the early ads for the [Apple] PowerBook. It’s kind of like ChatGPT where it was this appliance that nobody quite knew everything you could do with it. The ads were literally like “It’s a calculator, it’s an alarm clock.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So there isn’t a single thing you can look at, but it behooves us to learn from history. If you just look at the last 10 years, there might not be the perfect analogous thing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;You mentioned browsers and devices there. How are you thinking about expanding ChatGPT into those form factors?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is the kind of place where you dream big. One category we have covered is productivity, which is effectively ChatGPT. But there are so many other product categories to be built, and they’re all going to change with AI. Entertainment is one, which is why I’m excited about Sora. Social media is another one. Obviously, hardware and access points to the internet are interesting too.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;You should really think about what we’re building as a family of products and applications that are tied together by your account, personalization, and identity layer. I’m really excited that we’re not boxing ourselves in. Even if we were just the ChatGPT company, there would be infinite things to build, but our ambition on what we can do for people just goes way beyond that.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;I’m interested in hearing how you think the consumer business of OpenAI fits into the nonprofit mission. I’ve heard some people say the consumer business funds the mission. How do you see it?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The OpenAI I joined was a research lab that might ship a demo or two. In fact, my job description at the time was framed to me as “helping commercialize OpenAI technology” — very open ended. At that time, the product existed to bring the research to life so that people actually get it. I think that was true and still is true, as you can see with Sora. The best way to start a grounded discourse on the profoundness of a technology is to ship something.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Then we moved from that framing to, okay, maybe the product is more than that. Maybe the product is actually the way we fund the mission. It became evident at some point, even before I got to OpenAI, that this is all going to be very expensive. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But after ChatGPT, we started talking about it a bit differently. Our mission is to ensure that AGI benefits all of humanity, and reaches people. If you combine that with the insight that AGI is probably not this single moment in time, but rather a gradual thing, you have to think of product as the delivery vehicle of the mission. It’s the way you actually benefit people in practice.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If you look at what these 800 million people are doing every week, ChatGPT is helping them achieve their goals. I don’t know if you saw the guy in the keynote who taught himself to code at 89. That’s insane to me. I talk to ChatGPT users who help their autistic kids by modeling social interactions. I talk to people who are entirely self-taught in a language based on what they do with ChatGPT. Like, that is the mission.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I don’t think it’s fair to talk about the consumer business as a funding vehicle. Rather, it’s the expression. That is one way in which OpenAI has evolved, to me at least, since I’ve joined.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Let’s dive deeper into the apps that were announced today. OpenAI has said that third parties can only take the “minimum amount of data” necessary to run an app in ChatGPT. How are you thinking about user privacy?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;From day one, we’re going to ask developers to disclose to users what information they’re requesting. We’re also only going to let [apps] go live if they are reasonable in the data that they request. We published our developer guidelines [at launch] so people won’t be surprised when we reject their app because it doesn’t comply with our stance on privacy.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Over the next month, we want to build ways for users to give fine-grained access to developers. I think Apple has done a phenomenal job with this, where you can share data just this time, or all the time, etc.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To do that well, we might need some concept of a partitioned memory in ChatGPT, which we’re still thinking through. But we’re really excited about the idea because you might want to keep certain conversations, like health, separate from others, such as music. Users may want to share one, but not the other, with an app. So we’re going to have a lot more to share soon, because it’s actually a combined research and engineering challenge to do this well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The thing that’s uncompromisable for us is transparency. We want users, at all points, to understand what data might be going to a third party, but the controls will come over time as we build them out.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;DoorDash and Instacart are two companies that will have apps in ChatGPT soon enough. If I want to order some snacks, how will ChatGPT know which one to go to?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is the classic question. The best way to start is you show them both. If you’ve used one of them before, we’ll prioritize that one. If you’ve used both, we’ll ask which one you prefer. We could get more sophisticated over time. You could imagine one of these apps being much higher quality than another. Maybe there would be reason to prioritize one over the other. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We have multiple partners in the same product categories. I think the most graceful and respectful way to handle that is to serve both apps.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Are you thinking about letting companies pay for their apps to have preferential spot placement in ChatGPT?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is one of the things we’re hoping to do some discovery on with developers. There’s this trade-off. You could try to figure it all out in advance, and roll it out with the announcement, but that probably means you didn’t talk to a lot of people. Or you could delay it, which means everyone’s asking questions and doesn’t know exactly what’s going to happen, but it gives us the ability to actually engage.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;We chose the latter just because we know that building this ecosystem is going to be a long game. It’s not going to happen on day one, and therefore it’s better to be thoughtful on what sort of distribution mechanisms are and aren’t fair game.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the end of the day, we want a great user experience. So if that would lead to apps [surfacing] that are irrelevant to the user, I don’t think we’d like it. If this was a lever that helped us prioritize apps that are really serious because they’re clearly trying to invest in exposure, it could be a good thing. We have no point of view as of today. It’s certainly something that’s come up with different partners.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;When Nick Turley joined OpenAI in 2022 as the head of ChatGPT, he was tasked with commercializing the company’s research. He has made great strides toward that goal, growing the product to 800 million weekly active users. Now Turley wants to take an even bigger swing: transforming ChatGPT into a new type of operating system full of third-party apps.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I sat down with Turley this week on the outskirts of San Francisco’s Fort Mason, a former U.S. military post where OpenAI held its third annual developer conference, to discuss how he’s thinking about ChatGPT’s future. You can find a transcript of our conversation at the bottom of this article.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;To turn ChatGPT into an operating system, Turley tells me he’s drawing inspiration from web browsers. Over the last decade, browsers have emerged as a new kind of operating system — not in the literal sense like macOS or Windows — because they’ve become the main place people work on computers thanks to a variety of web applications. Turley sees ChatGPT evolving in a similar way: a platform that could change how people interact with software.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is reportedly developing a browser too. Turley doesn’t confirm or deny this, but he does say browsers are “really interesting.” The company is also working with Jony Ive and a team of longtime Apple designers on a family of hardware devices. Given these efforts, it’s easy to see how a ChatGPT operating system full of apps could become a central component of OpenAI’s consumer ecosystem.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has been chasing this idea for a while. In 2023, the company launched an array of “AI app store” efforts such as ChatGPT plugins and the GPT Store. Those products didn’t exactly take off, but OpenAI seems to have a better approach this time around.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch of apps aligns with OpenAI’s desire to turn ChatGPT into an e-commerce destination. Apps from Expedia, DoorDash, and Uber could lead to more transactions in ChatGPT, something OpenAI can now facilitate and capture some of the revenue from. Having a product featured in ChatGPT could be a major source of business for both third parties and OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This might also be OpenAI’s most compelling pitch to developers yet. Third parties can now reach ChatGPT’s 800 million users during their everyday conversations. Apps are part of ChatGPT’s core experience, rather than in a separate store of widgets. Developers can also build more interactive experiences in ChatGPT, beyond just chatbots connected to their company’s data.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;However, the business of running an operating system also comes with lots of messy problems, such as how to promote certain apps over others. Turley says OpenAI isn’t ruling out letting some companies pay for their apps to have priority placement in ChatGPT, but the company is figuring out how to do this without hurting the user experience.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Third-party developers likely also want access to ChatGPT user data. In a set of guidelines, OpenAI says app developers must “gather only the minimum data required to perform the tool’s function,” but it’s unclear what that means in practice. Turley says OpenAI may build out new features — such as a partitioned memory in ChatGPT — that could let users give fine-grained data access to developers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One standout comment from our conversation was how Turley views ChatGPT as the “delivery vehicle” for OpenAI’s nonprofit mission: to develop and distribute artificial general intelligence (AGI) — highly autonomous AI systems — in a way that benefits humanity. Some OpenAI researchers worry that the company’s consumer business could overpower its nonprofit mission. But according to Turley, ChatGPT is how OpenAI will distribute AGI to the masses. How’s that for a spin?&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Here’s my conversation with Nick Turley, head of ChatGPT, which has been edited for clarity and brevity. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3055345" height="678" src="https://techcrunch.com/wp-content/uploads/2025/10/Nick-Turley.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;OpenAI’s Head of ChatGPT, Nick Turley.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;OpenAI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;How are you thinking about ChatGPT as a platform for other companies?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I think we’re gonna look back at ChatGPT in a couple years and feel like the current product is in the command line era. It’s really powerful, but it’s lacking something very important, which is affordances.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the classic operating system world, that’s obvious. We prefer going to Mac or Windows and opening applications versus remembering all the commands. It’s kind of bonkers to me that we’ve scaled the product to 800 million weekly active users with the form factor we have. This is a weird and hard [way] to grow category, and yet it’s growing like crazy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The evolution we’re trying to make over the next few years is one where ChatGPT itself is more like an operating system where you can come and use applications. If you want to write, there’s an app for that. If you want to code, there’s an app for that. If you want to interact with goods and services, there are applications for you.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But we can’t build everything ourselves. We’re not going to have a music streaming service, or replicate Coursera’s catalog of educational materials. We’re not going to get into the business that Expedia and Booking.com are in. And for that reason, it makes sense to partner.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There’s also a whole generation of apps that people are going to build that wouldn’t have been possible previously. The Ubers of the world only exist because of the mobile platform, and I’m really excited about what those might be for ChatGPT.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We also want to give developers, who have been with us since the beginning, access to ChatGPT’s 800 million weekly users. If they’re able to enhance ChatGPT and build real businesses on top of that, it creates more winners in the ecosystem.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Where do you draw inspiration from when building ChatGPT?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;You can’t go to one spot. I often tell job candidates they need to have first principles thinking, and if they’re gonna try to run a playbook they saw at Meta or Google, you’re actually gonna run out of competitors to copy. When it comes to [ChatGPT] or Sora, there’s just zero precedent. So you kind of have to get your analogies from different places.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I think browsers are really interesting because, in some ways, they’ve become the operating system in the last 10 years. How many of us actually use desktop apps? You might use Excel or PowerPoint, but most of what we do actually happens in the browser via application-like things.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I also spent some time looking at the early ads for the [Apple] PowerBook. It’s kind of like ChatGPT where it was this appliance that nobody quite knew everything you could do with it. The ads were literally like “It’s a calculator, it’s an alarm clock.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So there isn’t a single thing you can look at, but it behooves us to learn from history. If you just look at the last 10 years, there might not be the perfect analogous thing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;You mentioned browsers and devices there. How are you thinking about expanding ChatGPT into those form factors?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is the kind of place where you dream big. One category we have covered is productivity, which is effectively ChatGPT. But there are so many other product categories to be built, and they’re all going to change with AI. Entertainment is one, which is why I’m excited about Sora. Social media is another one. Obviously, hardware and access points to the internet are interesting too.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;You should really think about what we’re building as a family of products and applications that are tied together by your account, personalization, and identity layer. I’m really excited that we’re not boxing ourselves in. Even if we were just the ChatGPT company, there would be infinite things to build, but our ambition on what we can do for people just goes way beyond that.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;I’m interested in hearing how you think the consumer business of OpenAI fits into the nonprofit mission. I’ve heard some people say the consumer business funds the mission. How do you see it?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The OpenAI I joined was a research lab that might ship a demo or two. In fact, my job description at the time was framed to me as “helping commercialize OpenAI technology” — very open ended. At that time, the product existed to bring the research to life so that people actually get it. I think that was true and still is true, as you can see with Sora. The best way to start a grounded discourse on the profoundness of a technology is to ship something.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Then we moved from that framing to, okay, maybe the product is more than that. Maybe the product is actually the way we fund the mission. It became evident at some point, even before I got to OpenAI, that this is all going to be very expensive. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But after ChatGPT, we started talking about it a bit differently. Our mission is to ensure that AGI benefits all of humanity, and reaches people. If you combine that with the insight that AGI is probably not this single moment in time, but rather a gradual thing, you have to think of product as the delivery vehicle of the mission. It’s the way you actually benefit people in practice.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If you look at what these 800 million people are doing every week, ChatGPT is helping them achieve their goals. I don’t know if you saw the guy in the keynote who taught himself to code at 89. That’s insane to me. I talk to ChatGPT users who help their autistic kids by modeling social interactions. I talk to people who are entirely self-taught in a language based on what they do with ChatGPT. Like, that is the mission.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I don’t think it’s fair to talk about the consumer business as a funding vehicle. Rather, it’s the expression. That is one way in which OpenAI has evolved, to me at least, since I’ve joined.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Let’s dive deeper into the apps that were announced today. OpenAI has said that third parties can only take the “minimum amount of data” necessary to run an app in ChatGPT. How are you thinking about user privacy?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;From day one, we’re going to ask developers to disclose to users what information they’re requesting. We’re also only going to let [apps] go live if they are reasonable in the data that they request. We published our developer guidelines [at launch] so people won’t be surprised when we reject their app because it doesn’t comply with our stance on privacy.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Over the next month, we want to build ways for users to give fine-grained access to developers. I think Apple has done a phenomenal job with this, where you can share data just this time, or all the time, etc.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To do that well, we might need some concept of a partitioned memory in ChatGPT, which we’re still thinking through. But we’re really excited about the idea because you might want to keep certain conversations, like health, separate from others, such as music. Users may want to share one, but not the other, with an app. So we’re going to have a lot more to share soon, because it’s actually a combined research and engineering challenge to do this well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The thing that’s uncompromisable for us is transparency. We want users, at all points, to understand what data might be going to a third party, but the controls will come over time as we build them out.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;DoorDash and Instacart are two companies that will have apps in ChatGPT soon enough. If I want to order some snacks, how will ChatGPT know which one to go to?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is the classic question. The best way to start is you show them both. If you’ve used one of them before, we’ll prioritize that one. If you’ve used both, we’ll ask which one you prefer. We could get more sophisticated over time. You could imagine one of these apps being much higher quality than another. Maybe there would be reason to prioritize one over the other. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We have multiple partners in the same product categories. I think the most graceful and respectful way to handle that is to serve both apps.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Are you thinking about letting companies pay for their apps to have preferential spot placement in ChatGPT?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is one of the things we’re hoping to do some discovery on with developers. There’s this trade-off. You could try to figure it all out in advance, and roll it out with the announcement, but that probably means you didn’t talk to a lot of people. Or you could delay it, which means everyone’s asking questions and doesn’t know exactly what’s going to happen, but it gives us the ability to actually engage.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;We chose the latter just because we know that building this ecosystem is going to be a long game. It’s not going to happen on day one, and therefore it’s better to be thoughtful on what sort of distribution mechanisms are and aren’t fair game.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the end of the day, we want a great user experience. So if that would lead to apps [surfacing] that are irrelevant to the user, I don’t think we’d like it. If this was a lever that helped us prioritize apps that are really serious because they’re clearly trying to invest in exposure, it could be a good thing. We have no point of view as of today. It’s certainly something that’s come up with different partners.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/08/openais-nick-turley-on-transforming-chatgpt-into-an-operating-system/</guid><pubDate>Wed, 08 Oct 2025 20:00:00 +0000</pubDate></item><item><title>To scale agentic AI, Notion tore down its tech stack and started fresh (AI | VentureBeat)</title><link>https://venturebeat.com/ai/to-scale-agentic-ai-notion-tore-down-its-tech-stack-and-started-fresh</link><description>[unable to retrieve full-text content]&lt;p&gt;Many organizations would be hesitant to overhaul their tech stack and start from scratch. 

Not &lt;a href="https://www.notion.com/"&gt;Notion&lt;/a&gt;. 

For the 3.0 version of its productivity software (released in September), the company didn’t hesitate to rebuild from the ground up; they recognized that it was necessary, in fact, to support agentic AI at enterprise scale.

Whereas traditional AI-powered workflows involve explicit, step-by-step instructions based on few-shot learning, AI agents powered by advanced reasoning models are thoughtful about tool definition, can identify and comprehend what tools they have at their disposal and plan next steps. 

“Rather than trying to retrofit into what we were building, we wanted to play to the strengths of reasoning models,” Sarah Sachs, Notion’s head of AI modeling, told VentureBeat. “We&amp;#x27;ve rebuilt a new architecture because workflows are different from agents.”&lt;/p&gt;&lt;h2&gt;Re-orchestrating so models can work autonomously&lt;/h2&gt;&lt;p&gt;&lt;a href="https://venturebeat.com/ai/notion-bets-big-on-integrated-llms-adds-gpt-4-1-and-claude-3-7-to-platform"&gt;Notion&lt;/a&gt; has been adopted by 94% of Forbes AI 50 companies, has 100 million total users and counts among its customers OpenAI, Cursor, Figma, Ramp and Vercel. 

In a rapidly evolving AI landscape, the company identified the need to move beyond simpler, task-based workflows to goal-oriented reasoning systems that allow agents to autonomously select, orchestrate, and execute tools across connected environments. &lt;/p&gt;&lt;p&gt;Very quickly, &lt;a href="https://venturebeat.com/ai/teaching-the-model-designing-llm-feedback-loops-that-get-smarter-over-time"&gt;reasoning models&lt;/a&gt; have become “far better” at learning to use tools and follow chain-of-thought (CoT) instructions, Sachs noted. This allows them to be “far more independent” and make multiple decisions within one agentic workflow. “We rebuilt our AI system to play to that,&amp;quot; she said. 

From an engineering perspective, this meant replacing rigid prompt-based flows with a unified orchestration model, Sachs explained. This core model is supported by modular sub-agents that search Notion and the web, query and add to databases and edit content. 

Each agent uses tools contextually; for instance, they can decide whether to search Notion itself, or another platform like Slack. The model will perform successive searches until the relevant information is found. It can then, for instance, convert notes into proposals, create follow-up messages, track tasks, and spot and make updates in knowledge bases. 

In Notion 2.0, the team focused on having AI perform specific tasks, which required them to “think exhaustively” about how to prompt the model, Sachs noted. However, with version 3.0, users can assign tasks to agents, and agents can actually take action and perform multiple tasks concurrently.  

“We reorchestrated it to be self-selecting on the tools, rather than few-shotting, which is explicitly prompting how to go through all these different scenarios,” Sachs explained. The aim is to ensure everything interfaces with AI and that “anything you can do, your Notion agent can do.”&lt;/p&gt;&lt;h2&gt;Bifurcating to isolate hallucinations&lt;/h2&gt;&lt;p&gt;Notion’s philosophy of “better, faster, cheaper,” drives a continuous iteration cycle that balances latency and accuracy through fine-tuned vector embeddings and elastic search optimization. Sachs’ team employs a rigorous evaluation framework that combines deterministic tests, vernacular optimization, human-annotated data and LLMs-as-a-judge, with model-based scoring identifying discrepancies and inaccuracies. 

“By bifurcating the evaluation, we&amp;#x27;re able to identify where the problems come from, and that helps us isolate unnecessary hallucinations,” Sachs explained. Further, making the architecture itself simpler means it’s easier to make changes as models and techniques evolve. 

“We optimize latency and parallel thinking as much as possible,” which leads to “way better accuracy,” Sachs noted. Models are grounded in data from the web and the Notion connected workspace. 

Ultimately, Sachs reported, the investment in rebuilding its architecture has already provided Notion returns in terms of capability and faster rate of change. 

She added, “We are fully open to rebuilding it again, when the next breakthrough happens, if we have to.”&lt;/p&gt;&lt;h2&gt;Understanding contextual latency&lt;/h2&gt;&lt;p&gt;When building and fine-tuning models, it’s important to understand that latency is subjective: AI must provide the most relevant information, not necessarily the most, at the cost of speed. 

“You&amp;#x27;d be surprised at the different ways customers are willing to wait for things and not wait for things,” Sachs said. It makes for an interesting experiment: How slow can you go before people abandon the model?

With pure navigational search, for instance, users may not be as patient; they want answers near-immediately. “If you ask, ‘What&amp;#x27;s two plus two,’ you don&amp;#x27;t want to wait for your agent to be searching everywhere in Slack and JIRA,” Sachs pointed out. 

But the longer the time it&amp;#x27;s given, the more exhaustive a reasoning agent can be. For instance, Notion can perform &lt;a href="https://venturebeat.com/ai/the-anti-chatgpt-thomson-reuters-multi-agent-system-slashes-20-hour-tasks-to"&gt;20 minutes of autonomous work&lt;/a&gt; across hundreds of websites, files and other materials. In these instances, users are more willing to wait, Sachs explained; they allow the model to execute in the background while they attend to other tasks. 

“It&amp;#x27;s a product question,” said Sachs. “How do we set user expectations from the UI? How do we ascertain user expectations on latency?”&lt;/p&gt;&lt;h2&gt;Notion is its biggest user&lt;/h2&gt;&lt;p&gt;Notion understands the importance of using its own product — in fact, its employees are among its biggest power users. 

Sachs explained that teams have active sandboxes that generate training and evaluation data, as well as a “really active” thumbs-up-thumbs-down user feedback loop. Users aren’t shy about saying what they think should be improved or features they’d like to see. 

Sachs emphasized that when a user thumbs down an interaction, they are explicitly giving permission to a human annotator to analyze that interaction in a way that de-anonymizes them as much as possible. 

“We are using our own tool as a company all day, every day, and so we get really fast feedback loops,” said Sachs. “We’re really dogfooding our own product.” 

That said, it’s their own product they’re building, Sachs noted, so they understand that they may have goggles on when it comes to quality and functionality. To balance this out, Notion has trusted &amp;quot;very AI-savvy&amp;quot; design partners who are granted early access to new capabilities and provide important feedback. 

Sachs emphasized that this is just as important as internal prototyping. 

“We&amp;#x27;re all about experimenting in the open, I think you get much richer feedback,” said Sachs. “Because at the end of the day, if we just look at how Notion uses Notion, we&amp;#x27;re not really giving the best experience to our customers.” 

Just as importantly, continuous internal testing allows teams to evaluate progressions and make sure models aren&amp;#x27;t regressing (when accuracy and performance degrades over time). &amp;quot;Everything you&amp;#x27;re doing stays faithful,&amp;quot; Sachs explained. &amp;quot;You know that your latency is within bounds.&amp;quot; &lt;/p&gt;&lt;p&gt;Many companies make the mistake of focusing too intensely on retroactively-focused evans; this makes it difficult for them to understand how or where they&amp;#x27;re improving, Sachs pointed out. Notion considers evals as a &amp;quot;litmus test&amp;quot; of development and forward-looking progression and evals of observability and regression proofing. 

“I think a big mistake a lot of companies make is conflating the two,” said Sachs. “We use them for both purposes; we think about them really differently.”&lt;/p&gt;&lt;h2&gt;Takeaways from Notion&amp;#x27;s journey&lt;/h2&gt;&lt;p&gt;For enterprises, Notion can serve as a blueprint for how to responsibly and dynamically operationalize agentic AI in a connected, permissioned enterprise workspace. 

Sach’s takeaways for other tech leaders: &lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Don’t be afraid to rebuild when foundational capabilities change; Notion fully re-engineered its architecture to align with reasoning-based models.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Treat latency as contextual: Optimize per use case, rather than universally. &lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Ground all outputs in trustworthy, curated enterprise data to ensure accuracy and trust. 

She advised: “Be willing to make the hard decisions. Be willing to sit at the top of the frontier, so to speak, on what you&amp;#x27;re developing to build the best product you can for your customers.” &lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;Many organizations would be hesitant to overhaul their tech stack and start from scratch. 

Not &lt;a href="https://www.notion.com/"&gt;Notion&lt;/a&gt;. 

For the 3.0 version of its productivity software (released in September), the company didn’t hesitate to rebuild from the ground up; they recognized that it was necessary, in fact, to support agentic AI at enterprise scale.

Whereas traditional AI-powered workflows involve explicit, step-by-step instructions based on few-shot learning, AI agents powered by advanced reasoning models are thoughtful about tool definition, can identify and comprehend what tools they have at their disposal and plan next steps. 

“Rather than trying to retrofit into what we were building, we wanted to play to the strengths of reasoning models,” Sarah Sachs, Notion’s head of AI modeling, told VentureBeat. “We&amp;#x27;ve rebuilt a new architecture because workflows are different from agents.”&lt;/p&gt;&lt;h2&gt;Re-orchestrating so models can work autonomously&lt;/h2&gt;&lt;p&gt;&lt;a href="https://venturebeat.com/ai/notion-bets-big-on-integrated-llms-adds-gpt-4-1-and-claude-3-7-to-platform"&gt;Notion&lt;/a&gt; has been adopted by 94% of Forbes AI 50 companies, has 100 million total users and counts among its customers OpenAI, Cursor, Figma, Ramp and Vercel. 

In a rapidly evolving AI landscape, the company identified the need to move beyond simpler, task-based workflows to goal-oriented reasoning systems that allow agents to autonomously select, orchestrate, and execute tools across connected environments. &lt;/p&gt;&lt;p&gt;Very quickly, &lt;a href="https://venturebeat.com/ai/teaching-the-model-designing-llm-feedback-loops-that-get-smarter-over-time"&gt;reasoning models&lt;/a&gt; have become “far better” at learning to use tools and follow chain-of-thought (CoT) instructions, Sachs noted. This allows them to be “far more independent” and make multiple decisions within one agentic workflow. “We rebuilt our AI system to play to that,&amp;quot; she said. 

From an engineering perspective, this meant replacing rigid prompt-based flows with a unified orchestration model, Sachs explained. This core model is supported by modular sub-agents that search Notion and the web, query and add to databases and edit content. 

Each agent uses tools contextually; for instance, they can decide whether to search Notion itself, or another platform like Slack. The model will perform successive searches until the relevant information is found. It can then, for instance, convert notes into proposals, create follow-up messages, track tasks, and spot and make updates in knowledge bases. 

In Notion 2.0, the team focused on having AI perform specific tasks, which required them to “think exhaustively” about how to prompt the model, Sachs noted. However, with version 3.0, users can assign tasks to agents, and agents can actually take action and perform multiple tasks concurrently.  

“We reorchestrated it to be self-selecting on the tools, rather than few-shotting, which is explicitly prompting how to go through all these different scenarios,” Sachs explained. The aim is to ensure everything interfaces with AI and that “anything you can do, your Notion agent can do.”&lt;/p&gt;&lt;h2&gt;Bifurcating to isolate hallucinations&lt;/h2&gt;&lt;p&gt;Notion’s philosophy of “better, faster, cheaper,” drives a continuous iteration cycle that balances latency and accuracy through fine-tuned vector embeddings and elastic search optimization. Sachs’ team employs a rigorous evaluation framework that combines deterministic tests, vernacular optimization, human-annotated data and LLMs-as-a-judge, with model-based scoring identifying discrepancies and inaccuracies. 

“By bifurcating the evaluation, we&amp;#x27;re able to identify where the problems come from, and that helps us isolate unnecessary hallucinations,” Sachs explained. Further, making the architecture itself simpler means it’s easier to make changes as models and techniques evolve. 

“We optimize latency and parallel thinking as much as possible,” which leads to “way better accuracy,” Sachs noted. Models are grounded in data from the web and the Notion connected workspace. 

Ultimately, Sachs reported, the investment in rebuilding its architecture has already provided Notion returns in terms of capability and faster rate of change. 

She added, “We are fully open to rebuilding it again, when the next breakthrough happens, if we have to.”&lt;/p&gt;&lt;h2&gt;Understanding contextual latency&lt;/h2&gt;&lt;p&gt;When building and fine-tuning models, it’s important to understand that latency is subjective: AI must provide the most relevant information, not necessarily the most, at the cost of speed. 

“You&amp;#x27;d be surprised at the different ways customers are willing to wait for things and not wait for things,” Sachs said. It makes for an interesting experiment: How slow can you go before people abandon the model?

With pure navigational search, for instance, users may not be as patient; they want answers near-immediately. “If you ask, ‘What&amp;#x27;s two plus two,’ you don&amp;#x27;t want to wait for your agent to be searching everywhere in Slack and JIRA,” Sachs pointed out. 

But the longer the time it&amp;#x27;s given, the more exhaustive a reasoning agent can be. For instance, Notion can perform &lt;a href="https://venturebeat.com/ai/the-anti-chatgpt-thomson-reuters-multi-agent-system-slashes-20-hour-tasks-to"&gt;20 minutes of autonomous work&lt;/a&gt; across hundreds of websites, files and other materials. In these instances, users are more willing to wait, Sachs explained; they allow the model to execute in the background while they attend to other tasks. 

“It&amp;#x27;s a product question,” said Sachs. “How do we set user expectations from the UI? How do we ascertain user expectations on latency?”&lt;/p&gt;&lt;h2&gt;Notion is its biggest user&lt;/h2&gt;&lt;p&gt;Notion understands the importance of using its own product — in fact, its employees are among its biggest power users. 

Sachs explained that teams have active sandboxes that generate training and evaluation data, as well as a “really active” thumbs-up-thumbs-down user feedback loop. Users aren’t shy about saying what they think should be improved or features they’d like to see. 

Sachs emphasized that when a user thumbs down an interaction, they are explicitly giving permission to a human annotator to analyze that interaction in a way that de-anonymizes them as much as possible. 

“We are using our own tool as a company all day, every day, and so we get really fast feedback loops,” said Sachs. “We’re really dogfooding our own product.” 

That said, it’s their own product they’re building, Sachs noted, so they understand that they may have goggles on when it comes to quality and functionality. To balance this out, Notion has trusted &amp;quot;very AI-savvy&amp;quot; design partners who are granted early access to new capabilities and provide important feedback. 

Sachs emphasized that this is just as important as internal prototyping. 

“We&amp;#x27;re all about experimenting in the open, I think you get much richer feedback,” said Sachs. “Because at the end of the day, if we just look at how Notion uses Notion, we&amp;#x27;re not really giving the best experience to our customers.” 

Just as importantly, continuous internal testing allows teams to evaluate progressions and make sure models aren&amp;#x27;t regressing (when accuracy and performance degrades over time). &amp;quot;Everything you&amp;#x27;re doing stays faithful,&amp;quot; Sachs explained. &amp;quot;You know that your latency is within bounds.&amp;quot; &lt;/p&gt;&lt;p&gt;Many companies make the mistake of focusing too intensely on retroactively-focused evans; this makes it difficult for them to understand how or where they&amp;#x27;re improving, Sachs pointed out. Notion considers evals as a &amp;quot;litmus test&amp;quot; of development and forward-looking progression and evals of observability and regression proofing. 

“I think a big mistake a lot of companies make is conflating the two,” said Sachs. “We use them for both purposes; we think about them really differently.”&lt;/p&gt;&lt;h2&gt;Takeaways from Notion&amp;#x27;s journey&lt;/h2&gt;&lt;p&gt;For enterprises, Notion can serve as a blueprint for how to responsibly and dynamically operationalize agentic AI in a connected, permissioned enterprise workspace. 

Sach’s takeaways for other tech leaders: &lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Don’t be afraid to rebuild when foundational capabilities change; Notion fully re-engineered its architecture to align with reasoning-based models.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Treat latency as contextual: Optimize per use case, rather than universally. &lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Ground all outputs in trustworthy, curated enterprise data to ensure accuracy and trust. 

She advised: “Be willing to make the hard decisions. Be willing to sit at the top of the frontier, so to speak, on what you&amp;#x27;re developing to build the best product you can for your customers.” &lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/to-scale-agentic-ai-notion-tore-down-its-tech-stack-and-started-fresh</guid><pubDate>Wed, 08 Oct 2025 21:08:00 +0000</pubDate></item><item><title>Bank of England warns AI stock bubble rivals 2000 dotcom peak (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/10/bank-of-england-warns-ai-stock-bubble-rivals-2000-dotcom-peak/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Central bank says market concentration hasn't been this extreme in 50 years.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The Bank of England building in London." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/bank_of_england-640x360.jpg" width="640" /&gt;
                  &lt;img alt="The Bank of England building in London." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/bank_of_england-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The Bank of England building in London.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Scott E Barbour via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;AI bubble talk is in the air, and among the chorus of voices warning of an AI-fueled market bubble (which includes OpenAI CEO Sam Altman and Amazon's Jeff Bezos) is the Bank of England, which warned on Wednesday that global financial markets could face a sharp correction if investor sentiment turns negative on AI.&lt;/p&gt;
&lt;p&gt;The UK central bank said US stock valuations resemble those seen near the peak of the dotcom bubble on some measures, with AI-focused companies making up an unprecedented portion of market value.&lt;/p&gt;
&lt;p&gt;In its quarterly report derived from a meeting of its Financial Policy Committee that took place last week, BoE wrote that "the risk of a sharp market correction has increased." Reuters notes that it's the BoE's strongest warning to date about potential AI-driven market declines. The committee, chaired by Governor Andrew Bailey, said spillover risks to Britain's financial system from such a shock were "material."&lt;/p&gt;
&lt;p&gt;The warning comes as the S&amp;amp;P 500 hit a record high on Tuesday, up 14 percent year to date. The BoE noted in its report that 30 percent of the S&amp;amp;P 500's valuation comes from just five companies at the top, which is the most concentrated the index has been in 50 years. These companies include chipmaker Nvidia, Microsoft, Apple, Amazon, and Facebook parent Meta, all of which have invested substantially in AI development.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Share valuations based on past earnings have also reached their highest levels since the dotcom bubble 25 years ago, though the BoE noted they appear less extreme when based on investors' expectations for future profits. "This, when combined with increasing concentration within market indices, leaves equity markets particularly exposed should expectations around the impact of AI become less optimistic," the central bank said.&lt;/p&gt;
&lt;h2&gt;Toil and trouble?&lt;/h2&gt;
&lt;p&gt;The dotcom bubble offers a potentially instructive parallel to our current era. In the late 1990s, investors poured money into Internet companies based on the promise of a transformed economy, seemingly ignoring whether individual businesses had viable paths to profitability. Between 1995 and March 2000, the Nasdaq index rose 600 percent. When sentiment shifted, the correction was severe: the Nasdaq fell 78 percent from its peak, reaching a low point in October 2002.&lt;/p&gt;
&lt;p&gt;Whether we'll see the same thing or worse if an AI bubble pops is mere speculation at this point. But similarly to the early 2000s, the question about today's market isn't necessarily about the utility of AI tools themselves (the Internet was useful, after all, despite the bubble), but whether the amount of money being poured into the companies that sell them is out of proportion with the potential profits those improvements might bring.&lt;/p&gt;
&lt;p&gt;We don't have a crystal ball to determine when such a bubble might pop, or even if it is guaranteed to do so, but we'll likely continue to see more warning signs ahead if AI-related deals continue to grow larger and larger over time.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Central bank says market concentration hasn't been this extreme in 50 years.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The Bank of England building in London." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/bank_of_england-640x360.jpg" width="640" /&gt;
                  &lt;img alt="The Bank of England building in London." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/bank_of_england-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The Bank of England building in London.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Scott E Barbour via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;AI bubble talk is in the air, and among the chorus of voices warning of an AI-fueled market bubble (which includes OpenAI CEO Sam Altman and Amazon's Jeff Bezos) is the Bank of England, which warned on Wednesday that global financial markets could face a sharp correction if investor sentiment turns negative on AI.&lt;/p&gt;
&lt;p&gt;The UK central bank said US stock valuations resemble those seen near the peak of the dotcom bubble on some measures, with AI-focused companies making up an unprecedented portion of market value.&lt;/p&gt;
&lt;p&gt;In its quarterly report derived from a meeting of its Financial Policy Committee that took place last week, BoE wrote that "the risk of a sharp market correction has increased." Reuters notes that it's the BoE's strongest warning to date about potential AI-driven market declines. The committee, chaired by Governor Andrew Bailey, said spillover risks to Britain's financial system from such a shock were "material."&lt;/p&gt;
&lt;p&gt;The warning comes as the S&amp;amp;P 500 hit a record high on Tuesday, up 14 percent year to date. The BoE noted in its report that 30 percent of the S&amp;amp;P 500's valuation comes from just five companies at the top, which is the most concentrated the index has been in 50 years. These companies include chipmaker Nvidia, Microsoft, Apple, Amazon, and Facebook parent Meta, all of which have invested substantially in AI development.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Share valuations based on past earnings have also reached their highest levels since the dotcom bubble 25 years ago, though the BoE noted they appear less extreme when based on investors' expectations for future profits. "This, when combined with increasing concentration within market indices, leaves equity markets particularly exposed should expectations around the impact of AI become less optimistic," the central bank said.&lt;/p&gt;
&lt;h2&gt;Toil and trouble?&lt;/h2&gt;
&lt;p&gt;The dotcom bubble offers a potentially instructive parallel to our current era. In the late 1990s, investors poured money into Internet companies based on the promise of a transformed economy, seemingly ignoring whether individual businesses had viable paths to profitability. Between 1995 and March 2000, the Nasdaq index rose 600 percent. When sentiment shifted, the correction was severe: the Nasdaq fell 78 percent from its peak, reaching a low point in October 2002.&lt;/p&gt;
&lt;p&gt;Whether we'll see the same thing or worse if an AI bubble pops is mere speculation at this point. But similarly to the early 2000s, the question about today's market isn't necessarily about the utility of AI tools themselves (the Internet was useful, after all, despite the bubble), but whether the amount of money being poured into the companies that sell them is out of proportion with the potential profits those improvements might bring.&lt;/p&gt;
&lt;p&gt;We don't have a crystal ball to determine when such a bubble might pop, or even if it is guaranteed to do so, but we'll likely continue to see more warning signs ahead if AI-related deals continue to grow larger and larger over time.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/10/bank-of-england-warns-ai-stock-bubble-rivals-2000-dotcom-peak/</guid><pubDate>Wed, 08 Oct 2025 21:18:30 +0000</pubDate></item><item><title>Even after Stargate, Oracle, Nvidia, and AMD, OpenAI has more big deals coming soon, Sam Altman says (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/08/even-after-stargate-oracle-nvidia-and-amd-openai-has-more-big-deals-coming-soon-sam-altman-says/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/11/Sam-Altman-OpenAI.jpg?resize=1200,680" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;At nearly the same moment as Nvidia CEO Jensen Huang was expressing surprise over OpenAI’s multibillion-dollar deal with competitor AMD — shortly after his company agreed to invest up to $100 billion into the AI model maker — Sam Altman was saying that more such deals are in the works.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Huang appeared on CNBC’s Squawk Box on Wednesday. When asked if he knew about the AMD deal before it was announced, he answered, “Not really.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As TechCrunch previously reported, OpenAI’s deal with AMD is unusual. AMD has agreed to grant OpenAI large tranches of AMD stock — up to 10% of the company over a period of years contingent on factors like increases in stock price. In exchange, OpenAI will use and help develop the chipmaker’s next-generation AI GPUs chips. This makes OpenAI a shareholder in AMD. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia’s deal is the reverse. Nvidia has invested in the AI model-making startup, making it a shareholder in OpenAI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While OpenAI has been using Nvidia gear for years through cloud providers like Microsoft Azure, Oracle OCI, and CoreWeave, “This is the first time we’re going to sell directly to them,” Huang explained. He added that his company would still continue to supply gear to the cloud makers, too.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These direct sales, which include AI gear beyond GPUs like systems and networking, are intended to “prepare” OpenAI for the day when it is its own “self-hosted hyperscaler,” Huang said. In other words, when it’s using its own data centers.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Huang admits that OpenAI doesn’t “have the money yet” to pay for all of this gear. He estimated that each gigawatt of AI data center will cost OpenAI “$50 to $60 billion,” to cover everything from the land and power to the servers and equipment.&amp;nbsp; &amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;So far, in 2025, OpenAI has commissioned 10 gigawatts’ worth of U.S. facilities through its $500 billion Stargate deal with partners Oracle and SoftBank. (Plus, it penned a $300 billion cloud deal with Oracle.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Its partnership with Nvidia was for at least 10 gigawatts of AI data centers. Its partnership with AMD was for 6 gigawatts. Plus its “Stargate UK” partnership involves expanding data centers in the U.K., and it has other European commitments. By some estimates, OpenAI has this year inked $1 trillion worth of such deals. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Similar to the AMD deal, Nvidia’s deal has been criticized for being “circular,” Bloomberg reported. The critics say Nvidia is essentially underwriting OpenAI’s purchases, getting the AI startup’s stock for its efforts.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-altman-to-the-world-expect-more"&gt;Altman to the world: Expect more&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;As Huang was dissecting OpenAI’s infrastructure needs on CNBC, OpenAI CEO Sam Altman’s interview with Andreessen Horowitz’s a16z Podcast dropped.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;During the podcast, a16z co-founder Ben Horowitz told Altman that he’s “very impressed by deal structure improvement,” referring to these most recent deals. Andreessen Horowitz is an OpenAI investor, so it would be shocking if he wasn’t impressed. OpenAI has found a way to potentially obtain billions of dollars of equipment on someone else’s dime. Repeatedly.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When asked about these recent deals, Altman said, “You should expect much more from us in the coming months.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman sees OpenAI’s future models and upcoming other products as so much more capable, thereby fueling so much more demand, that “we have decided that it is time to go make a very aggressive infrastructure bet,” he explained. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The problem is that OpenAI’s revenue today is currently nowhere near a $1 trillion, though it is, by all accounts, growing rapidly, reportedly hitting $4.5 billion in the first half of 2025.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Yet Altman obviously believes that eventually all of this investment will pay for itself. “I’ve never been more confident in the research road map in front of us and also the economic value that will come from using those [future] models.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But, he said, OpenAI can’t get to all of that economic lushness on its own.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“To make the bet at this scale, we kind of need the whole industry, or big chunk of the industry, to support it. And this is from the level of electrons to model distribution and all the stuff in between, which is a lot. So we’re going to partner with a lot of people,” Altman said, with more deals expected in the coming months.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So stand by, tech industry. OpenAI is still wheeling and dealing.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/11/Sam-Altman-OpenAI.jpg?resize=1200,680" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;At nearly the same moment as Nvidia CEO Jensen Huang was expressing surprise over OpenAI’s multibillion-dollar deal with competitor AMD — shortly after his company agreed to invest up to $100 billion into the AI model maker — Sam Altman was saying that more such deals are in the works.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Huang appeared on CNBC’s Squawk Box on Wednesday. When asked if he knew about the AMD deal before it was announced, he answered, “Not really.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As TechCrunch previously reported, OpenAI’s deal with AMD is unusual. AMD has agreed to grant OpenAI large tranches of AMD stock — up to 10% of the company over a period of years contingent on factors like increases in stock price. In exchange, OpenAI will use and help develop the chipmaker’s next-generation AI GPUs chips. This makes OpenAI a shareholder in AMD. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia’s deal is the reverse. Nvidia has invested in the AI model-making startup, making it a shareholder in OpenAI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While OpenAI has been using Nvidia gear for years through cloud providers like Microsoft Azure, Oracle OCI, and CoreWeave, “This is the first time we’re going to sell directly to them,” Huang explained. He added that his company would still continue to supply gear to the cloud makers, too.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These direct sales, which include AI gear beyond GPUs like systems and networking, are intended to “prepare” OpenAI for the day when it is its own “self-hosted hyperscaler,” Huang said. In other words, when it’s using its own data centers.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Huang admits that OpenAI doesn’t “have the money yet” to pay for all of this gear. He estimated that each gigawatt of AI data center will cost OpenAI “$50 to $60 billion,” to cover everything from the land and power to the servers and equipment.&amp;nbsp; &amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;So far, in 2025, OpenAI has commissioned 10 gigawatts’ worth of U.S. facilities through its $500 billion Stargate deal with partners Oracle and SoftBank. (Plus, it penned a $300 billion cloud deal with Oracle.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Its partnership with Nvidia was for at least 10 gigawatts of AI data centers. Its partnership with AMD was for 6 gigawatts. Plus its “Stargate UK” partnership involves expanding data centers in the U.K., and it has other European commitments. By some estimates, OpenAI has this year inked $1 trillion worth of such deals. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Similar to the AMD deal, Nvidia’s deal has been criticized for being “circular,” Bloomberg reported. The critics say Nvidia is essentially underwriting OpenAI’s purchases, getting the AI startup’s stock for its efforts.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-altman-to-the-world-expect-more"&gt;Altman to the world: Expect more&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;As Huang was dissecting OpenAI’s infrastructure needs on CNBC, OpenAI CEO Sam Altman’s interview with Andreessen Horowitz’s a16z Podcast dropped.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;During the podcast, a16z co-founder Ben Horowitz told Altman that he’s “very impressed by deal structure improvement,” referring to these most recent deals. Andreessen Horowitz is an OpenAI investor, so it would be shocking if he wasn’t impressed. OpenAI has found a way to potentially obtain billions of dollars of equipment on someone else’s dime. Repeatedly.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When asked about these recent deals, Altman said, “You should expect much more from us in the coming months.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman sees OpenAI’s future models and upcoming other products as so much more capable, thereby fueling so much more demand, that “we have decided that it is time to go make a very aggressive infrastructure bet,” he explained. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The problem is that OpenAI’s revenue today is currently nowhere near a $1 trillion, though it is, by all accounts, growing rapidly, reportedly hitting $4.5 billion in the first half of 2025.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Yet Altman obviously believes that eventually all of this investment will pay for itself. “I’ve never been more confident in the research road map in front of us and also the economic value that will come from using those [future] models.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But, he said, OpenAI can’t get to all of that economic lushness on its own.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“To make the bet at this scale, we kind of need the whole industry, or big chunk of the industry, to support it. And this is from the level of electrons to model distribution and all the stuff in between, which is a lot. So we’re going to partner with a lot of people,” Altman said, with more deals expected in the coming months.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So stand by, tech industry. OpenAI is still wheeling and dealing.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/08/even-after-stargate-oracle-nvidia-and-amd-openai-has-more-big-deals-coming-soon-sam-altman-says/</guid><pubDate>Wed, 08 Oct 2025 23:00:06 +0000</pubDate></item><item><title>New memory framework builds AI agents that can handle the real world's unpredictability (AI | VentureBeat)</title><link>https://venturebeat.com/ai/new-memory-framework-builds-ai-agents-that-can-handle-the-real-worlds</link><description>[unable to retrieve full-text content]&lt;p&gt;Researchers at the &lt;a href="https://illinois.edu/"&gt;&lt;u&gt;University of Illinois Urbana-Champaign&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://research.google/teams/cloud-ai-research/"&gt;&lt;u&gt;Google Cloud AI Research&lt;/u&gt;&lt;/a&gt; have developed a framework that enables large language model (LLM) agents to organize their experiences into a memory bank, helping them get better at complex tasks over time.&lt;/p&gt;&lt;p&gt;The framework, called &lt;a href="https://arxiv.org/abs/2509.25140"&gt;&lt;u&gt;ReasoningBank&lt;/u&gt;&lt;/a&gt;, distills “generalizable reasoning strategies” from an agent’s successful and failed attempts to solve problems. The agent then uses this memory during inference to avoid repeating past mistakes and make better decisions as it faces new problems. The researchers show that when combined with &lt;a href="https://venturebeat.com/ai/how-test-time-scaling-unlocks-hidden-reasoning-abilities-in-small-language-models-and-allows-them-to-outperform-llms"&gt;&lt;u&gt;test-time scaling techniques&lt;/u&gt;&lt;/a&gt;, where an agent makes multiple attempts at a problem, ReasoningBank significantly improves the performance and efficiency of LLM agents.&lt;/p&gt;&lt;p&gt;Their findings show that ReasoningBank consistently outperforms classic memory mechanisms across web browsing and software engineering benchmarks, offering a practical path toward building more adaptive and reliable AI agents for enterprise applications.&lt;/p&gt;&lt;h2&gt;The challenge of LLM agent memory&lt;/h2&gt;&lt;p&gt;As LLM agents are deployed in applications that run for long periods, they encounter a continuous stream of tasks. One of the key limitations of current LLM agents is their failure to learn from this accumulated experience. By approaching each task in isolation, they inevitably repeat past mistakes, discard valuable insights from related problems, and fail to develop skills that would make them more capable over time.&lt;/p&gt;&lt;p&gt;The solution to this limitation is to give agents some kind of memory. Previous efforts to give agents memory have focused on storing past interactions for reuse by organizing information in various forms from plain text to structured graphs. However, these approaches often fall short. Many use raw interaction logs or only store successful task examples. This means they can&amp;#x27;t distill higher-level, transferable reasoning patterns and, crucially, they don’t extract and use the valuable information from the agent’s failures. As the researchers note in their paper, “existing memory designs often remain limited to passive record-keeping rather than providing actionable, generalizable guidance for future decisions.”&lt;/p&gt;&lt;h2&gt;How ReasoningBank works&lt;/h2&gt;&lt;p&gt;ReasoningBank is a memory framework designed to overcome these limitations. Its central idea is to distill useful strategies and reasoning hints from past experiences into structured memory items that can be stored and reused.&lt;/p&gt;&lt;p&gt;According to Jun Yan, a Research Scientist at Google and co-author of the paper, this marks a fundamental shift in how agents operate. &amp;quot;Traditional agents operate statically—each task is processed in isolation,&amp;quot; Yan explained. &amp;quot;ReasoningBank changes this by turning every task experience (successful or failed) into structured, reusable reasoning memory. As a result, the agent doesn’t start from scratch with each customer; it recalls and adapts proven strategies from similar past cases.&amp;quot;&lt;/p&gt;&lt;p&gt;The framework processes both successful and failed experiences and turns them into a collection of useful strategies and preventive lessons. The agent judges success and failure through &lt;a href="https://venturebeat.com/ai/metas-self-taught-evaluator-enables-llms-to-create-their-own-training-data"&gt;&lt;u&gt;LLM-as-a-judge schemes&lt;/u&gt;&lt;/a&gt; to obviate the need for human labeling.&lt;/p&gt;&lt;p&gt;Yan provides a practical example of this process in action. An agent tasked with finding Sony headphones might fail because its broad search query returns over 4,000 irrelevant products. &amp;quot;ReasoningBank will first try to figure out why this approach failed,&amp;quot; Yan said. &amp;quot;It will then distill strategies such as ‘optimize search query’ and ‘confine products with category filtering.’ Those strategies will be extremely useful to get future similar tasks successfully done.&amp;quot;&lt;/p&gt;&lt;p&gt;The process operates in a closed loop. When an agent faces a new task, it uses an embedding-based search to retrieve relevant memories from ReasoningBank to guide its actions. These memories are inserted into the agent’s system prompt, providing context for its decision-making. Once the task is completed, the framework creates new memory items to extract insights from successes and failures. This new knowledge is then analyzed, distilled, and merged into the ReasoningBank, allowing the agent to continuously evolve and improve its capabilities.&lt;/p&gt;&lt;h2&gt;Supercharging memory with scaling&lt;/h2&gt;&lt;p&gt;The researchers found a powerful synergy between memory and &lt;a href="https://venturebeat.com/ai/deepmind-new-inference-time-scaling-technique-improves-planning-accuracy-in-llms"&gt;&lt;u&gt;test-time scaling&lt;/u&gt;&lt;/a&gt;. Classic test-time scaling involves generating multiple independent answers to the same question, but the researchers argue that this “vanilla form is suboptimal because it does not leverage inherent contrastive signal that arises from redundant exploration on the same problem.”&lt;/p&gt;&lt;p&gt;To address this, they propose Memory-aware Test-Time Scaling (MaTTS), which integrates scaling with ReasoningBank. MaTTS comes in two forms. In “parallel scaling,” the system generates multiple trajectories for the same query, then compares and contrasts them to identify consistent reasoning patterns. In sequential scaling, the agent iteratively refines its reasoning within a single attempt, with the intermediate notes and corrections also serving as valuable memory signals.&lt;/p&gt;&lt;p&gt;This creates a virtuous cycle: the existing memory in ReasoningBank steers the agent toward more promising solutions, while the diverse experiences generated through scaling enable the agent to create higher-quality memories to store in ReasoningBank. &lt;/p&gt;&lt;p&gt;“This positive feedback loop positions memory-driven experience scaling as a new scaling dimension for agents,” the researchers write.&lt;/p&gt;&lt;h2&gt;ReasoningBank in action&lt;/h2&gt;&lt;p&gt;The researchers tested their framework on &lt;a href="https://webarena.dev/"&gt;&lt;u&gt;WebArena &lt;/u&gt;&lt;/a&gt;(web browsing) and &lt;a href="https://www.swebench.com/"&gt;&lt;u&gt;SWE-Bench-Verified&lt;/u&gt;&lt;/a&gt; (software engineering) benchmarks, using models like Google’s Gemini 2.5 Pro and Anthropic’s Claude 3.7 Sonnet. They compared ReasoningBank against baselines including memory-free agents and agents using trajectory-based or workflow-based memory frameworks.&lt;/p&gt;&lt;p&gt;The results show that ReasoningBank consistently outperforms these baselines across all datasets and LLM backbones. On WebArena, it improved the overall success rate by up to 8.3 percentage points compared to a memory-free agent. It also generalized better on more difficult, cross-domain tasks, while reducing the number of interaction steps needed to complete tasks. When combined with MaTTS, both parallel and sequential scaling further boosted performance, consistently outperforming standard test-time scaling.&lt;/p&gt;&lt;p&gt;This efficiency gain has a direct impact on operational costs. Yan points to a case where a memory-free agent took eight trial-and-error steps just to find the right product filter on a website. &amp;quot;Those trial and error costs could be avoided by leveraging relevant insights from ReasoningBank,&amp;quot; he noted. &amp;quot;In this case, we save almost twice the operational costs,&amp;quot; which also improves the user experience by resolving issues faster.&lt;/p&gt;&lt;p&gt;For enterprises, ReasoningBank can help develop cost-effective agents that can learn from experience and adapt over time in complex workflows and areas like software development, customer support, and data analysis. As the paper concludes, “Our findings suggest a practical pathway toward building adaptive and lifelong-learning agents.”&lt;/p&gt;&lt;p&gt;Yan confirmed that their findings point toward a future of truly compositional intelligence. For example, a coding agent could learn discrete skills like API integration and database management from separate tasks. &amp;quot;Over time, these modular skills... become building blocks the agent can flexibly recombine to solve more complex tasks,&amp;quot; he said, suggesting a future where agents can autonomously assemble their knowledge to manage entire workflows with minimal human oversight.&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;Researchers at the &lt;a href="https://illinois.edu/"&gt;&lt;u&gt;University of Illinois Urbana-Champaign&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://research.google/teams/cloud-ai-research/"&gt;&lt;u&gt;Google Cloud AI Research&lt;/u&gt;&lt;/a&gt; have developed a framework that enables large language model (LLM) agents to organize their experiences into a memory bank, helping them get better at complex tasks over time.&lt;/p&gt;&lt;p&gt;The framework, called &lt;a href="https://arxiv.org/abs/2509.25140"&gt;&lt;u&gt;ReasoningBank&lt;/u&gt;&lt;/a&gt;, distills “generalizable reasoning strategies” from an agent’s successful and failed attempts to solve problems. The agent then uses this memory during inference to avoid repeating past mistakes and make better decisions as it faces new problems. The researchers show that when combined with &lt;a href="https://venturebeat.com/ai/how-test-time-scaling-unlocks-hidden-reasoning-abilities-in-small-language-models-and-allows-them-to-outperform-llms"&gt;&lt;u&gt;test-time scaling techniques&lt;/u&gt;&lt;/a&gt;, where an agent makes multiple attempts at a problem, ReasoningBank significantly improves the performance and efficiency of LLM agents.&lt;/p&gt;&lt;p&gt;Their findings show that ReasoningBank consistently outperforms classic memory mechanisms across web browsing and software engineering benchmarks, offering a practical path toward building more adaptive and reliable AI agents for enterprise applications.&lt;/p&gt;&lt;h2&gt;The challenge of LLM agent memory&lt;/h2&gt;&lt;p&gt;As LLM agents are deployed in applications that run for long periods, they encounter a continuous stream of tasks. One of the key limitations of current LLM agents is their failure to learn from this accumulated experience. By approaching each task in isolation, they inevitably repeat past mistakes, discard valuable insights from related problems, and fail to develop skills that would make them more capable over time.&lt;/p&gt;&lt;p&gt;The solution to this limitation is to give agents some kind of memory. Previous efforts to give agents memory have focused on storing past interactions for reuse by organizing information in various forms from plain text to structured graphs. However, these approaches often fall short. Many use raw interaction logs or only store successful task examples. This means they can&amp;#x27;t distill higher-level, transferable reasoning patterns and, crucially, they don’t extract and use the valuable information from the agent’s failures. As the researchers note in their paper, “existing memory designs often remain limited to passive record-keeping rather than providing actionable, generalizable guidance for future decisions.”&lt;/p&gt;&lt;h2&gt;How ReasoningBank works&lt;/h2&gt;&lt;p&gt;ReasoningBank is a memory framework designed to overcome these limitations. Its central idea is to distill useful strategies and reasoning hints from past experiences into structured memory items that can be stored and reused.&lt;/p&gt;&lt;p&gt;According to Jun Yan, a Research Scientist at Google and co-author of the paper, this marks a fundamental shift in how agents operate. &amp;quot;Traditional agents operate statically—each task is processed in isolation,&amp;quot; Yan explained. &amp;quot;ReasoningBank changes this by turning every task experience (successful or failed) into structured, reusable reasoning memory. As a result, the agent doesn’t start from scratch with each customer; it recalls and adapts proven strategies from similar past cases.&amp;quot;&lt;/p&gt;&lt;p&gt;The framework processes both successful and failed experiences and turns them into a collection of useful strategies and preventive lessons. The agent judges success and failure through &lt;a href="https://venturebeat.com/ai/metas-self-taught-evaluator-enables-llms-to-create-their-own-training-data"&gt;&lt;u&gt;LLM-as-a-judge schemes&lt;/u&gt;&lt;/a&gt; to obviate the need for human labeling.&lt;/p&gt;&lt;p&gt;Yan provides a practical example of this process in action. An agent tasked with finding Sony headphones might fail because its broad search query returns over 4,000 irrelevant products. &amp;quot;ReasoningBank will first try to figure out why this approach failed,&amp;quot; Yan said. &amp;quot;It will then distill strategies such as ‘optimize search query’ and ‘confine products with category filtering.’ Those strategies will be extremely useful to get future similar tasks successfully done.&amp;quot;&lt;/p&gt;&lt;p&gt;The process operates in a closed loop. When an agent faces a new task, it uses an embedding-based search to retrieve relevant memories from ReasoningBank to guide its actions. These memories are inserted into the agent’s system prompt, providing context for its decision-making. Once the task is completed, the framework creates new memory items to extract insights from successes and failures. This new knowledge is then analyzed, distilled, and merged into the ReasoningBank, allowing the agent to continuously evolve and improve its capabilities.&lt;/p&gt;&lt;h2&gt;Supercharging memory with scaling&lt;/h2&gt;&lt;p&gt;The researchers found a powerful synergy between memory and &lt;a href="https://venturebeat.com/ai/deepmind-new-inference-time-scaling-technique-improves-planning-accuracy-in-llms"&gt;&lt;u&gt;test-time scaling&lt;/u&gt;&lt;/a&gt;. Classic test-time scaling involves generating multiple independent answers to the same question, but the researchers argue that this “vanilla form is suboptimal because it does not leverage inherent contrastive signal that arises from redundant exploration on the same problem.”&lt;/p&gt;&lt;p&gt;To address this, they propose Memory-aware Test-Time Scaling (MaTTS), which integrates scaling with ReasoningBank. MaTTS comes in two forms. In “parallel scaling,” the system generates multiple trajectories for the same query, then compares and contrasts them to identify consistent reasoning patterns. In sequential scaling, the agent iteratively refines its reasoning within a single attempt, with the intermediate notes and corrections also serving as valuable memory signals.&lt;/p&gt;&lt;p&gt;This creates a virtuous cycle: the existing memory in ReasoningBank steers the agent toward more promising solutions, while the diverse experiences generated through scaling enable the agent to create higher-quality memories to store in ReasoningBank. &lt;/p&gt;&lt;p&gt;“This positive feedback loop positions memory-driven experience scaling as a new scaling dimension for agents,” the researchers write.&lt;/p&gt;&lt;h2&gt;ReasoningBank in action&lt;/h2&gt;&lt;p&gt;The researchers tested their framework on &lt;a href="https://webarena.dev/"&gt;&lt;u&gt;WebArena &lt;/u&gt;&lt;/a&gt;(web browsing) and &lt;a href="https://www.swebench.com/"&gt;&lt;u&gt;SWE-Bench-Verified&lt;/u&gt;&lt;/a&gt; (software engineering) benchmarks, using models like Google’s Gemini 2.5 Pro and Anthropic’s Claude 3.7 Sonnet. They compared ReasoningBank against baselines including memory-free agents and agents using trajectory-based or workflow-based memory frameworks.&lt;/p&gt;&lt;p&gt;The results show that ReasoningBank consistently outperforms these baselines across all datasets and LLM backbones. On WebArena, it improved the overall success rate by up to 8.3 percentage points compared to a memory-free agent. It also generalized better on more difficult, cross-domain tasks, while reducing the number of interaction steps needed to complete tasks. When combined with MaTTS, both parallel and sequential scaling further boosted performance, consistently outperforming standard test-time scaling.&lt;/p&gt;&lt;p&gt;This efficiency gain has a direct impact on operational costs. Yan points to a case where a memory-free agent took eight trial-and-error steps just to find the right product filter on a website. &amp;quot;Those trial and error costs could be avoided by leveraging relevant insights from ReasoningBank,&amp;quot; he noted. &amp;quot;In this case, we save almost twice the operational costs,&amp;quot; which also improves the user experience by resolving issues faster.&lt;/p&gt;&lt;p&gt;For enterprises, ReasoningBank can help develop cost-effective agents that can learn from experience and adapt over time in complex workflows and areas like software development, customer support, and data analysis. As the paper concludes, “Our findings suggest a practical pathway toward building adaptive and lifelong-learning agents.”&lt;/p&gt;&lt;p&gt;Yan confirmed that their findings point toward a future of truly compositional intelligence. For example, a coding agent could learn discrete skills like API integration and database management from separate tasks. &amp;quot;Over time, these modular skills... become building blocks the agent can flexibly recombine to solve more complex tasks,&amp;quot; he said, suggesting a future where agents can autonomously assemble their knowledge to manage entire workflows with minimal human oversight.&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/new-memory-framework-builds-ai-agents-that-can-handle-the-real-worlds</guid><pubDate>Wed, 08 Oct 2025 23:35:00 +0000</pubDate></item></channel></rss>