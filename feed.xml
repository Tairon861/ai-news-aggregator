<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 18 Feb 2026 02:29:48 +0000</lastBuildDate><item><title>Here are the 17 US-based AI companies that have raised $100M or more in 2026 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/17/here-are-the-17-us-based-ai-companies-that-have-raised-100m-or-more-in-2026/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/07/ai-deals.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Nearly 20&amp;nbsp;U.S.-based AI startups have raised mega-rounds&amp;nbsp;of $100 million or more in 2026&amp;nbsp;—&amp;nbsp;and&amp;nbsp;it’s&amp;nbsp;been less than two months.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If the first few weeks of 2026 are any&amp;nbsp;indicator, the AI startup market is in for another year of&amp;nbsp;monster funding rounds at eye-watering valuations.&amp;nbsp;U.S. AI startups raised more than&amp;nbsp;$76 billion&amp;nbsp;through&amp;nbsp;mega-rounds&amp;nbsp;in 2025, per TechCrunch’s count.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Will startups see the same success in 2026?&amp;nbsp;Time will tell.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Here are all the U.S.-based AI startups that have raised $100 million or more thus far:&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-february"&gt;February&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Simile&lt;/strong&gt;, which builds AI to mimic human decisions,&amp;nbsp;raised a&amp;nbsp;$100 million Series A round&amp;nbsp;led by Index Ventures. The round was announced on February 12&amp;nbsp;and&amp;nbsp;included Hanabi Capital, Bain Capital&amp;nbsp;Ventures,&amp;nbsp;and multiple angel investors.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Anthropic&lt;/strong&gt; announced a&amp;nbsp;$30 billion&amp;nbsp;Series G funding round&amp;nbsp;on February 12 that valued the AI research lab at&amp;nbsp;$380 billion. More than 30 investors participated&amp;nbsp;in the&amp;nbsp;round,&amp;nbsp;including Founders Fund, Coatue, and Nvidia, among many others.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Media-generation platform&amp;nbsp;&lt;strong&gt;Runway&amp;nbsp;&lt;/strong&gt;raised a $315 million Series E round that valued the company at $5.3 billion. This funding was led by General Atlantic and was announced on February 10. Nvidia,&amp;nbsp;Fidelity,&amp;nbsp;and Felicis also invested, among others.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Goodfire&lt;/strong&gt;, an AI research lab, announced a&amp;nbsp;$150 million Series B round on February 5. B Capital led the round with participation from Juniper Ventures, Lightspeed Venture&amp;nbsp;Partners,&amp;nbsp;and&amp;nbsp;Menlo Ventures. The round valued the company at&amp;nbsp;$1.25&amp;nbsp;billion.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;AI research company&amp;nbsp;&lt;strong&gt;Fundamental&lt;/strong&gt;&amp;nbsp;announced a&amp;nbsp;$255 million Series A round&amp;nbsp;on February 5. This&amp;nbsp;round valued the company at&amp;nbsp;$1.4 billion. Investors&amp;nbsp;in the round included Oak HC/FT, Salesforce Ventures, Valor Equity&amp;nbsp;Partners,&amp;nbsp;and QP Ventures, among others.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Voice AI company&amp;nbsp;&lt;strong&gt;ElevenLabs&lt;/strong&gt;&amp;nbsp;raised a&amp;nbsp;$500 million Series D round&amp;nbsp;that was announced on February 4. The round was led by Sequoia and valued the company at&amp;nbsp;$11 billion.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-january"&gt;January&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;PaleBlueDot&amp;nbsp;AI&lt;/strong&gt;, a&amp;nbsp;compute&amp;nbsp;platform, raised a&amp;nbsp;$150 million Series B round&amp;nbsp;that valued&amp;nbsp;the startup&amp;nbsp;at&amp;nbsp;$1 billion. The round was announced on January 28 and was led by B Capital.&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Conversational AI platform&amp;nbsp;&lt;strong&gt;Decagon&amp;nbsp;&lt;/strong&gt;announced a&amp;nbsp;$250 million Series D round&amp;nbsp;on January 28. The round was co-led by Coatue and Index Ventures and valued the company at&amp;nbsp;$4.5&amp;nbsp;billion.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;AI research lab&amp;nbsp;&lt;strong&gt;Flapping Airplanes&lt;/strong&gt;&amp;nbsp;raised&amp;nbsp;a&amp;nbsp;$180 million seed round&amp;nbsp;that was led by Google Ventures, Sequoia,&amp;nbsp;and Index Ventures. The round was announced&amp;nbsp;on January 28 and valued the company at&amp;nbsp;$1.5 billion.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Baseten&amp;nbsp;&lt;/strong&gt;raised a&amp;nbsp;$300 million Series E round&amp;nbsp;that valued the AI&amp;nbsp;infrastructure&amp;nbsp;startup at&amp;nbsp;$5 billion. The round was&amp;nbsp;led by IVP and&amp;nbsp;CapitalG&amp;nbsp;and was announced on January 23.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Inferact&lt;/strong&gt;,&amp;nbsp;an AI inference startup, raised a&amp;nbsp;$150 million seed round&amp;nbsp;mere months after its founding. The round was announced on January 22 and&amp;nbsp;garnered&amp;nbsp;the&amp;nbsp;company&amp;nbsp;an $800 million valuation.&amp;nbsp;The round was co-led by Andreessen Horowitz and Lightspeed Venture Partners.&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Cambridge, Massachusetts-based&amp;nbsp;&lt;strong&gt;OpenEvidence&amp;nbsp;&lt;/strong&gt;raised a&amp;nbsp;$250 million Series D round&amp;nbsp;for its medical AI chatbot. The round was co-led by Thrive Global and DST Global and was announced on January 21. This round valued&amp;nbsp;OpenEvidence&amp;nbsp;at&amp;nbsp;$12 billion.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;AI research lab&amp;nbsp;&lt;strong&gt;humans&amp;amp;&lt;/strong&gt;&amp;nbsp;raised a monster&amp;nbsp;$480 million seed round&amp;nbsp;that was announced on January 20. Investors in the round include&amp;nbsp;Nvidia, Jeff Bezos, and GV, among others. This round valued the young startup at&amp;nbsp;$4.48 billion.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;SkildAI&lt;/strong&gt;, which builds AI models to power robots, raised a&amp;nbsp;$1.4 billion&amp;nbsp;Series C round&amp;nbsp;that valued&amp;nbsp;the startup&amp;nbsp;at&amp;nbsp;$14 billion. The&amp;nbsp;round was announced on January 14 and was led by SoftBank and Nvidia.&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Voice AI platform&amp;nbsp;&lt;strong&gt;Deepgram&lt;/strong&gt;&amp;nbsp;raised a&amp;nbsp;$130&amp;nbsp;million Series C round&amp;nbsp;led&amp;nbsp;by AVP, with participation from Tiger Global,&amp;nbsp;ServiceNow&amp;nbsp;Ventures, and Madrona, among others. The round was announced on January&amp;nbsp;13&amp;nbsp;and valued the company at&amp;nbsp;$1.3&amp;nbsp;billion.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Arena&lt;/strong&gt;, a large language model evaluation platform, raised a&amp;nbsp;$150 million Series A round&amp;nbsp;that was co-led by Felicis and UC Investments. This round&amp;nbsp;valued the one-year-old startup at&amp;nbsp;$1.7 billion&amp;nbsp;and was announced on&amp;nbsp;January 6.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Elon Musk’s&amp;nbsp;&lt;strong&gt;xAI&lt;/strong&gt;&amp;nbsp;started the new year with a bang. The AI research lab announced a&amp;nbsp;$20 billion&amp;nbsp;Series E round&amp;nbsp;on January 6. Valor Equity Partners,&amp;nbsp;Fidelity,&amp;nbsp;and the Qatar Investment Authority&amp;nbsp;participated&amp;nbsp;in&amp;nbsp;the round, among others. The company&amp;nbsp;was&amp;nbsp;acquired by Musk’s SpaceX&amp;nbsp;a few weeks later.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/07/ai-deals.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Nearly 20&amp;nbsp;U.S.-based AI startups have raised mega-rounds&amp;nbsp;of $100 million or more in 2026&amp;nbsp;—&amp;nbsp;and&amp;nbsp;it’s&amp;nbsp;been less than two months.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If the first few weeks of 2026 are any&amp;nbsp;indicator, the AI startup market is in for another year of&amp;nbsp;monster funding rounds at eye-watering valuations.&amp;nbsp;U.S. AI startups raised more than&amp;nbsp;$76 billion&amp;nbsp;through&amp;nbsp;mega-rounds&amp;nbsp;in 2025, per TechCrunch’s count.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Will startups see the same success in 2026?&amp;nbsp;Time will tell.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Here are all the U.S.-based AI startups that have raised $100 million or more thus far:&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-february"&gt;February&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Simile&lt;/strong&gt;, which builds AI to mimic human decisions,&amp;nbsp;raised a&amp;nbsp;$100 million Series A round&amp;nbsp;led by Index Ventures. The round was announced on February 12&amp;nbsp;and&amp;nbsp;included Hanabi Capital, Bain Capital&amp;nbsp;Ventures,&amp;nbsp;and multiple angel investors.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Anthropic&lt;/strong&gt; announced a&amp;nbsp;$30 billion&amp;nbsp;Series G funding round&amp;nbsp;on February 12 that valued the AI research lab at&amp;nbsp;$380 billion. More than 30 investors participated&amp;nbsp;in the&amp;nbsp;round,&amp;nbsp;including Founders Fund, Coatue, and Nvidia, among many others.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Media-generation platform&amp;nbsp;&lt;strong&gt;Runway&amp;nbsp;&lt;/strong&gt;raised a $315 million Series E round that valued the company at $5.3 billion. This funding was led by General Atlantic and was announced on February 10. Nvidia,&amp;nbsp;Fidelity,&amp;nbsp;and Felicis also invested, among others.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Goodfire&lt;/strong&gt;, an AI research lab, announced a&amp;nbsp;$150 million Series B round on February 5. B Capital led the round with participation from Juniper Ventures, Lightspeed Venture&amp;nbsp;Partners,&amp;nbsp;and&amp;nbsp;Menlo Ventures. The round valued the company at&amp;nbsp;$1.25&amp;nbsp;billion.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;AI research company&amp;nbsp;&lt;strong&gt;Fundamental&lt;/strong&gt;&amp;nbsp;announced a&amp;nbsp;$255 million Series A round&amp;nbsp;on February 5. This&amp;nbsp;round valued the company at&amp;nbsp;$1.4 billion. Investors&amp;nbsp;in the round included Oak HC/FT, Salesforce Ventures, Valor Equity&amp;nbsp;Partners,&amp;nbsp;and QP Ventures, among others.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Voice AI company&amp;nbsp;&lt;strong&gt;ElevenLabs&lt;/strong&gt;&amp;nbsp;raised a&amp;nbsp;$500 million Series D round&amp;nbsp;that was announced on February 4. The round was led by Sequoia and valued the company at&amp;nbsp;$11 billion.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-january"&gt;January&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;PaleBlueDot&amp;nbsp;AI&lt;/strong&gt;, a&amp;nbsp;compute&amp;nbsp;platform, raised a&amp;nbsp;$150 million Series B round&amp;nbsp;that valued&amp;nbsp;the startup&amp;nbsp;at&amp;nbsp;$1 billion. The round was announced on January 28 and was led by B Capital.&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Conversational AI platform&amp;nbsp;&lt;strong&gt;Decagon&amp;nbsp;&lt;/strong&gt;announced a&amp;nbsp;$250 million Series D round&amp;nbsp;on January 28. The round was co-led by Coatue and Index Ventures and valued the company at&amp;nbsp;$4.5&amp;nbsp;billion.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;AI research lab&amp;nbsp;&lt;strong&gt;Flapping Airplanes&lt;/strong&gt;&amp;nbsp;raised&amp;nbsp;a&amp;nbsp;$180 million seed round&amp;nbsp;that was led by Google Ventures, Sequoia,&amp;nbsp;and Index Ventures. The round was announced&amp;nbsp;on January 28 and valued the company at&amp;nbsp;$1.5 billion.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Baseten&amp;nbsp;&lt;/strong&gt;raised a&amp;nbsp;$300 million Series E round&amp;nbsp;that valued the AI&amp;nbsp;infrastructure&amp;nbsp;startup at&amp;nbsp;$5 billion. The round was&amp;nbsp;led by IVP and&amp;nbsp;CapitalG&amp;nbsp;and was announced on January 23.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Inferact&lt;/strong&gt;,&amp;nbsp;an AI inference startup, raised a&amp;nbsp;$150 million seed round&amp;nbsp;mere months after its founding. The round was announced on January 22 and&amp;nbsp;garnered&amp;nbsp;the&amp;nbsp;company&amp;nbsp;an $800 million valuation.&amp;nbsp;The round was co-led by Andreessen Horowitz and Lightspeed Venture Partners.&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Cambridge, Massachusetts-based&amp;nbsp;&lt;strong&gt;OpenEvidence&amp;nbsp;&lt;/strong&gt;raised a&amp;nbsp;$250 million Series D round&amp;nbsp;for its medical AI chatbot. The round was co-led by Thrive Global and DST Global and was announced on January 21. This round valued&amp;nbsp;OpenEvidence&amp;nbsp;at&amp;nbsp;$12 billion.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;AI research lab&amp;nbsp;&lt;strong&gt;humans&amp;amp;&lt;/strong&gt;&amp;nbsp;raised a monster&amp;nbsp;$480 million seed round&amp;nbsp;that was announced on January 20. Investors in the round include&amp;nbsp;Nvidia, Jeff Bezos, and GV, among others. This round valued the young startup at&amp;nbsp;$4.48 billion.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;SkildAI&lt;/strong&gt;, which builds AI models to power robots, raised a&amp;nbsp;$1.4 billion&amp;nbsp;Series C round&amp;nbsp;that valued&amp;nbsp;the startup&amp;nbsp;at&amp;nbsp;$14 billion. The&amp;nbsp;round was announced on January 14 and was led by SoftBank and Nvidia.&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Voice AI platform&amp;nbsp;&lt;strong&gt;Deepgram&lt;/strong&gt;&amp;nbsp;raised a&amp;nbsp;$130&amp;nbsp;million Series C round&amp;nbsp;led&amp;nbsp;by AVP, with participation from Tiger Global,&amp;nbsp;ServiceNow&amp;nbsp;Ventures, and Madrona, among others. The round was announced on January&amp;nbsp;13&amp;nbsp;and valued the company at&amp;nbsp;$1.3&amp;nbsp;billion.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Arena&lt;/strong&gt;, a large language model evaluation platform, raised a&amp;nbsp;$150 million Series A round&amp;nbsp;that was co-led by Felicis and UC Investments. This round&amp;nbsp;valued the one-year-old startup at&amp;nbsp;$1.7 billion&amp;nbsp;and was announced on&amp;nbsp;January 6.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Elon Musk’s&amp;nbsp;&lt;strong&gt;xAI&lt;/strong&gt;&amp;nbsp;started the new year with a bang. The AI research lab announced a&amp;nbsp;$20 billion&amp;nbsp;Series E round&amp;nbsp;on January 6. Valor Equity Partners,&amp;nbsp;Fidelity,&amp;nbsp;and the Qatar Investment Authority&amp;nbsp;participated&amp;nbsp;in&amp;nbsp;the round, among others. The company&amp;nbsp;was&amp;nbsp;acquired by Musk’s SpaceX&amp;nbsp;a few weeks later.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/17/here-are-the-17-us-based-ai-companies-that-have-raised-100m-or-more-in-2026/</guid><pubDate>Tue, 17 Feb 2026 14:58:09 +0000</pubDate></item><item><title>SS&amp;C Blue Prism: On the journey from RPA to agentic automation (AI News)</title><link>https://www.artificialintelligence-news.com/news/ssc-blue-prism-on-the-journey-from-rpa-to-agentic-automation/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/patrick-tomasso-5hvn-2WW6rY-unsplash-1-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;For organizations who are still wedded to the rules and structures of robotic process automation (RPA), then considering agentic AI as the next step for automation may be faintly terrifying. SS&amp;amp;C Blue Prism, however, is here to help, taking customers on the journey from RPA to agentic automation at a pace with which they’re comfortable.&lt;/p&gt;&lt;p&gt;Big as it may be, this move is a necessary one. Modern workflows are at a level of complexity that outlines what traditional RPA was designed to do, according to Steven Colquitt, VP Software Engineering, SS&amp;amp;C Blue Prism. Unstructured data comes from various sources resembling non-deterministic real-world interactions. “Inputs can vary, outcomes can shift and decisions depend on context in real-time,” notes Colquitt.&lt;/p&gt;&lt;p&gt;Brian Halpin, Managing Director, Automation, SS&amp;amp;C Blue Prism, gives the example of a credit agreement where you might need to get 30 or 40 answers from it. He uses the word “answers” deliberately as opposed to data points to account for the level of reasoning that a large language model (LLM) performs.&lt;/p&gt;&lt;p&gt;The element of this being a journey continues to resonate, however. “We’re now saying we’re giving an AI agent the outcome that we want, but we’re not giving it the instructions on how to complete,” says Halpin. “We’re not saying, ‘follow step one, two, three, four, five.’ We’re saying, ‘I want this loan reviewed’ or ‘I want this customer onboarded.’&lt;/p&gt;&lt;p&gt;“Ultimately, I think that’s where the market will go,” adds Halpin. “Is it ready for that? No. Why? Because there’s trust, there’s regulations, there’s auditability […] stability, security. We know LLMs are prone to hallucinations, we know they drift, and [if] you change the underlying model, things change and responses get different.&lt;/p&gt;&lt;p&gt;“There’s an awful lot of learning to happen before I think companies go fully autonomous and real agentic workflows [are] driven from that sort of non-deterministic perspective,” says Halpin. “But then, there will be something else, right? There will be another model. So really, it is all a journey right now.”&lt;/p&gt;&lt;p&gt;SS&amp;amp;C Blue Prism has thousands of customers who have automated processes in place, from centers of excellence (CoEs) to running digital workers in their operations, who they’re hoping to upgrade into the “world of AI”, as Halpin puts it. Sometimes it’s about connecting two separate areas.&lt;/p&gt;&lt;p&gt;“It’s been interesting,” Halpin notes. “As I talk to [our] customers, I see a common thread among companies right now where, in a lot of cases, AI has been established as a separate unit in a company. You go over to the process automation team, and they’re maybe not even allowed to use the AI.&lt;/p&gt;&lt;p&gt;“So, it’s about, ‘How do you help them get that capability and blend it into their process efficiency and allow them to get to the next 20%, 30% of automation, in terms of the end-to-end process?’”&lt;/p&gt;&lt;p&gt;As part of this, SS&amp;amp;C Blue Prism is soon to launch new technology which helps organizations build and embed AI agents within workflows, as well as assist with orchestration. Those who attended TechEx Global, on February 4-5 as part of the Intelligent Automation conference, where SS&amp;amp;C Blue Prism participated, got the full story, as well as understanding the company’s ongoing path.&lt;/p&gt;&lt;p&gt;“[SS&amp;amp;C Technologies] are one of the biggest users of RPA in the world,” adds Halpin. “We have over three and a half thousand digital workers deployed [across the SS&amp;amp;C estate]. We’re saving hundreds of millions in run-rate benefit. We’ve about 35 AI agents in production attached to those digital workers doing […] complex tasks, and really, we just want to share that journey.”&lt;/p&gt;&lt;p&gt;&lt;em&gt;Watch the full interview with Brian Halpin below:&lt;/em&gt;&lt;/p&gt;&lt;figure class="wp-block-video"&gt;&lt;video controls="controls" height="438" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/Brian_Halpin_Blue_Prism_IA_03_02.mp4" width="780"&gt;&lt;/video&gt;&lt;/figure&gt;&lt;p&gt;&lt;em&gt;Photo by Patrick Tomasso on Unsplash&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/patrick-tomasso-5hvn-2WW6rY-unsplash-1-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;For organizations who are still wedded to the rules and structures of robotic process automation (RPA), then considering agentic AI as the next step for automation may be faintly terrifying. SS&amp;amp;C Blue Prism, however, is here to help, taking customers on the journey from RPA to agentic automation at a pace with which they’re comfortable.&lt;/p&gt;&lt;p&gt;Big as it may be, this move is a necessary one. Modern workflows are at a level of complexity that outlines what traditional RPA was designed to do, according to Steven Colquitt, VP Software Engineering, SS&amp;amp;C Blue Prism. Unstructured data comes from various sources resembling non-deterministic real-world interactions. “Inputs can vary, outcomes can shift and decisions depend on context in real-time,” notes Colquitt.&lt;/p&gt;&lt;p&gt;Brian Halpin, Managing Director, Automation, SS&amp;amp;C Blue Prism, gives the example of a credit agreement where you might need to get 30 or 40 answers from it. He uses the word “answers” deliberately as opposed to data points to account for the level of reasoning that a large language model (LLM) performs.&lt;/p&gt;&lt;p&gt;The element of this being a journey continues to resonate, however. “We’re now saying we’re giving an AI agent the outcome that we want, but we’re not giving it the instructions on how to complete,” says Halpin. “We’re not saying, ‘follow step one, two, three, four, five.’ We’re saying, ‘I want this loan reviewed’ or ‘I want this customer onboarded.’&lt;/p&gt;&lt;p&gt;“Ultimately, I think that’s where the market will go,” adds Halpin. “Is it ready for that? No. Why? Because there’s trust, there’s regulations, there’s auditability […] stability, security. We know LLMs are prone to hallucinations, we know they drift, and [if] you change the underlying model, things change and responses get different.&lt;/p&gt;&lt;p&gt;“There’s an awful lot of learning to happen before I think companies go fully autonomous and real agentic workflows [are] driven from that sort of non-deterministic perspective,” says Halpin. “But then, there will be something else, right? There will be another model. So really, it is all a journey right now.”&lt;/p&gt;&lt;p&gt;SS&amp;amp;C Blue Prism has thousands of customers who have automated processes in place, from centers of excellence (CoEs) to running digital workers in their operations, who they’re hoping to upgrade into the “world of AI”, as Halpin puts it. Sometimes it’s about connecting two separate areas.&lt;/p&gt;&lt;p&gt;“It’s been interesting,” Halpin notes. “As I talk to [our] customers, I see a common thread among companies right now where, in a lot of cases, AI has been established as a separate unit in a company. You go over to the process automation team, and they’re maybe not even allowed to use the AI.&lt;/p&gt;&lt;p&gt;“So, it’s about, ‘How do you help them get that capability and blend it into their process efficiency and allow them to get to the next 20%, 30% of automation, in terms of the end-to-end process?’”&lt;/p&gt;&lt;p&gt;As part of this, SS&amp;amp;C Blue Prism is soon to launch new technology which helps organizations build and embed AI agents within workflows, as well as assist with orchestration. Those who attended TechEx Global, on February 4-5 as part of the Intelligent Automation conference, where SS&amp;amp;C Blue Prism participated, got the full story, as well as understanding the company’s ongoing path.&lt;/p&gt;&lt;p&gt;“[SS&amp;amp;C Technologies] are one of the biggest users of RPA in the world,” adds Halpin. “We have over three and a half thousand digital workers deployed [across the SS&amp;amp;C estate]. We’re saving hundreds of millions in run-rate benefit. We’ve about 35 AI agents in production attached to those digital workers doing […] complex tasks, and really, we just want to share that journey.”&lt;/p&gt;&lt;p&gt;&lt;em&gt;Watch the full interview with Brian Halpin below:&lt;/em&gt;&lt;/p&gt;&lt;figure class="wp-block-video"&gt;&lt;video controls="controls" height="438" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/Brian_Halpin_Blue_Prism_IA_03_02.mp4" width="780"&gt;&lt;/video&gt;&lt;/figure&gt;&lt;p&gt;&lt;em&gt;Photo by Patrick Tomasso on Unsplash&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/ssc-blue-prism-on-the-journey-from-rpa-to-agentic-automation/</guid><pubDate>Tue, 17 Feb 2026 15:27:34 +0000</pubDate></item><item><title>Amazon Fire TV’s new interface is now rolling out in the US (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/17/amazon-fire-tvs-new-interface-is-now-rolling-out-in-the-u-s/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon is rolling out a new user interface for its Fire TV streaming devices, designed to put more focus on the content, while also simplifying navigation. The update, which is initially available to Fire TV owners in the U.S., represents the first major Fire TV redesign in years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The changes arrive after an explosion of streaming content has made it more difficult to know what’s available to watch on which service, requiring streaming platforms like Fire TV to serve more as a discovery hub than just a tool to launch streaming apps.  &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company first previewed the new design at the Consumer Electronics Show in Las Vegas in January, showing off an interface intended to make Fire TV feel less cluttered. The updated design features rounded corners, varied gradients, consistent typography, and increased spacing between content, and it adds more space for pinned apps.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3079579" height="383" src="https://techcrunch.com/wp-content/uploads/2026/01/3-New-Fire-TV-UI-TV-Show-Screen.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Previously, Fire TV users could only pin six apps to the home screen. Now, with smaller app icons, the update expands that to 20 slots for apps, accommodating services like Netflix, Disney+, YouTube, Prime Video, Hulu, HBO Max, and other top streamers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, the navigation bar at the top of the screen has been simplified into categories marked with simple icons, including &amp;nbsp;Movies, TV, Live TV, Sports, and News. The search button is also easily within reach to the left of the Home tab.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="New Fire TV UI Sports" class="wp-image-3079580" height="383" src="https://techcrunch.com/wp-content/uploads/2026/01/4-New-Fire-TV-UI-Sports-Screen.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Within these tabs, Fire TV surfaces the content you’re already watching and displays other suggestions drawn from the services you’ve subscribed to, organized in rows labeled “For You.” The tabs also highlight free movies to stream, top movies and shows, and other paid content you might enjoy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Live TV tab, meanwhile, centralizes access to the live content that’s available across your streaming services, plus broadcast or cable TV, if you subscribe or use an antenna. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="New Fire TV UI Games" class="wp-image-3079582" height="383" src="https://techcrunch.com/wp-content/uploads/2026/01/5-New-Fire-TV-UI-Games-Screen.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Less frequently used features live under a three-line “hamburger” menu on the left, and include Games, Art &amp;amp; Photos, the Appstore, Music Video &amp;amp; Audio, a universal watchlist called “My Stuff,” Settings, and other options.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon’s AI assistant Alexa+ is also built into the new interface, allowing users to ask questions on almost any topic, not just movies and TV. Queries can be asked using natural language, and Fire TV owners can refine them or ask follow-up questions as they chat with the AI assistant. The AI can also interact with on-screen content. For instance, you could select a movie tile and say, “Tell me more about that one.” You can even ask nuanced questions like, “Find me more movies that have the same look.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="New Fire TV UI Browse Screen" class="wp-image-3079583" height="383" src="https://techcrunch.com/wp-content/uploads/2026/01/6-New-Fire-TV-UI-Browse-Screen.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon recently announced that Alexa+ is available to customers with a Prime subscription as an included perk. Others can choose to pay for access separately. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The new user interface launches first on the&amp;nbsp;Fire&amp;nbsp;TV&amp;nbsp;Stick 4K Plus,&amp;nbsp;Fire&amp;nbsp;TV&amp;nbsp;Stick 4K Max (2nd Gen), and&amp;nbsp;the Fire&amp;nbsp;TV&amp;nbsp;Omni Mini-LED Series in the U.S. This spring, it will roll out to more countries and devices, including the latest generation of the Fire TV 4K streaming players and TVs such as the Fire&amp;nbsp;TV&amp;nbsp;2-Series,&amp;nbsp;Fire&amp;nbsp;TV&amp;nbsp;4-Series,&amp;nbsp;and Fire&amp;nbsp;TV&amp;nbsp;Omni QLED Series, as well as TVs made by partners like Hisense, Insignia, Panasonic, and TCL.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The update is also available on the new Amazon Ember Artline, a new series of televisions that can make your TV screen look like a framed work of art when not in use.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon is rolling out a new user interface for its Fire TV streaming devices, designed to put more focus on the content, while also simplifying navigation. The update, which is initially available to Fire TV owners in the U.S., represents the first major Fire TV redesign in years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The changes arrive after an explosion of streaming content has made it more difficult to know what’s available to watch on which service, requiring streaming platforms like Fire TV to serve more as a discovery hub than just a tool to launch streaming apps.  &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company first previewed the new design at the Consumer Electronics Show in Las Vegas in January, showing off an interface intended to make Fire TV feel less cluttered. The updated design features rounded corners, varied gradients, consistent typography, and increased spacing between content, and it adds more space for pinned apps.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3079579" height="383" src="https://techcrunch.com/wp-content/uploads/2026/01/3-New-Fire-TV-UI-TV-Show-Screen.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Previously, Fire TV users could only pin six apps to the home screen. Now, with smaller app icons, the update expands that to 20 slots for apps, accommodating services like Netflix, Disney+, YouTube, Prime Video, Hulu, HBO Max, and other top streamers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, the navigation bar at the top of the screen has been simplified into categories marked with simple icons, including &amp;nbsp;Movies, TV, Live TV, Sports, and News. The search button is also easily within reach to the left of the Home tab.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="New Fire TV UI Sports" class="wp-image-3079580" height="383" src="https://techcrunch.com/wp-content/uploads/2026/01/4-New-Fire-TV-UI-Sports-Screen.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Within these tabs, Fire TV surfaces the content you’re already watching and displays other suggestions drawn from the services you’ve subscribed to, organized in rows labeled “For You.” The tabs also highlight free movies to stream, top movies and shows, and other paid content you might enjoy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Live TV tab, meanwhile, centralizes access to the live content that’s available across your streaming services, plus broadcast or cable TV, if you subscribe or use an antenna. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="New Fire TV UI Games" class="wp-image-3079582" height="383" src="https://techcrunch.com/wp-content/uploads/2026/01/5-New-Fire-TV-UI-Games-Screen.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Less frequently used features live under a three-line “hamburger” menu on the left, and include Games, Art &amp;amp; Photos, the Appstore, Music Video &amp;amp; Audio, a universal watchlist called “My Stuff,” Settings, and other options.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon’s AI assistant Alexa+ is also built into the new interface, allowing users to ask questions on almost any topic, not just movies and TV. Queries can be asked using natural language, and Fire TV owners can refine them or ask follow-up questions as they chat with the AI assistant. The AI can also interact with on-screen content. For instance, you could select a movie tile and say, “Tell me more about that one.” You can even ask nuanced questions like, “Find me more movies that have the same look.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="New Fire TV UI Browse Screen" class="wp-image-3079583" height="383" src="https://techcrunch.com/wp-content/uploads/2026/01/6-New-Fire-TV-UI-Browse-Screen.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon recently announced that Alexa+ is available to customers with a Prime subscription as an included perk. Others can choose to pay for access separately. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The new user interface launches first on the&amp;nbsp;Fire&amp;nbsp;TV&amp;nbsp;Stick 4K Plus,&amp;nbsp;Fire&amp;nbsp;TV&amp;nbsp;Stick 4K Max (2nd Gen), and&amp;nbsp;the Fire&amp;nbsp;TV&amp;nbsp;Omni Mini-LED Series in the U.S. This spring, it will roll out to more countries and devices, including the latest generation of the Fire TV 4K streaming players and TVs such as the Fire&amp;nbsp;TV&amp;nbsp;2-Series,&amp;nbsp;Fire&amp;nbsp;TV&amp;nbsp;4-Series,&amp;nbsp;and Fire&amp;nbsp;TV&amp;nbsp;Omni QLED Series, as well as TVs made by partners like Hisense, Insignia, Panasonic, and TCL.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The update is also available on the new Amazon Ember Artline, a new series of televisions that can make your TV screen look like a framed work of art when not in use.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/17/amazon-fire-tvs-new-interface-is-now-rolling-out-in-the-u-s/</guid><pubDate>Tue, 17 Feb 2026 15:58:43 +0000</pubDate></item><item><title>WordPress.com adds an AI Assistant that can edit, adjust styles, create images, and more (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/17/wordpress-com-adds-an-ai-assistant-that-can-edit-adjust-styles-create-images-and-more/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;WordPress.com, the website hosting platform from Automattic, will now include a built-in WordPress AI assistant, the company announced on Tuesday. The feature is designed to work inside the website to understand its content and layout, allowing site owners to make changes with natural language commands.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the new tool, you can adjust the site’s layout, its style, or other patterns by issuing commands to the AI assistant. You’ll then see the changes reflected on the site as you work. These instructions don’t have to be precisely tailored prompts, either, the company notes. Instead, you can use more general language, like “make this section feel more modern or spacious,” “change my site’s colors to be brighter and bolder,” or “give me more font options that feel clean and professional.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3093460" height="422" src="https://techcrunch.com/wp-content/uploads/2026/02/wordpress-ai-assistant-page-editor.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;WordPress.com&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;You can also direct the AI to add or adjust your layout, instructing it to do things like “add a contact page,” or “add a testimonials section below this section.” However, the company notes that its adjustments work with block themes, not classic ones. If you’re using the latter, the assistant won’t appear in the editor.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The WordPress AI assistant can update the site’s content, as well, like asking it to rewrite your bio to sound more confident, or translating a section into another language. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI can also function like an editor, offering headline suggestions, fact checks, and other grammar and editing suggestions. This aspect is available through the block notes editor that arrived in WordPress 6.9, where you’re able to collaborate with teammates in the editor. Now you can pull the AI into that workflow by typing @ai followed by your requests. The AI will provide its answers here, including relevant links and other information where it cites external sources.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3093462" height="394" src="https://techcrunch.com/wp-content/uploads/2026/02/ai-block-notes-wordpress-ai-assistant.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;WordPress.com&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, for help with visuals, the assistant leverages Google Gemini’s Nano Banana AI models, which can be used to either make new images or edit existing ones. With the AI helper, available as a new “Generate Image” button in the Media Library, you can specify image requirements like aspect ratios or dictate image styles. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3093461" height="417" src="https://techcrunch.com/wp-content/uploads/2026/02/image-editing-generating-wordpress-ai-assistant.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;WordPress.com&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company notes the WordPress AI Assistant is an opt-in feature users can enable if they choose. To do so, they will need to visit their Sites list once logged in, click their site name, and then Settings. Under settings, they’ll scroll down to “AI tools” and toggle the “Enable AI assistant” setting on.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3093463" height="459" src="https://techcrunch.com/wp-content/uploads/2026/02/enable-ai-assistant-wordpress-com.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;WordPress.com&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Customers who purchase a website with the AI website builder will have the assistant enabled automatically.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;WordPress.com, the website hosting platform from Automattic, will now include a built-in WordPress AI assistant, the company announced on Tuesday. The feature is designed to work inside the website to understand its content and layout, allowing site owners to make changes with natural language commands.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the new tool, you can adjust the site’s layout, its style, or other patterns by issuing commands to the AI assistant. You’ll then see the changes reflected on the site as you work. These instructions don’t have to be precisely tailored prompts, either, the company notes. Instead, you can use more general language, like “make this section feel more modern or spacious,” “change my site’s colors to be brighter and bolder,” or “give me more font options that feel clean and professional.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3093460" height="422" src="https://techcrunch.com/wp-content/uploads/2026/02/wordpress-ai-assistant-page-editor.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;WordPress.com&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;You can also direct the AI to add or adjust your layout, instructing it to do things like “add a contact page,” or “add a testimonials section below this section.” However, the company notes that its adjustments work with block themes, not classic ones. If you’re using the latter, the assistant won’t appear in the editor.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The WordPress AI assistant can update the site’s content, as well, like asking it to rewrite your bio to sound more confident, or translating a section into another language. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI can also function like an editor, offering headline suggestions, fact checks, and other grammar and editing suggestions. This aspect is available through the block notes editor that arrived in WordPress 6.9, where you’re able to collaborate with teammates in the editor. Now you can pull the AI into that workflow by typing @ai followed by your requests. The AI will provide its answers here, including relevant links and other information where it cites external sources.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3093462" height="394" src="https://techcrunch.com/wp-content/uploads/2026/02/ai-block-notes-wordpress-ai-assistant.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;WordPress.com&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, for help with visuals, the assistant leverages Google Gemini’s Nano Banana AI models, which can be used to either make new images or edit existing ones. With the AI helper, available as a new “Generate Image” button in the Media Library, you can specify image requirements like aspect ratios or dictate image styles. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3093461" height="417" src="https://techcrunch.com/wp-content/uploads/2026/02/image-editing-generating-wordpress-ai-assistant.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;WordPress.com&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company notes the WordPress AI Assistant is an opt-in feature users can enable if they choose. To do so, they will need to visit their Sites list once logged in, click their site name, and then Settings. Under settings, they’ll scroll down to “AI tools” and toggle the “Enable AI assistant” setting on.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3093463" height="459" src="https://techcrunch.com/wp-content/uploads/2026/02/enable-ai-assistant-wordpress-com.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;WordPress.com&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Customers who purchase a website with the AI website builder will have the assistant enabled automatically.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/17/wordpress-com-adds-an-ai-assistant-that-can-edit-adjust-styles-create-images-and-more/</guid><pubDate>Tue, 17 Feb 2026 16:10:44 +0000</pubDate></item><item><title>European Parliament blocks AI on lawmakers’ devices, citing security risks (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/17/european-parliament-blocks-ai-on-lawmakers-devices-citing-security-risks/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/EU-ai-1258475609.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The European Parliament has reportedly blocked lawmakers from using the baked-in AI tools on their work devices, citing cybersecurity and privacy risks with uploading confidential correspondence to the cloud.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Per an email seen by Politico, the parliament’s IT department said it could not guarantee the security of the data uploaded to the servers of AI companies and that the full extent of what information is shared with AI companies is “still being assessed.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As such, the email said, “It is considered safer to keep such features disabled.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Uploading data to AI chatbots, like Anthropic’s Claude, Microsoft’s Copilot, and OpenAI’s ChatGPT, for example, means that U.S. authorities can demand the companies that run the chatbots turn over information about their users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI chatbots also typically rely on using information that users provide or upload to improve their models, increasing the chance that potentially sensitive information uploaded by one person may be shared and seen by other users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Europe has some of the strongest data protection rules in the world. But the European Commission, the executive body that oversees the 27-member state bloc, last year floated new legislative proposals aimed at relaxing its data protection rules to make it easier for tech giants to train their AI models on Europeans’ data, drawing ire from critics who said the move caves in to U.S. technology giants.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The move to restrict European lawmakers from accessing AI products on their devices comes as several EU member countries reevaluate their relationships with U.S. tech giants, which remain subject to U.S. law and the unpredictable whims and demands of the Trump administration.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In recent weeks, the U.S. Department of Homeland Security has sent hundreds of subpoenas demanding U.S. tech and social media giants turn over information about people, including Americans, who have been publicly critical of the Trump administration’s policies.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google, Meta, and Reddit complied in several cases, even though the subpoenas had not been issued by a judge and were not enforced by a court.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/EU-ai-1258475609.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The European Parliament has reportedly blocked lawmakers from using the baked-in AI tools on their work devices, citing cybersecurity and privacy risks with uploading confidential correspondence to the cloud.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Per an email seen by Politico, the parliament’s IT department said it could not guarantee the security of the data uploaded to the servers of AI companies and that the full extent of what information is shared with AI companies is “still being assessed.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As such, the email said, “It is considered safer to keep such features disabled.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Uploading data to AI chatbots, like Anthropic’s Claude, Microsoft’s Copilot, and OpenAI’s ChatGPT, for example, means that U.S. authorities can demand the companies that run the chatbots turn over information about their users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI chatbots also typically rely on using information that users provide or upload to improve their models, increasing the chance that potentially sensitive information uploaded by one person may be shared and seen by other users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Europe has some of the strongest data protection rules in the world. But the European Commission, the executive body that oversees the 27-member state bloc, last year floated new legislative proposals aimed at relaxing its data protection rules to make it easier for tech giants to train their AI models on Europeans’ data, drawing ire from critics who said the move caves in to U.S. technology giants.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The move to restrict European lawmakers from accessing AI products on their devices comes as several EU member countries reevaluate their relationships with U.S. tech giants, which remain subject to U.S. law and the unpredictable whims and demands of the Trump administration.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In recent weeks, the U.S. Department of Homeland Security has sent hundreds of subpoenas demanding U.S. tech and social media giants turn over information about people, including Americans, who have been publicly critical of the Trump administration’s policies.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google, Meta, and Reddit complied in several cases, even though the subpoenas had not been issued by a judge and were not enforced by a court.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/17/european-parliament-blocks-ai-on-lawmakers-devices-citing-security-risks/</guid><pubDate>Tue, 17 Feb 2026 16:30:43 +0000</pubDate></item><item><title>Running AI models is turning into a memory game (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/17/running-ai-models-is-turning-into-a-memory-game/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2009/01/samsung_50nm_dram.jpg?w=425" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;When we talk about the cost of AI infrastructure, the focus is usually on Nvidia and GPUs — but memory is an increasingly important part of the picture. As hyperscalers prepare to build out billions of dollars’ worth of new data centers, the price for DRAM chips has jumped roughly 7x in the last year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the same time, there’s a growing discipline in orchestrating all that memory to make sure the right data gets to the right agent at the right time. The companies that master it will be able to make the same queries with fewer tokens, which can be the difference between folding and staying in business.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Semiconductor analyst Doug O’Laughlin has an interesting look at the importance of memory chips on his Substack, where he talks with Val Bercovici, chief AI officer at Weka. They’re both semiconductor guys, so the focus is more on the chips than the broader architecture; the implications for AI software are pretty significant too.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I was particularly struck by this passage, in which Bercovici looks at the growing complexity of Anthropic’s prompt-caching documentation:&lt;/p&gt;

&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;
&lt;p class="wp-block-paragraph"&gt;The tell is if we go to Anthropic’s prompt caching pricing page. It started off as a very simple page six or seven months ago, especially as Claude Code was launching — just “use caching, it’s cheaper.” Now it’s an encyclopedia of advice on exactly how many cache writes to pre-buy. You’ve got 5-minute tiers, which are very common across the industry, or 1-hour tiers — and nothing above. That’s a really important tell. Then of course you’ve got all sorts of arbitrage opportunities around the pricing for cache reads based on how many cache writes you’ve pre-purchased.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p class="wp-block-paragraph"&gt;The question here is how long Claude holds your prompt in cached memory: You can pay for a 5-minute window, or pay more for an hour-long window. It’s much cheaper to draw on data that’s still in the cache, so if you manage it right, you can save an awful lot. There is a catch though: Every new bit of data you add to the query may bump something else out of the cache window.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is complex stuff, but the upshot is simple enough: Managing memory in AI models is going to be a huge part of AI going forward. Companies that do it well are going to rise to the top.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And there is plenty of progress to be made in this new field. Back in October, I covered a startup called Tensormesh that was working on one layer in the stack known as cache optimization.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Opportunities exist in other parts of the stack. For instance, lower down the stack, there’s the question of how data centers are using the different types of memory they have. (The interview includes a nice discussion of when DRAM chips are used instead of HBM, although it’s pretty deep in the hardware weeds.) Higher up the stack, end users are figuring out how to structure their model swarms to take advantage of the shared cache.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As companies get better at memory orchestration, they’ll use fewer tokens and inference will get cheaper. Meanwhile, models are getting more efficient at processing each token, pushing the cost down still further. As server costs drop, a lot of applications that don’t seem viable now will start to edge into profitability.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2009/01/samsung_50nm_dram.jpg?w=425" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;When we talk about the cost of AI infrastructure, the focus is usually on Nvidia and GPUs — but memory is an increasingly important part of the picture. As hyperscalers prepare to build out billions of dollars’ worth of new data centers, the price for DRAM chips has jumped roughly 7x in the last year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the same time, there’s a growing discipline in orchestrating all that memory to make sure the right data gets to the right agent at the right time. The companies that master it will be able to make the same queries with fewer tokens, which can be the difference between folding and staying in business.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Semiconductor analyst Doug O’Laughlin has an interesting look at the importance of memory chips on his Substack, where he talks with Val Bercovici, chief AI officer at Weka. They’re both semiconductor guys, so the focus is more on the chips than the broader architecture; the implications for AI software are pretty significant too.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I was particularly struck by this passage, in which Bercovici looks at the growing complexity of Anthropic’s prompt-caching documentation:&lt;/p&gt;

&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;
&lt;p class="wp-block-paragraph"&gt;The tell is if we go to Anthropic’s prompt caching pricing page. It started off as a very simple page six or seven months ago, especially as Claude Code was launching — just “use caching, it’s cheaper.” Now it’s an encyclopedia of advice on exactly how many cache writes to pre-buy. You’ve got 5-minute tiers, which are very common across the industry, or 1-hour tiers — and nothing above. That’s a really important tell. Then of course you’ve got all sorts of arbitrage opportunities around the pricing for cache reads based on how many cache writes you’ve pre-purchased.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p class="wp-block-paragraph"&gt;The question here is how long Claude holds your prompt in cached memory: You can pay for a 5-minute window, or pay more for an hour-long window. It’s much cheaper to draw on data that’s still in the cache, so if you manage it right, you can save an awful lot. There is a catch though: Every new bit of data you add to the query may bump something else out of the cache window.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is complex stuff, but the upshot is simple enough: Managing memory in AI models is going to be a huge part of AI going forward. Companies that do it well are going to rise to the top.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And there is plenty of progress to be made in this new field. Back in October, I covered a startup called Tensormesh that was working on one layer in the stack known as cache optimization.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Opportunities exist in other parts of the stack. For instance, lower down the stack, there’s the question of how data centers are using the different types of memory they have. (The interview includes a nice discussion of when DRAM chips are used instead of HBM, although it’s pretty deep in the hardware weeds.) Higher up the stack, end users are figuring out how to structure their model swarms to take advantage of the shared cache.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As companies get better at memory orchestration, they’ll use fewer tokens and inference will get cheaper. Meanwhile, models are getting more efficient at processing each token, pushing the cost down still further. As server costs drop, a lot of applications that don’t seem viable now will start to edge into profitability.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/17/running-ai-models-is-turning-into-a-memory-game/</guid><pubDate>Tue, 17 Feb 2026 16:44:14 +0000</pubDate></item><item><title>SpaceX vets raise $50M Series A for data center links (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/17/spacex-vets-raise-50m-series-a-for-data-center-links/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/Screenshot-2026-02-16-at-11.06.38-AM.png?resize=1200,679" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Travis Brashears, Cameron Ramos, and Serena Grown-Haeberli began collaborating at SpaceX, developing optical communications links that keep thousands of Starlink internet satellites in constant contact.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now, the three engineers are co-founders of Mesh Optical Technologies, a Los Angeles startup that announced a $50 million Series A led by Thrive Capital on Tuesday.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Mesh aims to mass-produce optical transceivers, devices that convert optical signals from fiber or laser into electrical signals for computers. CEO Brashears, President Ramos, and VP of Product Grown-Haeberli realized the opportunity when designing a new generation of compute-hungry SpaceX satellites forced them to assess the optical transceiver market, and they saw its limitations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Optical transceivers are particularly important for data centers aimed at training and operating large deep learning models, because they allow multiple GPUs to work in concert. One established U.S. supplier, AOI, won a contract worth $4 billion to provide components for AWS data centers last year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Someone will brag about a million GPU cluster; you have to multiply by four to five for the number of transceivers in that cluster,” Brashears explained.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s goal is to manufacture a thousand units per day within the year so they can begin qualifying for bulk orders in 2027 and 2028.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The optical transceiver market is dominated by Chinese firms and suppliers, and Mesh sees an advantage in building its supply chain outside of that country. While trade restrictions haven’t impacted the market yet, the founders and their backers see themselves as getting in front of a national security dilemma.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“If AI is the most important technology in several generations (which we believe to be true), to have critical parts of AI data center capex run through misaligned/competitive countries is a problem,” Thrive Partner Philip Clark wrote TechCrunch. “In the immediate term, Mesh is solving our need for better ways to do interconnect if we want to keep scaling AI.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The challenge for Mesh, the founders say, is executing lights-out, automated manufacturing techniques, which aren’t common in U.S. industry. So much of this expertise is concentrated in China that even European equipment suppliers expect Chinese customers — one German firm’s standard intake form asks for a Chinese company registration number.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;By co-locating design and production, the founders hope to realize more efficient and lower-cost components. Their current design removes one commonly used but power-hungry component, which Ramos said could reduce GPU cluster power usage by 3% to 5%, a meaningful amount as hyperscalers seek to wring as much efficiency out of their systems as possible.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Data centers are just the beginning of Mesh’s aspirations; the company sees optical wavelength communications as the next paradigm in communications.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The world has primarily focused on [radio frequencies] for a long time,” Brashears told TechCrunch. “We want to be at the precipice of transition from RF to photonics…we want to interconnect everything, and not just computers, but that’s where we’re starting.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/Screenshot-2026-02-16-at-11.06.38-AM.png?resize=1200,679" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Travis Brashears, Cameron Ramos, and Serena Grown-Haeberli began collaborating at SpaceX, developing optical communications links that keep thousands of Starlink internet satellites in constant contact.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now, the three engineers are co-founders of Mesh Optical Technologies, a Los Angeles startup that announced a $50 million Series A led by Thrive Capital on Tuesday.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Mesh aims to mass-produce optical transceivers, devices that convert optical signals from fiber or laser into electrical signals for computers. CEO Brashears, President Ramos, and VP of Product Grown-Haeberli realized the opportunity when designing a new generation of compute-hungry SpaceX satellites forced them to assess the optical transceiver market, and they saw its limitations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Optical transceivers are particularly important for data centers aimed at training and operating large deep learning models, because they allow multiple GPUs to work in concert. One established U.S. supplier, AOI, won a contract worth $4 billion to provide components for AWS data centers last year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Someone will brag about a million GPU cluster; you have to multiply by four to five for the number of transceivers in that cluster,” Brashears explained.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s goal is to manufacture a thousand units per day within the year so they can begin qualifying for bulk orders in 2027 and 2028.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The optical transceiver market is dominated by Chinese firms and suppliers, and Mesh sees an advantage in building its supply chain outside of that country. While trade restrictions haven’t impacted the market yet, the founders and their backers see themselves as getting in front of a national security dilemma.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“If AI is the most important technology in several generations (which we believe to be true), to have critical parts of AI data center capex run through misaligned/competitive countries is a problem,” Thrive Partner Philip Clark wrote TechCrunch. “In the immediate term, Mesh is solving our need for better ways to do interconnect if we want to keep scaling AI.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The challenge for Mesh, the founders say, is executing lights-out, automated manufacturing techniques, which aren’t common in U.S. industry. So much of this expertise is concentrated in China that even European equipment suppliers expect Chinese customers — one German firm’s standard intake form asks for a Chinese company registration number.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;By co-locating design and production, the founders hope to realize more efficient and lower-cost components. Their current design removes one commonly used but power-hungry component, which Ramos said could reduce GPU cluster power usage by 3% to 5%, a meaningful amount as hyperscalers seek to wring as much efficiency out of their systems as possible.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Data centers are just the beginning of Mesh’s aspirations; the company sees optical wavelength communications as the next paradigm in communications.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The world has primarily focused on [radio frequencies] for a long time,” Brashears told TechCrunch. “We want to be at the precipice of transition from RF to photonics…we want to interconnect everything, and not just computers, but that’s where we’re starting.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/17/spacex-vets-raise-50m-series-a-for-data-center-links/</guid><pubDate>Tue, 17 Feb 2026 17:00:00 +0000</pubDate></item><item><title>Mistral AI buys Koyeb in first acquisition to back its cloud ambitions (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/17/mistral-ai-buys-koyeb-in-first-acquisition-to-back-its-cloud-ambitions/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2020/10/koyeb-team01.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Mistral AI, the French company last valued at $13.8 billion, has made its first acquisition. The OpenAI competitor has agreed to buy Koyeb, a Paris-based startup that simplifies AI app deployment at scale and manages the infrastructure behind it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mistral has been primarily known for developing large language models (LLMs), but this deal confirms its ambitions to position itself as a full-stack player. In June 2025, it had announced Mistral Compute, an AI cloud infrastructure offering which it now hopes Koyeb will accelerate.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Founded in 2020 by three former employees of French cloud provider Scaleway, Koyeb aimed to help developers process data without worrying about server infrastructure — a concept known as serverless. This approach gained relevance as AI grew more demanding, also inspiring the recent launch of Koyeb Sandboxes, which provide isolated environments to deploy AI agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Before the acquisition, Koyeb’s platform already helped users deploy models from Mistral and others. In a blog post, Koyeb said its platform will continue operating. But its team and technology will now also help Mistral deploy models directly on clients’ own hardware (on premises), optimize its use of GPUs, and help scale AI inference — the process of running a trained AI model to generate responses — according to a press release from Mistral.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As part of the deal, Koyeb’s 13 employees and its three co-founders, Yann Léger, Edouard Bonlieu, and Bastien Chatelard (pictured above in 2020), are set to join the engineering team of Mistral, overseen by CTO and co-founder Timothée Lacroix. Under his leadership, Koyeb expects its platform to transition into a “core component” of Mistral Compute over the coming months.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Koyeb’s product and expertise will accelerate our development on the Compute front, and contribute to building a true AI cloud,” Lacroix wrote in a statement. Mistral has been ramping up its cloud ambitions. Just a few days ago, the company announced a $1.4 billion investment in data centers in Sweden amid growing demand for alternatives to U.S. infrastructure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Koyeb had raised $8.6 million to date, including a $1.6 million pre-seed round in 2020, followed in 2023 by a $7 million seed round led by Paris-based VC firm Serena, whose principal Floriane de Maupeou celebrated the acquisition. For the firm, this combination will play a key role “in building the foundations of sovereign AI infrastructure in Europe,” she told TechCrunch.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In part thanks to these geopolitical tailwinds, but also due to its focus on helping enterprises unlock value from AI, Mistral recently passed the milestone of $400 million in annual recurring revenue. Koyeb, too, will be focused on enterprise clients going forward, and new users will no longer be able to sign up for its Starter tier.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mistral didn’t disclose financial terms of the deal, and it is unknown whether other acquisitions are in the works. But speaking at Stockholm’s Techarena conference last week, CEO Arthur Mensch said Mistral is hiring for infrastructure and other roles, pitching the company to prospective employees as an organization that is “headquartered in Europe, that is doing frontier research in Europe.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2020/10/koyeb-team01.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Mistral AI, the French company last valued at $13.8 billion, has made its first acquisition. The OpenAI competitor has agreed to buy Koyeb, a Paris-based startup that simplifies AI app deployment at scale and manages the infrastructure behind it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mistral has been primarily known for developing large language models (LLMs), but this deal confirms its ambitions to position itself as a full-stack player. In June 2025, it had announced Mistral Compute, an AI cloud infrastructure offering which it now hopes Koyeb will accelerate.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Founded in 2020 by three former employees of French cloud provider Scaleway, Koyeb aimed to help developers process data without worrying about server infrastructure — a concept known as serverless. This approach gained relevance as AI grew more demanding, also inspiring the recent launch of Koyeb Sandboxes, which provide isolated environments to deploy AI agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Before the acquisition, Koyeb’s platform already helped users deploy models from Mistral and others. In a blog post, Koyeb said its platform will continue operating. But its team and technology will now also help Mistral deploy models directly on clients’ own hardware (on premises), optimize its use of GPUs, and help scale AI inference — the process of running a trained AI model to generate responses — according to a press release from Mistral.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As part of the deal, Koyeb’s 13 employees and its three co-founders, Yann Léger, Edouard Bonlieu, and Bastien Chatelard (pictured above in 2020), are set to join the engineering team of Mistral, overseen by CTO and co-founder Timothée Lacroix. Under his leadership, Koyeb expects its platform to transition into a “core component” of Mistral Compute over the coming months.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Koyeb’s product and expertise will accelerate our development on the Compute front, and contribute to building a true AI cloud,” Lacroix wrote in a statement. Mistral has been ramping up its cloud ambitions. Just a few days ago, the company announced a $1.4 billion investment in data centers in Sweden amid growing demand for alternatives to U.S. infrastructure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Koyeb had raised $8.6 million to date, including a $1.6 million pre-seed round in 2020, followed in 2023 by a $7 million seed round led by Paris-based VC firm Serena, whose principal Floriane de Maupeou celebrated the acquisition. For the firm, this combination will play a key role “in building the foundations of sovereign AI infrastructure in Europe,” she told TechCrunch.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In part thanks to these geopolitical tailwinds, but also due to its focus on helping enterprises unlock value from AI, Mistral recently passed the milestone of $400 million in annual recurring revenue. Koyeb, too, will be focused on enterprise clients going forward, and new users will no longer be able to sign up for its Starter tier.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mistral didn’t disclose financial terms of the deal, and it is unknown whether other acquisitions are in the works. But speaking at Stockholm’s Techarena conference last week, CEO Arthur Mensch said Mistral is hiring for infrastructure and other roles, pitching the company to prospective employees as an organization that is “headquartered in Europe, that is doing frontier research in Europe.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/17/mistral-ai-buys-koyeb-in-first-acquisition-to-back-its-cloud-ambitions/</guid><pubDate>Tue, 17 Feb 2026 17:22:09 +0000</pubDate></item><item><title>Anthropic releases Sonnet 4.6 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/17/anthropic-releases-sonnet-4-6/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/Claude-Chrome-Ext_email-hero-hero.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic has released a new version of its midsized Sonnet model, keeping pace with the company’s four-month update cycle. In a post announcing the new model, Anthropic emphasized improvements in coding, instruction-following, and computer use.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sonnet 4.6 will be the default model for Free and Pro plan users.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The beta release of Sonnet 4.6 will include a context window of 1 million tokens, twice the size of the largest window previously available for Sonnet. Anthropic described the new context window as “enough to hold entire codebases, lengthy contracts, or dozens of research papers in a single request.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The release comes just two weeks after the launch of Opus 4.6, with an updated Haiku model likely to follow in the coming weeks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch comes with a new set of record benchmark scores, including OS World for computer use and SWE-Bench for software engineering. But perhaps the most impressive is its 60.4% score on ARC-AGI-2, meant to measure skills specific to human intelligence. The score puts Sonnet 4.6 above most comparable models, although it still trails models like Opus 4.6, Gemini 3 Deep Think, and one refined version of GPT 5.2.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/Claude-Chrome-Ext_email-hero-hero.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic has released a new version of its midsized Sonnet model, keeping pace with the company’s four-month update cycle. In a post announcing the new model, Anthropic emphasized improvements in coding, instruction-following, and computer use.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sonnet 4.6 will be the default model for Free and Pro plan users.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The beta release of Sonnet 4.6 will include a context window of 1 million tokens, twice the size of the largest window previously available for Sonnet. Anthropic described the new context window as “enough to hold entire codebases, lengthy contracts, or dozens of research papers in a single request.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The release comes just two weeks after the launch of Opus 4.6, with an updated Haiku model likely to follow in the coming weeks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch comes with a new set of record benchmark scores, including OS World for computer use and SWE-Bench for software engineering. But perhaps the most impressive is its 60.4% score on ARC-AGI-2, meant to measure skills specific to human intelligence. The score puts Sonnet 4.6 above most comparable models, although it still trails models like Opus 4.6, Gemini 3 Deep Think, and one refined version of GPT 5.2.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/17/anthropic-releases-sonnet-4-6/</guid><pubDate>Tue, 17 Feb 2026 18:00:00 +0000</pubDate></item><item><title>[NEW] Apple is reportedly cooking up a trio of AI wearables (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/17/apple-is-reportedly-cooking-up-a-trio-of-ai-wearables/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/tim-cook-speaking-GettyImages-2234517834.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Late last month, The Information reported that Apple was developing an AI wearable — an AirTag-sized pendant with cameras that could be pinned to a user’s shirt. Now, Bloomberg writes that the development of such a device — along with two other AI-powered items — is accelerating as Apple looks to stay competitive with other tech giants that are racing to release similar products.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to the AI pin, Apple is also speeding up the development of its upcoming AI-powered smart glasses, which have been code-named N50, the report claims. Apple obviously has competition in this space, as other companies — including Meta (which is arguably the most successful player when it comes to smart glasses) and Snap (which plans to release its “Specs” later this year) — are working on similar products.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Apple’s new smart glasses, which will supposedly include a high-resolution camera, may see a public release sooner rather than later, with Bloomberg reporting that the company is “targeting the start of production as early as December, ahead of a public release in 2027.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Additionally, Bloomberg reports that Apple is working on AirPods with new AI capabilities.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;All of these items will be designed to connect to the iPhone and will include Siri, the company’s virtual assistant, as a critical component of the user experience, the outlet notes. The glasses are being described as “more upscale and feature-rich” than the AirPods and the AI pendant, however. TechCrunch reached out to Apple for more information.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/tim-cook-speaking-GettyImages-2234517834.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Late last month, The Information reported that Apple was developing an AI wearable — an AirTag-sized pendant with cameras that could be pinned to a user’s shirt. Now, Bloomberg writes that the development of such a device — along with two other AI-powered items — is accelerating as Apple looks to stay competitive with other tech giants that are racing to release similar products.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to the AI pin, Apple is also speeding up the development of its upcoming AI-powered smart glasses, which have been code-named N50, the report claims. Apple obviously has competition in this space, as other companies — including Meta (which is arguably the most successful player when it comes to smart glasses) and Snap (which plans to release its “Specs” later this year) — are working on similar products.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Apple’s new smart glasses, which will supposedly include a high-resolution camera, may see a public release sooner rather than later, with Bloomberg reporting that the company is “targeting the start of production as early as December, ahead of a public release in 2027.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Additionally, Bloomberg reports that Apple is working on AirPods with new AI capabilities.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;All of these items will be designed to connect to the iPhone and will include Siri, the company’s virtual assistant, as a critical component of the user experience, the outlet notes. The glasses are being described as “more upscale and feature-rich” than the AirPods and the AI pendant, however. TechCrunch reached out to Apple for more information.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/17/apple-is-reportedly-cooking-up-a-trio-of-ai-wearables/</guid><pubDate>Tue, 17 Feb 2026 20:14:00 +0000</pubDate></item><item><title>[NEW] Teaching AI to read a map (The latest research from Google)</title><link>https://research.google/blog/teaching-ai-to-read-a-map/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;The pipeline works in four automated and scalable stages, using AI models as both creators and critics to ensure quality and produce pixel-level annotations.&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. Generating diverse maps&lt;/b&gt;&lt;/p&gt;&lt;p&gt;First, we use a large language model (LLM) to generate rich, descriptive prompts for different types of maps. The LLM generates everything from "a map of a zoo with interconnected habitats" to "a shopping mall with a central food court" or "a fantasy theme park with winding paths through different themed lands." These text prompts are then fed into a text-to-image model that renders them into complex map images.&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. Identifying traversable paths with an AI "Mask Critic"&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Once we have a map image, we need to identify all the "walkable" areas. Our system does this by clustering the pixels by color to create candidate path masks — essentially, a black-and-white map of all the walkways.&lt;/p&gt;&lt;p&gt;But not every shaded region is a valid path. So, we employ another MLLM as a "Mask Critic” used to examine each candidate mask and judge whether it represents a realistic, connected network of paths by looking at both the map image and the mask candidate. If the MLLM identifies the mask candidate as containing mostly valid traversable regions (e.g., paved sidewalks, marked crosswalks, pedestrian-only paths), then it labels the candidate as high quality. Then only these high-quality masks are passed to the next stage.&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. Building a navigable graph&lt;/b&gt;&lt;/p&gt;&lt;p&gt;With a clean mask of all traversable areas, we convert that 2D image into a more structured graph format. Think of this as creating a digital version of a road network, where intersections are nodes and the roads between them are edges. This "pixel-graph" captures the connectivity of the map, making it easy to calculate routes computationally.&lt;/p&gt;&lt;p&gt;&lt;b&gt;4. Generating perfect paths with an AI "Path Critic"&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Finally, we sample thousands of random start and end points on the graph for each map. We use a classic Dijkstra's algorithm to find the absolute shortest path between these points. Then, we use another MLLM as a "Path Critic" to perform a final quality check. This critic looks at the final generated path overlaid on the map image and gives it a thumbs-up or thumbs-down, ensuring the route is logical, stays within the lines, and looks like a path a human would take.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;The pipeline works in four automated and scalable stages, using AI models as both creators and critics to ensure quality and produce pixel-level annotations.&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. Generating diverse maps&lt;/b&gt;&lt;/p&gt;&lt;p&gt;First, we use a large language model (LLM) to generate rich, descriptive prompts for different types of maps. The LLM generates everything from "a map of a zoo with interconnected habitats" to "a shopping mall with a central food court" or "a fantasy theme park with winding paths through different themed lands." These text prompts are then fed into a text-to-image model that renders them into complex map images.&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. Identifying traversable paths with an AI "Mask Critic"&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Once we have a map image, we need to identify all the "walkable" areas. Our system does this by clustering the pixels by color to create candidate path masks — essentially, a black-and-white map of all the walkways.&lt;/p&gt;&lt;p&gt;But not every shaded region is a valid path. So, we employ another MLLM as a "Mask Critic” used to examine each candidate mask and judge whether it represents a realistic, connected network of paths by looking at both the map image and the mask candidate. If the MLLM identifies the mask candidate as containing mostly valid traversable regions (e.g., paved sidewalks, marked crosswalks, pedestrian-only paths), then it labels the candidate as high quality. Then only these high-quality masks are passed to the next stage.&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. Building a navigable graph&lt;/b&gt;&lt;/p&gt;&lt;p&gt;With a clean mask of all traversable areas, we convert that 2D image into a more structured graph format. Think of this as creating a digital version of a road network, where intersections are nodes and the roads between them are edges. This "pixel-graph" captures the connectivity of the map, making it easy to calculate routes computationally.&lt;/p&gt;&lt;p&gt;&lt;b&gt;4. Generating perfect paths with an AI "Path Critic"&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Finally, we sample thousands of random start and end points on the graph for each map. We use a classic Dijkstra's algorithm to find the absolute shortest path between these points. Then, we use another MLLM as a "Path Critic" to perform a final quality check. This critic looks at the final generated path overlaid on the map image and gives it a thumbs-up or thumbs-down, ensuring the route is logical, stays within the lines, and looks like a path a human would take.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/teaching-ai-to-read-a-map/</guid><pubDate>Tue, 17 Feb 2026 21:37:00 +0000</pubDate></item><item><title>[NEW] NVIDIA Nemotron 2 Nano 9B Japanese: 日本のソブリンAIを支える最先端小規模言語モデル (Hugging Face - Blog)</title><link>https://huggingface.co/blog/nvidia/nemotron-nano-9b-v2-japanese-ja</link><description>&lt;div class="not-prose mb-6 font-sans lg:hidden"&gt;&lt;div class="SVELTE_HYDRATER contents"&gt;&lt;div class="flex flex-wrap items-center gap-2.5 pt-1  z-1 lg:sticky lg:top-8"&gt;
	


	&lt;ul class="flex items-center text-gray-600  flex-row  text-base   "&gt;&lt;li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800 " title="suhara"&gt;&lt;img alt="alt" class="overflow-hidden rounded-full" src="https://huggingface.co/avatars/311461de0933d7e4a8a222d0e76f3754.svg" /&gt;
					
			&lt;/li&gt;&lt;li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800 " title="Atsunori"&gt;&lt;img alt="alt" class="overflow-hidden rounded-full" src="https://cdn-avatars.huggingface.co/v1/production/uploads/1615517039409-noauth.jpeg" /&gt;
					
			&lt;/li&gt;

		&lt;li class="text-xs hover:text-gray-700 dark:text-gray-400 dark:hover:text-gray-300 order-last ml-3"&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;

&lt;dialog class="shadow-alternate z-40 mx-4 my-auto h-fit select-text overflow-hidden rounded-xl bg-white max-sm:max-w-[calc(100dvw-2rem)] sm:mx-auto lg:mt-26 md:portrait:mt-30 xl:mt-30 2xl:mt-32 w-full sm:w-96 max-w-[calc(100%-4rem)] text-base not-prose"&gt;
	&lt;/dialog&gt;&lt;/div&gt;&lt;/div&gt;
					
					

					&lt;!-- HTML_TAG_START --&gt;
NVIDIA Nemotronは、オープンモデルだけでなく、データセット、ライブラリ、レシピ、クックブックを提供し、開発者がモデルをカスタマイズし、多様なユースケースや言語に適応できるようにすることでソブリンAIを推進しています。
&lt;p&gt;本日、NVIDIAは、Nejumi Leaderboard 4のパラメータ数10B以下において、最先端の性能（SOTA）を達成した NVIDIA Nemotron-Nano-9B-v2-Japaneseを公開しました。&lt;/p&gt;
&lt;p&gt;本モデルは、高度な日本語理解と強力なエージェント機能を、導入しやすい軽量なサイズで実現しており、日本のエンタープライズAI開発における重要なマイルストーンとなります。この成果は、実績あるNemotron-Nano-9B-v2のアーキテクチャと、Nemotron-Personas-Japanによって実現された高品質な日本語合成データ生成（SDG）という、2つの重要な基盤の上に築かれています。&lt;/p&gt;
&lt;p&gt;既に公開済みのNemotron 2 Nanoモデルを日本語向けにカスタマイズすることで、多様なユースケースや言語に対応したカスタム最先端モデルの開発・公開をコミュニティに促すことを目指しています。Nemotronチームは、このカスタマイズから得た知見を今後のNemotronリリースに反映し、日本語における推論能力の強化を図っています。&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		&lt;strong&gt;日本のエンタープライズにおけるSLM（小規模言語モデル）の重要性&lt;/strong&gt;
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;日本のエンタープライズAIにおける重要なギャップ:&lt;/strong&gt; 現在の日本のエンタープライズAI環境には、「高度な日本語能力」と「エージェンティックAIとしてのタスク遂行能力」を兼ね備えたSLMがほとんど存在しないという課題があります。これにより、特に以下の点において導入の障壁が生じています。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;オンプレミスでのデプロイ要件:&lt;/strong&gt; 機密データを扱う企業では、プライベートネットワーク内でのモデル運用が不可欠です。10B（100億）パラメータ未満のモデルであれば、実用レベルの性能を維持しつつ、インフラ面の導入ハードルを大幅に下げることができます。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;カスタマイズの効率化:&lt;/strong&gt; 実証済みのエージェント能力を持つ強力な日本語ベースモデルから開始することで、ファインチューニングのサイクルを短縮できます。基礎能力の構築ではなく、特定のドメインへの適応に計算リソースを集中させることが可能になります。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;エージェント開発の加速:&lt;/strong&gt; 本モデルのアーキテクチャと性能により、大規模モデルのようなオーバーヘッドなしに、マルチエージェントシステムや複雑なワークフローの迅速なプロトタイピングが可能になります。&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		&lt;strong&gt;実績ある基盤の活用&lt;/strong&gt;
	&lt;/span&gt;
&lt;/h2&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Nemotron 2 Nano: 卓越したアーキテクチャ
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;Nemotron-Nano-9B-v2-Japanese は、英語ベンチマークにおいてサイズ対性能比で卓越した結果を示した NVIDIA Nemotron-Nano-9B-v2 をベースに構築されています。この効率的なアーキテクチャを基盤としてさらなるカスタマイズを実施し、日本語能力を強化しました。本アーキテクチャには以下の特長があります。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;高度な推論能力を実現と最適化されたパラメータ効率  &lt;/li&gt;
&lt;li&gt;多言語適応のための強固な基盤  &lt;/li&gt;
&lt;li&gt;実証済みのエージェントタスク遂行能力&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;この検証済みのアーキテクチャを日本語に適応させることで、ベースモデルの強みを維持しつつ、優れた日本語能力を実現しています。&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Nemotron-Personas-Japan: 高品質な合成データ生成のシードセット
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;本モデルのデータ戦略は、オープンソース（CC BY 4.0）データセットである「Nemotron-Personas-Japan」を、合成データ生成（SDG）の高品質なシードとして活用することに焦点を当てています。このデータセットは、日本の実世界における人口統計、地理的分布、性格特性の分布に基づき合成生成されたペルソナで構成され、人口の多様性と豊かさを捉えています。こうした文化的に正確なペルソナを基盤として、高度に多様性があり、拡張性・堅牢性に優れたトレーニングパイプラインを構築しました。シードデータの豊富なペルソナ群により、多様なシナリオやニュアンスにわたる合成データセットを効率的に拡張できました。この手法により、拡張データは元のペルソナの厳密な文化的整合性を維持しつつ、最先端トレーニングに必要な規模を達成しています。&lt;/p&gt;
&lt;p&gt;特にNemotron-Nano-9B-v2-Japaneseでは、これらのペルソナをツール呼び出しシナリオにおけるトレーニングデータの生成基盤として活用しました。これにより、モデルが獲得する能力が単なるツール呼び出し機能にとどまらず、文化的に適切な日本語の対話と現実世界のユースケースに根差したものであることが保証されます。&lt;/p&gt;
&lt;p&gt;Nemotron-Personas collectionには、米国、インド、シンガポール、ブラジルのデータセットも含まれており、同じ手法を地域を超えて再現することが可能となっています。&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		&lt;strong&gt;トレーニングパイプライン&lt;/strong&gt;
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Nemotron-Nano-9B-v2-Japaneseは、継続事前学習、合成データ生成、事後学習に至るプロセスを日本語オープンソースコーパスとNVIDIAのNemotronスタックを組み合わせて構築されました。&lt;/p&gt;
&lt;p&gt;&lt;img alt="training_diagram" src="https://cdn-uploads.huggingface.co/production/uploads/5fc181c4ea82dd667bb0ffae/uxrGpZ29BTHqQeD0_WQ5I.png" /&gt;&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		継続事前学習
	&lt;/span&gt;
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Japanese OSS Corpus: Wikipedia, fineweb-2 Japanese, aozorabunko, sip3-ja-general-web-corpus  &lt;/li&gt;
&lt;li&gt;Nemotron-CC-v2.1  &lt;/li&gt;
&lt;li&gt;Nemotron-Pretraining-Specialized-v1&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		SFT
	&lt;/span&gt;
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Nemotron-Personas-JapanをシードセットとしたTool Callingデータセット  &lt;/li&gt;
&lt;li&gt;Nemotron-Post-Training-v3&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Nemotron-Nano-9B-v2-Japaneseに使用したソフトウェア
	&lt;/span&gt;
&lt;/h3&gt;

&lt;p&gt;モデルの日本語能力を最大化するため、継続事前学習を実施しました。ここでは日本を代表するオープンソースLLMコミュニティである LLM-jp の資産を最大限に活用しています。同時にNemotron Pre-training Datasetsを活用し、モデルのエージェント機能を維持しました。&lt;/p&gt;
&lt;p&gt;SFTに使用したNemotron-Personas-JapanをシードとしたTool Callingデータセットは非常に強力でした。性能向上はツール呼び出しに留まらず、日本語知識、QA、指示追従など多岐に渡りました。さらに、このシードセットが600万のペルソナに基づいて構築されているため、SDGを効果的にスケールさせることができました。これにより、重複を最小限に抑えながら、現実世界の多様なシナリオを網羅することに成功しました。Nemotron-Personasコレクションは対象国を拡大しており、日本だけでなく他地域の開発者も同様のアプローチをとることができます。&lt;/p&gt;
&lt;p&gt;モデルのトレーニングは、Nemotron Nano 2で確立されたトレーニングレシピを継承しています。これにより、トレーニングの不安定性を招くことなくスループットを向上させることができました。&lt;/p&gt;
&lt;p&gt;このアプローチによって、ロバストなツール呼び出し機能とリーズニング能力を維持しながら強力な日本語言語モデルとしての性能を実現しています。&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		&lt;strong&gt;ベンチマークパフォーマンス&lt;/strong&gt;
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;&lt;img alt="leaderboard" src="https://cdn-uploads.huggingface.co/production/uploads/5fc181c4ea82dd667bb0ffae/5nuxnXClbAR3GI76KiG51.png" /&gt;&lt;/p&gt;
&lt;p&gt;Nemotron-Nano-9B-v2-Japanese は、日本で最も包括的なLLM評価プラットフォームである「Nejumi Leaderboard 4」において、10B未満のモデルカテゴリで1位を獲得しました。Nejumi Leaderboard は、以下の領域にわたる約40のベンチマークを通じてモデルを多角的に評価しています。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基礎的な言語能力: 日本語の理解と生成  &lt;/li&gt;
&lt;li&gt;エージェント能力: コード生成、数学的推論、ツール利用など  &lt;/li&gt;
&lt;li&gt;アライメント: 指示追従能力、バイアス、毒性、真実性、堅牢性など&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;これらの多次元的な評価により、Nejumi Leaderboard は、日本の環境においてカスタマイズや実運用のためのベースモデルを選定する開発者にとって、信頼できるリファレンスとなっています。&lt;/p&gt;
&lt;p&gt;&lt;img alt="benchmark_summary" src="https://cdn-uploads.huggingface.co/production/uploads/5fc181c4ea82dd667bb0ffae/MfwBo6rVX4MrmsI_8kQpa.png" /&gt;&lt;/p&gt;
&lt;p&gt;ベンチマークの結果は、Nemotron-Nano-9B-v2-Japanese がベースモデルである Nemotron-Nano-9B-v2 に強力な日本語能力を統合できたことを確認できます。これらの改善は、日本語の知識や質問応答能力にとどまらず、ツール呼び出し、コーディング、アライメントなど幅広いタスクに及びます。特筆すべきは、同等サイズの Qwen3-8B を上回り、優れたサイズ対性能比を実現している点です。&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		&lt;strong&gt;技術的優位性&lt;/strong&gt;
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;&lt;img alt="throughput" src="https://cdn-uploads.huggingface.co/production/uploads/5fc181c4ea82dd667bb0ffae/Jozble7RW6oSDRU9ietBv.png" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;推論の効率性: Nemotron 2 Nano（Transformer-Mamba）のアーキテクチャを継承することで、エッジGPUにデプロイ可能でありながら、オープンソースの代替モデルと比較して最大6倍のスループット向上を実現します。上の図は、Nemotron 2 Nanoの論文で測定された結果を示しています。  &lt;/li&gt;
&lt;li&gt;コンテキスト処理: 複数回（マルチターン）の会話やツール操作に最適化されています。  &lt;/li&gt;
&lt;li&gt;ツール呼び出しの信頼性: API呼び出しや関数実行のために、強力な構造化データ生成能力を備えています。  &lt;/li&gt;
&lt;li&gt;ファインチューニングの効率性: 手頃な計算インフラでもフルファインチューニングが可能なパラメータ数です。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		&lt;strong&gt;デプロイのオプション&lt;/strong&gt;
	&lt;/span&gt;
&lt;/h2&gt;
&lt;h4 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		直接デプロイ
	&lt;/span&gt;
&lt;/h4&gt;
&lt;p&gt;高い日本語理解とエージェンティックスキルを必要とするアプリケーションではモデルをそのままデプロイして活用できます。すでに学習済みの能力により、エージェントワークフローへの即時統合をサポートします。Nemotron 2 Nanoでサポートされている推論エンジンはシームレスに移行できます。&lt;/p&gt;
&lt;h4 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		独自ドメインへのカスタマイズ
	&lt;/span&gt;
&lt;/h4&gt;
&lt;p&gt;特定のドメインに特化したファインチューニングのベースとして、Nemotron-Nano-9B-v2-Japaneseを利用できます。ベンチマークで実証された日本語およびエージェンティックタスクでの良い性能は、専門的なアプリケーション開発のための強固な開始点となります。カスタマイズにはNeMo Framework（NeMo Megatron-Bridge, NeMo AutoModel, and NeMo-RL）をご利用いただけます。&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		&lt;strong&gt;今すぐ使ってください&lt;/strong&gt;
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;日本のAIアプリケーション開発者の皆様は、今すぐ Nemotron-Nano-9B-v2-Japanese をご利用いただけます。顧客対応エージェント、社内自動化ツール、あるいはドメイン特化型アシスタントなど、どのような用途であっても、本モデルは実運用へのデプロイに求められる優れたサイズ対性能比を提供します。&lt;/p&gt;
&lt;p&gt;Nemotron 2 Nanoの実績あるアーキテクチャと、高品質なデータセットのシードとなる Nemotron-Personas-Japan の組み合わせは、日本のソブリンAI開発における効率的な出発点となるでしょう。&lt;/p&gt;
&lt;p&gt;コミュニティの皆様に、Nemotronモデル、データセット、レシピ、ライブラリをぜひご活用いただき、さらに多くの言語やユースケース向けにNemotronモデルをカスタマイズしていただくことを歓迎します。皆様がどのようなものを構築されるか、楽しみにしています！&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Stay up to date on NVIDIA Nemotron by subscribing to NVIDIA news and following NVIDIA AI on LinkedIn, X, YouTube&lt;/em&gt;, &lt;em&gt;and the Nemotron channel on Discord.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Access open Nemotron Models on Hugging Face and a collection of NIM microservices and Developer Examples on build.nvidia.com.&lt;/em&gt; &lt;/p&gt;
&lt;!-- HTML_TAG_END --&gt;</description><content:encoded>&lt;div class="not-prose mb-6 font-sans lg:hidden"&gt;&lt;div class="SVELTE_HYDRATER contents"&gt;&lt;div class="flex flex-wrap items-center gap-2.5 pt-1  z-1 lg:sticky lg:top-8"&gt;
	


	&lt;ul class="flex items-center text-gray-600  flex-row  text-base   "&gt;&lt;li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800 " title="suhara"&gt;&lt;img alt="alt" class="overflow-hidden rounded-full" src="https://huggingface.co/avatars/311461de0933d7e4a8a222d0e76f3754.svg" /&gt;
					
			&lt;/li&gt;&lt;li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800 " title="Atsunori"&gt;&lt;img alt="alt" class="overflow-hidden rounded-full" src="https://cdn-avatars.huggingface.co/v1/production/uploads/1615517039409-noauth.jpeg" /&gt;
					
			&lt;/li&gt;

		&lt;li class="text-xs hover:text-gray-700 dark:text-gray-400 dark:hover:text-gray-300 order-last ml-3"&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;

&lt;dialog class="shadow-alternate z-40 mx-4 my-auto h-fit select-text overflow-hidden rounded-xl bg-white max-sm:max-w-[calc(100dvw-2rem)] sm:mx-auto lg:mt-26 md:portrait:mt-30 xl:mt-30 2xl:mt-32 w-full sm:w-96 max-w-[calc(100%-4rem)] text-base not-prose"&gt;
	&lt;/dialog&gt;&lt;/div&gt;&lt;/div&gt;
					
					

					&lt;!-- HTML_TAG_START --&gt;
NVIDIA Nemotronは、オープンモデルだけでなく、データセット、ライブラリ、レシピ、クックブックを提供し、開発者がモデルをカスタマイズし、多様なユースケースや言語に適応できるようにすることでソブリンAIを推進しています。
&lt;p&gt;本日、NVIDIAは、Nejumi Leaderboard 4のパラメータ数10B以下において、最先端の性能（SOTA）を達成した NVIDIA Nemotron-Nano-9B-v2-Japaneseを公開しました。&lt;/p&gt;
&lt;p&gt;本モデルは、高度な日本語理解と強力なエージェント機能を、導入しやすい軽量なサイズで実現しており、日本のエンタープライズAI開発における重要なマイルストーンとなります。この成果は、実績あるNemotron-Nano-9B-v2のアーキテクチャと、Nemotron-Personas-Japanによって実現された高品質な日本語合成データ生成（SDG）という、2つの重要な基盤の上に築かれています。&lt;/p&gt;
&lt;p&gt;既に公開済みのNemotron 2 Nanoモデルを日本語向けにカスタマイズすることで、多様なユースケースや言語に対応したカスタム最先端モデルの開発・公開をコミュニティに促すことを目指しています。Nemotronチームは、このカスタマイズから得た知見を今後のNemotronリリースに反映し、日本語における推論能力の強化を図っています。&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		&lt;strong&gt;日本のエンタープライズにおけるSLM（小規模言語モデル）の重要性&lt;/strong&gt;
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;日本のエンタープライズAIにおける重要なギャップ:&lt;/strong&gt; 現在の日本のエンタープライズAI環境には、「高度な日本語能力」と「エージェンティックAIとしてのタスク遂行能力」を兼ね備えたSLMがほとんど存在しないという課題があります。これにより、特に以下の点において導入の障壁が生じています。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;オンプレミスでのデプロイ要件:&lt;/strong&gt; 機密データを扱う企業では、プライベートネットワーク内でのモデル運用が不可欠です。10B（100億）パラメータ未満のモデルであれば、実用レベルの性能を維持しつつ、インフラ面の導入ハードルを大幅に下げることができます。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;カスタマイズの効率化:&lt;/strong&gt; 実証済みのエージェント能力を持つ強力な日本語ベースモデルから開始することで、ファインチューニングのサイクルを短縮できます。基礎能力の構築ではなく、特定のドメインへの適応に計算リソースを集中させることが可能になります。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;エージェント開発の加速:&lt;/strong&gt; 本モデルのアーキテクチャと性能により、大規模モデルのようなオーバーヘッドなしに、マルチエージェントシステムや複雑なワークフローの迅速なプロトタイピングが可能になります。&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		&lt;strong&gt;実績ある基盤の活用&lt;/strong&gt;
	&lt;/span&gt;
&lt;/h2&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Nemotron 2 Nano: 卓越したアーキテクチャ
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;Nemotron-Nano-9B-v2-Japanese は、英語ベンチマークにおいてサイズ対性能比で卓越した結果を示した NVIDIA Nemotron-Nano-9B-v2 をベースに構築されています。この効率的なアーキテクチャを基盤としてさらなるカスタマイズを実施し、日本語能力を強化しました。本アーキテクチャには以下の特長があります。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;高度な推論能力を実現と最適化されたパラメータ効率  &lt;/li&gt;
&lt;li&gt;多言語適応のための強固な基盤  &lt;/li&gt;
&lt;li&gt;実証済みのエージェントタスク遂行能力&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;この検証済みのアーキテクチャを日本語に適応させることで、ベースモデルの強みを維持しつつ、優れた日本語能力を実現しています。&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Nemotron-Personas-Japan: 高品質な合成データ生成のシードセット
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;本モデルのデータ戦略は、オープンソース（CC BY 4.0）データセットである「Nemotron-Personas-Japan」を、合成データ生成（SDG）の高品質なシードとして活用することに焦点を当てています。このデータセットは、日本の実世界における人口統計、地理的分布、性格特性の分布に基づき合成生成されたペルソナで構成され、人口の多様性と豊かさを捉えています。こうした文化的に正確なペルソナを基盤として、高度に多様性があり、拡張性・堅牢性に優れたトレーニングパイプラインを構築しました。シードデータの豊富なペルソナ群により、多様なシナリオやニュアンスにわたる合成データセットを効率的に拡張できました。この手法により、拡張データは元のペルソナの厳密な文化的整合性を維持しつつ、最先端トレーニングに必要な規模を達成しています。&lt;/p&gt;
&lt;p&gt;特にNemotron-Nano-9B-v2-Japaneseでは、これらのペルソナをツール呼び出しシナリオにおけるトレーニングデータの生成基盤として活用しました。これにより、モデルが獲得する能力が単なるツール呼び出し機能にとどまらず、文化的に適切な日本語の対話と現実世界のユースケースに根差したものであることが保証されます。&lt;/p&gt;
&lt;p&gt;Nemotron-Personas collectionには、米国、インド、シンガポール、ブラジルのデータセットも含まれており、同じ手法を地域を超えて再現することが可能となっています。&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		&lt;strong&gt;トレーニングパイプライン&lt;/strong&gt;
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Nemotron-Nano-9B-v2-Japaneseは、継続事前学習、合成データ生成、事後学習に至るプロセスを日本語オープンソースコーパスとNVIDIAのNemotronスタックを組み合わせて構築されました。&lt;/p&gt;
&lt;p&gt;&lt;img alt="training_diagram" src="https://cdn-uploads.huggingface.co/production/uploads/5fc181c4ea82dd667bb0ffae/uxrGpZ29BTHqQeD0_WQ5I.png" /&gt;&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		継続事前学習
	&lt;/span&gt;
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Japanese OSS Corpus: Wikipedia, fineweb-2 Japanese, aozorabunko, sip3-ja-general-web-corpus  &lt;/li&gt;
&lt;li&gt;Nemotron-CC-v2.1  &lt;/li&gt;
&lt;li&gt;Nemotron-Pretraining-Specialized-v1&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		SFT
	&lt;/span&gt;
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Nemotron-Personas-JapanをシードセットとしたTool Callingデータセット  &lt;/li&gt;
&lt;li&gt;Nemotron-Post-Training-v3&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Nemotron-Nano-9B-v2-Japaneseに使用したソフトウェア
	&lt;/span&gt;
&lt;/h3&gt;

&lt;p&gt;モデルの日本語能力を最大化するため、継続事前学習を実施しました。ここでは日本を代表するオープンソースLLMコミュニティである LLM-jp の資産を最大限に活用しています。同時にNemotron Pre-training Datasetsを活用し、モデルのエージェント機能を維持しました。&lt;/p&gt;
&lt;p&gt;SFTに使用したNemotron-Personas-JapanをシードとしたTool Callingデータセットは非常に強力でした。性能向上はツール呼び出しに留まらず、日本語知識、QA、指示追従など多岐に渡りました。さらに、このシードセットが600万のペルソナに基づいて構築されているため、SDGを効果的にスケールさせることができました。これにより、重複を最小限に抑えながら、現実世界の多様なシナリオを網羅することに成功しました。Nemotron-Personasコレクションは対象国を拡大しており、日本だけでなく他地域の開発者も同様のアプローチをとることができます。&lt;/p&gt;
&lt;p&gt;モデルのトレーニングは、Nemotron Nano 2で確立されたトレーニングレシピを継承しています。これにより、トレーニングの不安定性を招くことなくスループットを向上させることができました。&lt;/p&gt;
&lt;p&gt;このアプローチによって、ロバストなツール呼び出し機能とリーズニング能力を維持しながら強力な日本語言語モデルとしての性能を実現しています。&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		&lt;strong&gt;ベンチマークパフォーマンス&lt;/strong&gt;
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;&lt;img alt="leaderboard" src="https://cdn-uploads.huggingface.co/production/uploads/5fc181c4ea82dd667bb0ffae/5nuxnXClbAR3GI76KiG51.png" /&gt;&lt;/p&gt;
&lt;p&gt;Nemotron-Nano-9B-v2-Japanese は、日本で最も包括的なLLM評価プラットフォームである「Nejumi Leaderboard 4」において、10B未満のモデルカテゴリで1位を獲得しました。Nejumi Leaderboard は、以下の領域にわたる約40のベンチマークを通じてモデルを多角的に評価しています。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基礎的な言語能力: 日本語の理解と生成  &lt;/li&gt;
&lt;li&gt;エージェント能力: コード生成、数学的推論、ツール利用など  &lt;/li&gt;
&lt;li&gt;アライメント: 指示追従能力、バイアス、毒性、真実性、堅牢性など&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;これらの多次元的な評価により、Nejumi Leaderboard は、日本の環境においてカスタマイズや実運用のためのベースモデルを選定する開発者にとって、信頼できるリファレンスとなっています。&lt;/p&gt;
&lt;p&gt;&lt;img alt="benchmark_summary" src="https://cdn-uploads.huggingface.co/production/uploads/5fc181c4ea82dd667bb0ffae/MfwBo6rVX4MrmsI_8kQpa.png" /&gt;&lt;/p&gt;
&lt;p&gt;ベンチマークの結果は、Nemotron-Nano-9B-v2-Japanese がベースモデルである Nemotron-Nano-9B-v2 に強力な日本語能力を統合できたことを確認できます。これらの改善は、日本語の知識や質問応答能力にとどまらず、ツール呼び出し、コーディング、アライメントなど幅広いタスクに及びます。特筆すべきは、同等サイズの Qwen3-8B を上回り、優れたサイズ対性能比を実現している点です。&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		&lt;strong&gt;技術的優位性&lt;/strong&gt;
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;&lt;img alt="throughput" src="https://cdn-uploads.huggingface.co/production/uploads/5fc181c4ea82dd667bb0ffae/Jozble7RW6oSDRU9ietBv.png" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;推論の効率性: Nemotron 2 Nano（Transformer-Mamba）のアーキテクチャを継承することで、エッジGPUにデプロイ可能でありながら、オープンソースの代替モデルと比較して最大6倍のスループット向上を実現します。上の図は、Nemotron 2 Nanoの論文で測定された結果を示しています。  &lt;/li&gt;
&lt;li&gt;コンテキスト処理: 複数回（マルチターン）の会話やツール操作に最適化されています。  &lt;/li&gt;
&lt;li&gt;ツール呼び出しの信頼性: API呼び出しや関数実行のために、強力な構造化データ生成能力を備えています。  &lt;/li&gt;
&lt;li&gt;ファインチューニングの効率性: 手頃な計算インフラでもフルファインチューニングが可能なパラメータ数です。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		&lt;strong&gt;デプロイのオプション&lt;/strong&gt;
	&lt;/span&gt;
&lt;/h2&gt;
&lt;h4 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		直接デプロイ
	&lt;/span&gt;
&lt;/h4&gt;
&lt;p&gt;高い日本語理解とエージェンティックスキルを必要とするアプリケーションではモデルをそのままデプロイして活用できます。すでに学習済みの能力により、エージェントワークフローへの即時統合をサポートします。Nemotron 2 Nanoでサポートされている推論エンジンはシームレスに移行できます。&lt;/p&gt;
&lt;h4 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		独自ドメインへのカスタマイズ
	&lt;/span&gt;
&lt;/h4&gt;
&lt;p&gt;特定のドメインに特化したファインチューニングのベースとして、Nemotron-Nano-9B-v2-Japaneseを利用できます。ベンチマークで実証された日本語およびエージェンティックタスクでの良い性能は、専門的なアプリケーション開発のための強固な開始点となります。カスタマイズにはNeMo Framework（NeMo Megatron-Bridge, NeMo AutoModel, and NeMo-RL）をご利用いただけます。&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		&lt;strong&gt;今すぐ使ってください&lt;/strong&gt;
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;日本のAIアプリケーション開発者の皆様は、今すぐ Nemotron-Nano-9B-v2-Japanese をご利用いただけます。顧客対応エージェント、社内自動化ツール、あるいはドメイン特化型アシスタントなど、どのような用途であっても、本モデルは実運用へのデプロイに求められる優れたサイズ対性能比を提供します。&lt;/p&gt;
&lt;p&gt;Nemotron 2 Nanoの実績あるアーキテクチャと、高品質なデータセットのシードとなる Nemotron-Personas-Japan の組み合わせは、日本のソブリンAI開発における効率的な出発点となるでしょう。&lt;/p&gt;
&lt;p&gt;コミュニティの皆様に、Nemotronモデル、データセット、レシピ、ライブラリをぜひご活用いただき、さらに多くの言語やユースケース向けにNemotronモデルをカスタマイズしていただくことを歓迎します。皆様がどのようなものを構築されるか、楽しみにしています！&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Stay up to date on NVIDIA Nemotron by subscribing to NVIDIA news and following NVIDIA AI on LinkedIn, X, YouTube&lt;/em&gt;, &lt;em&gt;and the Nemotron channel on Discord.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Access open Nemotron Models on Hugging Face and a collection of NIM microservices and Developer Examples on build.nvidia.com.&lt;/em&gt; &lt;/p&gt;
&lt;!-- HTML_TAG_END --&gt;</content:encoded><guid isPermaLink="false">https://huggingface.co/blog/nvidia/nemotron-nano-9b-v2-japanese-ja</guid><pubDate>Tue, 17 Feb 2026 23:28:52 +0000</pubDate></item><item><title>[NEW] NVIDIA and Global Industrial Software Leaders Partner With India’s Largest Manufacturers to Drive AI Boom (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/india-global-industrial-software-leaders-manufacturers-ai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/NVIDIA-India-AI-Impact-Summit-Indias-Manufacturers-Drive-AI-Boom-scaled.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;India is entering a new age of industrialization, as AI transforms how the world designs, builds and runs physical products and systems. The country is investing $134 billion dollars in new manufacturing capacity across construction, automotive, renewable energy and robotics, creating both a massive challenge and opportunity to build software-defined factories from day one.&lt;/p&gt;
&lt;p&gt;At the center of this transformation are applications accelerated by NVIDIA CUDA-X and NVIDIA Omniverse libraries, which connect data from design to operations and bring physical AI into factories, warehouses and infrastructure.&lt;/p&gt;
&lt;p&gt;India’s largest manufacturers are teaming with global industrial software leaders Cadence, Siemens and Synopsys to advance the nation’s AI boom using applications accelerated by CUDA-X and Omniverse libraries.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;India’s Manufacturing Leaders Modernize Factories With &lt;/b&gt;&lt;b&gt;Siemens&lt;/b&gt;&lt;b&gt; and NVIDIA&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;To scale India’s growth, manufacturers are using Siemens industrial software integrated with NVIDIA CUDA-X and Omniverse libraries to design, build and operate next-generation, software-defined factories.&lt;/p&gt;
&lt;p&gt;Reliance New Energy, the clean energy arm of Reliance industries, is expanding its collaboration with NVIDIA and Siemens by combining Siemens’ digital twin technology with NVIDIA Omniverse libraries for faster, more precise simulation and plant design for its next-generation gigafactories.&lt;/p&gt;
&lt;p&gt;Addverb Technologies, a leading Indian company providing robots and innovative warehouse automation solutions, is using Siemens’ Technomatix portfolio, NVIDIA Omniverse libraries and NVIDIA Cosmos world foundation models to create digital twins of its factories and train its quadruped and wheeled humanoid robots in simulation.&lt;/p&gt;
&lt;p&gt;Hero MotoCorp is utilizing Siemens Xcelerator and NVIDIA infrastructure to accelerate the product development lifecycle by enhancing its capabilities in computer-aided engineering, numerical virtual verification and validation.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Partners Advance Design and Engineering With NVIDIA-Accelerated Software From &lt;/b&gt;&lt;b&gt;Synopsys&lt;/b&gt;&lt;b&gt; and &lt;/b&gt;&lt;b&gt;Cadence&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Leading enterprises are integrating Synopsys and Cadence’s electronic design automation tools, powered by NVIDIA AI infrastructure and libraries, to enable rapid design iteration and operational intelligence across the energy, automotive and electronics sectors.&lt;/p&gt;
&lt;p&gt;Electrical equipment and home appliances leader Havells India Limited is using Synopsys’ Ansys Fluent to accelerate simulation powered by NVIDIA CUDA-X. Havells has obtained 6x faster fluid dynamic simulations, enabling exploration of more design options to optimize airflow and energy efficiencies, and achieve faster time to market.&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Larsen &amp;amp; Toubro Semiconductor’s application of Cadence Spectre X, accelerated by CUDA-X libraries, on NVIDIA GPUs shortens design iterations of next-generation AI chips.&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;India’s Technology Leaders Advance Industrial Automation With Physical AI&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;India’s IT and business consulting sector has grown into a global powerhouse, projected to reach over $350 billion this year, serving as a primary engine for transforming the world’s largest industries.&lt;/p&gt;
&lt;p&gt;Tata Consultancy Services (TCS), a global leader in IT services, is investing in large-scale AI infrastructure to deliver enterprise solutions at scale. By harnessing the NVIDIA Metropolis platform, the NVIDIA Blueprint for video search and summarization and digital twins built on Omniverse libraries, TCS is setting safety and precision benchmarks at Tata Motors, converting standard camera feeds into intelligent sensors for automated quality checks and real-time safety compliance.&lt;/p&gt;
&lt;p&gt;TCS is also deploying physical AI applications, including autonomous safety and quality inspections via quadruped robots, to minimize risk across complex manufacturing environments.&lt;/p&gt;
&lt;p&gt;Wipro PARI, a leader in industrial automation, is integrating NVIDIA AI infrastructure,&amp;nbsp; Omniverse libraries and the NVIDIA Isaac robotics development platform to deliver solutions for its consumer and automotive customers. This includes real-time simulation and validation of robotic workflows, as well as virtual stress-testing of operations before physical deployment.&lt;/p&gt;
&lt;p&gt;Tata Consulting Engineers is launching its Cognitive Twin platform, built on NVIDIA Omniverse, to create real-time industrial simulations that link physical assets with digital intelligence across manufacturing, energy and infrastructure. The platform supports both capital project planning and operational optimization through early-stage simulation and AI-enabled decision-making. Pilot projects are underway with National High Speed Rail Corporation Limited, Torrent Power and Power Grid Corporation of India Limited.&lt;/p&gt;
&lt;p&gt;To see what’s next, explore industrial AI and manufacturing sessions at NVIDIA GTC.&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/NVIDIA-India-AI-Impact-Summit-Indias-Manufacturers-Drive-AI-Boom-scaled.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;India is entering a new age of industrialization, as AI transforms how the world designs, builds and runs physical products and systems. The country is investing $134 billion dollars in new manufacturing capacity across construction, automotive, renewable energy and robotics, creating both a massive challenge and opportunity to build software-defined factories from day one.&lt;/p&gt;
&lt;p&gt;At the center of this transformation are applications accelerated by NVIDIA CUDA-X and NVIDIA Omniverse libraries, which connect data from design to operations and bring physical AI into factories, warehouses and infrastructure.&lt;/p&gt;
&lt;p&gt;India’s largest manufacturers are teaming with global industrial software leaders Cadence, Siemens and Synopsys to advance the nation’s AI boom using applications accelerated by CUDA-X and Omniverse libraries.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;India’s Manufacturing Leaders Modernize Factories With &lt;/b&gt;&lt;b&gt;Siemens&lt;/b&gt;&lt;b&gt; and NVIDIA&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;To scale India’s growth, manufacturers are using Siemens industrial software integrated with NVIDIA CUDA-X and Omniverse libraries to design, build and operate next-generation, software-defined factories.&lt;/p&gt;
&lt;p&gt;Reliance New Energy, the clean energy arm of Reliance industries, is expanding its collaboration with NVIDIA and Siemens by combining Siemens’ digital twin technology with NVIDIA Omniverse libraries for faster, more precise simulation and plant design for its next-generation gigafactories.&lt;/p&gt;
&lt;p&gt;Addverb Technologies, a leading Indian company providing robots and innovative warehouse automation solutions, is using Siemens’ Technomatix portfolio, NVIDIA Omniverse libraries and NVIDIA Cosmos world foundation models to create digital twins of its factories and train its quadruped and wheeled humanoid robots in simulation.&lt;/p&gt;
&lt;p&gt;Hero MotoCorp is utilizing Siemens Xcelerator and NVIDIA infrastructure to accelerate the product development lifecycle by enhancing its capabilities in computer-aided engineering, numerical virtual verification and validation.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Partners Advance Design and Engineering With NVIDIA-Accelerated Software From &lt;/b&gt;&lt;b&gt;Synopsys&lt;/b&gt;&lt;b&gt; and &lt;/b&gt;&lt;b&gt;Cadence&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Leading enterprises are integrating Synopsys and Cadence’s electronic design automation tools, powered by NVIDIA AI infrastructure and libraries, to enable rapid design iteration and operational intelligence across the energy, automotive and electronics sectors.&lt;/p&gt;
&lt;p&gt;Electrical equipment and home appliances leader Havells India Limited is using Synopsys’ Ansys Fluent to accelerate simulation powered by NVIDIA CUDA-X. Havells has obtained 6x faster fluid dynamic simulations, enabling exploration of more design options to optimize airflow and energy efficiencies, and achieve faster time to market.&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Larsen &amp;amp; Toubro Semiconductor’s application of Cadence Spectre X, accelerated by CUDA-X libraries, on NVIDIA GPUs shortens design iterations of next-generation AI chips.&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;India’s Technology Leaders Advance Industrial Automation With Physical AI&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;India’s IT and business consulting sector has grown into a global powerhouse, projected to reach over $350 billion this year, serving as a primary engine for transforming the world’s largest industries.&lt;/p&gt;
&lt;p&gt;Tata Consultancy Services (TCS), a global leader in IT services, is investing in large-scale AI infrastructure to deliver enterprise solutions at scale. By harnessing the NVIDIA Metropolis platform, the NVIDIA Blueprint for video search and summarization and digital twins built on Omniverse libraries, TCS is setting safety and precision benchmarks at Tata Motors, converting standard camera feeds into intelligent sensors for automated quality checks and real-time safety compliance.&lt;/p&gt;
&lt;p&gt;TCS is also deploying physical AI applications, including autonomous safety and quality inspections via quadruped robots, to minimize risk across complex manufacturing environments.&lt;/p&gt;
&lt;p&gt;Wipro PARI, a leader in industrial automation, is integrating NVIDIA AI infrastructure,&amp;nbsp; Omniverse libraries and the NVIDIA Isaac robotics development platform to deliver solutions for its consumer and automotive customers. This includes real-time simulation and validation of robotic workflows, as well as virtual stress-testing of operations before physical deployment.&lt;/p&gt;
&lt;p&gt;Tata Consulting Engineers is launching its Cognitive Twin platform, built on NVIDIA Omniverse, to create real-time industrial simulations that link physical assets with digital intelligence across manufacturing, energy and infrastructure. The platform supports both capital project planning and operational optimization through early-stage simulation and AI-enabled decision-making. Pilot projects are underway with National High Speed Rail Corporation Limited, Torrent Power and Power Grid Corporation of India Limited.&lt;/p&gt;
&lt;p&gt;To see what’s next, explore industrial AI and manufacturing sessions at NVIDIA GTC.&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/india-global-industrial-software-leaders-manufacturers-ai/</guid><pubDate>Wed, 18 Feb 2026 00:30:32 +0000</pubDate></item><item><title>[NEW] India’s Global Systems Integrators Build Next Wave of Enterprise Agents With NVIDIA AI, Transforming Back Office and Customer Support (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/india-enterprise-ai-agents/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/ai-impact-summit-in26-visual-gsi-4871450-concept1-r2-1680x945.png" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Agentic AI is reshaping India’s tech industry, delivering leaps in services worldwide.&lt;/p&gt;
&lt;p&gt;Tapping into NVIDIA AI Enterprise software and NVIDIA Nemotron models, India’s technology leaders are accelerating productivity and efficiency across industries — from call centers to telecommunications and healthcare.&lt;/p&gt;
&lt;p&gt;Infosys, Persistent, Tech Mahindra and Wipro are leading the way for business transformation, improving back-office productivity and customer services with integrated agentic AI platforms built with NVIDIA AI Enterprise.&lt;/p&gt;
&lt;p&gt;At this year’s India AI Impact Summit, the state of the art for next-generation business services driven by agentic and generative AI was on full display.&lt;/p&gt;
&lt;p&gt;India’s tech industry is on track to reach $500 billion in revenue by 2030, up from about $250 billion in 2023, according to IBEF, citing momentum in AI from 38,000 GPUs secured in September.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Wipro WEGA Platform Boosting Efficiency for Call Centers With NVIDIA AI&lt;/b&gt; &lt;b&gt;Enterprise&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;For health insurance plans in government‑regulated markets, customer experience is important — especially during peak enrollment cycles, when deadlines loom and subscribers need 24/7 support to assess options and optimize enrollment decisions for their families. Traditional contact center business models, built around seasonal hiring and lengthy training, simply can’t keep pace. What’s needed is a new operating model that improves customer experience while containing the growing cost of service.&lt;/p&gt;
&lt;p&gt;Wipro’s AI‑agent-assisted solution, powered by the WEGA platform and NVIDIA AI Enterprise software, offers a glimpse of that future. Deployed for a major U.S. healthcare insurance provider, the system is already reshaping member experiences by enabling service representatives to handle more complex requests, accelerate resolution times, deliver more personalized support and improve operational efficiencies.&lt;/p&gt;
&lt;p&gt;AI agents help meet the expectations customers bring to their health plans: immediate access to accurate information, conversational self‑service, frictionless enrollment and consistent guidance across channels. Behind the scenes, payers face rising call volumes, fragmented data and heavy administrative workloads. AI agents bridge that gap by scaling instantly, operating around the clock and supporting human representatives with real‑time intelligence.&lt;/p&gt;
&lt;p&gt;The results have been striking: 42% of inbound calls are now handled by AI agents and near‑instant responsiveness across 900 concurrent calls and 164 requests per second — all with sub‑200‑millisecond latency.&lt;/p&gt;
&lt;p&gt;Members benefit from natural, conversational self‑service. Human agents receive real‑time prompts and knowledge retrieval. A centralized data hub surfaces personalized insights, while automated digitization removes manual work from downstream processes.&lt;/p&gt;
&lt;p&gt;Using production grade, horizontally scalable NVIDIA NIM microservices and NVIDIA NeMo Guardrails, part of NVIDIA AI Enterprise, the solution includes the performance, governance and safety required in regulated healthcare environments.&lt;/p&gt;
&lt;p&gt;Its impact is already extending beyond healthcare, with similar deployments underway in financial services. Anywhere accuracy, compliance and scale matter, AI agents are becoming a transformative force.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Tech Mahindra Deploying Large Telco Model to Power Autonomous Network Operations Using NVIDIA NIM&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Tech Mahindra is accelerating the shift toward AI-assisted network operations with a new platform built in collaboration with NVIDIA. At the center is a large telco model (LTM) that generates prioritized, data‑driven recommendations to help field technicians rank each fix by its historical success rate across the network. The result is faster, more accurate resolutions — often in a single visit — and a clear path toward level‑4‑plus operational maturity.&lt;/p&gt;
&lt;p&gt;A large telecommunications services provider is adopting the same LTM foundation as part of its operations roadmap, targeting improvements in service‑layer issue resolution, customer experience and back‑office efficiency through higher‑quality tickets and fewer escalations.&lt;/p&gt;
&lt;p&gt;The platform uses NVIDIA Nemotron embedding models for semantic search across telemetry and a Nemotron reranking model to sharpen decision relevance. These models are deployed with NVIDIA NIM microservices for rapid, reliable accelerated AI inference. NVIDIA NeMo Agent Toolkit orchestrates agent workflows across network domains, enabling true agentic operations at scale.&lt;/p&gt;
&lt;p&gt;By embracing autonomous network operations, Tech Mahindra shows how AI can transform a global telecom industry generating more than $1.5 trillion in annual revenue — where even small gains in uptime and efficiency deliver outsized economic impact.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Infosys Builds an Enterprise-Grade Coding Small Language Model With NVIDIA AI Enterprise&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Infosys developed a new small language model for coding, built using the NVIDIA NeMo framework that’s part of NVIDIA AI Enterprise, and integrated within Infosys Topaz Fabric. The model accelerates software delivery with frontier‑grade performance while remaining lightweight, and it can be deployed across on-premises enterprise data centers, cloud environments and even standard desktops.&lt;/p&gt;
&lt;p&gt;The 2.5‑billion‑parameter model supports agent development, code generation, refactoring and end‑to‑end software‑engineering workflows. It’s trained on a curated blend of high‑quality code, synthetic data, mathematical reasoning and natural language inputs — an approach that enables it to match frontier‑model performance on benchmarks such as MBPP, MBPP+ and BFCL.&lt;/p&gt;
&lt;p&gt;Infosys also prioritized safety and trust. The model incorporates safety‑aligned training and responsible AI practices that reduce harmful outputs while preserving fluency. Its secure‑coding capabilities are validated through industry benchmarks including Stanford AIR‑Bench and Meta’s CyberSecEval, giving enterprises confidence to deploy it across code generation, debugging and multi‑agent development pipelines.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Persistent Accelerates AI‑Driven Molecular Discovery With NVIDIA BioNeMo and NeMo Agent Toolkit&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Persistent Systems is working with NVIDIA to push early‑stage drug discovery into a new era of speed and scientific fidelity. The collaboration brings together Persistent’s deep life sciences engineering expertise with NVIDIA’s full‑stack accelerated computing platform, giving researchers a powerful path from AI experimentation to production‑grade discovery workflows.&lt;/p&gt;
&lt;p&gt;At the center of the effort is Persistent’s new Generative Molecules and Virtual Screening (GenMoIVS) solution, built on the NVIDIA BioNeMo platform and the NeMo Agent Toolkit. GenMoIVS uses large, domain‑specific models to simulate molecular behavior with high accuracy, generating and evaluating candidate compounds before they ever reach a wet lab. These agentic workflows continuously reason across virtual screening, prioritization and experimental planning, helping teams de‑risk early discovery and shorten development cycles.&lt;/p&gt;
&lt;p&gt;The platform runs on NVIDIA’s accelerated computing platform, including NVIDIA AI Enterprise software and NIM microservices, enabling high‑throughput simulation and real‑time scientific decision-making in regulated environments. By combining scalable infrastructure with production‑ready agentic AI, Persistent is giving life sciences organizations a faster, more cost‑effective way to explore the compound space and improve downstream success rates.&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/ai-impact-summit-in26-visual-gsi-4871450-concept1-r2-1680x945.png" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Agentic AI is reshaping India’s tech industry, delivering leaps in services worldwide.&lt;/p&gt;
&lt;p&gt;Tapping into NVIDIA AI Enterprise software and NVIDIA Nemotron models, India’s technology leaders are accelerating productivity and efficiency across industries — from call centers to telecommunications and healthcare.&lt;/p&gt;
&lt;p&gt;Infosys, Persistent, Tech Mahindra and Wipro are leading the way for business transformation, improving back-office productivity and customer services with integrated agentic AI platforms built with NVIDIA AI Enterprise.&lt;/p&gt;
&lt;p&gt;At this year’s India AI Impact Summit, the state of the art for next-generation business services driven by agentic and generative AI was on full display.&lt;/p&gt;
&lt;p&gt;India’s tech industry is on track to reach $500 billion in revenue by 2030, up from about $250 billion in 2023, according to IBEF, citing momentum in AI from 38,000 GPUs secured in September.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Wipro WEGA Platform Boosting Efficiency for Call Centers With NVIDIA AI&lt;/b&gt; &lt;b&gt;Enterprise&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;For health insurance plans in government‑regulated markets, customer experience is important — especially during peak enrollment cycles, when deadlines loom and subscribers need 24/7 support to assess options and optimize enrollment decisions for their families. Traditional contact center business models, built around seasonal hiring and lengthy training, simply can’t keep pace. What’s needed is a new operating model that improves customer experience while containing the growing cost of service.&lt;/p&gt;
&lt;p&gt;Wipro’s AI‑agent-assisted solution, powered by the WEGA platform and NVIDIA AI Enterprise software, offers a glimpse of that future. Deployed for a major U.S. healthcare insurance provider, the system is already reshaping member experiences by enabling service representatives to handle more complex requests, accelerate resolution times, deliver more personalized support and improve operational efficiencies.&lt;/p&gt;
&lt;p&gt;AI agents help meet the expectations customers bring to their health plans: immediate access to accurate information, conversational self‑service, frictionless enrollment and consistent guidance across channels. Behind the scenes, payers face rising call volumes, fragmented data and heavy administrative workloads. AI agents bridge that gap by scaling instantly, operating around the clock and supporting human representatives with real‑time intelligence.&lt;/p&gt;
&lt;p&gt;The results have been striking: 42% of inbound calls are now handled by AI agents and near‑instant responsiveness across 900 concurrent calls and 164 requests per second — all with sub‑200‑millisecond latency.&lt;/p&gt;
&lt;p&gt;Members benefit from natural, conversational self‑service. Human agents receive real‑time prompts and knowledge retrieval. A centralized data hub surfaces personalized insights, while automated digitization removes manual work from downstream processes.&lt;/p&gt;
&lt;p&gt;Using production grade, horizontally scalable NVIDIA NIM microservices and NVIDIA NeMo Guardrails, part of NVIDIA AI Enterprise, the solution includes the performance, governance and safety required in regulated healthcare environments.&lt;/p&gt;
&lt;p&gt;Its impact is already extending beyond healthcare, with similar deployments underway in financial services. Anywhere accuracy, compliance and scale matter, AI agents are becoming a transformative force.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Tech Mahindra Deploying Large Telco Model to Power Autonomous Network Operations Using NVIDIA NIM&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Tech Mahindra is accelerating the shift toward AI-assisted network operations with a new platform built in collaboration with NVIDIA. At the center is a large telco model (LTM) that generates prioritized, data‑driven recommendations to help field technicians rank each fix by its historical success rate across the network. The result is faster, more accurate resolutions — often in a single visit — and a clear path toward level‑4‑plus operational maturity.&lt;/p&gt;
&lt;p&gt;A large telecommunications services provider is adopting the same LTM foundation as part of its operations roadmap, targeting improvements in service‑layer issue resolution, customer experience and back‑office efficiency through higher‑quality tickets and fewer escalations.&lt;/p&gt;
&lt;p&gt;The platform uses NVIDIA Nemotron embedding models for semantic search across telemetry and a Nemotron reranking model to sharpen decision relevance. These models are deployed with NVIDIA NIM microservices for rapid, reliable accelerated AI inference. NVIDIA NeMo Agent Toolkit orchestrates agent workflows across network domains, enabling true agentic operations at scale.&lt;/p&gt;
&lt;p&gt;By embracing autonomous network operations, Tech Mahindra shows how AI can transform a global telecom industry generating more than $1.5 trillion in annual revenue — where even small gains in uptime and efficiency deliver outsized economic impact.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Infosys Builds an Enterprise-Grade Coding Small Language Model With NVIDIA AI Enterprise&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Infosys developed a new small language model for coding, built using the NVIDIA NeMo framework that’s part of NVIDIA AI Enterprise, and integrated within Infosys Topaz Fabric. The model accelerates software delivery with frontier‑grade performance while remaining lightweight, and it can be deployed across on-premises enterprise data centers, cloud environments and even standard desktops.&lt;/p&gt;
&lt;p&gt;The 2.5‑billion‑parameter model supports agent development, code generation, refactoring and end‑to‑end software‑engineering workflows. It’s trained on a curated blend of high‑quality code, synthetic data, mathematical reasoning and natural language inputs — an approach that enables it to match frontier‑model performance on benchmarks such as MBPP, MBPP+ and BFCL.&lt;/p&gt;
&lt;p&gt;Infosys also prioritized safety and trust. The model incorporates safety‑aligned training and responsible AI practices that reduce harmful outputs while preserving fluency. Its secure‑coding capabilities are validated through industry benchmarks including Stanford AIR‑Bench and Meta’s CyberSecEval, giving enterprises confidence to deploy it across code generation, debugging and multi‑agent development pipelines.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Persistent Accelerates AI‑Driven Molecular Discovery With NVIDIA BioNeMo and NeMo Agent Toolkit&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Persistent Systems is working with NVIDIA to push early‑stage drug discovery into a new era of speed and scientific fidelity. The collaboration brings together Persistent’s deep life sciences engineering expertise with NVIDIA’s full‑stack accelerated computing platform, giving researchers a powerful path from AI experimentation to production‑grade discovery workflows.&lt;/p&gt;
&lt;p&gt;At the center of the effort is Persistent’s new Generative Molecules and Virtual Screening (GenMoIVS) solution, built on the NVIDIA BioNeMo platform and the NeMo Agent Toolkit. GenMoIVS uses large, domain‑specific models to simulate molecular behavior with high accuracy, generating and evaluating candidate compounds before they ever reach a wet lab. These agentic workflows continuously reason across virtual screening, prioritization and experimental planning, helping teams de‑risk early discovery and shorten development cycles.&lt;/p&gt;
&lt;p&gt;The platform runs on NVIDIA’s accelerated computing platform, including NVIDIA AI Enterprise software and NIM microservices, enabling high‑throughput simulation and real‑time scientific decision-making in regulated environments. By combining scalable infrastructure with production‑ready agentic AI, Persistent is giving life sciences organizations a faster, more cost‑effective way to explore the compound space and improve downstream success rates.&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/india-enterprise-ai-agents/</guid><pubDate>Wed, 18 Feb 2026 00:30:41 +0000</pubDate></item><item><title>[NEW] India Fuels Its AI Mission With NVIDIA (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/india-ai-mission-infrastructure-models/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;India is the nexus of AI innovation this week as the host of the AI Impact Summit, which brings together global heads of state and industry to chart the future of AI.&lt;/p&gt;
&lt;p&gt;At the summit, taking place in New Delhi, industry leaders, government agencies, educational institutions and startups are sharing how they’re working with NVIDIA to drive the AI industrial revolution in the world’s most populous country.&lt;/p&gt;
&lt;p&gt;These initiatives support the IndiaAI Mission, a government effort that’s infusing India’s AI ecosystem with over $1 billion to bolster the nation’s compute capacity and foster the development of sovereign AI datasets, frontier models and applications. The mission also supports AI education, startup innovation and frameworks for trustworthy AI.&lt;/p&gt;
&lt;p&gt;Read how NVIDIA is supporting IndiaAI Mission priorities including:&lt;/p&gt;

&lt;h2 id="infrastructure"&gt;&lt;b&gt;NVIDIA Cloud Partners Boost India AI Infrastructure&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;To achieve its AI ambitions, India is investing heavily in its computing infrastructure. Under the IndiaAI Compute Pillar, the nation is building out its AI cloud offerings with systems including tens of thousands of NVIDIA GPUs.&lt;/p&gt;
&lt;p&gt;NVIDIA is collaborating with next‑generation cloud providers Yotta, L&amp;amp;T and E2E Networks to deliver advanced AI factories to meet India’s growing need for AI compute and enable it to develop AI models and services that drive innovation.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Yotta is a hyperscale data center and cloud provider building large‑scale sovereign AI infrastructure for India, branded as Shakti Cloud, powered by over 20,000 NVIDIA Blackwell Ultra GPUs. Its campuses in Navi Mumbai and Greater Noida deliver GPU‑dense, high‑bandwidth AI cloud services on a pay‑per‑use model, designed to make advanced AI training and inference affordable and compliant for Indian enterprises and public sector customers.&lt;/li&gt;
&lt;li&gt;E2E Networks is building an NVIDIA Blackwell GPU cluster on its TIR platform, hosted at the L&amp;amp;T Vyoma Data Center in Chennai. The TIR cloud compute platform will feature NVIDIA HGX B200 systems and NVIDIA Enterprise software as well as NVIDIA Nemotron open models to supercharge sovereign development across agentic AI, healthcare, finance, manufacturing and agriculture.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;India’s AI cloud infrastructure will host workloads as well as manufacture intelligence for model training, fine-tuning and high‑scale inference. Capacity within these data centers will be reserved for model builders, startups, researchers and enterprises to build, fine-tune and deploy AI in India.&lt;/p&gt;
&lt;p&gt;Further expanding access to NVIDIA AI infrastructure in India, Netweb Technologies is launching its Tyrone Camarero AI Supercomputing systems built on the NVIDIA Grace Blackwell architecture. The NVIDIA GB200 NVL4 platforms — manufactured in India by Netweb under the government’s “Make in India” mission — feature four NVIDIA Blackwell GPUs and two NVIDIA Grace CPUs to power scientific computing, model training and inference.&lt;/p&gt;
&lt;h2 id="models"&gt;&lt;b&gt;NVIDIA and India AI-Native Companies Build the Nation’s Frontier AI Models&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-large wp-image-90004" height="945" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/ai-impact-summit-in-26-promo-pack-ai-natives-devnews-press-1920x1080-v2-1680x945.jpg" width="1680" /&gt;&lt;/p&gt;
&lt;p&gt;Another key goal of the IndiaAI Mission — led by its Innovation Center Pillar — is to develop and deploy foundation models trained on India-specific data and domestic AI infrastructure.&lt;/p&gt;
&lt;p&gt;For a nation as multilingual as India — with 22 constitutionally recognized languages and over 1,500 more recorded by the country’s census — frontier AI models are a powerful tool to help its more than 1.4 billion residents interact with technology in their primary language.&lt;/p&gt;
&lt;p&gt;Organizations across the country are building AI applications with NVIDIA Nemotron to support public-sector services, financial systems and enterprise operations in multiple languages.&lt;/p&gt;
&lt;p&gt;NVIDIA Nemotron open models, datasets, tools and libraries enable organizations to build frontier speech, language and multimodal models at scale and across languages for government, consumer and enterprise applications. It includes India-specific datasets like Nemotron-Personas-India, an open dataset built from publicly available census data using NeMo Data Designer that includes 21 million fully synthetic Indic personas to enable population-scale sovereign AI development.&lt;/p&gt;
&lt;p&gt;Adopters in India of Nemotron — and NeMo Curator, an open library for multilingual and multimodal data curation — include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;BharatGen&lt;/b&gt;, a sovereign AI initiative supported by the Government of India aimed at strengthening the country’s multilingual and multimodal AI ecosystem. As part of this effort, BharatGen has developed a 17-billion-parameter mixture-of-experts (MoE) model from the ground up, using the NVIDIA NeMo framework for pretraining and the NeMo RL library for post-training. The open source models are designed to power applications across public services, agriculture, security and cultural preservation.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Chariot&lt;/b&gt;, a company building AI systems for speech and multimodal communication. Using the NeMo framework, Chariot is developing an 8-billion-parameter model for real-time text to speech, supporting applications that improve accessibility and digital interaction across consumer and enterprise use cases.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Commotion&lt;/b&gt;, backed by Tata Communications, which has developed an AI operating system to automate complex enterprise workflows. By integrating NVIDIA Nemotron models and speech capabilities, the platform enables governed, production-grade AI deployments, helping enterprises scale AI across critical business operations.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;CoRover.ai&lt;/b&gt;, which has deployed NVIDIA Nemotron Speech open models and NVIDIA Riva libraries for end-to-end, ultralow-latency speech AI — including the NVIDIA Riva Whisper v3 model for multilingual automatic speech recognition in English, Hindi and Gujarati. Powering customer service applications for the Indian Railway Catering and Tourism Corporation, CoRover’s platform supports around 10,000 concurrent users and more than 5,000 daily ticket bookings.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Gnani.ai&lt;/b&gt;, which offers enterprises a multilingual agentic AI platform that can interact with customers through voice and text. Gnani is building a 14-billion-parameter speech-to-speech model built on NVIDIA Nemotron Speech models, datasets and NeMo libraries including NeMo libraries through NVIDIA Cloud Partner E2E Networks — with plans to expand to a 32-billion-parameter model. By fine-tuning the NVIDIA Nemotron Speech model for Indic languages, Gnani has achieved a 15x reduction in inference costs, enabling the company to scale to support more than 10 million calls per day for customers in telecom, banking and hospitality.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;National Payments Corporation of India (NPCI)&lt;/b&gt;, which operates India’s retail payment and settlement systems and is deploying AI models to support digital financial services. Building on its production deployment of the AI-powered UPI Help Assistant — a pilot initiative for India’s Unified Payments Interface (UPI) — NPCI is exploring training FiMi, a financial model for India, using the NVIDIA Nemotron 3 Nano model and its own datasets. The model, fine-tuned with the NeMo framework, will support multilingual customer service across India’s banking ecosystem.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Sarvam.ai&lt;/b&gt;, a leader in full-stack sovereign generative AI that provides enterprise-grade multimodal, speech-to-text, text-to-speech, translation and reasoning models. The company is open sourcing its Sarvam-3 series of text and multimodal large language model variants, trained for 22 Indic languages, English math and code. Sarvam is using NeMo Curator to construct high-quality multilingual training data while adopting a subset of NVIDIA Nemotron datasets. The foundation models were pre-trained from scratch across 3B, 30B and 100B parameter sizes using the NVIDIA NeMo framework and Megatron-LM, and post-trained with NeMo RL. Training was conducted on NVIDIA H100 GPUs through NVIDIA Cloud Partners, including Yotta. With these sovereign models, Sarvam.ai’s new Pravah platform enables production-grade inference for Indian government and enterprise applications.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Soket.ai&lt;/b&gt;, which is using a modern large-model training stack on open NVIDIA Nemotron technologies, including NVIDIA Megatron and NVIDIA NeMo. These open source components enable scalable experimentation, training stability and efficient GPU usage, while preserving full control over the model’s data, design and life cycle.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Tech Mahindra&lt;/b&gt;, which has developed an 8-billion-parameter foundation model tailored for Indian languages and dialects. The model, built with Nemotron, is being designed for use in classrooms, where it can help make educational materials available in a wider range of Indian languages including Hindi, Maithili and Dogri. The team generated synthetic data with Nemotron libraries and tools such as NeMo Data Designer and conducted supervised fine-tuning with NeMo AutoModel.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Zoho&lt;/b&gt;, which is advancing its Zia LLM platform with proprietary models built using NVIDIA NeMo on the NVIDIA Blackwell and Hopper platforms, integrated across its software-as-a-service applications. This privacy-first architecture delivers contextual, production-grade AI for critical business workflows like customer relation management and finance, ensuring technology sovereignty and enterprise security at a global scale.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Developers building sovereign AI systems can access NVIDIA Nemotron and NeMo today. Nemotron models can be deployed anywhere on NVIDIA-accelerated infrastructure — including on NVIDIA DGX Spark, which is now available in India through qualified partners including PNY, RP tech India, Tech Data, a TD SYNNEX Company, as well as on NVIDIA Marketplace. A version manufactured in India as part of the “Make in India” initiative is available through Netweb.&lt;/p&gt;
&lt;p&gt;DGX Spark also runs sovereign AI models by Indian model builders including Sarvam.ai.&lt;/p&gt;
&lt;h2 id="research-innovation"&gt;&lt;b&gt;Government and Academic Partnerships to Support Research in AI for Science and Engineering&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Under its Application Development Initiative Pillar, the IndiaAI Mission is supporting high-impact AI applications — and its Startup Financing Pillar aims to democratize funding availability for AI entrepreneurs across the country.&lt;/p&gt;
&lt;p&gt;NVIDIA is collaborating with government agencies, research institutions, venture capital firms and startups to advance projects aligned with these goals.&lt;/p&gt;
&lt;p&gt;NVIDIA is collaborating with the Anusandhan National Research Foundation (ANRF), a statutory body under the Indian government, to spur even more cutting-edge AI research across the nation’s leading academic institutions. The initiative will support ANRF’s AI for Science &amp;amp; Engineering program and future AI programs.&lt;/p&gt;
&lt;p&gt;NVIDIA will offer ANRF grantee institutions complimentary access to NVIDIA AI Enterprise software and specialized technical mentorship through the NVIDIA AI Technology Center. The collaboration will also include AI bootcamps, workshops and hackathons to strengthen India’s AI research ecosystem.&lt;/p&gt;
&lt;p&gt;NVIDIA is also partnering with prominent venture capital firms including Peak XV, Z47, Elevation Capital,, Nexus Venture Partners and Accel India to identify and fund promising startups of all stages that are building AI solutions for India and international use. More than 4,000 of India’s AI startups are already part of the NVIDIA Inception program.&lt;/p&gt;
&lt;p&gt;For more from the India AI Summit, learn how NVIDIA and global industrial software leaders are partnering with India’s largest manufacturers — and how India’s global systems integrators are building enterprise AI agents with NVIDIA.&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;India is the nexus of AI innovation this week as the host of the AI Impact Summit, which brings together global heads of state and industry to chart the future of AI.&lt;/p&gt;
&lt;p&gt;At the summit, taking place in New Delhi, industry leaders, government agencies, educational institutions and startups are sharing how they’re working with NVIDIA to drive the AI industrial revolution in the world’s most populous country.&lt;/p&gt;
&lt;p&gt;These initiatives support the IndiaAI Mission, a government effort that’s infusing India’s AI ecosystem with over $1 billion to bolster the nation’s compute capacity and foster the development of sovereign AI datasets, frontier models and applications. The mission also supports AI education, startup innovation and frameworks for trustworthy AI.&lt;/p&gt;
&lt;p&gt;Read how NVIDIA is supporting IndiaAI Mission priorities including:&lt;/p&gt;

&lt;h2 id="infrastructure"&gt;&lt;b&gt;NVIDIA Cloud Partners Boost India AI Infrastructure&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;To achieve its AI ambitions, India is investing heavily in its computing infrastructure. Under the IndiaAI Compute Pillar, the nation is building out its AI cloud offerings with systems including tens of thousands of NVIDIA GPUs.&lt;/p&gt;
&lt;p&gt;NVIDIA is collaborating with next‑generation cloud providers Yotta, L&amp;amp;T and E2E Networks to deliver advanced AI factories to meet India’s growing need for AI compute and enable it to develop AI models and services that drive innovation.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Yotta is a hyperscale data center and cloud provider building large‑scale sovereign AI infrastructure for India, branded as Shakti Cloud, powered by over 20,000 NVIDIA Blackwell Ultra GPUs. Its campuses in Navi Mumbai and Greater Noida deliver GPU‑dense, high‑bandwidth AI cloud services on a pay‑per‑use model, designed to make advanced AI training and inference affordable and compliant for Indian enterprises and public sector customers.&lt;/li&gt;
&lt;li&gt;E2E Networks is building an NVIDIA Blackwell GPU cluster on its TIR platform, hosted at the L&amp;amp;T Vyoma Data Center in Chennai. The TIR cloud compute platform will feature NVIDIA HGX B200 systems and NVIDIA Enterprise software as well as NVIDIA Nemotron open models to supercharge sovereign development across agentic AI, healthcare, finance, manufacturing and agriculture.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;India’s AI cloud infrastructure will host workloads as well as manufacture intelligence for model training, fine-tuning and high‑scale inference. Capacity within these data centers will be reserved for model builders, startups, researchers and enterprises to build, fine-tune and deploy AI in India.&lt;/p&gt;
&lt;p&gt;Further expanding access to NVIDIA AI infrastructure in India, Netweb Technologies is launching its Tyrone Camarero AI Supercomputing systems built on the NVIDIA Grace Blackwell architecture. The NVIDIA GB200 NVL4 platforms — manufactured in India by Netweb under the government’s “Make in India” mission — feature four NVIDIA Blackwell GPUs and two NVIDIA Grace CPUs to power scientific computing, model training and inference.&lt;/p&gt;
&lt;h2 id="models"&gt;&lt;b&gt;NVIDIA and India AI-Native Companies Build the Nation’s Frontier AI Models&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-large wp-image-90004" height="945" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/ai-impact-summit-in-26-promo-pack-ai-natives-devnews-press-1920x1080-v2-1680x945.jpg" width="1680" /&gt;&lt;/p&gt;
&lt;p&gt;Another key goal of the IndiaAI Mission — led by its Innovation Center Pillar — is to develop and deploy foundation models trained on India-specific data and domestic AI infrastructure.&lt;/p&gt;
&lt;p&gt;For a nation as multilingual as India — with 22 constitutionally recognized languages and over 1,500 more recorded by the country’s census — frontier AI models are a powerful tool to help its more than 1.4 billion residents interact with technology in their primary language.&lt;/p&gt;
&lt;p&gt;Organizations across the country are building AI applications with NVIDIA Nemotron to support public-sector services, financial systems and enterprise operations in multiple languages.&lt;/p&gt;
&lt;p&gt;NVIDIA Nemotron open models, datasets, tools and libraries enable organizations to build frontier speech, language and multimodal models at scale and across languages for government, consumer and enterprise applications. It includes India-specific datasets like Nemotron-Personas-India, an open dataset built from publicly available census data using NeMo Data Designer that includes 21 million fully synthetic Indic personas to enable population-scale sovereign AI development.&lt;/p&gt;
&lt;p&gt;Adopters in India of Nemotron — and NeMo Curator, an open library for multilingual and multimodal data curation — include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;BharatGen&lt;/b&gt;, a sovereign AI initiative supported by the Government of India aimed at strengthening the country’s multilingual and multimodal AI ecosystem. As part of this effort, BharatGen has developed a 17-billion-parameter mixture-of-experts (MoE) model from the ground up, using the NVIDIA NeMo framework for pretraining and the NeMo RL library for post-training. The open source models are designed to power applications across public services, agriculture, security and cultural preservation.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Chariot&lt;/b&gt;, a company building AI systems for speech and multimodal communication. Using the NeMo framework, Chariot is developing an 8-billion-parameter model for real-time text to speech, supporting applications that improve accessibility and digital interaction across consumer and enterprise use cases.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Commotion&lt;/b&gt;, backed by Tata Communications, which has developed an AI operating system to automate complex enterprise workflows. By integrating NVIDIA Nemotron models and speech capabilities, the platform enables governed, production-grade AI deployments, helping enterprises scale AI across critical business operations.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;CoRover.ai&lt;/b&gt;, which has deployed NVIDIA Nemotron Speech open models and NVIDIA Riva libraries for end-to-end, ultralow-latency speech AI — including the NVIDIA Riva Whisper v3 model for multilingual automatic speech recognition in English, Hindi and Gujarati. Powering customer service applications for the Indian Railway Catering and Tourism Corporation, CoRover’s platform supports around 10,000 concurrent users and more than 5,000 daily ticket bookings.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Gnani.ai&lt;/b&gt;, which offers enterprises a multilingual agentic AI platform that can interact with customers through voice and text. Gnani is building a 14-billion-parameter speech-to-speech model built on NVIDIA Nemotron Speech models, datasets and NeMo libraries including NeMo libraries through NVIDIA Cloud Partner E2E Networks — with plans to expand to a 32-billion-parameter model. By fine-tuning the NVIDIA Nemotron Speech model for Indic languages, Gnani has achieved a 15x reduction in inference costs, enabling the company to scale to support more than 10 million calls per day for customers in telecom, banking and hospitality.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;National Payments Corporation of India (NPCI)&lt;/b&gt;, which operates India’s retail payment and settlement systems and is deploying AI models to support digital financial services. Building on its production deployment of the AI-powered UPI Help Assistant — a pilot initiative for India’s Unified Payments Interface (UPI) — NPCI is exploring training FiMi, a financial model for India, using the NVIDIA Nemotron 3 Nano model and its own datasets. The model, fine-tuned with the NeMo framework, will support multilingual customer service across India’s banking ecosystem.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Sarvam.ai&lt;/b&gt;, a leader in full-stack sovereign generative AI that provides enterprise-grade multimodal, speech-to-text, text-to-speech, translation and reasoning models. The company is open sourcing its Sarvam-3 series of text and multimodal large language model variants, trained for 22 Indic languages, English math and code. Sarvam is using NeMo Curator to construct high-quality multilingual training data while adopting a subset of NVIDIA Nemotron datasets. The foundation models were pre-trained from scratch across 3B, 30B and 100B parameter sizes using the NVIDIA NeMo framework and Megatron-LM, and post-trained with NeMo RL. Training was conducted on NVIDIA H100 GPUs through NVIDIA Cloud Partners, including Yotta. With these sovereign models, Sarvam.ai’s new Pravah platform enables production-grade inference for Indian government and enterprise applications.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Soket.ai&lt;/b&gt;, which is using a modern large-model training stack on open NVIDIA Nemotron technologies, including NVIDIA Megatron and NVIDIA NeMo. These open source components enable scalable experimentation, training stability and efficient GPU usage, while preserving full control over the model’s data, design and life cycle.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Tech Mahindra&lt;/b&gt;, which has developed an 8-billion-parameter foundation model tailored for Indian languages and dialects. The model, built with Nemotron, is being designed for use in classrooms, where it can help make educational materials available in a wider range of Indian languages including Hindi, Maithili and Dogri. The team generated synthetic data with Nemotron libraries and tools such as NeMo Data Designer and conducted supervised fine-tuning with NeMo AutoModel.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Zoho&lt;/b&gt;, which is advancing its Zia LLM platform with proprietary models built using NVIDIA NeMo on the NVIDIA Blackwell and Hopper platforms, integrated across its software-as-a-service applications. This privacy-first architecture delivers contextual, production-grade AI for critical business workflows like customer relation management and finance, ensuring technology sovereignty and enterprise security at a global scale.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Developers building sovereign AI systems can access NVIDIA Nemotron and NeMo today. Nemotron models can be deployed anywhere on NVIDIA-accelerated infrastructure — including on NVIDIA DGX Spark, which is now available in India through qualified partners including PNY, RP tech India, Tech Data, a TD SYNNEX Company, as well as on NVIDIA Marketplace. A version manufactured in India as part of the “Make in India” initiative is available through Netweb.&lt;/p&gt;
&lt;p&gt;DGX Spark also runs sovereign AI models by Indian model builders including Sarvam.ai.&lt;/p&gt;
&lt;h2 id="research-innovation"&gt;&lt;b&gt;Government and Academic Partnerships to Support Research in AI for Science and Engineering&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Under its Application Development Initiative Pillar, the IndiaAI Mission is supporting high-impact AI applications — and its Startup Financing Pillar aims to democratize funding availability for AI entrepreneurs across the country.&lt;/p&gt;
&lt;p&gt;NVIDIA is collaborating with government agencies, research institutions, venture capital firms and startups to advance projects aligned with these goals.&lt;/p&gt;
&lt;p&gt;NVIDIA is collaborating with the Anusandhan National Research Foundation (ANRF), a statutory body under the Indian government, to spur even more cutting-edge AI research across the nation’s leading academic institutions. The initiative will support ANRF’s AI for Science &amp;amp; Engineering program and future AI programs.&lt;/p&gt;
&lt;p&gt;NVIDIA will offer ANRF grantee institutions complimentary access to NVIDIA AI Enterprise software and specialized technical mentorship through the NVIDIA AI Technology Center. The collaboration will also include AI bootcamps, workshops and hackathons to strengthen India’s AI research ecosystem.&lt;/p&gt;
&lt;p&gt;NVIDIA is also partnering with prominent venture capital firms including Peak XV, Z47, Elevation Capital,, Nexus Venture Partners and Accel India to identify and fund promising startups of all stages that are building AI solutions for India and international use. More than 4,000 of India’s AI startups are already part of the NVIDIA Inception program.&lt;/p&gt;
&lt;p&gt;For more from the India AI Summit, learn how NVIDIA and global industrial software leaders are partnering with India’s largest manufacturers — and how India’s global systems integrators are building enterprise AI agents with NVIDIA.&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/india-ai-mission-infrastructure-models/</guid><pubDate>Wed, 18 Feb 2026 00:30:49 +0000</pubDate></item></channel></rss>