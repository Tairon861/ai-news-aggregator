<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Mon, 13 Oct 2025 01:45:16 +0000</lastBuildDate><item><title>Nvidia’s AI empire: A look at its top startup investments (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/12/nvidias-ai-empire-a-look-at-its-top-startup-investments/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/11/GettyImages-2183848501.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;No company has capitalized on the AI revolution more dramatically than Nvidia. Its revenue, profitability, and cash reserves have skyrocketed since the introduction of ChatGPT over two years ago — and the many competitive generative AI services that have launched since. Its stock price has soared, making it a $4.5 trillion market cap company.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The world’s leading high-performance GPU maker has used its ballooning fortunes to significantly increase investments in startups,&amp;nbsp;particularly in AI.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Nvidia has participated in 50 venture capital deals&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;so far in 2025, already surpassing the 48 deals the company completed in all of 2024, according to PitchBook data. Note that these investments exclude those made by its formal corporate VC fund, NVentures, which also significantly increased its investment pace over that period. (PitchBook says NVentures engaged in 21 deals this year, compared to just one in 2022.)&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia&amp;nbsp;has stated&amp;nbsp;that the goal of its corporate investing is to expand the AI ecosystem by backing startups it considers to be “game changers and market makers.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Below is a list of startups that raised rounds exceeding $100 million since 2023 where Nvidia is a named participant, organized from the highest to lowest amount raised in the round.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This list shows just how far and wide Nvidia has spread its tentacles in the tech industry, beyond supplying its products.&amp;nbsp;&lt;br /&gt;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-the-billion-dollar-round-club"&gt;&lt;strong&gt;The billion-dollar-round club&lt;/strong&gt;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;OpenAI:&amp;nbsp;&lt;/strong&gt;Nvidia backed the ChatGPT maker for the first time in October 2024, reportedly writing a&amp;nbsp;$100 million check as part of a colossal $6.6 billion round that valued the company at $157 billion. The chipmaker’s investment was dwarfed by OpenAI’s other backers, notably Thrive, which according to the New York Times invested $1.3 billion. While PitchBook data indicates Nvidia did not participate in OpenAI’s $40 billion funding round that closed in March, the chipmaker announced in September that it would invest up to&amp;nbsp;$100 billion&amp;nbsp;in the company over time, structured as a strategic partnership to deploy massive AI infrastructure.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;xAI:&amp;nbsp;&lt;/strong&gt;In 2024, OpenAI tried to persuade its investors not to invest in any of its rivals. But Nvidia participated in the $6 billion round of Elon Musk’s xAI last December anyway. Nvidia will also invest up to&amp;nbsp;$2 billion&amp;nbsp;in the equity portion of xAI’s planned $20 billion funding round, Bloomberg reported, a deal structured to help xAI purchase more Nvidia gear.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Mistral AI:&lt;/strong&gt;&amp;nbsp;Nvidia invested in Mistral for the third time when the French-based large language model developer raised €1.7 billion (about $2 billion) Series C at a €11.7billion ($13.5 billion) post-money valuation in&amp;nbsp;September.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Reflection AI&lt;/strong&gt;: In October, Nvidia led a&amp;nbsp;$2 billion funding round&amp;nbsp;for Reflection AI, a one-year-old startup, valuing the company at $8 billion. Reflection AI is positioning itself as a US-based competitor to Chinese DeepSeek, whose open-source large language model offers a less-expensive alternative to closed-source models from companies such as OpenAI and Anthropic.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Thinking Machines Lab&lt;/strong&gt;: Nvidia was among a long list of investors who backed former OpenAI Chief Technology Officer Mira Murati’s Thinking Machines Lab’s&amp;nbsp;$2 billion seed&amp;nbsp;round. The funding, which was formally announced in July, valued the new AI startup at $12 billion.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Inflection:&amp;nbsp;&lt;/strong&gt;One of Nvidia’s first significant AI investments also had one of the more unusual (but increasingly common) outcomes. In June 2023, Nvidia was one of several lead investors in Inflection’s&amp;nbsp;$1.3 billion&amp;nbsp;round, a company co-founded by Mustafa Suleyman, the famed founder of DeepMind. Less than a year later, Microsoft hired Inflection’s founders,&amp;nbsp;paying $620 million&amp;nbsp;for a non-exclusive technology license, leaving the company with a significantly diminished workforce and a less defined future.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Nscale&lt;/strong&gt;: After the startup’s&amp;nbsp;$1.1 billion round&amp;nbsp;in September, Nvidia participated in Nscale’s&amp;nbsp;$433 million SAFE&amp;nbsp;funding in October. That’s a deal that secures future equity for investors. Nscale, which formed in 2023 after&amp;nbsp;spinning out of Australian cryptocurrency mining company Akorn Energy, is building data centers in the UK and Norway for&amp;nbsp;OpenAI’s Stargate project.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Wayve:&amp;nbsp;&lt;/strong&gt;In May 2024, Nvidia participated in a&amp;nbsp;$1.05 billion round&amp;nbsp;for the U.K.-based startup, which is developing a self-learning system for autonomous driving. Nvidia is expected to invest an dditional&amp;nbsp;$500 million&amp;nbsp;in Wayve, the startup told TechCrunch in September. Wayve is testing its vehicles in the U.K. and the San Francisco Bay Area.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Figure AI:&amp;nbsp;&lt;/strong&gt;In September,&amp;nbsp;Nvidia participated in the Figure AI’s Series C funding round of&amp;nbsp;over $1 billion, which valued the humanoid robotics startup at $39 billion.&amp;nbsp;The chipmaker first invested in Figure in February 2024 when the company raised&amp;nbsp;a $675 million&amp;nbsp;Series B round at a $2.6 billion valuation.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Scale AI:&amp;nbsp;&lt;/strong&gt;In May 2024, Nvidia joined Accel and other tech giants Amazon and Meta to invest&amp;nbsp;$1 billion&amp;nbsp;in Scale AI, which provides data-labeling services to companies for training AI models. The round valued the San Francisco-based company at nearly $14 billion.&amp;nbsp;In June, Meta invested&amp;nbsp;$14.3 billion&amp;nbsp;for a 49% stake of Scale, and hired away the company’s co-founder and CEO Alexandr Wang, as well as several other key Scale employees.&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-the-many-hundreds-of-millions-of-dollars-club"&gt;&lt;strong&gt;The many-hundreds-of-millions-of-dollars club&lt;/strong&gt;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Commonwealth Fusion&lt;/strong&gt;: The chipmaker participated in the nuclear fusion-energy startup’s &amp;nbsp;$863 million funding round&amp;nbsp;in August 2025. The deal, which also included investors like Google and Breakthrough Energy Ventures, valued the company at $3 billion.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Crusoe:&amp;nbsp;&lt;/strong&gt;A startup building data centers&amp;nbsp;reportedly&amp;nbsp;to be leased to Oracle, Microsoft, and OpenAI&amp;nbsp;raised $686 million&amp;nbsp;in November 2024, according to an SEC filing. The investment was led by Founders Fund, and the long list of other investors included Nvidia.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Cohere&lt;/strong&gt;:&amp;nbsp;The chipmaker has invested in enterprise large language model provider Cohere across multiple funding rounds, including the&amp;nbsp;$500 million Series D, which closed in August, valuing Cohere at $6.8 billion. Nvidia first backed the Toronto-based startup in 2023.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Perplexity&lt;/strong&gt;: Nvidia first invested in Perplexity in November 2023 and has participated in most of the subsequent funding rounds of the AI search engine startup,&amp;nbsp;including the&amp;nbsp;$500 million&amp;nbsp;round closed in December 2024.&amp;nbsp;The chipmaker participated in the company’s July funding round, which valued Perplexity at $18 billion. However, Nvidia did not join the startup’s subsequent&amp;nbsp;$200 million fundraise&amp;nbsp;in September, which boosted the company’s valuation to $20 billion, according to PitchBook data.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Poolside:&amp;nbsp;&lt;/strong&gt;In October 2024, the&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;AI&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;coding assistant startup Poolside announced it raised&amp;nbsp;$500 million&amp;nbsp;led by Bain Capital Ventures. Nvidia participated in the round, which valued the AI startup at $3 billion.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Lambda:&amp;nbsp;&lt;/strong&gt;AI cloud provider Lambda, which provides services for model training, raised a&amp;nbsp;$480 million Series D&amp;nbsp;at a reported&amp;nbsp;$2.5 billion valuation&amp;nbsp;in February. The round was co-led by SGW and Andra Capital Lambda, and joined by Nvidia, ARK Invest, and others. A significant part of Lambda’s business involves renting servers powered by Nvidia’s GPUs.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;CoreWeave:&amp;nbsp;&lt;/strong&gt;Although CoreWeave is no longer a startup, but a public company, Nvidia invested in GPU-cloud provider&amp;nbsp;when it was still one, back in April 2023. That’s when CoreWeave raised&amp;nbsp;$221 million&amp;nbsp;in funding. Nvidia remains a significant shareholder.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Together AI:&amp;nbsp;&lt;/strong&gt;In February, Nvidia participated in the&amp;nbsp;$305 million Series B&amp;nbsp;of this company, which offers cloud-based infrastructure for building AI models. The round valued Together AI at $3.3 billion and was co-led by Prosperity7, a Saudi Arabian venture firm, and General Catalyst. Nvidia backed the company&amp;nbsp;for the first time&amp;nbsp;in 2023.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Firmus Technologies:&lt;/strong&gt;&amp;nbsp;In September, Firmus Technologies, the Singapore-based data center company, received&amp;nbsp;A$330 million&amp;nbsp;(approximately $215 million USD) in funding at a&amp;nbsp;A$1.85 billion&amp;nbsp;($1.2 billion USD) valuation from investors, including Nvidia. Firmus is developing an energy-efficient ‘AI factory’ in Tasmania, an island state of Australia. The startup originally provided cooling technologies for Bitcoin mining.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Sakana AI:&amp;nbsp;&lt;/strong&gt;In September 2024, Nvidia invested in&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;the&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;Japan-based startup, which trains low-cost generative AI models using small datasets. The startup raised a massive&amp;nbsp;Series A round of about $214 million&amp;nbsp;at a valuation of $1.5 billion.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Nuro&lt;/strong&gt;:&amp;nbsp;In August, Nvidia participated in the&amp;nbsp;$203 million&amp;nbsp;funding round for the self-driving startup focused on delivery. The deal valued Nuro at $6 billion, a significant 30% drop from its peak at $8.6 billion valuation in 2021.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Imbue:&amp;nbsp;&lt;/strong&gt;The AI research lab that&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;claims to be developing AI systems that can reason and code raised a&amp;nbsp;$200 million round in September 2023 from investors, including Nvidia, Astera Institute, and former Cruise CEO Kyle Vogt.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Waabi:&amp;nbsp;&lt;/strong&gt;In June 2024, the autonomous trucking startup raised a&amp;nbsp;$200 million Series B&amp;nbsp;round co-led by existing investors Uber and Khosla Ventures. Other investors included Nvidia, Volvo Group Venture Capital, and Porsche Automobil Holding SE.&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-deals-of-over-a-100-million"&gt;&lt;strong&gt;Deals of over a $100 million&lt;/strong&gt;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Ayar Labs:&amp;nbsp;&lt;/strong&gt;In December, Nvidia invested in the&amp;nbsp;$155 million round&amp;nbsp;of Ayar Labs, a&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;company developing optical interconnects to improve AI compute and power efficiency.&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;This was the third time Nvidia backed the startup.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Kore.ai:&amp;nbsp;&lt;/strong&gt;The startup developing enterprise-focused AI chatbots raised&amp;nbsp;$150 million&amp;nbsp;in December of 2023. In addition to Nvidia, investors participating in the funding included FTV Capital, Vistara Growth, and Sweetwater Private Equity.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Sandbox AQ:&lt;/strong&gt;&amp;nbsp;In April, Nvidia, alongside Google, BNP Paribas, and others, invested&amp;nbsp;$150 million&amp;nbsp;in Sandbox AQ, a startup developing large quantitative models (LQMs) for handling complex numerical analysis and statistical calculations. The investment increased Sandbox AQ’s Series E round to $450 million and the company’s valuation to $5.75 billion.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Hippocratic AI:&amp;nbsp;&lt;/strong&gt;This startup, which is developing large language models for healthcare, announced in January&amp;nbsp;that it raised a&amp;nbsp;$141 million Series B&amp;nbsp;at a valuation of $1.64 billion led by Kleiner Perkins. Nvidia participated in the round, along with returning investors Andreessen Horowitz, General Catalyst, and others. The company claims that its AI solutions can handle non-diagnostic patient-facing tasks such as pre-operating procedures, remote patient monitoring, and appointment preparation.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Weka:&amp;nbsp;&lt;/strong&gt;In May 2024, Nvidia invested in a&amp;nbsp;$140 million&amp;nbsp;round for AI-native data management platform Weka.&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;The round valued the Silicon Valley company at $1.6 billion.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Runway:&amp;nbsp;&lt;/strong&gt;In April, Nvidia participated in Runway’s&amp;nbsp;$308 million round, which was led by General Atlantic and valued the startup developing generative AI models for media production&amp;nbsp;at $3.55 billion, according to PitchBook data. The chipmaker has been an investor in&amp;nbsp;since 2023.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Bright Machines:&amp;nbsp;&lt;/strong&gt;In June 2024, Nvidia participated in a&amp;nbsp;$126 million Series C&amp;nbsp;of Bright Machines, a smart robotics and AI-driven software startup.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Enfabrica:&amp;nbsp;&lt;/strong&gt;In September 2023, Nvidia invested in networking chips designer Enfabrica’s&amp;nbsp;$125 million Series B. Although the startup raised another $115 million in November, Nvidia didn’t participate in the round.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Reka AI&lt;/strong&gt;:&amp;nbsp;In July, an AI research lab Reka, raised&amp;nbsp;$110 million&amp;nbsp;in a round that included Snowflake and Nvidia.&amp;nbsp;The deal tripled the startup’s valuation to&amp;nbsp;over $1 billion, according to Bloomberg.&amp;nbsp;&amp;nbsp;&lt;em&gt; &amp;nbsp;&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This post was first published in January 2025.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/11/GettyImages-2183848501.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;No company has capitalized on the AI revolution more dramatically than Nvidia. Its revenue, profitability, and cash reserves have skyrocketed since the introduction of ChatGPT over two years ago — and the many competitive generative AI services that have launched since. Its stock price has soared, making it a $4.5 trillion market cap company.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The world’s leading high-performance GPU maker has used its ballooning fortunes to significantly increase investments in startups,&amp;nbsp;particularly in AI.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Nvidia has participated in 50 venture capital deals&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;so far in 2025, already surpassing the 48 deals the company completed in all of 2024, according to PitchBook data. Note that these investments exclude those made by its formal corporate VC fund, NVentures, which also significantly increased its investment pace over that period. (PitchBook says NVentures engaged in 21 deals this year, compared to just one in 2022.)&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia&amp;nbsp;has stated&amp;nbsp;that the goal of its corporate investing is to expand the AI ecosystem by backing startups it considers to be “game changers and market makers.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Below is a list of startups that raised rounds exceeding $100 million since 2023 where Nvidia is a named participant, organized from the highest to lowest amount raised in the round.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This list shows just how far and wide Nvidia has spread its tentacles in the tech industry, beyond supplying its products.&amp;nbsp;&lt;br /&gt;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-the-billion-dollar-round-club"&gt;&lt;strong&gt;The billion-dollar-round club&lt;/strong&gt;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;OpenAI:&amp;nbsp;&lt;/strong&gt;Nvidia backed the ChatGPT maker for the first time in October 2024, reportedly writing a&amp;nbsp;$100 million check as part of a colossal $6.6 billion round that valued the company at $157 billion. The chipmaker’s investment was dwarfed by OpenAI’s other backers, notably Thrive, which according to the New York Times invested $1.3 billion. While PitchBook data indicates Nvidia did not participate in OpenAI’s $40 billion funding round that closed in March, the chipmaker announced in September that it would invest up to&amp;nbsp;$100 billion&amp;nbsp;in the company over time, structured as a strategic partnership to deploy massive AI infrastructure.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;xAI:&amp;nbsp;&lt;/strong&gt;In 2024, OpenAI tried to persuade its investors not to invest in any of its rivals. But Nvidia participated in the $6 billion round of Elon Musk’s xAI last December anyway. Nvidia will also invest up to&amp;nbsp;$2 billion&amp;nbsp;in the equity portion of xAI’s planned $20 billion funding round, Bloomberg reported, a deal structured to help xAI purchase more Nvidia gear.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Mistral AI:&lt;/strong&gt;&amp;nbsp;Nvidia invested in Mistral for the third time when the French-based large language model developer raised €1.7 billion (about $2 billion) Series C at a €11.7billion ($13.5 billion) post-money valuation in&amp;nbsp;September.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Reflection AI&lt;/strong&gt;: In October, Nvidia led a&amp;nbsp;$2 billion funding round&amp;nbsp;for Reflection AI, a one-year-old startup, valuing the company at $8 billion. Reflection AI is positioning itself as a US-based competitor to Chinese DeepSeek, whose open-source large language model offers a less-expensive alternative to closed-source models from companies such as OpenAI and Anthropic.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Thinking Machines Lab&lt;/strong&gt;: Nvidia was among a long list of investors who backed former OpenAI Chief Technology Officer Mira Murati’s Thinking Machines Lab’s&amp;nbsp;$2 billion seed&amp;nbsp;round. The funding, which was formally announced in July, valued the new AI startup at $12 billion.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Inflection:&amp;nbsp;&lt;/strong&gt;One of Nvidia’s first significant AI investments also had one of the more unusual (but increasingly common) outcomes. In June 2023, Nvidia was one of several lead investors in Inflection’s&amp;nbsp;$1.3 billion&amp;nbsp;round, a company co-founded by Mustafa Suleyman, the famed founder of DeepMind. Less than a year later, Microsoft hired Inflection’s founders,&amp;nbsp;paying $620 million&amp;nbsp;for a non-exclusive technology license, leaving the company with a significantly diminished workforce and a less defined future.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Nscale&lt;/strong&gt;: After the startup’s&amp;nbsp;$1.1 billion round&amp;nbsp;in September, Nvidia participated in Nscale’s&amp;nbsp;$433 million SAFE&amp;nbsp;funding in October. That’s a deal that secures future equity for investors. Nscale, which formed in 2023 after&amp;nbsp;spinning out of Australian cryptocurrency mining company Akorn Energy, is building data centers in the UK and Norway for&amp;nbsp;OpenAI’s Stargate project.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Wayve:&amp;nbsp;&lt;/strong&gt;In May 2024, Nvidia participated in a&amp;nbsp;$1.05 billion round&amp;nbsp;for the U.K.-based startup, which is developing a self-learning system for autonomous driving. Nvidia is expected to invest an dditional&amp;nbsp;$500 million&amp;nbsp;in Wayve, the startup told TechCrunch in September. Wayve is testing its vehicles in the U.K. and the San Francisco Bay Area.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Figure AI:&amp;nbsp;&lt;/strong&gt;In September,&amp;nbsp;Nvidia participated in the Figure AI’s Series C funding round of&amp;nbsp;over $1 billion, which valued the humanoid robotics startup at $39 billion.&amp;nbsp;The chipmaker first invested in Figure in February 2024 when the company raised&amp;nbsp;a $675 million&amp;nbsp;Series B round at a $2.6 billion valuation.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Scale AI:&amp;nbsp;&lt;/strong&gt;In May 2024, Nvidia joined Accel and other tech giants Amazon and Meta to invest&amp;nbsp;$1 billion&amp;nbsp;in Scale AI, which provides data-labeling services to companies for training AI models. The round valued the San Francisco-based company at nearly $14 billion.&amp;nbsp;In June, Meta invested&amp;nbsp;$14.3 billion&amp;nbsp;for a 49% stake of Scale, and hired away the company’s co-founder and CEO Alexandr Wang, as well as several other key Scale employees.&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-the-many-hundreds-of-millions-of-dollars-club"&gt;&lt;strong&gt;The many-hundreds-of-millions-of-dollars club&lt;/strong&gt;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Commonwealth Fusion&lt;/strong&gt;: The chipmaker participated in the nuclear fusion-energy startup’s &amp;nbsp;$863 million funding round&amp;nbsp;in August 2025. The deal, which also included investors like Google and Breakthrough Energy Ventures, valued the company at $3 billion.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Crusoe:&amp;nbsp;&lt;/strong&gt;A startup building data centers&amp;nbsp;reportedly&amp;nbsp;to be leased to Oracle, Microsoft, and OpenAI&amp;nbsp;raised $686 million&amp;nbsp;in November 2024, according to an SEC filing. The investment was led by Founders Fund, and the long list of other investors included Nvidia.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Cohere&lt;/strong&gt;:&amp;nbsp;The chipmaker has invested in enterprise large language model provider Cohere across multiple funding rounds, including the&amp;nbsp;$500 million Series D, which closed in August, valuing Cohere at $6.8 billion. Nvidia first backed the Toronto-based startup in 2023.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Perplexity&lt;/strong&gt;: Nvidia first invested in Perplexity in November 2023 and has participated in most of the subsequent funding rounds of the AI search engine startup,&amp;nbsp;including the&amp;nbsp;$500 million&amp;nbsp;round closed in December 2024.&amp;nbsp;The chipmaker participated in the company’s July funding round, which valued Perplexity at $18 billion. However, Nvidia did not join the startup’s subsequent&amp;nbsp;$200 million fundraise&amp;nbsp;in September, which boosted the company’s valuation to $20 billion, according to PitchBook data.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Poolside:&amp;nbsp;&lt;/strong&gt;In October 2024, the&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;AI&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;coding assistant startup Poolside announced it raised&amp;nbsp;$500 million&amp;nbsp;led by Bain Capital Ventures. Nvidia participated in the round, which valued the AI startup at $3 billion.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Lambda:&amp;nbsp;&lt;/strong&gt;AI cloud provider Lambda, which provides services for model training, raised a&amp;nbsp;$480 million Series D&amp;nbsp;at a reported&amp;nbsp;$2.5 billion valuation&amp;nbsp;in February. The round was co-led by SGW and Andra Capital Lambda, and joined by Nvidia, ARK Invest, and others. A significant part of Lambda’s business involves renting servers powered by Nvidia’s GPUs.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;CoreWeave:&amp;nbsp;&lt;/strong&gt;Although CoreWeave is no longer a startup, but a public company, Nvidia invested in GPU-cloud provider&amp;nbsp;when it was still one, back in April 2023. That’s when CoreWeave raised&amp;nbsp;$221 million&amp;nbsp;in funding. Nvidia remains a significant shareholder.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Together AI:&amp;nbsp;&lt;/strong&gt;In February, Nvidia participated in the&amp;nbsp;$305 million Series B&amp;nbsp;of this company, which offers cloud-based infrastructure for building AI models. The round valued Together AI at $3.3 billion and was co-led by Prosperity7, a Saudi Arabian venture firm, and General Catalyst. Nvidia backed the company&amp;nbsp;for the first time&amp;nbsp;in 2023.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Firmus Technologies:&lt;/strong&gt;&amp;nbsp;In September, Firmus Technologies, the Singapore-based data center company, received&amp;nbsp;A$330 million&amp;nbsp;(approximately $215 million USD) in funding at a&amp;nbsp;A$1.85 billion&amp;nbsp;($1.2 billion USD) valuation from investors, including Nvidia. Firmus is developing an energy-efficient ‘AI factory’ in Tasmania, an island state of Australia. The startup originally provided cooling technologies for Bitcoin mining.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Sakana AI:&amp;nbsp;&lt;/strong&gt;In September 2024, Nvidia invested in&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;the&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;Japan-based startup, which trains low-cost generative AI models using small datasets. The startup raised a massive&amp;nbsp;Series A round of about $214 million&amp;nbsp;at a valuation of $1.5 billion.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Nuro&lt;/strong&gt;:&amp;nbsp;In August, Nvidia participated in the&amp;nbsp;$203 million&amp;nbsp;funding round for the self-driving startup focused on delivery. The deal valued Nuro at $6 billion, a significant 30% drop from its peak at $8.6 billion valuation in 2021.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Imbue:&amp;nbsp;&lt;/strong&gt;The AI research lab that&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;claims to be developing AI systems that can reason and code raised a&amp;nbsp;$200 million round in September 2023 from investors, including Nvidia, Astera Institute, and former Cruise CEO Kyle Vogt.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Waabi:&amp;nbsp;&lt;/strong&gt;In June 2024, the autonomous trucking startup raised a&amp;nbsp;$200 million Series B&amp;nbsp;round co-led by existing investors Uber and Khosla Ventures. Other investors included Nvidia, Volvo Group Venture Capital, and Porsche Automobil Holding SE.&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-deals-of-over-a-100-million"&gt;&lt;strong&gt;Deals of over a $100 million&lt;/strong&gt;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Ayar Labs:&amp;nbsp;&lt;/strong&gt;In December, Nvidia invested in the&amp;nbsp;$155 million round&amp;nbsp;of Ayar Labs, a&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;company developing optical interconnects to improve AI compute and power efficiency.&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;This was the third time Nvidia backed the startup.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Kore.ai:&amp;nbsp;&lt;/strong&gt;The startup developing enterprise-focused AI chatbots raised&amp;nbsp;$150 million&amp;nbsp;in December of 2023. In addition to Nvidia, investors participating in the funding included FTV Capital, Vistara Growth, and Sweetwater Private Equity.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Sandbox AQ:&lt;/strong&gt;&amp;nbsp;In April, Nvidia, alongside Google, BNP Paribas, and others, invested&amp;nbsp;$150 million&amp;nbsp;in Sandbox AQ, a startup developing large quantitative models (LQMs) for handling complex numerical analysis and statistical calculations. The investment increased Sandbox AQ’s Series E round to $450 million and the company’s valuation to $5.75 billion.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Hippocratic AI:&amp;nbsp;&lt;/strong&gt;This startup, which is developing large language models for healthcare, announced in January&amp;nbsp;that it raised a&amp;nbsp;$141 million Series B&amp;nbsp;at a valuation of $1.64 billion led by Kleiner Perkins. Nvidia participated in the round, along with returning investors Andreessen Horowitz, General Catalyst, and others. The company claims that its AI solutions can handle non-diagnostic patient-facing tasks such as pre-operating procedures, remote patient monitoring, and appointment preparation.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Weka:&amp;nbsp;&lt;/strong&gt;In May 2024, Nvidia invested in a&amp;nbsp;$140 million&amp;nbsp;round for AI-native data management platform Weka.&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;The round valued the Silicon Valley company at $1.6 billion.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Runway:&amp;nbsp;&lt;/strong&gt;In April, Nvidia participated in Runway’s&amp;nbsp;$308 million round, which was led by General Atlantic and valued the startup developing generative AI models for media production&amp;nbsp;at $3.55 billion, according to PitchBook data. The chipmaker has been an investor in&amp;nbsp;since 2023.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Bright Machines:&amp;nbsp;&lt;/strong&gt;In June 2024, Nvidia participated in a&amp;nbsp;$126 million Series C&amp;nbsp;of Bright Machines, a smart robotics and AI-driven software startup.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Enfabrica:&amp;nbsp;&lt;/strong&gt;In September 2023, Nvidia invested in networking chips designer Enfabrica’s&amp;nbsp;$125 million Series B. Although the startup raised another $115 million in November, Nvidia didn’t participate in the round.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Reka AI&lt;/strong&gt;:&amp;nbsp;In July, an AI research lab Reka, raised&amp;nbsp;$110 million&amp;nbsp;in a round that included Snowflake and Nvidia.&amp;nbsp;The deal tripled the startup’s valuation to&amp;nbsp;over $1 billion, according to Bloomberg.&amp;nbsp;&amp;nbsp;&lt;em&gt; &amp;nbsp;&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This post was first published in January 2025.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/12/nvidias-ai-empire-a-look-at-its-top-startup-investments/</guid><pubDate>Sun, 12 Oct 2025 15:30:28 +0000</pubDate></item><item><title>[NEW] We keep talking about AI agents, but do we ever know what they are? (AI | VentureBeat)</title><link>https://venturebeat.com/ai/we-keep-talking-about-ai-agents-but-do-we-ever-know-what-they-are</link><description>[unable to retrieve full-text content]&lt;p&gt;Imagine you do two things on a Monday morning.&lt;/p&gt;&lt;p&gt;First, you ask a chatbot to summarize your new emails. Next, you ask an AI tool to figure out why your top competitor grew so fast last quarter. The &lt;a href="https://venturebeat.com/ai/is-vibe-coding-ruining-a-generation-of-engineers"&gt;AI silently gets to work&lt;/a&gt;. It scours financial reports, news articles and social media sentiment. It cross-references that data with your internal sales numbers, drafts a strategy outlining three potential reasons for the competitor&amp;#x27;s success and schedules a 30-minute meeting with your team to present its findings.&lt;/p&gt;&lt;p&gt;We&amp;#x27;re calling both of these &amp;quot;&lt;a href="https://venturebeat.com/ai/neither-driver-nor-passenger-covenantal-co-creator"&gt;AI agents&lt;/a&gt;,&amp;quot; but they represent worlds of difference in intelligence, capability and the level of trust we place in them. This ambiguity creates a fog that makes it difficult to build, evaluate, and safely govern these powerful new tools. If we can&amp;#x27;t agree on what we&amp;#x27;re building, how can we know when we&amp;#x27;ve succeeded?&lt;/p&gt;&lt;p&gt;This post won&amp;#x27;t try to sell you on yet another definitive framework. Instead, think of it as a survey of the current landscape of agent autonomy, a map to help us all navigate the terrain together.&lt;/p&gt;&lt;h2&gt;What are we even talking about? Defining an &amp;quot;AI agent&amp;quot;&lt;/h2&gt;&lt;p&gt;Before we can measure an agent&amp;#x27;s autonomy, we need to agree on what an &amp;quot;agent&amp;quot; actually is. The most widely accepted starting point comes from the foundational textbook on AI, Stuart Russell and Peter Norvig’s&lt;a href="https://en.wikipedia.org/wiki/Intelligent_agent"&gt; “&lt;u&gt;Artificial Intelligence: A Modern Approach&lt;/u&gt;&lt;/a&gt;.” &lt;/p&gt;&lt;p&gt;They define an agent as anything that can be viewed as perceiving its environment through sensors and acting upon that environment through actuators. A thermostat is a simple agent: Its sensor perceives the room temperature, and its actuator acts by turning the heat on or off.&lt;/p&gt;&lt;p&gt;&lt;i&gt;ReAct Model for AI Agents (Credit: Confluent)&lt;/i&gt; &lt;/p&gt;&lt;p&gt;That classic definition provides a solid mental model. For today&amp;#x27;s technology, we can translate it into four key components that make up a modern AI agent:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Perception &lt;/b&gt;(the &amp;quot;senses&amp;quot;): This is how an agent takes in information about its digital or physical environment. It&amp;#x27;s the input stream that allows the agent to understand the current state of the world relevant to its task.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Reasoning engine&lt;/b&gt; (the &amp;quot;brain&amp;quot;): This is the core logic that processes the perceptions and decides what to do next. For modern agents, this is typically powered by a large language model (LLM). The engine is responsible for planning, breaking down large goals into smaller steps, handling errors and choosing the right tools for the job.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Action &lt;/b&gt;(the &amp;quot;hands&amp;quot;): This is how an agent affects its environment to move closer to its goal. The ability to take action via tools is what gives an agent its power.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Goal/objective&lt;/b&gt;: This is the overarching task or purpose that guides all of the agent&amp;#x27;s actions. It is the &amp;quot;why&amp;quot; that turns a collection of tools into a purposeful system. The goal can be simple (&amp;quot;Find the best price for this book&amp;quot;) or complex (&amp;quot;Launch the marketing campaign for our new product&amp;quot;)&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Putting it all together, a true agent is a full-body system. The reasoning engine is the brain, but it’s useless without the senses (perception) to understand the world and the hands (actions) to change it. This complete system, all guided by a central goal, is what creates genuine agency.&lt;/p&gt;&lt;p&gt;With these components in mind, the distinction we made earlier becomes clear. A standard chatbot isn&amp;#x27;t a true agent. It perceives your question and acts by providing an answer, but it lacks an overarching goal and the ability to use external tools to accomplish it.&lt;/p&gt;&lt;p&gt;An agent, on the other hand, is software that has agency. &lt;/p&gt;&lt;p&gt;It has the capacity to act independently and dynamically toward a goal. And it&amp;#x27;s this capacity that makes a discussion about the levels of autonomy so important.&lt;/p&gt;&lt;h2&gt;Learning from the past: How we learned to classify autonomy&lt;/h2&gt;&lt;p&gt;The dizzying pace of AI can make it feel like we&amp;#x27;re navigating uncharted territory. But when it comes to classifying autonomy, we’re not starting from scratch. Other industries have been working on this problem for decades, and their playbooks offer powerful lessons for the world of &lt;a href="https://venturebeat.com/ai/teaching-the-model-designing-llm-feedback-loops-that-get-smarter-over-time"&gt;AI agents&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The core challenge is always the same: How do you create a clear, shared language for the gradual handover of responsibility from a human to a machine?&lt;/p&gt;&lt;h3&gt;SAE levels of driving automation&lt;/h3&gt;&lt;p&gt;Perhaps the most successful framework comes from the automotive industry. The&lt;a href="https://www.sae.org/blog/sae-j3016-update"&gt; &lt;u&gt;SAE J3016 standard&lt;/u&gt;&lt;/a&gt; defines six levels of driving automation, from Level 0 (fully manual) to Level 5 (fully autonomous).&lt;/p&gt;&lt;p&gt;&lt;i&gt;The SAE J3016 Levels of Driving Automation (Credit: SAE International)&lt;/i&gt; &lt;/p&gt;&lt;p&gt;What makes this model so effective isn&amp;#x27;t its technical detail, but its focus on two simple concepts:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Dynamic driving task (DDT):&lt;/b&gt; This is everything involved in the real-time act of driving: steering, braking, accelerating and monitoring the road.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Operational design domain (ODD):&lt;/b&gt; These are the specific conditions under which the system is designed to work. For example, &amp;quot;only on divided highways&amp;quot; or &amp;quot;only in clear weather during the daytime.&amp;quot;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;The question for each level is simple: Who is doing the DDT, and what is the ODD? &lt;/p&gt;&lt;p&gt;At Level 2, the human must supervise at all times. At Level 3, the car handles the DDT within its ODD, but the human must be ready to take over. At Level 4, the car can handle everything within its ODD, and if it encounters a problem, it can safely pull over on its own.&lt;/p&gt;&lt;p&gt;&lt;b&gt;The key insight for AI agents:&lt;/b&gt; A robust framework isn&amp;#x27;t about the sophistication of the AI &amp;quot;brain.&amp;quot; It&amp;#x27;s about clearly defining the division of responsibility between human and machine under specific, well-defined conditions.&lt;/p&gt;&lt;h3&gt;Aviation&amp;#x27;s 10 Levels of Automation&lt;/h3&gt;&lt;p&gt;While the SAE’s six levels are great for broad classification, aviation offers a more granular model for systems designed for close human-machine collaboration. The&lt;a href="https://www.mitre.org/sites/default/files/2021-11/pr-16-3426-lessons-lost-automation-in-aviation-definition-of-automation.pdf"&gt; &lt;u&gt;Parasuraman, Sheridan, and Wickens model&lt;/u&gt;&lt;/a&gt; proposes a detailed 10-level spectrum of automation.&lt;/p&gt;&lt;p&gt;&lt;i&gt;Levels of Automation of Decision and Action Selection for Aviation (Credit: The MITRE Corporation)&lt;/i&gt;&lt;/p&gt;&lt;p&gt;This framework is less about full autonomy and more about the nuances of interaction. For example:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;At &lt;b&gt;Level 3&lt;/b&gt;, the computer &amp;quot;narrows the selection down to a few&amp;quot; for the human to choose from.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;At &lt;b&gt;Level 6&lt;/b&gt;, the computer &amp;quot;allows the human a restricted time to veto before it executes&amp;quot; an action.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;At &lt;b&gt;Level 9&lt;/b&gt;, the computer &amp;quot;informs the human only if it, the computer, decides to.&amp;quot;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;The key insight for AI agents:&lt;/b&gt; This model is perfect for describing the collaborative &amp;quot;centaur&amp;quot; systems we&amp;#x27;re seeing today. Most AI agents won&amp;#x27;t be fully autonomous (Level 10) but will exist somewhere on this spectrum, acting as a co-pilot that suggests, executes with approval or acts with a veto window.&lt;/p&gt;&lt;h3&gt;Robotics and unmanned systems&lt;/h3&gt;&lt;p&gt;Finally, the world of robotics brings in another critical dimension: context. The National Institute of Standards and Technology&amp;#x27;s (NIST)&lt;a href="https://www.nist.gov/el/intelligent-systems-division-73500/cognition-and-collaboration-systems/autonomy-levels-unmanned"&gt;&lt;u&gt; Autonomy Levels for Unmanned Systems (ALFUS) framework&lt;/u&gt;&lt;/a&gt; was designed for systems like drones and industrial robots.&lt;/p&gt;&lt;p&gt;&lt;i&gt;The Three-Axis Model for ALFUS (Credit: NIST)&lt;/i&gt; &lt;/p&gt;&lt;p&gt;Its main contribution is adding context to the definition of autonomy, assessing it along three axes:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Human independence:&lt;/b&gt; How much human supervision is required?&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Mission complexity:&lt;/b&gt; How difficult or unstructured is the task?&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Environmental complexity:&lt;/b&gt; How predictable and stable is the environment in which the agent operates?&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;The key insight for AI agents:&lt;/b&gt; This framework reminds us that autonomy isn&amp;#x27;t a single number. An agent performing a simple task in a stable, predictable digital environment (like sorting files in a single folder) is fundamentally less autonomous than an agent performing a complex task across the chaotic, unpredictable environment of the open internet, even if the level of human supervision is the same.&lt;/p&gt;&lt;h2&gt;The emerging frameworks for AI agents&lt;/h2&gt;&lt;p&gt;Having looked at the lessons from automotive, aviation and robotics, we can now examine the emerging frameworks designed for &lt;a href="https://venturebeat.com/ai/why-99-of-companies-fail-at-ai-integration-and-how-to-join-the-1-that"&gt;AI agents&lt;/a&gt;. While the field is still new and no single standard has won out, most proposals fall into three distinct, but often overlapping, categories based on the primary question they seek to answer.&lt;/p&gt;&lt;h3&gt;Category 1: The &amp;quot;What can it do?&amp;quot; frameworks (capability-focused)&lt;/h3&gt;&lt;p&gt;These frameworks classify agents based on their underlying technical architecture and what they are capable of achieving. They provide a roadmap for developers, outlining a progression of increasingly sophisticated technical milestones that often correspond directly to code patterns.&lt;/p&gt;&lt;p&gt;A prime example of this developer-centric approach comes from Hugging Face. Their&lt;a href="https://arxiv.org/pdf/2502.02649"&gt; &lt;u&gt;framework&lt;/u&gt;&lt;/a&gt; uses a star rating to show the gradual shift in control from human to AI:&lt;/p&gt;&lt;p&gt;&lt;i&gt;Five Levels of AI Agent Autonomy, as proposed by HuggingFace (Credit: Hugging Face)&lt;/i&gt;
&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Zero stars (simple processor):&lt;/b&gt; The AI has no impact on the program&amp;#x27;s flow. It simply processes information and its output is displayed, like a print statement. The human is in complete control.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;One star (router):&lt;/b&gt; The AI makes a basic decision that directs program flow, like choosing between two predefined paths (if/else). The human still defines &lt;i&gt;how&lt;/i&gt; everything is done.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Two stars (tool call):&lt;/b&gt; The AI chooses which predefined tool to use and what arguments to use with it. The human has defined the available tools, but the AI decides how to execute them.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Three stars (multi-step agent):&lt;/b&gt; The AI now controls the iteration loop. It decides which tool to use, when to use it and whether to continue working on the task.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Four stars (fully autonomous):&lt;/b&gt; The AI can generate and execute entirely new code to accomplish a goal, going beyond the predefined tools it was given.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;Strengths:&lt;/b&gt; This model is excellent for engineers. It&amp;#x27;s concrete, maps directly to code and clearly benchmarks the transfer of executive control to the AI. &lt;/p&gt;&lt;p&gt;&lt;b&gt;Weaknesses:&lt;/b&gt; It is highly technical and less intuitive for non-developers trying to understand an agent&amp;#x27;s real-world impact.&lt;/p&gt;&lt;h3&gt;Category 2: The &amp;quot;How do we work together?&amp;quot; frameworks (interaction-focused)&lt;/h3&gt;&lt;p&gt;This second category defines autonomy not by the agent’s internal skills, but by the nature of its relationship with the human user. The central question is: Who is in control, and how do we collaborate?&lt;/p&gt;&lt;p&gt;This approach often mirrors the nuance we saw in the aviation models. For instance, a framework detailed in the paper&lt;a href="https://arxiv.org/abs/2506.12469"&gt; &lt;u&gt;Levels of Autonomy for AI Agents&lt;/u&gt;&lt;/a&gt; defines levels based on the user&amp;#x27;s role:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;L1 - user as an operator:&lt;/b&gt; The human is in direct control (like a person using Photoshop with AI-assist features).&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;L4 - user as an approver:&lt;/b&gt; The agent proposes a full plan or action, and the human must give a simple &amp;quot;yes&amp;quot; or &amp;quot;no&amp;quot; before it proceeds.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;L5 - user as an observer:&lt;/b&gt; The agent has full autonomy to pursue a goal and simply reports its progress and results back to the human.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;i&gt;Levels of Autonomy for AI Agents&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Strengths:&lt;/b&gt; These frameworks are highly intuitive and user-centric. They directly address the critical issues of control, trust, and oversight.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Weaknesses:&lt;/b&gt; An agent with simple capabilities and one with highly advanced reasoning could both fall into the &amp;quot;Approver&amp;quot; level, so this approach can sometimes obscure the underlying technical sophistication.&lt;/p&gt;&lt;h3&gt;Category 3: The &amp;quot;Who is responsible?&amp;quot; frameworks (governance-focused)&lt;/h3&gt;&lt;p&gt;The final category is less concerned with how an agent works and more with what happens when it fails. These frameworks are designed to help answer crucial questions about law, safety and ethics.&lt;/p&gt;&lt;p&gt;Think tanks like Germany&amp;#x27;s Stiftung Neue VTrantwortung have&lt;a href="https://zavod14.si/wp-content/uploads/2019/12/ELF_PP_How-to-regulate-AI_2019.pdf"&gt; &lt;u&gt;analyzed&lt;/u&gt;&lt;/a&gt; AI agents through the lens of legal liability. Their work aims to classify agents in a way that helps regulators determine who is responsible for an agent&amp;#x27;s actions: The user who deployed it, the developer who built it or the company that owns the platform it runs on?&lt;/p&gt;&lt;p&gt;This perspective is essential for navigating complex regulations like the&lt;a href="https://artificialintelligenceact.eu/"&gt; &lt;u&gt;EU&amp;#x27;s Artificial Intelligence Act&lt;/u&gt;&lt;/a&gt;, which will treat AI systems differently based on the level of risk they pose.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Strengths:&lt;/b&gt; This approach is absolutely essential for real-world deployment. It forces the difficult but necessary conversations about accountability that build public trust.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Weaknesses:&lt;/b&gt; It&amp;#x27;s more of a legal or policy guide than a technical roadmap for developers.&lt;/p&gt;&lt;p&gt;A comprehensive understanding requires looking at all three questions at once: An agent&amp;#x27;s capabilities, how we interact with it and who is responsible for the outcome..&lt;/p&gt;&lt;h2&gt;Identifying the gaps and challenges&lt;/h2&gt;&lt;p&gt;Looking at the landscape of autonomy frameworks shows us that no  single model is sufficient because the true challenges lie in the gaps between them, in areas that are incredibly difficult to define and measure.&lt;/p&gt;&lt;h3&gt;What is the &amp;quot;Road&amp;quot; for a digital agent?&lt;/h3&gt;&lt;p&gt;The SAE framework for self-driving cars gave us the powerful concept of an ODD, the specific conditions under which a system can operate safely. For a car, that might be &amp;quot;divided highways, in clear weather, during the day.&amp;quot; This is a great solution for a physical environment, but what’s the ODD for a digital agent?&lt;/p&gt;&lt;p&gt;The &amp;quot;road&amp;quot; for an agent is the entire internet. An infinite, chaotic and constantly changing environment. Websites get redesigned overnight, APIs are deprecated and social norms in online communities shift. &lt;/p&gt;&lt;p&gt;How do we define a &amp;quot;safe&amp;quot; operational boundary for an agent that can browse websites, access databases and interact with third-party services? Answering this is one of the biggest unsolved problems. Without a clear digital ODD, we can&amp;#x27;t make the same safety guarantees that are becoming standard in the automotive world.&lt;/p&gt;&lt;p&gt;This is why, for now, the most effective and reliable agents operate within well-defined, closed-world scenarios. As I argued in a recent&lt;a href="https://venturebeat.com/ai/forget-the-hype-real-ai-agents-solve-bounded-problems-not-open-world-fantasies/"&gt; &lt;u&gt;VentureBeat article&lt;/u&gt;&lt;/a&gt;, forgetting the open-world fantasies and focusing on &amp;quot;bounded problems&amp;quot; is the key to real-world success. This means defining a clear, limited set of tools, data sources and potential actions. &lt;/p&gt;&lt;h3&gt;Beyond simple tool use&lt;/h3&gt;&lt;p&gt;Today&amp;#x27;s agents are getting very good at executing straightforward plans. If you tell one to &amp;quot;find the price of this item using Tool A, then book a meeting with Tool B,&amp;quot; it can often succeed. But true autonomy requires much more. &lt;/p&gt;&lt;p&gt;Many systems today hit a technical wall when faced with tasks that require:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Long-term reasoning and planning:&lt;/b&gt; Agents struggle to create and adapt complex, multi-step plans in the face of uncertainty. They can follow a recipe, but they can&amp;#x27;t yet invent one from scratch when things go wrong.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Robust self-correction:&lt;/b&gt; What happens when an API call fails or a website returns an unexpected error? A truly autonomous agent needs the resilience to diagnose the problem, form a new hypothesis and try a different approach, all without a human stepping in.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Composability:&lt;/b&gt; The future likely involves not one agent, but a team of specialized agents working together. Getting them to collaborate reliably, to pass information back and forth, delegate tasks and resolve conflicts is a monumental software engineering challenge that we are just beginning to tackle.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;The elephant in the room: Alignment and control&lt;/h3&gt;&lt;p&gt;This is the most critical challenge of all, because it&amp;#x27;s not just technical, it&amp;#x27;s deeply human. Alignment is the problem of ensuring an agent&amp;#x27;s goals and actions are consistent with our intentions and values, even when those values are complex, unstated or nuanced.&lt;/p&gt;&lt;p&gt;Imagine you give an agent the seemingly harmless goal of &amp;quot;maximizing customer engagement for our new product.&amp;quot; The agent might correctly determine that the most effective strategy is to send a dozen notifications a day to every user. The agent has achieved its literal goal perfectly, but it has violated the unstated, common-sense goal of &amp;quot;don&amp;#x27;t be incredibly annoying.&amp;quot;&lt;/p&gt;&lt;p&gt;This is a failure of alignment.&lt;/p&gt;&lt;p&gt;The core difficulty, which organizations like the&lt;a href="https://www.alignmentforum.org/"&gt; &lt;u&gt;AI Alignment Forum&lt;/u&gt;&lt;/a&gt; are dedicated to studying, is that it is incredibly hard to specify fuzzy, complex human preferences in the precise, literal language of code. As agents become more powerful, ensuring they are not just capable but also safe, predictable and aligned with our true intent becomes the most important challenge we face.&lt;/p&gt;&lt;h2&gt;The future is agentic (and collaborative)&lt;/h2&gt;&lt;p&gt;The path forward for AI agents is not a single leap to a god-like super-intelligence, but a more practical and collaborative journey. The immense challenges of open-world reasoning and perfect alignment mean that the future is a team effort.&lt;/p&gt;&lt;p&gt;We will see less of the single, all-powerful agent and more of an &amp;quot;agentic mesh&amp;quot; — a network of specialized agents, each operating within a bounded domain, working together to tackle complex problems. &lt;/p&gt;&lt;p&gt;More importantly, they will work with us. The most valuable and safest applications will keep a human on the loop, casting them as a co-pilot or strategist to augment our intellect with the speed of machine execution. This &amp;quot;centaur&amp;quot; model will be the most effective and responsible path forward.&lt;/p&gt;&lt;p&gt;The frameworks we&amp;#x27;ve explored aren’t just theoretical. They’re practical tools for building trust, assigning responsibility and setting clear expectations. They help developers define limits and leaders shape vision, laying the groundwork for AI to become a dependable partner in our work and lives.&lt;/p&gt;&lt;p&gt;&lt;i&gt;Sean Falconer is &lt;/i&gt;&lt;a href="https://www.confluent.io/"&gt;&lt;i&gt;Confluent&amp;#x27;s &lt;/i&gt;&lt;/a&gt;&lt;i&gt;AI entrepreneur in residence.&lt;/i&gt;&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;Imagine you do two things on a Monday morning.&lt;/p&gt;&lt;p&gt;First, you ask a chatbot to summarize your new emails. Next, you ask an AI tool to figure out why your top competitor grew so fast last quarter. The &lt;a href="https://venturebeat.com/ai/is-vibe-coding-ruining-a-generation-of-engineers"&gt;AI silently gets to work&lt;/a&gt;. It scours financial reports, news articles and social media sentiment. It cross-references that data with your internal sales numbers, drafts a strategy outlining three potential reasons for the competitor&amp;#x27;s success and schedules a 30-minute meeting with your team to present its findings.&lt;/p&gt;&lt;p&gt;We&amp;#x27;re calling both of these &amp;quot;&lt;a href="https://venturebeat.com/ai/neither-driver-nor-passenger-covenantal-co-creator"&gt;AI agents&lt;/a&gt;,&amp;quot; but they represent worlds of difference in intelligence, capability and the level of trust we place in them. This ambiguity creates a fog that makes it difficult to build, evaluate, and safely govern these powerful new tools. If we can&amp;#x27;t agree on what we&amp;#x27;re building, how can we know when we&amp;#x27;ve succeeded?&lt;/p&gt;&lt;p&gt;This post won&amp;#x27;t try to sell you on yet another definitive framework. Instead, think of it as a survey of the current landscape of agent autonomy, a map to help us all navigate the terrain together.&lt;/p&gt;&lt;h2&gt;What are we even talking about? Defining an &amp;quot;AI agent&amp;quot;&lt;/h2&gt;&lt;p&gt;Before we can measure an agent&amp;#x27;s autonomy, we need to agree on what an &amp;quot;agent&amp;quot; actually is. The most widely accepted starting point comes from the foundational textbook on AI, Stuart Russell and Peter Norvig’s&lt;a href="https://en.wikipedia.org/wiki/Intelligent_agent"&gt; “&lt;u&gt;Artificial Intelligence: A Modern Approach&lt;/u&gt;&lt;/a&gt;.” &lt;/p&gt;&lt;p&gt;They define an agent as anything that can be viewed as perceiving its environment through sensors and acting upon that environment through actuators. A thermostat is a simple agent: Its sensor perceives the room temperature, and its actuator acts by turning the heat on or off.&lt;/p&gt;&lt;p&gt;&lt;i&gt;ReAct Model for AI Agents (Credit: Confluent)&lt;/i&gt; &lt;/p&gt;&lt;p&gt;That classic definition provides a solid mental model. For today&amp;#x27;s technology, we can translate it into four key components that make up a modern AI agent:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Perception &lt;/b&gt;(the &amp;quot;senses&amp;quot;): This is how an agent takes in information about its digital or physical environment. It&amp;#x27;s the input stream that allows the agent to understand the current state of the world relevant to its task.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Reasoning engine&lt;/b&gt; (the &amp;quot;brain&amp;quot;): This is the core logic that processes the perceptions and decides what to do next. For modern agents, this is typically powered by a large language model (LLM). The engine is responsible for planning, breaking down large goals into smaller steps, handling errors and choosing the right tools for the job.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Action &lt;/b&gt;(the &amp;quot;hands&amp;quot;): This is how an agent affects its environment to move closer to its goal. The ability to take action via tools is what gives an agent its power.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Goal/objective&lt;/b&gt;: This is the overarching task or purpose that guides all of the agent&amp;#x27;s actions. It is the &amp;quot;why&amp;quot; that turns a collection of tools into a purposeful system. The goal can be simple (&amp;quot;Find the best price for this book&amp;quot;) or complex (&amp;quot;Launch the marketing campaign for our new product&amp;quot;)&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Putting it all together, a true agent is a full-body system. The reasoning engine is the brain, but it’s useless without the senses (perception) to understand the world and the hands (actions) to change it. This complete system, all guided by a central goal, is what creates genuine agency.&lt;/p&gt;&lt;p&gt;With these components in mind, the distinction we made earlier becomes clear. A standard chatbot isn&amp;#x27;t a true agent. It perceives your question and acts by providing an answer, but it lacks an overarching goal and the ability to use external tools to accomplish it.&lt;/p&gt;&lt;p&gt;An agent, on the other hand, is software that has agency. &lt;/p&gt;&lt;p&gt;It has the capacity to act independently and dynamically toward a goal. And it&amp;#x27;s this capacity that makes a discussion about the levels of autonomy so important.&lt;/p&gt;&lt;h2&gt;Learning from the past: How we learned to classify autonomy&lt;/h2&gt;&lt;p&gt;The dizzying pace of AI can make it feel like we&amp;#x27;re navigating uncharted territory. But when it comes to classifying autonomy, we’re not starting from scratch. Other industries have been working on this problem for decades, and their playbooks offer powerful lessons for the world of &lt;a href="https://venturebeat.com/ai/teaching-the-model-designing-llm-feedback-loops-that-get-smarter-over-time"&gt;AI agents&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The core challenge is always the same: How do you create a clear, shared language for the gradual handover of responsibility from a human to a machine?&lt;/p&gt;&lt;h3&gt;SAE levels of driving automation&lt;/h3&gt;&lt;p&gt;Perhaps the most successful framework comes from the automotive industry. The&lt;a href="https://www.sae.org/blog/sae-j3016-update"&gt; &lt;u&gt;SAE J3016 standard&lt;/u&gt;&lt;/a&gt; defines six levels of driving automation, from Level 0 (fully manual) to Level 5 (fully autonomous).&lt;/p&gt;&lt;p&gt;&lt;i&gt;The SAE J3016 Levels of Driving Automation (Credit: SAE International)&lt;/i&gt; &lt;/p&gt;&lt;p&gt;What makes this model so effective isn&amp;#x27;t its technical detail, but its focus on two simple concepts:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Dynamic driving task (DDT):&lt;/b&gt; This is everything involved in the real-time act of driving: steering, braking, accelerating and monitoring the road.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Operational design domain (ODD):&lt;/b&gt; These are the specific conditions under which the system is designed to work. For example, &amp;quot;only on divided highways&amp;quot; or &amp;quot;only in clear weather during the daytime.&amp;quot;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;The question for each level is simple: Who is doing the DDT, and what is the ODD? &lt;/p&gt;&lt;p&gt;At Level 2, the human must supervise at all times. At Level 3, the car handles the DDT within its ODD, but the human must be ready to take over. At Level 4, the car can handle everything within its ODD, and if it encounters a problem, it can safely pull over on its own.&lt;/p&gt;&lt;p&gt;&lt;b&gt;The key insight for AI agents:&lt;/b&gt; A robust framework isn&amp;#x27;t about the sophistication of the AI &amp;quot;brain.&amp;quot; It&amp;#x27;s about clearly defining the division of responsibility between human and machine under specific, well-defined conditions.&lt;/p&gt;&lt;h3&gt;Aviation&amp;#x27;s 10 Levels of Automation&lt;/h3&gt;&lt;p&gt;While the SAE’s six levels are great for broad classification, aviation offers a more granular model for systems designed for close human-machine collaboration. The&lt;a href="https://www.mitre.org/sites/default/files/2021-11/pr-16-3426-lessons-lost-automation-in-aviation-definition-of-automation.pdf"&gt; &lt;u&gt;Parasuraman, Sheridan, and Wickens model&lt;/u&gt;&lt;/a&gt; proposes a detailed 10-level spectrum of automation.&lt;/p&gt;&lt;p&gt;&lt;i&gt;Levels of Automation of Decision and Action Selection for Aviation (Credit: The MITRE Corporation)&lt;/i&gt;&lt;/p&gt;&lt;p&gt;This framework is less about full autonomy and more about the nuances of interaction. For example:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;At &lt;b&gt;Level 3&lt;/b&gt;, the computer &amp;quot;narrows the selection down to a few&amp;quot; for the human to choose from.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;At &lt;b&gt;Level 6&lt;/b&gt;, the computer &amp;quot;allows the human a restricted time to veto before it executes&amp;quot; an action.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;At &lt;b&gt;Level 9&lt;/b&gt;, the computer &amp;quot;informs the human only if it, the computer, decides to.&amp;quot;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;The key insight for AI agents:&lt;/b&gt; This model is perfect for describing the collaborative &amp;quot;centaur&amp;quot; systems we&amp;#x27;re seeing today. Most AI agents won&amp;#x27;t be fully autonomous (Level 10) but will exist somewhere on this spectrum, acting as a co-pilot that suggests, executes with approval or acts with a veto window.&lt;/p&gt;&lt;h3&gt;Robotics and unmanned systems&lt;/h3&gt;&lt;p&gt;Finally, the world of robotics brings in another critical dimension: context. The National Institute of Standards and Technology&amp;#x27;s (NIST)&lt;a href="https://www.nist.gov/el/intelligent-systems-division-73500/cognition-and-collaboration-systems/autonomy-levels-unmanned"&gt;&lt;u&gt; Autonomy Levels for Unmanned Systems (ALFUS) framework&lt;/u&gt;&lt;/a&gt; was designed for systems like drones and industrial robots.&lt;/p&gt;&lt;p&gt;&lt;i&gt;The Three-Axis Model for ALFUS (Credit: NIST)&lt;/i&gt; &lt;/p&gt;&lt;p&gt;Its main contribution is adding context to the definition of autonomy, assessing it along three axes:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Human independence:&lt;/b&gt; How much human supervision is required?&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Mission complexity:&lt;/b&gt; How difficult or unstructured is the task?&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Environmental complexity:&lt;/b&gt; How predictable and stable is the environment in which the agent operates?&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;The key insight for AI agents:&lt;/b&gt; This framework reminds us that autonomy isn&amp;#x27;t a single number. An agent performing a simple task in a stable, predictable digital environment (like sorting files in a single folder) is fundamentally less autonomous than an agent performing a complex task across the chaotic, unpredictable environment of the open internet, even if the level of human supervision is the same.&lt;/p&gt;&lt;h2&gt;The emerging frameworks for AI agents&lt;/h2&gt;&lt;p&gt;Having looked at the lessons from automotive, aviation and robotics, we can now examine the emerging frameworks designed for &lt;a href="https://venturebeat.com/ai/why-99-of-companies-fail-at-ai-integration-and-how-to-join-the-1-that"&gt;AI agents&lt;/a&gt;. While the field is still new and no single standard has won out, most proposals fall into three distinct, but often overlapping, categories based on the primary question they seek to answer.&lt;/p&gt;&lt;h3&gt;Category 1: The &amp;quot;What can it do?&amp;quot; frameworks (capability-focused)&lt;/h3&gt;&lt;p&gt;These frameworks classify agents based on their underlying technical architecture and what they are capable of achieving. They provide a roadmap for developers, outlining a progression of increasingly sophisticated technical milestones that often correspond directly to code patterns.&lt;/p&gt;&lt;p&gt;A prime example of this developer-centric approach comes from Hugging Face. Their&lt;a href="https://arxiv.org/pdf/2502.02649"&gt; &lt;u&gt;framework&lt;/u&gt;&lt;/a&gt; uses a star rating to show the gradual shift in control from human to AI:&lt;/p&gt;&lt;p&gt;&lt;i&gt;Five Levels of AI Agent Autonomy, as proposed by HuggingFace (Credit: Hugging Face)&lt;/i&gt;
&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Zero stars (simple processor):&lt;/b&gt; The AI has no impact on the program&amp;#x27;s flow. It simply processes information and its output is displayed, like a print statement. The human is in complete control.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;One star (router):&lt;/b&gt; The AI makes a basic decision that directs program flow, like choosing between two predefined paths (if/else). The human still defines &lt;i&gt;how&lt;/i&gt; everything is done.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Two stars (tool call):&lt;/b&gt; The AI chooses which predefined tool to use and what arguments to use with it. The human has defined the available tools, but the AI decides how to execute them.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Three stars (multi-step agent):&lt;/b&gt; The AI now controls the iteration loop. It decides which tool to use, when to use it and whether to continue working on the task.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Four stars (fully autonomous):&lt;/b&gt; The AI can generate and execute entirely new code to accomplish a goal, going beyond the predefined tools it was given.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;Strengths:&lt;/b&gt; This model is excellent for engineers. It&amp;#x27;s concrete, maps directly to code and clearly benchmarks the transfer of executive control to the AI. &lt;/p&gt;&lt;p&gt;&lt;b&gt;Weaknesses:&lt;/b&gt; It is highly technical and less intuitive for non-developers trying to understand an agent&amp;#x27;s real-world impact.&lt;/p&gt;&lt;h3&gt;Category 2: The &amp;quot;How do we work together?&amp;quot; frameworks (interaction-focused)&lt;/h3&gt;&lt;p&gt;This second category defines autonomy not by the agent’s internal skills, but by the nature of its relationship with the human user. The central question is: Who is in control, and how do we collaborate?&lt;/p&gt;&lt;p&gt;This approach often mirrors the nuance we saw in the aviation models. For instance, a framework detailed in the paper&lt;a href="https://arxiv.org/abs/2506.12469"&gt; &lt;u&gt;Levels of Autonomy for AI Agents&lt;/u&gt;&lt;/a&gt; defines levels based on the user&amp;#x27;s role:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;L1 - user as an operator:&lt;/b&gt; The human is in direct control (like a person using Photoshop with AI-assist features).&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;L4 - user as an approver:&lt;/b&gt; The agent proposes a full plan or action, and the human must give a simple &amp;quot;yes&amp;quot; or &amp;quot;no&amp;quot; before it proceeds.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;L5 - user as an observer:&lt;/b&gt; The agent has full autonomy to pursue a goal and simply reports its progress and results back to the human.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;i&gt;Levels of Autonomy for AI Agents&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Strengths:&lt;/b&gt; These frameworks are highly intuitive and user-centric. They directly address the critical issues of control, trust, and oversight.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Weaknesses:&lt;/b&gt; An agent with simple capabilities and one with highly advanced reasoning could both fall into the &amp;quot;Approver&amp;quot; level, so this approach can sometimes obscure the underlying technical sophistication.&lt;/p&gt;&lt;h3&gt;Category 3: The &amp;quot;Who is responsible?&amp;quot; frameworks (governance-focused)&lt;/h3&gt;&lt;p&gt;The final category is less concerned with how an agent works and more with what happens when it fails. These frameworks are designed to help answer crucial questions about law, safety and ethics.&lt;/p&gt;&lt;p&gt;Think tanks like Germany&amp;#x27;s Stiftung Neue VTrantwortung have&lt;a href="https://zavod14.si/wp-content/uploads/2019/12/ELF_PP_How-to-regulate-AI_2019.pdf"&gt; &lt;u&gt;analyzed&lt;/u&gt;&lt;/a&gt; AI agents through the lens of legal liability. Their work aims to classify agents in a way that helps regulators determine who is responsible for an agent&amp;#x27;s actions: The user who deployed it, the developer who built it or the company that owns the platform it runs on?&lt;/p&gt;&lt;p&gt;This perspective is essential for navigating complex regulations like the&lt;a href="https://artificialintelligenceact.eu/"&gt; &lt;u&gt;EU&amp;#x27;s Artificial Intelligence Act&lt;/u&gt;&lt;/a&gt;, which will treat AI systems differently based on the level of risk they pose.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Strengths:&lt;/b&gt; This approach is absolutely essential for real-world deployment. It forces the difficult but necessary conversations about accountability that build public trust.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Weaknesses:&lt;/b&gt; It&amp;#x27;s more of a legal or policy guide than a technical roadmap for developers.&lt;/p&gt;&lt;p&gt;A comprehensive understanding requires looking at all three questions at once: An agent&amp;#x27;s capabilities, how we interact with it and who is responsible for the outcome..&lt;/p&gt;&lt;h2&gt;Identifying the gaps and challenges&lt;/h2&gt;&lt;p&gt;Looking at the landscape of autonomy frameworks shows us that no  single model is sufficient because the true challenges lie in the gaps between them, in areas that are incredibly difficult to define and measure.&lt;/p&gt;&lt;h3&gt;What is the &amp;quot;Road&amp;quot; for a digital agent?&lt;/h3&gt;&lt;p&gt;The SAE framework for self-driving cars gave us the powerful concept of an ODD, the specific conditions under which a system can operate safely. For a car, that might be &amp;quot;divided highways, in clear weather, during the day.&amp;quot; This is a great solution for a physical environment, but what’s the ODD for a digital agent?&lt;/p&gt;&lt;p&gt;The &amp;quot;road&amp;quot; for an agent is the entire internet. An infinite, chaotic and constantly changing environment. Websites get redesigned overnight, APIs are deprecated and social norms in online communities shift. &lt;/p&gt;&lt;p&gt;How do we define a &amp;quot;safe&amp;quot; operational boundary for an agent that can browse websites, access databases and interact with third-party services? Answering this is one of the biggest unsolved problems. Without a clear digital ODD, we can&amp;#x27;t make the same safety guarantees that are becoming standard in the automotive world.&lt;/p&gt;&lt;p&gt;This is why, for now, the most effective and reliable agents operate within well-defined, closed-world scenarios. As I argued in a recent&lt;a href="https://venturebeat.com/ai/forget-the-hype-real-ai-agents-solve-bounded-problems-not-open-world-fantasies/"&gt; &lt;u&gt;VentureBeat article&lt;/u&gt;&lt;/a&gt;, forgetting the open-world fantasies and focusing on &amp;quot;bounded problems&amp;quot; is the key to real-world success. This means defining a clear, limited set of tools, data sources and potential actions. &lt;/p&gt;&lt;h3&gt;Beyond simple tool use&lt;/h3&gt;&lt;p&gt;Today&amp;#x27;s agents are getting very good at executing straightforward plans. If you tell one to &amp;quot;find the price of this item using Tool A, then book a meeting with Tool B,&amp;quot; it can often succeed. But true autonomy requires much more. &lt;/p&gt;&lt;p&gt;Many systems today hit a technical wall when faced with tasks that require:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Long-term reasoning and planning:&lt;/b&gt; Agents struggle to create and adapt complex, multi-step plans in the face of uncertainty. They can follow a recipe, but they can&amp;#x27;t yet invent one from scratch when things go wrong.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Robust self-correction:&lt;/b&gt; What happens when an API call fails or a website returns an unexpected error? A truly autonomous agent needs the resilience to diagnose the problem, form a new hypothesis and try a different approach, all without a human stepping in.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Composability:&lt;/b&gt; The future likely involves not one agent, but a team of specialized agents working together. Getting them to collaborate reliably, to pass information back and forth, delegate tasks and resolve conflicts is a monumental software engineering challenge that we are just beginning to tackle.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;The elephant in the room: Alignment and control&lt;/h3&gt;&lt;p&gt;This is the most critical challenge of all, because it&amp;#x27;s not just technical, it&amp;#x27;s deeply human. Alignment is the problem of ensuring an agent&amp;#x27;s goals and actions are consistent with our intentions and values, even when those values are complex, unstated or nuanced.&lt;/p&gt;&lt;p&gt;Imagine you give an agent the seemingly harmless goal of &amp;quot;maximizing customer engagement for our new product.&amp;quot; The agent might correctly determine that the most effective strategy is to send a dozen notifications a day to every user. The agent has achieved its literal goal perfectly, but it has violated the unstated, common-sense goal of &amp;quot;don&amp;#x27;t be incredibly annoying.&amp;quot;&lt;/p&gt;&lt;p&gt;This is a failure of alignment.&lt;/p&gt;&lt;p&gt;The core difficulty, which organizations like the&lt;a href="https://www.alignmentforum.org/"&gt; &lt;u&gt;AI Alignment Forum&lt;/u&gt;&lt;/a&gt; are dedicated to studying, is that it is incredibly hard to specify fuzzy, complex human preferences in the precise, literal language of code. As agents become more powerful, ensuring they are not just capable but also safe, predictable and aligned with our true intent becomes the most important challenge we face.&lt;/p&gt;&lt;h2&gt;The future is agentic (and collaborative)&lt;/h2&gt;&lt;p&gt;The path forward for AI agents is not a single leap to a god-like super-intelligence, but a more practical and collaborative journey. The immense challenges of open-world reasoning and perfect alignment mean that the future is a team effort.&lt;/p&gt;&lt;p&gt;We will see less of the single, all-powerful agent and more of an &amp;quot;agentic mesh&amp;quot; — a network of specialized agents, each operating within a bounded domain, working together to tackle complex problems. &lt;/p&gt;&lt;p&gt;More importantly, they will work with us. The most valuable and safest applications will keep a human on the loop, casting them as a co-pilot or strategist to augment our intellect with the speed of machine execution. This &amp;quot;centaur&amp;quot; model will be the most effective and responsible path forward.&lt;/p&gt;&lt;p&gt;The frameworks we&amp;#x27;ve explored aren’t just theoretical. They’re practical tools for building trust, assigning responsibility and setting clear expectations. They help developers define limits and leaders shape vision, laying the groundwork for AI to become a dependable partner in our work and lives.&lt;/p&gt;&lt;p&gt;&lt;i&gt;Sean Falconer is &lt;/i&gt;&lt;a href="https://www.confluent.io/"&gt;&lt;i&gt;Confluent&amp;#x27;s &lt;/i&gt;&lt;/a&gt;&lt;i&gt;AI entrepreneur in residence.&lt;/i&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/we-keep-talking-about-ai-agents-but-do-we-ever-know-what-they-are</guid><pubDate>Sun, 12 Oct 2025 19:00:00 +0000</pubDate></item></channel></rss>