<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 27 Sep 2025 06:27:23 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>YouTube Music tests AI hosts that share trivia and commentary (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/26/youtube-music-tests-ai-hosts-that-share-trivia-and-commentary/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/07/youtube-music-icon.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;YouTube Music is testing AI music hosts that provide relevant stories, fan trivia, and commentary about what you’re listening to, the company announced on Friday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The move comes two years after Spotify launched an AI DJ that delivers a curated selection of music alongside AI-powered spoken commentary about the tracks and artists you like. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;YouTube Music’s new feature builds on its ongoing experiments with conversational AI. In July, the service rolled out an AI conversational radio feature that lets users create a custom radio station by describing what they want to hear.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube Music’s new AI hosts are currently being tested through YouTube Labs, the platform’s new hub for AI experiments. In a blog post, the company said YouTube Labs is “a new initiative dedicated to exploring the potential of AI on YouTube.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube Labs is similar to Google Labs, Google’s experimental arm that lets users test early-stage AI products and provide feedback. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube Labs is open to all YouTube users, which means they don’t need a Premium membership to sign up. However, the company notes that only a limited number of U.S.-based participants&amp;nbsp;will be given access to the experimental program.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube Labs has been implementing AI features across YouTube recently.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Earlier this month, the company released a series of AI features for creators, including GenAI tools for Shorts creation. A few months ago, YouTube launched an AI-powered search results carousel similar to Google’s AI Overviews and expanded access to its conversational AI tool to help users find more information, receive content recommendations, and get video summaries.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While YouTube is embracing AI features, it’s also cracking down on AI slop. The platform recently updated its policies to crack down on creators’ ability to generate revenue from “inauthentic” content, including mass-produced videos and other types of repetitive content.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/07/youtube-music-icon.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;YouTube Music is testing AI music hosts that provide relevant stories, fan trivia, and commentary about what you’re listening to, the company announced on Friday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The move comes two years after Spotify launched an AI DJ that delivers a curated selection of music alongside AI-powered spoken commentary about the tracks and artists you like. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;YouTube Music’s new feature builds on its ongoing experiments with conversational AI. In July, the service rolled out an AI conversational radio feature that lets users create a custom radio station by describing what they want to hear.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube Music’s new AI hosts are currently being tested through YouTube Labs, the platform’s new hub for AI experiments. In a blog post, the company said YouTube Labs is “a new initiative dedicated to exploring the potential of AI on YouTube.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube Labs is similar to Google Labs, Google’s experimental arm that lets users test early-stage AI products and provide feedback. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube Labs is open to all YouTube users, which means they don’t need a Premium membership to sign up. However, the company notes that only a limited number of U.S.-based participants&amp;nbsp;will be given access to the experimental program.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube Labs has been implementing AI features across YouTube recently.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Earlier this month, the company released a series of AI features for creators, including GenAI tools for Shorts creation. A few months ago, YouTube launched an AI-powered search results carousel similar to Google’s AI Overviews and expanded access to its conversational AI tool to help users find more information, receive content recommendations, and get video summaries.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While YouTube is embracing AI features, it’s also cracking down on AI slop. The platform recently updated its policies to crack down on creators’ ability to generate revenue from “inauthentic” content, including mass-produced videos and other types of repetitive content.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/26/youtube-music-tests-ai-hosts-that-share-trivia-and-commentary/</guid><pubDate>Fri, 26 Sep 2025 19:02:02 +0000</pubDate></item><item><title>US investigators are using AI to detect child abuse images made by AI (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/26/1124343/us-investigators-are-using-ai-to-detect-child-abuse-images-made-by-ai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/detect-kids.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Generative AI has enabled the production of child sexual abuse images to skyrocket. Now the leading investigator of child exploitation in the US is experimenting with using AI to distinguish AI-generated images from material depicting real victims, according to a new government filing.&lt;/p&gt;  &lt;p&gt;The Department of Homeland Security’s Cyber Crimes Center, which investigates child exploitation across international borders, has awarded a $150,000 contract to San Francisco–based Hive AI for its software, which can identify whether a piece of content was AI-generated.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The filing, posted on September 19, is heavily redacted and Hive cofounder and CEO Kevin Guo told &lt;em&gt;MIT Technology Review&lt;/em&gt; that he could not discuss the details of the contract, but confirmed it involves use of the company’s AI detection algorithms for child sexual abuse material (CSAM).&lt;/p&gt;  &lt;p&gt;The filing quotes data from the National Center for Missing and Exploited Children that reported a 1,325% increase in incidents involving generative AI in 2024. “The sheer volume of digital content circulating online necessitates the use of automated tools to process and analyze data efficiently,” the filing reads.&lt;/p&gt; 
 &lt;p&gt;The first priority of child exploitation investigators is to find and stop any abuse currently happening, but the flood of AI-generated CSAM has made it difficult for investigators to know whether images depict a real victim currently at risk. A tool that could successfully flag real victims would be a massive help when they try to prioritize cases.&lt;/p&gt;  &lt;p&gt;Identifying AI-generated images “ensures that investigative resources are focused on cases involving real victims, maximizing the program’s impact and safeguarding vulnerable individuals,” the filing reads.&lt;/p&gt; 
 &lt;p&gt;Hive AI offers AI tools that create videos and images, as well as a range of content moderation tools that can flag violence, spam, and sexual material and even identify celebrities. In December, &lt;em&gt;MIT Technology Review&lt;/em&gt; reported that the company was selling its deepfake-detection technology to the US military.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;For detecting CSAM, Hive offers a tool created with Thorn, a child safety nonprofit, which companies can integrate into their platforms. This tool uses a “hashing” system, which assigns unique IDs to content known by investigators to be CSAM, and blocks that material from being uploaded. This tool, and others like it, have become a standard line of defense for tech companies.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But these tools simply identify a piece of content as CSAM; they don’t detect whether it was generated by AI. Hive has created a separate tool that determines whether images in general were AI-generated. Though it is not trained specifically to work on CSAM, according to Guo, it doesn’t need to be.&lt;/p&gt;  &lt;p&gt;“There’s some underlying combination of pixels in this image that we can identify” as AI-generated, he says. “It can be generalizable.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;This tool, Guo says, is what the Cyber Crimes Center will be using to evaluate CSAM. He adds that Hive benchmarks its detection tools for each specific use case its customers have in mind.&lt;/p&gt;  &lt;p&gt;The National Center for Missing and Exploited Children, which participates in efforts to stop the spread of CSAM, did not respond to requests for comment on the effectiveness of such detection models in time for publication.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In its filing, the government justifies awarding the contract to Hive without a competitive bidding process. Though parts of this justification are redacted, it primarily references two points also found in a Hive presentation slide deck. One involves a 2024 study from the University of Chicago, which found that Hive’s AI detection tool outranked four other detectors in identifying AI-generated art. The other is its contract with the Pentagon for identifying deepfakes. The trial will last three months.&amp;nbsp;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/detect-kids.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Generative AI has enabled the production of child sexual abuse images to skyrocket. Now the leading investigator of child exploitation in the US is experimenting with using AI to distinguish AI-generated images from material depicting real victims, according to a new government filing.&lt;/p&gt;  &lt;p&gt;The Department of Homeland Security’s Cyber Crimes Center, which investigates child exploitation across international borders, has awarded a $150,000 contract to San Francisco–based Hive AI for its software, which can identify whether a piece of content was AI-generated.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The filing, posted on September 19, is heavily redacted and Hive cofounder and CEO Kevin Guo told &lt;em&gt;MIT Technology Review&lt;/em&gt; that he could not discuss the details of the contract, but confirmed it involves use of the company’s AI detection algorithms for child sexual abuse material (CSAM).&lt;/p&gt;  &lt;p&gt;The filing quotes data from the National Center for Missing and Exploited Children that reported a 1,325% increase in incidents involving generative AI in 2024. “The sheer volume of digital content circulating online necessitates the use of automated tools to process and analyze data efficiently,” the filing reads.&lt;/p&gt; 
 &lt;p&gt;The first priority of child exploitation investigators is to find and stop any abuse currently happening, but the flood of AI-generated CSAM has made it difficult for investigators to know whether images depict a real victim currently at risk. A tool that could successfully flag real victims would be a massive help when they try to prioritize cases.&lt;/p&gt;  &lt;p&gt;Identifying AI-generated images “ensures that investigative resources are focused on cases involving real victims, maximizing the program’s impact and safeguarding vulnerable individuals,” the filing reads.&lt;/p&gt; 
 &lt;p&gt;Hive AI offers AI tools that create videos and images, as well as a range of content moderation tools that can flag violence, spam, and sexual material and even identify celebrities. In December, &lt;em&gt;MIT Technology Review&lt;/em&gt; reported that the company was selling its deepfake-detection technology to the US military.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;For detecting CSAM, Hive offers a tool created with Thorn, a child safety nonprofit, which companies can integrate into their platforms. This tool uses a “hashing” system, which assigns unique IDs to content known by investigators to be CSAM, and blocks that material from being uploaded. This tool, and others like it, have become a standard line of defense for tech companies.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But these tools simply identify a piece of content as CSAM; they don’t detect whether it was generated by AI. Hive has created a separate tool that determines whether images in general were AI-generated. Though it is not trained specifically to work on CSAM, according to Guo, it doesn’t need to be.&lt;/p&gt;  &lt;p&gt;“There’s some underlying combination of pixels in this image that we can identify” as AI-generated, he says. “It can be generalizable.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;This tool, Guo says, is what the Cyber Crimes Center will be using to evaluate CSAM. He adds that Hive benchmarks its detection tools for each specific use case its customers have in mind.&lt;/p&gt;  &lt;p&gt;The National Center for Missing and Exploited Children, which participates in efforts to stop the spread of CSAM, did not respond to requests for comment on the effectiveness of such detection models in time for publication.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In its filing, the government justifies awarding the contract to Hive without a competitive bidding process. Though parts of this justification are redacted, it primarily references two points also found in a Hive presentation slide deck. One involves a 2024 study from the University of Chicago, which found that Hive’s AI detection tool outranked four other detectors in identifying AI-generated art. The other is its contract with the Pentagon for identifying deepfakes. The trial will last three months.&amp;nbsp;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/26/1124343/us-investigators-are-using-ai-to-detect-child-abuse-images-made-by-ai/</guid><pubDate>Fri, 26 Sep 2025 19:03:34 +0000</pubDate></item><item><title>What’s behind the massive AI data center headlines? (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/26/whats-behind-the-massive-ai-data-center-headlines/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/02/GettyImages-957037038-nvidia.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Silicon Valley flooded the news this week with headlines about wild AI infrastructure investments. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia said it would invest up to $100 billion in OpenAI. Then OpenAI said it would build out five more Stargate AI data centers with Oracle and SoftBank, adding gigawatts of new capacity online in the coming years. And it was later revealed that Oracle sold $18 billion in bonds to pay for these data centers.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On their own, each deal is dizzying in scale. But in aggregate, we see how Silicon Valley is moving heaven and earth to give OpenAI enough power to train and serve future versions of ChatGPT.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This week on Equity, Anthony Ha and I (Max Zeff) go beyond the headlines to break down what’s really going on in these AI infrastructure deals.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Rather conveniently, OpenAI also gave the world a glimpse this week of a power-intensive feature it could serve more broadly if it had access to more AI data centers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company launched Pulse — a new feature in ChatGPT that works overnight to deliver personalized morning briefings for users. The experience feels similar to a news app or a social feed — something you check first thing in the morning — but doesn’t have posts from other users or ads (yet).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Pulse is part of a new class of OpenAI products that work independently, even when users aren’t in the ChatGPT app. The company would like to deliver a lot more of these features and roll them out to free users, but they’re limited by the number of computer servers available to them. OpenAI said it can only offer Pulse to its $200-a-month Pro subscribers right now due to capacity constraints.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The real question is whether features like Pulse are worth the hundreds of billions of dollars being invested in AI data centers to support OpenAI. The feature looks cool and all, but that’s a tall order.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Watch the full episode to hear more about the massive AI infrastructure investments reshaping Silicon Valley, TikTok’s ownership saga, and the policy changes affecting tech’s biggest players.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/02/GettyImages-957037038-nvidia.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Silicon Valley flooded the news this week with headlines about wild AI infrastructure investments. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia said it would invest up to $100 billion in OpenAI. Then OpenAI said it would build out five more Stargate AI data centers with Oracle and SoftBank, adding gigawatts of new capacity online in the coming years. And it was later revealed that Oracle sold $18 billion in bonds to pay for these data centers.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On their own, each deal is dizzying in scale. But in aggregate, we see how Silicon Valley is moving heaven and earth to give OpenAI enough power to train and serve future versions of ChatGPT.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This week on Equity, Anthony Ha and I (Max Zeff) go beyond the headlines to break down what’s really going on in these AI infrastructure deals.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Rather conveniently, OpenAI also gave the world a glimpse this week of a power-intensive feature it could serve more broadly if it had access to more AI data centers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company launched Pulse — a new feature in ChatGPT that works overnight to deliver personalized morning briefings for users. The experience feels similar to a news app or a social feed — something you check first thing in the morning — but doesn’t have posts from other users or ads (yet).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Pulse is part of a new class of OpenAI products that work independently, even when users aren’t in the ChatGPT app. The company would like to deliver a lot more of these features and roll them out to free users, but they’re limited by the number of computer servers available to them. OpenAI said it can only offer Pulse to its $200-a-month Pro subscribers right now due to capacity constraints.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The real question is whether features like Pulse are worth the hundreds of billions of dollars being invested in AI data centers to support OpenAI. The feature looks cool and all, but that’s a tall order.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Watch the full episode to hear more about the massive AI infrastructure investments reshaping Silicon Valley, TikTok’s ownership saga, and the policy changes affecting tech’s biggest players.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/26/whats-behind-the-massive-ai-data-center-headlines/</guid><pubDate>Fri, 26 Sep 2025 19:40:24 +0000</pubDate></item><item><title>YouTube Music is testing AI hosts that will interrupt your tunes (AI – Ars Technica)</title><link>https://arstechnica.com/google/2025/09/youtube-music-is-testing-ai-hosts-that-will-interrupt-your-tunes/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        YouTube Labs will be a place to preview all the app's upcoming AI features.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="YouTube labs" class="absolute inset-0 w-full h-full object-cover hidden" height="379" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/YTP_YTLabs-640x379.jpg" width="640" /&gt;
                  &lt;img alt="YouTube labs" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="468" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/YTP_YTLabs.jpg" width="790" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;YouTube has a new Labs program, allowing listeners to "discover the next generation of YouTube." In case you were wondering, that generation is apparently all about AI. The streaming site says Labs will offer a glimpse of the AI features it's developing for YouTube Music, and it starts with AI "hosts" that will chime in while you're listening to music. Yes, really.&lt;/p&gt;
&lt;p&gt;The new AI music hosts are supposed to provide a richer listening experience, according to YouTube. As you're listening to tunes, the AI will generate audio snippets similar to, but shorter than, the fake podcasts you can create in NotebookLM. The "Beyond the Beat" host will break in every so often with relevant stories, trivia, and commentary about your musical tastes. YouTube says this feature will appear when you are listening to mixes and radio stations.&lt;/p&gt;
&lt;p&gt;The experimental feature is intended to be a bit like having a radio host drop some playful banter while cueing up the next song. It sounds a bit like Spotify's AI DJ, but the YouTube AI doesn't create playlists like Spotify's robot. This is still generative AI, which comes with the risk of hallucinations and low-quality slop, neither of which belongs in your music. That said, Google's Audio Overviews are often surprisingly good in small doses.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;To opt in, visit the new YouTube Labs landing page. After joining, the YouTube Music app will get a new button on the Now Playing screen with the familiar Gemini sparkle logo. Tapping that will allow you to snooze the commentary for an hour or the remainder of the day. There is no option to completely disable the AI host in the app, so you'll have to opt out of the test if you decide Beyond the Beat is more trouble than it's worth.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2119422 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="1012" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/YT-AI-snooze.png" width="1280" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      You can snooze the AI host.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;We've been on the hunt for this AI host since opting into the test several hours ago, but the robot has yet to appear. YouTube says the feature is now live for a "limited number" of US testers to try, but it's possible the frequency of AI interruptions will change as Google gathers more data on how much people like (or don't) having a robot tell them about music.&lt;/p&gt;
&lt;p&gt;This is the only experiment available in YouTube Labs for now, but the company says more AI features will be added to Labs soon. This will help Google gather feedback to decide how to roll out the features widely. So if you have strong feelings about the AI host, it may be worthwhile to submit feedback from the Labs page. YouTube is accelerating its use of AI. On the video side, the site is working toward releasing a suite of AI video tools, and it automatically upscales some videos, much to the chagrin of uploaders.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        YouTube Labs will be a place to preview all the app's upcoming AI features.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="YouTube labs" class="absolute inset-0 w-full h-full object-cover hidden" height="379" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/YTP_YTLabs-640x379.jpg" width="640" /&gt;
                  &lt;img alt="YouTube labs" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="468" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/YTP_YTLabs.jpg" width="790" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;YouTube has a new Labs program, allowing listeners to "discover the next generation of YouTube." In case you were wondering, that generation is apparently all about AI. The streaming site says Labs will offer a glimpse of the AI features it's developing for YouTube Music, and it starts with AI "hosts" that will chime in while you're listening to music. Yes, really.&lt;/p&gt;
&lt;p&gt;The new AI music hosts are supposed to provide a richer listening experience, according to YouTube. As you're listening to tunes, the AI will generate audio snippets similar to, but shorter than, the fake podcasts you can create in NotebookLM. The "Beyond the Beat" host will break in every so often with relevant stories, trivia, and commentary about your musical tastes. YouTube says this feature will appear when you are listening to mixes and radio stations.&lt;/p&gt;
&lt;p&gt;The experimental feature is intended to be a bit like having a radio host drop some playful banter while cueing up the next song. It sounds a bit like Spotify's AI DJ, but the YouTube AI doesn't create playlists like Spotify's robot. This is still generative AI, which comes with the risk of hallucinations and low-quality slop, neither of which belongs in your music. That said, Google's Audio Overviews are often surprisingly good in small doses.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;To opt in, visit the new YouTube Labs landing page. After joining, the YouTube Music app will get a new button on the Now Playing screen with the familiar Gemini sparkle logo. Tapping that will allow you to snooze the commentary for an hour or the remainder of the day. There is no option to completely disable the AI host in the app, so you'll have to opt out of the test if you decide Beyond the Beat is more trouble than it's worth.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2119422 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="1012" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/YT-AI-snooze.png" width="1280" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      You can snooze the AI host.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;We've been on the hunt for this AI host since opting into the test several hours ago, but the robot has yet to appear. YouTube says the feature is now live for a "limited number" of US testers to try, but it's possible the frequency of AI interruptions will change as Google gathers more data on how much people like (or don't) having a robot tell them about music.&lt;/p&gt;
&lt;p&gt;This is the only experiment available in YouTube Labs for now, but the company says more AI features will be added to Labs soon. This will help Google gather feedback to decide how to roll out the features widely. So if you have strong feelings about the AI host, it may be worthwhile to submit feedback from the Labs page. YouTube is accelerating its use of AI. On the video side, the site is working toward releasing a suite of AI video tools, and it automatically upscales some videos, much to the chagrin of uploaders.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/google/2025/09/youtube-music-is-testing-ai-hosts-that-will-interrupt-your-tunes/</guid><pubDate>Fri, 26 Sep 2025 21:05:30 +0000</pubDate></item><item><title>Can AI detect hedgehogs from space? Maybe if you find brambles first. (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/09/can-ai-detect-hedgehogs-from-space-maybe-if-you-find-brambles-first/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Cambridge researchers use satellite-based bramble detection as a proxy for mapping hedgehog habitats.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="An adult UK hedgehog, erinaceus europaeus, among autumn leaves and a fly agaric mushroom." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/uk_hedgehog_1-640x360.jpg" width="640" /&gt;
                  &lt;img alt="An adult UK hedgehog, erinaceus europaeus, among autumn leaves and a fly agaric mushroom." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/uk_hedgehog_1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      An adult UK hedgehog among autumn leaves and a fly agaric mushroom.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Mike Powles via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;You can't spot a hedgehog from space, but you might be able to find where they live by looking for brambles. That's the premise behind ongoing research at the University of Cambridge, where scientists are using satellite imagery and AI models to map potential hedgehog habitats across the UK by first identifying their favorite hiding spots: bramble patches.&lt;/p&gt;
&lt;p&gt;European hedgehog populations have declined by roughly 30 to 50 percent over the past decade, so tracking these nocturnal creatures across large areas remains difficult and expensive. Rather than searching for the hedgehogs directly, researcher Gabriel Mahler developed an AI model that identifies brambles, which are thorny shrubs that hedgehogs use for shelter and foraging, from satellite data.&lt;/p&gt;
&lt;p&gt;These small mammals rely on this type of dense vegetation for daytime shelter, nesting sites, and protection from predators. Brambles also attract insects and provide berries, supporting the invertebrate populations that hedgehogs eat.&lt;/p&gt;
&lt;p&gt;Traditional hedgehog surveys require extensive nighttime fieldwork, specialized equipment, or citizen scientists reporting sightings. Those are methods that don't scale well for national conservation planning. By contrast, satellite imagery covers vast areas continuously, and if AI models could reliably identify key habitat features like brambles, conservationists might gain a powerful tool for large-scale habitat assessment.&lt;/p&gt;
&lt;h2&gt;From satellites to shrubs&lt;/h2&gt;
&lt;p&gt;While AI is a popular buzzword these days, it's worth noting that the Cambridge team's detector is not based on a large language model like ChatGPT. Instead, the model uses relatively simple machine learning techniques: a combination of logistic regression and k-nearest neighbors classification.&lt;/p&gt;
&lt;p&gt;Mahler's bramble detector also combines TESSERA earth representation embeddings, which process imagery from the European Space Agency's Sentinel satellites, with ground-truth observations from iNaturalist, a citizen science platform.&lt;/p&gt;
&lt;p&gt;But does it actually work? To find out, Mahler and colleagues Sadiq Jaffer, Anil Madhavapeddy, and Shane Weisz spent a day walking around Cambridge with smartphones and GPS devices, checking whether the model's predictions matched reality.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"It took us about 20 seconds to find the first one in an area indicated by the model," wrote Jaffer in a blog post documenting the field test. Starting at Milton Community Centre, where the model showed high confidence of brambles near the car park, the team systematically visited locations with varying prediction levels.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2119476 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="The research team locating their first bramble." class="fullwidth full" height="768" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/20250924_130422.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The research team locating their first bramble.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Sadiq Jaffer

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;At Milton Country Park, every high-confidence area they checked contained substantial bramble growth. When they investigated a residential hotspot, they found an empty plot overrun with brambles. Most amusingly, a major prediction in North Cambridge led them to Bramblefields Local Nature Reserve. True to its name, the area contained extensive bramble coverage.&lt;/p&gt;
&lt;p&gt;The model reportedly performed best when detecting large, uncovered bramble patches visible from above. Smaller brambles under tree cover showed lower confidence scores—a logical limitation given the satellite's overhead perspective. "Since TESSERA is learned representation from remote sensing data, it would make sense that bramble partially obscured from above might be harder to spot," Jaffer explained.&lt;/p&gt;
&lt;h2&gt;An early experiment&lt;/h2&gt;
&lt;p&gt;While the researchers expressed enthusiasm over the early results, the bramble detection work represents a proof-of-concept that is still under active research. The model has not yet been published in a peer-reviewed journal, and the field validation described here was an informal test rather than a scientific study. The Cambridge team acknowledges these limitations and plans more systematic validation.&lt;/p&gt;
&lt;p&gt;However, it's still a relatively positive research application of neural network techniques that reminds us that the field of artificial intelligence is much larger than just generative AI models, such as ChatGPT, or video synthesis models.&lt;/p&gt;
&lt;p&gt;Should the team's research pan out, the simplicity of the bramble detector offers some practical advantages. Unlike more resource-intensive deep learning models, the system could potentially run on mobile devices, enabling real-time field validation. The team considered developing a phone-based active learning system that would enable field researchers to improve the model while verifying its predictions.&lt;/p&gt;
&lt;p&gt;In the future, similar AI-based approaches combining satellite remote sensing with citizen science data could potentially map invasive species, track agricultural pests, or monitor changes in various ecosystems. For threatened species like hedgehogs, rapidly mapping critical habitat features becomes increasingly valuable during a time when climate change and urbanization are actively reshaping the places that hedgehogs like to call home.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Cambridge researchers use satellite-based bramble detection as a proxy for mapping hedgehog habitats.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="An adult UK hedgehog, erinaceus europaeus, among autumn leaves and a fly agaric mushroom." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/uk_hedgehog_1-640x360.jpg" width="640" /&gt;
                  &lt;img alt="An adult UK hedgehog, erinaceus europaeus, among autumn leaves and a fly agaric mushroom." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/uk_hedgehog_1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      An adult UK hedgehog among autumn leaves and a fly agaric mushroom.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Mike Powles via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;You can't spot a hedgehog from space, but you might be able to find where they live by looking for brambles. That's the premise behind ongoing research at the University of Cambridge, where scientists are using satellite imagery and AI models to map potential hedgehog habitats across the UK by first identifying their favorite hiding spots: bramble patches.&lt;/p&gt;
&lt;p&gt;European hedgehog populations have declined by roughly 30 to 50 percent over the past decade, so tracking these nocturnal creatures across large areas remains difficult and expensive. Rather than searching for the hedgehogs directly, researcher Gabriel Mahler developed an AI model that identifies brambles, which are thorny shrubs that hedgehogs use for shelter and foraging, from satellite data.&lt;/p&gt;
&lt;p&gt;These small mammals rely on this type of dense vegetation for daytime shelter, nesting sites, and protection from predators. Brambles also attract insects and provide berries, supporting the invertebrate populations that hedgehogs eat.&lt;/p&gt;
&lt;p&gt;Traditional hedgehog surveys require extensive nighttime fieldwork, specialized equipment, or citizen scientists reporting sightings. Those are methods that don't scale well for national conservation planning. By contrast, satellite imagery covers vast areas continuously, and if AI models could reliably identify key habitat features like brambles, conservationists might gain a powerful tool for large-scale habitat assessment.&lt;/p&gt;
&lt;h2&gt;From satellites to shrubs&lt;/h2&gt;
&lt;p&gt;While AI is a popular buzzword these days, it's worth noting that the Cambridge team's detector is not based on a large language model like ChatGPT. Instead, the model uses relatively simple machine learning techniques: a combination of logistic regression and k-nearest neighbors classification.&lt;/p&gt;
&lt;p&gt;Mahler's bramble detector also combines TESSERA earth representation embeddings, which process imagery from the European Space Agency's Sentinel satellites, with ground-truth observations from iNaturalist, a citizen science platform.&lt;/p&gt;
&lt;p&gt;But does it actually work? To find out, Mahler and colleagues Sadiq Jaffer, Anil Madhavapeddy, and Shane Weisz spent a day walking around Cambridge with smartphones and GPS devices, checking whether the model's predictions matched reality.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"It took us about 20 seconds to find the first one in an area indicated by the model," wrote Jaffer in a blog post documenting the field test. Starting at Milton Community Centre, where the model showed high confidence of brambles near the car park, the team systematically visited locations with varying prediction levels.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2119476 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="The research team locating their first bramble." class="fullwidth full" height="768" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/20250924_130422.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The research team locating their first bramble.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Sadiq Jaffer

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;At Milton Country Park, every high-confidence area they checked contained substantial bramble growth. When they investigated a residential hotspot, they found an empty plot overrun with brambles. Most amusingly, a major prediction in North Cambridge led them to Bramblefields Local Nature Reserve. True to its name, the area contained extensive bramble coverage.&lt;/p&gt;
&lt;p&gt;The model reportedly performed best when detecting large, uncovered bramble patches visible from above. Smaller brambles under tree cover showed lower confidence scores—a logical limitation given the satellite's overhead perspective. "Since TESSERA is learned representation from remote sensing data, it would make sense that bramble partially obscured from above might be harder to spot," Jaffer explained.&lt;/p&gt;
&lt;h2&gt;An early experiment&lt;/h2&gt;
&lt;p&gt;While the researchers expressed enthusiasm over the early results, the bramble detection work represents a proof-of-concept that is still under active research. The model has not yet been published in a peer-reviewed journal, and the field validation described here was an informal test rather than a scientific study. The Cambridge team acknowledges these limitations and plans more systematic validation.&lt;/p&gt;
&lt;p&gt;However, it's still a relatively positive research application of neural network techniques that reminds us that the field of artificial intelligence is much larger than just generative AI models, such as ChatGPT, or video synthesis models.&lt;/p&gt;
&lt;p&gt;Should the team's research pan out, the simplicity of the bramble detector offers some practical advantages. Unlike more resource-intensive deep learning models, the system could potentially run on mobile devices, enabling real-time field validation. The team considered developing a phone-based active learning system that would enable field researchers to improve the model while verifying its predictions.&lt;/p&gt;
&lt;p&gt;In the future, similar AI-based approaches combining satellite remote sensing with citizen science data could potentially map invasive species, track agricultural pests, or monitor changes in various ecosystems. For threatened species like hedgehogs, rapidly mapping critical habitat features becomes increasingly valuable during a time when climate change and urbanization are actively reshaping the places that hedgehogs like to call home.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/09/can-ai-detect-hedgehogs-from-space-maybe-if-you-find-brambles-first/</guid><pubDate>Fri, 26 Sep 2025 22:22:13 +0000</pubDate></item></channel></rss>