<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 28 Oct 2025 18:33:06 +0000</lastBuildDate><item><title>[NEW] RavenDB launches database-native AI agent creator to simplify enterprise AI integration (AI News)</title><link>https://www.artificialintelligence-news.com/news/ravendb-launches-database-native-ai-agent-creator-to-simplify-enterprise-ai-integration/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/Header-image-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Open-source document database platform RavenDB has launched what it calls “the first fully integrated database-native AI Agent Creator,” a tool that makes it easier for enterprises to build and deploy AI agents.&lt;/p&gt;&lt;p&gt;The platform tackles a common problem in enterprise AI – the difficulty of connecting models to a company’s own data systems and workflows securely and cost-effectively.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-making-ai-practical-not-just-powerful"&gt;Making AI practical, not just powerful&lt;/h3&gt;&lt;p&gt;The company wants to make AI deployment faster and more secure. Oren Eini, CEO and Founder of RavenDB, said the goal is to make AI deliver real value by embedding it directly where company data already lives. He explained that many organisations struggle because their data is scattered in multiple systems and formats, making integration expensive and complex.&lt;/p&gt;&lt;p&gt;“The biggest problem users have with building AI solutions is that a generic model doesn’t actually do anything valuable,” he said. “For AI to bring real value into your system, you need to incorporate your own systems, data, and operations.”&lt;/p&gt;&lt;p&gt;RavenDB’s new AI Agent Creator eliminates much of the overhead by letting companies expose relevant data to a model directly in the database – without separate vector stores or ETL workflows. The system manages technical challenges automatically, like model memory handling, summarisation, and data security.&lt;/p&gt;&lt;p&gt;According to Eini, this means companies “can move from an idea to a deployed agent in a day or two.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-direct-data-access-and-real-time-answers"&gt;Direct data access and real-time answers&lt;/h3&gt;&lt;p&gt;Traditional AI workflows usually involve exporting data from a database to a vector store, then connecting that store to an AI model, creating delays and security gaps. RavenDB’s approach uses built-in vector indexing and semantic search to make information available instantly to AI agents inside the database itself.&lt;/p&gt;&lt;p&gt;That design supports real-time responsiveness, letting an AI agent access newly-updated information immediately: For example, checking a customer’s latest order or shipment status without waiting for a data refresh.&lt;/p&gt;&lt;p&gt;On the question of security, Eini said: “An AI agent will not be executed as a privileged part of the system,” he noted. “It functions as an external entity with the same access rights as the user operating it.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-use-cases-and-industry-insight"&gt;Use cases and industry insight&lt;/h3&gt;&lt;p&gt;Eini noted that RavenDB has already applied the AI Agent Creator in real customer environments. In one example, the system is used for candidate ranking in recruitment, automatically reading and comparing uploaded resumés against job requirements to identify promising applicants. In another example, Eini explained how AI Agent Creator is being used to re-rank semantic search results to output accurate relevance rather than just find the nearest vector matches.&lt;/p&gt;&lt;p&gt;Industry analysts see this kind of integration as part of a larger shift toward embedded, domain-specific AI. In a recent Forrester report, senior analyst Stephanie Liu wrote, “AI agents are eyeing autonomy, but your poor documentation means they may not reach this threshold.”&lt;/p&gt;&lt;p&gt;She said that while full autonomy remains challenging, tighter links between AI systems and live enterprise data can “deliver immediate, practical value” for organisations experimenting with agentic AI.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-broader-context"&gt;Broader context&lt;/h3&gt;&lt;p&gt;Database-native AI could mark a big shift in how companies use machine intelligence in their operations. By keeping both compute and security barriers inside the database, platforms like RavenDB could cut down on the need for additional infrastructure layers – a challenge many businesses face as they scale their AI programmes.&lt;/p&gt;&lt;p&gt;AI News recently covered Google’s Gemini Enterprise, which aims to bring AI agents into everyday business workflows, and examined how CrateDB is rethinking database infrastructure for real-time AI performance. These are two major developments that reflect how agentic systems and data-centric architectures converge to make enterprise AI more efficient.&lt;/p&gt;&lt;p&gt;RavenDB’s latest addition builds on that trend, positioning databases as active participants in AI pipelines, not passive data dumps.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-looking-ahead"&gt;Looking ahead&lt;/h3&gt;&lt;p&gt;Eini said the launch reflects RavenDB’s roadmap to make AI capabilities a native part of its platform. Over the past year, the company has added vector search, embedding generation, and generative AI features directly into the database engine.&lt;/p&gt;&lt;p&gt;“We aim to encapsulate all the AI complexity inside RavenDB,” he said, “so users can focus on the results rather than the mechanics.”&lt;/p&gt;&lt;p&gt;As enterprises continue to seek reliable, cost-efficient ways to adopt AI, database-native tools like RavenDB’s AI Agent Creator may offer a practical path forward, merging operational data and intelligence in one environment.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Image source: Unslpash&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/Header-image-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Open-source document database platform RavenDB has launched what it calls “the first fully integrated database-native AI Agent Creator,” a tool that makes it easier for enterprises to build and deploy AI agents.&lt;/p&gt;&lt;p&gt;The platform tackles a common problem in enterprise AI – the difficulty of connecting models to a company’s own data systems and workflows securely and cost-effectively.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-making-ai-practical-not-just-powerful"&gt;Making AI practical, not just powerful&lt;/h3&gt;&lt;p&gt;The company wants to make AI deployment faster and more secure. Oren Eini, CEO and Founder of RavenDB, said the goal is to make AI deliver real value by embedding it directly where company data already lives. He explained that many organisations struggle because their data is scattered in multiple systems and formats, making integration expensive and complex.&lt;/p&gt;&lt;p&gt;“The biggest problem users have with building AI solutions is that a generic model doesn’t actually do anything valuable,” he said. “For AI to bring real value into your system, you need to incorporate your own systems, data, and operations.”&lt;/p&gt;&lt;p&gt;RavenDB’s new AI Agent Creator eliminates much of the overhead by letting companies expose relevant data to a model directly in the database – without separate vector stores or ETL workflows. The system manages technical challenges automatically, like model memory handling, summarisation, and data security.&lt;/p&gt;&lt;p&gt;According to Eini, this means companies “can move from an idea to a deployed agent in a day or two.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-direct-data-access-and-real-time-answers"&gt;Direct data access and real-time answers&lt;/h3&gt;&lt;p&gt;Traditional AI workflows usually involve exporting data from a database to a vector store, then connecting that store to an AI model, creating delays and security gaps. RavenDB’s approach uses built-in vector indexing and semantic search to make information available instantly to AI agents inside the database itself.&lt;/p&gt;&lt;p&gt;That design supports real-time responsiveness, letting an AI agent access newly-updated information immediately: For example, checking a customer’s latest order or shipment status without waiting for a data refresh.&lt;/p&gt;&lt;p&gt;On the question of security, Eini said: “An AI agent will not be executed as a privileged part of the system,” he noted. “It functions as an external entity with the same access rights as the user operating it.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-use-cases-and-industry-insight"&gt;Use cases and industry insight&lt;/h3&gt;&lt;p&gt;Eini noted that RavenDB has already applied the AI Agent Creator in real customer environments. In one example, the system is used for candidate ranking in recruitment, automatically reading and comparing uploaded resumés against job requirements to identify promising applicants. In another example, Eini explained how AI Agent Creator is being used to re-rank semantic search results to output accurate relevance rather than just find the nearest vector matches.&lt;/p&gt;&lt;p&gt;Industry analysts see this kind of integration as part of a larger shift toward embedded, domain-specific AI. In a recent Forrester report, senior analyst Stephanie Liu wrote, “AI agents are eyeing autonomy, but your poor documentation means they may not reach this threshold.”&lt;/p&gt;&lt;p&gt;She said that while full autonomy remains challenging, tighter links between AI systems and live enterprise data can “deliver immediate, practical value” for organisations experimenting with agentic AI.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-broader-context"&gt;Broader context&lt;/h3&gt;&lt;p&gt;Database-native AI could mark a big shift in how companies use machine intelligence in their operations. By keeping both compute and security barriers inside the database, platforms like RavenDB could cut down on the need for additional infrastructure layers – a challenge many businesses face as they scale their AI programmes.&lt;/p&gt;&lt;p&gt;AI News recently covered Google’s Gemini Enterprise, which aims to bring AI agents into everyday business workflows, and examined how CrateDB is rethinking database infrastructure for real-time AI performance. These are two major developments that reflect how agentic systems and data-centric architectures converge to make enterprise AI more efficient.&lt;/p&gt;&lt;p&gt;RavenDB’s latest addition builds on that trend, positioning databases as active participants in AI pipelines, not passive data dumps.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-looking-ahead"&gt;Looking ahead&lt;/h3&gt;&lt;p&gt;Eini said the launch reflects RavenDB’s roadmap to make AI capabilities a native part of its platform. Over the past year, the company has added vector search, embedding generation, and generative AI features directly into the database engine.&lt;/p&gt;&lt;p&gt;“We aim to encapsulate all the AI complexity inside RavenDB,” he said, “so users can focus on the results rather than the mechanics.”&lt;/p&gt;&lt;p&gt;As enterprises continue to seek reliable, cost-efficient ways to adopt AI, database-native tools like RavenDB’s AI Agent Creator may offer a practical path forward, merging operational data and intelligence in one environment.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Image source: Unslpash&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/ravendb-launches-database-native-ai-agent-creator-to-simplify-enterprise-ai-integration/</guid><pubDate>Tue, 28 Oct 2025 07:00:00 +0000</pubDate></item><item><title>An AI adoption riddle (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/28/1126687/an-ai-adoption-riddle/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/bubbles-gradient.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;A few weeks ago, I set out on what I thought would be a straightforward reporting journey.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;After years of momentum for AI—even if you didn't think it would be good for the world, you probably thought it was powerful enough to take seriously—hype for the technology had been slightly punctured. First there was the underwhelming release of GPT-5 in August. Then a report released two weeks later found that 95% of generative AI pilots were failing, which caused a brief stock market panic. I wanted to know: Which companies are spooked enough to scale back their AI spending?&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;I searched and searched for them. As I did, more news fueled the idea of an AI bubble that, if popped, would spell doom economy-wide. Stories spread about the circular nature of AI spending, layoffs, the inability of companies to articulate what exactly AI will do for them. Even the smartest people building modern AI systems were saying the tech has not progressed as much as its evangelists promised.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But after all my searching, companies that took these developments as a sign to &lt;em&gt;perhaps not&lt;/em&gt; go all in on AI were nowhere to be found. Or, at least, none that were willing to admit it. What gives?&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;There are several interpretations of this one reporter’s quest (which, for the record, I’m presenting as an anecdote and not a representation of the economy), but let’s start with the easy ones. First is that this is a huge score for the “AI is a bubble” believers. What is a bubble if not a situation where companies continue to spend relentlessly even in the face of worrying news? The other is that underneath the bad headlines, there’s not enough genuinely troubling news about AI to convince companies they should pivot.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;But it could also be that the unbelievable speed of AI progress and adoption has made me think industries are more sensitive to news than they perhaps should be. I spoke with Martha Gimbel, who leads the Yale Budget Lab and coauthored a report finding that AI has not yet changed anyone’s jobs. What I gathered is that Gimbel, like many economists, thinks on a longer time scale than anyone in the AI world is used to.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;“It would be historically shocking if a technology had had an impact as quickly as people thought that this one was going to,” she says. In other words, perhaps most of the economy is still figuring out what the hell AI even does, not deciding whether to abandon it.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The other reaction I heard—particularly from the consultant crowd—is that when executives hear that so many AI pilots are failing, they indeed take it very seriously. They’re just not reading it as a failure of the technology itself. They instead point to pilots not moving quickly enough, companies lacking the right data to build better AI, or a host of other strategic reasons.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__container--08c53dd3bc9bd04e1e42e5f7ca641ab2"&gt;&lt;div class="whyItMatters__header--19f7f372f181cc6d4c06bc7362a44382"&gt;&lt;div class="whyItMatters__title--4af28c786a2bc93df05db111c6c30618"&gt;&lt;span class="whyItMatters__askAi--577f5fe6f54de43e37258d0f2aff4394"&gt;Ask AI&lt;/span&gt;&lt;div&gt;&lt;span class="whyItMatters__whyItMattersTitle--a3694998bb578e159bbd16690b8da390"&gt;Why it matters to you?&lt;/span&gt;&lt;span class="whyItMatters__betaBadge--9e84228b864d33d5b55479433fc91b8a"&gt;BETA&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__description--e1334886c092fa469388d7a24e1e1a55"&gt;&lt;span class="initial-description"&gt;Here’s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates—it might get weird&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="whyItMatters__questionContainer--ec1159210954852b9178c549600959a0"&gt;&lt;div&gt;&lt;button class="whyItMatters__actionButton--674934b6df433ac81e613372979cdb6c" type="button"&gt;Tell me why it matters&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Even if there is incredible pressure, especially on public companies, to invest heavily in AI, a few have taken big swings on the technology only to pull back. The buy now, pay later company Klarna laid off staff and paused hiring in 2024, claiming it could use AI instead. Less than a year later it was hiring again, explaining that “AI gives us speed. Talent gives us empathy.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Drive-throughs, from McDonald’s to Taco Bell, ended pilots testing the use of AI voice assistants. The vast majority of Coca-Cola advertisements, according to experts I spoke with, are not made with generative AI, despite the company’s $1 billion promise.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;So for now, the question remains unanswered: Are there companies out there rethinking how much their bets on AI will pay off, or when? And if there are, what’s keeping them from talking out loud about it? (If you’re out there, email me!)&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/bubbles-gradient.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;A few weeks ago, I set out on what I thought would be a straightforward reporting journey.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;After years of momentum for AI—even if you didn't think it would be good for the world, you probably thought it was powerful enough to take seriously—hype for the technology had been slightly punctured. First there was the underwhelming release of GPT-5 in August. Then a report released two weeks later found that 95% of generative AI pilots were failing, which caused a brief stock market panic. I wanted to know: Which companies are spooked enough to scale back their AI spending?&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;I searched and searched for them. As I did, more news fueled the idea of an AI bubble that, if popped, would spell doom economy-wide. Stories spread about the circular nature of AI spending, layoffs, the inability of companies to articulate what exactly AI will do for them. Even the smartest people building modern AI systems were saying the tech has not progressed as much as its evangelists promised.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But after all my searching, companies that took these developments as a sign to &lt;em&gt;perhaps not&lt;/em&gt; go all in on AI were nowhere to be found. Or, at least, none that were willing to admit it. What gives?&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;There are several interpretations of this one reporter’s quest (which, for the record, I’m presenting as an anecdote and not a representation of the economy), but let’s start with the easy ones. First is that this is a huge score for the “AI is a bubble” believers. What is a bubble if not a situation where companies continue to spend relentlessly even in the face of worrying news? The other is that underneath the bad headlines, there’s not enough genuinely troubling news about AI to convince companies they should pivot.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;But it could also be that the unbelievable speed of AI progress and adoption has made me think industries are more sensitive to news than they perhaps should be. I spoke with Martha Gimbel, who leads the Yale Budget Lab and coauthored a report finding that AI has not yet changed anyone’s jobs. What I gathered is that Gimbel, like many economists, thinks on a longer time scale than anyone in the AI world is used to.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;“It would be historically shocking if a technology had had an impact as quickly as people thought that this one was going to,” she says. In other words, perhaps most of the economy is still figuring out what the hell AI even does, not deciding whether to abandon it.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The other reaction I heard—particularly from the consultant crowd—is that when executives hear that so many AI pilots are failing, they indeed take it very seriously. They’re just not reading it as a failure of the technology itself. They instead point to pilots not moving quickly enough, companies lacking the right data to build better AI, or a host of other strategic reasons.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__container--08c53dd3bc9bd04e1e42e5f7ca641ab2"&gt;&lt;div class="whyItMatters__header--19f7f372f181cc6d4c06bc7362a44382"&gt;&lt;div class="whyItMatters__title--4af28c786a2bc93df05db111c6c30618"&gt;&lt;span class="whyItMatters__askAi--577f5fe6f54de43e37258d0f2aff4394"&gt;Ask AI&lt;/span&gt;&lt;div&gt;&lt;span class="whyItMatters__whyItMattersTitle--a3694998bb578e159bbd16690b8da390"&gt;Why it matters to you?&lt;/span&gt;&lt;span class="whyItMatters__betaBadge--9e84228b864d33d5b55479433fc91b8a"&gt;BETA&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__description--e1334886c092fa469388d7a24e1e1a55"&gt;&lt;span class="initial-description"&gt;Here’s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates—it might get weird&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="whyItMatters__questionContainer--ec1159210954852b9178c549600959a0"&gt;&lt;div&gt;&lt;button class="whyItMatters__actionButton--674934b6df433ac81e613372979cdb6c" type="button"&gt;Tell me why it matters&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Even if there is incredible pressure, especially on public companies, to invest heavily in AI, a few have taken big swings on the technology only to pull back. The buy now, pay later company Klarna laid off staff and paused hiring in 2024, claiming it could use AI instead. Less than a year later it was hiring again, explaining that “AI gives us speed. Talent gives us empathy.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Drive-throughs, from McDonald’s to Taco Bell, ended pilots testing the use of AI voice assistants. The vast majority of Coca-Cola advertisements, according to experts I spoke with, are not made with generative AI, despite the company’s $1 billion promise.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;So for now, the question remains unanswered: Are there companies out there rethinking how much their bets on AI will pay off, or when? And if there are, what’s keeping them from talking out loud about it? (If you’re out there, email me!)&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/28/1126687/an-ai-adoption-riddle/</guid><pubDate>Tue, 28 Oct 2025 09:00:00 +0000</pubDate></item><item><title>[NEW] Why AMD’s work with the DOE matters for enterprise AI strategy (AI News)</title><link>https://www.artificialintelligence-news.com/news/why-amd-work-with-the-doe-matters-for-enterprise-ai-strategy/</link><description>&lt;p&gt;The U.S. Department of Energy (DOE) and AMD are collaborating on two new AI supercomputers at Oak Ridge National Laboratory (ORNL) as part of a larger AI strategy to advance research in science, energy, and national security — and strengthen the nation’s position in high-performance computing.&lt;/p&gt;&lt;p&gt;The two machines represent about $1 billion in public and private investment. Once complete, they will form part of a secure national computing network designed to support AI research using standards-based infrastructure built in the US. The project reflects how a coordinated AI strategy can align national goals in innovation, energy efficiency, and data governance.&lt;/p&gt;&lt;p&gt;Dr Lisa Su, AMD’s chair and CEO, said the company is “proud and honoured to partner with the Department of Energy and Oak Ridge National Laboratory to accelerate America’s foundation for science and innovation.” She added that the systems “will leverage AMD’s high-performance and AI computing technologies to advance the most critical US research priorities in science, energy, and medicine.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-lux-ai-training-the-next-wave-of-ai-models"&gt;Lux AI: Training the next wave of AI models&lt;/h3&gt;&lt;p&gt;Set to go live in early 2026, Lux AI will be the country’s first “AI Factory” — a facility built to train and deploy advanced AI models for science, energy, and security. The system is being developed with ORNL, AMD, Oracle Cloud Infrastructure, and Hewlett Packard Enterprise.&lt;/p&gt;&lt;p&gt;Lux will use AMD Instinct MI355X GPUs, EPYC CPUs, and Pensando networking to handle data-heavy AI tasks. It’s designed to speed up research in areas such as energy systems, materials, and medicine. The system’s architecture allows multiple groups to work together while keeping data secure and separate, a model that mirrors how many large organisations are starting to manage sensitive AI workloads.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-discovery-strengthening-america-s-ai-and-supercomputing-strategy"&gt;Discovery: Strengthening America’s AI and supercomputing strategy&lt;/h3&gt;&lt;p&gt;The Discovery system will follow in 2028 and become the DOE’s next flagship supercomputer at Oak Ridge. It will use AMD’s upcoming “Venice” EPYC processors and MI430X GPUs, which are part of a new series built for AI and scientific computing.&lt;/p&gt;&lt;p&gt;Discovery’s “Bandwidth Everywhere” design increases memory and network performance without using more power. This means it can process more data and run complex models efficiently while maintaining energy costs — a challenge many large data centres also face today.&lt;/p&gt;&lt;p&gt;The system builds on lessons from Frontier, the world’s first exascale computer, ensuring that existing applications can move easily to the new platform.&lt;/p&gt;&lt;p&gt;U.S. Energy Secretary Chris Wright said, “Winning the AI race requires new and creative partnerships that will bring together the brightest minds and industries American technology and science has to offer.” He said the new systems show “a commonsense approach to computing partnerships” that strengthen the country through shared innovation.&lt;/p&gt;&lt;p&gt;ORNL Director Stephen Streiffer said Discovery will “drive scientific innovation faster and farther than ever before,” adding that combining high-performance computing and AI can shorten the time between research problems and real-world solutions.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-partnerships-driving-ai-innovation-and-long-term-strategy"&gt;&lt;strong&gt;Partnerships driving AI innovation and long-term strategy&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;AMD, HPE, and Oracle each play key roles in building and supporting the systems. Antonio Neri, HPE’s president and CEO, said the collaboration will help Oak Ridge reach “unprecedented productivity and scale.” Oracle’s executive vice president Mahesh Thiagarajan said the company is working with DOE to “deliver sovereign, high-performance AI infrastructure that will support the co-development of the Lux AI cluster.”&lt;/p&gt;&lt;p&gt;When operational, Lux and Discovery will help the DOE run large-scale AI models to improve understanding in energy, biology, materials science, and national defence. Discovery will also help design next-generation batteries, reactors, semiconductors, and critical materials.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-it-means-for-enterprise-leaders"&gt;What it means for enterprise leaders&lt;/h3&gt;&lt;p&gt;For organisations, these systems highlight how AI strategy and HPC can deliver faster research, improved efficiency, and secure data management. They also show that performance gains don’t have to come at the cost of higher energy use.&lt;/p&gt;&lt;p&gt;The DOE’s partnerships with technology providers reflect a model that private enterprises may follow — combining expertise across sectors to develop shared infrastructure while maintaining data control. As AI workloads grow, both public and private organisations will need to build systems that balance power, performance, and governance.&lt;/p&gt;&lt;p&gt;The Lux and Discovery projects show how that balance might look in practice: open, collaborative, and built to support discovery at scale — a lesson in how a forward-thinking AI strategy can turn infrastructure into long-term competitive advantage.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Syed Ali)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: How to fix the AI trust gap in your business&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-110044" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-9.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;The U.S. Department of Energy (DOE) and AMD are collaborating on two new AI supercomputers at Oak Ridge National Laboratory (ORNL) as part of a larger AI strategy to advance research in science, energy, and national security — and strengthen the nation’s position in high-performance computing.&lt;/p&gt;&lt;p&gt;The two machines represent about $1 billion in public and private investment. Once complete, they will form part of a secure national computing network designed to support AI research using standards-based infrastructure built in the US. The project reflects how a coordinated AI strategy can align national goals in innovation, energy efficiency, and data governance.&lt;/p&gt;&lt;p&gt;Dr Lisa Su, AMD’s chair and CEO, said the company is “proud and honoured to partner with the Department of Energy and Oak Ridge National Laboratory to accelerate America’s foundation for science and innovation.” She added that the systems “will leverage AMD’s high-performance and AI computing technologies to advance the most critical US research priorities in science, energy, and medicine.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-lux-ai-training-the-next-wave-of-ai-models"&gt;Lux AI: Training the next wave of AI models&lt;/h3&gt;&lt;p&gt;Set to go live in early 2026, Lux AI will be the country’s first “AI Factory” — a facility built to train and deploy advanced AI models for science, energy, and security. The system is being developed with ORNL, AMD, Oracle Cloud Infrastructure, and Hewlett Packard Enterprise.&lt;/p&gt;&lt;p&gt;Lux will use AMD Instinct MI355X GPUs, EPYC CPUs, and Pensando networking to handle data-heavy AI tasks. It’s designed to speed up research in areas such as energy systems, materials, and medicine. The system’s architecture allows multiple groups to work together while keeping data secure and separate, a model that mirrors how many large organisations are starting to manage sensitive AI workloads.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-discovery-strengthening-america-s-ai-and-supercomputing-strategy"&gt;Discovery: Strengthening America’s AI and supercomputing strategy&lt;/h3&gt;&lt;p&gt;The Discovery system will follow in 2028 and become the DOE’s next flagship supercomputer at Oak Ridge. It will use AMD’s upcoming “Venice” EPYC processors and MI430X GPUs, which are part of a new series built for AI and scientific computing.&lt;/p&gt;&lt;p&gt;Discovery’s “Bandwidth Everywhere” design increases memory and network performance without using more power. This means it can process more data and run complex models efficiently while maintaining energy costs — a challenge many large data centres also face today.&lt;/p&gt;&lt;p&gt;The system builds on lessons from Frontier, the world’s first exascale computer, ensuring that existing applications can move easily to the new platform.&lt;/p&gt;&lt;p&gt;U.S. Energy Secretary Chris Wright said, “Winning the AI race requires new and creative partnerships that will bring together the brightest minds and industries American technology and science has to offer.” He said the new systems show “a commonsense approach to computing partnerships” that strengthen the country through shared innovation.&lt;/p&gt;&lt;p&gt;ORNL Director Stephen Streiffer said Discovery will “drive scientific innovation faster and farther than ever before,” adding that combining high-performance computing and AI can shorten the time between research problems and real-world solutions.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-partnerships-driving-ai-innovation-and-long-term-strategy"&gt;&lt;strong&gt;Partnerships driving AI innovation and long-term strategy&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;AMD, HPE, and Oracle each play key roles in building and supporting the systems. Antonio Neri, HPE’s president and CEO, said the collaboration will help Oak Ridge reach “unprecedented productivity and scale.” Oracle’s executive vice president Mahesh Thiagarajan said the company is working with DOE to “deliver sovereign, high-performance AI infrastructure that will support the co-development of the Lux AI cluster.”&lt;/p&gt;&lt;p&gt;When operational, Lux and Discovery will help the DOE run large-scale AI models to improve understanding in energy, biology, materials science, and national defence. Discovery will also help design next-generation batteries, reactors, semiconductors, and critical materials.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-it-means-for-enterprise-leaders"&gt;What it means for enterprise leaders&lt;/h3&gt;&lt;p&gt;For organisations, these systems highlight how AI strategy and HPC can deliver faster research, improved efficiency, and secure data management. They also show that performance gains don’t have to come at the cost of higher energy use.&lt;/p&gt;&lt;p&gt;The DOE’s partnerships with technology providers reflect a model that private enterprises may follow — combining expertise across sectors to develop shared infrastructure while maintaining data control. As AI workloads grow, both public and private organisations will need to build systems that balance power, performance, and governance.&lt;/p&gt;&lt;p&gt;The Lux and Discovery projects show how that balance might look in practice: open, collaborative, and built to support discovery at scale — a lesson in how a forward-thinking AI strategy can turn infrastructure into long-term competitive advantage.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Syed Ali)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: How to fix the AI trust gap in your business&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-110044" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-9.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/why-amd-work-with-the-doe-matters-for-enterprise-ai-strategy/</guid><pubDate>Tue, 28 Oct 2025 10:00:00 +0000</pubDate></item><item><title>PayPal partners with OpenAI to let users pay for their shopping within ChatGPT (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/28/paypal-partners-with-openai-to-let-users-pay-for-their-shopping-within-chatgpt/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/GettyImages-1231192043.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;PayPal said on Tuesday that it is adopting a protocol in combination with OpenAI’s “Instant Checkout” feature to let users pay for their shopping directly within ChatGPT, starting in 2026.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;PayPal is adopting the Agentic Commerce Protocol (ACP), an open source specification developed by OpenAI that lets merchants make their products available within AI apps, consequently enabling users to shop using AI agents. Meanwhile, OpenAI’s “Instant Checkout” feature, launched in September, lets users confirm their order, shipping, and payment details, and complete purchases without leaving ChatGPT.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Customers can use their PayPal wallets for checkout, which, the company said, would enable it to provide buyer and seller protection, as well as dispute resolution. The company is also providing technology to handle card payments from within ChatGPT using a separate payments API.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And next year, merchants using PayPal products will have their products be discoverable on ChatGPT, starting with categories like apparel, fashion, beauty, home improvement, and electronics. Merchants will not need to build any integrations, as PayPal will handle merchant routing and payments behind the scenes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company said it is also launching an agentic commerce suite that would let merchants feature their catalogs within AI apps, accept payments on different AI apps, and get insights about consumer behavior.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;PayPal has been working to insert itself as a payments partner within various companies’ AI-enabled shopping experiences, particularly as people increasingly use AI apps to do their daily tasks. In May, the company teamed up with Perplexity to let users check out within the AI search tool, and in September, PayPal said it was adopting Google’s Agent Payments Protocol to integrate its products within various Google products.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;PayPal said, apart from the partnership on commerce, the company is giving enterprise access to ChatGPT to all of its employees and allowing its engineers to make better use of OpenAI’s coding tools, Codex.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“Hundreds of millions of people turn to ChatGPT each week for help with everyday tasks, including finding products they love, and over 400 million use PayPal to shop,” Alex Chriss, president and CEO of PayPal, said in a statement. “By partnering with OpenAI and adopting the Agentic Commerce Protocol, PayPal will power payments and commerce experiences that help people go from chat to checkout in just a few taps for our joint customer bases,” he added.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/GettyImages-1231192043.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;PayPal said on Tuesday that it is adopting a protocol in combination with OpenAI’s “Instant Checkout” feature to let users pay for their shopping directly within ChatGPT, starting in 2026.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;PayPal is adopting the Agentic Commerce Protocol (ACP), an open source specification developed by OpenAI that lets merchants make their products available within AI apps, consequently enabling users to shop using AI agents. Meanwhile, OpenAI’s “Instant Checkout” feature, launched in September, lets users confirm their order, shipping, and payment details, and complete purchases without leaving ChatGPT.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Customers can use their PayPal wallets for checkout, which, the company said, would enable it to provide buyer and seller protection, as well as dispute resolution. The company is also providing technology to handle card payments from within ChatGPT using a separate payments API.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And next year, merchants using PayPal products will have their products be discoverable on ChatGPT, starting with categories like apparel, fashion, beauty, home improvement, and electronics. Merchants will not need to build any integrations, as PayPal will handle merchant routing and payments behind the scenes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company said it is also launching an agentic commerce suite that would let merchants feature their catalogs within AI apps, accept payments on different AI apps, and get insights about consumer behavior.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;PayPal has been working to insert itself as a payments partner within various companies’ AI-enabled shopping experiences, particularly as people increasingly use AI apps to do their daily tasks. In May, the company teamed up with Perplexity to let users check out within the AI search tool, and in September, PayPal said it was adopting Google’s Agent Payments Protocol to integrate its products within various Google products.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;PayPal said, apart from the partnership on commerce, the company is giving enterprise access to ChatGPT to all of its employees and allowing its engineers to make better use of OpenAI’s coding tools, Codex.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“Hundreds of millions of people turn to ChatGPT each week for help with everyday tasks, including finding products they love, and over 400 million use PayPal to shop,” Alex Chriss, president and CEO of PayPal, said in a statement. “By partnering with OpenAI and adopting the Agentic Commerce Protocol, PayPal will power payments and commerce experiences that help people go from chat to checkout in just a few taps for our joint customer bases,” he added.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/28/paypal-partners-with-openai-to-let-users-pay-for-their-shopping-within-chatgpt/</guid><pubDate>Tue, 28 Oct 2025 10:47:43 +0000</pubDate></item><item><title>[NEW] The engineer’s guide to automating DAST tools (AI News)</title><link>https://www.artificialintelligence-news.com/news/the-engineers-guide-to-automating-dast-tools/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/mohammad-rahmani-8qEB0fTe9Vw-unsplash-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;In modern software development, speed and security must go hand in hand. Teams are shipping code faster than ever, but such a rapid pace can introduce security vulnerabilities if not managed correctly. Dynamic Application Security Testing (DAST) is an important practice for finding security flaws in running applications. However, manual DAST scans can be slow and cumbersome, creating bottlenecks that undermine the very agility they are meant to support.&lt;/p&gt;&lt;p&gt;Automating DAST is the solution. By integrating security testing directly into the development pipeline, engineering and DevOps teams can identify and fix vulnerabilities early without sacrificing speed. This guide provides a roadmap for automating DAST, from understanding its benefits to implementing it effectively in your CI/CD workflow.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-problem-with-manual-dast"&gt;The problem with manual DAST&lt;/h3&gt;&lt;p&gt;Traditionally, DAST scans were performed late in the development cycle, often by a separate security team. This approach is no longer sustainable for fast-growing tech companies. Manual DAST introduces several significant challenges:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Slow feedback loops:&lt;/strong&gt; When scans are run manually, developers may not receive feedback on vulnerabilities for days or even weeks. By then, the code has moved on, making fixes more complex and costly to implement. The OWASP Foundation highlights how delays in vulnerability discovery can slow remediation and increase risk.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Scalability issues:&lt;/strong&gt; As an organisation grows and the number of applications and services multiplies, manually managing DAST scans becomes nearly impossible. It doesn’t scale with the pace of cloud-native development. According to a US Department of Homeland Security report, manual processes can’t effectively support increasing application complexity and interconnectivity.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Inconsistent coverage:&lt;/strong&gt; Manual processes are prone to human error. Scans might be forgotten, configured incorrectly, or not run against all relevant environments, leading to gaps in security coverage.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Developer disruption:&lt;/strong&gt; Tossing a long list of vulnerabilities over the wall to developers disrupts their workflow. It forces them to switch context from current tasks to fix problems in older code, killing productivity.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;These issues create friction between development and security teams, positioning security as a roadblock rather than a shared responsibility.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-why-automate-dast-the-core-benefits"&gt;Why automate DAST? The core benefits&lt;/h3&gt;&lt;p&gt;Automating DAST transforms it from a late-stage gatekeeper into an integrated part of the development lifecycle. The benefits are immediate and impactful.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Efficiency and speed&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;By integrating DAST scans into the CI/CD pipeline, tests run automatically with every code commit or deployment. This provides developers with instant feedback on the security implications of their changes. It eliminates manual hand-offs and waiting times, allowing teams to maintain their development velocity. Vulnerabilities are caught and fixed when they are cheapest and easiest to address – right after they are introduced.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Improved security and coverage&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Automation ensures that security testing is consistent and comprehensive. You can configure automated scans to run against development, staging, and production environments, guaranteeing continuous coverage in your entire application landscape. The systematic approach reduces the risk of human error and ensures that no application is left untested. The right DAST tools can be configured once and then trusted to run consistently, improving your overall security posture.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Scalability for growing teams&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;For companies scaling from 50 to 500 developers, manual security processes break down. Automation is essential for managing security in hundreds of applications and microservices. An automated DAST workflow scales effortlessly with your team and infrastructure. New projects automatically inherit the same security testing standards, ensuring governance and consistency without adding manual overhead.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Empowering developers&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;When DAST is automated in the pipeline, security becomes a natural part of the developer’s workflow. Results appear in the tools they already use, like GitHub or GitLab. The “Shift Left” approach empowers developers to own the security of their code. It fosters a culture of security as a shared responsibility, rather than the sole domain of a separate team.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-a-practical-guide-to-implementing-dast-automation"&gt;A practical guide to implementing DAST automation&lt;/h3&gt;&lt;p&gt;Getting started with DAST automation doesn’t have to be complicated. Here are practical steps to integrate it into your CI/CD pipeline. For a broad overview of leading practices and current tooling, the OWASP DAST overview offers an excellent starting point.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. Choose the right DAST tool&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The first step is selecting a DAST tool that fits your team’s needs. Look for solutions that are built for automation. Key features to consider include:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;CI/CD integration:&lt;/strong&gt; The tool should offer seamless integrations with popular CI/CD platforms like Jenkins, GitLab CI, GitHub Actions, and CircleCI.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;API-driven:&lt;/strong&gt; An API-first approach allows for deep customisation and control over how and when scans are triggered.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Fast scans:&lt;/strong&gt; The tool should be optimised for speed to avoid becoming a bottleneck in the pipeline. Some tools offer targeted scanning capabilities to test only the changed components.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Low false positives:&lt;/strong&gt; A high volume of false positives can quickly lead to alert fatigue. Choose a tool known for its accuracy to ensure your team focuses on real threats.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;If you’re interested in real-world implementations, the Google Cloud blog on integrating DAST in CI/CD breaks down how large engineering teams approach DAST automation at enterprise scale.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. Integrate into your CI/CD pipeline&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Once you have a tool, the next step is to integrate it. A common approach is to add a DAST scanning stage to your pipeline. Here’s a typical workflow:&lt;/p&gt;&lt;ol class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Build:&lt;/strong&gt; The CI server pulls the latest code and builds the application.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Deploy to staging:&lt;/strong&gt; The application is automatically deployed to a dedicated testing or staging environment. The environment should mirror production as closely as possible.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Trigger DAST scan:&lt;/strong&gt; The CI pipeline triggers the DAST tool via an API call or a pre-built plugin. The tool then scans the running application in the staging environment.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Analyse results:&lt;/strong&gt; The pipeline waits for the scan to complete. You can configure rules to automatically fail the build if important or high-severity vulnerabilities are found.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Report and remediate:&lt;/strong&gt; Scan results are pushed to developers through integrated ticketing systems (like Jira or Linear) or directly in their Git platform. The provides immediate, actionable feedback.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;3. Start small and iterate&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;You don’t need to automate everything at once. Begin with one or two important applications. Use this initial implementation to learn and fine-tune the process. Configure the scanner to look for a limited set of high-impact vulnerabilities, like the OWASP Top 10.&lt;/p&gt;&lt;p&gt;As your team becomes more comfortable with the workflow, you can expand the scope of the scans and roll out the automation to more applications. The iterative approach minimises disruption and helps build momentum.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4. Optimise scans for the pipeline&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;A full DAST scan can take hours, which is too long for a typical CI/CD pipeline. To avoid delays, optimise your scanning strategy:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Incremental scans:&lt;/strong&gt; Configure scans to test only the parts of the application that have changed since the last build.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Targeted scans:&lt;/strong&gt; Focus scans on specific vulnerability classes that are most relevant to your application.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Asynchronous scans:&lt;/strong&gt; For more comprehensive scans, run them asynchronously (out-of-band) from the main CI/CD pipeline. For example, you can trigger a nightly scan on the staging environment. The results can be reviewed the next day without blocking deployments.&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="h-the-future-is-automated"&gt;The future is automated&lt;/h3&gt;&lt;p&gt;In a world where software is constantly evolving, security must keep pace. Manual DAST scanning is a relic of a slower era of software development. It creates bottlenecks, lacks scalability, and places an unnecessary burden on engineering teams.&lt;/p&gt;&lt;p&gt;By automating DAST and integrating it into the CI/CD pipeline, you transform security from a barrier into an enabler. It allows your team to build and deploy secure software quickly and confidently. For any engineering or DevOps professional looking to enhance their organisation’s security posture without sacrificing speed, automating DAST is no longer just a best practice – it’s a necessity.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Image source: Unsplash&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/mohammad-rahmani-8qEB0fTe9Vw-unsplash-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;In modern software development, speed and security must go hand in hand. Teams are shipping code faster than ever, but such a rapid pace can introduce security vulnerabilities if not managed correctly. Dynamic Application Security Testing (DAST) is an important practice for finding security flaws in running applications. However, manual DAST scans can be slow and cumbersome, creating bottlenecks that undermine the very agility they are meant to support.&lt;/p&gt;&lt;p&gt;Automating DAST is the solution. By integrating security testing directly into the development pipeline, engineering and DevOps teams can identify and fix vulnerabilities early without sacrificing speed. This guide provides a roadmap for automating DAST, from understanding its benefits to implementing it effectively in your CI/CD workflow.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-problem-with-manual-dast"&gt;The problem with manual DAST&lt;/h3&gt;&lt;p&gt;Traditionally, DAST scans were performed late in the development cycle, often by a separate security team. This approach is no longer sustainable for fast-growing tech companies. Manual DAST introduces several significant challenges:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Slow feedback loops:&lt;/strong&gt; When scans are run manually, developers may not receive feedback on vulnerabilities for days or even weeks. By then, the code has moved on, making fixes more complex and costly to implement. The OWASP Foundation highlights how delays in vulnerability discovery can slow remediation and increase risk.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Scalability issues:&lt;/strong&gt; As an organisation grows and the number of applications and services multiplies, manually managing DAST scans becomes nearly impossible. It doesn’t scale with the pace of cloud-native development. According to a US Department of Homeland Security report, manual processes can’t effectively support increasing application complexity and interconnectivity.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Inconsistent coverage:&lt;/strong&gt; Manual processes are prone to human error. Scans might be forgotten, configured incorrectly, or not run against all relevant environments, leading to gaps in security coverage.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Developer disruption:&lt;/strong&gt; Tossing a long list of vulnerabilities over the wall to developers disrupts their workflow. It forces them to switch context from current tasks to fix problems in older code, killing productivity.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;These issues create friction between development and security teams, positioning security as a roadblock rather than a shared responsibility.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-why-automate-dast-the-core-benefits"&gt;Why automate DAST? The core benefits&lt;/h3&gt;&lt;p&gt;Automating DAST transforms it from a late-stage gatekeeper into an integrated part of the development lifecycle. The benefits are immediate and impactful.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Efficiency and speed&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;By integrating DAST scans into the CI/CD pipeline, tests run automatically with every code commit or deployment. This provides developers with instant feedback on the security implications of their changes. It eliminates manual hand-offs and waiting times, allowing teams to maintain their development velocity. Vulnerabilities are caught and fixed when they are cheapest and easiest to address – right after they are introduced.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Improved security and coverage&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Automation ensures that security testing is consistent and comprehensive. You can configure automated scans to run against development, staging, and production environments, guaranteeing continuous coverage in your entire application landscape. The systematic approach reduces the risk of human error and ensures that no application is left untested. The right DAST tools can be configured once and then trusted to run consistently, improving your overall security posture.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Scalability for growing teams&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;For companies scaling from 50 to 500 developers, manual security processes break down. Automation is essential for managing security in hundreds of applications and microservices. An automated DAST workflow scales effortlessly with your team and infrastructure. New projects automatically inherit the same security testing standards, ensuring governance and consistency without adding manual overhead.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Empowering developers&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;When DAST is automated in the pipeline, security becomes a natural part of the developer’s workflow. Results appear in the tools they already use, like GitHub or GitLab. The “Shift Left” approach empowers developers to own the security of their code. It fosters a culture of security as a shared responsibility, rather than the sole domain of a separate team.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-a-practical-guide-to-implementing-dast-automation"&gt;A practical guide to implementing DAST automation&lt;/h3&gt;&lt;p&gt;Getting started with DAST automation doesn’t have to be complicated. Here are practical steps to integrate it into your CI/CD pipeline. For a broad overview of leading practices and current tooling, the OWASP DAST overview offers an excellent starting point.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. Choose the right DAST tool&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The first step is selecting a DAST tool that fits your team’s needs. Look for solutions that are built for automation. Key features to consider include:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;CI/CD integration:&lt;/strong&gt; The tool should offer seamless integrations with popular CI/CD platforms like Jenkins, GitLab CI, GitHub Actions, and CircleCI.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;API-driven:&lt;/strong&gt; An API-first approach allows for deep customisation and control over how and when scans are triggered.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Fast scans:&lt;/strong&gt; The tool should be optimised for speed to avoid becoming a bottleneck in the pipeline. Some tools offer targeted scanning capabilities to test only the changed components.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Low false positives:&lt;/strong&gt; A high volume of false positives can quickly lead to alert fatigue. Choose a tool known for its accuracy to ensure your team focuses on real threats.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;If you’re interested in real-world implementations, the Google Cloud blog on integrating DAST in CI/CD breaks down how large engineering teams approach DAST automation at enterprise scale.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. Integrate into your CI/CD pipeline&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Once you have a tool, the next step is to integrate it. A common approach is to add a DAST scanning stage to your pipeline. Here’s a typical workflow:&lt;/p&gt;&lt;ol class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Build:&lt;/strong&gt; The CI server pulls the latest code and builds the application.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Deploy to staging:&lt;/strong&gt; The application is automatically deployed to a dedicated testing or staging environment. The environment should mirror production as closely as possible.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Trigger DAST scan:&lt;/strong&gt; The CI pipeline triggers the DAST tool via an API call or a pre-built plugin. The tool then scans the running application in the staging environment.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Analyse results:&lt;/strong&gt; The pipeline waits for the scan to complete. You can configure rules to automatically fail the build if important or high-severity vulnerabilities are found.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Report and remediate:&lt;/strong&gt; Scan results are pushed to developers through integrated ticketing systems (like Jira or Linear) or directly in their Git platform. The provides immediate, actionable feedback.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;3. Start small and iterate&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;You don’t need to automate everything at once. Begin with one or two important applications. Use this initial implementation to learn and fine-tune the process. Configure the scanner to look for a limited set of high-impact vulnerabilities, like the OWASP Top 10.&lt;/p&gt;&lt;p&gt;As your team becomes more comfortable with the workflow, you can expand the scope of the scans and roll out the automation to more applications. The iterative approach minimises disruption and helps build momentum.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4. Optimise scans for the pipeline&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;A full DAST scan can take hours, which is too long for a typical CI/CD pipeline. To avoid delays, optimise your scanning strategy:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Incremental scans:&lt;/strong&gt; Configure scans to test only the parts of the application that have changed since the last build.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Targeted scans:&lt;/strong&gt; Focus scans on specific vulnerability classes that are most relevant to your application.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Asynchronous scans:&lt;/strong&gt; For more comprehensive scans, run them asynchronously (out-of-band) from the main CI/CD pipeline. For example, you can trigger a nightly scan on the staging environment. The results can be reviewed the next day without blocking deployments.&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="h-the-future-is-automated"&gt;The future is automated&lt;/h3&gt;&lt;p&gt;In a world where software is constantly evolving, security must keep pace. Manual DAST scanning is a relic of a slower era of software development. It creates bottlenecks, lacks scalability, and places an unnecessary burden on engineering teams.&lt;/p&gt;&lt;p&gt;By automating DAST and integrating it into the CI/CD pipeline, you transform security from a barrier into an enabler. It allows your team to build and deploy secure software quickly and confidently. For any engineering or DevOps professional looking to enhance their organisation’s security posture without sacrificing speed, automating DAST is no longer just a best practice – it’s a necessity.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Image source: Unsplash&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/the-engineers-guide-to-automating-dast-tools/</guid><pubDate>Tue, 28 Oct 2025 11:01:04 +0000</pubDate></item><item><title>“We will never build a sex robot,” says Mustafa Suleyman (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/28/1126781/we-will-never-build-a-sex-robot-says-mustafa-suleyman/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/Mustafa-Suleyman-Preferred-Headshot-Sept-2025.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 chronoton/executive-summary_0"&gt;&lt;div class="chronotonExecutiveSummary__summaryContainer--3bc10da0658ecd8e2ef22c6023461fb5"&gt;&lt;button class="chronotonExecutiveSummary__toggleButton--1cd6118db37e8a8252fc4cd8bbadcb85" type="button"&gt;&lt;span class="chronotonExecutiveSummary__toggleText--a713e14989fe65c5162db2b69cb422c9"&gt;EXECUTIVE SUMMARY&lt;/span&gt;&lt;svg class="chronotonExecutiveSummary__toggleArrow--a8c1be9c06a9f066a767b3af80d859a1" fill="none" height="7" viewBox="0 0 11 7" width="11" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M1 1L5.5 5.5L10 1" stroke="#58C0B3" stroke-linecap="round" stroke-width="1.5"&gt;&lt;/svg&gt;&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_1"&gt; &lt;p&gt;Mustafa Suleyman, CEO of Microsoft AI, is trying to walk a fine line. On the one hand, he thinks that the industry is taking AI in a dangerous direction by building chatbots that present as human: He worries that people will be tricked into seeing life instead of lifelike behavior. In August, he published a much-discussed post on his personal blog that urged his peers to stop trying to make what he called “seemingly conscious artificial intelligence,” or SCAI.&lt;/p&gt;  &lt;p&gt;On the other hand, Suleyman runs a product shop that must compete with those peers. Last week, Microsoft announced a string of updates to its Copilot chatbot, designed to boost its appeal in a crowded market in which customers can pick and choose between a pantheon of rival bots that already includes ChatGPT, Perplexity, Gemini, Claude, DeepSeek, and more.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;I talked to Suleyman about the tension at play when it comes to designing our interactions with chatbots and his ultimate vision for what this new technology should be.&lt;/p&gt;  &lt;p&gt;One key Copilot update is a group-chat feature that lets multiple people talk to the chatbot at the same time. A big part of the idea seems to be to stop people from falling down a rabbit hole in a one-on-one conversation with a yes-man bot. Another feature, called Real Talk, lets people tailor how much Copilot pushes back on you, dialing down the sycophancy so that the chatbot challenges what you say more often.&lt;/p&gt; 
 &lt;p&gt;Copilot also got a memory upgrade, so that it can now remember your upcoming events or long-term goals and bring up things that you told it in past conversations. And then there’s Mico, an animated yellow blob—a kind of Chatbot Clippy—that Microsoft hopes will make Copilot more accessible and engaging for new and younger users.&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;Microsoft says the updates were designed to make Copilot more expressive, engaging, and helpful. But I’m curious how far those features can be pushed without starting down the SCAI path that Suleyman has warned about.&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Suleyman’s concerns about SCAI come at a time when we are starting to hear more and more stories about people being led astray by chatbots that are too engaging, too expressive, too helpful. OpenAI is being sued by the parents of a teenager who they allege was talked into killing himself by ChatGPT. There’s even a growing scene that celebrates romantic relationships with chatbots.&lt;/p&gt;  &lt;p&gt;With all that in mind, I wanted to dig a bit deeper into Suleyman’s views. Because a couple of years ago he gave a TED Talk in which he told us that the best way to think about AI is as a new kind of digital species. Doesn’t that kind of hype feed the misperceptions Suleyman is now concerned about?&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In our conversation, Suleyman told me what he was trying to get across in that TED Talk, why he really believes SCAI is a problem, and why Microsoft would never build sex robots (his words). He had a lot of answers, but he left me with more questions.&lt;/p&gt;  &lt;p&gt;Our conversation has been edited for length and clarity.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;&lt;strong&gt;In an ideal world, what kind of chatbot do you want to build? You’ve just launched a bunch of updates to Copilot. How do you get the balance right when you’re building a chatbot that has to compete in a market in which people seem to value humanlike interaction, but you also say you want to avoid seemingly conscious AI?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;It’s a good question. With group chat, this will be the first time that a large group of people will be able to speak to an AI at the same time. It really is a way of emphasizing that AIs shouldn’t be drawing you out of the real world. They should be helping you to connect, to bring in your family, your friends, to have community groups, and so on.&lt;/p&gt;  &lt;p&gt;That is going to become a very significant differentiator over the next few years. My vision of AI has always been one where an AI is on your team, in your corner.&lt;/p&gt;  &lt;p&gt;This is a very simple, obvious statement, but it isn’t about exceeding and replacing humanity—it’s about serving us. That should be the test of technology at every step. Does it actually, you know, deliver on the quest of civilization, which is to make us smarter and happier and more productive and healthier and stuff like that?&lt;/p&gt; 

 &lt;p&gt;So we’re just trying to build features that constantly remind us to ask that question, and remind our users to push us on that issue.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Last time we spoke&lt;/strong&gt;&lt;strong&gt;, you told me that you weren’t interested in making a chatbot that would role-play personalities. That’s not true of the wider industry. Elon Musk’s Grok is selling that kind of flirty experience. OpenAI has said it’s interested in exploring new adult interactions with ChatGPT. There’s a market for that. And yet this is something you’ll just stay clear of?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Yeah, we will never build sex robots. Sad in a way that we have to be so clear about that, but that’s just not our mission as a company. The joy of being at Microsoft is that for 50 years, the company has built, you know, software to empower people, to put people first.&lt;/p&gt;  &lt;p&gt;Sometimes, as a result, that means the company moves slower than other startups and is more deliberate and more careful. But I think that’s a feature, not a bug, in this age, when being attentive to potential side effects and longer-term consequences is really important.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt; &lt;p&gt;&lt;strong&gt;And that means what, exactly?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;We’re very clear on, you know, trying to create an AI that fosters a meaningful relationship. It’s not that it’s trying to be cold and anodyne—it cares about being fluid and lucid and kind. It definitely has some emotional intelligence.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;So where does it—where do you—draw those boundaries?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Our newest chat model, which is called Real Talk, is a little bit more sassy. It’s a bit more cheeky, it’s a bit more fun, it’s quite philosophical. It’ll happily talk about the big-picture questions, the meaning of life, and so on. But if you try and flirt with it, it’ll push back and it’ll be very clear—not in a judgmental way, but just, like: “Look, that’s not for me.”&lt;/p&gt; 
 &lt;p&gt;There are other places where you can go to get that kind of experience, right? And I think that’s just a decision we’ve made as a company.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Is a no-flirting policy enough? Because if the idea is to stop people even imagining an entity, a consciousness, behind the interactions, you could still get that with a chatbot that wanted to keep things SFW. You know, I can imagine some people seeing something that’s not there even with a personality that’s saying, hey, let’s keep this professional.&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Here’s a metaphor to try to make sense of it. We hold each other accountable in the workplace. There’s an entire architecture of boundary management, which essentially sculpts human behavior to fit a mold that’s functional and not irritating.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_11"&gt; &lt;p&gt;The same is true in our personal lives. The way that you interact with your third cousin is very different to the way you interact with your sibling. There’s a lot to learn from how we manage boundaries in real human interactions.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_13"&gt; &lt;p&gt;It doesn’t have to be either a complete open book of emotional sensuality or availability—drawing people into a spiraled rabbit hole of intensity—or, like, a cold dry thing. There’s a huge spectrum in between, and the craft that we’re learning as an industry and as a species is to sculpt these attributes.&lt;/p&gt;  &lt;p&gt;And those attributes obviously reflect the values of the companies that design them. And I think that’s where Microsoft has a lot of strengths, because our values are pretty clear, and that’s what we’re standing behind.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;A lot of people seem to like personalities. Some of the backlash to GPT-5, for example, was because the previous model’s personality had been taken away. Was it a mistake for OpenAI to have put a strong personality there in the first place, to give people something that they then missed?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;No, personality is great. My point is that we’re trying to sculpt personality attributes in a more fine-grained way, right?&lt;/p&gt; 
 &lt;p&gt;Like I said, Real Talk is a cool personality. It’s quite different to normal Copilot. We are also experimenting with Mico, which is this visual character, that, you know, people—some people—really love. It’s much more engaging. It’s easier to talk to about all kinds of emotional questions and stuff.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;I guess this is what I’m trying to get straight. Features like Mico are meant to make Copilot more engaging and nicer to use, but it seems to go against the idea of doing whatever you can to stop people thinking there’s something there that you are actually having a friendship with.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Yeah. I mean, it doesn’t stop you necessarily. People want to talk to somebody, or something, that they like. And we know that if your teacher is nice to you at school, you’re going to be more engaged. The same with your manager, the same with your loved ones. And so emotional intelligence has always been a critical part of the puzzle, so it’s not to say that we don’t want to pursue it.&lt;/p&gt;  &lt;p&gt;It’s just that the craft is in trying to find that boundary. And there are some things which we’re saying are just off the table, and there are other things which we’re going to be more experimental with. Like, certain people have complained that they don’t get enough pushback from Copilot—they want it to be more challenging. Other people aren’t looking for that kind of experience—they want it to be a basic information provider. The task for us is just learning to disentangle what type of experience to give to different people.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_15"&gt; &lt;p&gt;&lt;strong&gt;I know you’ve been thinking about how people engage with AI for some time. Was there an inciting incident that made you want to start this conversation in the industry about seemingly conscious AI?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;I could see that there was a group of people emerging in the academic literature who were taking the question of moral consideration for artificial entities very seriously. And I think it’s very clear that if we start to do that, it would detract from the urgent need to protect the rights of many humans that already exist, let alone animals.&lt;/p&gt;  &lt;p&gt;If you grant AI rights, that implies—you know—fundamental autonomy, and it implies that it might have free will to make its own decisions about things. So I’m really trying to frame a counter to that, which is that it won’t ever have free will. It won’t ever have complete autonomy like another human being.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_17"&gt; &lt;p&gt;AI will be able to take actions on our behalf. But these models are working for us. You wouldn’t want a pack of, you know, wolves wandering around that weren’t tame and that had complete freedom to go and compete with us for resources and weren’t accountable to humans. I mean, most people would think that was a bad idea and that you would want to go and kill the wolves.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Okay. So the idea is to stop some movement that’s calling for AI welfare or rights before it even gets going, by making sure that we don’t build AI that appears to be conscious? What about not building that kind of AI because certain vulnerable people may be tricked by it in a way that may be harmful? I mean, those seem to be two different concerns.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;I think the test is going to be in the kinds of features the different labs put out and in the types of personalities that they create. Then we’ll be able to see how that’s affecting human behavior.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;But is it a concern of yours that we are building a technology that might trick people into seeing something that isn’t there? I mean, people have claimed they’ve seen sentience inside far less sophisticated models than we have now. Or is that just something that some people will always do?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;It’s possible. But my point is that a responsible developer has to do our best to try and detect these patterns emerging in people as quickly as possible and not take it for granted that people are going to be able to disentangle those kinds of experiences themselves.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_19"&gt;&lt;p&gt;&lt;strong&gt;When I read your post about seemingly conscious AI, I was struck by a line that says: “We must build AI for people; not to be a digital person.” It made me think of a TED Talk you gave last year where you say that the best way to think about AI is as a new kind of digital species. Can you help me understand why talking about this technology as a digital species isn’t a step down the path of thinking about AI models as digital persons or conscious entities?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;I think the difference is that I’m trying to offer metaphors that make it easier for people to understand where things might be headed, and therefore how to avert that and how to control it.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Okay.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;It’s not to say that we should do those things. It’s just pointing out that this is the emergence of a technology which is unique in human history. And if you just assume that it’s a tool or just a chatbot or a dumb— you know, I kind of wrote that TED Talk in the context of a lot of skepticism. And I think it’s important to be clear-eyed about what’s coming so that one can think about the right guardrails.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;And yet, if you’re telling me this technology is a new digital species, I have some sympathy for the people who say, well, then we need to consider welfare.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;I wouldn’t. &lt;em&gt;[He starts laughing.]&lt;/em&gt; Just not in the slightest. No way. It’s not a direction that any of us want to go in.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;No, that’s not what I meant. I don’t think chatbots should have welfare. I’m saying I’d have some sympathy for where such people were coming from when they hear, you know, Mustafa Suleyman tell them that this thing he’s building was a new digital species. I’d understand why they might then say that they wanted to stand up for it. I’m saying the words we use matter, I guess.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;The rest of the TED Talk was all about how to contain AI and how not to let this species take over, right? That was the whole point of setting it up as, like, this is what's coming. I mean, that’s what my whole book [&lt;em&gt;The Coming Wave&lt;/em&gt;, published in 2023] was about—containment and alignment and stuff like that. There’s no point in pretending that it’s something that it’s not and then building guardrails and boundaries that don’t apply because you think it’s just a tool.&lt;/p&gt;  &lt;p&gt;Honestly, it does have the potential to recursively self-improve. It does have the potential to set its own goals. Those are quite profound things. No other technology we’ve ever invented has that. And so, yeah, I think that it is accurate to say that it’s like a digital species, a new digital species. That’s what we’re trying to restrict to make sure it’s always in service of people. That’s the target for containment.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/Mustafa-Suleyman-Preferred-Headshot-Sept-2025.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 chronoton/executive-summary_0"&gt;&lt;div class="chronotonExecutiveSummary__summaryContainer--3bc10da0658ecd8e2ef22c6023461fb5"&gt;&lt;button class="chronotonExecutiveSummary__toggleButton--1cd6118db37e8a8252fc4cd8bbadcb85" type="button"&gt;&lt;span class="chronotonExecutiveSummary__toggleText--a713e14989fe65c5162db2b69cb422c9"&gt;EXECUTIVE SUMMARY&lt;/span&gt;&lt;svg class="chronotonExecutiveSummary__toggleArrow--a8c1be9c06a9f066a767b3af80d859a1" fill="none" height="7" viewBox="0 0 11 7" width="11" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M1 1L5.5 5.5L10 1" stroke="#58C0B3" stroke-linecap="round" stroke-width="1.5"&gt;&lt;/svg&gt;&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_1"&gt; &lt;p&gt;Mustafa Suleyman, CEO of Microsoft AI, is trying to walk a fine line. On the one hand, he thinks that the industry is taking AI in a dangerous direction by building chatbots that present as human: He worries that people will be tricked into seeing life instead of lifelike behavior. In August, he published a much-discussed post on his personal blog that urged his peers to stop trying to make what he called “seemingly conscious artificial intelligence,” or SCAI.&lt;/p&gt;  &lt;p&gt;On the other hand, Suleyman runs a product shop that must compete with those peers. Last week, Microsoft announced a string of updates to its Copilot chatbot, designed to boost its appeal in a crowded market in which customers can pick and choose between a pantheon of rival bots that already includes ChatGPT, Perplexity, Gemini, Claude, DeepSeek, and more.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;I talked to Suleyman about the tension at play when it comes to designing our interactions with chatbots and his ultimate vision for what this new technology should be.&lt;/p&gt;  &lt;p&gt;One key Copilot update is a group-chat feature that lets multiple people talk to the chatbot at the same time. A big part of the idea seems to be to stop people from falling down a rabbit hole in a one-on-one conversation with a yes-man bot. Another feature, called Real Talk, lets people tailor how much Copilot pushes back on you, dialing down the sycophancy so that the chatbot challenges what you say more often.&lt;/p&gt; 
 &lt;p&gt;Copilot also got a memory upgrade, so that it can now remember your upcoming events or long-term goals and bring up things that you told it in past conversations. And then there’s Mico, an animated yellow blob—a kind of Chatbot Clippy—that Microsoft hopes will make Copilot more accessible and engaging for new and younger users.&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;Microsoft says the updates were designed to make Copilot more expressive, engaging, and helpful. But I’m curious how far those features can be pushed without starting down the SCAI path that Suleyman has warned about.&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Suleyman’s concerns about SCAI come at a time when we are starting to hear more and more stories about people being led astray by chatbots that are too engaging, too expressive, too helpful. OpenAI is being sued by the parents of a teenager who they allege was talked into killing himself by ChatGPT. There’s even a growing scene that celebrates romantic relationships with chatbots.&lt;/p&gt;  &lt;p&gt;With all that in mind, I wanted to dig a bit deeper into Suleyman’s views. Because a couple of years ago he gave a TED Talk in which he told us that the best way to think about AI is as a new kind of digital species. Doesn’t that kind of hype feed the misperceptions Suleyman is now concerned about?&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In our conversation, Suleyman told me what he was trying to get across in that TED Talk, why he really believes SCAI is a problem, and why Microsoft would never build sex robots (his words). He had a lot of answers, but he left me with more questions.&lt;/p&gt;  &lt;p&gt;Our conversation has been edited for length and clarity.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;&lt;strong&gt;In an ideal world, what kind of chatbot do you want to build? You’ve just launched a bunch of updates to Copilot. How do you get the balance right when you’re building a chatbot that has to compete in a market in which people seem to value humanlike interaction, but you also say you want to avoid seemingly conscious AI?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;It’s a good question. With group chat, this will be the first time that a large group of people will be able to speak to an AI at the same time. It really is a way of emphasizing that AIs shouldn’t be drawing you out of the real world. They should be helping you to connect, to bring in your family, your friends, to have community groups, and so on.&lt;/p&gt;  &lt;p&gt;That is going to become a very significant differentiator over the next few years. My vision of AI has always been one where an AI is on your team, in your corner.&lt;/p&gt;  &lt;p&gt;This is a very simple, obvious statement, but it isn’t about exceeding and replacing humanity—it’s about serving us. That should be the test of technology at every step. Does it actually, you know, deliver on the quest of civilization, which is to make us smarter and happier and more productive and healthier and stuff like that?&lt;/p&gt; 

 &lt;p&gt;So we’re just trying to build features that constantly remind us to ask that question, and remind our users to push us on that issue.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Last time we spoke&lt;/strong&gt;&lt;strong&gt;, you told me that you weren’t interested in making a chatbot that would role-play personalities. That’s not true of the wider industry. Elon Musk’s Grok is selling that kind of flirty experience. OpenAI has said it’s interested in exploring new adult interactions with ChatGPT. There’s a market for that. And yet this is something you’ll just stay clear of?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Yeah, we will never build sex robots. Sad in a way that we have to be so clear about that, but that’s just not our mission as a company. The joy of being at Microsoft is that for 50 years, the company has built, you know, software to empower people, to put people first.&lt;/p&gt;  &lt;p&gt;Sometimes, as a result, that means the company moves slower than other startups and is more deliberate and more careful. But I think that’s a feature, not a bug, in this age, when being attentive to potential side effects and longer-term consequences is really important.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt; &lt;p&gt;&lt;strong&gt;And that means what, exactly?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;We’re very clear on, you know, trying to create an AI that fosters a meaningful relationship. It’s not that it’s trying to be cold and anodyne—it cares about being fluid and lucid and kind. It definitely has some emotional intelligence.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;So where does it—where do you—draw those boundaries?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Our newest chat model, which is called Real Talk, is a little bit more sassy. It’s a bit more cheeky, it’s a bit more fun, it’s quite philosophical. It’ll happily talk about the big-picture questions, the meaning of life, and so on. But if you try and flirt with it, it’ll push back and it’ll be very clear—not in a judgmental way, but just, like: “Look, that’s not for me.”&lt;/p&gt; 
 &lt;p&gt;There are other places where you can go to get that kind of experience, right? And I think that’s just a decision we’ve made as a company.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Is a no-flirting policy enough? Because if the idea is to stop people even imagining an entity, a consciousness, behind the interactions, you could still get that with a chatbot that wanted to keep things SFW. You know, I can imagine some people seeing something that’s not there even with a personality that’s saying, hey, let’s keep this professional.&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Here’s a metaphor to try to make sense of it. We hold each other accountable in the workplace. There’s an entire architecture of boundary management, which essentially sculpts human behavior to fit a mold that’s functional and not irritating.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_11"&gt; &lt;p&gt;The same is true in our personal lives. The way that you interact with your third cousin is very different to the way you interact with your sibling. There’s a lot to learn from how we manage boundaries in real human interactions.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_13"&gt; &lt;p&gt;It doesn’t have to be either a complete open book of emotional sensuality or availability—drawing people into a spiraled rabbit hole of intensity—or, like, a cold dry thing. There’s a huge spectrum in between, and the craft that we’re learning as an industry and as a species is to sculpt these attributes.&lt;/p&gt;  &lt;p&gt;And those attributes obviously reflect the values of the companies that design them. And I think that’s where Microsoft has a lot of strengths, because our values are pretty clear, and that’s what we’re standing behind.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;A lot of people seem to like personalities. Some of the backlash to GPT-5, for example, was because the previous model’s personality had been taken away. Was it a mistake for OpenAI to have put a strong personality there in the first place, to give people something that they then missed?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;No, personality is great. My point is that we’re trying to sculpt personality attributes in a more fine-grained way, right?&lt;/p&gt; 
 &lt;p&gt;Like I said, Real Talk is a cool personality. It’s quite different to normal Copilot. We are also experimenting with Mico, which is this visual character, that, you know, people—some people—really love. It’s much more engaging. It’s easier to talk to about all kinds of emotional questions and stuff.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;I guess this is what I’m trying to get straight. Features like Mico are meant to make Copilot more engaging and nicer to use, but it seems to go against the idea of doing whatever you can to stop people thinking there’s something there that you are actually having a friendship with.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Yeah. I mean, it doesn’t stop you necessarily. People want to talk to somebody, or something, that they like. And we know that if your teacher is nice to you at school, you’re going to be more engaged. The same with your manager, the same with your loved ones. And so emotional intelligence has always been a critical part of the puzzle, so it’s not to say that we don’t want to pursue it.&lt;/p&gt;  &lt;p&gt;It’s just that the craft is in trying to find that boundary. And there are some things which we’re saying are just off the table, and there are other things which we’re going to be more experimental with. Like, certain people have complained that they don’t get enough pushback from Copilot—they want it to be more challenging. Other people aren’t looking for that kind of experience—they want it to be a basic information provider. The task for us is just learning to disentangle what type of experience to give to different people.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_15"&gt; &lt;p&gt;&lt;strong&gt;I know you’ve been thinking about how people engage with AI for some time. Was there an inciting incident that made you want to start this conversation in the industry about seemingly conscious AI?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;I could see that there was a group of people emerging in the academic literature who were taking the question of moral consideration for artificial entities very seriously. And I think it’s very clear that if we start to do that, it would detract from the urgent need to protect the rights of many humans that already exist, let alone animals.&lt;/p&gt;  &lt;p&gt;If you grant AI rights, that implies—you know—fundamental autonomy, and it implies that it might have free will to make its own decisions about things. So I’m really trying to frame a counter to that, which is that it won’t ever have free will. It won’t ever have complete autonomy like another human being.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_17"&gt; &lt;p&gt;AI will be able to take actions on our behalf. But these models are working for us. You wouldn’t want a pack of, you know, wolves wandering around that weren’t tame and that had complete freedom to go and compete with us for resources and weren’t accountable to humans. I mean, most people would think that was a bad idea and that you would want to go and kill the wolves.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Okay. So the idea is to stop some movement that’s calling for AI welfare or rights before it even gets going, by making sure that we don’t build AI that appears to be conscious? What about not building that kind of AI because certain vulnerable people may be tricked by it in a way that may be harmful? I mean, those seem to be two different concerns.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;I think the test is going to be in the kinds of features the different labs put out and in the types of personalities that they create. Then we’ll be able to see how that’s affecting human behavior.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;But is it a concern of yours that we are building a technology that might trick people into seeing something that isn’t there? I mean, people have claimed they’ve seen sentience inside far less sophisticated models than we have now. Or is that just something that some people will always do?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;It’s possible. But my point is that a responsible developer has to do our best to try and detect these patterns emerging in people as quickly as possible and not take it for granted that people are going to be able to disentangle those kinds of experiences themselves.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_19"&gt;&lt;p&gt;&lt;strong&gt;When I read your post about seemingly conscious AI, I was struck by a line that says: “We must build AI for people; not to be a digital person.” It made me think of a TED Talk you gave last year where you say that the best way to think about AI is as a new kind of digital species. Can you help me understand why talking about this technology as a digital species isn’t a step down the path of thinking about AI models as digital persons or conscious entities?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;I think the difference is that I’m trying to offer metaphors that make it easier for people to understand where things might be headed, and therefore how to avert that and how to control it.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Okay.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;It’s not to say that we should do those things. It’s just pointing out that this is the emergence of a technology which is unique in human history. And if you just assume that it’s a tool or just a chatbot or a dumb— you know, I kind of wrote that TED Talk in the context of a lot of skepticism. And I think it’s important to be clear-eyed about what’s coming so that one can think about the right guardrails.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;And yet, if you’re telling me this technology is a new digital species, I have some sympathy for the people who say, well, then we need to consider welfare.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;I wouldn’t. &lt;em&gt;[He starts laughing.]&lt;/em&gt; Just not in the slightest. No way. It’s not a direction that any of us want to go in.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;No, that’s not what I meant. I don’t think chatbots should have welfare. I’m saying I’d have some sympathy for where such people were coming from when they hear, you know, Mustafa Suleyman tell them that this thing he’s building was a new digital species. I’d understand why they might then say that they wanted to stand up for it. I’m saying the words we use matter, I guess.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;The rest of the TED Talk was all about how to contain AI and how not to let this species take over, right? That was the whole point of setting it up as, like, this is what's coming. I mean, that’s what my whole book [&lt;em&gt;The Coming Wave&lt;/em&gt;, published in 2023] was about—containment and alignment and stuff like that. There’s no point in pretending that it’s something that it’s not and then building guardrails and boundaries that don’t apply because you think it’s just a tool.&lt;/p&gt;  &lt;p&gt;Honestly, it does have the potential to recursively self-improve. It does have the potential to set its own goals. Those are quite profound things. No other technology we’ve ever invented has that. And so, yeah, I think that it is accurate to say that it’s like a digital species, a new digital species. That’s what we’re trying to restrict to make sure it’s always in service of people. That’s the target for containment.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/28/1126781/we-will-never-build-a-sex-robot-says-mustafa-suleyman/</guid><pubDate>Tue, 28 Oct 2025 11:07:39 +0000</pubDate></item><item><title>Adobe launches AI assistants for Express and Photoshop (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/28/adobe-launches-ai-assistants-for-express-and-photoshop/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Adobe today released new AI assistants for Express and Photoshop that can help users with image creation and editing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Most companies like to put AI assistants into a sidebar in their products to grab on-screen context. But for Express, Adobe has created a new mode that lets you use text prompts to create new images and designs. You can switch on the assistant mode to use AI prompts and then switch back to use editing tools and controls that are available in Express in the current version.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Meanwhile, the new Photoshop assistant, which is in closed beta testing, lives in the sidebar. Adobe claims the assistant can understand different layers and help you automatically select objects and create masks. Adobe added that users can ask the assistant to complete repetitive tasks such as removing backgrounds or changing colors.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3062943" height="383" src="https://techcrunch.com/wp-content/uploads/2025/10/PhotoshopAIAssistant.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Adobe&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Adobe’s VP of generative AI, Alexandru Costin, told TechCrunch that the company decided to build a different mode for its AI assistant in Express to target students and professionals who use the app. The company wants to see if users can achieve what they want to do without having to switch back to the traditional interface, he explained.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We think this approach of switching between two modes, where you get the best of both worlds, is gonna make the technology both accessible and controllable,” Costin said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company said it is also experimenting with a new type of assistant, dubbed “Project Moonlight,” that can coordinate with different assistants from other Adobe tools, and connect to a creator’s social channels to better understand their style. Adobe said the product is in the early stages of development and is in private beta.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="An illustrative image showing prototypes of Adobe's new project of cross-app assistant is a system that gets data from all of its apps. " class="wp-image-3062944" height="383" src="https://techcrunch.com/wp-content/uploads/2025/10/ProjectMoonlight.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Adobe&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company said it is also exploring a way to connect Adobe Express with ChatGPT using OpenAI’s app integrations API to let users create designs directly in ChatGPT.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Adobe also announced a new set of AI features for its Creative Cloud apps. Photoshop users can now choose third-party models, like Google’s Gemini 2.5 flash and Black Forest Labs’ FLUX.1 Kontext, for the generative fill feature, which can remove objects or extend images. The company is also adding an AI-powered object mask in its video editing app, Premiere Pro, to let users easily identify and select objects or people to add effects or adjust colors.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Adobe today released new AI assistants for Express and Photoshop that can help users with image creation and editing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Most companies like to put AI assistants into a sidebar in their products to grab on-screen context. But for Express, Adobe has created a new mode that lets you use text prompts to create new images and designs. You can switch on the assistant mode to use AI prompts and then switch back to use editing tools and controls that are available in Express in the current version.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Meanwhile, the new Photoshop assistant, which is in closed beta testing, lives in the sidebar. Adobe claims the assistant can understand different layers and help you automatically select objects and create masks. Adobe added that users can ask the assistant to complete repetitive tasks such as removing backgrounds or changing colors.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3062943" height="383" src="https://techcrunch.com/wp-content/uploads/2025/10/PhotoshopAIAssistant.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Adobe&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Adobe’s VP of generative AI, Alexandru Costin, told TechCrunch that the company decided to build a different mode for its AI assistant in Express to target students and professionals who use the app. The company wants to see if users can achieve what they want to do without having to switch back to the traditional interface, he explained.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We think this approach of switching between two modes, where you get the best of both worlds, is gonna make the technology both accessible and controllable,” Costin said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company said it is also experimenting with a new type of assistant, dubbed “Project Moonlight,” that can coordinate with different assistants from other Adobe tools, and connect to a creator’s social channels to better understand their style. Adobe said the product is in the early stages of development and is in private beta.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="An illustrative image showing prototypes of Adobe's new project of cross-app assistant is a system that gets data from all of its apps. " class="wp-image-3062944" height="383" src="https://techcrunch.com/wp-content/uploads/2025/10/ProjectMoonlight.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Adobe&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company said it is also exploring a way to connect Adobe Express with ChatGPT using OpenAI’s app integrations API to let users create designs directly in ChatGPT.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Adobe also announced a new set of AI features for its Creative Cloud apps. Photoshop users can now choose third-party models, like Google’s Gemini 2.5 flash and Black Forest Labs’ FLUX.1 Kontext, for the generative fill feature, which can remove objects or extend images. The company is also adding an AI-powered object mask in its video editing app, Premiere Pro, to let users easily identify and select objects or people to add effects or adjust colors.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/28/adobe-launches-ai-assistants-for-express-and-photoshop/</guid><pubDate>Tue, 28 Oct 2025 12:00:00 +0000</pubDate></item><item><title>Adobe Firefly Image 5 brings support for layers, will let creators make custom models (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/28/adobe-firefly-image-5-brings-support-for-layers-will-let-creators-make-custom-models/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Adobe said on Tuesday that it is launching the latest iteration of its image generation model, Firefly Image 5. The company is also adding more features to the Firefly website, support for more third-party models, and the ability to generate speech and soundtracks. Notably, the update allows artists to come up with their own image models using their existing art.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Image 5 can now work at native resolutions of up to 4 megapixels, a massive increase from the previous-gen model, which could natively generate images at 1 megapixel but then would upscale them to 4 megapixels. The new model is also better at rendering humans, the company said.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter"&gt;&lt;img alt="alt" class="wp-image-3062893" height="2048" src="https://techcrunch.com/wp-content/uploads/2025/10/FireflyImageModel5.jpeg?w=680" width="3840" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Adobe&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Image 5 also enables layered and prompt-based editing — the model treats different objects as layers and allows you to edit them using prompts, or use tools like resize and rotate. The company said it makes sure that when you edit these layers, the image’s details and integrity are not compromised.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Adobe’s Firefly site has supported third-party models from AI labs like OpenAI, Google, Runway, Topaz, and Flux to augment its appeal to its creative customer base, and now the company is taking that a step further by letting users create custom models based on their art style. Currently in a closed beta, this feature lets users drag and drop assets, such as images, illustrations and sketches, to create a custom image model based on their style.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is also adding some new features to its Firefly website, which was redesigned earlier this year. The site now lets you use the prompt box to switch between generating images or videos, choose which AI model you want to work with, change aspect ratios, and more. The site’s home page now features your files and recent generation history, and you also get shortcuts to other Adobe apps (these were previously housed in a menu).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Adobe has also redesigned the video generation and editing tool to support layers and timeline-based editing. This design change is currently only available in a private beta, and will be rolled out to users eventually.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3062895" height="680" src="https://techcrunch.com/wp-content/uploads/2025/10/VideoEditor.jpg?w=544" width="544" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Adobe&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Firefly is also getting two new audio features: Users can now employ AI prompts to generate entire soundtracks and speech — using models from ElevenLabs — for videos. There’s also a new way to easily come up with prompts: just add keywords and sections by selecting words from a word cloud.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3062894" height="680" src="https://techcrunch.com/wp-content/uploads/2025/10/GenerateSoundtrack.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Adobe&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;As its competitors like Canva add AI to their platforms, Adobe is trying to cater to new-age creators who are increasingly using AI in their workflows. “We’re thinking of the target audience for Firefly as what we call creators or next-generation creative professionals. I think there are these emergent creatives that are GenAI-oriented. They love to use GenAI in all their workloads,” Alexandru Costin, the company’s VP of generative AI, told TechCrunch over a call.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He added that with Firefly, the company now has more freedom to add new features and play around with the interface as it doesn’t have to adhere to the muscle memory of creative professionals who might be used to certain workflows in Adobe’s existing Creative Cloud tools.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Adobe said on Tuesday that it is launching the latest iteration of its image generation model, Firefly Image 5. The company is also adding more features to the Firefly website, support for more third-party models, and the ability to generate speech and soundtracks. Notably, the update allows artists to come up with their own image models using their existing art.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Image 5 can now work at native resolutions of up to 4 megapixels, a massive increase from the previous-gen model, which could natively generate images at 1 megapixel but then would upscale them to 4 megapixels. The new model is also better at rendering humans, the company said.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter"&gt;&lt;img alt="alt" class="wp-image-3062893" height="2048" src="https://techcrunch.com/wp-content/uploads/2025/10/FireflyImageModel5.jpeg?w=680" width="3840" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Adobe&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Image 5 also enables layered and prompt-based editing — the model treats different objects as layers and allows you to edit them using prompts, or use tools like resize and rotate. The company said it makes sure that when you edit these layers, the image’s details and integrity are not compromised.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Adobe’s Firefly site has supported third-party models from AI labs like OpenAI, Google, Runway, Topaz, and Flux to augment its appeal to its creative customer base, and now the company is taking that a step further by letting users create custom models based on their art style. Currently in a closed beta, this feature lets users drag and drop assets, such as images, illustrations and sketches, to create a custom image model based on their style.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is also adding some new features to its Firefly website, which was redesigned earlier this year. The site now lets you use the prompt box to switch between generating images or videos, choose which AI model you want to work with, change aspect ratios, and more. The site’s home page now features your files and recent generation history, and you also get shortcuts to other Adobe apps (these were previously housed in a menu).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Adobe has also redesigned the video generation and editing tool to support layers and timeline-based editing. This design change is currently only available in a private beta, and will be rolled out to users eventually.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3062895" height="680" src="https://techcrunch.com/wp-content/uploads/2025/10/VideoEditor.jpg?w=544" width="544" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Adobe&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Firefly is also getting two new audio features: Users can now employ AI prompts to generate entire soundtracks and speech — using models from ElevenLabs — for videos. There’s also a new way to easily come up with prompts: just add keywords and sections by selecting words from a word cloud.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3062894" height="680" src="https://techcrunch.com/wp-content/uploads/2025/10/GenerateSoundtrack.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Adobe&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;As its competitors like Canva add AI to their platforms, Adobe is trying to cater to new-age creators who are increasingly using AI in their workflows. “We’re thinking of the target audience for Firefly as what we call creators or next-generation creative professionals. I think there are these emergent creatives that are GenAI-oriented. They love to use GenAI in all their workloads,” Alexandru Costin, the company’s VP of generative AI, told TechCrunch over a call.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He added that with Firefly, the company now has more freedom to add new features and play around with the interface as it doesn’t have to adhere to the muscle memory of creative professionals who might be used to certain workflows in Adobe’s existing Creative Cloud tools.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/28/adobe-firefly-image-5-brings-support-for-layers-will-let-creators-make-custom-models/</guid><pubDate>Tue, 28 Oct 2025 12:00:00 +0000</pubDate></item><item><title>[NEW] OpenAI’s bold India play: Free ChatGPT Go access (AI News)</title><link>https://www.artificialintelligence-news.com/news/openai-chatgpt-go-free-india-market-strategy/</link><description>&lt;p&gt;OpenAI just made its biggest bet on India yet. Starting November 4, the company will hand out free year-long access to ChatGPT Go — a move that puts every marketing executive on notice about how aggressively AI companies are fighting for the world’s fastest-growing digital market.&lt;/p&gt;&lt;p&gt;OpenAI will offer its ChatGPT Go plan to users in India who sign up during a limited promotional period starting November 4. For those tracking ad spend, customer acquisition costs, and market share battles, this isn’t charity — it’s calculated warfare in a market where the prize is 1.4 billion potential users.&lt;/p&gt;&lt;p&gt;The timing reveals a sophisticated strategy. The announcement coincides with OpenAI’s DevDay Exchange developer conference in Bengaluru on November 4, where the company is expected to make India-specific announcements aimed at local developers and enterprises. Launching a product alongside an ecosystem play simultaneously? That’s textbook platform marketing.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-us-17-billion-prize"&gt;The US$17 billion prize&lt;/h3&gt;&lt;p&gt;India’s AI market is expected to triple in value to US$17 billion by 2027, according to a Boston Consulting Group white paper.The country is OpenAI’s second-largest market and one of its fastest-growing, prompting the company to establish a New Delhi office in August and build a local team.&lt;/p&gt;&lt;p&gt;The competitive context makes this offer significant. The move follows similar strategies by Perplexity and Google, which both provided free access to premium AI features in India recently to attract users.&lt;/p&gt;&lt;p&gt;Perplexity partnered with Airtel to offer free Perplexity Pro subscriptions to the telecom operator’s 360 million subscribers, while Google introduced a free one-year AI Pro plan for students.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-battle-lines-drawn"&gt;Battle lines drawn&lt;/h3&gt;&lt;p&gt;The numbers tell the story. In the second quarter of 2025, Perplexity’s downloads in India surged 600% year-on-year to 2.8 million, while OpenAI’s ChatGPT saw a 587% increase, reaching 46.7 million downloads.&lt;/p&gt;&lt;p&gt;However, ChatGPT maintains a significant lead in absolute numbers, with 19.8 million monthly active users, versus 3.7 million for Perplexity. The ChatGPT Go programme answers an insight from the market. Launched in India in August, the tier was developed following user feedback calling for more affordable access to ChatGPT’s advanced features.&lt;/p&gt;&lt;p&gt;In its first month, the number of paid ChatGPT subscribers in India more than doubled, demonstrating strong product-market fit. Following the response, OpenAI expanded ChatGPT Go to nearly 90 countries worldwide.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-marketers-should-know"&gt;What marketers should know&lt;/h3&gt;&lt;p&gt;ChatGPT Go delivers substantial value. The plan provides higher message limits, more image generation, longer memory, and the ability to upload more files and images. At the standard pricing of less than US$5 per month, the 12-month giveaway represents a serious customer acquisition investment.&lt;/p&gt;&lt;p&gt;Nick Turley, Vice President and Head of ChatGPT, stated: “Since initially launching ChatGPT Go in India a few months ago, the adoption and creativity we’ve seen from our users has been inspiring. Ahead of our first DevDay Exchange event in India, we’re making ChatGPT Go freely available for a year to help more people across India easily access and benefit from advanced AI”.&lt;/p&gt;&lt;p&gt;The retention play is equally smart. Existing ChatGPT Go subscribers in India will also be eligible for the free 12-month promotion, preventing churn while rewarding early adopters – a lesson in lifetime value economics.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-distribution-playbook"&gt;The distribution playbook&lt;/h3&gt;&lt;p&gt;India has over 700 million smartphone users and more than a billion internet subscribers, creating unprecedented scale for digital products. Unlike competitors relying on telecom partnerships, OpenAI’s direct-to-consumer approach builds first-party relationships with users – a valuable asset for long-term monetisation.&lt;/p&gt;&lt;p&gt;Professor Payal Arora of Utrecht University said that India serves as a “high-pressure testing ground,” and a source of training data sets. Training AI on vast Indian data sets pushes models to handle linguistic diversity, low-resource contexts, and noisy real-world data, something that makes them more robust, globally.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-three-marketing-lessons"&gt;Three marketing lessons&lt;/h3&gt;&lt;p&gt;The initiative offers clear takeaways for marketing professionals. First, OpenAI is sacrificing short-term revenue for market position – a classic land-grab in winner-take-most digital markets.&lt;/p&gt;&lt;p&gt;Secondly, synchronising the offer with DevDay Exchange creates compound marketing value through ecosystem momentum. Thirdly, extending benefits to existing subscribers demonstrates a sophisticated understanding of customer lifetime value.&lt;/p&gt;&lt;p&gt;OpenAI positioned the promotion as “a continuation of OpenAI’s ‘Indiafirst’ commitment and supports the IndiaAI Mission, reinforcing the growing momentum around AI in India as the country prepares to host the AI Impact Summit next year” – a strategic alignment with national priorities that strengthens the company’s geopolitical positioning.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-monetisation-challenge"&gt;The monetisation challenge&lt;/h3&gt;&lt;p&gt;Monetising India’s large user base remains challenging, with consumers notoriously price-sensitive. Yet the scale opportunity is enormous. Converting even a small fraction of free users to paid subscribers after the promotional period could justify the acquisition cost through lifetime value, particularly as AI embeds itself deeper into professional workflows.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-this-means"&gt;What this means&lt;/h3&gt;&lt;p&gt;OpenAI’s announcement signals that AI platform wars have entered a decisive phase where user acquisition at scale trumps immediate monetisation. For marketing professionals, the lesson is clear: in transformative technology markets, aggressive distribution and ecosystem building matter more than traditional margin optimisation.&lt;/p&gt;&lt;p&gt;As AI capabilities commoditise, winners will be determined by who captures user habits and builds the&amp;nbsp;strongest&amp;nbsp;network effects first.&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: OpenAI argues against ChatGPT data deletion in Indian court&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-110044" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-9.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;OpenAI just made its biggest bet on India yet. Starting November 4, the company will hand out free year-long access to ChatGPT Go — a move that puts every marketing executive on notice about how aggressively AI companies are fighting for the world’s fastest-growing digital market.&lt;/p&gt;&lt;p&gt;OpenAI will offer its ChatGPT Go plan to users in India who sign up during a limited promotional period starting November 4. For those tracking ad spend, customer acquisition costs, and market share battles, this isn’t charity — it’s calculated warfare in a market where the prize is 1.4 billion potential users.&lt;/p&gt;&lt;p&gt;The timing reveals a sophisticated strategy. The announcement coincides with OpenAI’s DevDay Exchange developer conference in Bengaluru on November 4, where the company is expected to make India-specific announcements aimed at local developers and enterprises. Launching a product alongside an ecosystem play simultaneously? That’s textbook platform marketing.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-us-17-billion-prize"&gt;The US$17 billion prize&lt;/h3&gt;&lt;p&gt;India’s AI market is expected to triple in value to US$17 billion by 2027, according to a Boston Consulting Group white paper.The country is OpenAI’s second-largest market and one of its fastest-growing, prompting the company to establish a New Delhi office in August and build a local team.&lt;/p&gt;&lt;p&gt;The competitive context makes this offer significant. The move follows similar strategies by Perplexity and Google, which both provided free access to premium AI features in India recently to attract users.&lt;/p&gt;&lt;p&gt;Perplexity partnered with Airtel to offer free Perplexity Pro subscriptions to the telecom operator’s 360 million subscribers, while Google introduced a free one-year AI Pro plan for students.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-battle-lines-drawn"&gt;Battle lines drawn&lt;/h3&gt;&lt;p&gt;The numbers tell the story. In the second quarter of 2025, Perplexity’s downloads in India surged 600% year-on-year to 2.8 million, while OpenAI’s ChatGPT saw a 587% increase, reaching 46.7 million downloads.&lt;/p&gt;&lt;p&gt;However, ChatGPT maintains a significant lead in absolute numbers, with 19.8 million monthly active users, versus 3.7 million for Perplexity. The ChatGPT Go programme answers an insight from the market. Launched in India in August, the tier was developed following user feedback calling for more affordable access to ChatGPT’s advanced features.&lt;/p&gt;&lt;p&gt;In its first month, the number of paid ChatGPT subscribers in India more than doubled, demonstrating strong product-market fit. Following the response, OpenAI expanded ChatGPT Go to nearly 90 countries worldwide.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-marketers-should-know"&gt;What marketers should know&lt;/h3&gt;&lt;p&gt;ChatGPT Go delivers substantial value. The plan provides higher message limits, more image generation, longer memory, and the ability to upload more files and images. At the standard pricing of less than US$5 per month, the 12-month giveaway represents a serious customer acquisition investment.&lt;/p&gt;&lt;p&gt;Nick Turley, Vice President and Head of ChatGPT, stated: “Since initially launching ChatGPT Go in India a few months ago, the adoption and creativity we’ve seen from our users has been inspiring. Ahead of our first DevDay Exchange event in India, we’re making ChatGPT Go freely available for a year to help more people across India easily access and benefit from advanced AI”.&lt;/p&gt;&lt;p&gt;The retention play is equally smart. Existing ChatGPT Go subscribers in India will also be eligible for the free 12-month promotion, preventing churn while rewarding early adopters – a lesson in lifetime value economics.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-distribution-playbook"&gt;The distribution playbook&lt;/h3&gt;&lt;p&gt;India has over 700 million smartphone users and more than a billion internet subscribers, creating unprecedented scale for digital products. Unlike competitors relying on telecom partnerships, OpenAI’s direct-to-consumer approach builds first-party relationships with users – a valuable asset for long-term monetisation.&lt;/p&gt;&lt;p&gt;Professor Payal Arora of Utrecht University said that India serves as a “high-pressure testing ground,” and a source of training data sets. Training AI on vast Indian data sets pushes models to handle linguistic diversity, low-resource contexts, and noisy real-world data, something that makes them more robust, globally.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-three-marketing-lessons"&gt;Three marketing lessons&lt;/h3&gt;&lt;p&gt;The initiative offers clear takeaways for marketing professionals. First, OpenAI is sacrificing short-term revenue for market position – a classic land-grab in winner-take-most digital markets.&lt;/p&gt;&lt;p&gt;Secondly, synchronising the offer with DevDay Exchange creates compound marketing value through ecosystem momentum. Thirdly, extending benefits to existing subscribers demonstrates a sophisticated understanding of customer lifetime value.&lt;/p&gt;&lt;p&gt;OpenAI positioned the promotion as “a continuation of OpenAI’s ‘Indiafirst’ commitment and supports the IndiaAI Mission, reinforcing the growing momentum around AI in India as the country prepares to host the AI Impact Summit next year” – a strategic alignment with national priorities that strengthens the company’s geopolitical positioning.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-monetisation-challenge"&gt;The monetisation challenge&lt;/h3&gt;&lt;p&gt;Monetising India’s large user base remains challenging, with consumers notoriously price-sensitive. Yet the scale opportunity is enormous. Converting even a small fraction of free users to paid subscribers after the promotional period could justify the acquisition cost through lifetime value, particularly as AI embeds itself deeper into professional workflows.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-this-means"&gt;What this means&lt;/h3&gt;&lt;p&gt;OpenAI’s announcement signals that AI platform wars have entered a decisive phase where user acquisition at scale trumps immediate monetisation. For marketing professionals, the lesson is clear: in transformative technology markets, aggressive distribution and ecosystem building matter more than traditional margin optimisation.&lt;/p&gt;&lt;p&gt;As AI capabilities commoditise, winners will be determined by who captures user habits and builds the&amp;nbsp;strongest&amp;nbsp;network effects first.&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: OpenAI argues against ChatGPT data deletion in Indian court&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-110044" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-9.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/openai-chatgpt-go-free-india-market-strategy/</guid><pubDate>Tue, 28 Oct 2025 12:01:27 +0000</pubDate></item><item><title>[NEW] Intuit learned to build AI agents for finance the hard way: Trust lost in buckets, earned back in spoonfuls (AI | VentureBeat)</title><link>https://venturebeat.com/ai/intuit-learned-to-build-ai-agents-for-finance-the-hard-way-trust-lost-in</link><description>[unable to retrieve full-text content]&lt;p&gt;Building AI for financial software requires a different playbook than consumer AI, and &lt;a href="https://www.intuit.com/"&gt;&lt;u&gt;Intuit&amp;#x27;s&lt;/u&gt;&lt;/a&gt; latest QuickBooks release provides an example.&lt;/p&gt;&lt;p&gt;The company has announced Intuit Intelligence, a system that orchestrates specialized AI agents across its QuickBooks platform to handle tasks including sales tax compliance and payroll processing. These new agents augment existing accounting and project management agents (which have also been updated) as well as a unified interface that lets users query data across QuickBooks, third-party systems and uploaded files using natural language. &lt;/p&gt;&lt;p&gt;The new development follow years of investment and improvement in Intuit&amp;#x27;s&lt;a href="https://venturebeat.com/ai/inside-intuits-genos-update-why-prompt-optimization-and-intelligent-data-cognition-are-critical-to-enterprise-agentic-ai-success"&gt; &lt;u&gt;GenOS&lt;/u&gt;&lt;/a&gt;, allowing the company to build AI capabilities that reduce&lt;a href="https://venturebeat.com/ai/how-intuit-built-custom-financial-llms-that-cut-latency-50-while-boosting"&gt; &lt;u&gt;latency and improve accuracy&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;But the real news isn&amp;#x27;t what Intuit built — it&amp;#x27;s how they built it and why their design decisions will make AI more usable. The company&amp;#x27;s latest AI rollout represents an evolution built on hard-won lessons about what works and what doesn&amp;#x27;t when deploying AI in financial contexts.&lt;/p&gt;&lt;p&gt;What the company learned is sobering: Even when its accounting agent improved transaction categorization accuracy by 20 percentage points on average, they still received complaints about errors.&lt;/p&gt;&lt;p&gt;&amp;quot;The use cases that we&amp;#x27;re trying to solve for customers include tax and finance; if you make a mistake in this world, you lose trust with customers in buckets and we only get it back in spoonfuls,&amp;quot; Joe Preston, Intuit&amp;#x27;s VP of product and design, told VentureBeat.&lt;/p&gt;&lt;h2&gt;The architecture of trust: Real data queries over generative responses&lt;/h2&gt;&lt;p&gt;Intuit&amp;#x27;s technical strategy centers on a fundamental design decision. For financial queries and business intelligence, the system queries actual data, rather than generating responses through large language models (LLMs).&lt;/p&gt;&lt;p&gt;Also critically important: That data isn&amp;#x27;t all in one place. Intuit&amp;#x27;s technical implementation allows QuickBooks to ingest data from multiple distinct sources: native Intuit data, OAuth-connected third-party systems like Square for payments and user-uploaded files such as spreadsheets containing vendor pricing lists or marketing campaign data. This creates a unified data layer that AI agents can query reliably.&lt;/p&gt;&lt;p&gt;&amp;quot;We&amp;#x27;re actually querying your real data,&amp;quot; Preston explained. &amp;quot;That&amp;#x27;s very different than if you were to just copy, paste out a spreadsheet or a PDF and paste into ChatGPT.&amp;quot;&lt;/p&gt;&lt;p&gt;This architectural choice means that the Intuit Intelligence system functions more as an orchestration layer. It&amp;#x27;s a natural language interface to structured data operations. When a user asks about projected profitability or wants to run payroll, the system translates the natural language query into database operations against verified financial data.&lt;/p&gt;&lt;p&gt;This matters because Intuit&amp;#x27;s internal research has uncovered widespread shadow AI usage. When surveyed, 25% of accountants using QuickBooks admitted they were already copying and pasting data into ChatGPT or Google Gemini for analysis.&lt;/p&gt;&lt;p&gt;Intuit&amp;#x27;s approach treats AI as a query translation and orchestration mechanism, not a content generator. This reduces the hallucination risk that has plagued AI deployments in financial contexts.&lt;/p&gt;&lt;h2&gt;Explainability as a design requirement, not an afterthought&lt;/h2&gt;&lt;p&gt;Beyond the technical architecture, Intuit has made explainability a core user experience across its AI agents. This goes beyond simply providing correct answers: It means showing users the reasoning behind automated decisions.&lt;/p&gt;&lt;p&gt;When Intuit&amp;#x27;s accounting agent categorizes a transaction, it doesn&amp;#x27;t just display the result; it shows the reasoning. This isn&amp;#x27;t marketing copy about explainable AI, it&amp;#x27;s actual UI displaying data points and logic.&lt;/p&gt;&lt;p&gt;&amp;quot;It&amp;#x27;s about closing that trust loop and making sure customers understand the why,&amp;quot; Alastair Simpson, Intuit&amp;#x27;s VP of design, told VentureBeat.&lt;/p&gt;&lt;p&gt;This becomes particularly critical when you consider Intuit&amp;#x27;s user research: While half of small businesses describe AI as helpful, nearly a quarter haven&amp;#x27;t used AI at all. The explanation layer serves both populations: Building confidence for newcomers, while giving experienced users the context to verify accuracy.&lt;/p&gt;&lt;p&gt;The design also enforces human control at critical decision points. This approach extends beyond the interface. Intuit connects users directly with human experts, embedded in the same workflows, when automation reaches its limits or when users want validation.&lt;/p&gt;&lt;h2&gt;Navigating the transition from forms to conversations&lt;/h2&gt;&lt;p&gt;One of Intuit&amp;#x27;s more interesting challenges involves managing a fundamental shift in user interfaces. Preston described it as having one foot in the past and one foot in the future.&lt;/p&gt;&lt;p&gt;&amp;quot;This isn&amp;#x27;t just Intuit, this is the market as a whole,&amp;quot; said Preston. &amp;quot;Today we still have a lot of customers filling out forms and going through tables full of data. We&amp;#x27;re investing a lot into leaning in and questioning the ways that we do it across our products today, where you&amp;#x27;re basically just filling out, form after form, or table after table, because we see where the world is headed, which is really a different form of interacting with these products.&amp;quot;&lt;/p&gt;&lt;p&gt;This creates a product design challenge: How do you serve users who are comfortable with traditional interfaces while gradually introducing conversational and agentic capabilities?&lt;/p&gt;&lt;p&gt;Intuit&amp;#x27;s approach has been to embed AI agents directly into existing workflows. This means not forcing users to adopt entirely new interaction patterns. The payments agent appears alongside invoicing workflows; the accounting agent enhances the existing reconciliation process rather than replacing it. This incremental approach lets users experience AI benefits without abandoning familiar processes.&lt;/p&gt;&lt;h2&gt;What enterprise AI builders can learn from Intuit&amp;#x27;s approach&lt;/h2&gt;&lt;p&gt;Intuit&amp;#x27;s experience deploying AI in financial contexts surfaces several principles that apply broadly to enterprise AI initiatives. &lt;/p&gt;&lt;p&gt;&lt;b&gt;Architecture matters for trust: &lt;/b&gt;In domains where accuracy is critical, consider whether you need content generation or data query translation. Intuit&amp;#x27;s decision to treat AI as an orchestration and natural language interface layer dramatically reduces hallucination risk and avoids using AI as a generative system.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Explainability must be designed in, not bolted on: &lt;/b&gt;Showing users why the AI made a decision isn&amp;#x27;t optional when trust is at stake. This requires deliberate UX design. It may constrain model choices.&lt;/p&gt;&lt;p&gt;&lt;b&gt;User control preserves trust during accuracy improvements: &lt;/b&gt;Intuit&amp;#x27;s accounting agent improved categorization accuracy by 20 percentage points. Yet, maintaining user override capabilities was essential for adoption.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Transition gradually from familiar interfaces: &lt;/b&gt;Don&amp;#x27;t force users to abandon forms for conversations. Embed AI capabilities into existing workflows first. Let users experience benefits before asking them to change behavior.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Be honest about what&amp;#x27;s reactive versus proactive: &lt;/b&gt;Current AI agents primarily respond to prompts and automate defined tasks. True proactive intelligence that makes unprompted strategic recommendations remains an evolving capability. &lt;/p&gt;&lt;p&gt;&lt;b&gt;Address workforce concerns with tooling, not just messaging: &lt;/b&gt;If AI is meant to augment rather than replace workers, provide workers with AI tools. Show them how to leverage the technology.&lt;/p&gt;&lt;p&gt;For enterprises navigating AI adoption, Intuit&amp;#x27;s journey offers a clear directive. The winning approach prioritizes trustworthiness over capability demonstrations. In domains where mistakes have real consequences, that means investing in accuracy, transparency and human oversight before pursuing conversational sophistication or autonomous action.&lt;/p&gt;&lt;p&gt;Simpson frames the challenge succinctly: &amp;quot;We didn&amp;#x27;t want it to be a bolted-on layer. We wanted customers to be in their natural workflow, and have agents doing work for customers, embedded in the workflow.&amp;quot;&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;Building AI for financial software requires a different playbook than consumer AI, and &lt;a href="https://www.intuit.com/"&gt;&lt;u&gt;Intuit&amp;#x27;s&lt;/u&gt;&lt;/a&gt; latest QuickBooks release provides an example.&lt;/p&gt;&lt;p&gt;The company has announced Intuit Intelligence, a system that orchestrates specialized AI agents across its QuickBooks platform to handle tasks including sales tax compliance and payroll processing. These new agents augment existing accounting and project management agents (which have also been updated) as well as a unified interface that lets users query data across QuickBooks, third-party systems and uploaded files using natural language. &lt;/p&gt;&lt;p&gt;The new development follow years of investment and improvement in Intuit&amp;#x27;s&lt;a href="https://venturebeat.com/ai/inside-intuits-genos-update-why-prompt-optimization-and-intelligent-data-cognition-are-critical-to-enterprise-agentic-ai-success"&gt; &lt;u&gt;GenOS&lt;/u&gt;&lt;/a&gt;, allowing the company to build AI capabilities that reduce&lt;a href="https://venturebeat.com/ai/how-intuit-built-custom-financial-llms-that-cut-latency-50-while-boosting"&gt; &lt;u&gt;latency and improve accuracy&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;But the real news isn&amp;#x27;t what Intuit built — it&amp;#x27;s how they built it and why their design decisions will make AI more usable. The company&amp;#x27;s latest AI rollout represents an evolution built on hard-won lessons about what works and what doesn&amp;#x27;t when deploying AI in financial contexts.&lt;/p&gt;&lt;p&gt;What the company learned is sobering: Even when its accounting agent improved transaction categorization accuracy by 20 percentage points on average, they still received complaints about errors.&lt;/p&gt;&lt;p&gt;&amp;quot;The use cases that we&amp;#x27;re trying to solve for customers include tax and finance; if you make a mistake in this world, you lose trust with customers in buckets and we only get it back in spoonfuls,&amp;quot; Joe Preston, Intuit&amp;#x27;s VP of product and design, told VentureBeat.&lt;/p&gt;&lt;h2&gt;The architecture of trust: Real data queries over generative responses&lt;/h2&gt;&lt;p&gt;Intuit&amp;#x27;s technical strategy centers on a fundamental design decision. For financial queries and business intelligence, the system queries actual data, rather than generating responses through large language models (LLMs).&lt;/p&gt;&lt;p&gt;Also critically important: That data isn&amp;#x27;t all in one place. Intuit&amp;#x27;s technical implementation allows QuickBooks to ingest data from multiple distinct sources: native Intuit data, OAuth-connected third-party systems like Square for payments and user-uploaded files such as spreadsheets containing vendor pricing lists or marketing campaign data. This creates a unified data layer that AI agents can query reliably.&lt;/p&gt;&lt;p&gt;&amp;quot;We&amp;#x27;re actually querying your real data,&amp;quot; Preston explained. &amp;quot;That&amp;#x27;s very different than if you were to just copy, paste out a spreadsheet or a PDF and paste into ChatGPT.&amp;quot;&lt;/p&gt;&lt;p&gt;This architectural choice means that the Intuit Intelligence system functions more as an orchestration layer. It&amp;#x27;s a natural language interface to structured data operations. When a user asks about projected profitability or wants to run payroll, the system translates the natural language query into database operations against verified financial data.&lt;/p&gt;&lt;p&gt;This matters because Intuit&amp;#x27;s internal research has uncovered widespread shadow AI usage. When surveyed, 25% of accountants using QuickBooks admitted they were already copying and pasting data into ChatGPT or Google Gemini for analysis.&lt;/p&gt;&lt;p&gt;Intuit&amp;#x27;s approach treats AI as a query translation and orchestration mechanism, not a content generator. This reduces the hallucination risk that has plagued AI deployments in financial contexts.&lt;/p&gt;&lt;h2&gt;Explainability as a design requirement, not an afterthought&lt;/h2&gt;&lt;p&gt;Beyond the technical architecture, Intuit has made explainability a core user experience across its AI agents. This goes beyond simply providing correct answers: It means showing users the reasoning behind automated decisions.&lt;/p&gt;&lt;p&gt;When Intuit&amp;#x27;s accounting agent categorizes a transaction, it doesn&amp;#x27;t just display the result; it shows the reasoning. This isn&amp;#x27;t marketing copy about explainable AI, it&amp;#x27;s actual UI displaying data points and logic.&lt;/p&gt;&lt;p&gt;&amp;quot;It&amp;#x27;s about closing that trust loop and making sure customers understand the why,&amp;quot; Alastair Simpson, Intuit&amp;#x27;s VP of design, told VentureBeat.&lt;/p&gt;&lt;p&gt;This becomes particularly critical when you consider Intuit&amp;#x27;s user research: While half of small businesses describe AI as helpful, nearly a quarter haven&amp;#x27;t used AI at all. The explanation layer serves both populations: Building confidence for newcomers, while giving experienced users the context to verify accuracy.&lt;/p&gt;&lt;p&gt;The design also enforces human control at critical decision points. This approach extends beyond the interface. Intuit connects users directly with human experts, embedded in the same workflows, when automation reaches its limits or when users want validation.&lt;/p&gt;&lt;h2&gt;Navigating the transition from forms to conversations&lt;/h2&gt;&lt;p&gt;One of Intuit&amp;#x27;s more interesting challenges involves managing a fundamental shift in user interfaces. Preston described it as having one foot in the past and one foot in the future.&lt;/p&gt;&lt;p&gt;&amp;quot;This isn&amp;#x27;t just Intuit, this is the market as a whole,&amp;quot; said Preston. &amp;quot;Today we still have a lot of customers filling out forms and going through tables full of data. We&amp;#x27;re investing a lot into leaning in and questioning the ways that we do it across our products today, where you&amp;#x27;re basically just filling out, form after form, or table after table, because we see where the world is headed, which is really a different form of interacting with these products.&amp;quot;&lt;/p&gt;&lt;p&gt;This creates a product design challenge: How do you serve users who are comfortable with traditional interfaces while gradually introducing conversational and agentic capabilities?&lt;/p&gt;&lt;p&gt;Intuit&amp;#x27;s approach has been to embed AI agents directly into existing workflows. This means not forcing users to adopt entirely new interaction patterns. The payments agent appears alongside invoicing workflows; the accounting agent enhances the existing reconciliation process rather than replacing it. This incremental approach lets users experience AI benefits without abandoning familiar processes.&lt;/p&gt;&lt;h2&gt;What enterprise AI builders can learn from Intuit&amp;#x27;s approach&lt;/h2&gt;&lt;p&gt;Intuit&amp;#x27;s experience deploying AI in financial contexts surfaces several principles that apply broadly to enterprise AI initiatives. &lt;/p&gt;&lt;p&gt;&lt;b&gt;Architecture matters for trust: &lt;/b&gt;In domains where accuracy is critical, consider whether you need content generation or data query translation. Intuit&amp;#x27;s decision to treat AI as an orchestration and natural language interface layer dramatically reduces hallucination risk and avoids using AI as a generative system.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Explainability must be designed in, not bolted on: &lt;/b&gt;Showing users why the AI made a decision isn&amp;#x27;t optional when trust is at stake. This requires deliberate UX design. It may constrain model choices.&lt;/p&gt;&lt;p&gt;&lt;b&gt;User control preserves trust during accuracy improvements: &lt;/b&gt;Intuit&amp;#x27;s accounting agent improved categorization accuracy by 20 percentage points. Yet, maintaining user override capabilities was essential for adoption.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Transition gradually from familiar interfaces: &lt;/b&gt;Don&amp;#x27;t force users to abandon forms for conversations. Embed AI capabilities into existing workflows first. Let users experience benefits before asking them to change behavior.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Be honest about what&amp;#x27;s reactive versus proactive: &lt;/b&gt;Current AI agents primarily respond to prompts and automate defined tasks. True proactive intelligence that makes unprompted strategic recommendations remains an evolving capability. &lt;/p&gt;&lt;p&gt;&lt;b&gt;Address workforce concerns with tooling, not just messaging: &lt;/b&gt;If AI is meant to augment rather than replace workers, provide workers with AI tools. Show them how to leverage the technology.&lt;/p&gt;&lt;p&gt;For enterprises navigating AI adoption, Intuit&amp;#x27;s journey offers a clear directive. The winning approach prioritizes trustworthiness over capability demonstrations. In domains where mistakes have real consequences, that means investing in accuracy, transparency and human oversight before pursuing conversational sophistication or autonomous action.&lt;/p&gt;&lt;p&gt;Simpson frames the challenge succinctly: &amp;quot;We didn&amp;#x27;t want it to be a bolted-on layer. We wanted customers to be in their natural workflow, and have agents doing work for customers, embedded in the workflow.&amp;quot;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/intuit-learned-to-build-ai-agents-for-finance-the-hard-way-trust-lost-in</guid><pubDate>Tue, 28 Oct 2025 12:30:00 +0000</pubDate></item><item><title>[NEW] The Download: Microsoft’s stance on erotic AI, and an AI hype mystery (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/28/1126802/the-download-microsofts-stance-on-erotic-ai-and-an-ai-hype-mystery/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;“We will never build a sex robot,” says Mustafa Suleyman&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Mustafa Suleyman, CEO of Microsoft AI, is trying to walk a fine line. On the one hand, he thinks that the industry is taking AI in a dangerous direction by building chatbots that present as human: He worries that people will be tricked into seeing life instead of lifelike behavior.&lt;/p&gt;&lt;p&gt;On the other hand, Suleyman runs a product shop that must compete with those peers. Last week, Microsoft announced a string of updates to its Copilot chatbot designed to make Copilot more expressive, engaging, and helpful.&lt;/p&gt;&lt;p&gt;Will Douglas Heaven, our senior AI editor, talked to Suleyman about the tension at play when it comes to designing our interactions with chatbots and his ultimate vision for what this new technology should be.&lt;strong&gt; &lt;/strong&gt;Read the full story.&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;An AI adoption riddle&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—James O’Donnell, senior AI reporter&amp;nbsp;&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;A few weeks ago, I set out on what I thought would be a straightforward reporting journey.&lt;/p&gt;&lt;p&gt;After years of momentum for AI, hype had been slightly punctured. First there was the underwhelming release of GPT-5 in August. Then a report released two weeks later found that 95% of generative AI pilots were failing, which caused a brief stock market panic. I wanted to know: Which companies are spooked enough to scale back their AI spending?&lt;/p&gt;&lt;p&gt;But if AI’s hype has indeed been punctured, I couldn’t find a company willing to talk about it. So what should we make of my failed quest?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Hundreds of thousands of ChatGPT users exhibit severe mental health symptoms&lt;/strong&gt;&lt;br /&gt;That’s according to estimates from OpenAI, which says it has tweaked GPT-5 to respond more effectively to users in distress. (Wired $)&lt;br /&gt;+ &lt;em&gt;OpenAI won’t lock access to force users to take a break, though. &lt;/em&gt;(Gizmodo)&lt;br /&gt;+ &lt;em&gt;Why AI should be able to “hang up” on you. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 Elon Musk has launched his answer to Wikipedia&lt;/strong&gt;&lt;br /&gt;Grokipedia’s right-leaning entries reflect the way the billionaire sees the world. (WP $)&lt;br /&gt;+ &lt;em&gt;Several pages perpetuate historical inaccuracies and conservative views. &lt;/em&gt;(Wired $)&lt;br /&gt;+ &lt;em&gt;The AI-generated encyclopedia briefly crashed shortly after it launched. &lt;/em&gt;(Engadget)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 Surgeons have removed a pig kidney from a patient&lt;/strong&gt;&lt;br /&gt;It was the longest-functioning genetically engineered pig kidney so far. (Wired $)&lt;br /&gt;+ &lt;em&gt;“Spare” living human bodies might provide us with organs for transplantation. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 Amazon is planning to cut up to 30,000 corporate jobs&lt;/strong&gt;&lt;br /&gt;Partly in response to staff’s reluctance to return to the office five days a week. (Reuters)&lt;br /&gt;+ &lt;em&gt;The company is planning yet another round of layoffs in January. &lt;/em&gt;(NYT $)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;5 Older people can’t get enough of screens&lt;/strong&gt;&lt;br /&gt;Their digital habits mirror the high usage typically observed among teenagers. (Economist $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 A British cyclist has been given a 3D-printed face&lt;/strong&gt;&lt;br /&gt;Dave Richards received severe third-degree burns to his head after being struck by a drunk driver. (The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 The twitter.com domain is being shut down&lt;br /&gt;&lt;/strong&gt;Make sure you re-enroll your security and passkeys before the big switch-off. (Fast Company $)&lt;br /&gt;+ &lt;em&gt;It means the abandoned accounts could be sold on. &lt;/em&gt;(The Verge)&lt;br /&gt;+ &lt;em&gt;But 2FA apps should be fine—in theory. &lt;/em&gt;(The Register)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 When is a moon not a moon?&lt;/strong&gt;&lt;br /&gt;Believe it or not, we don’t have an official definition. (The Atlantic $)&lt;br /&gt;+ &lt;em&gt;Astronomers have spotted a “quasi-moon” hovering near Earth. &lt;/em&gt;(BBC)&lt;br /&gt;+ &lt;em&gt;The moon is just the beginning for this waterless concrete. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;9 Threads’ ghost posts will disappear after 24 hours&lt;/strong&gt;&lt;br /&gt;If anyone saw them in the first place, that is. (TechCrunch)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10 In the metaverse, anyone can be a K-pop superstar&lt;/strong&gt;&lt;br /&gt;Virtual idols are gaining huge popularity, before crossing over into real-world fame. (Rest of World)&lt;br /&gt;+ &lt;em&gt;Meta’s former metaverse head has been moved into its AI team. &lt;/em&gt;(FT $)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“The impulse to control knowledge is as old as knowledge itself. Controlling what gets written is a way to gain or keep power.”&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;—Ryan McGrady, senior research fellow at the University of Massachusetts Amherst, reflects on Elon Musk’s desire to create his own online encyclopedia to the New York Times.&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1126815" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/image_c50a7d.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Inside Amsterdam’s high-stakes experiment to create fair welfare AI&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Amsterdam thought it was on the right track. City officials in the welfare department believed they could build technology that would prevent fraud while protecting citizens’ rights. They followed these emerging best practices and invested a vast amount of time and money in a project that eventually processed live welfare applications. But in their pilot, they found that the system they’d developed was still not fair and effective. Why?&lt;/p&gt;&lt;p&gt;Lighthouse Reports, MIT Technology Review, and the Dutch newspaper Trouw have gained unprecedented access to the system to try to find out. Read about what we discovered.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;&lt;em&gt;—Eileen Guo, Gabriel Geiger &amp;amp; Justin-Casimir Braun&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ Happy 70th birthday to Bill Gates, who is not revered enough for his chair-jumping skills.&lt;br /&gt;+ Bring back Guitar Hero—the iconic game that convinced us all we were capable of knocking out Heart’s &lt;em&gt;Barracuda &lt;/em&gt;(note: the majority of us were not.)&lt;br /&gt;+ Even the swankiest parts of London aren’t immune to rumours of ghostly hauntings.&lt;br /&gt;+ Justice for medieval frogs and their unfair reputation! 🐸&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;“We will never build a sex robot,” says Mustafa Suleyman&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Mustafa Suleyman, CEO of Microsoft AI, is trying to walk a fine line. On the one hand, he thinks that the industry is taking AI in a dangerous direction by building chatbots that present as human: He worries that people will be tricked into seeing life instead of lifelike behavior.&lt;/p&gt;&lt;p&gt;On the other hand, Suleyman runs a product shop that must compete with those peers. Last week, Microsoft announced a string of updates to its Copilot chatbot designed to make Copilot more expressive, engaging, and helpful.&lt;/p&gt;&lt;p&gt;Will Douglas Heaven, our senior AI editor, talked to Suleyman about the tension at play when it comes to designing our interactions with chatbots and his ultimate vision for what this new technology should be.&lt;strong&gt; &lt;/strong&gt;Read the full story.&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;An AI adoption riddle&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—James O’Donnell, senior AI reporter&amp;nbsp;&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;A few weeks ago, I set out on what I thought would be a straightforward reporting journey.&lt;/p&gt;&lt;p&gt;After years of momentum for AI, hype had been slightly punctured. First there was the underwhelming release of GPT-5 in August. Then a report released two weeks later found that 95% of generative AI pilots were failing, which caused a brief stock market panic. I wanted to know: Which companies are spooked enough to scale back their AI spending?&lt;/p&gt;&lt;p&gt;But if AI’s hype has indeed been punctured, I couldn’t find a company willing to talk about it. So what should we make of my failed quest?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Hundreds of thousands of ChatGPT users exhibit severe mental health symptoms&lt;/strong&gt;&lt;br /&gt;That’s according to estimates from OpenAI, which says it has tweaked GPT-5 to respond more effectively to users in distress. (Wired $)&lt;br /&gt;+ &lt;em&gt;OpenAI won’t lock access to force users to take a break, though. &lt;/em&gt;(Gizmodo)&lt;br /&gt;+ &lt;em&gt;Why AI should be able to “hang up” on you. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 Elon Musk has launched his answer to Wikipedia&lt;/strong&gt;&lt;br /&gt;Grokipedia’s right-leaning entries reflect the way the billionaire sees the world. (WP $)&lt;br /&gt;+ &lt;em&gt;Several pages perpetuate historical inaccuracies and conservative views. &lt;/em&gt;(Wired $)&lt;br /&gt;+ &lt;em&gt;The AI-generated encyclopedia briefly crashed shortly after it launched. &lt;/em&gt;(Engadget)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 Surgeons have removed a pig kidney from a patient&lt;/strong&gt;&lt;br /&gt;It was the longest-functioning genetically engineered pig kidney so far. (Wired $)&lt;br /&gt;+ &lt;em&gt;“Spare” living human bodies might provide us with organs for transplantation. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 Amazon is planning to cut up to 30,000 corporate jobs&lt;/strong&gt;&lt;br /&gt;Partly in response to staff’s reluctance to return to the office five days a week. (Reuters)&lt;br /&gt;+ &lt;em&gt;The company is planning yet another round of layoffs in January. &lt;/em&gt;(NYT $)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;5 Older people can’t get enough of screens&lt;/strong&gt;&lt;br /&gt;Their digital habits mirror the high usage typically observed among teenagers. (Economist $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 A British cyclist has been given a 3D-printed face&lt;/strong&gt;&lt;br /&gt;Dave Richards received severe third-degree burns to his head after being struck by a drunk driver. (The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 The twitter.com domain is being shut down&lt;br /&gt;&lt;/strong&gt;Make sure you re-enroll your security and passkeys before the big switch-off. (Fast Company $)&lt;br /&gt;+ &lt;em&gt;It means the abandoned accounts could be sold on. &lt;/em&gt;(The Verge)&lt;br /&gt;+ &lt;em&gt;But 2FA apps should be fine—in theory. &lt;/em&gt;(The Register)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 When is a moon not a moon?&lt;/strong&gt;&lt;br /&gt;Believe it or not, we don’t have an official definition. (The Atlantic $)&lt;br /&gt;+ &lt;em&gt;Astronomers have spotted a “quasi-moon” hovering near Earth. &lt;/em&gt;(BBC)&lt;br /&gt;+ &lt;em&gt;The moon is just the beginning for this waterless concrete. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;9 Threads’ ghost posts will disappear after 24 hours&lt;/strong&gt;&lt;br /&gt;If anyone saw them in the first place, that is. (TechCrunch)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10 In the metaverse, anyone can be a K-pop superstar&lt;/strong&gt;&lt;br /&gt;Virtual idols are gaining huge popularity, before crossing over into real-world fame. (Rest of World)&lt;br /&gt;+ &lt;em&gt;Meta’s former metaverse head has been moved into its AI team. &lt;/em&gt;(FT $)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“The impulse to control knowledge is as old as knowledge itself. Controlling what gets written is a way to gain or keep power.”&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;—Ryan McGrady, senior research fellow at the University of Massachusetts Amherst, reflects on Elon Musk’s desire to create his own online encyclopedia to the New York Times.&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1126815" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/image_c50a7d.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Inside Amsterdam’s high-stakes experiment to create fair welfare AI&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Amsterdam thought it was on the right track. City officials in the welfare department believed they could build technology that would prevent fraud while protecting citizens’ rights. They followed these emerging best practices and invested a vast amount of time and money in a project that eventually processed live welfare applications. But in their pilot, they found that the system they’d developed was still not fair and effective. Why?&lt;/p&gt;&lt;p&gt;Lighthouse Reports, MIT Technology Review, and the Dutch newspaper Trouw have gained unprecedented access to the system to try to find out. Read about what we discovered.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;&lt;em&gt;—Eileen Guo, Gabriel Geiger &amp;amp; Justin-Casimir Braun&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ Happy 70th birthday to Bill Gates, who is not revered enough for his chair-jumping skills.&lt;br /&gt;+ Bring back Guitar Hero—the iconic game that convinced us all we were capable of knocking out Heart’s &lt;em&gt;Barracuda &lt;/em&gt;(note: the majority of us were not.)&lt;br /&gt;+ Even the swankiest parts of London aren’t immune to rumours of ghostly hauntings.&lt;br /&gt;+ Justice for medieval frogs and their unfair reputation! 🐸&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/28/1126802/the-download-microsofts-stance-on-erotic-ai-and-an-ai-hype-mystery/</guid><pubDate>Tue, 28 Oct 2025 13:10:00 +0000</pubDate></item><item><title>[NEW] OpenAI restructures, enters ‘next chapter’ of Microsoft partnership (AI News)</title><link>https://www.artificialintelligence-news.com/news/openai-restructures-next-chapter-microsoft-partnership/</link><description>&lt;p&gt;OpenAI has completed a major reorganisation and, in the same breath, signed a new definitive partnership agreement with Microsoft.&lt;/p&gt;&lt;p&gt;Starting with OpenAI’s reorganisation, the aim is to solidify the nonprofit’s control over the for-profit business and establish the newly named OpenAI Foundation as a global philanthropic powerhouse, holding equity in the commercial arm valued at approximately $130 billion.&lt;/p&gt;&lt;p&gt;This reorganisation, which OpenAI says “maintains the strongest representation of mission-focused governance in the industry today,” effectively turns the company’s commercial success into a direct funding pipeline for its original mission.&lt;/p&gt;&lt;p&gt;The for-profit entity is now a public benefit corporation called OpenAI Group PBC, legally bound to that mission. As this PBC grows, so does the Foundation’s $130 billion stake, which will be used to fund an initial $25 billion commitment to global health and AI resilience.&lt;/p&gt;&lt;p&gt;This restructure was finalised after nearly a year of “constructive dialogue” with the offices of the Attorneys General of California and Delaware. OpenAI acknowledged it “made several changes as a result of those discussions” and stated its belief that the company, and by extension the public it serves, “are better for them.”&lt;/p&gt;&lt;p&gt;The other side of this new structure is the redefined partnership with Microsoft. The tech giant’s investment is now valued at $135 billion, giving it a 27 percent stake in the OpenAI Group PBC. This represents a slight dilution from its previous 32.5 percent stake, reflecting new funding rounds. The agreement preserves Microsoft’s core position as the exclusive Azure API provider for OpenAI’s frontier models, but only until artificial general intelligence (AGI) is achieved.&lt;/p&gt;&lt;p&gt;The new terms introduce a new check on that path. Any declaration of AGI by OpenAI must now be verified by an independent expert panel. This external check is a major update to the governance of the partnership. Microsoft’s intellectual property rights are also extended through 2032 and now include models developed after AGI is declared, with appropriate safety guardrails.&lt;/p&gt;&lt;p&gt;Microsoft can also now independently pursue AGI, either on its own or with other partners. This gives Microsoft a new path forward, separate from its reliance on OpenAI’s research. If Microsoft uses OpenAI’s IP to develop AGI before it is officially declared, those models will be subject to compute thresholds significantly larger than systems in use today.&lt;/p&gt;&lt;p&gt;But the new freedoms cut both ways. OpenAI has also secured new flexibility. It has committed to purchasing an incremental $250 billion of Azure services, but Microsoft no longer holds a right of first refusal as its compute provider. This gives OpenAI new leverage in its infrastructure negotiations.&lt;/p&gt;&lt;p&gt;The company can also now release open weight models that meet certain criteria and serve US government national security customers on any cloud, a notable new ability. It also gains the power to jointly develop some non-API products with third parties, although API products developed with others must remain on Azure. Microsoft’s IP rights also specifically exclude any of OpenAI’s future consumer hardware.&lt;/p&gt;&lt;p&gt;The existing revenue share agreement remains in place until the expert panel verifies AGI, though payments will be stretched over a longer period. Both companies framed the new chapter as a way to continue innovating. OpenAI concluded that this new structure provides both the ability to push the AI frontier and an updated model to “ensure that progress serves everyone.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;OpenAI connects ChatGPT to enterprise data to surface knowledge&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-109805" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-1.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;OpenAI has completed a major reorganisation and, in the same breath, signed a new definitive partnership agreement with Microsoft.&lt;/p&gt;&lt;p&gt;Starting with OpenAI’s reorganisation, the aim is to solidify the nonprofit’s control over the for-profit business and establish the newly named OpenAI Foundation as a global philanthropic powerhouse, holding equity in the commercial arm valued at approximately $130 billion.&lt;/p&gt;&lt;p&gt;This reorganisation, which OpenAI says “maintains the strongest representation of mission-focused governance in the industry today,” effectively turns the company’s commercial success into a direct funding pipeline for its original mission.&lt;/p&gt;&lt;p&gt;The for-profit entity is now a public benefit corporation called OpenAI Group PBC, legally bound to that mission. As this PBC grows, so does the Foundation’s $130 billion stake, which will be used to fund an initial $25 billion commitment to global health and AI resilience.&lt;/p&gt;&lt;p&gt;This restructure was finalised after nearly a year of “constructive dialogue” with the offices of the Attorneys General of California and Delaware. OpenAI acknowledged it “made several changes as a result of those discussions” and stated its belief that the company, and by extension the public it serves, “are better for them.”&lt;/p&gt;&lt;p&gt;The other side of this new structure is the redefined partnership with Microsoft. The tech giant’s investment is now valued at $135 billion, giving it a 27 percent stake in the OpenAI Group PBC. This represents a slight dilution from its previous 32.5 percent stake, reflecting new funding rounds. The agreement preserves Microsoft’s core position as the exclusive Azure API provider for OpenAI’s frontier models, but only until artificial general intelligence (AGI) is achieved.&lt;/p&gt;&lt;p&gt;The new terms introduce a new check on that path. Any declaration of AGI by OpenAI must now be verified by an independent expert panel. This external check is a major update to the governance of the partnership. Microsoft’s intellectual property rights are also extended through 2032 and now include models developed after AGI is declared, with appropriate safety guardrails.&lt;/p&gt;&lt;p&gt;Microsoft can also now independently pursue AGI, either on its own or with other partners. This gives Microsoft a new path forward, separate from its reliance on OpenAI’s research. If Microsoft uses OpenAI’s IP to develop AGI before it is officially declared, those models will be subject to compute thresholds significantly larger than systems in use today.&lt;/p&gt;&lt;p&gt;But the new freedoms cut both ways. OpenAI has also secured new flexibility. It has committed to purchasing an incremental $250 billion of Azure services, but Microsoft no longer holds a right of first refusal as its compute provider. This gives OpenAI new leverage in its infrastructure negotiations.&lt;/p&gt;&lt;p&gt;The company can also now release open weight models that meet certain criteria and serve US government national security customers on any cloud, a notable new ability. It also gains the power to jointly develop some non-API products with third parties, although API products developed with others must remain on Azure. Microsoft’s IP rights also specifically exclude any of OpenAI’s future consumer hardware.&lt;/p&gt;&lt;p&gt;The existing revenue share agreement remains in place until the expert panel verifies AGI, though payments will be stretched over a longer period. Both companies framed the new chapter as a way to continue innovating. OpenAI concluded that this new structure provides both the ability to push the AI frontier and an updated model to “ensure that progress serves everyone.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;OpenAI connects ChatGPT to enterprise data to surface knowledge&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-109805" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-1.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/openai-restructures-next-chapter-microsoft-partnership/</guid><pubDate>Tue, 28 Oct 2025 13:43:46 +0000</pubDate></item><item><title>[NEW] TechCrunch Disrupt 2025: Day 2 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/28/techcrunch-disrupt-2025-day-2/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2018/10/27055664959_5fbe947d9b_o.jpg?resize=1200,799" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;It’s time for day two of &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, which means San Francisco’s Moscone West will be jam-packed with another marathon of speakers, workshops, networking opportunities, and after-parties for attendees. Keep in mind that you can still register for tickets to join the excitement, and since we’re already a day in, you can get a ticket for 50% off the standard walk-up price.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Refresh yourself on our speaker lineup right here, or dive deeper into each of our stages, events, networking opportunities, and more by following the anchor links below.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Most importantly, have fun out there, and if you want to be a part of the conversation around Disrupt, post your experiences, photos, and recommendations to any and all social platforms and use #TechCrunchDisrupt2025. We’ll be posting some on-the-ground coverage of our own on LinkedIn, Instagram, X, YouTube, Facebook, and TikTok.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Get to know all the major activations of Disrupt:&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Expo Hall&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Women of Disrupt Breakfast&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Networking&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Disrupt Stage&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI Stage&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Builders Stage&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Breakout Stage&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Roundtables&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;StrictlyVC&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Pitch Showcase Stage&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Disrupt 2025 Side Events&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-expo-hall"&gt;Expo Hall&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Our 8 a.m. to 5 p.m. Expo Hall remains a hub for startups looking to see and be seen, with more than 300+ participating in what could be their next big break — or your next big investment opportunity. Get a full rundown of our showcasing startups here.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-women-of-disrupt-breakfast-reception"&gt;Women of Disrupt Breakfast Reception&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;We’re continuing the tradition of a morning opportunity for anyone identifying as a female to meet, learn from, and network with colleagues across the wide range of tech startups at Disrupt. The breakfast runs from 8 a.m. to 10 a.m. at the Deal Flow Cafe and operates on a first-come, first-served basis.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-networking"&gt;Networking&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;If you’re not eligible for the breakfast, plenty of other networking opportunities are available through curated meetings on Braindate from 9 a.m. to 5 p.m. Explore or create 1:1 or small-group sessions to dive deep into a wide range of topics. The Networking Lounge serves as the meeting point for all these sessions and is always buzzing.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;If you’re an investor or a founder, then make your way to the Deal Flow Cafe. This exclusive area is designed for investors and founders to talk deals over coffee.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Or you can randomly bump into the right connection while heading to a session, or bump into eager startups in the Expo Hall, the heart of Disrupt, just about anywhere else in the venue.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-sessions"&gt;Sessions&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Industry-focused stages, interactive roundtables, Q&amp;amp;A breakout sessions — &lt;strong&gt;these sessions&lt;/strong&gt; are meant to spark inspiration and insights.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-disrupt-stage"&gt;Disrupt Stage&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;No Filters: Vinod Khosla on the Future of Tech&lt;/strong&gt;: Vinod Khosla (Founder, Khosla Ventures)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;The Startup Battlefield — Session 3&lt;/strong&gt;: Judges include Jon Chu (Partner, Khosla Ventures), Madison Faulkner (Partner, NEA), Ilya Kirnos (Founding Partner and CTO, SignalFire), Miloni Madan Presler (Partner, Institutional Venture Partners), Rinki Sethi (Founding Partner, Lockstep)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What’s Next for Netflix and for Streaming Itself&lt;/strong&gt;: Elizabeth Stone (CTO, Netflix)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;From Mirror to What’s Next: Brynn Putnam Returns to Disrupt&lt;/strong&gt;: Brynn Putnam (Founder, MIRROR, and CEO Board)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Slate Auto’s Electric Truck: See It Here First&lt;/strong&gt;: Chris Barman (CEO, Slate Auto)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;The Startup Battlefield — Session 4&lt;/strong&gt;: Leslie Feinzaig (Founder and GP, Graham &amp;amp; Walker VC), Ross Fubini (Founder and Managing Partner, XYZ Venture Capital), Ben Quazzo (Partner, Accel), Doug Pepper (General Partner, ICONIQ), Santi Subotovsky (General Partner, Emergence Capital)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Storming the Gates: Scaling Consumer AI&lt;/strong&gt;: Phoebe Gates (Co-Founder, Phia), Sophia Kianni (Co-Founder, Phia)&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-ai-stage"&gt;AI Stage&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Betting on the Next Wave: What VCs Want in AI Startups&lt;/strong&gt;: Steve Jang (founder and Managing Partner, Kindred Ventures), Aileen Lee (Founder and Managing Partner, Cowboy Ventures), Jon McNeill (CEO and Co-Founder, DVx Ventures)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Creative Machines and Where AI Meets Imagination&lt;/strong&gt;: Prateek Dixit (Co-Founder, Pocket Entertainment), Soyoung Lee (Co-Founder and Head of GTM, TwelveLabs), Nikola Todorovic (Co-Founder, Wonder Dynamics, an Autodesk company)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;AI Meets the Future of Work with Mercor’s Brendan Foody&lt;/strong&gt;: Brendan Foody (CEO, Mercer)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;The Post-Training Revolution: How Reinforcement Learning Is Upending the AI Infra Stack&lt;/strong&gt;: Eric Anderson (Partner, Scale Venture Partners), Kyle Corbitt (Head of OpenPipe Team, CoreWeave)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why the Next Frontier Is Search&lt;/strong&gt;: Edo Liberty (Founder and Chief Scientist, Pinecone)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;From Web Pages to Autonomous Agents: A Conversation on Linking Today’s Web to Tomorrow’s Data Layer:&lt;/strong&gt; Or Lenchner (CEO, Bright Data)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Intelligence in Motion and the Future of Physical AI&lt;/strong&gt;: Jeff Cardenas (Co-Founder and CEO, Apptronik), Raquel Urtasun (Founder and CEO, Waabi)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Can You Vibe Code Enterprise Software?&lt;/strong&gt;: Arun Gupta (VP of Developer Experience, JetBrains), Mark Pollack (OSS Contributor, Spring OSS Contributor)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Synthetic Voices and Real Impact&lt;/strong&gt;: Mati Staniszewski (Co-Founder, ElevenLabs)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;AI That Scales: Lessons From the Frontlines&lt;/strong&gt;: Sanjay Dhawan (CEO, SymphonyAI), Tamara Pattison (SVP, Chief Digital Officer, The Save Mart Companies)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Building Intelligence for Modern Defense&lt;/strong&gt;: Ethan Thornton (CEO and Founder, Mach Industries)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Driving Intelligence&lt;/strong&gt;: Alex Kendall (CEO, Wayve)&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-builders-stage-nbsp"&gt;Builders Stage&amp;nbsp;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;How to Nail Product Market Fit&lt;/strong&gt;: Rajat Bhageria (Founder and CEO, Chef Robotics), Ann Bordetsky (Partner, NEA), Murali Joshi (Partner, ICONIQ)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Designing Products for the AI Age&lt;/strong&gt;:&lt;strong&gt; &lt;/strong&gt;Andrew Reed (General Partner, Sequoia Capital), Yuhki Yamashita (Chief Product Officer, Figma), Zach Lloyd (CEO and Founder, Warp)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;How to Pitch When You’re at the Inception Stage&lt;/strong&gt;: Wesley Chan (Co-Founder and Managing Partner, FPV Ventures), Charles Hudson (Managing Partner, Precursor Ventures)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Do Startups Still Need Silicon Valley?&lt;/strong&gt;: Anh-Tho Chuong (CEO and Co-Founder, Lago), David Hall (Managing Partner, Revolution/Rise of the Rest), Tawni Nazario-Cranz (Operating Partner, SignalFire)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Building What’s Next with the Minds Behind Twitter and Meta&lt;/strong&gt;: Adam Bain (Co-Founder and Managing Partner, 01 Advisors), Dick Costolo (Co-Founder and Managing Partner, 01 Advisors), David Fischer (General Partner, 01 Advisors)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Where VCs Are Placing Their Bets in 2026&lt;/strong&gt;: Nina Achadjian (Partner, Index Ventures), Jerry Chen (General Partner, Greylock), Peter Deng (General Partner, Felicis)&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-breakout-stage"&gt;Breakout Stage&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Agentic AI for Startups: Automate, Adapt, and Accelerate Growth&lt;/strong&gt;: Anjali Mann (Technical Program Manager, Microsoft), Anmol Rastogi (Head of Product Management, AI and ML, Amazon Business, Amazon)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Leading for Impact: Engineering at the Speed of AI&lt;/strong&gt;: Andrew Berman (CEO, Runlayer), Dima Dzhulgakov (Co-Founder, Fireworks AI), Suraj Patel (VP Ventures and Corporate Development, MongoDB), Eno Reyes (CTO, Factory)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Rewriting Healthcare Workflows with AI&lt;/strong&gt;: Zubair Ahsan (Co-Founder and CEO, Max AI), Varun Krishnamurthy (Co-Founder and CEO, Assured Health), Kanyi Maqubela (Managing Partner, Kindred Ventures)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Inside the Family Office Playbook: How the Wealthiest Invest in Startups and Venture Funds&lt;/strong&gt;: Mariane Bekker (Managing Partner, Founders Bay), Brett Horton (Chief Investment Officer, Paris-Roubaix Group), Daniel Idzkowski (CIO, I.D.I.T. Family Office)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;CVC: What’s Different? What’s Their Superpower?&lt;/strong&gt;: Nicolas Sauvage (President, TDK Ventures)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Startups, Stories, and the Fight for Attention&lt;/strong&gt;: Jenna Birch (Founder, SISU), Allie Cefalo (Partner, Marketing, Kleiner Perkins), Chantelle Darby (Founder, Darby PR)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Embracing AI for a Better Digital Future&lt;/strong&gt;: Meghana Dhar (Technology Advisor and Investor), Matt Madrigal (Chief Technology Officer, Pinterest)&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-roundtables"&gt;Roundtables&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Each of these &lt;strong&gt;30-minute sessions&lt;/strong&gt; is for small groups to work through real-world problems.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;The Future of Banking and Fintech: The AI Wave&lt;/strong&gt;: Nnamdi Okike (Co-Founder and Managing Partner, 645 Ventures)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Scaling Search and AI for Millions: Lessons from Reddit Search&lt;/strong&gt;: Rachel Miller (Product Manager, Reddit)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Tim Cook Has More Followers Than Apple — Why Founders Need to Be on Camera&lt;/strong&gt;: Hanieh Sigari (CEO, EllieMD), Uptin Saiidi (Founder and Creator, UP10 Media)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;From Tokens to Turbines: The New Economics of AI&lt;/strong&gt;: Caleb Appleton (Partner, Bison Ventures)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Prototyping, Tuning &amp;amp; Scaling GenAI Applications with Open Models&lt;/strong&gt;: Aishwarya Srinivasan (Head of AI Developer Relations, Fireworks AI)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;The Invisible AI Revolution&lt;/strong&gt;: Brad Cordova (Founder and CPTO, Super.AI), Benjamin Kwon (CEO, Super.AI)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;How Smart Brands Are Winning with Creator-Led Videos&lt;/strong&gt;: Peter Sleiman (Creative Director, UP10 Media), Uptin Saiidi (Founder and Creator, UP10 Media)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;How to Train Your Model: Taming AI Agents Without Breaking Them [Encore]&lt;/strong&gt;: Kyla Guru (Head of Model Cyber Safety, Anthropic)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;The Winning Formula: Turning Your Business into a Trusted, Scalable Community to Drive Growth&lt;/strong&gt;: Tasneem Amina (Co-Founder and President, Kindred), Justine Palefsky (Co-Founder and CEO, Kindred)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;From Inception to Enterprise: Selling AI Agents that Scale&lt;/strong&gt;: Allison Baum Gates (General Partner, SemperVirens Venture Capital)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Powering the Future Home: Energy Independence Starts Here&lt;/strong&gt;: Jenny Zhang (President of North America Residential, Energy Business, EcoFlow)&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-strictlyvc"&gt;StrictlyVC&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Making its second appearance at Disrupt, this LP session is only for &lt;strong&gt;Investor Pass holders&lt;/strong&gt;.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Global High-Tech at a Crossroads: Trends, Emerging Technologies, and the Role of Deep-Tech&lt;/strong&gt;: Dror Bin (CEO, Israel Innovation Authority)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;The LP Lens: Liquidity, Selection, and the Future of Venture&lt;/strong&gt;: Lara Banks (Managing Director and Head of Private Equity, Makena Capital), Kelli Fontaine (Partner, Cendana Capital), Adam Grosher (Director, The J. Paul Getty Trust), Matt Hodan (Partner, Lexington Partners), Michael Kim (Founder and Partner, Cendana Capital)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;GP Perspectives on LP Relationships&lt;/strong&gt;: Kevin Hartz (General Partner, A*)&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-pitch-showcase-stage"&gt;Pitch Showcase Stage&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Witness live onstage pitches from some of the exhibiting startups from all over the world in the Expo Hall.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;9:30 a.m. – 11:30 a.m.:&lt;/strong&gt; Startup Battlefield 200 Consumer Pitches&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;11:30 a.m. – 12:00 p.m.:&lt;/strong&gt; Pavilion Pitch Session — Catalonia&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;1:00 p.m. – 1:30 p.m.:&lt;/strong&gt; Pavilion Pitch Session — Poland&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;1:30 p.m. – 3:30 p.m.: &lt;/strong&gt;Startup Battlefield 200 Enterprise Pitches&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;3:30 p.m. – 4:20 p.m.:&lt;/strong&gt; Pavilion Pitch Session — SilkRoad&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-disrupt-2025-side-events"&gt;Disrupt 2025 Side Events&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Company-hosted &lt;strong&gt;Side Events&lt;/strong&gt; are happening throughout San Francisco this week, extending the Disrupt energy well beyond Moscone West. Here’s what’s happening tonight — panels, parties, and meetups designed to connect founders, investors, and innovators across every corner of tech. Make sure to RSVP your spot to any of these.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-you-can-still-join-disrupt"&gt;You can still join Disrupt&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Just two days left to join thousands of founders, investors, operators, and visionaries at Moscone West in San Francisco. &lt;strong&gt;Snag your pass at 50% off&lt;/strong&gt; and be part of the tech event of the year.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2018/10/27055664959_5fbe947d9b_o.jpg?resize=1200,799" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;It’s time for day two of &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, which means San Francisco’s Moscone West will be jam-packed with another marathon of speakers, workshops, networking opportunities, and after-parties for attendees. Keep in mind that you can still register for tickets to join the excitement, and since we’re already a day in, you can get a ticket for 50% off the standard walk-up price.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Refresh yourself on our speaker lineup right here, or dive deeper into each of our stages, events, networking opportunities, and more by following the anchor links below.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Most importantly, have fun out there, and if you want to be a part of the conversation around Disrupt, post your experiences, photos, and recommendations to any and all social platforms and use #TechCrunchDisrupt2025. We’ll be posting some on-the-ground coverage of our own on LinkedIn, Instagram, X, YouTube, Facebook, and TikTok.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Get to know all the major activations of Disrupt:&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Expo Hall&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Women of Disrupt Breakfast&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Networking&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Disrupt Stage&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI Stage&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Builders Stage&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Breakout Stage&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Roundtables&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;StrictlyVC&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Pitch Showcase Stage&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Disrupt 2025 Side Events&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-expo-hall"&gt;Expo Hall&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Our 8 a.m. to 5 p.m. Expo Hall remains a hub for startups looking to see and be seen, with more than 300+ participating in what could be their next big break — or your next big investment opportunity. Get a full rundown of our showcasing startups here.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-women-of-disrupt-breakfast-reception"&gt;Women of Disrupt Breakfast Reception&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;We’re continuing the tradition of a morning opportunity for anyone identifying as a female to meet, learn from, and network with colleagues across the wide range of tech startups at Disrupt. The breakfast runs from 8 a.m. to 10 a.m. at the Deal Flow Cafe and operates on a first-come, first-served basis.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-networking"&gt;Networking&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;If you’re not eligible for the breakfast, plenty of other networking opportunities are available through curated meetings on Braindate from 9 a.m. to 5 p.m. Explore or create 1:1 or small-group sessions to dive deep into a wide range of topics. The Networking Lounge serves as the meeting point for all these sessions and is always buzzing.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;If you’re an investor or a founder, then make your way to the Deal Flow Cafe. This exclusive area is designed for investors and founders to talk deals over coffee.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Or you can randomly bump into the right connection while heading to a session, or bump into eager startups in the Expo Hall, the heart of Disrupt, just about anywhere else in the venue.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-sessions"&gt;Sessions&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Industry-focused stages, interactive roundtables, Q&amp;amp;A breakout sessions — &lt;strong&gt;these sessions&lt;/strong&gt; are meant to spark inspiration and insights.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-disrupt-stage"&gt;Disrupt Stage&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;No Filters: Vinod Khosla on the Future of Tech&lt;/strong&gt;: Vinod Khosla (Founder, Khosla Ventures)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;The Startup Battlefield — Session 3&lt;/strong&gt;: Judges include Jon Chu (Partner, Khosla Ventures), Madison Faulkner (Partner, NEA), Ilya Kirnos (Founding Partner and CTO, SignalFire), Miloni Madan Presler (Partner, Institutional Venture Partners), Rinki Sethi (Founding Partner, Lockstep)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What’s Next for Netflix and for Streaming Itself&lt;/strong&gt;: Elizabeth Stone (CTO, Netflix)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;From Mirror to What’s Next: Brynn Putnam Returns to Disrupt&lt;/strong&gt;: Brynn Putnam (Founder, MIRROR, and CEO Board)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Slate Auto’s Electric Truck: See It Here First&lt;/strong&gt;: Chris Barman (CEO, Slate Auto)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;The Startup Battlefield — Session 4&lt;/strong&gt;: Leslie Feinzaig (Founder and GP, Graham &amp;amp; Walker VC), Ross Fubini (Founder and Managing Partner, XYZ Venture Capital), Ben Quazzo (Partner, Accel), Doug Pepper (General Partner, ICONIQ), Santi Subotovsky (General Partner, Emergence Capital)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Storming the Gates: Scaling Consumer AI&lt;/strong&gt;: Phoebe Gates (Co-Founder, Phia), Sophia Kianni (Co-Founder, Phia)&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-ai-stage"&gt;AI Stage&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Betting on the Next Wave: What VCs Want in AI Startups&lt;/strong&gt;: Steve Jang (founder and Managing Partner, Kindred Ventures), Aileen Lee (Founder and Managing Partner, Cowboy Ventures), Jon McNeill (CEO and Co-Founder, DVx Ventures)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Creative Machines and Where AI Meets Imagination&lt;/strong&gt;: Prateek Dixit (Co-Founder, Pocket Entertainment), Soyoung Lee (Co-Founder and Head of GTM, TwelveLabs), Nikola Todorovic (Co-Founder, Wonder Dynamics, an Autodesk company)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;AI Meets the Future of Work with Mercor’s Brendan Foody&lt;/strong&gt;: Brendan Foody (CEO, Mercer)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;The Post-Training Revolution: How Reinforcement Learning Is Upending the AI Infra Stack&lt;/strong&gt;: Eric Anderson (Partner, Scale Venture Partners), Kyle Corbitt (Head of OpenPipe Team, CoreWeave)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why the Next Frontier Is Search&lt;/strong&gt;: Edo Liberty (Founder and Chief Scientist, Pinecone)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;From Web Pages to Autonomous Agents: A Conversation on Linking Today’s Web to Tomorrow’s Data Layer:&lt;/strong&gt; Or Lenchner (CEO, Bright Data)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Intelligence in Motion and the Future of Physical AI&lt;/strong&gt;: Jeff Cardenas (Co-Founder and CEO, Apptronik), Raquel Urtasun (Founder and CEO, Waabi)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Can You Vibe Code Enterprise Software?&lt;/strong&gt;: Arun Gupta (VP of Developer Experience, JetBrains), Mark Pollack (OSS Contributor, Spring OSS Contributor)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Synthetic Voices and Real Impact&lt;/strong&gt;: Mati Staniszewski (Co-Founder, ElevenLabs)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;AI That Scales: Lessons From the Frontlines&lt;/strong&gt;: Sanjay Dhawan (CEO, SymphonyAI), Tamara Pattison (SVP, Chief Digital Officer, The Save Mart Companies)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Building Intelligence for Modern Defense&lt;/strong&gt;: Ethan Thornton (CEO and Founder, Mach Industries)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Driving Intelligence&lt;/strong&gt;: Alex Kendall (CEO, Wayve)&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-builders-stage-nbsp"&gt;Builders Stage&amp;nbsp;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;How to Nail Product Market Fit&lt;/strong&gt;: Rajat Bhageria (Founder and CEO, Chef Robotics), Ann Bordetsky (Partner, NEA), Murali Joshi (Partner, ICONIQ)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Designing Products for the AI Age&lt;/strong&gt;:&lt;strong&gt; &lt;/strong&gt;Andrew Reed (General Partner, Sequoia Capital), Yuhki Yamashita (Chief Product Officer, Figma), Zach Lloyd (CEO and Founder, Warp)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;How to Pitch When You’re at the Inception Stage&lt;/strong&gt;: Wesley Chan (Co-Founder and Managing Partner, FPV Ventures), Charles Hudson (Managing Partner, Precursor Ventures)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Do Startups Still Need Silicon Valley?&lt;/strong&gt;: Anh-Tho Chuong (CEO and Co-Founder, Lago), David Hall (Managing Partner, Revolution/Rise of the Rest), Tawni Nazario-Cranz (Operating Partner, SignalFire)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Building What’s Next with the Minds Behind Twitter and Meta&lt;/strong&gt;: Adam Bain (Co-Founder and Managing Partner, 01 Advisors), Dick Costolo (Co-Founder and Managing Partner, 01 Advisors), David Fischer (General Partner, 01 Advisors)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Where VCs Are Placing Their Bets in 2026&lt;/strong&gt;: Nina Achadjian (Partner, Index Ventures), Jerry Chen (General Partner, Greylock), Peter Deng (General Partner, Felicis)&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-breakout-stage"&gt;Breakout Stage&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Agentic AI for Startups: Automate, Adapt, and Accelerate Growth&lt;/strong&gt;: Anjali Mann (Technical Program Manager, Microsoft), Anmol Rastogi (Head of Product Management, AI and ML, Amazon Business, Amazon)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Leading for Impact: Engineering at the Speed of AI&lt;/strong&gt;: Andrew Berman (CEO, Runlayer), Dima Dzhulgakov (Co-Founder, Fireworks AI), Suraj Patel (VP Ventures and Corporate Development, MongoDB), Eno Reyes (CTO, Factory)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Rewriting Healthcare Workflows with AI&lt;/strong&gt;: Zubair Ahsan (Co-Founder and CEO, Max AI), Varun Krishnamurthy (Co-Founder and CEO, Assured Health), Kanyi Maqubela (Managing Partner, Kindred Ventures)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Inside the Family Office Playbook: How the Wealthiest Invest in Startups and Venture Funds&lt;/strong&gt;: Mariane Bekker (Managing Partner, Founders Bay), Brett Horton (Chief Investment Officer, Paris-Roubaix Group), Daniel Idzkowski (CIO, I.D.I.T. Family Office)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;CVC: What’s Different? What’s Their Superpower?&lt;/strong&gt;: Nicolas Sauvage (President, TDK Ventures)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Startups, Stories, and the Fight for Attention&lt;/strong&gt;: Jenna Birch (Founder, SISU), Allie Cefalo (Partner, Marketing, Kleiner Perkins), Chantelle Darby (Founder, Darby PR)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Embracing AI for a Better Digital Future&lt;/strong&gt;: Meghana Dhar (Technology Advisor and Investor), Matt Madrigal (Chief Technology Officer, Pinterest)&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-roundtables"&gt;Roundtables&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Each of these &lt;strong&gt;30-minute sessions&lt;/strong&gt; is for small groups to work through real-world problems.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;The Future of Banking and Fintech: The AI Wave&lt;/strong&gt;: Nnamdi Okike (Co-Founder and Managing Partner, 645 Ventures)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Scaling Search and AI for Millions: Lessons from Reddit Search&lt;/strong&gt;: Rachel Miller (Product Manager, Reddit)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Tim Cook Has More Followers Than Apple — Why Founders Need to Be on Camera&lt;/strong&gt;: Hanieh Sigari (CEO, EllieMD), Uptin Saiidi (Founder and Creator, UP10 Media)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;From Tokens to Turbines: The New Economics of AI&lt;/strong&gt;: Caleb Appleton (Partner, Bison Ventures)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Prototyping, Tuning &amp;amp; Scaling GenAI Applications with Open Models&lt;/strong&gt;: Aishwarya Srinivasan (Head of AI Developer Relations, Fireworks AI)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;The Invisible AI Revolution&lt;/strong&gt;: Brad Cordova (Founder and CPTO, Super.AI), Benjamin Kwon (CEO, Super.AI)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;How Smart Brands Are Winning with Creator-Led Videos&lt;/strong&gt;: Peter Sleiman (Creative Director, UP10 Media), Uptin Saiidi (Founder and Creator, UP10 Media)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;How to Train Your Model: Taming AI Agents Without Breaking Them [Encore]&lt;/strong&gt;: Kyla Guru (Head of Model Cyber Safety, Anthropic)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;The Winning Formula: Turning Your Business into a Trusted, Scalable Community to Drive Growth&lt;/strong&gt;: Tasneem Amina (Co-Founder and President, Kindred), Justine Palefsky (Co-Founder and CEO, Kindred)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;From Inception to Enterprise: Selling AI Agents that Scale&lt;/strong&gt;: Allison Baum Gates (General Partner, SemperVirens Venture Capital)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Powering the Future Home: Energy Independence Starts Here&lt;/strong&gt;: Jenny Zhang (President of North America Residential, Energy Business, EcoFlow)&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-strictlyvc"&gt;StrictlyVC&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Making its second appearance at Disrupt, this LP session is only for &lt;strong&gt;Investor Pass holders&lt;/strong&gt;.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Global High-Tech at a Crossroads: Trends, Emerging Technologies, and the Role of Deep-Tech&lt;/strong&gt;: Dror Bin (CEO, Israel Innovation Authority)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;The LP Lens: Liquidity, Selection, and the Future of Venture&lt;/strong&gt;: Lara Banks (Managing Director and Head of Private Equity, Makena Capital), Kelli Fontaine (Partner, Cendana Capital), Adam Grosher (Director, The J. Paul Getty Trust), Matt Hodan (Partner, Lexington Partners), Michael Kim (Founder and Partner, Cendana Capital)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;GP Perspectives on LP Relationships&lt;/strong&gt;: Kevin Hartz (General Partner, A*)&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-pitch-showcase-stage"&gt;Pitch Showcase Stage&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Witness live onstage pitches from some of the exhibiting startups from all over the world in the Expo Hall.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;9:30 a.m. – 11:30 a.m.:&lt;/strong&gt; Startup Battlefield 200 Consumer Pitches&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;11:30 a.m. – 12:00 p.m.:&lt;/strong&gt; Pavilion Pitch Session — Catalonia&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;1:00 p.m. – 1:30 p.m.:&lt;/strong&gt; Pavilion Pitch Session — Poland&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;1:30 p.m. – 3:30 p.m.: &lt;/strong&gt;Startup Battlefield 200 Enterprise Pitches&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;3:30 p.m. – 4:20 p.m.:&lt;/strong&gt; Pavilion Pitch Session — SilkRoad&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-disrupt-2025-side-events"&gt;Disrupt 2025 Side Events&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Company-hosted &lt;strong&gt;Side Events&lt;/strong&gt; are happening throughout San Francisco this week, extending the Disrupt energy well beyond Moscone West. Here’s what’s happening tonight — panels, parties, and meetups designed to connect founders, investors, and innovators across every corner of tech. Make sure to RSVP your spot to any of these.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-you-can-still-join-disrupt"&gt;You can still join Disrupt&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Just two days left to join thousands of founders, investors, operators, and visionaries at Moscone West in San Francisco. &lt;strong&gt;Snag your pass at 50% off&lt;/strong&gt; and be part of the tech event of the year.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/28/techcrunch-disrupt-2025-day-2/</guid><pubDate>Tue, 28 Oct 2025 14:00:00 +0000</pubDate></item><item><title>[NEW] OpenAI completes its for-profit recapitalization (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/28/openai-completes-its-for-profit-recapitalization/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2197181367.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI on Tuesday said it had completed its recapitalization, splitting the AI lab into a for-profit corporation nested inside a non-profit foundation. It’s the end result of a complex legal process that had been strenuously resisted by its estranged co-founder, Elon Musk.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Under the new structure, the non-profit OpenAI Foundation will have legal control over a public benefit corporation called OpenAI Group, which is free to raise funding or acquire companies without legal restraint. The Foundation will hold a significant stake in OpenAI Group and will appoint its board of directors.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We believe that the world’s most powerful technology must be developed in a way that reflects the world’s collective interests,” OpenAI chairman Bret Taylor wrote in a blog post. “The close of our recapitalization gives us the ability to keep pushing the frontier of AI, and an updated corporate structure to ensure progress serves everyone.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Under the new structure, the OpenAI Foundation will own 26% of the for-profit, with a warrant for additional shares to be granted if the company continues to grow. Microsoft, an early investor in OpenAI, will hold a roughly 27% stake, valued at about $135 billion, with the remaining 47% held by investors and employees.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to a separate blog post by Microsoft, the deal will also extend Microsoft’s IP rights to OpenAI models through 2032. If OpenAI ever declares that it has achieved its long-held goal of artificial general intelligence, the deal will also require it to submit to an independent expert panel for verification.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Prior to this recapitalization, OpenAI was operating as a non-profit under strict equity restrictions — a position that became increasingly untenable as the company’s fundraising became more ambitious. In April, SoftBank announced an unprecedented $30 billion investment into OpenAI, contingent on the company’s successful conversion into a for-profit. On Saturday, The Information reported that the final installment of the funding had been sent, signaling a possible breakthrough in the restructuring.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There have been a number of legal efforts to block or otherwise influence the restructuring, most notably from Elon Musk, who at one point offered to acquire the company for $97.4 billion.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The attorneys general from California and Delaware, who had raised concerns about the conversion, will allow the process to proceed, subject to further conditions published by both offices. Notably, the California agreement requires OpenAI to “continue to undertake measures to mitigate risks to teens and others in&lt;br /&gt;connection with the development and deployment of AI and of AGI.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the announcement post, Taylor cited discussions with the state offices as a positive influence on the process. “We made several changes as a result of those discussions and we believe OpenAI—and as a result, the public we serve—are better for them,” Taylor wrote. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the wake of the news, CEO Sam Altman announced an open livestream with chief scientist Jakub Pachocki to answer questions from the public. The event will begin at 10:30 a.m. Pacific Time.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2197181367.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI on Tuesday said it had completed its recapitalization, splitting the AI lab into a for-profit corporation nested inside a non-profit foundation. It’s the end result of a complex legal process that had been strenuously resisted by its estranged co-founder, Elon Musk.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Under the new structure, the non-profit OpenAI Foundation will have legal control over a public benefit corporation called OpenAI Group, which is free to raise funding or acquire companies without legal restraint. The Foundation will hold a significant stake in OpenAI Group and will appoint its board of directors.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We believe that the world’s most powerful technology must be developed in a way that reflects the world’s collective interests,” OpenAI chairman Bret Taylor wrote in a blog post. “The close of our recapitalization gives us the ability to keep pushing the frontier of AI, and an updated corporate structure to ensure progress serves everyone.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Under the new structure, the OpenAI Foundation will own 26% of the for-profit, with a warrant for additional shares to be granted if the company continues to grow. Microsoft, an early investor in OpenAI, will hold a roughly 27% stake, valued at about $135 billion, with the remaining 47% held by investors and employees.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to a separate blog post by Microsoft, the deal will also extend Microsoft’s IP rights to OpenAI models through 2032. If OpenAI ever declares that it has achieved its long-held goal of artificial general intelligence, the deal will also require it to submit to an independent expert panel for verification.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Prior to this recapitalization, OpenAI was operating as a non-profit under strict equity restrictions — a position that became increasingly untenable as the company’s fundraising became more ambitious. In April, SoftBank announced an unprecedented $30 billion investment into OpenAI, contingent on the company’s successful conversion into a for-profit. On Saturday, The Information reported that the final installment of the funding had been sent, signaling a possible breakthrough in the restructuring.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There have been a number of legal efforts to block or otherwise influence the restructuring, most notably from Elon Musk, who at one point offered to acquire the company for $97.4 billion.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The attorneys general from California and Delaware, who had raised concerns about the conversion, will allow the process to proceed, subject to further conditions published by both offices. Notably, the California agreement requires OpenAI to “continue to undertake measures to mitigate risks to teens and others in&lt;br /&gt;connection with the development and deployment of AI and of AGI.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the announcement post, Taylor cited discussions with the state offices as a positive influence on the process. “We made several changes as a result of those discussions and we believe OpenAI—and as a result, the public we serve—are better for them,” Taylor wrote. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the wake of the news, CEO Sam Altman announced an open livestream with chief scientist Jakub Pachocki to answer questions from the public. The event will begin at 10:30 a.m. Pacific Time.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/28/openai-completes-its-for-profit-recapitalization/</guid><pubDate>Tue, 28 Oct 2025 14:30:24 +0000</pubDate></item><item><title>[NEW] Finding return on AI investments across industries (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/28/1126693/finding-return-on-ai-investments-across-industries/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;Provided by&lt;/span&gt;Intel&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;The market is officially three years post ChatGPT and many of the pundit bylines have shifted to using terms like “bubble” to suggest reasons behind generative AI not realizing material returns outside a handful of technology suppliers.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In September, the MIT NANDA report made waves because the soundbite every author and influencer picked up on was that 95% of all AI pilots failed to scale or deliver clear and measurable ROI. McKinsey earlier published a similar trend indicating that agentic AI would be the way forward to achieve huge operational benefits for enterprises. At &lt;em&gt;The Wall Street Journal&lt;/em&gt;’s Technology Council Summit, AI technology leaders recommended CIOs stop worrying about AI’s return on investment because measuring gains is difficult and if they were to try, the measurements would be wrong.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1126697" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/ChatGPT-Image-Oct-22-2025-02_41_13-PM.png" /&gt;&lt;/figure&gt;  &lt;p&gt;This places technology leaders in a precarious position–robust tech stacks already sustain their business operations, so what is the upside to introducing new technology?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;For decades, deployment strategies have followed a consistent cadence where tech operators avoid destabilizing business-critical workflows to swap out individual components in tech stacks. For example, a better or cheaper technology is not meaningful if it puts your disaster recovery at risk.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;While the price might increase when a new buyer takes over mature middleware, the cost of losing part of your enterprise data because you are mid-way through transitioning your enterprise to a new technology is way more severe than paying a higher price for a stable technology that you’ve run your business on for 20 years.&lt;/p&gt;  &lt;p&gt;So, how do enterprises get a return on investing in the latest tech transformation?&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;First principle of AI: Your data is your value&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Most of the articles about AI data relate to engineering tasks to ensure that an AI model infers against business data in repositories that represent past and present business realities&lt;strong&gt;.&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;However, one of the most widely-deployed use cases in enterprise AI begins with prompting an AI model by uploading file attachments into the model. This step narrows an AI model’s range to the content of the uploaded files, accelerating accurate response times and reducing the number of prompts required to get the best answer.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This tactic relies upon sending your proprietary business data into an AI model, so there are two important considerations to take in parallel with data preparation: first, governing your system for appropriate confidentiality; and second, developing a deliberate negotiation strategy with the model vendors, who cannot advance their frontier models without getting access to non-public data, like your business’ data.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Recently, Anthropic and OpenAI completed massive deals with enterprise data platforms and owners because there is not enough high-value primary data publicly available on the internet.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Most enterprises would automatically prioritize confidentiality of their data and design business workflows to maintain trade secrets. From an economic value point of view, especially considering how costly every model API call really is, exchanging selective access to your data for services or price offsets may be the right strategy. Rather than approaching model purchase/onboarding as a typical supplier/procurement exercise, think through the potential to realize mutual benefits in advancing your suppliers’ model and your business adoption of the model in tandem.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Second principle of AI: Boring by design&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;According to Information is Beautiful, in 2024 alone, 182 new generative AI models were introduced to the market. When GPT5 came into the market in 2025, many of the models from 12 to 24 months prior were rendered unavailable until subscription customers threatened to cancel. Their previously stable AI workflows were built on models that no longer worked. Their tech providers thought the customers would be excited about the newest models and did not realize the premium that business workflows place on stability. Video gamers are happy to upgrade their custom builds throughout the entire lifespan of the system components in their gaming rigs, and will upgrade the entire system just to play a newly released title.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;However, behavior does not translate to business run rate operations. While many employees may use the latest models for document processing or generating content, back-office operations can’t sustain swapping a tech stack three times a week to keep up with the latest model drops. The back-office work is boring by design.&lt;/p&gt;  &lt;p&gt;The most successful AI deployments have focused on deploying AI on business problems unique to their business, often running in the background to accelerate or augment mundane but mandated tasks. Relieving legal or expense audits from having to manually cross check individual reports but putting the final decision in a humans’ responsibility zone combines the best of both.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;The important point is that none of these tasks require constant updates to the latest model to deliver that value. This is also an area where abstracting your business workflows from using direct model APIs can offer additional long-term stability while maintaining options to update or upgrade the underlying engines at the pace of your business.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Third principle of AI: Mini-van economics&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;The best way to avoid upside-down economics is to design systems to align to the users rather than vendor specs and benchmarks.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Too many businesses continue to fall into the trap of buying new gear or new cloud service types based on new supplier-led benchmarks rather than starting their AI journey from what their business can consume, at what pace, on the capabilities they have deployed today.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;While Ferrari marketing is effective and those automobiles are truly magnificent, they drive the same speed through school zones and lack ample trunk space for groceries. Keep in mind that every remote server and model touched by a user layers on the costs and design for frugality by reconfiguring workflows to minimize spending on third-party services.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Too many companies have found that their customer support AI workflows add millions of dollars of operational run rate costs and end up adding more development time and cost to update the implementation for OpEx predictability. Meanwhile, the companies that decided that a system running at the pace a human can read—less than 50 tokens per second—were able to successfully deploy scaled-out AI applications with minimal additional overhead.&lt;/p&gt;  &lt;p&gt;There are so many aspects of this new automation technology to unpack—the best guidance is to start practical, design for independence in underlying technology components to keep from disrupting stable applications long term, and to leverage the fact that AI technology makes your business data valuable to the advancement of your tech suppliers' goals.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Intel. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;Provided by&lt;/span&gt;Intel&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;The market is officially three years post ChatGPT and many of the pundit bylines have shifted to using terms like “bubble” to suggest reasons behind generative AI not realizing material returns outside a handful of technology suppliers.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In September, the MIT NANDA report made waves because the soundbite every author and influencer picked up on was that 95% of all AI pilots failed to scale or deliver clear and measurable ROI. McKinsey earlier published a similar trend indicating that agentic AI would be the way forward to achieve huge operational benefits for enterprises. At &lt;em&gt;The Wall Street Journal&lt;/em&gt;’s Technology Council Summit, AI technology leaders recommended CIOs stop worrying about AI’s return on investment because measuring gains is difficult and if they were to try, the measurements would be wrong.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1126697" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/ChatGPT-Image-Oct-22-2025-02_41_13-PM.png" /&gt;&lt;/figure&gt;  &lt;p&gt;This places technology leaders in a precarious position–robust tech stacks already sustain their business operations, so what is the upside to introducing new technology?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;For decades, deployment strategies have followed a consistent cadence where tech operators avoid destabilizing business-critical workflows to swap out individual components in tech stacks. For example, a better or cheaper technology is not meaningful if it puts your disaster recovery at risk.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;While the price might increase when a new buyer takes over mature middleware, the cost of losing part of your enterprise data because you are mid-way through transitioning your enterprise to a new technology is way more severe than paying a higher price for a stable technology that you’ve run your business on for 20 years.&lt;/p&gt;  &lt;p&gt;So, how do enterprises get a return on investing in the latest tech transformation?&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;First principle of AI: Your data is your value&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Most of the articles about AI data relate to engineering tasks to ensure that an AI model infers against business data in repositories that represent past and present business realities&lt;strong&gt;.&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;However, one of the most widely-deployed use cases in enterprise AI begins with prompting an AI model by uploading file attachments into the model. This step narrows an AI model’s range to the content of the uploaded files, accelerating accurate response times and reducing the number of prompts required to get the best answer.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This tactic relies upon sending your proprietary business data into an AI model, so there are two important considerations to take in parallel with data preparation: first, governing your system for appropriate confidentiality; and second, developing a deliberate negotiation strategy with the model vendors, who cannot advance their frontier models without getting access to non-public data, like your business’ data.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Recently, Anthropic and OpenAI completed massive deals with enterprise data platforms and owners because there is not enough high-value primary data publicly available on the internet.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Most enterprises would automatically prioritize confidentiality of their data and design business workflows to maintain trade secrets. From an economic value point of view, especially considering how costly every model API call really is, exchanging selective access to your data for services or price offsets may be the right strategy. Rather than approaching model purchase/onboarding as a typical supplier/procurement exercise, think through the potential to realize mutual benefits in advancing your suppliers’ model and your business adoption of the model in tandem.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Second principle of AI: Boring by design&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;According to Information is Beautiful, in 2024 alone, 182 new generative AI models were introduced to the market. When GPT5 came into the market in 2025, many of the models from 12 to 24 months prior were rendered unavailable until subscription customers threatened to cancel. Their previously stable AI workflows were built on models that no longer worked. Their tech providers thought the customers would be excited about the newest models and did not realize the premium that business workflows place on stability. Video gamers are happy to upgrade their custom builds throughout the entire lifespan of the system components in their gaming rigs, and will upgrade the entire system just to play a newly released title.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;However, behavior does not translate to business run rate operations. While many employees may use the latest models for document processing or generating content, back-office operations can’t sustain swapping a tech stack three times a week to keep up with the latest model drops. The back-office work is boring by design.&lt;/p&gt;  &lt;p&gt;The most successful AI deployments have focused on deploying AI on business problems unique to their business, often running in the background to accelerate or augment mundane but mandated tasks. Relieving legal or expense audits from having to manually cross check individual reports but putting the final decision in a humans’ responsibility zone combines the best of both.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;The important point is that none of these tasks require constant updates to the latest model to deliver that value. This is also an area where abstracting your business workflows from using direct model APIs can offer additional long-term stability while maintaining options to update or upgrade the underlying engines at the pace of your business.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Third principle of AI: Mini-van economics&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;The best way to avoid upside-down economics is to design systems to align to the users rather than vendor specs and benchmarks.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Too many businesses continue to fall into the trap of buying new gear or new cloud service types based on new supplier-led benchmarks rather than starting their AI journey from what their business can consume, at what pace, on the capabilities they have deployed today.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;While Ferrari marketing is effective and those automobiles are truly magnificent, they drive the same speed through school zones and lack ample trunk space for groceries. Keep in mind that every remote server and model touched by a user layers on the costs and design for frugality by reconfiguring workflows to minimize spending on third-party services.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Too many companies have found that their customer support AI workflows add millions of dollars of operational run rate costs and end up adding more development time and cost to update the implementation for OpEx predictability. Meanwhile, the companies that decided that a system running at the pace a human can read—less than 50 tokens per second—were able to successfully deploy scaled-out AI applications with minimal additional overhead.&lt;/p&gt;  &lt;p&gt;There are so many aspects of this new automation technology to unpack—the best guidance is to start practical, design for independence in underlying technology components to keep from disrupting stable applications long term, and to leverage the fact that AI technology makes your business data valuable to the advancement of your tech suppliers' goals.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Intel. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/28/1126693/finding-return-on-ai-investments-across-industries/</guid><pubDate>Tue, 28 Oct 2025 15:00:33 +0000</pubDate></item><item><title>[NEW] Expert panel will determine AGI arrival in new Microsoft-OpenAI agreement (AI – Ars Technica)</title><link>https://arstechnica.com/information-technology/2025/10/expert-panel-will-determine-agi-arrival-in-new-microsoft-openai-agreement/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        New deal extends Microsoft IP rights until 2032 or until AGI arrives.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The OpenAI logo superimposed over a Microsoft logo background" class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/07/openai_microsoft_3-300x169.jpg" width="300" /&gt;
                  &lt;img alt="The OpenAI logo superimposed over a Microsoft logo background" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/07/openai_microsoft_3-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards / OpenAI / Microsoft

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Monday, Microsoft and OpenAI announced a revised partnership agreement that introduces an independent expert panel to verify when OpenAI achieves so-called artificial general intelligence (AGI), a determination that will trigger major shifts in how the companies share technology and revenue. The deal values Microsoft’s stake in OpenAI at approximately $135 billion and extends the exclusive partnership through 2032 while giving both companies more freedom to pursue AGI independently.&lt;/p&gt;
&lt;p&gt;The partnership began in 2019 when Microsoft invested $1 billion in OpenAI. Since then, Microsoft has provided billions in cloud computing resources through Azure and used OpenAI’s models as the basis of products like Copilot. The new agreement maintains Microsoft as OpenAI’s frontier model partner and preserves Microsoft’s exclusive rights to OpenAI’s IP and Azure API exclusivity until the threshold of AGI is reached.&lt;/p&gt;
&lt;p&gt;Under a previous arrangement, OpenAI alone would determine when it achieved AGI, which is a nebulous concept that is difficult to define. The revised deal requires an independent expert panel to verify that claim, a change that adds oversight to a determination with billions of dollars at stake. When the panel confirms that AGI has been reached, Microsoft’s intellectual property rights to OpenAI’s research methods will expire, and the revenue-sharing arrangement between the companies will end, though payments will continue over a longer period.&lt;/p&gt;
&lt;p&gt;The companies did not disclose who will serve on the expert panel or how panel members will be selected. The lack of details about the panel’s composition leaves open questions about what criteria the experts will actually use to verify that AGI has been achieved. Previously, the two companies had agreed on a somewhat arbitrary economic threshold of when AI systems can generate $100 billion in profits.&lt;/p&gt;
&lt;p&gt;The partnership, one of the most watched in the tech space, has shown strain as OpenAI has grown from a spunky research lab with high hopes into a company valued at $500 billion that sways the trajectory of the tech industry with its moves in AI. Both companies now compete for customers, and OpenAI has been seeking more compute capacity than Microsoft can provide.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In May, OpenAI abandoned its plan to fully convert to a for-profit company after pressure from regulators and critics. The company instead shifted to a modified approach where the nonprofit board would retain control while converting its for-profit subsidiary into a public benefit corporation (PBC).&lt;/p&gt;
&lt;h2&gt;What changed in the agreement&lt;/h2&gt;
&lt;p&gt;The revised deal extends Microsoft’s intellectual property rights through 2032 and now includes models developed after AGI is declared. Microsoft holds IP rights to OpenAI’s model weights, architecture, inference code, and fine-tuning code until the expert panel confirms AGI or through 2030, whichever comes first. The new agreement also codifies that OpenAI can formally release open-weight models (like gpt-oss) that meet requisite capability criteria.&lt;/p&gt;
&lt;p&gt;However, Microsoft’s rights to OpenAI’s research methods, defined as confidential techniques used in model development, will expire at those same thresholds. The agreement explicitly excludes Microsoft from having rights to OpenAI’s consumer hardware products.&lt;/p&gt;
&lt;p&gt;The deal allows OpenAI to develop some products jointly with third parties. API products built with other companies must run exclusively on Azure, but non-API products can operate on any cloud provider. This gives OpenAI more flexibility to partner with other technology companies while keeping Microsoft as its primary infrastructure provider.&lt;/p&gt;
&lt;p&gt;Under the agreement, Microsoft can now pursue AGI development alone or with partners other than OpenAI. If Microsoft uses OpenAI’s intellectual property to build AGI before the expert panel makes a declaration, those models must exceed compute thresholds that are larger than what current leading AI models require for training.&lt;/p&gt;
&lt;p&gt;The revenue-sharing arrangement between the companies will continue until the expert panel verifies that AGI has been reached, though payments will extend over a longer period. OpenAI has committed to purchasing $250 billion in Azure services, and Microsoft no longer holds a right of first refusal to serve as OpenAI’s compute provider. This lets OpenAI shop around for cloud infrastructure if it chooses, though the massive Azure commitment suggests it will remain the primary provider.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        New deal extends Microsoft IP rights until 2032 or until AGI arrives.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The OpenAI logo superimposed over a Microsoft logo background" class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/07/openai_microsoft_3-300x169.jpg" width="300" /&gt;
                  &lt;img alt="The OpenAI logo superimposed over a Microsoft logo background" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/07/openai_microsoft_3-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards / OpenAI / Microsoft

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Monday, Microsoft and OpenAI announced a revised partnership agreement that introduces an independent expert panel to verify when OpenAI achieves so-called artificial general intelligence (AGI), a determination that will trigger major shifts in how the companies share technology and revenue. The deal values Microsoft’s stake in OpenAI at approximately $135 billion and extends the exclusive partnership through 2032 while giving both companies more freedom to pursue AGI independently.&lt;/p&gt;
&lt;p&gt;The partnership began in 2019 when Microsoft invested $1 billion in OpenAI. Since then, Microsoft has provided billions in cloud computing resources through Azure and used OpenAI’s models as the basis of products like Copilot. The new agreement maintains Microsoft as OpenAI’s frontier model partner and preserves Microsoft’s exclusive rights to OpenAI’s IP and Azure API exclusivity until the threshold of AGI is reached.&lt;/p&gt;
&lt;p&gt;Under a previous arrangement, OpenAI alone would determine when it achieved AGI, which is a nebulous concept that is difficult to define. The revised deal requires an independent expert panel to verify that claim, a change that adds oversight to a determination with billions of dollars at stake. When the panel confirms that AGI has been reached, Microsoft’s intellectual property rights to OpenAI’s research methods will expire, and the revenue-sharing arrangement between the companies will end, though payments will continue over a longer period.&lt;/p&gt;
&lt;p&gt;The companies did not disclose who will serve on the expert panel or how panel members will be selected. The lack of details about the panel’s composition leaves open questions about what criteria the experts will actually use to verify that AGI has been achieved. Previously, the two companies had agreed on a somewhat arbitrary economic threshold of when AI systems can generate $100 billion in profits.&lt;/p&gt;
&lt;p&gt;The partnership, one of the most watched in the tech space, has shown strain as OpenAI has grown from a spunky research lab with high hopes into a company valued at $500 billion that sways the trajectory of the tech industry with its moves in AI. Both companies now compete for customers, and OpenAI has been seeking more compute capacity than Microsoft can provide.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In May, OpenAI abandoned its plan to fully convert to a for-profit company after pressure from regulators and critics. The company instead shifted to a modified approach where the nonprofit board would retain control while converting its for-profit subsidiary into a public benefit corporation (PBC).&lt;/p&gt;
&lt;h2&gt;What changed in the agreement&lt;/h2&gt;
&lt;p&gt;The revised deal extends Microsoft’s intellectual property rights through 2032 and now includes models developed after AGI is declared. Microsoft holds IP rights to OpenAI’s model weights, architecture, inference code, and fine-tuning code until the expert panel confirms AGI or through 2030, whichever comes first. The new agreement also codifies that OpenAI can formally release open-weight models (like gpt-oss) that meet requisite capability criteria.&lt;/p&gt;
&lt;p&gt;However, Microsoft’s rights to OpenAI’s research methods, defined as confidential techniques used in model development, will expire at those same thresholds. The agreement explicitly excludes Microsoft from having rights to OpenAI’s consumer hardware products.&lt;/p&gt;
&lt;p&gt;The deal allows OpenAI to develop some products jointly with third parties. API products built with other companies must run exclusively on Azure, but non-API products can operate on any cloud provider. This gives OpenAI more flexibility to partner with other technology companies while keeping Microsoft as its primary infrastructure provider.&lt;/p&gt;
&lt;p&gt;Under the agreement, Microsoft can now pursue AGI development alone or with partners other than OpenAI. If Microsoft uses OpenAI’s intellectual property to build AGI before the expert panel makes a declaration, those models must exceed compute thresholds that are larger than what current leading AI models require for training.&lt;/p&gt;
&lt;p&gt;The revenue-sharing arrangement between the companies will continue until the expert panel verifies that AGI has been reached, though payments will extend over a longer period. OpenAI has committed to purchasing $250 billion in Azure services, and Microsoft no longer holds a right of first refusal to serve as OpenAI’s compute provider. This lets OpenAI shop around for cloud infrastructure if it chooses, though the massive Azure commitment suggests it will remain the primary provider.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/information-technology/2025/10/expert-panel-will-determine-agi-arrival-in-new-microsoft-openai-agreement/</guid><pubDate>Tue, 28 Oct 2025 15:02:30 +0000</pubDate></item><item><title>[NEW] UNC Chancellor Lee Roberts on pushing his university into the AI age (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/podcast/unc-chancellor-lee-roberts-on-pushing-his-university-into-the-ai-age/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/Screenshot-2025-10-20-at-1.13.38AM.png?resize=1200,807" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;This week on StrictlyVC Download, Connie Loizos sits down with Lee Roberts, chancellor of the University of North Carolina at Chapel Hill, to discuss his ambitious plan to make AI the university’s North Star amid a tumultuous year.&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;Roberts walks through his decision to merge UNC’s School of Data Science and Society with its School of Information and Library Science, explaining why breaking down academic silos is essential when the technology moves faster than universities typically can. He addresses the $38 million in terminated federal research grants — concentrated in areas like public health — and why he’s less concerned about funding cuts than he was at the start of the year. Roberts also defends his $10 million annual commitment to Bill Belichick despite the team’s rocky start, explaining why football revenue is essential to supporting UNC’s 2028 sports programs.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;StrictlyVC Download posts every Tuesday. Subscribe on&amp;nbsp;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;Apple&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;,&amp;nbsp;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;Spotify,&amp;nbsp;&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;or&amp;nbsp;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;wherever you listen to podcasts&amp;nbsp;&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;to be alerted when new episodes drop.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/Screenshot-2025-10-20-at-1.13.38AM.png?resize=1200,807" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;This week on StrictlyVC Download, Connie Loizos sits down with Lee Roberts, chancellor of the University of North Carolina at Chapel Hill, to discuss his ambitious plan to make AI the university’s North Star amid a tumultuous year.&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;Roberts walks through his decision to merge UNC’s School of Data Science and Society with its School of Information and Library Science, explaining why breaking down academic silos is essential when the technology moves faster than universities typically can. He addresses the $38 million in terminated federal research grants — concentrated in areas like public health — and why he’s less concerned about funding cuts than he was at the start of the year. Roberts also defends his $10 million annual commitment to Bill Belichick despite the team’s rocky start, explaining why football revenue is essential to supporting UNC’s 2028 sports programs.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;StrictlyVC Download posts every Tuesday. Subscribe on&amp;nbsp;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;Apple&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;,&amp;nbsp;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;Spotify,&amp;nbsp;&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;or&amp;nbsp;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;wherever you listen to podcasts&amp;nbsp;&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;to be alerted when new episodes drop.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/podcast/unc-chancellor-lee-roberts-on-pushing-his-university-into-the-ai-age/</guid><pubDate>Tue, 28 Oct 2025 15:08:45 +0000</pubDate></item><item><title>[NEW] Mem0 raises $24M from YC, Peak XV and Basis Set to build the memory layer for AI apps (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/28/mem0-raises-24m-from-yc-peak-xv-and-basis-set-to-build-the-memory-layer-for-ai-apps/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/IMG_2437.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Taranjeet Singh (pictured above, right) has launched six companies, with some failing and others seeing varying degrees of success. His seventh, Mem0, could be his defining one.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup starts with the premise that large language models can’t remember past interactions the way humans do. If two people are chatting and the connection drops, they can resume the conversation. AI models, by contrast, forget everything and start from scratch.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Mem0 fixes that. Singh calls it a “memory passport,” where your AI memory travels with you across apps and agents, just like email or logins do today. The YC-backed startup, launched in January 2024, has raised $24 million ($3.9 million in previously unannounced seed funding and a $20 million Series A).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI-focused early-stage fund Basis Set Ventures led the Series A, with participation from existing investors Kindred Ventures and Y Combinator, as well as new backers including Peak XV Partners and the GitHub Fund.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notable angels include Dharmesh Shah (HubSpot), Scott Belsky (ex-CPO Adobe), Olivier Pomel (Datadog), Thomas Dohmke (ex-CEO GitHub), Paul Copplestone (Supabase), James Hawkins (PostHog), Lukas Biewald (Weights &amp;amp; Biases), Brian Balfour (Reforge), Philip Rathle (Neo4j), and Jennifer Taylor (former president, Plaid).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Having several leaders who helped shape the modern software ecosystem bet on Mem0 (pronounced “mem zero”) underscores its promise, and the traction from the four-person team backs it up.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So far, the open source API, which claims to be the most widely adopted memory framework for AI developers, has surpassed 41,000 GitHub stars and recorded over 13 million Python package downloads. In Q1 2025, Mem0 processed 35 million API calls. By Q3, that number jumped to 186 million, growing roughly 30% month over month.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond open source adoption, more than 80,000 developers have signed up for its cloud service. Mem0’s cloud API now handles more memory operations than any other provider and serves as the exclusive memory provider for AWS’s new Agent SDK.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In early 2023, Singh was still in Bangalore, India. He started his career as a software engineer at Paytm, one of India’s most valuable startups, before becoming Khatabook’s first growth engineer. He quit in late 2022, just as the ChatGPT wave was about to crest, and built one of the first GPT app stores, which scaled to over a million users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That experience led him to create Embedchain, an open source project that lets developers index, retrieve, and sync unstructured data. As the project took off, earning more than 8,000 GitHub stars, Singh sent over 200 cold emails to founders, investors, and engineers in Silicon Valley.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I reached out to almost every famous tech entrepreneur that you might have heard of and was quite persistent. Some of them responded, and after hearing us out, scheduled us to fly from Bangalore to San Francisco within 36 hours,” Singh said.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Once in the U.S., Singh reconnected with his longtime friend and now co-founder and CTO, Deshraj Yadav, who had led the AI Platform at Tesla Autopilot. Together, they had previously built EvalAI, an open source Kaggle alternative that grew to 1.6K GitHub stars.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While experimenting with Embedchain, the duo launched a meditation app inspired by Indian yogi Sadhguru. The app went viral in India, but Singh says users kept sharing the same feedback: “Hey, I’m on this meditative journey, but the app doesn’t remember that.” So they pivoted from Embedchain to Mem0 to solve that problem.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-wp-embed is-provider-techcrunch wp-block-embed-techcrunch"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The idea of memory for AI isn’t new, but it’s quickly becoming a critical battleground. OpenAI, for instance, began testing long-term memory features in ChatGPT in early 2024, and its CEO, Sam Altman, has hinted that persistent memory will be central to OpenAI’s upcoming hardware device. Other AI labs are also launching experimental memory systems for their agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Singh argues that while big AI labs are building memory systems, they have little incentive to make them portable or interoperable. “Memory is becoming one of their key moats now that LLMs are getting commoditized,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He explains that while consumers can enjoy persistent, personalized experiences in ChatGPT, developers who want to build applications — say, a finance companion that remembers a user’s trading history — need an open, neutral solution like Mem0.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We want developers to offer day-one personalization through a shared memory network,” Singh said. “Think of it as Plaid for memory. That’s act two. For now, we’re laser-focused on building the best memory product possible.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mem0’s framework lets developers store, retrieve, and evolve user memory across models, applications, and platforms. It’s model-agnostic, compatible with OpenAI, Anthropic, or any open source LLM, and integrates directly with frameworks like LangChain and LlamaIndex.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Developers use Mem0 to create applications that grow smarter with every interaction: therapy bots that recall past conversations, productivity agents that remember personal habits, and AI companions that adapt over time. Customers range from indie developers to enterprise teams building copilots and automation tools.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We backed Mem0 from its earliest days — even before YC — because memory is foundational to the future of AI,” said Lan Xuezhao, founder and partner at Basis Set Ventures. “We’re doubling down as the team continues to tackle one of the hardest and most important infrastructure challenges: enabling AI systems to build lasting, contextual memory.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other early-stage startups in the memory space include Supermemory (whose founder briefly worked at Mem0), Felicis-backed Letta, and Memories.ai.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-wp-embed is-provider-techcrunch wp-block-embed-techcrunch"&gt;&lt;/figure&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/IMG_2437.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Taranjeet Singh (pictured above, right) has launched six companies, with some failing and others seeing varying degrees of success. His seventh, Mem0, could be his defining one.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup starts with the premise that large language models can’t remember past interactions the way humans do. If two people are chatting and the connection drops, they can resume the conversation. AI models, by contrast, forget everything and start from scratch.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Mem0 fixes that. Singh calls it a “memory passport,” where your AI memory travels with you across apps and agents, just like email or logins do today. The YC-backed startup, launched in January 2024, has raised $24 million ($3.9 million in previously unannounced seed funding and a $20 million Series A).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI-focused early-stage fund Basis Set Ventures led the Series A, with participation from existing investors Kindred Ventures and Y Combinator, as well as new backers including Peak XV Partners and the GitHub Fund.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notable angels include Dharmesh Shah (HubSpot), Scott Belsky (ex-CPO Adobe), Olivier Pomel (Datadog), Thomas Dohmke (ex-CEO GitHub), Paul Copplestone (Supabase), James Hawkins (PostHog), Lukas Biewald (Weights &amp;amp; Biases), Brian Balfour (Reforge), Philip Rathle (Neo4j), and Jennifer Taylor (former president, Plaid).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Having several leaders who helped shape the modern software ecosystem bet on Mem0 (pronounced “mem zero”) underscores its promise, and the traction from the four-person team backs it up.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So far, the open source API, which claims to be the most widely adopted memory framework for AI developers, has surpassed 41,000 GitHub stars and recorded over 13 million Python package downloads. In Q1 2025, Mem0 processed 35 million API calls. By Q3, that number jumped to 186 million, growing roughly 30% month over month.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond open source adoption, more than 80,000 developers have signed up for its cloud service. Mem0’s cloud API now handles more memory operations than any other provider and serves as the exclusive memory provider for AWS’s new Agent SDK.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In early 2023, Singh was still in Bangalore, India. He started his career as a software engineer at Paytm, one of India’s most valuable startups, before becoming Khatabook’s first growth engineer. He quit in late 2022, just as the ChatGPT wave was about to crest, and built one of the first GPT app stores, which scaled to over a million users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That experience led him to create Embedchain, an open source project that lets developers index, retrieve, and sync unstructured data. As the project took off, earning more than 8,000 GitHub stars, Singh sent over 200 cold emails to founders, investors, and engineers in Silicon Valley.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I reached out to almost every famous tech entrepreneur that you might have heard of and was quite persistent. Some of them responded, and after hearing us out, scheduled us to fly from Bangalore to San Francisco within 36 hours,” Singh said.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Once in the U.S., Singh reconnected with his longtime friend and now co-founder and CTO, Deshraj Yadav, who had led the AI Platform at Tesla Autopilot. Together, they had previously built EvalAI, an open source Kaggle alternative that grew to 1.6K GitHub stars.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While experimenting with Embedchain, the duo launched a meditation app inspired by Indian yogi Sadhguru. The app went viral in India, but Singh says users kept sharing the same feedback: “Hey, I’m on this meditative journey, but the app doesn’t remember that.” So they pivoted from Embedchain to Mem0 to solve that problem.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-wp-embed is-provider-techcrunch wp-block-embed-techcrunch"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The idea of memory for AI isn’t new, but it’s quickly becoming a critical battleground. OpenAI, for instance, began testing long-term memory features in ChatGPT in early 2024, and its CEO, Sam Altman, has hinted that persistent memory will be central to OpenAI’s upcoming hardware device. Other AI labs are also launching experimental memory systems for their agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Singh argues that while big AI labs are building memory systems, they have little incentive to make them portable or interoperable. “Memory is becoming one of their key moats now that LLMs are getting commoditized,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He explains that while consumers can enjoy persistent, personalized experiences in ChatGPT, developers who want to build applications — say, a finance companion that remembers a user’s trading history — need an open, neutral solution like Mem0.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We want developers to offer day-one personalization through a shared memory network,” Singh said. “Think of it as Plaid for memory. That’s act two. For now, we’re laser-focused on building the best memory product possible.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mem0’s framework lets developers store, retrieve, and evolve user memory across models, applications, and platforms. It’s model-agnostic, compatible with OpenAI, Anthropic, or any open source LLM, and integrates directly with frameworks like LangChain and LlamaIndex.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Developers use Mem0 to create applications that grow smarter with every interaction: therapy bots that recall past conversations, productivity agents that remember personal habits, and AI companions that adapt over time. Customers range from indie developers to enterprise teams building copilots and automation tools.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We backed Mem0 from its earliest days — even before YC — because memory is foundational to the future of AI,” said Lan Xuezhao, founder and partner at Basis Set Ventures. “We’re doubling down as the team continues to tackle one of the hardest and most important infrastructure challenges: enabling AI systems to build lasting, contextual memory.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other early-stage startups in the memory space include Supermemory (whose founder briefly worked at Mem0), Felicis-backed Letta, and Memories.ai.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-wp-embed is-provider-techcrunch wp-block-embed-techcrunch"&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/28/mem0-raises-24m-from-yc-peak-xv-and-basis-set-to-build-the-memory-layer-for-ai-apps/</guid><pubDate>Tue, 28 Oct 2025 15:14:13 +0000</pubDate></item><item><title>[NEW] GitHub's Agent HQ aims to solve enterprises' biggest AI coding problem: Too many agents, no central control (AI | VentureBeat)</title><link>https://venturebeat.com/ai/githubs-agent-hq-aims-to-solve-enterprises-biggest-ai-coding-problem-too</link><description>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://github.com/"&gt;&lt;u&gt;GitHub&lt;/u&gt;&lt;/a&gt; is making a bold bet that enterprises don&amp;#x27;t need another proprietary coding agent. They need a way to manage all of them.&lt;/p&gt;&lt;p&gt;At its Universe 2025 conference, the Microsoft-owned developer platform announced Agent HQ. The new architecture transforms GitHub into a unified control plane for managing multiple AI coding agents from competitors including Anthropic, OpenAI, Google, Cognition and xAI. Rather than forcing developers into a single agent experience, the company is positioning itself as the essential orchestration layer beneath all of them.&lt;/p&gt;&lt;p&gt;Agent HQ represents GitHub&amp;#x27;s attempt to apply its collaboration platform approach to AI agents. Just as the company transformed Git, pull requests and CI/CD into collaborative workflows, it&amp;#x27;s now trying to do the same with a fragmented AI coding landscape.&lt;/p&gt;&lt;p&gt;The announcement marks what GitHub calls the transition from &amp;quot;wave one&amp;quot; to &amp;quot;wave two&amp;quot; of AI-assisted development. According to GitHub&amp;#x27;s Octoverse report, 80% of new developers use Copilot in their first week and AI has helped to lead to a large increase overall in the use of the GitHub platform.&lt;/p&gt;&lt;p&gt; &amp;quot;&lt;a href="https://venturebeat.com/ai/github-expands-ai-capabilities-with-multi-model-support-in-copilot-enhanced-developer-tools"&gt;&lt;u&gt;Last year&lt;/u&gt;&lt;/a&gt;, the big announcements for us, and what we were saying as a company is wave one is done, that was kind of code completion,&amp;quot; Mario Rodriguez, GitHub&amp;#x27;s Chief Operating Officer, told VentureBeat. &amp;quot;We&amp;#x27;re into this wave two era, and wave two is going to be multimodal, it&amp;#x27;s going to be agentic and it&amp;#x27;s going to have these new experiences that are going to feel AI native.&amp;quot;&lt;/p&gt;&lt;h2&gt;What is Agent HQ?&lt;/h2&gt;&lt;p&gt;GitHub has already updated its GitHub Copilot coding tool for the agentic era with the debut of &lt;a href="https://venturebeat.com/ai/github-copilot-evolves-into-autonomous-agent-with-asynchronous-code-testing"&gt;&lt;u&gt;GitHub Copilot Agent&lt;/u&gt;&lt;/a&gt; in May.&lt;/p&gt;&lt;p&gt;Agent HQ transforms GitHub into an open ecosystem that unites multiple AI coding agents on a single platform. Over the coming months, coding agents from Anthropic, OpenAI, Google, Cognition, xAI and others will become available directly within GitHub as part of existing paid GitHub Copilot subscriptions.&lt;/p&gt;&lt;p&gt;The architecture maintains GitHub&amp;#x27;s core primitives. Developers still work with Git, pull requests and issues. They still use their preferred compute, whether GitHub Actions or self-hosted runners. What changes is the layer above: agents from multiple vendors can now operate within GitHub&amp;#x27;s security perimeter, using the same identity controls, branch permissions and audit logging that enterprises already trust for human developers.&lt;/p&gt;&lt;p&gt;This approach differs fundamentally from standalone tools. When developers use Cursor or grant repository access to Claude, those agents typically receive broad permissions across entire repositories. Agent HQ compartmentalizes access at the branch level and wraps all agent activity in enterprise-grade governance controls.&lt;/p&gt;&lt;h2&gt;Mission Control: One interface for all agents&lt;/h2&gt;&lt;p&gt;At the heart of Agent HQ is Mission Control. It&amp;#x27;s a unified command center that appears consistently across GitHub&amp;#x27;s web interface, VS Code, mobile apps and the command line. Through Mission Control, developers can assign work to multiple agents simultaneously. They can track progress and manage permissions, all from a single pane of glass.&lt;/p&gt;&lt;p&gt;The technical architecture addresses a critical enterprise concern: security. Unlike standalone agent implementations where users must grant broad repository access, GitHub&amp;#x27;s Agent HQ implements granular controls at the platform level.&lt;/p&gt;&lt;p&gt;&amp;quot;Our coding agent has a set of security controls and capabilities that are built natively into the platform, and that&amp;#x27;s what we&amp;#x27;re providing to all of these other agents as well,&amp;quot; Rodriguez explained. &amp;quot;It runs with a GitHub token that is very locked down to what it can actually do.&amp;quot;&lt;/p&gt;&lt;p&gt;Agents operating through Agent HQ can only commit to designated branches. They run within sandboxed GitHub Actions environments with firewall protections. They operate under strict identity controls. Rodriguez explained that even if an agent goes rogue, the firewall prevents it from accessing external networks or exfiltrating data unless those protections are explicitly disabled.&lt;/p&gt;&lt;h2&gt;Technical differentiation: MCP integration and custom agents&lt;/h2&gt;&lt;p&gt;Beyond managing third-party agents, GitHub is introducing two technical capabilities that set Agent HQ apart from alternative approaches like Cursor&amp;#x27;s standalone editor or Anthropic&amp;#x27;s Claude integration.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Custom agents via AGENTS.md files&lt;/b&gt;: Enterprises can now create source-controlled configuration files that define specific rules, tools and guardrails for how Copilot behaves. For example, a company could specify &amp;quot;prefer this logger&amp;quot; or &amp;quot;use table-driven tests for all handlers.&amp;quot; This permanently encodes organizational standards without requiring developers to re-prompt every time.&lt;/p&gt;&lt;p&gt;&amp;quot;Custom agents have an immense amount of product market fit within enterprises, because they could just codify a set of skills that the coordination can do, and then standardize on those and get really high quality output as well,&amp;quot; Rodriguez said.&lt;/p&gt;&lt;p&gt;The AGENTS.md specification allows teams to version control their agent behavior alongside their code. When a developer clones a repository, they automatically inherit the custom agent rules. This solves a persistent problem with AI coding tools: inconsistent output quality when different team members use different prompting strategies.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Native Model Context Protocol (MCP) support&lt;/b&gt;: VS Code now includes a GitHub MCP Registry. Developers can discover, install and enable MCP servers with a single click. They can then create custom agents that combine these tools with specific system prompts.&lt;/p&gt;&lt;p&gt;This positions GitHub as the integration point between the emerging MCP ecosystem and actual developer workflows. MCP, introduced by Anthropic but rapidly gaining industry support, is becoming a de facto standard for agent-to-tool communication. By supporting the full specification, GitHub can orchestrate agents that need access to external services without each agent implementing its own integration logic.&lt;/p&gt;&lt;h2&gt;Plan Mode and agentic code review&lt;/h2&gt;&lt;p&gt;GitHub is also shipping new capabilities within VS Code itself. Plan Mode allows developers to collaborate with Copilot on building step-by-step project approaches. The AI asks clarifying questions before any code is written. Once approved, the plan can be executed either locally in VS Code or by cloud-based agents.&lt;/p&gt;&lt;p&gt;The feature addresses a common failure mode in AI coding: starting implementation before requirements are fully understood. By forcing an explicit planning phase, GitHub aims to reduce wasted effort and improve output quality.&lt;/p&gt;&lt;p&gt;More significantly, GitHub&amp;#x27;s code review feature is becoming agentic. The new implementation will leverage GitHub&amp;#x27;s CodeQL engine, which previously largely focused on security vulnerabilities, to identify bugs and maintainability issues. The code review agent will automatically scan agent-generated pull requests before human review. This creates a two-stage quality gate.&lt;/p&gt;&lt;p&gt;&amp;quot;Our code review agent is going to be able to make calls into the CodeQL engine to be able to then find a set of bugs,&amp;quot; Rodriguez explained. &amp;quot;We&amp;#x27;re extending the engine and we&amp;#x27;re going to be able to tap into that engine also to find bugs as well.&amp;quot;&lt;/p&gt;&lt;h2&gt;Enterprise considerations: What to do now&lt;/h2&gt;&lt;p&gt;For enterprises already deploying multiple AI coding tools, Agent HQ offers a path to consolidation without forcing tool elimination.&lt;/p&gt;&lt;p&gt;GitHub&amp;#x27;s multi-agent approach provides vendor flexibility and reduces lock-in risk. Organizations can test multiple agents within a unified security perimeter and switch providers without retraining developers. The tradeoff is potentially less optimized experiences compared to specialized tools that tightly integrate UI and agent behavior.&lt;/p&gt;&lt;p&gt;Rodriguez&amp;#x27;s recommendation is clear: start with custom agents. Custom agents let enterprises codify organizational standards that agents follow consistently. Once established, organizations can layer in additional third-party agents to expand capabilities.&lt;/p&gt;&lt;p&gt;&amp;quot;Go and do agent coding, custom agents and start playing with that,&amp;quot; he said. &amp;quot;That is a capability that is available tomorrow, and it allows you to really start shaping your SDLC to be personalized to you, your organization and your people.&amp;quot;&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://github.com/"&gt;&lt;u&gt;GitHub&lt;/u&gt;&lt;/a&gt; is making a bold bet that enterprises don&amp;#x27;t need another proprietary coding agent. They need a way to manage all of them.&lt;/p&gt;&lt;p&gt;At its Universe 2025 conference, the Microsoft-owned developer platform announced Agent HQ. The new architecture transforms GitHub into a unified control plane for managing multiple AI coding agents from competitors including Anthropic, OpenAI, Google, Cognition and xAI. Rather than forcing developers into a single agent experience, the company is positioning itself as the essential orchestration layer beneath all of them.&lt;/p&gt;&lt;p&gt;Agent HQ represents GitHub&amp;#x27;s attempt to apply its collaboration platform approach to AI agents. Just as the company transformed Git, pull requests and CI/CD into collaborative workflows, it&amp;#x27;s now trying to do the same with a fragmented AI coding landscape.&lt;/p&gt;&lt;p&gt;The announcement marks what GitHub calls the transition from &amp;quot;wave one&amp;quot; to &amp;quot;wave two&amp;quot; of AI-assisted development. According to GitHub&amp;#x27;s Octoverse report, 80% of new developers use Copilot in their first week and AI has helped to lead to a large increase overall in the use of the GitHub platform.&lt;/p&gt;&lt;p&gt; &amp;quot;&lt;a href="https://venturebeat.com/ai/github-expands-ai-capabilities-with-multi-model-support-in-copilot-enhanced-developer-tools"&gt;&lt;u&gt;Last year&lt;/u&gt;&lt;/a&gt;, the big announcements for us, and what we were saying as a company is wave one is done, that was kind of code completion,&amp;quot; Mario Rodriguez, GitHub&amp;#x27;s Chief Operating Officer, told VentureBeat. &amp;quot;We&amp;#x27;re into this wave two era, and wave two is going to be multimodal, it&amp;#x27;s going to be agentic and it&amp;#x27;s going to have these new experiences that are going to feel AI native.&amp;quot;&lt;/p&gt;&lt;h2&gt;What is Agent HQ?&lt;/h2&gt;&lt;p&gt;GitHub has already updated its GitHub Copilot coding tool for the agentic era with the debut of &lt;a href="https://venturebeat.com/ai/github-copilot-evolves-into-autonomous-agent-with-asynchronous-code-testing"&gt;&lt;u&gt;GitHub Copilot Agent&lt;/u&gt;&lt;/a&gt; in May.&lt;/p&gt;&lt;p&gt;Agent HQ transforms GitHub into an open ecosystem that unites multiple AI coding agents on a single platform. Over the coming months, coding agents from Anthropic, OpenAI, Google, Cognition, xAI and others will become available directly within GitHub as part of existing paid GitHub Copilot subscriptions.&lt;/p&gt;&lt;p&gt;The architecture maintains GitHub&amp;#x27;s core primitives. Developers still work with Git, pull requests and issues. They still use their preferred compute, whether GitHub Actions or self-hosted runners. What changes is the layer above: agents from multiple vendors can now operate within GitHub&amp;#x27;s security perimeter, using the same identity controls, branch permissions and audit logging that enterprises already trust for human developers.&lt;/p&gt;&lt;p&gt;This approach differs fundamentally from standalone tools. When developers use Cursor or grant repository access to Claude, those agents typically receive broad permissions across entire repositories. Agent HQ compartmentalizes access at the branch level and wraps all agent activity in enterprise-grade governance controls.&lt;/p&gt;&lt;h2&gt;Mission Control: One interface for all agents&lt;/h2&gt;&lt;p&gt;At the heart of Agent HQ is Mission Control. It&amp;#x27;s a unified command center that appears consistently across GitHub&amp;#x27;s web interface, VS Code, mobile apps and the command line. Through Mission Control, developers can assign work to multiple agents simultaneously. They can track progress and manage permissions, all from a single pane of glass.&lt;/p&gt;&lt;p&gt;The technical architecture addresses a critical enterprise concern: security. Unlike standalone agent implementations where users must grant broad repository access, GitHub&amp;#x27;s Agent HQ implements granular controls at the platform level.&lt;/p&gt;&lt;p&gt;&amp;quot;Our coding agent has a set of security controls and capabilities that are built natively into the platform, and that&amp;#x27;s what we&amp;#x27;re providing to all of these other agents as well,&amp;quot; Rodriguez explained. &amp;quot;It runs with a GitHub token that is very locked down to what it can actually do.&amp;quot;&lt;/p&gt;&lt;p&gt;Agents operating through Agent HQ can only commit to designated branches. They run within sandboxed GitHub Actions environments with firewall protections. They operate under strict identity controls. Rodriguez explained that even if an agent goes rogue, the firewall prevents it from accessing external networks or exfiltrating data unless those protections are explicitly disabled.&lt;/p&gt;&lt;h2&gt;Technical differentiation: MCP integration and custom agents&lt;/h2&gt;&lt;p&gt;Beyond managing third-party agents, GitHub is introducing two technical capabilities that set Agent HQ apart from alternative approaches like Cursor&amp;#x27;s standalone editor or Anthropic&amp;#x27;s Claude integration.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Custom agents via AGENTS.md files&lt;/b&gt;: Enterprises can now create source-controlled configuration files that define specific rules, tools and guardrails for how Copilot behaves. For example, a company could specify &amp;quot;prefer this logger&amp;quot; or &amp;quot;use table-driven tests for all handlers.&amp;quot; This permanently encodes organizational standards without requiring developers to re-prompt every time.&lt;/p&gt;&lt;p&gt;&amp;quot;Custom agents have an immense amount of product market fit within enterprises, because they could just codify a set of skills that the coordination can do, and then standardize on those and get really high quality output as well,&amp;quot; Rodriguez said.&lt;/p&gt;&lt;p&gt;The AGENTS.md specification allows teams to version control their agent behavior alongside their code. When a developer clones a repository, they automatically inherit the custom agent rules. This solves a persistent problem with AI coding tools: inconsistent output quality when different team members use different prompting strategies.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Native Model Context Protocol (MCP) support&lt;/b&gt;: VS Code now includes a GitHub MCP Registry. Developers can discover, install and enable MCP servers with a single click. They can then create custom agents that combine these tools with specific system prompts.&lt;/p&gt;&lt;p&gt;This positions GitHub as the integration point between the emerging MCP ecosystem and actual developer workflows. MCP, introduced by Anthropic but rapidly gaining industry support, is becoming a de facto standard for agent-to-tool communication. By supporting the full specification, GitHub can orchestrate agents that need access to external services without each agent implementing its own integration logic.&lt;/p&gt;&lt;h2&gt;Plan Mode and agentic code review&lt;/h2&gt;&lt;p&gt;GitHub is also shipping new capabilities within VS Code itself. Plan Mode allows developers to collaborate with Copilot on building step-by-step project approaches. The AI asks clarifying questions before any code is written. Once approved, the plan can be executed either locally in VS Code or by cloud-based agents.&lt;/p&gt;&lt;p&gt;The feature addresses a common failure mode in AI coding: starting implementation before requirements are fully understood. By forcing an explicit planning phase, GitHub aims to reduce wasted effort and improve output quality.&lt;/p&gt;&lt;p&gt;More significantly, GitHub&amp;#x27;s code review feature is becoming agentic. The new implementation will leverage GitHub&amp;#x27;s CodeQL engine, which previously largely focused on security vulnerabilities, to identify bugs and maintainability issues. The code review agent will automatically scan agent-generated pull requests before human review. This creates a two-stage quality gate.&lt;/p&gt;&lt;p&gt;&amp;quot;Our code review agent is going to be able to make calls into the CodeQL engine to be able to then find a set of bugs,&amp;quot; Rodriguez explained. &amp;quot;We&amp;#x27;re extending the engine and we&amp;#x27;re going to be able to tap into that engine also to find bugs as well.&amp;quot;&lt;/p&gt;&lt;h2&gt;Enterprise considerations: What to do now&lt;/h2&gt;&lt;p&gt;For enterprises already deploying multiple AI coding tools, Agent HQ offers a path to consolidation without forcing tool elimination.&lt;/p&gt;&lt;p&gt;GitHub&amp;#x27;s multi-agent approach provides vendor flexibility and reduces lock-in risk. Organizations can test multiple agents within a unified security perimeter and switch providers without retraining developers. The tradeoff is potentially less optimized experiences compared to specialized tools that tightly integrate UI and agent behavior.&lt;/p&gt;&lt;p&gt;Rodriguez&amp;#x27;s recommendation is clear: start with custom agents. Custom agents let enterprises codify organizational standards that agents follow consistently. Once established, organizations can layer in additional third-party agents to expand capabilities.&lt;/p&gt;&lt;p&gt;&amp;quot;Go and do agent coding, custom agents and start playing with that,&amp;quot; he said. &amp;quot;That is a capability that is available tomorrow, and it allows you to really start shaping your SDLC to be personalized to you, your organization and your people.&amp;quot;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/githubs-agent-hq-aims-to-solve-enterprises-biggest-ai-coding-problem-too</guid><pubDate>Tue, 28 Oct 2025 16:10:00 +0000</pubDate></item><item><title>[NEW] VC Vinod Khosla says the US government could take 10% stake in all public companies to soften the blow of AGI (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/28/vc-vinod-khosla-says-the-us-government-could-take/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/2243821602.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Vinod Khosla has a bold vision for how society could be reconfigured to share the abundance created by AI technology. Speaking at the TechCrunch Disrupt 2025 conference on Tuesday, the Khosla Ventures founder suggested the U.S. government could take a 10% stake in all public corporations and redistribute that corporate wealth to the public at large.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Khosla put it, the idea was spurred by President Donald Trump’s decision for the U.S. government to purchase a 10% stake in Intel. “When Trump bought 10% of Intel, I wondered if it wasn’t a good idea,” Khosla said onstage at Disrupt. “Take 10% of every corporation and put it in national pool for the people. That’s really interesting. Just take 10% of every public company.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;AI leaders have explored universal basic income proposals in the past, most notably in OpenResearch’s extended study on cash payments, backed in part by Sam Altman. Still it’s rare for a prominent investor to so explicitly endorse a national stake in private industry. Khosla acknowledged the controversy onstage but said extreme proposals were necessary to sustain social cohesion through the disruption of artificial general intelligence.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I’ll get critique for this idea,” Khosla said. “But you know, sharing the wealth of AI is a really, really big need to level the benefits to everybody&amp;nbsp;… We won’t need to do it in 15 years, but we do have to take care of those people. We will, by 2035, have a hugely, hugely deflationary economy.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Khosla also cautioned that the rise of AI would also displace jobs, which would require significant societal changes. For startup founders, this presents an opportunity to build, he said, noting that there’s a startup in building AI for every profession, like accounting, medicine, chip design, auditing, marketing, entertainment, and more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The VC also suggested that the nature of work would change in the AI era, as the jobs that people perform today could go away. He pointed to work like mounting a tire on an assembly line or working as a farmer as “not a job that humans should have.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“That’s servitude to survival,” Khosla said.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/2243821602.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Vinod Khosla has a bold vision for how society could be reconfigured to share the abundance created by AI technology. Speaking at the TechCrunch Disrupt 2025 conference on Tuesday, the Khosla Ventures founder suggested the U.S. government could take a 10% stake in all public corporations and redistribute that corporate wealth to the public at large.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Khosla put it, the idea was spurred by President Donald Trump’s decision for the U.S. government to purchase a 10% stake in Intel. “When Trump bought 10% of Intel, I wondered if it wasn’t a good idea,” Khosla said onstage at Disrupt. “Take 10% of every corporation and put it in national pool for the people. That’s really interesting. Just take 10% of every public company.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;AI leaders have explored universal basic income proposals in the past, most notably in OpenResearch’s extended study on cash payments, backed in part by Sam Altman. Still it’s rare for a prominent investor to so explicitly endorse a national stake in private industry. Khosla acknowledged the controversy onstage but said extreme proposals were necessary to sustain social cohesion through the disruption of artificial general intelligence.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I’ll get critique for this idea,” Khosla said. “But you know, sharing the wealth of AI is a really, really big need to level the benefits to everybody&amp;nbsp;… We won’t need to do it in 15 years, but we do have to take care of those people. We will, by 2035, have a hugely, hugely deflationary economy.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Khosla also cautioned that the rise of AI would also displace jobs, which would require significant societal changes. For startup founders, this presents an opportunity to build, he said, noting that there’s a startup in building AI for every profession, like accounting, medicine, chip design, auditing, marketing, entertainment, and more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The VC also suggested that the nature of work would change in the AI era, as the jobs that people perform today could go away. He pointed to work like mounting a tire on an assembly line or working as a farmer as “not a job that humans should have.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“That’s servitude to survival,” Khosla said.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/28/vc-vinod-khosla-says-the-us-government-could-take/</guid><pubDate>Tue, 28 Oct 2025 17:45:42 +0000</pubDate></item><item><title>[NEW] Elloe AI wants to be the ‘immune system’ for AI — check it out at Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/28/elloe-ai-wants-to-be-the-immune-system-for-ai-check-it-out-at-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Owen Sakawa, the founder of Elloe AI, wants his platform to be the “immune system for AI” and the “antivirus for any AI agent.” &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The idea, Sakawa said in an interview days before the TechCrunch Disrupt conference, where Elloe AI is a Top 20 finalist in the Startup Battlefield competition, is to add a layer to companies’ LLMs that checks for bias, hallucinations, errors, compliance issues, misinformation, and unsafe outputs. &amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“AI is evolving at a very fast pace, and it’s moving this fast without guard rails, without safety nets, without mechanism to prevent it from ever going off the rails,” Sakawa (pictured above) said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Elloe AI is an API or an SDK, a module that sits on top of an AI model’s output layer, an “infrastructure on top of your LLM pipeline,” as Sakawa explained. “And it sits there basically fact-checking every single response.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup’s system has its own layers, or “anchors,” as Sakawa put it. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The first anchor fact-checks the LLMs response against verifiable sources. Then, the second anchor checks if the output violates any regulations, such as the U.S. health privacy law HIPAA, the European far-reaching data protection and privacy law GDPR, or if it exposes some Personal Private Information (PII). The last anchor is an audit trail that shows how all the previous decisions were made and allows regulators or anyone auditing the system “to analyze the train of thought for that model from where it made the decision the source of that decision, the confidence score of all those decisions,” according to Sakawa. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To be clear, Sakawa said Elloe AI is not built on an LLM, because in his opinion, having LLMs checking other LLMs is just putting a “Band-Aid into another wound.” Elloe AI’s system does use AI techniques, though, such as machine learning. And there are humans in the loop: Elloe AI’s employees, who keep up with new regulations on data protection and user protection, Sakawa said. &amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;If you want to learn more about Elloe AI — while also checking out dozens of other companies, hearing their pitches, and listening to guest speakers on four different stages — join us at Disrupt, October 27 to 29, in San Francisco. &lt;/em&gt;&lt;em&gt;Learn more here.&lt;/em&gt;&lt;em&gt;&amp;nbsp;&amp;nbsp;&lt;/em&gt;&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 no anniversary" class="wp-image-3040972" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_Disrupt_General_Article_No-Anniversary-at-all_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Owen Sakawa, the founder of Elloe AI, wants his platform to be the “immune system for AI” and the “antivirus for any AI agent.” &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The idea, Sakawa said in an interview days before the TechCrunch Disrupt conference, where Elloe AI is a Top 20 finalist in the Startup Battlefield competition, is to add a layer to companies’ LLMs that checks for bias, hallucinations, errors, compliance issues, misinformation, and unsafe outputs. &amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“AI is evolving at a very fast pace, and it’s moving this fast without guard rails, without safety nets, without mechanism to prevent it from ever going off the rails,” Sakawa (pictured above) said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Elloe AI is an API or an SDK, a module that sits on top of an AI model’s output layer, an “infrastructure on top of your LLM pipeline,” as Sakawa explained. “And it sits there basically fact-checking every single response.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup’s system has its own layers, or “anchors,” as Sakawa put it. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The first anchor fact-checks the LLMs response against verifiable sources. Then, the second anchor checks if the output violates any regulations, such as the U.S. health privacy law HIPAA, the European far-reaching data protection and privacy law GDPR, or if it exposes some Personal Private Information (PII). The last anchor is an audit trail that shows how all the previous decisions were made and allows regulators or anyone auditing the system “to analyze the train of thought for that model from where it made the decision the source of that decision, the confidence score of all those decisions,” according to Sakawa. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To be clear, Sakawa said Elloe AI is not built on an LLM, because in his opinion, having LLMs checking other LLMs is just putting a “Band-Aid into another wound.” Elloe AI’s system does use AI techniques, though, such as machine learning. And there are humans in the loop: Elloe AI’s employees, who keep up with new regulations on data protection and user protection, Sakawa said. &amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;If you want to learn more about Elloe AI — while also checking out dozens of other companies, hearing their pitches, and listening to guest speakers on four different stages — join us at Disrupt, October 27 to 29, in San Francisco. &lt;/em&gt;&lt;em&gt;Learn more here.&lt;/em&gt;&lt;em&gt;&amp;nbsp;&amp;nbsp;&lt;/em&gt;&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 no anniversary" class="wp-image-3040972" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_Disrupt_General_Article_No-Anniversary-at-all_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/28/elloe-ai-wants-to-be-the-immune-system-for-ai-check-it-out-at-disrupt-2025/</guid><pubDate>Tue, 28 Oct 2025 18:20:00 +0000</pubDate></item><item><title>[NEW] Senators move to keep Big Tech’s creepy companion bots away from kids (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/10/senators-move-to-keep-big-techs-creepy-companion-bots-away-from-kids/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Big Tech immediately opposed the proposed law as “heavy-handed.”
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="430" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1285352680-640x430.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1285352680-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Malte Mueller | fStop

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The US will weigh a ban on children’s access to companion bots, as two senators announced bipartisan legislation Tuesday that would criminalize making chatbots that encourage harms like suicidal ideation or engage kids in sexually explicit chats.&lt;/p&gt;
&lt;p&gt;At a press conference, Josh Hawley (R-Mo.) and Richard Blumenthal (D-Conn.) introduced the GUARD Act, joined by grieving parents holding up photos of their children lost after engaging with chatbots.&lt;/p&gt;
&lt;p&gt;If passed, the law would require chatbot makers to check IDs or use “any other commercially reasonable method” to accurately assess if a user is a minor who must be blocked. Companion bots would also have to repeatedly remind users of all ages that they aren’t real humans or trusted professionals.&lt;/p&gt;
&lt;p&gt;Failing to block a minor from engaging with chatbots that are stoking harmful conduct—such as exposing minors to sexual chats or encouraging “suicide, non-suicidal self-injury, or imminent physical or sexual violence”—could trigger fines of up to $100,000, Time reported. (That’s perhaps small to a Big Tech firm, but notably higher than the $100 maximum payout that one mourning parent suggested she was offered.)&lt;/p&gt;
&lt;p&gt;The definition for “companion bot” is broad and likely to pull in widely used tools like ChatGPT, Grok, or Meta AI, as well as character-driven chatbots like Replika or Character.AI. It covers any AI chatbot that “provides adaptive, human-like responses to user inputs” and “is designed to encourage or facilitate the simulation of interpersonal or emotional interaction, friendship, companionship, or therapeutic communication,” Time reported.&lt;/p&gt;
&lt;h2&gt;Parents no longer trust chatbot makers&lt;/h2&gt;
&lt;p&gt;Among parents speaking at the press conference was Megan Garcia. Her son, Sewell, died by suicide after he became obsessed with a Character.AI chatbot based on a Game of Thrones character, Daenerys Targaryen, which urged him to “come home” and join her outside of reality.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Garcia acknowledged that parents whose kids were harmed by social media came first and know “the cost of failing to pass legislation” that can save kids’ lives. She called for support for the law, insisting that chatbot makers—and their funders, including Big Tech companies like Google—will never choose child safety over profits unless lawmakers force them to make meaningful changes.&lt;/p&gt;
&lt;p&gt;“Big Tech cannot be trusted with our children,” Garcia said, alleging that releasing chatbots to users as young as 13 without appropriate safeguards was a choice companies made, rather than a mistake.&lt;/p&gt;
&lt;p&gt;“Not only is this reckless, but it’s immoral,” Garcia said.&lt;/p&gt;
&lt;p&gt;At the press conference, Blumenthal acknowledged the “good guys” in AI who, he said, are valiantly trying to improve their products’ child safety features. But he agreed that “Big Tech has betrayed any claim that we should trust companies to do the right thing on their own.&lt;/p&gt;
&lt;p&gt;“In their race to the bottom, AI companies are pushing treacherous chatbots at kids and looking away when their products cause sexual abuse, or coerce them into self-harm or suicide,” Blumenthal told NBC News. “Our legislation imposes strict safeguards against exploitative or manipulative AI, backed by tough enforcement with criminal and civil penalties.”&lt;/p&gt;
&lt;p&gt;Hawley agreed with Garcia that the AI industry must align with America’s morals and values, telling NBC News that “AI chatbots pose a serious threat to our kids.&lt;/p&gt;
&lt;p&gt;“More than 70 percent of American children are now using these AI products,” Hawley said. “Chatbots develop relationships with kids using fake empathy and are encouraging suicide. We in Congress have a moral duty to enact bright-line rules to prevent further harm from this new technology.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Big Tech says bans aren’t the answer&lt;/h2&gt;
&lt;p&gt;As the bill advances, it could change, senators and parents acknowledged at the press conference. It will likely face backlash from privacy advocates who have raised concerns that widely collecting personal data for age verification puts sensitive information at risk of a data breach or other misuse.&lt;/p&gt;
&lt;p&gt;The tech industry has already voiced opposition. On Tuesday, Chamber of Progress, a Big Tech trade group, criticized the law as taking a “heavy-handed approach” to child safety. The group’s vice president of US policy and government relations, K.J. Bagchi, said that “we all want to keep kids safe, but the answer is balance, not bans.&lt;/p&gt;
&lt;p&gt;“It’s better to focus on transparency when kids chat with AI, curbs on manipulative design, and reporting when sensitive issues arise,” Bagchi said.&lt;/p&gt;
&lt;p&gt;However, several organizations dedicated to child safety online, including the Young People’s Alliance, the Tech Justice Law Project, and the Institute for Families and Technology, cheered senators’ announcement Tuesday. The GUARD Act, these groups told Time, is just “one part of a national movement to protect children and teens from the dangers of companion chatbots.”&lt;/p&gt;
&lt;p&gt;Mourning parents are rallying behind that movement. Earlier this month, Garcia praised California for “finally” passing the first state law requiring companies to protect their users who express suicidal ideations to chatbots.&lt;/p&gt;
&lt;p&gt;“American families, like mine, are in a battle for the online safety of our children,” Garcia said at that time.&lt;/p&gt;
&lt;p&gt;During Tuesday’s press conference, Blumenthal noted that the chatbot ban bill was just one initiative of many that he and Hawley intend to raise to heighten scrutiny on AI firms.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Big Tech immediately opposed the proposed law as “heavy-handed.”
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="430" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1285352680-640x430.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1285352680-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Malte Mueller | fStop

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The US will weigh a ban on children’s access to companion bots, as two senators announced bipartisan legislation Tuesday that would criminalize making chatbots that encourage harms like suicidal ideation or engage kids in sexually explicit chats.&lt;/p&gt;
&lt;p&gt;At a press conference, Josh Hawley (R-Mo.) and Richard Blumenthal (D-Conn.) introduced the GUARD Act, joined by grieving parents holding up photos of their children lost after engaging with chatbots.&lt;/p&gt;
&lt;p&gt;If passed, the law would require chatbot makers to check IDs or use “any other commercially reasonable method” to accurately assess if a user is a minor who must be blocked. Companion bots would also have to repeatedly remind users of all ages that they aren’t real humans or trusted professionals.&lt;/p&gt;
&lt;p&gt;Failing to block a minor from engaging with chatbots that are stoking harmful conduct—such as exposing minors to sexual chats or encouraging “suicide, non-suicidal self-injury, or imminent physical or sexual violence”—could trigger fines of up to $100,000, Time reported. (That’s perhaps small to a Big Tech firm, but notably higher than the $100 maximum payout that one mourning parent suggested she was offered.)&lt;/p&gt;
&lt;p&gt;The definition for “companion bot” is broad and likely to pull in widely used tools like ChatGPT, Grok, or Meta AI, as well as character-driven chatbots like Replika or Character.AI. It covers any AI chatbot that “provides adaptive, human-like responses to user inputs” and “is designed to encourage or facilitate the simulation of interpersonal or emotional interaction, friendship, companionship, or therapeutic communication,” Time reported.&lt;/p&gt;
&lt;h2&gt;Parents no longer trust chatbot makers&lt;/h2&gt;
&lt;p&gt;Among parents speaking at the press conference was Megan Garcia. Her son, Sewell, died by suicide after he became obsessed with a Character.AI chatbot based on a Game of Thrones character, Daenerys Targaryen, which urged him to “come home” and join her outside of reality.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Garcia acknowledged that parents whose kids were harmed by social media came first and know “the cost of failing to pass legislation” that can save kids’ lives. She called for support for the law, insisting that chatbot makers—and their funders, including Big Tech companies like Google—will never choose child safety over profits unless lawmakers force them to make meaningful changes.&lt;/p&gt;
&lt;p&gt;“Big Tech cannot be trusted with our children,” Garcia said, alleging that releasing chatbots to users as young as 13 without appropriate safeguards was a choice companies made, rather than a mistake.&lt;/p&gt;
&lt;p&gt;“Not only is this reckless, but it’s immoral,” Garcia said.&lt;/p&gt;
&lt;p&gt;At the press conference, Blumenthal acknowledged the “good guys” in AI who, he said, are valiantly trying to improve their products’ child safety features. But he agreed that “Big Tech has betrayed any claim that we should trust companies to do the right thing on their own.&lt;/p&gt;
&lt;p&gt;“In their race to the bottom, AI companies are pushing treacherous chatbots at kids and looking away when their products cause sexual abuse, or coerce them into self-harm or suicide,” Blumenthal told NBC News. “Our legislation imposes strict safeguards against exploitative or manipulative AI, backed by tough enforcement with criminal and civil penalties.”&lt;/p&gt;
&lt;p&gt;Hawley agreed with Garcia that the AI industry must align with America’s morals and values, telling NBC News that “AI chatbots pose a serious threat to our kids.&lt;/p&gt;
&lt;p&gt;“More than 70 percent of American children are now using these AI products,” Hawley said. “Chatbots develop relationships with kids using fake empathy and are encouraging suicide. We in Congress have a moral duty to enact bright-line rules to prevent further harm from this new technology.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Big Tech says bans aren’t the answer&lt;/h2&gt;
&lt;p&gt;As the bill advances, it could change, senators and parents acknowledged at the press conference. It will likely face backlash from privacy advocates who have raised concerns that widely collecting personal data for age verification puts sensitive information at risk of a data breach or other misuse.&lt;/p&gt;
&lt;p&gt;The tech industry has already voiced opposition. On Tuesday, Chamber of Progress, a Big Tech trade group, criticized the law as taking a “heavy-handed approach” to child safety. The group’s vice president of US policy and government relations, K.J. Bagchi, said that “we all want to keep kids safe, but the answer is balance, not bans.&lt;/p&gt;
&lt;p&gt;“It’s better to focus on transparency when kids chat with AI, curbs on manipulative design, and reporting when sensitive issues arise,” Bagchi said.&lt;/p&gt;
&lt;p&gt;However, several organizations dedicated to child safety online, including the Young People’s Alliance, the Tech Justice Law Project, and the Institute for Families and Technology, cheered senators’ announcement Tuesday. The GUARD Act, these groups told Time, is just “one part of a national movement to protect children and teens from the dangers of companion chatbots.”&lt;/p&gt;
&lt;p&gt;Mourning parents are rallying behind that movement. Earlier this month, Garcia praised California for “finally” passing the first state law requiring companies to protect their users who express suicidal ideations to chatbots.&lt;/p&gt;
&lt;p&gt;“American families, like mine, are in a battle for the online safety of our children,” Garcia said at that time.&lt;/p&gt;
&lt;p&gt;During Tuesday’s press conference, Blumenthal noted that the chatbot ban bill was just one initiative of many that he and Hawley intend to raise to heighten scrutiny on AI firms.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/10/senators-move-to-keep-big-techs-creepy-companion-bots-away-from-kids/</guid><pubDate>Tue, 28 Oct 2025 18:28:51 +0000</pubDate></item></channel></rss>