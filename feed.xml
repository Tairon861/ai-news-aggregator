<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 07 Oct 2025 06:31:15 +0000</lastBuildDate><item><title>MrBeast says AI could threaten creators’ livelihoods, calling it ‘scary times’ for the industry (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/06/mrbeast-says-ai-could-threaten-creators-livelihoods-calling-it-scary-times-for-the-industry/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/Beast-Games-Suit-Arms-Crossed.jpg?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Top YouTube creator MrBeast is worried about AI’s impact on creators’ livelihoods, despite having dabbled with using the technology himself. On Monday, the creator posted his concerns on social media, where he openly wondered how AI-generated videos could affect the “millions of creators currently making content for a living.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Scary times,” he added.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;MrBeast, whose real name is Jimmy Donaldson, is No. 1 on Forbes’ 2025 list of top creators, with $85 million in earnings and 634 million followers. What he says and does, as a result of his position, has an outsized influence across the industry. So if MrBeast is openly questioning whether AI is an existential threat to his business and others like it, then it’s fair to say that smaller creators are likely even more worried.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;His comments follow the recent launch of OpenAI’s Sora 2, a new version of its audio and video generator, alongside a mobile app that lets users create AI, including videos of themselves, which are shared in a TikTok-style vertical feed. The app has been an early hit, quickly hitting No. 1 on the U.S. App Store after a surge of downloads.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube has also embraced AI, launching things like AI editing tools, including those that let creators generate AI videos using its video model Veo to animate still photos or apply different styles to their videos. The company has infused AI into its product as well, for things like making clips or highlights from Live videos or podcasts. An AI chatbot can answer creators’ questions inside YouTube’s channel management software, YouTube Studio.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;MrBeast has also involved himself with AI, as commenters were quick to point out. The creator this summer faced a fair bit of backlash from fans and creators alike after releasing a tool that used AI to create video thumbnails. He quickly removed the tool from his analytics platform, Viewstats, and said he’d replace it with links to human artists available for commission.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;His company’s philanthropy arm has also made AI investments at times.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;There is still debate as to whether the novelty of AI video creation will turn everyone into a creator, or if the best videos will still need a human’s creative mind to think them up and then prompt the tool correctly. At the same time, there are those who view AI videos as low-quality content, often dubbed “slop,” and dislike seeing it in their feeds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even if the AI becomes undetectable at some point in the future, it’s possible that creators revealed to be using it without disclosure could lose their fans’ trust and harm their reputation. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/Beast-Games-Suit-Arms-Crossed.jpg?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Top YouTube creator MrBeast is worried about AI’s impact on creators’ livelihoods, despite having dabbled with using the technology himself. On Monday, the creator posted his concerns on social media, where he openly wondered how AI-generated videos could affect the “millions of creators currently making content for a living.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Scary times,” he added.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;MrBeast, whose real name is Jimmy Donaldson, is No. 1 on Forbes’ 2025 list of top creators, with $85 million in earnings and 634 million followers. What he says and does, as a result of his position, has an outsized influence across the industry. So if MrBeast is openly questioning whether AI is an existential threat to his business and others like it, then it’s fair to say that smaller creators are likely even more worried.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;His comments follow the recent launch of OpenAI’s Sora 2, a new version of its audio and video generator, alongside a mobile app that lets users create AI, including videos of themselves, which are shared in a TikTok-style vertical feed. The app has been an early hit, quickly hitting No. 1 on the U.S. App Store after a surge of downloads.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube has also embraced AI, launching things like AI editing tools, including those that let creators generate AI videos using its video model Veo to animate still photos or apply different styles to their videos. The company has infused AI into its product as well, for things like making clips or highlights from Live videos or podcasts. An AI chatbot can answer creators’ questions inside YouTube’s channel management software, YouTube Studio.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;MrBeast has also involved himself with AI, as commenters were quick to point out. The creator this summer faced a fair bit of backlash from fans and creators alike after releasing a tool that used AI to create video thumbnails. He quickly removed the tool from his analytics platform, Viewstats, and said he’d replace it with links to human artists available for commission.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;His company’s philanthropy arm has also made AI investments at times.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;There is still debate as to whether the novelty of AI video creation will turn everyone into a creator, or if the best videos will still need a human’s creative mind to think them up and then prompt the tool correctly. At the same time, there are those who view AI videos as low-quality content, often dubbed “slop,” and dislike seeing it in their feeds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even if the AI becomes undetectable at some point in the future, it’s possible that creators revealed to be using it without disclosure could lose their fans’ trust and harm their reputation. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/06/mrbeast-says-ai-could-threaten-creators-livelihoods-calling-it-scary-times-for-the-industry/</guid><pubDate>Mon, 06 Oct 2025 19:05:20 +0000</pubDate></item><item><title>OpenAI ramps up developer push with more powerful models in its API (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/06/openai-ramps-up-developer-push-with-more-powerful-models-in-its-api/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/Screenshot-2025-10-06-at-3.05.51PM.png?resize=1200,527" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI&amp;nbsp;unveiled&amp;nbsp;new API updates&amp;nbsp;at its Dev Day on Monday,&amp;nbsp;introducing GPT-5 Pro,&amp;nbsp;its latest language model,&amp;nbsp;its new video generation model&amp;nbsp;Sora 2, and a smaller, cheaper voice model.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The updates were part of a series of&amp;nbsp;announcements&amp;nbsp;geared toward wooing developers to OpenAI’s ecosystem, including the launch of an&amp;nbsp;agent-building tool&amp;nbsp;and the&amp;nbsp;ability to build apps in ChatGPT.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The addition of GPT-5 Pro might appeal to developers building applications in finance, legal, and healthcare — industries that need “high accuracy and depth of reasoning,” per OpenAI CEO Sam Altman.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman also noted that voice capabilities will be essential in the future as it quickly becomes one of the primary ways people use to interact with AI.&amp;nbsp;To that end, OpenAI is&amp;nbsp;launching&amp;nbsp;“gpt-realtime&amp;nbsp;mini,”&amp;nbsp;a&amp;nbsp;smaller, cheaper&amp;nbsp;voice model&amp;nbsp;in API&amp;nbsp;that supports low-latency streaming interactions for audio and speech.&amp;nbsp;The new model is 70% cheaper than&amp;nbsp;OpenAI’s&amp;nbsp;previous&amp;nbsp;advanced voice model&amp;nbsp;but&amp;nbsp;promises the “same voice quality and expressiveness.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Finally, creators involved in OpenAI’s developer ecosystem can&amp;nbsp;now&amp;nbsp;tap into Sora 2 in preview in the API. OpenAI released Sora 2, its latest audio and video generator, last week alongside the Sora app,&amp;nbsp;a TikTok competitor&amp;nbsp;filled with&amp;nbsp;short AI-generated videos. The Sora app allows users to generate videos of themselves, friends, or anything based on a&amp;nbsp;prompt, and share it via a TikTok-style algorithmic feed.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“[Developers] now have access to the same model that powers Sora 2’s stunning video outputs right in your own app,” Altman said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sora 2 builds on its&amp;nbsp;previous&amp;nbsp;generation with more realistic, physically consistent scenes with synchronized sound and greater creative control — from detailed camera direction to stylized visuals.&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“For example, you can take the iPhone view and prompt Sora to expand it into a sweeping, cinematic wide shot,” Altman said.&amp;nbsp;“But one of the most exciting things that&amp;nbsp;we’ve been working on is how well this new model pairs sound with visuals, not just speech, but rich soundscapes, ambient audio, synchronized effects that are grounded in what you’re seeing.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sora 2 is pitched as a tool for concept development, whether it’s a visual starting point for an ad based on the general vibe of a product, or a Mattel designer turning a sketch into a toy concept&amp;nbsp;— an example Altman provided at Dev Day that sheds light on&amp;nbsp;OpenAI’s deal with the Barbie-maker&amp;nbsp;to bring generative AI into the toy-making pipeline.&amp;nbsp;&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/Screenshot-2025-10-06-at-3.05.51PM.png?resize=1200,527" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI&amp;nbsp;unveiled&amp;nbsp;new API updates&amp;nbsp;at its Dev Day on Monday,&amp;nbsp;introducing GPT-5 Pro,&amp;nbsp;its latest language model,&amp;nbsp;its new video generation model&amp;nbsp;Sora 2, and a smaller, cheaper voice model.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The updates were part of a series of&amp;nbsp;announcements&amp;nbsp;geared toward wooing developers to OpenAI’s ecosystem, including the launch of an&amp;nbsp;agent-building tool&amp;nbsp;and the&amp;nbsp;ability to build apps in ChatGPT.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The addition of GPT-5 Pro might appeal to developers building applications in finance, legal, and healthcare — industries that need “high accuracy and depth of reasoning,” per OpenAI CEO Sam Altman.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman also noted that voice capabilities will be essential in the future as it quickly becomes one of the primary ways people use to interact with AI.&amp;nbsp;To that end, OpenAI is&amp;nbsp;launching&amp;nbsp;“gpt-realtime&amp;nbsp;mini,”&amp;nbsp;a&amp;nbsp;smaller, cheaper&amp;nbsp;voice model&amp;nbsp;in API&amp;nbsp;that supports low-latency streaming interactions for audio and speech.&amp;nbsp;The new model is 70% cheaper than&amp;nbsp;OpenAI’s&amp;nbsp;previous&amp;nbsp;advanced voice model&amp;nbsp;but&amp;nbsp;promises the “same voice quality and expressiveness.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Finally, creators involved in OpenAI’s developer ecosystem can&amp;nbsp;now&amp;nbsp;tap into Sora 2 in preview in the API. OpenAI released Sora 2, its latest audio and video generator, last week alongside the Sora app,&amp;nbsp;a TikTok competitor&amp;nbsp;filled with&amp;nbsp;short AI-generated videos. The Sora app allows users to generate videos of themselves, friends, or anything based on a&amp;nbsp;prompt, and share it via a TikTok-style algorithmic feed.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“[Developers] now have access to the same model that powers Sora 2’s stunning video outputs right in your own app,” Altman said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sora 2 builds on its&amp;nbsp;previous&amp;nbsp;generation with more realistic, physically consistent scenes with synchronized sound and greater creative control — from detailed camera direction to stylized visuals.&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“For example, you can take the iPhone view and prompt Sora to expand it into a sweeping, cinematic wide shot,” Altman said.&amp;nbsp;“But one of the most exciting things that&amp;nbsp;we’ve been working on is how well this new model pairs sound with visuals, not just speech, but rich soundscapes, ambient audio, synchronized effects that are grounded in what you’re seeing.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sora 2 is pitched as a tool for concept development, whether it’s a visual starting point for an ad based on the general vibe of a product, or a Mattel designer turning a sketch into a toy concept&amp;nbsp;— an example Altman provided at Dev Day that sheds light on&amp;nbsp;OpenAI’s deal with the Barbie-maker&amp;nbsp;to bring generative AI into the toy-making pipeline.&amp;nbsp;&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/06/openai-ramps-up-developer-push-with-more-powerful-models-in-its-api/</guid><pubDate>Mon, 06 Oct 2025 19:10:27 +0000</pubDate></item><item><title>OpenAI wants to make ChatGPT into a universal app frontend (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/10/openai-wants-to-make-chatgpt-into-a-universal-app-frontend/</link><description>&lt;article class="double-column h-entry post-2120929 post type-post status-publish format-standard has-post-thumbnail hentry category-ai tag-apps tag-canva tag-chatgpt tag-dev-days tag-figma tag-openai tag-sdk tag-spotify tag-zillow"&gt;
  
  &lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Spotify, Canva, Zillow among today's launch partners, more coming later this year.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="383" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/appgpt-640x383.png" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/appgpt-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      OpenAI's Alexi Christakis shows Figma-generated posters being generated within a ChatGPT conversation window.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;At an OpenAI Dev Days keynote today, CEO Sam Altman announced that the company is launching an SDK preview that will allow developers the ability "to build real apps inside of ChatGPT." Altman said that, starting today, the new SDK will give developers "full stack" control over app data, action triggers, and even interactive user interfaces for apps that can appear inline as part of an existing ChatGPT conversation window.&lt;/p&gt;
&lt;p&gt;The SDK is built on the open source Model Context Protocol (MCP), Altman said. That means developers that already use MCP only need to add an HTML resource to enable ChatGPT integration, he added.&lt;/p&gt;
&lt;p&gt;The new integration means a ChatGPT user can directly ask Figma to turn a sketch into a diagram, for instance, and get results integrated into their ChatGPT conversation. It also means that ChatGPT can suggest apps that might be suited to a more general query, like recommending and creating a Spotify playlist when someone asks for song suggestions.&lt;/p&gt;
&lt;p&gt;In a live onstage demo, OpenAI software engineer Alexi Christakis showed how the new API can "expose context back to ChatGPT from your app," a process he likened to ChatGPT "talking to apps." For instance, the LLM can expand in real time on what's being said in an embedded Coursera video. "I don't need to explain what I'm seeing in the video, ChatGPT sees it right away," Christakis said on stage.&lt;/p&gt;
&lt;p&gt;Other onstage demos showed off ChatGPT using Canva to generate poster ideas in the background while the user consulted an inline Zillow map for information. Even when the Zillow window was expanded to full screen, the user could ask ChatGPT for additional context via an overlaid chat window.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;While Altman mentioned an "agentic commerce protocol" that will allow app users to enjoy "instant checkout" from within ChatGPT, he later clarified that details on monetization will only be available "soon."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2120934 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="900" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/appgpt2.png" width="2523" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A full list of third-party apps that will be integrated into ChatGPT in the coming weeks.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;In addition to the apps mentioned above, others like Expedia and Booking.com will be available in ChatGPT starting today. Apps from other launch partners including Peloton, Target, Uber, and Doordash will be available inside ChatGPT "in the weeks ahead."&lt;/p&gt;
&lt;p&gt;Other developers can start building with the SDK today before submitting them to OpenAI for review and publication within ChatGPT "later this year." Altman said that apps that meet a certain set of "developer guidelines" will be listed in a comprehensive directory, while those meeting "higher standards for design and functionality will be featured more prominently."&lt;/p&gt;
&lt;h2&gt;AgentKit and API updates&lt;/h2&gt;
&lt;p&gt;Elsewhere in the keynote, Altman announced AgentKit, a new tool designed to let OpenAI users create specialized interactive chatbots using a simplified building block GUI interface. The new software includes integrated tools for measuring performance and testing workflows from within the ChatKit interface.&lt;/p&gt;
&lt;p&gt;In a live demo, OpenAI platform experience specialist Christina Huang gave herself an eight-minute deadline to use AgentKit to create a live, customized question-answering "Ask Froge" chatbot for the Dev Day website. While that demo was done with time to spare, Huang did make use of a lot of pre-built "widgets" and documents full of prepopulated information about the event to streamline the chatbot's creation.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      OpenAI's Dev Days keynote in full.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;The keynote also announced minor updates for OpenAI's codex coding agent, including integration with Slack and a new SDK to allow for easier integration into existing coding workflows. Altman also announced some recent models would be newly available to users via API, including Sora 2, GPT5-Pro, and a new smaller, cheaper version of the company's real-time audio interface.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
  &lt;/article&gt;&lt;article class="comment-pick"&gt;
          &lt;header&gt;
            &lt;span class="ars-avatar" style="color: #8c9eff; background-color: #1a237e;"&gt;&lt;span class="ars-avatar-letter"&gt;t&lt;/span&gt;&lt;/span&gt;

            &lt;div class="text-base font-bold sm:text-xl"&gt;
              timby
            &lt;/div&gt;
          &lt;/header&gt;

          &lt;div class="comments-pick-content"&gt;
            So ... this is OpenAI's attempt at creating, would you say, an "everything" app?&lt;p&gt;Man, if we thought Elon hated Sam Altman &lt;i&gt;already&lt;/i&gt;, we haven't seen &lt;i&gt;anything&lt;/i&gt; yet.
          &lt;/p&gt;&lt;/div&gt;

          &lt;div class="comments-pick-timestamp"&gt;
            
              &lt;time datetime="2025-10-06T19:29:18+00:00"&gt;October 6, 2025 at 7:29 pm&lt;/time&gt;
            
          &lt;/div&gt;
        &lt;/article&gt;</description><content:encoded>&lt;article class="double-column h-entry post-2120929 post type-post status-publish format-standard has-post-thumbnail hentry category-ai tag-apps tag-canva tag-chatgpt tag-dev-days tag-figma tag-openai tag-sdk tag-spotify tag-zillow"&gt;
  
  &lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Spotify, Canva, Zillow among today's launch partners, more coming later this year.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="383" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/appgpt-640x383.png" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/appgpt-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      OpenAI's Alexi Christakis shows Figma-generated posters being generated within a ChatGPT conversation window.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;At an OpenAI Dev Days keynote today, CEO Sam Altman announced that the company is launching an SDK preview that will allow developers the ability "to build real apps inside of ChatGPT." Altman said that, starting today, the new SDK will give developers "full stack" control over app data, action triggers, and even interactive user interfaces for apps that can appear inline as part of an existing ChatGPT conversation window.&lt;/p&gt;
&lt;p&gt;The SDK is built on the open source Model Context Protocol (MCP), Altman said. That means developers that already use MCP only need to add an HTML resource to enable ChatGPT integration, he added.&lt;/p&gt;
&lt;p&gt;The new integration means a ChatGPT user can directly ask Figma to turn a sketch into a diagram, for instance, and get results integrated into their ChatGPT conversation. It also means that ChatGPT can suggest apps that might be suited to a more general query, like recommending and creating a Spotify playlist when someone asks for song suggestions.&lt;/p&gt;
&lt;p&gt;In a live onstage demo, OpenAI software engineer Alexi Christakis showed how the new API can "expose context back to ChatGPT from your app," a process he likened to ChatGPT "talking to apps." For instance, the LLM can expand in real time on what's being said in an embedded Coursera video. "I don't need to explain what I'm seeing in the video, ChatGPT sees it right away," Christakis said on stage.&lt;/p&gt;
&lt;p&gt;Other onstage demos showed off ChatGPT using Canva to generate poster ideas in the background while the user consulted an inline Zillow map for information. Even when the Zillow window was expanded to full screen, the user could ask ChatGPT for additional context via an overlaid chat window.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;While Altman mentioned an "agentic commerce protocol" that will allow app users to enjoy "instant checkout" from within ChatGPT, he later clarified that details on monetization will only be available "soon."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2120934 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="900" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/appgpt2.png" width="2523" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A full list of third-party apps that will be integrated into ChatGPT in the coming weeks.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;In addition to the apps mentioned above, others like Expedia and Booking.com will be available in ChatGPT starting today. Apps from other launch partners including Peloton, Target, Uber, and Doordash will be available inside ChatGPT "in the weeks ahead."&lt;/p&gt;
&lt;p&gt;Other developers can start building with the SDK today before submitting them to OpenAI for review and publication within ChatGPT "later this year." Altman said that apps that meet a certain set of "developer guidelines" will be listed in a comprehensive directory, while those meeting "higher standards for design and functionality will be featured more prominently."&lt;/p&gt;
&lt;h2&gt;AgentKit and API updates&lt;/h2&gt;
&lt;p&gt;Elsewhere in the keynote, Altman announced AgentKit, a new tool designed to let OpenAI users create specialized interactive chatbots using a simplified building block GUI interface. The new software includes integrated tools for measuring performance and testing workflows from within the ChatKit interface.&lt;/p&gt;
&lt;p&gt;In a live demo, OpenAI platform experience specialist Christina Huang gave herself an eight-minute deadline to use AgentKit to create a live, customized question-answering "Ask Froge" chatbot for the Dev Day website. While that demo was done with time to spare, Huang did make use of a lot of pre-built "widgets" and documents full of prepopulated information about the event to streamline the chatbot's creation.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      OpenAI's Dev Days keynote in full.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;The keynote also announced minor updates for OpenAI's codex coding agent, including integration with Slack and a new SDK to allow for easier integration into existing coding workflows. Altman also announced some recent models would be newly available to users via API, including Sora 2, GPT5-Pro, and a new smaller, cheaper version of the company's real-time audio interface.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
  &lt;/article&gt;&lt;article class="comment-pick"&gt;
          &lt;header&gt;
            &lt;span class="ars-avatar" style="color: #8c9eff; background-color: #1a237e;"&gt;&lt;span class="ars-avatar-letter"&gt;t&lt;/span&gt;&lt;/span&gt;

            &lt;div class="text-base font-bold sm:text-xl"&gt;
              timby
            &lt;/div&gt;
          &lt;/header&gt;

          &lt;div class="comments-pick-content"&gt;
            So ... this is OpenAI's attempt at creating, would you say, an "everything" app?&lt;p&gt;Man, if we thought Elon hated Sam Altman &lt;i&gt;already&lt;/i&gt;, we haven't seen &lt;i&gt;anything&lt;/i&gt; yet.
          &lt;/p&gt;&lt;/div&gt;

          &lt;div class="comments-pick-timestamp"&gt;
            
              &lt;time datetime="2025-10-06T19:29:18+00:00"&gt;October 6, 2025 at 7:29 pm&lt;/time&gt;
            
          &lt;/div&gt;
        &lt;/article&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/10/openai-wants-to-make-chatgpt-into-a-universal-app-frontend/</guid><pubDate>Mon, 06 Oct 2025 19:10:44 +0000</pubDate></item><item><title>Taylor Swift fans accuse singer of using AI in her Google scavenger hunt videos (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/06/taylor-swift-fans-accuse-singer-of-using-ai-in-her-google-scavenger-hunt-videos/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/taylor-swift-2024.jpg?resize=1200,783" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;For the release of her twelfth album, “The Life of a Showgirl,” Taylor Swift sent fans on an online scavenger hunt this weekend, which began by searching for “Taylor Swift” on Google. But as fans unveiled secret videos as part of the campaign, some fretted that the clips looked like they were AI-generated — and they were not pleased.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A Google search for the singer’s name yields a cryptic message: “12 cities, 12 doors, 1 video to unlock.” &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Fans had to figure out the location of the doors, then physically find them and scan a QR code, which surfaced 12 unique videos that contained the clues needed to solve the puzzle. When fans Googled the correct phrase, another orange door appeared, which fans had to collectively “knock” on by clicking 12 million times. Finally, the door “opened,” revealing a lyric video for “The Fate of Ophelia,” which has its own orange door progress bar on YouTube.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube had scored the video exclusive for the track, as well as the lyric videos from the remaining songs on the new album.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google initially announced the scavenger hunt in a video on Instagram. The video begins with an aerial view of Earth, then quickly zooms in on a hilly, bejeweled landscape, until we see an orange door, overlayed with a Google search bar.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-instagram wp-block-embed-instagram"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;While Swifties love a puzzle, some were rubbed the wrong way by the 12 clue-containing videos, which looked to be AI-generated.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Instead of searching for clues to unveil Swift’s new lyric video, as Swift intended, some fans began to scour the video clips like detectives, looking for signs that the scenes were synthetic. However, while there are clips that look computer-generated, it’s unclear if they were made using AI, and if so, to what extent. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;It would make sense if these videos were generated using Google’s AI products. As OpenAI shows off its new Sora 2 video generator, this Taylor Swift collaboration would be a serendipitous opportunity for Google to show millions of Swifties what its Veo 3 model can do.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google did not respond to TechCrunch’s request for comment on how these videos were generated or if Swift and Google worked together on this activation by using Google’s own AI technology. But Swift’s team and Google have teamed up for similar promotional activities in the past, we should note. &lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The use of AI in creative works is a sensitive subject. Some artists think these tools can help them,  while others have protested the manner in which large language models are trained on their work without consent, effectively using artists’ own work to create the technology that could threaten their livelihoods.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Even Swift herself spoke out about the dangers of AI after President Donald Trump shared an AI-generated image of her showing support for his campaign last year; the incident spurred her to post an endorsement for former Vice President Kamala Harris, who ran against Trump in 2024.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-reddit wp-block-embed-reddit"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“Recently I was made aware that AI of ‘me’ falsely endorsing Donald Trump’s presidential run was posted to his site. It really conjured up my fears around AI, and the dangers of spreading misinformation. It brought me to the conclusion that I need to be very transparent about my actual plans for this election as a voter,” she wrote on Instagram at the time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The controversy around Swift’s possible use of AI is amplified given her own stature in the music industry. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While AI may appeal to some artists as a way to cut costs, the billionaire musician has every possible resource at her disposal to bring the fantastical scenes from her promotional videos to life.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/taylor-swift-2024.jpg?resize=1200,783" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;For the release of her twelfth album, “The Life of a Showgirl,” Taylor Swift sent fans on an online scavenger hunt this weekend, which began by searching for “Taylor Swift” on Google. But as fans unveiled secret videos as part of the campaign, some fretted that the clips looked like they were AI-generated — and they were not pleased.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A Google search for the singer’s name yields a cryptic message: “12 cities, 12 doors, 1 video to unlock.” &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Fans had to figure out the location of the doors, then physically find them and scan a QR code, which surfaced 12 unique videos that contained the clues needed to solve the puzzle. When fans Googled the correct phrase, another orange door appeared, which fans had to collectively “knock” on by clicking 12 million times. Finally, the door “opened,” revealing a lyric video for “The Fate of Ophelia,” which has its own orange door progress bar on YouTube.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube had scored the video exclusive for the track, as well as the lyric videos from the remaining songs on the new album.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google initially announced the scavenger hunt in a video on Instagram. The video begins with an aerial view of Earth, then quickly zooms in on a hilly, bejeweled landscape, until we see an orange door, overlayed with a Google search bar.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-instagram wp-block-embed-instagram"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;While Swifties love a puzzle, some were rubbed the wrong way by the 12 clue-containing videos, which looked to be AI-generated.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Instead of searching for clues to unveil Swift’s new lyric video, as Swift intended, some fans began to scour the video clips like detectives, looking for signs that the scenes were synthetic. However, while there are clips that look computer-generated, it’s unclear if they were made using AI, and if so, to what extent. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;It would make sense if these videos were generated using Google’s AI products. As OpenAI shows off its new Sora 2 video generator, this Taylor Swift collaboration would be a serendipitous opportunity for Google to show millions of Swifties what its Veo 3 model can do.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google did not respond to TechCrunch’s request for comment on how these videos were generated or if Swift and Google worked together on this activation by using Google’s own AI technology. But Swift’s team and Google have teamed up for similar promotional activities in the past, we should note. &lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The use of AI in creative works is a sensitive subject. Some artists think these tools can help them,  while others have protested the manner in which large language models are trained on their work without consent, effectively using artists’ own work to create the technology that could threaten their livelihoods.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Even Swift herself spoke out about the dangers of AI after President Donald Trump shared an AI-generated image of her showing support for his campaign last year; the incident spurred her to post an endorsement for former Vice President Kamala Harris, who ran against Trump in 2024.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-reddit wp-block-embed-reddit"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“Recently I was made aware that AI of ‘me’ falsely endorsing Donald Trump’s presidential run was posted to his site. It really conjured up my fears around AI, and the dangers of spreading misinformation. It brought me to the conclusion that I need to be very transparent about my actual plans for this election as a voter,” she wrote on Instagram at the time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The controversy around Swift’s possible use of AI is amplified given her own stature in the music industry. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While AI may appeal to some artists as a way to cut costs, the billionaire musician has every possible resource at her disposal to bring the fantastical scenes from her promotional videos to life.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/06/taylor-swift-fans-accuse-singer-of-using-ai-in-her-google-scavenger-hunt-videos/</guid><pubDate>Mon, 06 Oct 2025 20:50:16 +0000</pubDate></item><item><title>Deloitte goes all in on AI — despite having to issue a hefty refund for use of AI (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/06/deloitte-goes-all-in-on-ai-despite-having-to-issue-a-hefty-refund-for-use-of-ai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/GettyImages-2169550517.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;br /&gt;Professional services and consultant firm Deloitte&amp;nbsp;announced a landmark AI&amp;nbsp;enterprise&amp;nbsp;deal with Anthropic&amp;nbsp;the same day it was revealed the company would issue a refund for a government-contracted report that contained inaccurate&amp;nbsp;AI-produced&amp;nbsp;slop.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The upshot: Deloitte’s deal with Anthropic is a referendum on its commitment to AI, even as it grapples with the technology. And Deloitte is not alone in this challenge. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The timing of this announcement is interesting —&amp;nbsp;comical even. On the same day Deloitte touted&amp;nbsp;its increased use of AI,&amp;nbsp;the Australia Department of Employment and Workplace Relations said the&amp;nbsp;consulting company would have to issue a refund&amp;nbsp;for a report it did for the department that included AI hallucinations, the Financial Times reported.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The department had commissioned a A$439,000 “independent assurance review” from Deloitte, which was published earlier this year. The Australian Financial Review reported in August the review had a number of errors, including multiple citations to non-existent academic reports. A corrected version of the review was uploaded to the department’s website last week. Deloitte will repay the final installment of its government contract, the FT reported.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch reached out to Deloitte for comment and will update the article if the company responds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Deloitte announced&amp;nbsp;Monday plans roll out&amp;nbsp;Anthropic’s&amp;nbsp;chatbot Claude to&amp;nbsp;its&amp;nbsp;nearly 500,000&amp;nbsp;global employees on Monday. Deloitte&amp;nbsp;and Anthropic, which formed a partnership last year,&amp;nbsp;plan to create compliance&amp;nbsp;products and&amp;nbsp;features for regulated industries&amp;nbsp;including&amp;nbsp;financial services,&amp;nbsp;healthcare&amp;nbsp;and public services, according to an&amp;nbsp;Anthropic blog post.&amp;nbsp;Deloitte&amp;nbsp;also&amp;nbsp;plans to create different AI agent “personas” to&amp;nbsp;represent&amp;nbsp;the different departments within the company including accountants and software developers,&amp;nbsp;according to reporting from CNBC.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Deloitte is making this significant investment in&amp;nbsp;Anthropic’s&amp;nbsp;AI platform because our approach to responsible AI is very aligned, and together we can reshape how enterprises operate over the next decade. Claude continues to be a leading choice for many clients and our own AI transformation,” Ranjit Bawa,&amp;nbsp;global&amp;nbsp;technology and&amp;nbsp;ecosystems&amp;nbsp;and&amp;nbsp;alliances&amp;nbsp;leader,&amp;nbsp;at Deloitte wrote in the blog post.&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The financial terms of the deal&amp;nbsp;—&amp;nbsp;which Anthropic referred to as an alliance&amp;nbsp;—&amp;nbsp;were not&amp;nbsp;disclosed.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal is not only Anthropic’s&amp;nbsp;largest enterprise&amp;nbsp;deployment&amp;nbsp;yet, it also illustrates how AI is embedding itself in every aspect of modern life from tools used at work to casual queries made at home. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Deloitte is not the only company, or individual,&amp;nbsp;getting caught using inaccurate AI-produced information in recent months either.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In May, the Chicago Sun-Times newspaper&amp;nbsp;had to admit that it ran an AI-generated list of books&amp;nbsp;for its annual summer reading list after readers discovered some of the book&amp;nbsp;titles were hallucinated even if the authors were real.&amp;nbsp;An internal document viewed by Business Insider showed Amazon’s AI productivity tool, Q Business, struggled with accuracy in its first year. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic&amp;nbsp;itself&amp;nbsp;has&amp;nbsp;also&amp;nbsp;been knocked for&amp;nbsp;using&amp;nbsp;AI-hallucinated information&amp;nbsp;from its own chatbot&amp;nbsp;Claude.&amp;nbsp;The AI research lab’s lawyer&amp;nbsp;apologized&amp;nbsp;after&amp;nbsp;the company used an AI-generated citation&amp;nbsp;in a legal dispute with&amp;nbsp;music publishers&amp;nbsp;earlier this year.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/GettyImages-2169550517.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;br /&gt;Professional services and consultant firm Deloitte&amp;nbsp;announced a landmark AI&amp;nbsp;enterprise&amp;nbsp;deal with Anthropic&amp;nbsp;the same day it was revealed the company would issue a refund for a government-contracted report that contained inaccurate&amp;nbsp;AI-produced&amp;nbsp;slop.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The upshot: Deloitte’s deal with Anthropic is a referendum on its commitment to AI, even as it grapples with the technology. And Deloitte is not alone in this challenge. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The timing of this announcement is interesting —&amp;nbsp;comical even. On the same day Deloitte touted&amp;nbsp;its increased use of AI,&amp;nbsp;the Australia Department of Employment and Workplace Relations said the&amp;nbsp;consulting company would have to issue a refund&amp;nbsp;for a report it did for the department that included AI hallucinations, the Financial Times reported.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The department had commissioned a A$439,000 “independent assurance review” from Deloitte, which was published earlier this year. The Australian Financial Review reported in August the review had a number of errors, including multiple citations to non-existent academic reports. A corrected version of the review was uploaded to the department’s website last week. Deloitte will repay the final installment of its government contract, the FT reported.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch reached out to Deloitte for comment and will update the article if the company responds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Deloitte announced&amp;nbsp;Monday plans roll out&amp;nbsp;Anthropic’s&amp;nbsp;chatbot Claude to&amp;nbsp;its&amp;nbsp;nearly 500,000&amp;nbsp;global employees on Monday. Deloitte&amp;nbsp;and Anthropic, which formed a partnership last year,&amp;nbsp;plan to create compliance&amp;nbsp;products and&amp;nbsp;features for regulated industries&amp;nbsp;including&amp;nbsp;financial services,&amp;nbsp;healthcare&amp;nbsp;and public services, according to an&amp;nbsp;Anthropic blog post.&amp;nbsp;Deloitte&amp;nbsp;also&amp;nbsp;plans to create different AI agent “personas” to&amp;nbsp;represent&amp;nbsp;the different departments within the company including accountants and software developers,&amp;nbsp;according to reporting from CNBC.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Deloitte is making this significant investment in&amp;nbsp;Anthropic’s&amp;nbsp;AI platform because our approach to responsible AI is very aligned, and together we can reshape how enterprises operate over the next decade. Claude continues to be a leading choice for many clients and our own AI transformation,” Ranjit Bawa,&amp;nbsp;global&amp;nbsp;technology and&amp;nbsp;ecosystems&amp;nbsp;and&amp;nbsp;alliances&amp;nbsp;leader,&amp;nbsp;at Deloitte wrote in the blog post.&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The financial terms of the deal&amp;nbsp;—&amp;nbsp;which Anthropic referred to as an alliance&amp;nbsp;—&amp;nbsp;were not&amp;nbsp;disclosed.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal is not only Anthropic’s&amp;nbsp;largest enterprise&amp;nbsp;deployment&amp;nbsp;yet, it also illustrates how AI is embedding itself in every aspect of modern life from tools used at work to casual queries made at home. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Deloitte is not the only company, or individual,&amp;nbsp;getting caught using inaccurate AI-produced information in recent months either.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In May, the Chicago Sun-Times newspaper&amp;nbsp;had to admit that it ran an AI-generated list of books&amp;nbsp;for its annual summer reading list after readers discovered some of the book&amp;nbsp;titles were hallucinated even if the authors were real.&amp;nbsp;An internal document viewed by Business Insider showed Amazon’s AI productivity tool, Q Business, struggled with accuracy in its first year. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic&amp;nbsp;itself&amp;nbsp;has&amp;nbsp;also&amp;nbsp;been knocked for&amp;nbsp;using&amp;nbsp;AI-hallucinated information&amp;nbsp;from its own chatbot&amp;nbsp;Claude.&amp;nbsp;The AI research lab’s lawyer&amp;nbsp;apologized&amp;nbsp;after&amp;nbsp;the company used an AI-generated citation&amp;nbsp;in a legal dispute with&amp;nbsp;music publishers&amp;nbsp;earlier this year.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/06/deloitte-goes-all-in-on-ai-despite-having-to-issue-a-hefty-refund-for-use-of-ai/</guid><pubDate>Mon, 06 Oct 2025 22:29:47 +0000</pubDate></item><item><title>OpenAI unveils AgentKit that lets developers drag and drop to build AI agents (AI | VentureBeat)</title><link>https://venturebeat.com/ai/openai-unveils-agentkit-that-lets-developers-drag-and-drop-to-build-ai</link><description>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://openai.com/"&gt;OpenAI&lt;/a&gt; launched an agent builder that the company hopes will eliminate fragmented tools and make it easier for enterprises to utilize OpenAI’s system to create agents. &lt;/p&gt;&lt;p&gt;&lt;a href="https://openai.com/index/introducing-agentkit/"&gt;AgentKit&lt;/a&gt;, announced during OpenAI’s DevDay in San Francisco, enables developers and enterprises to build agents and add chat capabilities in one place, potentially competing with platforms like &lt;a href="https://zapier.com/"&gt;Zapier&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;By offering a more streamlined way to create agents, OpenAI advances further into becoming a full-stack application provider.&lt;/p&gt;&lt;p&gt;“Until now, building agents meant juggling fragmented tools—complex orchestration with no versioning, custom connectors, manual eval pipelines, prompt tuning, and weeks of frontend work before launch,” the company said in a blog post. &lt;/p&gt;&lt;p&gt;AgentKit includes:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Agent Builder, which is a visual canvas where devs can see what they’ve created and versioning multi-agent workflows&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Connector Registry is a central area for admins to manage connections across OpenAI products. A Global Admin console will be a prerequisite to using this feature.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;ChatKit enables users to integrate chat-based agents into their user interfaces. &lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Eventually, OpenAI said it will build a standalone Workflows API and add agent deployment tabs to ChatGPT. &lt;/p&gt;&lt;p&gt;OpenAI also expanded evaluation for agents, adding capabilities such as datasets with automated graders and annotations, trace grading that runs end-to-end assessments of workflows, automated prompt optimization, and support for third-party agent measurement tools. &lt;/p&gt;&lt;p&gt;Developers can access some features of AgentKit, but OpenAI is gradually rolling out additional features, such as Agent Builder. Currently, Agent Builder is available in beta, while ChatKit and new evaluation capabilities are generally available. Connector Registry “is beginning its beta rollout to some API and ChatGPT Enterprise and Edu users. &lt;/p&gt;&lt;p&gt;OpenAI said pricing for AgentKit tools will be included in the standard API model pricing. &lt;/p&gt;&lt;h2&gt;Agent Builder&lt;/h2&gt;&lt;p&gt;To clarify, many agents are built using OpenAI’s models; however, enterprises often access GPT-5 through other platforms to create their own agents. However, AgentKit brings enterprises more into its ecosystem, ensuring they don’t need to tap other platforms as often. &lt;/p&gt;&lt;p&gt;Demonstrated during DevDay, the company stated that Agent Builder is ideal for rapid iteration. It also provides developers with visibility into how the agents are working. &lt;/p&gt;&lt;p&gt;During the demo, an OpenAI developer made an agent that reads the DevDay agenda and suggests panels to watch. It took her just under eight minutes. &lt;/p&gt;&lt;p&gt;Other model providers saw the importance of offering developer toolkits to build agents to entice enterprises to use more of their tools. &lt;a href="https://www.google.com/"&gt;Google&lt;/a&gt; came out with its &lt;a href="https://venturebeat.com/ai/googles-new-agent-development-kit-lets-enterprises-rapidly-prototype-and-deploy-ai-agents-without-recoding"&gt;Agent Development Kit in April&lt;/a&gt;, expanding multi-agent system building “in under 100 lines of code.” &lt;a href="https://www.microsoft.com/"&gt;Microsoft&lt;/a&gt;, which runs the popular agent framework AutoGen, announced it is bringing agent creation to one place with its new &lt;a href="https://venturebeat.com/ai/microsoft-retires-autogen-and-debuts-agent-framework-to-unify-and-govern"&gt;Agent Framework&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;OpenAI customers, such as the fintech company Ramp, stated in a blog post that its teams were able to build a procurement agent in a few hours instead of months. &lt;/p&gt;&lt;p&gt;“Agent Builder transformed what once took months of complex orchestration, custom code, and manual optimizations into just a couple of hours. The visual canvas keeps product, legal, and engineering on the same page, slashing iteration cycles by 70% and getting an agent live in two sprints rather than two quarters,” Ramp said. &lt;/p&gt;&lt;p&gt;AgentKit’s Connector Registry would also enable enterprises to manage and maintain data across workspaces, consolidating data sources into a single panel that spans both ChatGPT and the API. It will have pre-built connectors to Dropbox, Google Drive, SharePoint and Microsoft Teams. It also supports third-party MCP servers. &lt;/p&gt;&lt;p&gt;Another capability of Agent Builder is Guardrails, an open-source safety layer that protects against the leakage of personally identifiable information (PII), jailbreaks, and unintended or malicious behavior.&lt;/p&gt;&lt;h2&gt;Bringing more chat &lt;/h2&gt;&lt;p&gt;Since most agentic interactions involve chat, it makes sense to simplify the process for developers to set up chat interfaces and connect them with the agents they’ve just built. &lt;/p&gt;&lt;p&gt;“Deploying chat UIs for agents can be surprisingly complex—handling streaming responses, managing threads, showing the model thinking and designing engaging in-chat experiences,” OpenAI said. &lt;/p&gt;&lt;p&gt;The company said ChatKit makes it simple to embed chat agents on platforms and embed these into apps or websites. &lt;/p&gt;&lt;p&gt;However, some OpenAI competitors have begun thinking beyond the chatbot and want to offer agentic interactions that feel more seamless. Google’s asynchronous coding agent, Jules, has &lt;a href="https://venturebeat.com/ai/googles-jules-coding-agent-moves-beyond-chat-with-new-command-line-and-api"&gt;introduced a new feature&lt;/a&gt; that enables users to interact with the agent through the command-line interface, eliminating the need to open a chat window. &lt;/p&gt;&lt;h2&gt;Responses &lt;/h2&gt;&lt;p&gt;The response to AgentKit has mainly been positive, with some developers noting that while it simplifies agent building, it doesn’t mean that everyone can now build agents. &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;div&gt;&lt;/div&gt;&lt;div&gt;&lt;/div&gt;&lt;p&gt;Several developers view Agent Kit not as a Zapier killer, but rather as a tool that complements the pipeline. &lt;/p&gt;&lt;div&gt;&lt;/div&gt;&lt;p&gt;&lt;/p&gt;&lt;div&gt;&lt;/div&gt;&lt;p&gt;Zapier debuted a no-code tool for building AI agents and bots,&lt;a href="https://venturebeat.com/ai/zapier-central-debuts-as-no-code-tool-for-building-enterprise-ai-bots"&gt; called Zapier Central,&lt;/a&gt; in 2024. &lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://openai.com/"&gt;OpenAI&lt;/a&gt; launched an agent builder that the company hopes will eliminate fragmented tools and make it easier for enterprises to utilize OpenAI’s system to create agents. &lt;/p&gt;&lt;p&gt;&lt;a href="https://openai.com/index/introducing-agentkit/"&gt;AgentKit&lt;/a&gt;, announced during OpenAI’s DevDay in San Francisco, enables developers and enterprises to build agents and add chat capabilities in one place, potentially competing with platforms like &lt;a href="https://zapier.com/"&gt;Zapier&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;By offering a more streamlined way to create agents, OpenAI advances further into becoming a full-stack application provider.&lt;/p&gt;&lt;p&gt;“Until now, building agents meant juggling fragmented tools—complex orchestration with no versioning, custom connectors, manual eval pipelines, prompt tuning, and weeks of frontend work before launch,” the company said in a blog post. &lt;/p&gt;&lt;p&gt;AgentKit includes:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Agent Builder, which is a visual canvas where devs can see what they’ve created and versioning multi-agent workflows&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Connector Registry is a central area for admins to manage connections across OpenAI products. A Global Admin console will be a prerequisite to using this feature.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;ChatKit enables users to integrate chat-based agents into their user interfaces. &lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Eventually, OpenAI said it will build a standalone Workflows API and add agent deployment tabs to ChatGPT. &lt;/p&gt;&lt;p&gt;OpenAI also expanded evaluation for agents, adding capabilities such as datasets with automated graders and annotations, trace grading that runs end-to-end assessments of workflows, automated prompt optimization, and support for third-party agent measurement tools. &lt;/p&gt;&lt;p&gt;Developers can access some features of AgentKit, but OpenAI is gradually rolling out additional features, such as Agent Builder. Currently, Agent Builder is available in beta, while ChatKit and new evaluation capabilities are generally available. Connector Registry “is beginning its beta rollout to some API and ChatGPT Enterprise and Edu users. &lt;/p&gt;&lt;p&gt;OpenAI said pricing for AgentKit tools will be included in the standard API model pricing. &lt;/p&gt;&lt;h2&gt;Agent Builder&lt;/h2&gt;&lt;p&gt;To clarify, many agents are built using OpenAI’s models; however, enterprises often access GPT-5 through other platforms to create their own agents. However, AgentKit brings enterprises more into its ecosystem, ensuring they don’t need to tap other platforms as often. &lt;/p&gt;&lt;p&gt;Demonstrated during DevDay, the company stated that Agent Builder is ideal for rapid iteration. It also provides developers with visibility into how the agents are working. &lt;/p&gt;&lt;p&gt;During the demo, an OpenAI developer made an agent that reads the DevDay agenda and suggests panels to watch. It took her just under eight minutes. &lt;/p&gt;&lt;p&gt;Other model providers saw the importance of offering developer toolkits to build agents to entice enterprises to use more of their tools. &lt;a href="https://www.google.com/"&gt;Google&lt;/a&gt; came out with its &lt;a href="https://venturebeat.com/ai/googles-new-agent-development-kit-lets-enterprises-rapidly-prototype-and-deploy-ai-agents-without-recoding"&gt;Agent Development Kit in April&lt;/a&gt;, expanding multi-agent system building “in under 100 lines of code.” &lt;a href="https://www.microsoft.com/"&gt;Microsoft&lt;/a&gt;, which runs the popular agent framework AutoGen, announced it is bringing agent creation to one place with its new &lt;a href="https://venturebeat.com/ai/microsoft-retires-autogen-and-debuts-agent-framework-to-unify-and-govern"&gt;Agent Framework&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;OpenAI customers, such as the fintech company Ramp, stated in a blog post that its teams were able to build a procurement agent in a few hours instead of months. &lt;/p&gt;&lt;p&gt;“Agent Builder transformed what once took months of complex orchestration, custom code, and manual optimizations into just a couple of hours. The visual canvas keeps product, legal, and engineering on the same page, slashing iteration cycles by 70% and getting an agent live in two sprints rather than two quarters,” Ramp said. &lt;/p&gt;&lt;p&gt;AgentKit’s Connector Registry would also enable enterprises to manage and maintain data across workspaces, consolidating data sources into a single panel that spans both ChatGPT and the API. It will have pre-built connectors to Dropbox, Google Drive, SharePoint and Microsoft Teams. It also supports third-party MCP servers. &lt;/p&gt;&lt;p&gt;Another capability of Agent Builder is Guardrails, an open-source safety layer that protects against the leakage of personally identifiable information (PII), jailbreaks, and unintended or malicious behavior.&lt;/p&gt;&lt;h2&gt;Bringing more chat &lt;/h2&gt;&lt;p&gt;Since most agentic interactions involve chat, it makes sense to simplify the process for developers to set up chat interfaces and connect them with the agents they’ve just built. &lt;/p&gt;&lt;p&gt;“Deploying chat UIs for agents can be surprisingly complex—handling streaming responses, managing threads, showing the model thinking and designing engaging in-chat experiences,” OpenAI said. &lt;/p&gt;&lt;p&gt;The company said ChatKit makes it simple to embed chat agents on platforms and embed these into apps or websites. &lt;/p&gt;&lt;p&gt;However, some OpenAI competitors have begun thinking beyond the chatbot and want to offer agentic interactions that feel more seamless. Google’s asynchronous coding agent, Jules, has &lt;a href="https://venturebeat.com/ai/googles-jules-coding-agent-moves-beyond-chat-with-new-command-line-and-api"&gt;introduced a new feature&lt;/a&gt; that enables users to interact with the agent through the command-line interface, eliminating the need to open a chat window. &lt;/p&gt;&lt;h2&gt;Responses &lt;/h2&gt;&lt;p&gt;The response to AgentKit has mainly been positive, with some developers noting that while it simplifies agent building, it doesn’t mean that everyone can now build agents. &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;div&gt;&lt;/div&gt;&lt;div&gt;&lt;/div&gt;&lt;p&gt;Several developers view Agent Kit not as a Zapier killer, but rather as a tool that complements the pipeline. &lt;/p&gt;&lt;div&gt;&lt;/div&gt;&lt;p&gt;&lt;/p&gt;&lt;div&gt;&lt;/div&gt;&lt;p&gt;Zapier debuted a no-code tool for building AI agents and bots,&lt;a href="https://venturebeat.com/ai/zapier-central-debuts-as-no-code-tool-for-building-enterprise-ai-bots"&gt; called Zapier Central,&lt;/a&gt; in 2024. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/openai-unveils-agentkit-that-lets-developers-drag-and-drop-to-build-ai</guid><pubDate>Mon, 06 Oct 2025 22:53:00 +0000</pubDate></item><item><title>[NEW] Printable aluminum alloy sets strength records, may enable lighter aircraft parts (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/printable-aluminum-alloy-sets-strength-records-may-enable-lighter-aircraft-parts-1007</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202510/MIT-Printing-Aluminum-01-press.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;MIT engineers have developed a printable aluminum alloy that can withstand high temperatures and is five times stronger than traditionally manufactured aluminum.&lt;/p&gt;&lt;p&gt;The new printable metal is made from a mix of aluminum and other elements that the team identified using a combination of simulations and machine learning, which significantly pruned the number of possible combinations of materials to search through. While traditional methods would require simulating over 1 million possible combinations of materials, the team’s new machine learning-based approach needed only to evaluate 40 possible compositions before identifying an ideal mix for a high-strength, printable aluminum alloy.&lt;/p&gt;&lt;p&gt;When they printed the alloy and tested the resulting material, the team confirmed that, as predicted, the aluminum alloy was as strong as the strongest aluminum alloys that are manufactured today using traditional casting methods.&lt;/p&gt;&lt;p&gt;The&amp;nbsp;researchers envision that the new printable aluminum could be made into stronger, more lightweight and temperature-resistant products, such as fan blades in jet engines. Fan blades are traditionally&amp;nbsp;cast from titanium — a material that is more than 50 percent heavier and up to 10 times costlier than aluminum — or made from advanced composites.&lt;/p&gt;&lt;p&gt;“If we can use lighter, high-strength material, this would save a considerable amount of energy for the transportation industry,” says&amp;nbsp;Mohadeseh Taheri-Mousavi, who led the work as a postdoc at MIT and is now an assistant professor at Carnegie Mellon University.&lt;/p&gt;&lt;p&gt;“Because 3D printing can produce complex geometries, save material, and enable unique designs, we see this printable alloy as something that could also be used in advanced vacuum pumps, high-end automobiles, and cooling devices for data centers,” adds John Hart, the Class of 1922 Professor and head of the Department of Mechanical Engineering at MIT.&lt;/p&gt;&lt;p&gt;Hart and Taheri-Mousavi provide details on the new printable aluminum design in a paper published in the journal &lt;em&gt;Advanced Materials&lt;/em&gt;. The paper’s MIT co-authors include Michael Xu, Clay Houser, Shaolou Wei, James LeBeau, and Greg Olson, along with Florian Hengsbach and Mirko Schaper of Paderborn University in Germany, and Zhaoxuan Ge and Benjamin Glaser of Carnegie Mellon University.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Micro-sizing&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The new work grew out of an MIT class that Taheri-Mousavi took in 2020, which was taught by Greg Olson, professor of the practice in the Department of Materials Science and Engineering. As part of the class, students learned to use computational simulations to design high-performance alloys. Alloys are materials that are made from a mix of different elements, the combination of which imparts exceptional strength and other unique properties to the material as a whole.&lt;/p&gt;&lt;p&gt;Olson challenged the class to design an aluminum alloy that would be stronger than the strongest printable aluminum alloy designed to date. As with most materials, the strength of aluminum depends in large part on its microstructure: The smaller and more densely packed its microscopic constituents, or “precipitates,” the stronger the alloy would be.&lt;/p&gt;&lt;p&gt;With this in mind, the class used computer simulations to methodically combine aluminum with various types and concentrations of elements, to simulate and predict the resulting alloy’s strength. However, the exercise failed to produce a stronger result. At the end of the class, Taheri-Mousavi wondered: Could machine learning do better?&lt;/p&gt;&lt;p&gt;“At some point, there are a lot of things that contribute nonlinearly to a material’s properties, and you are lost,” Taheri-Mousavi says. “With machine-learning tools, they can point you to where you need to focus, and tell you for example, these two elements are controlling this feature. It lets you explore the design space more efficiently.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Layer by layer&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;In the new study, Taheri-Mousavi continued where Olson’s class left off, this time looking to identify a stronger recipe for aluminum alloy. This time, she used machine-learning techniques designed to efficiently comb through data such as the properties of elements, to identify key connections and correlations that should lead to a more desirable outcome or product.&lt;/p&gt;&lt;p&gt;She found that, using just 40 compositions mixing aluminum with different elements, their machine-learning approach quickly homed in on a recipe for an aluminum alloy with higher volume fraction of small precipitates, and therefore higher strength, than what the previous studies identified. The alloy’s strength was even higher than what they could identify after simulating over 1 million possibilities without using machine learning.&lt;/p&gt;&lt;p&gt;To physically produce this new strong, small-precipitate alloy, the team realized 3D printing would be the way to go instead of traditional metal casting, in which molten liquid aluminum is poured into a mold and is left to cool and harden. The longer this cooling time is, the more likely the individual precipitate is to grow.&lt;/p&gt;&lt;p&gt;The researchers showed that 3D printing, broadly also known as additive manufacturing, can be a faster way to cool and solidify the aluminum alloy. Specifically, they considered laser bed powder fusion (LBPF) — a technique by which a powder is deposited, layer by layer, on a surface in a desired pattern and then quickly melted by a laser that traces over the pattern. The melted pattern is thin enough that it solidfies quickly before another layer is deposited and similarly “printed.” The team found that LBPF’s inherently rapid cooling and solidification enabled the small-precipitate, high-strength aluminum alloy that their machine learning method predicted.&lt;/p&gt;&lt;p&gt;“Sometimes we have to think about how to get a material to be compatible with 3D printing,” says study co-author John Hart. “Here, 3D printing opens a new door because of the unique characteristics of the process — particularly, the fast cooling rate. Very rapid freezing of the alloy after it’s melted by the laser creates this special set of properties.”&lt;/p&gt;&lt;p&gt;Putting their idea into practice, the researchers ordered a formulation of printable powder, based on their new aluminum alloy recipe. They sent the powder — a mix of aluminum and five other elements — to collaborators in Germany, who printed small samples of the alloy using their in-house LPBF system. The samples were then sent to MIT where the team ran multiple tests to measure the alloy’s strength and image the samples’ microstructure.&lt;/p&gt;&lt;p&gt;Their results confirmed the predictions made by their initial machine learning search: The printed alloy was five times stronger than a casted counterpart and 50 percent stronger than alloys designed using conventional simulations without machine learning. The new alloy’s microstructure also consisted of a higher volume fraction of small precipitates, and was stable at high temperatures of up to 400 degrees Celsius — a very high temperature for aluminum alloys.&lt;/p&gt;&lt;p&gt;The researchers are applying similar machine-learning techniques to further optimize other properties of the alloy.&lt;/p&gt;&lt;p&gt;“Our methodology opens new doors for anyone who wants to do 3D printing alloy design,” Taheri-Mousavi says. “My dream is that one day, passengers looking out their airplane window will see fan blades of engines made from our aluminum alloys.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202510/MIT-Printing-Aluminum-01-press.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;MIT engineers have developed a printable aluminum alloy that can withstand high temperatures and is five times stronger than traditionally manufactured aluminum.&lt;/p&gt;&lt;p&gt;The new printable metal is made from a mix of aluminum and other elements that the team identified using a combination of simulations and machine learning, which significantly pruned the number of possible combinations of materials to search through. While traditional methods would require simulating over 1 million possible combinations of materials, the team’s new machine learning-based approach needed only to evaluate 40 possible compositions before identifying an ideal mix for a high-strength, printable aluminum alloy.&lt;/p&gt;&lt;p&gt;When they printed the alloy and tested the resulting material, the team confirmed that, as predicted, the aluminum alloy was as strong as the strongest aluminum alloys that are manufactured today using traditional casting methods.&lt;/p&gt;&lt;p&gt;The&amp;nbsp;researchers envision that the new printable aluminum could be made into stronger, more lightweight and temperature-resistant products, such as fan blades in jet engines. Fan blades are traditionally&amp;nbsp;cast from titanium — a material that is more than 50 percent heavier and up to 10 times costlier than aluminum — or made from advanced composites.&lt;/p&gt;&lt;p&gt;“If we can use lighter, high-strength material, this would save a considerable amount of energy for the transportation industry,” says&amp;nbsp;Mohadeseh Taheri-Mousavi, who led the work as a postdoc at MIT and is now an assistant professor at Carnegie Mellon University.&lt;/p&gt;&lt;p&gt;“Because 3D printing can produce complex geometries, save material, and enable unique designs, we see this printable alloy as something that could also be used in advanced vacuum pumps, high-end automobiles, and cooling devices for data centers,” adds John Hart, the Class of 1922 Professor and head of the Department of Mechanical Engineering at MIT.&lt;/p&gt;&lt;p&gt;Hart and Taheri-Mousavi provide details on the new printable aluminum design in a paper published in the journal &lt;em&gt;Advanced Materials&lt;/em&gt;. The paper’s MIT co-authors include Michael Xu, Clay Houser, Shaolou Wei, James LeBeau, and Greg Olson, along with Florian Hengsbach and Mirko Schaper of Paderborn University in Germany, and Zhaoxuan Ge and Benjamin Glaser of Carnegie Mellon University.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Micro-sizing&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The new work grew out of an MIT class that Taheri-Mousavi took in 2020, which was taught by Greg Olson, professor of the practice in the Department of Materials Science and Engineering. As part of the class, students learned to use computational simulations to design high-performance alloys. Alloys are materials that are made from a mix of different elements, the combination of which imparts exceptional strength and other unique properties to the material as a whole.&lt;/p&gt;&lt;p&gt;Olson challenged the class to design an aluminum alloy that would be stronger than the strongest printable aluminum alloy designed to date. As with most materials, the strength of aluminum depends in large part on its microstructure: The smaller and more densely packed its microscopic constituents, or “precipitates,” the stronger the alloy would be.&lt;/p&gt;&lt;p&gt;With this in mind, the class used computer simulations to methodically combine aluminum with various types and concentrations of elements, to simulate and predict the resulting alloy’s strength. However, the exercise failed to produce a stronger result. At the end of the class, Taheri-Mousavi wondered: Could machine learning do better?&lt;/p&gt;&lt;p&gt;“At some point, there are a lot of things that contribute nonlinearly to a material’s properties, and you are lost,” Taheri-Mousavi says. “With machine-learning tools, they can point you to where you need to focus, and tell you for example, these two elements are controlling this feature. It lets you explore the design space more efficiently.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Layer by layer&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;In the new study, Taheri-Mousavi continued where Olson’s class left off, this time looking to identify a stronger recipe for aluminum alloy. This time, she used machine-learning techniques designed to efficiently comb through data such as the properties of elements, to identify key connections and correlations that should lead to a more desirable outcome or product.&lt;/p&gt;&lt;p&gt;She found that, using just 40 compositions mixing aluminum with different elements, their machine-learning approach quickly homed in on a recipe for an aluminum alloy with higher volume fraction of small precipitates, and therefore higher strength, than what the previous studies identified. The alloy’s strength was even higher than what they could identify after simulating over 1 million possibilities without using machine learning.&lt;/p&gt;&lt;p&gt;To physically produce this new strong, small-precipitate alloy, the team realized 3D printing would be the way to go instead of traditional metal casting, in which molten liquid aluminum is poured into a mold and is left to cool and harden. The longer this cooling time is, the more likely the individual precipitate is to grow.&lt;/p&gt;&lt;p&gt;The researchers showed that 3D printing, broadly also known as additive manufacturing, can be a faster way to cool and solidify the aluminum alloy. Specifically, they considered laser bed powder fusion (LBPF) — a technique by which a powder is deposited, layer by layer, on a surface in a desired pattern and then quickly melted by a laser that traces over the pattern. The melted pattern is thin enough that it solidfies quickly before another layer is deposited and similarly “printed.” The team found that LBPF’s inherently rapid cooling and solidification enabled the small-precipitate, high-strength aluminum alloy that their machine learning method predicted.&lt;/p&gt;&lt;p&gt;“Sometimes we have to think about how to get a material to be compatible with 3D printing,” says study co-author John Hart. “Here, 3D printing opens a new door because of the unique characteristics of the process — particularly, the fast cooling rate. Very rapid freezing of the alloy after it’s melted by the laser creates this special set of properties.”&lt;/p&gt;&lt;p&gt;Putting their idea into practice, the researchers ordered a formulation of printable powder, based on their new aluminum alloy recipe. They sent the powder — a mix of aluminum and five other elements — to collaborators in Germany, who printed small samples of the alloy using their in-house LPBF system. The samples were then sent to MIT where the team ran multiple tests to measure the alloy’s strength and image the samples’ microstructure.&lt;/p&gt;&lt;p&gt;Their results confirmed the predictions made by their initial machine learning search: The printed alloy was five times stronger than a casted counterpart and 50 percent stronger than alloys designed using conventional simulations without machine learning. The new alloy’s microstructure also consisted of a higher volume fraction of small precipitates, and was stable at high temperatures of up to 400 degrees Celsius — a very high temperature for aluminum alloys.&lt;/p&gt;&lt;p&gt;The researchers are applying similar machine-learning techniques to further optimize other properties of the alloy.&lt;/p&gt;&lt;p&gt;“Our methodology opens new doors for anyone who wants to do 3D printing alloy design,” Taheri-Mousavi says. “My dream is that one day, passengers looking out their airplane window will see fan blades of engines made from our aluminum alloys.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/printable-aluminum-alloy-sets-strength-records-may-enable-lighter-aircraft-parts-1007</guid><pubDate>Tue, 07 Oct 2025 04:00:00 +0000</pubDate></item><item><title>[NEW] New prediction model could improve the reliability of fusion power plants (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/new-prediction-model-could-improve-reliability-fusion-power-plants-1007</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202510/MIT-Tokamak-Tuning-01.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Tokamaks are machines that are meant to hold and harness the power of the sun. These fusion machines use powerful magnets to contain a plasma hotter than the sun’s core and push the plasma’s atoms to fuse and release energy. If tokamaks can operate safely and efficiently, the machines could one day provide clean and limitless fusion energy.&lt;/p&gt;&lt;p&gt;Today, there are a number of experimental tokamaks in operation around the world, with more underway. Most are small-scale research machines built to investigate how the devices can spin up plasma and harness its energy. One of the challenges that tokamaks face is how to safely and reliably turn off a plasma current that is circulating at speeds of up to 100 kilometers per second, at temperatures of over 100 million degrees Celsius.&lt;/p&gt;&lt;p&gt;Such “rampdowns” are necessary when a plasma becomes unstable. To prevent the plasma from further disrupting and potentially damaging the device’s interior, operators ramp down the plasma current. But occasionally the rampdown itself can destabilize the plasma. In some machines, rampdowns have caused scrapes and scarring to the tokamak’s interior — minor damage that still requires considerable time and resources to repair.&lt;/p&gt;&lt;p&gt;Now, scientists at MIT have developed a method to predict how plasma in a tokamak will behave during a rampdown. The team combined machine-learning tools with a physics-based model of plasma dynamics to simulate a plasma’s behavior and any instabilities that may arise as the plasma is ramped down and turned off. The researchers trained and tested the new model on plasma data from an experimental tokamak in Switzerland. They found the method quickly learned how plasma would evolve as it was tuned down in different ways. What’s more, the method achieved a high level of accuracy using a relatively small amount of data. This training efficiency is promising, given that each experimental run of a tokamak is expensive and quality data is limited as a result.&lt;/p&gt;&lt;p&gt;The new model, which the team highlights this week in an open-access &lt;em&gt;Nature Communications&amp;nbsp;&lt;/em&gt;paper, could improve the safety and reliability of future fusion power plants.&lt;/p&gt;&lt;p&gt;“For fusion to be a useful energy source it’s going to have to be reliable,” says lead author Allen Wang, a graduate student in aeronautics and astronautics and a member of the Disruption Group at MIT’s Plasma Science and Fusion Center (PSFC). “To be reliable, we need to get good at managing our plasmas.”&lt;/p&gt;&lt;p&gt;The study’s MIT co-authors include PSFC Principal Research Scientist and Disruptions Group leader Cristina Rea, and members of the Laboratory for Information and Decision Systems (LIDS) Oswin So, Charles Dawson, and Professor Chuchu Fan, along with Mark (Dan) Boyer of Commonwealth Fusion Systems and collaborators from the Swiss Plasma Center in Switzerland.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;“A delicate balance”&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Tokamaks are experimental fusion devices that were first built in the Soviet Union in the 1950s. The device gets its name from a Russian acronym that translates to a “toroidal chamber with magnetic coils.” Just as its name describes, a tokamak is toroidal, or donut-shaped, and uses powerful magnets to contain and spin up a gas to temperatures and energies high enough that atoms in the resulting plasma can fuse and release energy.&lt;/p&gt;&lt;p&gt;Today, tokamak experiments are relatively low-energy in scale, with few approaching the size and output needed to generate safe, reliable, usable energy. Disruptions in experimental, low-energy tokamaks are generally not an issue. But as fusion machines scale up to grid-scale dimensions, controlling much higher-energy plasmas at all phases will be paramount to maintaining a machine’s safe and efficient operation.&lt;/p&gt;&lt;p&gt;“Uncontrolled plasma terminations, even during rampdown, can generate intense heat fluxes damaging the internal walls,” Wang notes. “Quite often, especially with the high-performance plasmas, rampdowns actually can push the plasma closer to some instability limits. So, it’s a delicate balance. And there’s a lot of focus now on how to manage instabilities so that we can routinely and reliably take these plasmas and safely power them down. And there are relatively few studies done on how to do that well.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Bringing down the pulse&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Wang and his colleagues developed a model to predict how a plasma will behave during tokamak rampdown. While they could have simply applied machine-learning tools such as a neural network to learn signs of instabilities in plasma data, “you would need an ungodly amount of data” for such tools to discern the very subtle and ephemeral changes in extremely high-temperature, high-energy plasmas, Wang says.&lt;/p&gt;&lt;p&gt;Instead, the researchers paired a neural network with an existing model that simulates plasma dynamics according to the fundamental rules of physics. With this combination of machine learning and a physics-based plasma simulation, the team found that only a couple hundred pulses at low performance, and a small handful of pulses at high performance, were sufficient to train and validate the new model.&lt;/p&gt;&lt;p&gt;The data they used for the new study came from the TCV, the Swiss “variable configuration tokamak” operated by the Swiss Plasma Center at EPFL (the Swiss Federal Institute of Technology Lausanne). The TCV is a small experimental fusion experimental device that is used for research purposes, often as test bed for next-generation device solutions. Wang used the data from several hundred TCV plasma pulses that included properties of the plasma such as its temperature and energies during each pulse’s ramp-up, run, and ramp-down. He trained the new model on this data, then tested it and found it was able to accurately predict the plasma’s evolution given the initial conditions of a particular tokamak run.&lt;/p&gt;&lt;p&gt;The researchers also developed an algorithm to translate the model’s predictions into practical “trajectories,” or plasma-managing instructions that a tokamak controller can automatically carry out to for instance adjust the magnets or temperature maintain the plasma’s stability. They implemented the algorithm on several TCV runs and found that it produced trajectories that safely ramped down a plasma pulse, in some cases faster and without disruptions compared to runs without the new method.&lt;/p&gt;&lt;p&gt;“At some point the plasma will always go away, but we call it a disruption when the plasma goes away at high energy. Here, we ramped the energy down to nothing,” Wang notes. “We did it a number of times. And we did things much better across the board. So,&amp;nbsp;we had statistical confidence that we made things better.”&lt;/p&gt;&lt;p&gt;The work was supported in part by Commonwealth Fusion Systems (CFS), an MIT spinout that intends to build the world’s first compact, grid-scale fusion power plant. The company is developing a demo tokamak, SPARC, designed to produce net-energy plasma, meaning that it should generate more energy than it takes to heat up the plasma. Wang and his colleagues are working with CFS on ways that the new prediction model and tools like it can better predict plasma behavior and prevent costly disruptions to enable safe and reliable fusion power.&lt;/p&gt;&lt;p&gt;“We’re trying to tackle the science questions to make fusion routinely useful,” Wang says. “What we’ve done here is the start of what is still a long journey. But I think we’ve made some nice progress.”&lt;/p&gt;&lt;p&gt;Additional support for the research came from the framework of the EUROfusion Consortium, via the Euratom Research and Training Program and funded by the Swiss State Secretariat for Education, Research, and Innovation.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202510/MIT-Tokamak-Tuning-01.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Tokamaks are machines that are meant to hold and harness the power of the sun. These fusion machines use powerful magnets to contain a plasma hotter than the sun’s core and push the plasma’s atoms to fuse and release energy. If tokamaks can operate safely and efficiently, the machines could one day provide clean and limitless fusion energy.&lt;/p&gt;&lt;p&gt;Today, there are a number of experimental tokamaks in operation around the world, with more underway. Most are small-scale research machines built to investigate how the devices can spin up plasma and harness its energy. One of the challenges that tokamaks face is how to safely and reliably turn off a plasma current that is circulating at speeds of up to 100 kilometers per second, at temperatures of over 100 million degrees Celsius.&lt;/p&gt;&lt;p&gt;Such “rampdowns” are necessary when a plasma becomes unstable. To prevent the plasma from further disrupting and potentially damaging the device’s interior, operators ramp down the plasma current. But occasionally the rampdown itself can destabilize the plasma. In some machines, rampdowns have caused scrapes and scarring to the tokamak’s interior — minor damage that still requires considerable time and resources to repair.&lt;/p&gt;&lt;p&gt;Now, scientists at MIT have developed a method to predict how plasma in a tokamak will behave during a rampdown. The team combined machine-learning tools with a physics-based model of plasma dynamics to simulate a plasma’s behavior and any instabilities that may arise as the plasma is ramped down and turned off. The researchers trained and tested the new model on plasma data from an experimental tokamak in Switzerland. They found the method quickly learned how plasma would evolve as it was tuned down in different ways. What’s more, the method achieved a high level of accuracy using a relatively small amount of data. This training efficiency is promising, given that each experimental run of a tokamak is expensive and quality data is limited as a result.&lt;/p&gt;&lt;p&gt;The new model, which the team highlights this week in an open-access &lt;em&gt;Nature Communications&amp;nbsp;&lt;/em&gt;paper, could improve the safety and reliability of future fusion power plants.&lt;/p&gt;&lt;p&gt;“For fusion to be a useful energy source it’s going to have to be reliable,” says lead author Allen Wang, a graduate student in aeronautics and astronautics and a member of the Disruption Group at MIT’s Plasma Science and Fusion Center (PSFC). “To be reliable, we need to get good at managing our plasmas.”&lt;/p&gt;&lt;p&gt;The study’s MIT co-authors include PSFC Principal Research Scientist and Disruptions Group leader Cristina Rea, and members of the Laboratory for Information and Decision Systems (LIDS) Oswin So, Charles Dawson, and Professor Chuchu Fan, along with Mark (Dan) Boyer of Commonwealth Fusion Systems and collaborators from the Swiss Plasma Center in Switzerland.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;“A delicate balance”&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Tokamaks are experimental fusion devices that were first built in the Soviet Union in the 1950s. The device gets its name from a Russian acronym that translates to a “toroidal chamber with magnetic coils.” Just as its name describes, a tokamak is toroidal, or donut-shaped, and uses powerful magnets to contain and spin up a gas to temperatures and energies high enough that atoms in the resulting plasma can fuse and release energy.&lt;/p&gt;&lt;p&gt;Today, tokamak experiments are relatively low-energy in scale, with few approaching the size and output needed to generate safe, reliable, usable energy. Disruptions in experimental, low-energy tokamaks are generally not an issue. But as fusion machines scale up to grid-scale dimensions, controlling much higher-energy plasmas at all phases will be paramount to maintaining a machine’s safe and efficient operation.&lt;/p&gt;&lt;p&gt;“Uncontrolled plasma terminations, even during rampdown, can generate intense heat fluxes damaging the internal walls,” Wang notes. “Quite often, especially with the high-performance plasmas, rampdowns actually can push the plasma closer to some instability limits. So, it’s a delicate balance. And there’s a lot of focus now on how to manage instabilities so that we can routinely and reliably take these plasmas and safely power them down. And there are relatively few studies done on how to do that well.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Bringing down the pulse&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Wang and his colleagues developed a model to predict how a plasma will behave during tokamak rampdown. While they could have simply applied machine-learning tools such as a neural network to learn signs of instabilities in plasma data, “you would need an ungodly amount of data” for such tools to discern the very subtle and ephemeral changes in extremely high-temperature, high-energy plasmas, Wang says.&lt;/p&gt;&lt;p&gt;Instead, the researchers paired a neural network with an existing model that simulates plasma dynamics according to the fundamental rules of physics. With this combination of machine learning and a physics-based plasma simulation, the team found that only a couple hundred pulses at low performance, and a small handful of pulses at high performance, were sufficient to train and validate the new model.&lt;/p&gt;&lt;p&gt;The data they used for the new study came from the TCV, the Swiss “variable configuration tokamak” operated by the Swiss Plasma Center at EPFL (the Swiss Federal Institute of Technology Lausanne). The TCV is a small experimental fusion experimental device that is used for research purposes, often as test bed for next-generation device solutions. Wang used the data from several hundred TCV plasma pulses that included properties of the plasma such as its temperature and energies during each pulse’s ramp-up, run, and ramp-down. He trained the new model on this data, then tested it and found it was able to accurately predict the plasma’s evolution given the initial conditions of a particular tokamak run.&lt;/p&gt;&lt;p&gt;The researchers also developed an algorithm to translate the model’s predictions into practical “trajectories,” or plasma-managing instructions that a tokamak controller can automatically carry out to for instance adjust the magnets or temperature maintain the plasma’s stability. They implemented the algorithm on several TCV runs and found that it produced trajectories that safely ramped down a plasma pulse, in some cases faster and without disruptions compared to runs without the new method.&lt;/p&gt;&lt;p&gt;“At some point the plasma will always go away, but we call it a disruption when the plasma goes away at high energy. Here, we ramped the energy down to nothing,” Wang notes. “We did it a number of times. And we did things much better across the board. So,&amp;nbsp;we had statistical confidence that we made things better.”&lt;/p&gt;&lt;p&gt;The work was supported in part by Commonwealth Fusion Systems (CFS), an MIT spinout that intends to build the world’s first compact, grid-scale fusion power plant. The company is developing a demo tokamak, SPARC, designed to produce net-energy plasma, meaning that it should generate more energy than it takes to heat up the plasma. Wang and his colleagues are working with CFS on ways that the new prediction model and tools like it can better predict plasma behavior and prevent costly disruptions to enable safe and reliable fusion power.&lt;/p&gt;&lt;p&gt;“We’re trying to tackle the science questions to make fusion routinely useful,” Wang says. “What we’ve done here is the start of what is still a long journey. But I think we’ve made some nice progress.”&lt;/p&gt;&lt;p&gt;Additional support for the research came from the framework of the EUROfusion Consortium, via the Euratom Research and Training Program and funded by the Swiss State Secretariat for Education, Research, and Innovation.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/new-prediction-model-could-improve-reliability-fusion-power-plants-1007</guid><pubDate>Tue, 07 Oct 2025 04:00:00 +0000</pubDate></item></channel></rss>