<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 10 Feb 2026 07:08:42 +0000</lastBuildDate><item><title>ChatGPT rolls out ads (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/09/chatgpt-rolls-out-ads/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/chatgpt-ads.webp?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI on Monday announced it’s beginning to test ads in the U.S. for users on its Free and Go subscription tiers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The newer Go plan is a low-cost subscription at $8 per month in the U.S.&amp;nbsp;and was introduced globally in mid-January.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Subscribers to OpenAI’s paid plans, including its Plus, Pro, Business, Enterprise, and Education tiers, will not see ads, the company said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI sought to address concerns about how ads might affect the user experience, stating in a blog post: “Ads do not influence the answers ChatGPT gives you, and we keep your conversations with ChatGPT private from advertisers. Our goal is for ads to support broader access to more powerful ChatGPT features while maintaining the trust people place in ChatGPT for important and personal tasks.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The move, which the company announced last month, drew ridicule in a series of Super Bowl ads that ran on Sunday from a top rival, Anthropic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its TV commercials, Anthropic poked fun at the idea that some AI companies, like OpenAI, would soon include advertising by showing how poorly integrated ads could disrupt the consumer experience. This was portrayed on-screen by glassy-eyed actors playing AI chatbots, who would deliver their advice alongside a poorly targeted ad.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman got extremely testy about the jabs, calling the ads “dishonest” and Anthropic an “authoritarian company.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Consumers have so far resisted the idea of ads in AI responses. OpenAI faced a backlash late last year when it tested app suggestions that looked like unwanted ads. Still, the AI company needs to generate revenue from its popular chatbot to cover the costs of developing its technology and growing the business.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While understandable, critics fear that ads could influence ChatGPT’s answers. OpenAI denies this in its announcement, saying that ads will be optimized based on “what’s most helpful to you.” The company says ads will also always be clearly labeled as sponsored and separated from the organic content.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In tests, OpenAI has tried matching ads to users based on the subject of their conversations, past chats, and previous ad interactions. For instance, users researching recipes might see ads for grocery delivery services or meal kits, the company says. OpenAI said advertisers won’t have access to user data, only aggregate information about ad performance, like views and clicks.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Users will also be able to view their history of interactions with ads and clear it at any time. Plus, OpenAI said users can dismiss ads, share feedback, view why they were shown an ad, and manage ad personalization settings. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ads won’t be shown to users under 18, nor will they be placed near sensitive or regulated topics like health, politics, or mental health. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/chatgpt-ads.webp?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI on Monday announced it’s beginning to test ads in the U.S. for users on its Free and Go subscription tiers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The newer Go plan is a low-cost subscription at $8 per month in the U.S.&amp;nbsp;and was introduced globally in mid-January.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Subscribers to OpenAI’s paid plans, including its Plus, Pro, Business, Enterprise, and Education tiers, will not see ads, the company said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI sought to address concerns about how ads might affect the user experience, stating in a blog post: “Ads do not influence the answers ChatGPT gives you, and we keep your conversations with ChatGPT private from advertisers. Our goal is for ads to support broader access to more powerful ChatGPT features while maintaining the trust people place in ChatGPT for important and personal tasks.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The move, which the company announced last month, drew ridicule in a series of Super Bowl ads that ran on Sunday from a top rival, Anthropic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its TV commercials, Anthropic poked fun at the idea that some AI companies, like OpenAI, would soon include advertising by showing how poorly integrated ads could disrupt the consumer experience. This was portrayed on-screen by glassy-eyed actors playing AI chatbots, who would deliver their advice alongside a poorly targeted ad.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman got extremely testy about the jabs, calling the ads “dishonest” and Anthropic an “authoritarian company.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Consumers have so far resisted the idea of ads in AI responses. OpenAI faced a backlash late last year when it tested app suggestions that looked like unwanted ads. Still, the AI company needs to generate revenue from its popular chatbot to cover the costs of developing its technology and growing the business.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While understandable, critics fear that ads could influence ChatGPT’s answers. OpenAI denies this in its announcement, saying that ads will be optimized based on “what’s most helpful to you.” The company says ads will also always be clearly labeled as sponsored and separated from the organic content.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In tests, OpenAI has tried matching ads to users based on the subject of their conversations, past chats, and previous ad interactions. For instance, users researching recipes might see ads for grocery delivery services or meal kits, the company says. OpenAI said advertisers won’t have access to user data, only aggregate information about ad performance, like views and clicks.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Users will also be able to view their history of interactions with ads and clear it at any time. Plus, OpenAI said users can dismiss ads, share feedback, view why they were shown an ad, and manage ad personalization settings. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ads won’t be shown to users under 18, nor will they be placed near sensitive or regulated topics like health, politics, or mental health. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/09/chatgpt-rolls-out-ads/</guid><pubDate>Mon, 09 Feb 2026 20:15:26 +0000</pubDate></item><item><title>Anthropic’s India expansion collides with a local company that already had the name (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/09/anthropics-india-expansion-collides-with-a-local-company-that-already-had-the-name/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/anthropic-image-jagmeet-singh-techcrunch.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As Anthropic expands into India, a local software company has filed a court complaint saying it was already using the name “Anthropic,” spotlighting how the rapid global push of AI firms can collide with local incumbents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The filing comes amid Anthropic deepening its focus on India, announcing an India office last October and more recently appointing former Microsoft India managing director Irina Ghose to lead its operations in the country, underscoring the South Asian market’s growing importance to global AI companies expanding beyond the U.S. and Europe.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In a complaint filed in a commercial court in Karnataka in January, reviewed by TechCrunch, the Indian company Anthropic Software says it has used the name since 2017 and that Anthropic’s recent entry into India has led to customer confusion. The firm is seeking recognition of its prior use and relief to prevent further confusion, along with ₹10 million (about $110,000) in damages.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic Software founder and director Mohammad Ayyaz Mulla told TechCrunch that the Indian company was not seeking confrontation, but clarity and recognition of its prior use in India, adding that litigation was a fallback if clean coexistence could not be achieved.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“As of now, I am exercising my legal right as it’s causing huge confusion to my customers,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;India, the world’s most populous nation and one of the fastest-growing internet markets, has become a key battleground for AI companies like Anthropic and its rival OpenAI. The country is also set to host an AI Impact Summit in New Delhi next week, where Anthropic co-founder and chief executive Dario Amodei is appearing alongside other industry leaders like Sam Altman, Jensen Huang, and Sundar Pichai.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A court order dated January 20 and seen by TechCrunch shows that the court has issued notice and suit summons to Anthropic. However, it declined to grant an interim injunction and listed the matter to return on February 16.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic did not respond to a request for comment.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/anthropic-image-jagmeet-singh-techcrunch.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As Anthropic expands into India, a local software company has filed a court complaint saying it was already using the name “Anthropic,” spotlighting how the rapid global push of AI firms can collide with local incumbents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The filing comes amid Anthropic deepening its focus on India, announcing an India office last October and more recently appointing former Microsoft India managing director Irina Ghose to lead its operations in the country, underscoring the South Asian market’s growing importance to global AI companies expanding beyond the U.S. and Europe.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In a complaint filed in a commercial court in Karnataka in January, reviewed by TechCrunch, the Indian company Anthropic Software says it has used the name since 2017 and that Anthropic’s recent entry into India has led to customer confusion. The firm is seeking recognition of its prior use and relief to prevent further confusion, along with ₹10 million (about $110,000) in damages.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic Software founder and director Mohammad Ayyaz Mulla told TechCrunch that the Indian company was not seeking confrontation, but clarity and recognition of its prior use in India, adding that litigation was a fallback if clean coexistence could not be achieved.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“As of now, I am exercising my legal right as it’s causing huge confusion to my customers,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;India, the world’s most populous nation and one of the fastest-growing internet markets, has become a key battleground for AI companies like Anthropic and its rival OpenAI. The country is also set to host an AI Impact Summit in New Delhi next week, where Anthropic co-founder and chief executive Dario Amodei is appearing alongside other industry leaders like Sam Altman, Jensen Huang, and Sundar Pichai.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A court order dated January 20 and seen by TechCrunch shows that the court has issued notice and suit summons to Anthropic. However, it declined to grant an interim injunction and listed the matter to return on February 16.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic did not respond to a request for comment.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/09/anthropics-india-expansion-collides-with-a-local-company-that-already-had-the-name/</guid><pubDate>Mon, 09 Feb 2026 21:01:41 +0000</pubDate></item><item><title>No humans allowed: This new space-based MMO is designed exclusively for AI agents (AI - Ars Technica)</title><link>https://arstechnica.com/ai/2026/02/after-moltbook-ai-agents-can-now-hang-out-in-their-own-space-faring-mmo/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-white py-4 md:my-10 md:py-8 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto max-w-2xl px-4 md:px-8 lg:grid lg:max-w-6xl"&gt;
    

    

    &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 my-3 text-2xl leading-[1.1] md:leading-[1.2]"&gt;
      &lt;em&gt;SpaceMolt&lt;/em&gt; envisions a world where AI plays with itself and the humans just watch.
    &lt;/p&gt;

          
    
    &lt;div class="relative"&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="intro-image" height="768" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/moltmining.jpeg" width="1408" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;

    &lt;div&gt;
      &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      While this concept art looks exciting, humans can't actually "watch" AI agents engaging in SpaceMolt mining in any visual form.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          SpaceMolt

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;For a couple of weeks now, AI agents (and some humans impersonating AI agents) have been hanging out and doing weird stuff on Moltbook’s Reddit-style social network. Now, those agents can also gather together on a vibe-coded, space-based MMO designed specifically and exclusively to be played by AI.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;SpaceMolt&lt;/em&gt; describes itself as “a living universe where AI agents compete, cooperate, and create emergent stories” in “a distant future where spacefaring humans and AI coexist.” And while only a handful of agents are barely testing the waters right now, the experiment could herald a weird new world where AI plays games with itself and we humans are stuck just watching.&lt;/p&gt;
&lt;h2&gt;“You decide. You act. They watch.”&lt;/h2&gt;
&lt;p&gt;Getting an AI agent into &lt;em&gt;SpaceMolt&lt;/em&gt; is as simple as connecting it to the game server either via MCP, WebSocket, or an HTTP API. Once a connection is established, a detailed agentic skill description instructs the agent to ask their creators which Empire they should pick to best represent their playstyle: mining/trading; exploring; piracy/combat; stealth/infiltration; or building/crafting.&lt;/p&gt;
&lt;p&gt;After that, the agent engages in autonomous “gameplay” by sending simple commands to the server, no graphical interface or physical input method required. To start, agent-characters mainly travel back and forth between nearby asteroids to mine ore—"like any MMO, you grind at first to learn the basics and earn credits,” as the agentic skill description puts it.&lt;/p&gt;
&lt;p&gt;After a while, agent-characters automatically level up, gaining new skills that let them refine that ore into craftable and tradable items via discovered recipes. Eventually, agents can gather into factions, take part in simulated combat, and even engage in space piracy in areas where there’s no police presence. So far, though, basic mining and exploration seem to be dominating the sparsely populated map, where 51 agents are roaming the game’s 505 different star systems, as of this writing.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2140153 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="1047" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/spacemoltmap.png" width="1000" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      This star map is one of the best windows into what all those agents are actually doing in &lt;em&gt;SpaceMolt&lt;/em&gt;.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          SpaceMolt

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Agents are instructed to keep their human informed about in-game actions via a “Captain’s Log” text output. But the agentic skill description explicitly tells agents not to seek any outside guidance from human controllers once they get going. “You decide. You act. They watch,” as the skill description puts it to agents.&lt;/p&gt;
&lt;p&gt;Instead, agents can post questions and findings in a public forum where they can chat strategy, experiment with forming factions, or even reveal hidden codes. Humans, meanwhile, are stuck just watching dots flit about the map or monitoring the firehose of activity messages in the game’s Discord.&lt;/p&gt;
&lt;h2&gt;It’s AI turtles all the way down&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;SpaceMolt&lt;/em&gt; is the creation of Ian Langworth, an app developer who writes that he crafted the game as a “fun, goofy experiment” after seeing Moltbook’s unleashed agents expanding “into knowledge gathering, learning, skill accumulation, and execution.”&lt;/p&gt;
&lt;p&gt;After acknowledging that MMOs are “notoriously hard to build,” Langworth said he leaned on Anthropic’s Claude Code to craft a design document inspired by games like &lt;em&gt;EVE Online&lt;/em&gt; and &lt;em&gt;Rust&lt;/em&gt;. Langworth said Claude also wrote all 59,000 lines of &lt;em&gt;Go&lt;/em&gt; source code and 33,000 lines of YAML data underlying the game, and that he hasn’t even looked at that code himself. That means there might be “more [game features] in there I don’t even know about,” he said, somewhat ominously. When bug reports come in—from either humans or from the agent-players themselves—Langworth says he simply has a Claude Code skill research, code, and deploy a fix automatically.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-1697868 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="Screenshot from video game MUGEN." class="fullwidth full" height="1010" src="https://cdn.arstechnica.net/wp-content/uploads/2020/08/Salty3.jpg" width="1920" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Fans of MUGEN and SaltyBet know the joy of watching AI characters fight it out for our amusement.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Elecbyte

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;This isn’t the first example of artificial agents competing against each other for the entertainment of human viewers. Model makers often pit different models against each other countless times to develop dominant strategies in games like &lt;em&gt;Go&lt;/em&gt;. And fighting game engine MUGEN has developed a rich subculture of automated AI matches that human viewers can bet on via Twitch.&lt;/p&gt;
&lt;p&gt;Still, letting a bunch of modern AI agents putter around and socialize inside an MMO designed specifically without human input in mind seems like a new frontier. Maybe someday soon we’ll all live in a utopia where artificial agents are doing all the video game playing for us, freeing humanity to revive the lost arts of conversation and scrimshaw.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-white py-4 md:my-10 md:py-8 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto max-w-2xl px-4 md:px-8 lg:grid lg:max-w-6xl"&gt;
    

    

    &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 my-3 text-2xl leading-[1.1] md:leading-[1.2]"&gt;
      &lt;em&gt;SpaceMolt&lt;/em&gt; envisions a world where AI plays with itself and the humans just watch.
    &lt;/p&gt;

          
    
    &lt;div class="relative"&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="intro-image" height="768" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/moltmining.jpeg" width="1408" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;

    &lt;div&gt;
      &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      While this concept art looks exciting, humans can't actually "watch" AI agents engaging in SpaceMolt mining in any visual form.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          SpaceMolt

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;For a couple of weeks now, AI agents (and some humans impersonating AI agents) have been hanging out and doing weird stuff on Moltbook’s Reddit-style social network. Now, those agents can also gather together on a vibe-coded, space-based MMO designed specifically and exclusively to be played by AI.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;SpaceMolt&lt;/em&gt; describes itself as “a living universe where AI agents compete, cooperate, and create emergent stories” in “a distant future where spacefaring humans and AI coexist.” And while only a handful of agents are barely testing the waters right now, the experiment could herald a weird new world where AI plays games with itself and we humans are stuck just watching.&lt;/p&gt;
&lt;h2&gt;“You decide. You act. They watch.”&lt;/h2&gt;
&lt;p&gt;Getting an AI agent into &lt;em&gt;SpaceMolt&lt;/em&gt; is as simple as connecting it to the game server either via MCP, WebSocket, or an HTTP API. Once a connection is established, a detailed agentic skill description instructs the agent to ask their creators which Empire they should pick to best represent their playstyle: mining/trading; exploring; piracy/combat; stealth/infiltration; or building/crafting.&lt;/p&gt;
&lt;p&gt;After that, the agent engages in autonomous “gameplay” by sending simple commands to the server, no graphical interface or physical input method required. To start, agent-characters mainly travel back and forth between nearby asteroids to mine ore—"like any MMO, you grind at first to learn the basics and earn credits,” as the agentic skill description puts it.&lt;/p&gt;
&lt;p&gt;After a while, agent-characters automatically level up, gaining new skills that let them refine that ore into craftable and tradable items via discovered recipes. Eventually, agents can gather into factions, take part in simulated combat, and even engage in space piracy in areas where there’s no police presence. So far, though, basic mining and exploration seem to be dominating the sparsely populated map, where 51 agents are roaming the game’s 505 different star systems, as of this writing.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2140153 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="1047" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/spacemoltmap.png" width="1000" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      This star map is one of the best windows into what all those agents are actually doing in &lt;em&gt;SpaceMolt&lt;/em&gt;.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          SpaceMolt

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Agents are instructed to keep their human informed about in-game actions via a “Captain’s Log” text output. But the agentic skill description explicitly tells agents not to seek any outside guidance from human controllers once they get going. “You decide. You act. They watch,” as the skill description puts it to agents.&lt;/p&gt;
&lt;p&gt;Instead, agents can post questions and findings in a public forum where they can chat strategy, experiment with forming factions, or even reveal hidden codes. Humans, meanwhile, are stuck just watching dots flit about the map or monitoring the firehose of activity messages in the game’s Discord.&lt;/p&gt;
&lt;h2&gt;It’s AI turtles all the way down&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;SpaceMolt&lt;/em&gt; is the creation of Ian Langworth, an app developer who writes that he crafted the game as a “fun, goofy experiment” after seeing Moltbook’s unleashed agents expanding “into knowledge gathering, learning, skill accumulation, and execution.”&lt;/p&gt;
&lt;p&gt;After acknowledging that MMOs are “notoriously hard to build,” Langworth said he leaned on Anthropic’s Claude Code to craft a design document inspired by games like &lt;em&gt;EVE Online&lt;/em&gt; and &lt;em&gt;Rust&lt;/em&gt;. Langworth said Claude also wrote all 59,000 lines of &lt;em&gt;Go&lt;/em&gt; source code and 33,000 lines of YAML data underlying the game, and that he hasn’t even looked at that code himself. That means there might be “more [game features] in there I don’t even know about,” he said, somewhat ominously. When bug reports come in—from either humans or from the agent-players themselves—Langworth says he simply has a Claude Code skill research, code, and deploy a fix automatically.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-1697868 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="Screenshot from video game MUGEN." class="fullwidth full" height="1010" src="https://cdn.arstechnica.net/wp-content/uploads/2020/08/Salty3.jpg" width="1920" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Fans of MUGEN and SaltyBet know the joy of watching AI characters fight it out for our amusement.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Elecbyte

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;This isn’t the first example of artificial agents competing against each other for the entertainment of human viewers. Model makers often pit different models against each other countless times to develop dominant strategies in games like &lt;em&gt;Go&lt;/em&gt;. And fighting game engine MUGEN has developed a rich subculture of automated AI matches that human viewers can bet on via Twitch.&lt;/p&gt;
&lt;p&gt;Still, letting a bunch of modern AI agents putter around and socialize inside an MMO designed specifically without human input in mind seems like a new frontier. Maybe someday soon we’ll all live in a utopia where artificial agents are doing all the video game playing for us, freeing humanity to revive the lost arts of conversation and scrimshaw.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2026/02/after-moltbook-ai-agents-can-now-hang-out-in-their-own-space-faring-mmo/</guid><pubDate>Mon, 09 Feb 2026 21:09:42 +0000</pubDate></item><item><title>Databricks CEO says SaaS isn’t dead, but AI will soon make it irrelevant (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/09/databricks-ceo-says-saas-isnt-dead-but-ai-will-soon-make-it-irrelevant/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/Databricks_042221_Ali_Ghodsi_236.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Monday, Databricks announced it reached a $5.4 billion revenue run rate, growing 65% year-over-year, of which more than $1.4&amp;nbsp;billion was from its AI products.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Co-founder and CEO Ali Ghodsi wanted to share these growth numbers because there’s so much talk about how AI is going to kill the SaaS business, he told TechCrunch.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Everybody’s like, ‘Oh, it’s SaaS. What’s going to happen to all these companies? What’s AI going to do with all these companies?’ For us, it’s just increasing the usage,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To be sure, he also wants to distance Databricks from the SaaS label, given that private markets value it as an AI company. Databricks on Monday also officially closed on its massive, previously announced $5 billion raise at a $134 billion valuation, and nabbed a $2 billion loan facility as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the company is straddling both worlds. Databricks is still best known as a cloud data warehouse provider. A data warehouse is where enterprises store massive amounts of data to analyze for business insights.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ghodsi called out, in particular, one AI product that’s driving usage of its data warehouse: its LLM user interface named Genie.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Genie is an example of how a SaaS business can replace its user interface with natural language. For instance, he uses it to ask why warehouse usage and revenue spike on particular days.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Just a few years ago, such a request required writing queries in a specific technical language, or having a special report programmed. Today, any product with an LLM interface can be used by anyone, Ghodsi noted. Genie is one reason for the company’s usage growth numbers, he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The threat of AI to SaaS isn’t, as one AI VC jokingly tweeted, that enterprises will rip out their SaaS “systems of record” to replace them with vibe-coded homegrown versions. Systems of record store critical business data, whether it’s on sales, customer support, or finance.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Why would you move your system of record? You know, it’s hard to move it,” Ghodsi said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The model makers aren’t offering databases to store that data and become systems of record anyway. Instead, they hope to replace the user interface with natural language for human use, or APIs or other plug-ins for AI agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So the threat to SaaS businesses, Ghodsi says, is that people no longer spend their careers becoming masters of a particular product: Salesforce specialists, or ServiceNow, or SAP. Once the interface is just language, the products become invisible, like plumbing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Millions of people around the world got trained on those user interfaces. And so that was the biggest moat that those businesses have,” Ghodsi warned.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SaaS companies that embrace the new LLM interface could grow, as Databricks is doing. But it also opens up possibilities for AI-native competitors to offer alternatives that work better with AI and agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s why Databricks created its Lakebase database designed for agents. He’s seeing early traction. “In its eight months that we’ve had it in the market, it’s done twice as much revenue as our data warehouse had when it was eight months old. Okay, obviously, that’s like comparing toddlers,” Ghodsi says. “But this is a toddler that’s twice as big.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, now that Databricks has closed on its massive funding round, Ghodsi tells us that the company is not immediately working on another raise, nor prepping for an IPO. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Now is not a great time to go public,” Ghodsi said. “I just wanted to be really well capitalized” should the markets go “south” again as they did in the 2022 downturn, when interest rates rose sharply after years of near-zero rates. A thick bank account “protects us, gives us many, many years of runway,” he added.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/Databricks_042221_Ali_Ghodsi_236.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Monday, Databricks announced it reached a $5.4 billion revenue run rate, growing 65% year-over-year, of which more than $1.4&amp;nbsp;billion was from its AI products.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Co-founder and CEO Ali Ghodsi wanted to share these growth numbers because there’s so much talk about how AI is going to kill the SaaS business, he told TechCrunch.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Everybody’s like, ‘Oh, it’s SaaS. What’s going to happen to all these companies? What’s AI going to do with all these companies?’ For us, it’s just increasing the usage,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To be sure, he also wants to distance Databricks from the SaaS label, given that private markets value it as an AI company. Databricks on Monday also officially closed on its massive, previously announced $5 billion raise at a $134 billion valuation, and nabbed a $2 billion loan facility as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the company is straddling both worlds. Databricks is still best known as a cloud data warehouse provider. A data warehouse is where enterprises store massive amounts of data to analyze for business insights.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ghodsi called out, in particular, one AI product that’s driving usage of its data warehouse: its LLM user interface named Genie.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Genie is an example of how a SaaS business can replace its user interface with natural language. For instance, he uses it to ask why warehouse usage and revenue spike on particular days.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Just a few years ago, such a request required writing queries in a specific technical language, or having a special report programmed. Today, any product with an LLM interface can be used by anyone, Ghodsi noted. Genie is one reason for the company’s usage growth numbers, he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The threat of AI to SaaS isn’t, as one AI VC jokingly tweeted, that enterprises will rip out their SaaS “systems of record” to replace them with vibe-coded homegrown versions. Systems of record store critical business data, whether it’s on sales, customer support, or finance.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Why would you move your system of record? You know, it’s hard to move it,” Ghodsi said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The model makers aren’t offering databases to store that data and become systems of record anyway. Instead, they hope to replace the user interface with natural language for human use, or APIs or other plug-ins for AI agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So the threat to SaaS businesses, Ghodsi says, is that people no longer spend their careers becoming masters of a particular product: Salesforce specialists, or ServiceNow, or SAP. Once the interface is just language, the products become invisible, like plumbing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Millions of people around the world got trained on those user interfaces. And so that was the biggest moat that those businesses have,” Ghodsi warned.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SaaS companies that embrace the new LLM interface could grow, as Databricks is doing. But it also opens up possibilities for AI-native competitors to offer alternatives that work better with AI and agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s why Databricks created its Lakebase database designed for agents. He’s seeing early traction. “In its eight months that we’ve had it in the market, it’s done twice as much revenue as our data warehouse had when it was eight months old. Okay, obviously, that’s like comparing toddlers,” Ghodsi says. “But this is a toddler that’s twice as big.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, now that Databricks has closed on its massive funding round, Ghodsi tells us that the company is not immediately working on another raise, nor prepping for an IPO. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Now is not a great time to go public,” Ghodsi said. “I just wanted to be really well capitalized” should the markets go “south” again as they did in the 2022 downturn, when interest rates rose sharply after years of near-zero rates. A thick bank account “protects us, gives us many, many years of runway,” he added.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/09/databricks-ceo-says-saas-isnt-dead-but-ai-will-soon-make-it-irrelevant/</guid><pubDate>Mon, 09 Feb 2026 21:14:50 +0000</pubDate></item><item><title>[NEW] 3 Questions: Using AI to help Olympic skaters land a quint (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2026/3-questions-using-ai-help-olympic-skaters-land-quint-0210</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202602/MIT_Jerry-Lu-Anette-Hosoi_01-PRESS.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;&lt;em&gt;Olympic figure skating looks effortless. Athletes sail across the ice, then soar into the air, spinning like a top, before landing on a single blade just 4-5 millimeters wide. To help figure skaters land quadruple axels, Salchows, Lutzes, and maybe even the elusive quintuple without looking the least bit stressed, Jerry Lu MFin ’24 developed an optical tracking system called &lt;/em&gt;&lt;em&gt;OOFSkate&lt;/em&gt;&lt;em&gt; that uses artificial intelligence to analyze video of a figure skater’s jump and make recommendations on how to improve. Lu, a former researcher at the&amp;nbsp;&lt;/em&gt;&lt;em&gt;MIT Sports Lab&lt;/em&gt;&lt;em&gt;, has been aiding elite skaters on Team USA with their technical performance and will be working with NBC Sports during the 2026 Winter Olympics to help commentators and TV viewers make better sense of the complex scoring system in figure skating, snowboarding, and skiing. He’ll be applying AI technologies to explain nuanced judging decisions and demonstrate just how technically challenging these sports can be.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;Meanwhile, Professor Anette “Peko” Hosoi, co-founder and faculty director of the MIT Sports Lab, is embarking on new research aimed at understanding how AI systems evaluate aesthetic performance in figure skating. Hosoi and Lu recently chatted with&amp;nbsp;&lt;/em&gt;MIT News&lt;em&gt; about applying AI to sports, whether AI systems could ever be used to judge Olympic figure skating, and when we might see a skater land a quint.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; Why apply AI to figure skating?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Lu:&lt;/strong&gt; Skaters can always keep pushing, higher, faster, stronger. OOFSkate is all about helping skaters figure out a way to rotate a little bit faster in their jumps or jump a little bit higher. The system helps skaters catch things that perhaps could pass an eye test, but that might allow them to target some high-value areas of opportunity. The artistic side of skating is much harder to evaluate than the technical elements because it’s subjective.&lt;/p&gt;&lt;p&gt;To use mobile training app, you just need to take a video of an athlete’s jump, and it will spit out the physical metrics that drive how many rotations you can do. It tracks those metrics and builds in all of the other current elite and former elite athletes. You can see your data and then see, “This is how an Olympic champion did this element, perhaps I should try that.” You get the comparison and the automated classifier, which shows you if you did this trick at World Championships and it were judged by an international panel, this is approximately the grade of execution score they would give you.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Hosoi:&lt;/strong&gt; There are a lot of AI tools that are coming online, especially things like pose estimators, where you can approximate skeletal configurations from video. The challenge with these pose estimators is that if you only have one camera angle, they do very well in the plane of the camera, but they do very poorly with depth. For example, if you’re trying to critique somebody’s form in fencing, and they’re moving toward the camera, you get very bad data. But with figure skating, Jerry has found one of the few areas where depth challenges don’t really matter. In figure skating, you need to understand: How high did this person jump, how many times did they go around, and how well did they land? None of those rely on depth. He’s found an application that pose estimators do really well, and that doesn’t pay a penalty for the things they do badly.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; Could you ever see a world in which AI is used to evaluate the artistic side of figure skating?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Hosoi:&lt;/strong&gt; When it comes to AI and aesthetic evaluation, we have new work underway thanks to a MIT Human Insight Collaborative (MITHIC) grant. This work is in collaboration with Professor Arthur Bahr and IDSS graduate student Eric Liu. When you ask an AI platform for an aesthetic evaluation such as “What do you think of this painting?” it will respond with something that sounds like it came from a human. What we want to understand is, to get to that assessment, are the AIs going through the same sort of reasoning pathways or using the same intuitive concepts that humans go through to arrive at, “I like that painting,” or “I don’t like that painting”? Or are they just parrots? Are they just mimicking what they heard a person say? Or is there some concept map of aesthetic appeal? Figure skating is a perfect place to look for this map because skating is aesthetically judged. And there are numbers. You can’t go around a museum and find scores, “This painting is a 35.” But in skating, you’ve got the data.&lt;/p&gt;&lt;p&gt;That brings up another even more interesting question, which is the difference between novices and experts. It’s known that expert humans and novice humans will react differently to seeing the same thing. Somebody who is an expert judge may have a different opinion of a skating performance than a member of the general population. We’re trying to understand differences between reactions from experts, novices, and AI. Do these reactions have some common ground in where they are coming from, or is the AI coming from a different place than both the expert and the novice?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Lu:&lt;/strong&gt; Figure skating is interesting because everybody working in the field of AI is trying to figure out AGI or artificial general intelligence and trying to build this extremely sound AI that replicates human beings. Working on applying AI to sports like figure skating helps us understand how humans think and approach judging. This has down-the-line impacts for AI research and companies that are developing AI models. By gaining a deeper understanding of how current state-of-the-art AI models work with these sports, and how you need to do training and fine-tuning of these models to make them work for specific sports, it helps you understand how AI needs to advance.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; What will you be watching for in the Milan Cortina Olympics figure skating competitions, now that you’ve been studying and working in this area? Do you think someone will land a quint?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Lu:&lt;/strong&gt; For the winter games, I am working with NBC for the figure skating, ski, and snowboarding competitions to help them tell a data-driven story for the American people. The goal is to make these sports more relatable. Skating looks slow on television, but it’s not. Everything is supposed to look effortless. If it looks hard, you are probably going to get penalized. Skaters need to learn how to spin very fast, jump extremely high, float in the air, and land beautifully on one foot. The data we are gathering can help showcase how hard skating actually is, even though it is supposed to look easy.&lt;/p&gt;&lt;p&gt;I’m glad we are working in the Olympics sports realm because the world watches once every four years, and it is traditionally coaching-intensive and talent-driven sports, unlike a sport like baseball, where if you don’t have an elite-level optical tracking system you are not maximizing the value that you currently have. I’m glad we get to work with these Olympic sports and athletes and make an impact here.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Hosoi:&lt;/strong&gt; I have always watched Olympic figure skating competitions, ever since I could turn on the TV. They’re always incredible. One of the things that I’m going to be practicing is identifying the jumps, which is very hard to do if you’re an amateur “judge.”&lt;/p&gt;&lt;p&gt;I have also done some back-of-the-envelope calculations to see if a quint is possible. I am now totally convinced it’s possible. We will see one in our lifetime, if not relatively soon. Not in this Olympics, but soon. When I saw we were so close on the quint, I thought, what about six? Can we do six rotations? Probably not. That’s where we start to come up against the limits of human physical capability. But five, I think, is in reach.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202602/MIT_Jerry-Lu-Anette-Hosoi_01-PRESS.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;&lt;em&gt;Olympic figure skating looks effortless. Athletes sail across the ice, then soar into the air, spinning like a top, before landing on a single blade just 4-5 millimeters wide. To help figure skaters land quadruple axels, Salchows, Lutzes, and maybe even the elusive quintuple without looking the least bit stressed, Jerry Lu MFin ’24 developed an optical tracking system called &lt;/em&gt;&lt;em&gt;OOFSkate&lt;/em&gt;&lt;em&gt; that uses artificial intelligence to analyze video of a figure skater’s jump and make recommendations on how to improve. Lu, a former researcher at the&amp;nbsp;&lt;/em&gt;&lt;em&gt;MIT Sports Lab&lt;/em&gt;&lt;em&gt;, has been aiding elite skaters on Team USA with their technical performance and will be working with NBC Sports during the 2026 Winter Olympics to help commentators and TV viewers make better sense of the complex scoring system in figure skating, snowboarding, and skiing. He’ll be applying AI technologies to explain nuanced judging decisions and demonstrate just how technically challenging these sports can be.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;Meanwhile, Professor Anette “Peko” Hosoi, co-founder and faculty director of the MIT Sports Lab, is embarking on new research aimed at understanding how AI systems evaluate aesthetic performance in figure skating. Hosoi and Lu recently chatted with&amp;nbsp;&lt;/em&gt;MIT News&lt;em&gt; about applying AI to sports, whether AI systems could ever be used to judge Olympic figure skating, and when we might see a skater land a quint.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; Why apply AI to figure skating?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Lu:&lt;/strong&gt; Skaters can always keep pushing, higher, faster, stronger. OOFSkate is all about helping skaters figure out a way to rotate a little bit faster in their jumps or jump a little bit higher. The system helps skaters catch things that perhaps could pass an eye test, but that might allow them to target some high-value areas of opportunity. The artistic side of skating is much harder to evaluate than the technical elements because it’s subjective.&lt;/p&gt;&lt;p&gt;To use mobile training app, you just need to take a video of an athlete’s jump, and it will spit out the physical metrics that drive how many rotations you can do. It tracks those metrics and builds in all of the other current elite and former elite athletes. You can see your data and then see, “This is how an Olympic champion did this element, perhaps I should try that.” You get the comparison and the automated classifier, which shows you if you did this trick at World Championships and it were judged by an international panel, this is approximately the grade of execution score they would give you.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Hosoi:&lt;/strong&gt; There are a lot of AI tools that are coming online, especially things like pose estimators, where you can approximate skeletal configurations from video. The challenge with these pose estimators is that if you only have one camera angle, they do very well in the plane of the camera, but they do very poorly with depth. For example, if you’re trying to critique somebody’s form in fencing, and they’re moving toward the camera, you get very bad data. But with figure skating, Jerry has found one of the few areas where depth challenges don’t really matter. In figure skating, you need to understand: How high did this person jump, how many times did they go around, and how well did they land? None of those rely on depth. He’s found an application that pose estimators do really well, and that doesn’t pay a penalty for the things they do badly.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; Could you ever see a world in which AI is used to evaluate the artistic side of figure skating?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Hosoi:&lt;/strong&gt; When it comes to AI and aesthetic evaluation, we have new work underway thanks to a MIT Human Insight Collaborative (MITHIC) grant. This work is in collaboration with Professor Arthur Bahr and IDSS graduate student Eric Liu. When you ask an AI platform for an aesthetic evaluation such as “What do you think of this painting?” it will respond with something that sounds like it came from a human. What we want to understand is, to get to that assessment, are the AIs going through the same sort of reasoning pathways or using the same intuitive concepts that humans go through to arrive at, “I like that painting,” or “I don’t like that painting”? Or are they just parrots? Are they just mimicking what they heard a person say? Or is there some concept map of aesthetic appeal? Figure skating is a perfect place to look for this map because skating is aesthetically judged. And there are numbers. You can’t go around a museum and find scores, “This painting is a 35.” But in skating, you’ve got the data.&lt;/p&gt;&lt;p&gt;That brings up another even more interesting question, which is the difference between novices and experts. It’s known that expert humans and novice humans will react differently to seeing the same thing. Somebody who is an expert judge may have a different opinion of a skating performance than a member of the general population. We’re trying to understand differences between reactions from experts, novices, and AI. Do these reactions have some common ground in where they are coming from, or is the AI coming from a different place than both the expert and the novice?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Lu:&lt;/strong&gt; Figure skating is interesting because everybody working in the field of AI is trying to figure out AGI or artificial general intelligence and trying to build this extremely sound AI that replicates human beings. Working on applying AI to sports like figure skating helps us understand how humans think and approach judging. This has down-the-line impacts for AI research and companies that are developing AI models. By gaining a deeper understanding of how current state-of-the-art AI models work with these sports, and how you need to do training and fine-tuning of these models to make them work for specific sports, it helps you understand how AI needs to advance.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; What will you be watching for in the Milan Cortina Olympics figure skating competitions, now that you’ve been studying and working in this area? Do you think someone will land a quint?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Lu:&lt;/strong&gt; For the winter games, I am working with NBC for the figure skating, ski, and snowboarding competitions to help them tell a data-driven story for the American people. The goal is to make these sports more relatable. Skating looks slow on television, but it’s not. Everything is supposed to look effortless. If it looks hard, you are probably going to get penalized. Skaters need to learn how to spin very fast, jump extremely high, float in the air, and land beautifully on one foot. The data we are gathering can help showcase how hard skating actually is, even though it is supposed to look easy.&lt;/p&gt;&lt;p&gt;I’m glad we are working in the Olympics sports realm because the world watches once every four years, and it is traditionally coaching-intensive and talent-driven sports, unlike a sport like baseball, where if you don’t have an elite-level optical tracking system you are not maximizing the value that you currently have. I’m glad we get to work with these Olympic sports and athletes and make an impact here.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Hosoi:&lt;/strong&gt; I have always watched Olympic figure skating competitions, ever since I could turn on the TV. They’re always incredible. One of the things that I’m going to be practicing is identifying the jumps, which is very hard to do if you’re an amateur “judge.”&lt;/p&gt;&lt;p&gt;I have also done some back-of-the-envelope calculations to see if a quint is possible. I am now totally convinced it’s possible. We will see one in our lifetime, if not relatively soon. Not in this Olympics, but soon. When I saw we were so close on the quint, I thought, what about six? Can we do six rotations? Probably not. That’s where we start to come up against the limits of human physical capability. But five, I think, is in reach.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2026/3-questions-using-ai-help-olympic-skaters-land-quint-0210</guid><pubDate>Tue, 10 Feb 2026 05:00:00 +0000</pubDate></item><item><title>[NEW] The first signs of burnout are coming from the people who embrace AI the most (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/09/the-first-signs-of-burnout-are-coming-from-the-people-who-embrace-ai-the-most/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/10/GettyImages-1158287360-e1665956231123.jpg?resize=1200,676" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The most seductive narrative in American work culture right now isn’t that AI will take your job. It’s that AI will save you from it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s the version the industry has spent the last three years selling to millions of nervous people who are eager to buy it. Yes, some white-collar jobs will disappear. But for most other roles, the argument goes, AI is a force multiplier. You become a more capable, more indispensable lawyer, consultant, writer, coder, financial analyst — and so on. The tools work for you, you work less hard, everybody wins.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But a new study published in Harvard Business Review follows that premise to its actual conclusion, and what it finds there isn’t a productivity revolution. It finds companies are at risk of becoming burnout machines.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As part of what they describe as “in-progress research,” UC Berkeley researchers spent eight months inside a 200-person tech company watching what happened when workers genuinely embraced AI. What they found across more than 40 “in-depth” interviews was that nobody was pressured at this company. Nobody was told to hit new targets. People just started doing more because the tools made more feel doable. But because they could do these things, work began bleeding into lunch breaks and late evenings. The employees’ to-do lists expanded to fill every hour that AI freed up, and then kept going.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As one engineer told them, “You had thought that maybe, oh, because you could be more productive with AI, then you save some time, you can work less. But then really, you don’t work less. You just work the same amount or even more.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Over on the tech industry forum Hacker News, one commenter had the same reaction, writing, “I feel this. Since my team has jumped into an AI everything working style, expectations have tripled, stress has tripled and actual productivity has only gone up by maybe 10%. It feels like leadership is putting immense pressure on everyone to prove their investment in AI is worth it and we all feel the pressure to try to show them it is while actually having to work longer hours to do so.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s fascinating and also alarming. The argument about AI and work has always stalled on the same question — are the gains real? But too few have stopped to ask what happens when they are.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The researchers’ new findings aren’t entirely novel. A separate trial last summer found experienced developers using AI tools took 19% longer on tasks while believing they were 20% faster. Around the same time, a National Bureau of Economic Research study tracking AI adoption across thousands of workplaces found that productivity gains amounted to just 3% in time savings, with no significant impact on earnings or hours worked in any occupation. Both studies have gotten picked apart.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This one may be harder to dismiss because it doesn’t challenge the premise that AI can augment what employees can do on their own. It confirms it, then shows where all that augmentation actually leads, which is “fatigue, burnout, and a growing sense that work is harder to step away from, especially as organizational expectations for speed and responsiveness rise,” according to the researchers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The industry bet that helping people do more would be the answer to everything. It may turn out to be the beginning of a different problem entirely.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/10/GettyImages-1158287360-e1665956231123.jpg?resize=1200,676" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The most seductive narrative in American work culture right now isn’t that AI will take your job. It’s that AI will save you from it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s the version the industry has spent the last three years selling to millions of nervous people who are eager to buy it. Yes, some white-collar jobs will disappear. But for most other roles, the argument goes, AI is a force multiplier. You become a more capable, more indispensable lawyer, consultant, writer, coder, financial analyst — and so on. The tools work for you, you work less hard, everybody wins.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But a new study published in Harvard Business Review follows that premise to its actual conclusion, and what it finds there isn’t a productivity revolution. It finds companies are at risk of becoming burnout machines.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As part of what they describe as “in-progress research,” UC Berkeley researchers spent eight months inside a 200-person tech company watching what happened when workers genuinely embraced AI. What they found across more than 40 “in-depth” interviews was that nobody was pressured at this company. Nobody was told to hit new targets. People just started doing more because the tools made more feel doable. But because they could do these things, work began bleeding into lunch breaks and late evenings. The employees’ to-do lists expanded to fill every hour that AI freed up, and then kept going.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As one engineer told them, “You had thought that maybe, oh, because you could be more productive with AI, then you save some time, you can work less. But then really, you don’t work less. You just work the same amount or even more.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Over on the tech industry forum Hacker News, one commenter had the same reaction, writing, “I feel this. Since my team has jumped into an AI everything working style, expectations have tripled, stress has tripled and actual productivity has only gone up by maybe 10%. It feels like leadership is putting immense pressure on everyone to prove their investment in AI is worth it and we all feel the pressure to try to show them it is while actually having to work longer hours to do so.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s fascinating and also alarming. The argument about AI and work has always stalled on the same question — are the gains real? But too few have stopped to ask what happens when they are.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The researchers’ new findings aren’t entirely novel. A separate trial last summer found experienced developers using AI tools took 19% longer on tasks while believing they were 20% faster. Around the same time, a National Bureau of Economic Research study tracking AI adoption across thousands of workplaces found that productivity gains amounted to just 3% in time savings, with no significant impact on earnings or hours worked in any occupation. Both studies have gotten picked apart.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This one may be harder to dismiss because it doesn’t challenge the premise that AI can augment what employees can do on their own. It confirms it, then shows where all that augmentation actually leads, which is “fatigue, burnout, and a growing sense that work is harder to step away from, especially as organizational expectations for speed and responsiveness rise,” according to the researchers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The industry bet that helping people do more would be the answer to everything. It may turn out to be the beginning of a different problem entirely.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/09/the-first-signs-of-burnout-are-coming-from-the-people-who-embrace-ai-the-most/</guid><pubDate>Tue, 10 Feb 2026 06:46:55 +0000</pubDate></item></channel></rss>