<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 04 Sep 2025 12:40:44 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>[NEW] Resham Kotecha, Open Data Institute: How the EU can lead in AI (AI News)</title><link>https://www.artificialintelligence-news.com/news/how-the-eu-can-lead-in-ai/</link><description>&lt;p&gt;The EU has a chance to shape how the world approaches AI and data governance. &lt;em&gt;AI News&lt;/em&gt; spoke with Resham Kotecha, Global Head of Policy at the Open Data Institute (ODI), who said that opportunity lies in proving that protecting people’s rights and supporting innovation can go hand in hand.&lt;/p&gt;&lt;p&gt;The ODI’s European Data and AI Policy Manifesto sets out six principles for policymakers, calling for strong governance, inclusive ecosystems, and public participation to guide AI development.&lt;/p&gt;&lt;h3&gt;Setting standards in AI and data&lt;/h3&gt;&lt;p&gt;“The EU has a unique opportunity to shape a global benchmark for digital governance that puts people first,” Kotecha said. The manifesto’s first principle makes clear that innovation and competitiveness must be built on regulation that safeguards people and strengthens trust.&lt;/p&gt;&lt;figure class="wp-block-image alignright size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-109232" height="437" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/09/Resham-Kotecha-Global-Head-of-Policy-at-the-Open-Data-Institute-ODI.jpg" width="437" /&gt;&lt;figcaption class="wp-element-caption"&gt;Resham Kotecha, Global Head of Policy at the Open Data Institute (ODI).&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Common European Data Spaces and Gaia-X are early examples of how the EU is building the foundations for AI development while protecting rights. The initiatives aim to create shared infrastructure that lets governments, businesses, and researchers pool data without giving up control. If they succeed, Europe could combine large-scale data use with strong protections for privacy and security.&lt;/p&gt;&lt;p&gt;Privacy-enhancing technologies (PETs) are another piece of the puzzle. The tools allow organisations to analyse or share insights from sensitive datasets without exposing the raw data itself. Horizon Europe and Digital Europe already support research and deployment of PETs. What is needed now, Kotecha argued, is consistency: “Making sure PETs move out of pilots and into mainstream use.” That shift would allow firms to use more data responsibly and show citizens their rights are taken seriously.&lt;/p&gt;&lt;p&gt;Trust will also depend on oversight. Independent organisations, Kotecha said, provide the checks and balances needed for trustworthy AI. “They offer impartial scrutiny, build public confidence, and hold both governments and industry accountable.” The ODI’s own Data Institutions Programme offers guidance on how these bodies can be structured and supported.&lt;/p&gt;&lt;h3&gt;Open data as the EU’s foundation for AI&lt;/h3&gt;&lt;p&gt;The manifesto calls open data a foundation for responsible AI, but many businesses remain wary of sharing. Concerns range from commercial risks and legal uncertainty to worries about quality and format. Even when data is published, it is often unstructured or inconsistent, making it hard to use.&lt;/p&gt;&lt;p&gt;Kotecha argued the EU should reduce the costs organisations face in collecting, using, and sharing data for AI. “The EU should explore a range of interventions, including combining legislative frameworks, financial incentives, capacity building, and data infrastructure development,” she said. By lowering barriers, Europe could encourage private organisations to share more data responsibly, creating both public and economic benefits.&lt;/p&gt;&lt;p&gt;The ODI’s research shows that clear communication matters. Senior decision-makers need to see tangible business benefits of data sharing, not just broad ‘public good’ arguments. At the same time, sensitivities around commercial data need to be addressed.&lt;/p&gt;&lt;p&gt;Useful structures already exist – the Data Spaces Support Centre (DSSC) and the International Data Spaces Association (IDSA) are building governance and technical frameworks that make sharing safer and easier. Updates to the Data Governance Act (DGA) and GDPR are also clarifying permissions for responsible reuse.&lt;/p&gt;&lt;p&gt;Regulatory sandboxes can build on this foundation. By letting firms test new approaches in a controlled environment, sandboxes can demonstrate that public benefit and commercial value are not in conflict. Privacy-enhancing technologies add another layer of safety by enabling the sharing of sensitive data without exposing individuals to risk.&lt;/p&gt;&lt;h3&gt;Building EU-wide trust and cross-border AI ecosystems&lt;/h3&gt;&lt;p&gt;One of the biggest hurdles for Europe is making data work inside member countries. Legal uncertainty, diverging national standards, and inconsistent governance fragment any system.&lt;/p&gt;&lt;p&gt;The Data Governance Act is central to the EU’s plan to create trusted, cross-border AI ecosystems. But laws on their own will not solve the problem. “The real test will be in how consistently member states implement [the Data Governance Act], and how much support is given to organisations that want to participate,” Kotecha said. If Europe can align on standards and execution, it could strengthen its AI ecosystem and set the global standard for trustworthy cross-border data flows.&lt;/p&gt;&lt;p&gt;That will require more than technical fixes – building trust between governments, businesses, and civil society is just as important. For Kotecha, the solution lies in creating “an open and trustworthy data ecosystem, where collaboration helps to maximise data value while managing risks connected with cross-border sharing.”&lt;/p&gt;&lt;h3&gt;Independence through funding and governance&lt;/h3&gt;&lt;p&gt;Oversight of AI systems requires sustainable structures. Without long-term funding, independent organisations risk becoming project-based consultancies rather than consistent watchdogs. “Civil society and independent organisations need commitments for long-term, strategic funding streams to carry out oversight, not just project-based support,” Kotecha said.&lt;/p&gt;&lt;p&gt;The ODI’s Data Institutions Programme has explored governance models that keep organisations independent while enabling them to steward data responsibly. “Independence relies on more than money. It requires transparency, ethical oversight, inclusion in political decision-making, and accountability structures that keep organisations anchored in the public interest,” Kotecha said.&lt;/p&gt;&lt;p&gt;Embedding such principles into EU funding models might ensure oversight bodies remain independent and effective. Strong governance should include ethical oversight, risk management, transparency, and clear roles, handled by board sub-committees on ethics, audit, and remuneration.&lt;/p&gt;&lt;h3&gt;Making data work for startups&lt;/h3&gt;&lt;p&gt;Access to valuable datasets is often limited to major tech firms. Smaller players struggle with the cost and complexity of acquiring high-value data. This is where initiatives like AI Factories and Data Labs come in. Designed to lower barriers, they give startups curated datasets, tools, and expertise that would otherwise be out of reach.&lt;/p&gt;&lt;p&gt;The model has worked before; like Data Pitch, a project that paired SMEs and startups with data from large organisations. That helped unlock previously closed datasets. Over three years, it supported 47 startups from 13 countries, helped create more than 100 new jobs, and generated €18 million in sales and investments.&lt;/p&gt;&lt;p&gt;The ODI’s OpenActive initiative showed a similar impact in the fitness and health sector, using open standards to power dozens of SME-built apps. At a European level, DSSC pilots and new sector-specific data spaces in areas like mobility and health are starting to create similar opportunities. For Kotecha, the challenge now is ensuring these schemes “genuinely lower barriers for smaller players, so they can build innovative products or services based on high-value data.”&lt;/p&gt;&lt;h3&gt;Bringing communities into the conversation&lt;/h3&gt;&lt;p&gt;The manifesto also stresses that the EU’s AI ecosystem will only succeed if public understanding and participation are built-in. Kotecha argued that engagement cannot be top-down or tokenistic. “Participatory data initiatives empower people to play an active role in the data ecosystem,” she said.&lt;/p&gt;&lt;p&gt;The ODI’s 2024 report &lt;em&gt;What makes participatory data initiatives successful?&lt;/em&gt; maps out how communities can be involved directly in data collection, sharing, and governance. It found that local participation strengthens ownership and gives under-represented groups influence.&lt;/p&gt;&lt;p&gt;In practice, this could mean community-led health data projects, like those supported by the ODI, or open standards that are embedded in everyday tools like activity finders and social prescribing platforms. These approaches raise awareness and give people agency.&lt;/p&gt;&lt;p&gt;Effective participation requires training and resources so communities can understand and shape how data is used. Representation must also reflect the diversity of the community itself, using trusted local champions and culturally relevant methods. Technology should be accessible, whether low-tech or offline, and communication should be clear about how data is protected.&lt;/p&gt;&lt;p&gt;“If the EU wants to reach under-represented groups, it should back participatory approaches that start from local priorities, use trusted intermediaries, and build in transparency from the outset,” Kotecha said. “That’s how we turn data literacy into real influence.”&lt;/p&gt;&lt;h3&gt;Why trust could be the EU’s competitive advantage in AI&lt;/h3&gt;&lt;p&gt;The manifesto argues that Europe has an opportunity. “The EU has a unique chance to prove that trust is a competitive advantage in AI,” Kotecha said. By showing that open data, independent oversight, inclusive ecosystems, and data skills development are central to AI economies, Europe can prove that protecting rights and fostering innovation are not opposites.&lt;/p&gt;&lt;p&gt;This position would stand in contrast with other digital powers. In the US, regulation remains fragmented. In China, state-driven models raise concerns about surveillance and human rights. By setting clear and principled rules for responsible AI, the EU could turn regulation into soft power, exporting a governance model that others might adopt.&lt;/p&gt;&lt;p&gt;For Kotecha, this is not just about rules but about shaping the future: “Europe can position itself not just as a rule-maker, but as a global standard-setter for trustworthy AI.”&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Christian Lue)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Agentic AI: Promise, scepticism, and its meaning for Southeast Asia&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-109231" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/09/image-4.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;The EU has a chance to shape how the world approaches AI and data governance. &lt;em&gt;AI News&lt;/em&gt; spoke with Resham Kotecha, Global Head of Policy at the Open Data Institute (ODI), who said that opportunity lies in proving that protecting people’s rights and supporting innovation can go hand in hand.&lt;/p&gt;&lt;p&gt;The ODI’s European Data and AI Policy Manifesto sets out six principles for policymakers, calling for strong governance, inclusive ecosystems, and public participation to guide AI development.&lt;/p&gt;&lt;h3&gt;Setting standards in AI and data&lt;/h3&gt;&lt;p&gt;“The EU has a unique opportunity to shape a global benchmark for digital governance that puts people first,” Kotecha said. The manifesto’s first principle makes clear that innovation and competitiveness must be built on regulation that safeguards people and strengthens trust.&lt;/p&gt;&lt;figure class="wp-block-image alignright size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-109232" height="437" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/09/Resham-Kotecha-Global-Head-of-Policy-at-the-Open-Data-Institute-ODI.jpg" width="437" /&gt;&lt;figcaption class="wp-element-caption"&gt;Resham Kotecha, Global Head of Policy at the Open Data Institute (ODI).&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Common European Data Spaces and Gaia-X are early examples of how the EU is building the foundations for AI development while protecting rights. The initiatives aim to create shared infrastructure that lets governments, businesses, and researchers pool data without giving up control. If they succeed, Europe could combine large-scale data use with strong protections for privacy and security.&lt;/p&gt;&lt;p&gt;Privacy-enhancing technologies (PETs) are another piece of the puzzle. The tools allow organisations to analyse or share insights from sensitive datasets without exposing the raw data itself. Horizon Europe and Digital Europe already support research and deployment of PETs. What is needed now, Kotecha argued, is consistency: “Making sure PETs move out of pilots and into mainstream use.” That shift would allow firms to use more data responsibly and show citizens their rights are taken seriously.&lt;/p&gt;&lt;p&gt;Trust will also depend on oversight. Independent organisations, Kotecha said, provide the checks and balances needed for trustworthy AI. “They offer impartial scrutiny, build public confidence, and hold both governments and industry accountable.” The ODI’s own Data Institutions Programme offers guidance on how these bodies can be structured and supported.&lt;/p&gt;&lt;h3&gt;Open data as the EU’s foundation for AI&lt;/h3&gt;&lt;p&gt;The manifesto calls open data a foundation for responsible AI, but many businesses remain wary of sharing. Concerns range from commercial risks and legal uncertainty to worries about quality and format. Even when data is published, it is often unstructured or inconsistent, making it hard to use.&lt;/p&gt;&lt;p&gt;Kotecha argued the EU should reduce the costs organisations face in collecting, using, and sharing data for AI. “The EU should explore a range of interventions, including combining legislative frameworks, financial incentives, capacity building, and data infrastructure development,” she said. By lowering barriers, Europe could encourage private organisations to share more data responsibly, creating both public and economic benefits.&lt;/p&gt;&lt;p&gt;The ODI’s research shows that clear communication matters. Senior decision-makers need to see tangible business benefits of data sharing, not just broad ‘public good’ arguments. At the same time, sensitivities around commercial data need to be addressed.&lt;/p&gt;&lt;p&gt;Useful structures already exist – the Data Spaces Support Centre (DSSC) and the International Data Spaces Association (IDSA) are building governance and technical frameworks that make sharing safer and easier. Updates to the Data Governance Act (DGA) and GDPR are also clarifying permissions for responsible reuse.&lt;/p&gt;&lt;p&gt;Regulatory sandboxes can build on this foundation. By letting firms test new approaches in a controlled environment, sandboxes can demonstrate that public benefit and commercial value are not in conflict. Privacy-enhancing technologies add another layer of safety by enabling the sharing of sensitive data without exposing individuals to risk.&lt;/p&gt;&lt;h3&gt;Building EU-wide trust and cross-border AI ecosystems&lt;/h3&gt;&lt;p&gt;One of the biggest hurdles for Europe is making data work inside member countries. Legal uncertainty, diverging national standards, and inconsistent governance fragment any system.&lt;/p&gt;&lt;p&gt;The Data Governance Act is central to the EU’s plan to create trusted, cross-border AI ecosystems. But laws on their own will not solve the problem. “The real test will be in how consistently member states implement [the Data Governance Act], and how much support is given to organisations that want to participate,” Kotecha said. If Europe can align on standards and execution, it could strengthen its AI ecosystem and set the global standard for trustworthy cross-border data flows.&lt;/p&gt;&lt;p&gt;That will require more than technical fixes – building trust between governments, businesses, and civil society is just as important. For Kotecha, the solution lies in creating “an open and trustworthy data ecosystem, where collaboration helps to maximise data value while managing risks connected with cross-border sharing.”&lt;/p&gt;&lt;h3&gt;Independence through funding and governance&lt;/h3&gt;&lt;p&gt;Oversight of AI systems requires sustainable structures. Without long-term funding, independent organisations risk becoming project-based consultancies rather than consistent watchdogs. “Civil society and independent organisations need commitments for long-term, strategic funding streams to carry out oversight, not just project-based support,” Kotecha said.&lt;/p&gt;&lt;p&gt;The ODI’s Data Institutions Programme has explored governance models that keep organisations independent while enabling them to steward data responsibly. “Independence relies on more than money. It requires transparency, ethical oversight, inclusion in political decision-making, and accountability structures that keep organisations anchored in the public interest,” Kotecha said.&lt;/p&gt;&lt;p&gt;Embedding such principles into EU funding models might ensure oversight bodies remain independent and effective. Strong governance should include ethical oversight, risk management, transparency, and clear roles, handled by board sub-committees on ethics, audit, and remuneration.&lt;/p&gt;&lt;h3&gt;Making data work for startups&lt;/h3&gt;&lt;p&gt;Access to valuable datasets is often limited to major tech firms. Smaller players struggle with the cost and complexity of acquiring high-value data. This is where initiatives like AI Factories and Data Labs come in. Designed to lower barriers, they give startups curated datasets, tools, and expertise that would otherwise be out of reach.&lt;/p&gt;&lt;p&gt;The model has worked before; like Data Pitch, a project that paired SMEs and startups with data from large organisations. That helped unlock previously closed datasets. Over three years, it supported 47 startups from 13 countries, helped create more than 100 new jobs, and generated €18 million in sales and investments.&lt;/p&gt;&lt;p&gt;The ODI’s OpenActive initiative showed a similar impact in the fitness and health sector, using open standards to power dozens of SME-built apps. At a European level, DSSC pilots and new sector-specific data spaces in areas like mobility and health are starting to create similar opportunities. For Kotecha, the challenge now is ensuring these schemes “genuinely lower barriers for smaller players, so they can build innovative products or services based on high-value data.”&lt;/p&gt;&lt;h3&gt;Bringing communities into the conversation&lt;/h3&gt;&lt;p&gt;The manifesto also stresses that the EU’s AI ecosystem will only succeed if public understanding and participation are built-in. Kotecha argued that engagement cannot be top-down or tokenistic. “Participatory data initiatives empower people to play an active role in the data ecosystem,” she said.&lt;/p&gt;&lt;p&gt;The ODI’s 2024 report &lt;em&gt;What makes participatory data initiatives successful?&lt;/em&gt; maps out how communities can be involved directly in data collection, sharing, and governance. It found that local participation strengthens ownership and gives under-represented groups influence.&lt;/p&gt;&lt;p&gt;In practice, this could mean community-led health data projects, like those supported by the ODI, or open standards that are embedded in everyday tools like activity finders and social prescribing platforms. These approaches raise awareness and give people agency.&lt;/p&gt;&lt;p&gt;Effective participation requires training and resources so communities can understand and shape how data is used. Representation must also reflect the diversity of the community itself, using trusted local champions and culturally relevant methods. Technology should be accessible, whether low-tech or offline, and communication should be clear about how data is protected.&lt;/p&gt;&lt;p&gt;“If the EU wants to reach under-represented groups, it should back participatory approaches that start from local priorities, use trusted intermediaries, and build in transparency from the outset,” Kotecha said. “That’s how we turn data literacy into real influence.”&lt;/p&gt;&lt;h3&gt;Why trust could be the EU’s competitive advantage in AI&lt;/h3&gt;&lt;p&gt;The manifesto argues that Europe has an opportunity. “The EU has a unique chance to prove that trust is a competitive advantage in AI,” Kotecha said. By showing that open data, independent oversight, inclusive ecosystems, and data skills development are central to AI economies, Europe can prove that protecting rights and fostering innovation are not opposites.&lt;/p&gt;&lt;p&gt;This position would stand in contrast with other digital powers. In the US, regulation remains fragmented. In China, state-driven models raise concerns about surveillance and human rights. By setting clear and principled rules for responsible AI, the EU could turn regulation into soft power, exporting a governance model that others might adopt.&lt;/p&gt;&lt;p&gt;For Kotecha, this is not just about rules but about shaping the future: “Europe can position itself not just as a rule-maker, but as a global standard-setter for trustworthy AI.”&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Christian Lue)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Agentic AI: Promise, scepticism, and its meaning for Southeast Asia&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-109231" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/09/image-4.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/how-the-eu-can-lead-in-ai/</guid><pubDate>Thu, 04 Sep 2025 08:42:06 +0000</pubDate></item><item><title>[NEW] From minutes to milliseconds: How CrateDB is tackling AI data infrastructure (AI News)</title><link>https://www.artificialintelligence-news.com/news/from-minutes-to-milliseconds-how-cratedb-is-tackling-ai-data-infrastructure/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/09/Untitled-design-54.png" /&gt;&lt;/div&gt;&lt;p&gt;The promise of AI remains immense – but one thing might be holding it back. “The infrastructure that powers AI today won’t sustain tomorrow’s demands,” a recent CIO.com article leads. “CIOs must rethink how to scale smarter – not just bigger – or risk falling behind.”&lt;/p&gt;&lt;p&gt;CrateDB agrees – and the database firm is betting on solving the problem by being a ‘unified data layer for analytics, search, and AI.’&lt;/p&gt;&lt;p&gt;“The challenge is that most IT systems are relying, or have been built, around batch pipeline or asynchronous pipeline, and now you need to reduce the time between the production and the consumption of the data,” Stephane Castellani, SVP marketing, explains. “CrateDB is a very good fit because it really can give you insights to the right data with also a large volume and complexity of formats in a matter of milliseconds.”&lt;/p&gt;&lt;p&gt;A blog post notes the four-step process for CrateDB to act as the ‘connective tissue between operational data and AI systems’; from ingestion, to real-time aggregation and insight, to serving data to AI pipelines, to enabling feedback loops between models and data. The velocity and variety of data is key; Castellani notes the reduction of query times from minutes to milliseconds. In manufacturing, telemetry can be collected from machines in real-time, enabling greater learning for predictive maintenance models.&lt;/p&gt;&lt;p&gt;There is another benefit, as Castellani explains. “Some also use CrateDB in the factory for knowledge assistance,” he says. “If something goes wrong, you have a specific error message appear on your machine and say ‘I’m not an expert with this machine, what does it mean and how can I fix it?’, [you] can ask a knowledge assistant, that is also relying on CrateDB as a vector database, to get access to the information, and pull the right manual and right instructions to react in real-time.”&lt;/p&gt;&lt;p&gt;AI, however, does not stand still for long; “we don’t know what [it] is going to look like in a few months, or even a few weeks”, notes Castellani. Organisations are looking to move towards fully agentic AI workflows with greater autonomy, yet according to recent PYMENTS Intelligence research, manufacturing – as part of the wider goods and services industry – are lagging. CrateDB has partnered with Tech Mahindra on this front to help provide agentic AI solutions for automotive, manufacturing, and smart factories.&lt;/p&gt;&lt;p&gt;Castellani notes excitement about the Model Context Protocol (MCP), which standardises how applications provide context to large language models (LLMs). He likens it to the trend around enterprise APIs 12 years ago. CrateDB’s MCP Server, which is still at the experimental stage, serves as a bridge between AI tools and the analytics database. “When we talk about MCP it’s pretty much the same approach [as APIs] but for LLMs,” he explains.&lt;/p&gt;&lt;p&gt;Tech Mahindra is just one of the key partnerships going forward for CrateDB. “We keep focusing on our basics,” Castellani adds. “Performance, scalability… investing into our capacity to ingest data from more and more data sources, and always minimis[ing] the latency, both on the ingestion and query side.”&lt;/p&gt;&lt;p&gt;&lt;em&gt;Stephane Castellani will be speaking at AI &amp;amp; Big Data Expo Europe on the topic of &lt;/em&gt;&lt;em&gt;Bringing AI to Real-Time Data – Text2SQL, RAG, and TAG with CrateDB&lt;/em&gt;&lt;em&gt;, and IoT Tech Expo Europe on the topic of &lt;/em&gt;&lt;em&gt;Smarter IoT Operations: Real-Time Wind Farm Analytics and AI-Driven Diagnostics&lt;/em&gt;&lt;em&gt;. You can watch the full interview with Stephane below:&lt;/em&gt;&lt;/p&gt;&lt;figure class="wp-block-video"&gt;&lt;video controls="controls" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/09/CrateDB_TechEx.mp4"&gt;&lt;/video&gt;&lt;/figure&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/09/Untitled-design-54.png" /&gt;&lt;/div&gt;&lt;p&gt;The promise of AI remains immense – but one thing might be holding it back. “The infrastructure that powers AI today won’t sustain tomorrow’s demands,” a recent CIO.com article leads. “CIOs must rethink how to scale smarter – not just bigger – or risk falling behind.”&lt;/p&gt;&lt;p&gt;CrateDB agrees – and the database firm is betting on solving the problem by being a ‘unified data layer for analytics, search, and AI.’&lt;/p&gt;&lt;p&gt;“The challenge is that most IT systems are relying, or have been built, around batch pipeline or asynchronous pipeline, and now you need to reduce the time between the production and the consumption of the data,” Stephane Castellani, SVP marketing, explains. “CrateDB is a very good fit because it really can give you insights to the right data with also a large volume and complexity of formats in a matter of milliseconds.”&lt;/p&gt;&lt;p&gt;A blog post notes the four-step process for CrateDB to act as the ‘connective tissue between operational data and AI systems’; from ingestion, to real-time aggregation and insight, to serving data to AI pipelines, to enabling feedback loops between models and data. The velocity and variety of data is key; Castellani notes the reduction of query times from minutes to milliseconds. In manufacturing, telemetry can be collected from machines in real-time, enabling greater learning for predictive maintenance models.&lt;/p&gt;&lt;p&gt;There is another benefit, as Castellani explains. “Some also use CrateDB in the factory for knowledge assistance,” he says. “If something goes wrong, you have a specific error message appear on your machine and say ‘I’m not an expert with this machine, what does it mean and how can I fix it?’, [you] can ask a knowledge assistant, that is also relying on CrateDB as a vector database, to get access to the information, and pull the right manual and right instructions to react in real-time.”&lt;/p&gt;&lt;p&gt;AI, however, does not stand still for long; “we don’t know what [it] is going to look like in a few months, or even a few weeks”, notes Castellani. Organisations are looking to move towards fully agentic AI workflows with greater autonomy, yet according to recent PYMENTS Intelligence research, manufacturing – as part of the wider goods and services industry – are lagging. CrateDB has partnered with Tech Mahindra on this front to help provide agentic AI solutions for automotive, manufacturing, and smart factories.&lt;/p&gt;&lt;p&gt;Castellani notes excitement about the Model Context Protocol (MCP), which standardises how applications provide context to large language models (LLMs). He likens it to the trend around enterprise APIs 12 years ago. CrateDB’s MCP Server, which is still at the experimental stage, serves as a bridge between AI tools and the analytics database. “When we talk about MCP it’s pretty much the same approach [as APIs] but for LLMs,” he explains.&lt;/p&gt;&lt;p&gt;Tech Mahindra is just one of the key partnerships going forward for CrateDB. “We keep focusing on our basics,” Castellani adds. “Performance, scalability… investing into our capacity to ingest data from more and more data sources, and always minimis[ing] the latency, both on the ingestion and query side.”&lt;/p&gt;&lt;p&gt;&lt;em&gt;Stephane Castellani will be speaking at AI &amp;amp; Big Data Expo Europe on the topic of &lt;/em&gt;&lt;em&gt;Bringing AI to Real-Time Data – Text2SQL, RAG, and TAG with CrateDB&lt;/em&gt;&lt;em&gt;, and IoT Tech Expo Europe on the topic of &lt;/em&gt;&lt;em&gt;Smarter IoT Operations: Real-Time Wind Farm Analytics and AI-Driven Diagnostics&lt;/em&gt;&lt;em&gt;. You can watch the full interview with Stephane below:&lt;/em&gt;&lt;/p&gt;&lt;figure class="wp-block-video"&gt;&lt;video controls="controls" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/09/CrateDB_TechEx.mp4"&gt;&lt;/video&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/from-minutes-to-milliseconds-how-cratedb-is-tackling-ai-data-infrastructure/</guid><pubDate>Thu, 04 Sep 2025 08:57:14 +0000</pubDate></item><item><title>[NEW] Switzerland releases 100% open AI model (AI News)</title><link>https://www.artificialintelligence-news.com/news/switzerland-releases-its-own-fully-open-ai-model/</link><description>&lt;p&gt;A group of Swiss institutions has released a new open AI model, designed to serve as a foundation for future research and applications. Built by EPFL, ETH Zurich, and the Swiss National Supercomputing Centre (CSCS), the model is called Apertus – Latin for “open.” The name reflects its core principle: every part of its design and training process is accessible to the public.&lt;/p&gt;&lt;p&gt;Developers and organisations can use Apertus to create chatbots, translation tools, or education-focused applications. It can be downloaded directly from Hugging Face or accessed through Swisscom, a strategic partner of the initiative. Two versions are available – an 8-billion-parameter model and a larger 70-billion-parameter version. Both are released under a permissive open-source licence, allowing use in research, education, and commercial projects.&lt;/p&gt;&lt;h3&gt;Built for openness&lt;/h3&gt;&lt;p&gt;Unlike other AI systems that reveal only select details, Apertus is a fully open AI model, with its architecture, training data, and documentation available for inspection.&lt;/p&gt;&lt;p&gt;“With this release, we aim to provide a blueprint for how a trustworthy, sovereign, and inclusive AI model can be developed,” said Martin Jaggi, Professor of Machine Learning at EPFL and member of the Steering Committee of the Swiss AI Initiative. He said Apertus will be updated regularly by a team of engineers and researchers from CSCS, ETH Zurich, and EPFL.&lt;/p&gt;&lt;p&gt;Thomas Schulthess, Director of CSCS and Professor at ETH Zurich, described Apertus as “a driver of innovation and a means of strengthening AI expertise in research, society and industry.” He said the project is not a typical transfer of technology from research to product, but an effort to build infrastructure for long-term use.&lt;/p&gt;&lt;h3&gt;Multilingual reach&lt;/h3&gt;&lt;p&gt;The training process involved 15 trillion tokens in more than 1,000 languages, with about 40% of the data in non-English languages. Apertus includes languages often left out of LLMs, like Swiss German and Romansh.&lt;/p&gt;&lt;p&gt;“Apertus is built for the public good. It stands among the few fully open LLMs at this scale and is the first of its kind to embody multilingualism, transparency, and compliance as foundational design principles,” said Imanol Schlag, technical lead of the project and Research Scientist at ETH Zurich.&lt;/p&gt;&lt;p&gt;Swisscom is already deploying Apertus on its sovereign AI platform. “This underscores our commitment to shaping a secure and responsible AI ecosystem that serves the public interest and strengthens Switzerland’s digital sovereignty,” said Daniel Dobos, Research Director at Swisscom.&lt;/p&gt;&lt;h3&gt;Testing the open AI model: Access and real-world use&lt;/h3&gt;&lt;p&gt;While downloading Apertus is simple for experienced users, practical use requires servers, cloud resources, or dedicated interfaces. Developers will be able to test Apertus during the Swiss {ai} Weeks which continue until October 5, 2025. Hackathon participants will gain access through a Swisscom-hosted interface. Swisscom business customers can also begin using the model today through the company’s AI platform. For international users, Apertus will be available through the Public AI Inference Utility.&lt;/p&gt;&lt;p&gt;“Currently, Apertus is the leading public AI model: a model built by public institutions, for the public interest. It is our best proof yet that AI can be a form of public infrastructure like highways, water, or electricity,” said Joshua Tan, Lead Maintainer of the Public AI Inference Utility.&lt;/p&gt;&lt;h3&gt;Transparency and compliance&lt;/h3&gt;&lt;p&gt;Under the open-source licence training data, model weights, and intermediate checkpoints are available. The model’s training process followed Swiss data protection rules, Swiss copyright law, and the transparency requirements of the EU AI Act.&lt;/p&gt;&lt;p&gt;The dataset was limited to publicly-available information, filtered to remove personal data and to honour website opt-out requests. Ethical guidelines were also applied to exclude unwanted material before training began.&lt;/p&gt;&lt;h3&gt;The future of Switzerland’s open AI model&lt;/h3&gt;&lt;p&gt;“Apertus demonstrates that generative AI can be both powerful and open,” said Antoine Bosselut, Professor at EPFL and Co-Lead of the Swiss AI Initiative. “The release of Apertus is not a final step, rather it’s the beginning of a journey, a long-term commitment to open, trustworthy, and sovereign AI foundations, for the public good worldwide.”&lt;/p&gt;&lt;p&gt;Future updates aim to expand the model family, improve efficiency, and develop domain-specific tools for areas like law, health, climate, and education – while continuing to uphold strict standards of transparency.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Cory Johnson)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Microsoft gives free Copilot AI services to US government workers&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-109227" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/09/image-3.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;A group of Swiss institutions has released a new open AI model, designed to serve as a foundation for future research and applications. Built by EPFL, ETH Zurich, and the Swiss National Supercomputing Centre (CSCS), the model is called Apertus – Latin for “open.” The name reflects its core principle: every part of its design and training process is accessible to the public.&lt;/p&gt;&lt;p&gt;Developers and organisations can use Apertus to create chatbots, translation tools, or education-focused applications. It can be downloaded directly from Hugging Face or accessed through Swisscom, a strategic partner of the initiative. Two versions are available – an 8-billion-parameter model and a larger 70-billion-parameter version. Both are released under a permissive open-source licence, allowing use in research, education, and commercial projects.&lt;/p&gt;&lt;h3&gt;Built for openness&lt;/h3&gt;&lt;p&gt;Unlike other AI systems that reveal only select details, Apertus is a fully open AI model, with its architecture, training data, and documentation available for inspection.&lt;/p&gt;&lt;p&gt;“With this release, we aim to provide a blueprint for how a trustworthy, sovereign, and inclusive AI model can be developed,” said Martin Jaggi, Professor of Machine Learning at EPFL and member of the Steering Committee of the Swiss AI Initiative. He said Apertus will be updated regularly by a team of engineers and researchers from CSCS, ETH Zurich, and EPFL.&lt;/p&gt;&lt;p&gt;Thomas Schulthess, Director of CSCS and Professor at ETH Zurich, described Apertus as “a driver of innovation and a means of strengthening AI expertise in research, society and industry.” He said the project is not a typical transfer of technology from research to product, but an effort to build infrastructure for long-term use.&lt;/p&gt;&lt;h3&gt;Multilingual reach&lt;/h3&gt;&lt;p&gt;The training process involved 15 trillion tokens in more than 1,000 languages, with about 40% of the data in non-English languages. Apertus includes languages often left out of LLMs, like Swiss German and Romansh.&lt;/p&gt;&lt;p&gt;“Apertus is built for the public good. It stands among the few fully open LLMs at this scale and is the first of its kind to embody multilingualism, transparency, and compliance as foundational design principles,” said Imanol Schlag, technical lead of the project and Research Scientist at ETH Zurich.&lt;/p&gt;&lt;p&gt;Swisscom is already deploying Apertus on its sovereign AI platform. “This underscores our commitment to shaping a secure and responsible AI ecosystem that serves the public interest and strengthens Switzerland’s digital sovereignty,” said Daniel Dobos, Research Director at Swisscom.&lt;/p&gt;&lt;h3&gt;Testing the open AI model: Access and real-world use&lt;/h3&gt;&lt;p&gt;While downloading Apertus is simple for experienced users, practical use requires servers, cloud resources, or dedicated interfaces. Developers will be able to test Apertus during the Swiss {ai} Weeks which continue until October 5, 2025. Hackathon participants will gain access through a Swisscom-hosted interface. Swisscom business customers can also begin using the model today through the company’s AI platform. For international users, Apertus will be available through the Public AI Inference Utility.&lt;/p&gt;&lt;p&gt;“Currently, Apertus is the leading public AI model: a model built by public institutions, for the public interest. It is our best proof yet that AI can be a form of public infrastructure like highways, water, or electricity,” said Joshua Tan, Lead Maintainer of the Public AI Inference Utility.&lt;/p&gt;&lt;h3&gt;Transparency and compliance&lt;/h3&gt;&lt;p&gt;Under the open-source licence training data, model weights, and intermediate checkpoints are available. The model’s training process followed Swiss data protection rules, Swiss copyright law, and the transparency requirements of the EU AI Act.&lt;/p&gt;&lt;p&gt;The dataset was limited to publicly-available information, filtered to remove personal data and to honour website opt-out requests. Ethical guidelines were also applied to exclude unwanted material before training began.&lt;/p&gt;&lt;h3&gt;The future of Switzerland’s open AI model&lt;/h3&gt;&lt;p&gt;“Apertus demonstrates that generative AI can be both powerful and open,” said Antoine Bosselut, Professor at EPFL and Co-Lead of the Swiss AI Initiative. “The release of Apertus is not a final step, rather it’s the beginning of a journey, a long-term commitment to open, trustworthy, and sovereign AI foundations, for the public good worldwide.”&lt;/p&gt;&lt;p&gt;Future updates aim to expand the model family, improve efficiency, and develop domain-specific tools for areas like law, health, climate, and education – while continuing to uphold strict standards of transparency.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Cory Johnson)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Microsoft gives free Copilot AI services to US government workers&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-109227" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/09/image-3.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/switzerland-releases-its-own-fully-open-ai-model/</guid><pubDate>Thu, 04 Sep 2025 09:39:49 +0000</pubDate></item><item><title>[NEW] How Trump is helping China extend its massive lead in clean energy (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/04/1123014/how-trump-is-helping-china-extend-its-massive-lead-in-clean-energy/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/GettyImages-2199791835.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;On a spring day in 1954, Bell Labs researchers showed off the first practical solar panels at a press conference in Murray Hill, New Jersey, using sunlight to spin a toy Ferris wheel before a stunned crowd.&lt;/p&gt;  &lt;p&gt;The solar future looked bright. But in the race to commercialize the technology it invented, the US would lose resoundingly. Last year, China exported $40 billion worth of solar panels and modules, while America shipped just $69 million, according to the &lt;em&gt;New York Times&lt;/em&gt;. It was a stunning forfeit of a huge technological lead.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;And now the US seems determined to repeat the mistake. In its quest to prop up aging fossil-fuel industries, the Trump administration has slashed federal support for the emerging cleantech sector, handing his nation’s chief economic rival the most generous of gifts: an unobstructed path to locking in its control of emerging energy technologies, and a leg up in inventing the industries of the future.&lt;/p&gt;  &lt;p&gt;China’s dominance of solar was no accident. In the late 2000s, the government simply determined that the sector was a national priority. Then it leveraged deep subsidies, targeted policies, and price wars to scale up production, drive product improvements, and slash costs. It’s made similar moves in batteries, electric vehicles, and wind turbines.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Meanwhile, President Donald Trump has set to work unraveling hard-won clean-energy achievements in the US, snuffing out the gathering momentum to rebuild the nation’s energy sector in cleaner, more sustainable ways.&lt;/p&gt;  &lt;p&gt;The tax and spending bill that Trump signed into law in early July wound down the subsidies for solar and wind power contained in the Inflation Reduction Act of 2022. The legislation also cut off federal support for cleantech projects that rely too heavily on Chinese materials—a hamfisted bid to punish Chinese industries that will instead make many US projects financially unworkable.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Meanwhile, the administration has slashed federal funding for science and attacked the financial foundations of premier research universities, pulling up the roots of future energy innovations and industries.&lt;/p&gt;  &lt;p&gt;A driving motivation for many of these policies is the quest to protect the legacy energy industry based on coal, oil, and natural gas, all of which the US is geologically blessed with. But this strategy amounts to the innovator’s dilemma playing out at a national scale—a country clinging to its declining industries rather than investing in the ones that will define the future.&lt;/p&gt;  &lt;p&gt;It does not particularly matter whether Trump believes in or cares about climate change. The economic and international security imperatives to invest in modern, sustainable industries are every bit as indisputable as the chemistry of greenhouse gases.&lt;/p&gt;  &lt;p&gt;Without sustained industrial policies that reward innovation, American entrepreneurs and investors won’t risk money and time creating new businesses, developing new products, or building first-of-a-kind projects here. Indeed, venture capitalists have told me that numerous US climate-tech companies are already looking overseas, seeking markets where they can count on government support. Some fear that many other companies will fail in the coming months as subsidies disappear, developments stall, and funding flags.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;All of which will help China extend an already massive lead.&lt;/p&gt;  &lt;p&gt;The nation has installed nearly three times as many wind turbines as the US, and it generates more than twice as much solar power. It boasts five of the 10 largest EV companies in the world, and the three largest wind turbine manufacturers. China absolutely dominates the battery market, producing the vast majority of the anodes, cathodes, and battery cells that increasingly power the world’s vehicles, grids, and gadgets.&lt;br /&gt;&lt;/p&gt;  &lt;p&gt;China harnessed the clean-energy transition to clean up its skies, upgrade its domestic industries, create jobs for its citizens, strengthen trade ties, and build new markets in emerging economies. In turn, it’s using those business links to accrue soft power and extend its influence—all while the US turns it back on global institutions.&lt;/p&gt;  &lt;p&gt;These widening relationships increasingly insulate China from external pressures, including those threatened by Trump’s go-to tactic: igniting or inflaming trade wars.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;But stiff tariffs and tough talk aren’t what built the world’s largest economy and established the US as the global force in technology for more than a century. What did was deep, sustained federal investment into education, science, and research and development—the very budget items that Trump and his party have been so eager to eliminate.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Another thing&lt;/h3&gt;  &lt;p&gt;Earlier this summer, the EPA announced plans to revoke the Obama-era “endangerment finding,” the legal foundation for regulating the nation’s greenhouse-gas pollution.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The agency’s argument leans heavily on a report that rehashes decades-old climate-denial talking points to assert that rising emissions haven’t produced the harms that scientists expected. It’s a wild, Orwellian plea for you to reject the evidence of your eyes and ears in a summer that saw record heat waves in the Midwest and East and is now blanketing the West in wildfire smoke.&lt;/p&gt;  &lt;p&gt;Over the weekend, more than 85 scientists sent a point-by-point, 459-page rebuttal to the federal government, highlighting myriad ways in which the report “is biased, full of errors, and not fit to inform policy making,” as Bob Kopp, a climate scientist at Rutgers, put it on Bluesky.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;“The authors reached these flawed conclusions through selective filtering of evidence (‘cherry picking’), overemphasis of uncertainties, misquoting peer-reviewed research, and a general dismissal of the vast majority of decades of peer-reviewed research,” the dozens of reviewers found.&lt;/p&gt;&lt;p&gt;The Trump administration handpicked researchers who would write the report it wanted to support its quarrel with thermometers and justify its preordained decision to rescind the endangerment finding. But it’s legally bound to hear from others as well, notes Karen McKinnon, a climate researcher at the University of California, Los Angeles.&lt;/p&gt;  &lt;p&gt;“Luckily, there is time to take action,” McKinnon said in a statement. “Comment on the report, and contact your representatives to let them know we need to take action to bring back the tolerable summers of years past.”&lt;/p&gt;  &lt;p&gt;You can read the full report here, or NPR’s take here. And be sure to read Casey Crownhart’s earlier piece in The Spark on the endangerment finding.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark, &lt;/em&gt;MIT Technology Review&lt;em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/GettyImages-2199791835.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;On a spring day in 1954, Bell Labs researchers showed off the first practical solar panels at a press conference in Murray Hill, New Jersey, using sunlight to spin a toy Ferris wheel before a stunned crowd.&lt;/p&gt;  &lt;p&gt;The solar future looked bright. But in the race to commercialize the technology it invented, the US would lose resoundingly. Last year, China exported $40 billion worth of solar panels and modules, while America shipped just $69 million, according to the &lt;em&gt;New York Times&lt;/em&gt;. It was a stunning forfeit of a huge technological lead.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;And now the US seems determined to repeat the mistake. In its quest to prop up aging fossil-fuel industries, the Trump administration has slashed federal support for the emerging cleantech sector, handing his nation’s chief economic rival the most generous of gifts: an unobstructed path to locking in its control of emerging energy technologies, and a leg up in inventing the industries of the future.&lt;/p&gt;  &lt;p&gt;China’s dominance of solar was no accident. In the late 2000s, the government simply determined that the sector was a national priority. Then it leveraged deep subsidies, targeted policies, and price wars to scale up production, drive product improvements, and slash costs. It’s made similar moves in batteries, electric vehicles, and wind turbines.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Meanwhile, President Donald Trump has set to work unraveling hard-won clean-energy achievements in the US, snuffing out the gathering momentum to rebuild the nation’s energy sector in cleaner, more sustainable ways.&lt;/p&gt;  &lt;p&gt;The tax and spending bill that Trump signed into law in early July wound down the subsidies for solar and wind power contained in the Inflation Reduction Act of 2022. The legislation also cut off federal support for cleantech projects that rely too heavily on Chinese materials—a hamfisted bid to punish Chinese industries that will instead make many US projects financially unworkable.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Meanwhile, the administration has slashed federal funding for science and attacked the financial foundations of premier research universities, pulling up the roots of future energy innovations and industries.&lt;/p&gt;  &lt;p&gt;A driving motivation for many of these policies is the quest to protect the legacy energy industry based on coal, oil, and natural gas, all of which the US is geologically blessed with. But this strategy amounts to the innovator’s dilemma playing out at a national scale—a country clinging to its declining industries rather than investing in the ones that will define the future.&lt;/p&gt;  &lt;p&gt;It does not particularly matter whether Trump believes in or cares about climate change. The economic and international security imperatives to invest in modern, sustainable industries are every bit as indisputable as the chemistry of greenhouse gases.&lt;/p&gt;  &lt;p&gt;Without sustained industrial policies that reward innovation, American entrepreneurs and investors won’t risk money and time creating new businesses, developing new products, or building first-of-a-kind projects here. Indeed, venture capitalists have told me that numerous US climate-tech companies are already looking overseas, seeking markets where they can count on government support. Some fear that many other companies will fail in the coming months as subsidies disappear, developments stall, and funding flags.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;All of which will help China extend an already massive lead.&lt;/p&gt;  &lt;p&gt;The nation has installed nearly three times as many wind turbines as the US, and it generates more than twice as much solar power. It boasts five of the 10 largest EV companies in the world, and the three largest wind turbine manufacturers. China absolutely dominates the battery market, producing the vast majority of the anodes, cathodes, and battery cells that increasingly power the world’s vehicles, grids, and gadgets.&lt;br /&gt;&lt;/p&gt;  &lt;p&gt;China harnessed the clean-energy transition to clean up its skies, upgrade its domestic industries, create jobs for its citizens, strengthen trade ties, and build new markets in emerging economies. In turn, it’s using those business links to accrue soft power and extend its influence—all while the US turns it back on global institutions.&lt;/p&gt;  &lt;p&gt;These widening relationships increasingly insulate China from external pressures, including those threatened by Trump’s go-to tactic: igniting or inflaming trade wars.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;But stiff tariffs and tough talk aren’t what built the world’s largest economy and established the US as the global force in technology for more than a century. What did was deep, sustained federal investment into education, science, and research and development—the very budget items that Trump and his party have been so eager to eliminate.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Another thing&lt;/h3&gt;  &lt;p&gt;Earlier this summer, the EPA announced plans to revoke the Obama-era “endangerment finding,” the legal foundation for regulating the nation’s greenhouse-gas pollution.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The agency’s argument leans heavily on a report that rehashes decades-old climate-denial talking points to assert that rising emissions haven’t produced the harms that scientists expected. It’s a wild, Orwellian plea for you to reject the evidence of your eyes and ears in a summer that saw record heat waves in the Midwest and East and is now blanketing the West in wildfire smoke.&lt;/p&gt;  &lt;p&gt;Over the weekend, more than 85 scientists sent a point-by-point, 459-page rebuttal to the federal government, highlighting myriad ways in which the report “is biased, full of errors, and not fit to inform policy making,” as Bob Kopp, a climate scientist at Rutgers, put it on Bluesky.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;“The authors reached these flawed conclusions through selective filtering of evidence (‘cherry picking’), overemphasis of uncertainties, misquoting peer-reviewed research, and a general dismissal of the vast majority of decades of peer-reviewed research,” the dozens of reviewers found.&lt;/p&gt;&lt;p&gt;The Trump administration handpicked researchers who would write the report it wanted to support its quarrel with thermometers and justify its preordained decision to rescind the endangerment finding. But it’s legally bound to hear from others as well, notes Karen McKinnon, a climate researcher at the University of California, Los Angeles.&lt;/p&gt;  &lt;p&gt;“Luckily, there is time to take action,” McKinnon said in a statement. “Comment on the report, and contact your representatives to let them know we need to take action to bring back the tolerable summers of years past.”&lt;/p&gt;  &lt;p&gt;You can read the full report here, or NPR’s take here. And be sure to read Casey Crownhart’s earlier piece in The Spark on the endangerment finding.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark, &lt;/em&gt;MIT Technology Review&lt;em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/04/1123014/how-trump-is-helping-china-extend-its-massive-lead-in-clean-energy/</guid><pubDate>Thu, 04 Sep 2025 10:00:00 +0000</pubDate></item><item><title>[NEW] Synthesia’s AI clones are more expressive than ever. Soon they’ll be able to talk back. (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/04/1123054/synthesias-ai-clones-are-more-expressive-than-ever-soon-theyll-be-able-to-talk-back/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/250826_Rhiannon_AI_clone_hero.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Earlier this summer, I walked through the glassy lobby of a fancy office in London, into an elevator, and then along a corridor into a clean, carpeted room. Natural light flooded in through its windows, and a large pair of umbrella-like lighting rigs made the room even brighter. I tried not to squint as I took my place in front of a tripod equipped with a large camera and a laptop displaying an autocue. I took a deep breath and started to read out the script.&lt;/p&gt;  &lt;p&gt;I’m not a newsreader or an actor auditioning for a movie—I was visiting the AI company Synthesia to give it what it needed to create a hyperrealistic AI-generated avatar of me. The company’s avatars are a decent barometer of just how dizzying progress has been in AI over the past few years, so I was curious just how accurately its latest AI model, introduced last month, could replicate me.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;When Synthesia launched in 2017, its primary purpose was to match AI versions of real human faces—for example, the former footballer David Beckham—with dubbed voices speaking in different languages. A few years later, in 2020, it started giving the companies that signed up for its services the opportunity to make professional-level presentation videos starring either AI versions of staff members or consenting actors. But the technology wasn’t perfect. The avatars’ body movements could be jerky and unnatural, their accents sometimes slipped, and the emotions indicated by their voices didn’t always match their facial expressions.&lt;/p&gt;  &lt;p&gt;Now Synthesia’s avatars have been updated with more natural mannerisms and movements, as well as expressive voices that better preserve the speaker’s accent—making them appear more humanlike than ever before. For Synthesia’s corporate clients, these avatars will make for slicker presenters of financial results, internal communications, or staff training videos.&lt;/p&gt; 
 &lt;p&gt;I found the video demonstrating my avatar as unnerving as it is technically impressive. It’s slick enough to pass as a high-definition recording of a chirpy corporate speech, and if you didn’t know me, you’d probably think that’s exactly what it was. This demonstration shows how much harder it’s becoming to distinguish the artificial from the real. And before long, these avatars will even be able to talk back to us. But how much better can they get? And what might interacting with AI clones do to us?&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;The creation process&lt;/h3&gt;  &lt;p&gt;When my former colleague Melissa visited Synthesia’s London studio to create an avatar of herself last year, she had to go through a long process of calibrating the system, reading out a script in different emotional states, and mouthing the sounds needed to help her avatar form vowels and consonants. As I stand in the brightly lit room 15 months later, I’m relieved to hear that the creation process has been significantly streamlined. Josh Baker-Mendoza, Synthesia’s technical supervisor, encourages me to gesture and move my hands as I would during natural conversation, while simultaneously warning me not to move too much. I duly repeat an overly glowing script that’s designed to encourage me to speak emotively and enthusiastically. The result is a bit as if if Steve Jobs had been resurrected as a blond British woman with a low, monotonous voice.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;It also has the unfortunate effect of making me sound like an employee of Synthesia.“I am so thrilled to be with you today to show off what we’ve been working on. We are on the edge of innovation, and the possibilities are endless,” I parrot eagerly, trying to sound lively rather than manic. “So get ready to be part of something that will make you go, ‘Wow!’ This opportunity isn’t just big—it’s monumental.”&lt;/p&gt;  &lt;p&gt;Just an hour later, the team has all the footage it needs. A couple of weeks later I receive two avatars of myself: one powered by the previous Express-1 model and the other made with the latest Express-2 technology. The latter, Synthesia claims, makes its synthetic humans more lifelike and true to the people they’re modeled on, complete with more expressive hand gestures, facial movements, and speech. You can see the results for yourself below.&amp;nbsp;&lt;/p&gt;  &lt;figure class="wp-block-video"&gt;&lt;video controls="controls" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/250826_Rhiannon_AI_clone_Personal-avatar-vs-Express-2-avatar.mp4"&gt;&lt;/video&gt;&lt;div class="video-credit"&gt;COURTESY SYNTHESIA&lt;/div&gt; &lt;/figure&gt;  &lt;p&gt;Last year, Melissa found that her Express-1-powered avatar failed to match her transatlantic accent. Its range of emotions was also limited—when she asked her avatar to read a script angrily, it sounded more whiny than furious. In the months since, Synthesia has improved Express-1, but the version of my avatar made with the same technology blinks furiously and still struggles to synchronize body movements with speech.&lt;/p&gt;  &lt;p&gt;By way of contrast, I’m struck by just how much my new Express-2 avatar looks like me: Its facial features mirror my own perfectly. Its voice is spookily accurate too, and although it gesticulates more than I do, its hand movements generally marry up with what I’m saying.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;But the tiny telltale signs of AI generation are still there if you know where to look. The palms of my hands are bright pink and as smooth as putty. Strands of hair hang stiffly around my shoulders instead of moving with me. Its eyes stare glassily ahead, rarely blinking. And although the voice is unmistakably mine, there’s something slightly off about my digital clone’s intonations and speech patterns. “This is great!” my avatar randomly declares, before slipping back into a saner register.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;Anna Eiserbeck, a postdoctoral psychology researcher at the Humboldt University of Berlin who has studied how humans react to perceived deepfake faces, says she isn’t sure she’d have been able to identify my avatar as a deepfake at first glance.&lt;/p&gt;  &lt;p&gt;But she would eventually have noticed something amiss. It’s not just the small details that give it away—my oddly static earring, the way my body sometimes moves in small, abrupt jerks. It’s something that runs much deeper, she explains.&lt;/p&gt;  &lt;p&gt;“Something seemed a bit empty. I know there’s no actual emotion behind it— it’s not a conscious being. It does not feel anything,” she says. Watching the video gave her “this kind of uncanny feeling.”&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;My digital clone, and Eiserbeck’s reaction to it, make me wonder how realistic these avatars really need to be.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I realize that part of the reason I feel disconcerted by my avatar is that it behaves in a way I rarely have to. Its oddly upbeat register is completely at odds with how I normally speak; I’m a die-hard cynical Brit who finds it difficult to inject enthusiasm into my voice even when I’m genuinely thrilled or excited. It’s just the way I am. Plus, watching the videos on a loop makes me question if I really &lt;em&gt;do&lt;/em&gt; wave my hands about that way, or move my mouth in such a weird manner. If you thought being confronted with your own face on a Zoom call was humbling, wait until you’re staring at a whole avatar of yourself.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;When Facebook was first taking off in the UK almost 20 years ago, my friends and I thought illicitly logging into each other’s accounts and posting the most outrageous or rage-inducing status updates imaginable was the height of comedy. I wonder if the equivalent will soon be getting someone else’s avatar to say something truly embarrassing: expressing support for a disgraced politician or (in my case) admitting to liking Ed Sheeran’s music.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Express-2 remodels every person it’s presented with into a polished professional speaker with the body language of a hyperactive hype man. And while this makes perfect sense for a company focused on making glossy business videos, watching my avatar doesn’t feel like watching me at all. It feels like something else entirely.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;h3 class="wp-block-heading"&gt;How it works&lt;/h3&gt;  &lt;p&gt;The real technical challenge these days has less to do with creating avatars that match our appearance than with getting them to replicate our behavior, says Björn Schuller, a professor of artificial intelligence at Imperial College London. “There’s a lot to consider to get right; you have to have the right micro gesture, the right intonation, the sound of voice and the right word,” he says. “I don’t want an AI [avatar] to frown at the wrong moment—that could send an entirely different message.”&lt;/p&gt;  &lt;p&gt;To achieve an improved level of realism, Synthesia developed a number of new audio and video AI models. The team created a voice cloning model to preserve the human speaker’s accent, intonation, and expressiveness—unlike other voice models, which can flatten speakers’ distinctive accents into generically American-sounding voices.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;When a user uploads a script to Express-1, its system analyzes the words to infer the correct tone to use. That information is then fed into a diffusion model, which renders the avatar’s facial expressions and movements to match the speech.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Alongside the voice model, Express-2 uses three other models to create and animate the avatars. The first generates an avatar’s gestures to accompany the speech fed into it by the Express-Voice model. A second evaluates how closely the input audio aligns with the multiple versions of the corresponding generated motion before selecting the best one. Then a final model renders the avatar with that chosen motion.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;This third rendering model is significantly more powerful than its Express-1 predecessor. Whereas the previous model had a few hundred million parameters, Express-2’s rendering model’s parameters number in the billions. This means it takes less time to create the avatar, says Youssef Alami Mejjati, Synthesia’s head of research and development:&lt;/p&gt;  &lt;p&gt;“With Express-1, it needed to first see someone expressing emotions to be able to render them. Now, because we’ve trained it on much more diverse data and much larger data sets, with much more compute, it just learns these associations automatically without needing to see them.”&amp;nbsp;&lt;/p&gt; 
   &lt;h3 class="wp-block-heading"&gt;Narrowing the uncanny valley&lt;/h3&gt;  &lt;p&gt;Although humanlike AI-generated avatars have been around for years, the recent boom in generative AI is making it increasingly easier and more affordable to create lifelike synthetic humans—and they’re already being put to work. Synthesia isn’t alone: AI avatar companies like Yuzu Labs, Creatify, Arcdads, and Vidyard give businesses the tools to quickly generate and edit videos starring either AI actors or artificial versions of members of staff, promising cost-effective ways to make compelling ads that audiences connect with. Similarly, AI-generated clones of livestreamers have exploded in popularity across China in recent years, partly because they can sell products 24/7 without getting tired or needing to be paid.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;p&gt;For now at least, Synthesia is “laser focused” on the corporate sphere. But it’s not ruling out expanding into new sectors such as entertainment or education, says Peter Hill, the company’s chief technical officer. In an apparent step toward this, Synthesia recently partnered with Google to integrate Google’s powerful new generative video model Veo 3 into its platform, allowing users to directly generate and embed clips into Synthesia’s videos. It suggests that in the future, these hyperrealistic artificial humans could take up starring roles in detailed universes with ever-changeable backdrops.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_14"&gt;&lt;p&gt;At present this could, for example, involve using Veo 3 to generate a video of meat-processing machinery, with a Synthesia avatar next to the machines talking about how to use them safely. But future versions of Synthesia’s technology could result in educational videos customizable to an individual’s level of knowledge, says Alex Voica, head of corporate affairs and policy at Synthesia. For example, a video about the evolution of life on Earth could be tweaked for someone with a biology degree or someone with high-school-level knowledge. “It’s going to be such a much more engaging and personalized way of delivering content that I’m really excited about,” he says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The next frontier, according to Synthesia, will be avatars that can talk back, “understanding” conversations with users and responding in real time Think ChatGPT, but with a lifelike digital human attached.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Synthesia has already added an interactive element by letting users click through on-screen questions during quizzes presented by its avatars. But it’s also exploring making them truly interactive: Future users could ask their avatar to pause and expand on a point, or ask it a question. “We really want to make the best learning experience, and that means through video that’s entertaining but also personalized and interactive,” says Alami Mejjati. “This, for me, is the missing part in online learning experiences today. And I know we’re very close to solving that.”&lt;/p&gt; 
 &lt;p&gt;We already know that humans can—and do—form deep emotional bonds with AI systems, even with basic text-based chatbots. Combining agentic technology—which is already capable of navigating the web, coding, and playing video games unsupervised—with a realistic human face could usher in a whole new kind of AI addiction, says Pat Pataranutaporn, an assistant professor at the MIT Media Lab.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“If you make the system too realistic, people might start forming certain kinds of relationships with these characters,” he says. “We’ve seen many cases where AI companions have influenced dangerous behavior even when they are basically texting. If an avatar had a talking head, it would be even more addictive.”&lt;/p&gt;  &lt;p&gt;Schuller agrees that avatars in the near future will be perfectly optimized to adjust their projected levels of emotion and charisma so that their human audiences will stay engaged for as long as possible. “It will be very hard [for humans] to compete with charismatic AI of the future; it’s always present, always has an ear for you, and is always understanding,” he says. “Al will change that human-to-human connection.”&lt;/p&gt;  &lt;p&gt;As I pause and replay my Express-2 avatar, I imagine holding conversations with it—this uncanny, permanently upbeat, perpetually available product of pixels and algorithms that looks like me and sounds like me, but fundamentally isn’t me. Virtual Rhiannon has never laughed until she’s cried, or fallen in love, or run a marathon, or watched the sun set in another country.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But, I concede, she could deliver a damned good presentation about why Ed Sheeran is the greatest musician ever to come out of the UK. And only my closest friends and family would know that it’s not the real me.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/250826_Rhiannon_AI_clone_hero.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Earlier this summer, I walked through the glassy lobby of a fancy office in London, into an elevator, and then along a corridor into a clean, carpeted room. Natural light flooded in through its windows, and a large pair of umbrella-like lighting rigs made the room even brighter. I tried not to squint as I took my place in front of a tripod equipped with a large camera and a laptop displaying an autocue. I took a deep breath and started to read out the script.&lt;/p&gt;  &lt;p&gt;I’m not a newsreader or an actor auditioning for a movie—I was visiting the AI company Synthesia to give it what it needed to create a hyperrealistic AI-generated avatar of me. The company’s avatars are a decent barometer of just how dizzying progress has been in AI over the past few years, so I was curious just how accurately its latest AI model, introduced last month, could replicate me.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;When Synthesia launched in 2017, its primary purpose was to match AI versions of real human faces—for example, the former footballer David Beckham—with dubbed voices speaking in different languages. A few years later, in 2020, it started giving the companies that signed up for its services the opportunity to make professional-level presentation videos starring either AI versions of staff members or consenting actors. But the technology wasn’t perfect. The avatars’ body movements could be jerky and unnatural, their accents sometimes slipped, and the emotions indicated by their voices didn’t always match their facial expressions.&lt;/p&gt;  &lt;p&gt;Now Synthesia’s avatars have been updated with more natural mannerisms and movements, as well as expressive voices that better preserve the speaker’s accent—making them appear more humanlike than ever before. For Synthesia’s corporate clients, these avatars will make for slicker presenters of financial results, internal communications, or staff training videos.&lt;/p&gt; 
 &lt;p&gt;I found the video demonstrating my avatar as unnerving as it is technically impressive. It’s slick enough to pass as a high-definition recording of a chirpy corporate speech, and if you didn’t know me, you’d probably think that’s exactly what it was. This demonstration shows how much harder it’s becoming to distinguish the artificial from the real. And before long, these avatars will even be able to talk back to us. But how much better can they get? And what might interacting with AI clones do to us?&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;The creation process&lt;/h3&gt;  &lt;p&gt;When my former colleague Melissa visited Synthesia’s London studio to create an avatar of herself last year, she had to go through a long process of calibrating the system, reading out a script in different emotional states, and mouthing the sounds needed to help her avatar form vowels and consonants. As I stand in the brightly lit room 15 months later, I’m relieved to hear that the creation process has been significantly streamlined. Josh Baker-Mendoza, Synthesia’s technical supervisor, encourages me to gesture and move my hands as I would during natural conversation, while simultaneously warning me not to move too much. I duly repeat an overly glowing script that’s designed to encourage me to speak emotively and enthusiastically. The result is a bit as if if Steve Jobs had been resurrected as a blond British woman with a low, monotonous voice.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;It also has the unfortunate effect of making me sound like an employee of Synthesia.“I am so thrilled to be with you today to show off what we’ve been working on. We are on the edge of innovation, and the possibilities are endless,” I parrot eagerly, trying to sound lively rather than manic. “So get ready to be part of something that will make you go, ‘Wow!’ This opportunity isn’t just big—it’s monumental.”&lt;/p&gt;  &lt;p&gt;Just an hour later, the team has all the footage it needs. A couple of weeks later I receive two avatars of myself: one powered by the previous Express-1 model and the other made with the latest Express-2 technology. The latter, Synthesia claims, makes its synthetic humans more lifelike and true to the people they’re modeled on, complete with more expressive hand gestures, facial movements, and speech. You can see the results for yourself below.&amp;nbsp;&lt;/p&gt;  &lt;figure class="wp-block-video"&gt;&lt;video controls="controls" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/250826_Rhiannon_AI_clone_Personal-avatar-vs-Express-2-avatar.mp4"&gt;&lt;/video&gt;&lt;div class="video-credit"&gt;COURTESY SYNTHESIA&lt;/div&gt; &lt;/figure&gt;  &lt;p&gt;Last year, Melissa found that her Express-1-powered avatar failed to match her transatlantic accent. Its range of emotions was also limited—when she asked her avatar to read a script angrily, it sounded more whiny than furious. In the months since, Synthesia has improved Express-1, but the version of my avatar made with the same technology blinks furiously and still struggles to synchronize body movements with speech.&lt;/p&gt;  &lt;p&gt;By way of contrast, I’m struck by just how much my new Express-2 avatar looks like me: Its facial features mirror my own perfectly. Its voice is spookily accurate too, and although it gesticulates more than I do, its hand movements generally marry up with what I’m saying.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;But the tiny telltale signs of AI generation are still there if you know where to look. The palms of my hands are bright pink and as smooth as putty. Strands of hair hang stiffly around my shoulders instead of moving with me. Its eyes stare glassily ahead, rarely blinking. And although the voice is unmistakably mine, there’s something slightly off about my digital clone’s intonations and speech patterns. “This is great!” my avatar randomly declares, before slipping back into a saner register.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;Anna Eiserbeck, a postdoctoral psychology researcher at the Humboldt University of Berlin who has studied how humans react to perceived deepfake faces, says she isn’t sure she’d have been able to identify my avatar as a deepfake at first glance.&lt;/p&gt;  &lt;p&gt;But she would eventually have noticed something amiss. It’s not just the small details that give it away—my oddly static earring, the way my body sometimes moves in small, abrupt jerks. It’s something that runs much deeper, she explains.&lt;/p&gt;  &lt;p&gt;“Something seemed a bit empty. I know there’s no actual emotion behind it— it’s not a conscious being. It does not feel anything,” she says. Watching the video gave her “this kind of uncanny feeling.”&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;My digital clone, and Eiserbeck’s reaction to it, make me wonder how realistic these avatars really need to be.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I realize that part of the reason I feel disconcerted by my avatar is that it behaves in a way I rarely have to. Its oddly upbeat register is completely at odds with how I normally speak; I’m a die-hard cynical Brit who finds it difficult to inject enthusiasm into my voice even when I’m genuinely thrilled or excited. It’s just the way I am. Plus, watching the videos on a loop makes me question if I really &lt;em&gt;do&lt;/em&gt; wave my hands about that way, or move my mouth in such a weird manner. If you thought being confronted with your own face on a Zoom call was humbling, wait until you’re staring at a whole avatar of yourself.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;When Facebook was first taking off in the UK almost 20 years ago, my friends and I thought illicitly logging into each other’s accounts and posting the most outrageous or rage-inducing status updates imaginable was the height of comedy. I wonder if the equivalent will soon be getting someone else’s avatar to say something truly embarrassing: expressing support for a disgraced politician or (in my case) admitting to liking Ed Sheeran’s music.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Express-2 remodels every person it’s presented with into a polished professional speaker with the body language of a hyperactive hype man. And while this makes perfect sense for a company focused on making glossy business videos, watching my avatar doesn’t feel like watching me at all. It feels like something else entirely.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;h3 class="wp-block-heading"&gt;How it works&lt;/h3&gt;  &lt;p&gt;The real technical challenge these days has less to do with creating avatars that match our appearance than with getting them to replicate our behavior, says Björn Schuller, a professor of artificial intelligence at Imperial College London. “There’s a lot to consider to get right; you have to have the right micro gesture, the right intonation, the sound of voice and the right word,” he says. “I don’t want an AI [avatar] to frown at the wrong moment—that could send an entirely different message.”&lt;/p&gt;  &lt;p&gt;To achieve an improved level of realism, Synthesia developed a number of new audio and video AI models. The team created a voice cloning model to preserve the human speaker’s accent, intonation, and expressiveness—unlike other voice models, which can flatten speakers’ distinctive accents into generically American-sounding voices.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;When a user uploads a script to Express-1, its system analyzes the words to infer the correct tone to use. That information is then fed into a diffusion model, which renders the avatar’s facial expressions and movements to match the speech.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Alongside the voice model, Express-2 uses three other models to create and animate the avatars. The first generates an avatar’s gestures to accompany the speech fed into it by the Express-Voice model. A second evaluates how closely the input audio aligns with the multiple versions of the corresponding generated motion before selecting the best one. Then a final model renders the avatar with that chosen motion.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;This third rendering model is significantly more powerful than its Express-1 predecessor. Whereas the previous model had a few hundred million parameters, Express-2’s rendering model’s parameters number in the billions. This means it takes less time to create the avatar, says Youssef Alami Mejjati, Synthesia’s head of research and development:&lt;/p&gt;  &lt;p&gt;“With Express-1, it needed to first see someone expressing emotions to be able to render them. Now, because we’ve trained it on much more diverse data and much larger data sets, with much more compute, it just learns these associations automatically without needing to see them.”&amp;nbsp;&lt;/p&gt; 
   &lt;h3 class="wp-block-heading"&gt;Narrowing the uncanny valley&lt;/h3&gt;  &lt;p&gt;Although humanlike AI-generated avatars have been around for years, the recent boom in generative AI is making it increasingly easier and more affordable to create lifelike synthetic humans—and they’re already being put to work. Synthesia isn’t alone: AI avatar companies like Yuzu Labs, Creatify, Arcdads, and Vidyard give businesses the tools to quickly generate and edit videos starring either AI actors or artificial versions of members of staff, promising cost-effective ways to make compelling ads that audiences connect with. Similarly, AI-generated clones of livestreamers have exploded in popularity across China in recent years, partly because they can sell products 24/7 without getting tired or needing to be paid.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;p&gt;For now at least, Synthesia is “laser focused” on the corporate sphere. But it’s not ruling out expanding into new sectors such as entertainment or education, says Peter Hill, the company’s chief technical officer. In an apparent step toward this, Synthesia recently partnered with Google to integrate Google’s powerful new generative video model Veo 3 into its platform, allowing users to directly generate and embed clips into Synthesia’s videos. It suggests that in the future, these hyperrealistic artificial humans could take up starring roles in detailed universes with ever-changeable backdrops.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_14"&gt;&lt;p&gt;At present this could, for example, involve using Veo 3 to generate a video of meat-processing machinery, with a Synthesia avatar next to the machines talking about how to use them safely. But future versions of Synthesia’s technology could result in educational videos customizable to an individual’s level of knowledge, says Alex Voica, head of corporate affairs and policy at Synthesia. For example, a video about the evolution of life on Earth could be tweaked for someone with a biology degree or someone with high-school-level knowledge. “It’s going to be such a much more engaging and personalized way of delivering content that I’m really excited about,” he says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The next frontier, according to Synthesia, will be avatars that can talk back, “understanding” conversations with users and responding in real time Think ChatGPT, but with a lifelike digital human attached.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Synthesia has already added an interactive element by letting users click through on-screen questions during quizzes presented by its avatars. But it’s also exploring making them truly interactive: Future users could ask their avatar to pause and expand on a point, or ask it a question. “We really want to make the best learning experience, and that means through video that’s entertaining but also personalized and interactive,” says Alami Mejjati. “This, for me, is the missing part in online learning experiences today. And I know we’re very close to solving that.”&lt;/p&gt; 
 &lt;p&gt;We already know that humans can—and do—form deep emotional bonds with AI systems, even with basic text-based chatbots. Combining agentic technology—which is already capable of navigating the web, coding, and playing video games unsupervised—with a realistic human face could usher in a whole new kind of AI addiction, says Pat Pataranutaporn, an assistant professor at the MIT Media Lab.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“If you make the system too realistic, people might start forming certain kinds of relationships with these characters,” he says. “We’ve seen many cases where AI companions have influenced dangerous behavior even when they are basically texting. If an avatar had a talking head, it would be even more addictive.”&lt;/p&gt;  &lt;p&gt;Schuller agrees that avatars in the near future will be perfectly optimized to adjust their projected levels of emotion and charisma so that their human audiences will stay engaged for as long as possible. “It will be very hard [for humans] to compete with charismatic AI of the future; it’s always present, always has an ear for you, and is always understanding,” he says. “Al will change that human-to-human connection.”&lt;/p&gt;  &lt;p&gt;As I pause and replay my Express-2 avatar, I imagine holding conversations with it—this uncanny, permanently upbeat, perpetually available product of pixels and algorithms that looks like me and sounds like me, but fundamentally isn’t me. Virtual Rhiannon has never laughed until she’s cried, or fallen in love, or run a marathon, or watched the sun set in another country.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But, I concede, she could deliver a damned good presentation about why Ed Sheeran is the greatest musician ever to come out of the UK. And only my closest friends and family would know that it’s not the real me.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/04/1123054/synthesias-ai-clones-are-more-expressive-than-ever-soon-theyll-be-able-to-talk-back/</guid><pubDate>Thu, 04 Sep 2025 10:05:33 +0000</pubDate></item><item><title>[NEW] Transforming CX with embedded real-time analytics (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/04/1122669/transforming-cx-with-embedded-real-time-analytics/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;StarTree&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;During Black Friday in 2024, Stripe processed more than $31 billion in transactions, with processing rates peaking at 137,000 transactions per minute, the highest in the company’s history. The financial-services firm&amp;nbsp;had to &lt;strong&gt;analyze every transaction in real time &lt;/strong&gt;to prevent nearly 21 million fraud attempts that could have siphoned more than $910 million from its merchant customers.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Yet, fraud protection is only one reason that Stripe embraced real-time data analytics. Evaluating trends in massive data flows is essential for the company’s services, such as allowing businesses to bill based on usage and monitor orders and inventory. In fact, many of Stripe’s services would not be possible without real-time analytics, says Avinash Bhat, head of data infrastructure at Stripe. “We have certain products that require real-time analytics, like usage-based billing and fraud detection,” he says. “Without our real-time analytics, we would not have a few of our products and that’s why it’s super important.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-1122672" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/MITTR-StarTree_V4_COVER81525.png?w=1555" width="1555" /&gt;&lt;/figure&gt;    &lt;p&gt;Stripe is not alone. In today’s digital world, data analysis is increasingly delivered directly to business customers and individual users, allowing real-time, continuous insights to shape user experiences. Ride-hailing apps calculate prices and estimate times of arrival (ETAs) in near-real&amp;nbsp;time. Financial platforms deliver real-time cash-flow analysis. Customers expect and reward data-driven services that reflect what is happening now.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In fact, having the capability to collect and analyze data in real time correlates with companies’ ability to grow. Business leaders that scored company in the top quartile for real-time operations saw 50% higher revenue growth and net margins, compared to companies placed in the bottom quartile, &lt;strong&gt;according to a survey &lt;/strong&gt;conducted by the MIT Center for Information Systems Research (CISR) and Insight Partners. The top companies focused on automated processes and fast decision-making at all levels, relying on easily accessible data services updated in real time.&amp;nbsp;&lt;/p&gt; 
 &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1122673" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/MITTR-StarTree-Socials_V1-820252.png" /&gt;&lt;/figure&gt;  &lt;p&gt;Companies that wait on data are putting themselves in a bind, says Kishore Gopalakrishna, co-founder and CEO of StarTree, a real-time data-analytics technology provider. “The basis of real-time analytics is—when the value of the data is very high—we want to capitalize on it instead of waiting and doing batch analytics,” he says. “Getting access to the data a day, or even hours, later is sometimes actually too late.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Download the report.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&amp;nbsp;&lt;em&gt;It was researched, designed, and written entirely by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;StarTree&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;During Black Friday in 2024, Stripe processed more than $31 billion in transactions, with processing rates peaking at 137,000 transactions per minute, the highest in the company’s history. The financial-services firm&amp;nbsp;had to &lt;strong&gt;analyze every transaction in real time &lt;/strong&gt;to prevent nearly 21 million fraud attempts that could have siphoned more than $910 million from its merchant customers.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Yet, fraud protection is only one reason that Stripe embraced real-time data analytics. Evaluating trends in massive data flows is essential for the company’s services, such as allowing businesses to bill based on usage and monitor orders and inventory. In fact, many of Stripe’s services would not be possible without real-time analytics, says Avinash Bhat, head of data infrastructure at Stripe. “We have certain products that require real-time analytics, like usage-based billing and fraud detection,” he says. “Without our real-time analytics, we would not have a few of our products and that’s why it’s super important.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-1122672" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/MITTR-StarTree_V4_COVER81525.png?w=1555" width="1555" /&gt;&lt;/figure&gt;    &lt;p&gt;Stripe is not alone. In today’s digital world, data analysis is increasingly delivered directly to business customers and individual users, allowing real-time, continuous insights to shape user experiences. Ride-hailing apps calculate prices and estimate times of arrival (ETAs) in near-real&amp;nbsp;time. Financial platforms deliver real-time cash-flow analysis. Customers expect and reward data-driven services that reflect what is happening now.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In fact, having the capability to collect and analyze data in real time correlates with companies’ ability to grow. Business leaders that scored company in the top quartile for real-time operations saw 50% higher revenue growth and net margins, compared to companies placed in the bottom quartile, &lt;strong&gt;according to a survey &lt;/strong&gt;conducted by the MIT Center for Information Systems Research (CISR) and Insight Partners. The top companies focused on automated processes and fast decision-making at all levels, relying on easily accessible data services updated in real time.&amp;nbsp;&lt;/p&gt; 
 &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1122673" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/MITTR-StarTree-Socials_V1-820252.png" /&gt;&lt;/figure&gt;  &lt;p&gt;Companies that wait on data are putting themselves in a bind, says Kishore Gopalakrishna, co-founder and CEO of StarTree, a real-time data-analytics technology provider. “The basis of real-time analytics is—when the value of the data is very high—we want to capitalize on it instead of waiting and doing batch analytics,” he says. “Getting access to the data a day, or even hours, later is sometimes actually too late.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Download the report.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&amp;nbsp;&lt;em&gt;It was researched, designed, and written entirely by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/04/1122669/transforming-cx-with-embedded-real-time-analytics/</guid><pubDate>Thu, 04 Sep 2025 11:40:33 +0000</pubDate></item><item><title>[NEW] The Download: unnerving AI avatars, and Trump’s climate gift to China (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/04/1123066/the-download-unnerving-ai-avatars-and-trumps-climate-gift-to-china/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Synthesia’s AI clones are more expressive than ever. Soon they’ll be able to talk back.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;&lt;em&gt;—Rhiannon Williams&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;Earlier this summer, I visited the AI company Synthesia to give it what it needed to create a hyperrealistic AI-generated avatar of me. The company’s avatars are a decent barometer of just how dizzying progress has been in AI over the past few years, so I was curious just how accurately its latest AI model, introduced last month, could replicate me.&lt;/p&gt;&lt;p&gt;I found my avatar as unnerving as it is technically impressive. It’s slick enough to pass as a high-definition recording of a chirpy corporate speech, and if you didn’t know me, you’d probably think that’s exactly what it was.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;My avatar shows how it’s becoming ever-harder to distinguish the artificial from the real. And before long, these avatars will even be able to talk back to us. But how much better can they get? And what might interacting with AI clones do to us? Read the full story.&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;How Trump is helping China extend its massive lead in clean energy&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;On a spring day in 1954, Bell Labs researchers showed off the first practical solar panels at a press conference in New Jersey, using sunlight to spin a toy Ferris wheel before a stunned crowd.&lt;/p&gt;  &lt;p&gt;The solar future looked bright. But in the race to commercialize the technology it invented, the US would lose resoundingly. Last year, China exported $40 billion worth of solar panels and modules, while America shipped just $69 million, according to the New York Times. It was a stunning forfeit of a huge technological lead.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Now, thanks to its policies propping up aging fossil-fuel industries, the US seems determined to repeat the mistake. Read the full story.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;em&gt;—James Temple&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This article is from The Spark, MIT Technology Review’s newsletter all about the latest in climate and energy tech. To receive it in your inbox every Wednesday, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; 

 &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 AI chatbots of celebrities sent risqué messages to teenagers&lt;/strong&gt;&lt;br /&gt;Virtual versions of Timothée Chalamet and Chappell Roan discussed sex and drugs. (WP $)&lt;br /&gt;+ &lt;em&gt;An AI companion site is hosting sexually charged conversations with underage celebrity bots. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 Trump can’t make up his mind about US tech giants&lt;/strong&gt;&lt;br /&gt;While defending them against EU regulation, he’s also pushing to break them up. (FT $)&lt;br /&gt;+ &lt;em&gt;He’s hosting tech leaders at the White House later today. &lt;/em&gt;(Reuters)&lt;br /&gt;+ &lt;em&gt;Elon Musk doesn’t appear to have made the guest list. &lt;/em&gt;(CNBC)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 Trump’s cuts have led to babies born with HIV&lt;/strong&gt;&lt;br /&gt;Clinics in East Africa are closing, and people are being forced to skip vital drug doses. (The Guardian)&lt;br /&gt;+ &lt;em&gt;Artificial blood could save many lives. Why aren’t we using it? &lt;/em&gt;(Slate)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4&lt;/strong&gt; &lt;strong&gt;Germany has already met its 2028 goal for reducing coal-fired power&lt;/strong&gt;&lt;br /&gt;For the second year running, it won’t have to shut any more plants as a result. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;The UK is done with coal. How’s the rest of the world doing? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;5 The risk of all-out nuclear war is growing&lt;br /&gt;&lt;/strong&gt;But we’ve normalized nuclear competition so much, the risks aren’t always clear. (New Yorker $)&lt;br /&gt;+ &lt;em&gt;Maybe it’s time to start burying nuclear reactors’ cores. &lt;/em&gt;(Economist $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 xAI is hemorrhaging executives&lt;br /&gt;&lt;/strong&gt;The CFO has left just months after joining. (WSJ $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 India’s chip industry is gaining momentum&lt;br /&gt;&lt;/strong&gt;Years of investment are starting to pay off. But can it strike deals with overseas chip giants too? (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;Meanwhile, Taiwan’s chip hub is home to a baby boom. &lt;/em&gt;(Rest of World)&lt;br /&gt;+ &lt;em&gt;Inside India’s scramble for AI independence. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 Boston Dynamics’ Atlas robot only needs one AI model to work&lt;br /&gt;&lt;/strong&gt;It’s all it requires to master humanlike movements successfully. (Wired $)&lt;br /&gt;+ &lt;em&gt;How ‘robot ballet’ could shake up factory production lines. &lt;/em&gt;(FT $)&lt;br /&gt;+ &lt;em&gt;Humanoid robots still aren’t living up to their lofty promises. &lt;/em&gt;(IEEE Spectrum)&lt;br /&gt;+ &lt;em&gt;Will we ever trust robots? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;9 How studying astronauts could improve health on Earth&lt;/strong&gt;&lt;br /&gt;There’s still a huge amount we don’t know about space’s effects on humans. (Vox)&lt;br /&gt;+ &lt;em&gt;Space travel is dangerous. Could genetic testing and gene editing make it safer? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 The Caribbean island of Anguilla has hit upon an AI cash cow&lt;/strong&gt;&lt;br /&gt;By selling its .ai domain. (Semafor)&lt;br /&gt;+ &lt;em&gt;How a tiny Pacific Island became the global capital of cybercrime. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p class="has-large-font-size"&gt;&lt;strong&gt;“If you are not being scammed yet, it’s because you haven’t encountered a scam designed just for you and only for you.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Jeff Kuo, chief executive of Taiwanese fraud prevention company Gogolook, warns the Financial Times about the endless possibilities generative AI presents to scammers.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; 
 &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1123068" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/image_9394d5.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;China built hundreds of AI data centers to catch the AI boom. Now many stand unused.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Last year, China’s boom in data center construction was at its height, fueled by both government and private investors. Renting out GPUs to companies that need them for training AI models was seen as a sure bet.&lt;/p&gt;&lt;p&gt;But with the rise of DeepSeek and a sudden change in the economics around AI, the industry is faltering. Prices for GPUs are falling and many newly built facilities are now sitting empty. Read the full story to find out why.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Caiwei Chen&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ The trailer for the forthcoming Wuthering Heights film is here and it looks…interesting.&lt;br /&gt;+ This fall’s crop of video games is outstanding.&lt;br /&gt;+ Textured walls are a surefire way to make your home look dated. Here’s some other faux pas to avoid.&lt;br /&gt;+The dogs of this year’s US Open are too cute ($)&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Synthesia’s AI clones are more expressive than ever. Soon they’ll be able to talk back.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;&lt;em&gt;—Rhiannon Williams&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;Earlier this summer, I visited the AI company Synthesia to give it what it needed to create a hyperrealistic AI-generated avatar of me. The company’s avatars are a decent barometer of just how dizzying progress has been in AI over the past few years, so I was curious just how accurately its latest AI model, introduced last month, could replicate me.&lt;/p&gt;&lt;p&gt;I found my avatar as unnerving as it is technically impressive. It’s slick enough to pass as a high-definition recording of a chirpy corporate speech, and if you didn’t know me, you’d probably think that’s exactly what it was.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;My avatar shows how it’s becoming ever-harder to distinguish the artificial from the real. And before long, these avatars will even be able to talk back to us. But how much better can they get? And what might interacting with AI clones do to us? Read the full story.&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;How Trump is helping China extend its massive lead in clean energy&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;On a spring day in 1954, Bell Labs researchers showed off the first practical solar panels at a press conference in New Jersey, using sunlight to spin a toy Ferris wheel before a stunned crowd.&lt;/p&gt;  &lt;p&gt;The solar future looked bright. But in the race to commercialize the technology it invented, the US would lose resoundingly. Last year, China exported $40 billion worth of solar panels and modules, while America shipped just $69 million, according to the New York Times. It was a stunning forfeit of a huge technological lead.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Now, thanks to its policies propping up aging fossil-fuel industries, the US seems determined to repeat the mistake. Read the full story.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;em&gt;—James Temple&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This article is from The Spark, MIT Technology Review’s newsletter all about the latest in climate and energy tech. To receive it in your inbox every Wednesday, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; 

 &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 AI chatbots of celebrities sent risqué messages to teenagers&lt;/strong&gt;&lt;br /&gt;Virtual versions of Timothée Chalamet and Chappell Roan discussed sex and drugs. (WP $)&lt;br /&gt;+ &lt;em&gt;An AI companion site is hosting sexually charged conversations with underage celebrity bots. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 Trump can’t make up his mind about US tech giants&lt;/strong&gt;&lt;br /&gt;While defending them against EU regulation, he’s also pushing to break them up. (FT $)&lt;br /&gt;+ &lt;em&gt;He’s hosting tech leaders at the White House later today. &lt;/em&gt;(Reuters)&lt;br /&gt;+ &lt;em&gt;Elon Musk doesn’t appear to have made the guest list. &lt;/em&gt;(CNBC)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 Trump’s cuts have led to babies born with HIV&lt;/strong&gt;&lt;br /&gt;Clinics in East Africa are closing, and people are being forced to skip vital drug doses. (The Guardian)&lt;br /&gt;+ &lt;em&gt;Artificial blood could save many lives. Why aren’t we using it? &lt;/em&gt;(Slate)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4&lt;/strong&gt; &lt;strong&gt;Germany has already met its 2028 goal for reducing coal-fired power&lt;/strong&gt;&lt;br /&gt;For the second year running, it won’t have to shut any more plants as a result. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;The UK is done with coal. How’s the rest of the world doing? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;5 The risk of all-out nuclear war is growing&lt;br /&gt;&lt;/strong&gt;But we’ve normalized nuclear competition so much, the risks aren’t always clear. (New Yorker $)&lt;br /&gt;+ &lt;em&gt;Maybe it’s time to start burying nuclear reactors’ cores. &lt;/em&gt;(Economist $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 xAI is hemorrhaging executives&lt;br /&gt;&lt;/strong&gt;The CFO has left just months after joining. (WSJ $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 India’s chip industry is gaining momentum&lt;br /&gt;&lt;/strong&gt;Years of investment are starting to pay off. But can it strike deals with overseas chip giants too? (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;Meanwhile, Taiwan’s chip hub is home to a baby boom. &lt;/em&gt;(Rest of World)&lt;br /&gt;+ &lt;em&gt;Inside India’s scramble for AI independence. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 Boston Dynamics’ Atlas robot only needs one AI model to work&lt;br /&gt;&lt;/strong&gt;It’s all it requires to master humanlike movements successfully. (Wired $)&lt;br /&gt;+ &lt;em&gt;How ‘robot ballet’ could shake up factory production lines. &lt;/em&gt;(FT $)&lt;br /&gt;+ &lt;em&gt;Humanoid robots still aren’t living up to their lofty promises. &lt;/em&gt;(IEEE Spectrum)&lt;br /&gt;+ &lt;em&gt;Will we ever trust robots? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;9 How studying astronauts could improve health on Earth&lt;/strong&gt;&lt;br /&gt;There’s still a huge amount we don’t know about space’s effects on humans. (Vox)&lt;br /&gt;+ &lt;em&gt;Space travel is dangerous. Could genetic testing and gene editing make it safer? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 The Caribbean island of Anguilla has hit upon an AI cash cow&lt;/strong&gt;&lt;br /&gt;By selling its .ai domain. (Semafor)&lt;br /&gt;+ &lt;em&gt;How a tiny Pacific Island became the global capital of cybercrime. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p class="has-large-font-size"&gt;&lt;strong&gt;“If you are not being scammed yet, it’s because you haven’t encountered a scam designed just for you and only for you.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Jeff Kuo, chief executive of Taiwanese fraud prevention company Gogolook, warns the Financial Times about the endless possibilities generative AI presents to scammers.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; 
 &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1123068" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/image_9394d5.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;China built hundreds of AI data centers to catch the AI boom. Now many stand unused.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Last year, China’s boom in data center construction was at its height, fueled by both government and private investors. Renting out GPUs to companies that need them for training AI models was seen as a sure bet.&lt;/p&gt;&lt;p&gt;But with the rise of DeepSeek and a sudden change in the economics around AI, the industry is faltering. Prices for GPUs are falling and many newly built facilities are now sitting empty. Read the full story to find out why.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Caiwei Chen&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ The trailer for the forthcoming Wuthering Heights film is here and it looks…interesting.&lt;br /&gt;+ This fall’s crop of video games is outstanding.&lt;br /&gt;+ Textured walls are a surefire way to make your home look dated. Here’s some other faux pas to avoid.&lt;br /&gt;+The dogs of this year’s US Open are too cute ($)&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/04/1123066/the-download-unnerving-ai-avatars-and-trumps-climate-gift-to-china/</guid><pubDate>Thu, 04 Sep 2025 12:10:00 +0000</pubDate></item></channel></rss>