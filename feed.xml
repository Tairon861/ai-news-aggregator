<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 12 Aug 2025 01:48:57 +0000</lastBuildDate><item><title>Elon Musk confirms shutdown of Tesla Dojo, ‘an evolutionary dead end’ (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/11/elon-musk-confirms-shutdown-of-tesla-dojo-an-evolutionary-dead-end/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/tesla-elon-illustration-getty.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Elon Musk confirmed over the weekend reports that Tesla has disbanded the team working on its Dojo AI training supercomputer, just weeks after announcing he expected to have Tesla’s second cluster operating “at scale” in 2026.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Once it became clear that all paths converged to AI6, I had to shut down Dojo and make some tough personnel choices, as Dojo 2 was now an evolutionary dead end,” Musk posted on X, the social media platform he owns, on Sunday. “Dojo 3 arguably lives on in the form of a large number of AI6 [systems-on-a-chip] on a single board.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;After bringing its first Dojo supercomputer to life and powering it with a mix of Nvidia GPUs and in-house-made D1 chips, Tesla had planned to build a second Dojo factory — referred to by Musk as “Dojo 2” — that would have been powered by a second-generation D2 chip.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It appears the D2 chip under development has been shelved along with the broader Dojo project as Tesla shifts its focus to its AI5 and AI6 chips, which are being manufactured by TSMC and Samsung, respectively. The AI5 chip is primarily built to power FSD, Tesla’s driver assistance system, while AI6 is designed for both onboard inference — meaning, it promises to power self-driving in cars and autonomous capabilities in humanoid robots — and large-scale AI training.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It doesn’t make sense for Tesla to divide its resources and scale two quite different AI chip designs,” Musk posted late Friday evening. “The Tesla AI5, AI6 and subsequent chips will be excellent for inference and at least pretty good for training. All effort is focused on that.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He added that for a supercomputer cluster, it makes more sense to put “many AI5/AI6 chips on a board, whether for inference or training, simply to reduce network cabling complexity &amp;amp; cost by a few orders of magnitude.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“One could call that Dojo 3, I suppose,” he said.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Musk has talked about Dojo since 2019, reiterating that Dojo would be a cornerstone of Tesla’s mission to achieve full self-driving and commercialize humanoid robots. Talk of Dojo halted around August 2024 when Musk began touting Cortex instead, a “giant new AI training supercluster being built at Tesla HQ in Austin to solve real-world AI.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s not clear if Cortex is still in the works. TechCrunch has reached out to Tesla to learn more, as well as to inquire about the fate of the Dojo facility Tesla had invested $500 million to build in Buffalo, New York.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The shift in strategy comes at a time when Tesla is experiencing falling EV sales and significant brand damage after Musk’s forays into politics. Musk has worked to convince investors that Tesla still has a future in autonomy, despite a slow and limited robotaxi launch in Austin this past June that resulted in numerous reported incidents of the vehicles exhibiting problematic driving behavior.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We want to get to know our audience even better, and get your feedback on our coverage and events.&amp;nbsp;&lt;/em&gt;&lt;em&gt;Fill out this survey to give us your thoughts&lt;/em&gt;&lt;em&gt;, and get the chance to win a prize in return.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/tesla-elon-illustration-getty.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Elon Musk confirmed over the weekend reports that Tesla has disbanded the team working on its Dojo AI training supercomputer, just weeks after announcing he expected to have Tesla’s second cluster operating “at scale” in 2026.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Once it became clear that all paths converged to AI6, I had to shut down Dojo and make some tough personnel choices, as Dojo 2 was now an evolutionary dead end,” Musk posted on X, the social media platform he owns, on Sunday. “Dojo 3 arguably lives on in the form of a large number of AI6 [systems-on-a-chip] on a single board.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;After bringing its first Dojo supercomputer to life and powering it with a mix of Nvidia GPUs and in-house-made D1 chips, Tesla had planned to build a second Dojo factory — referred to by Musk as “Dojo 2” — that would have been powered by a second-generation D2 chip.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It appears the D2 chip under development has been shelved along with the broader Dojo project as Tesla shifts its focus to its AI5 and AI6 chips, which are being manufactured by TSMC and Samsung, respectively. The AI5 chip is primarily built to power FSD, Tesla’s driver assistance system, while AI6 is designed for both onboard inference — meaning, it promises to power self-driving in cars and autonomous capabilities in humanoid robots — and large-scale AI training.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It doesn’t make sense for Tesla to divide its resources and scale two quite different AI chip designs,” Musk posted late Friday evening. “The Tesla AI5, AI6 and subsequent chips will be excellent for inference and at least pretty good for training. All effort is focused on that.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He added that for a supercomputer cluster, it makes more sense to put “many AI5/AI6 chips on a board, whether for inference or training, simply to reduce network cabling complexity &amp;amp; cost by a few orders of magnitude.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“One could call that Dojo 3, I suppose,” he said.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Musk has talked about Dojo since 2019, reiterating that Dojo would be a cornerstone of Tesla’s mission to achieve full self-driving and commercialize humanoid robots. Talk of Dojo halted around August 2024 when Musk began touting Cortex instead, a “giant new AI training supercluster being built at Tesla HQ in Austin to solve real-world AI.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s not clear if Cortex is still in the works. TechCrunch has reached out to Tesla to learn more, as well as to inquire about the fate of the Dojo facility Tesla had invested $500 million to build in Buffalo, New York.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The shift in strategy comes at a time when Tesla is experiencing falling EV sales and significant brand damage after Musk’s forays into politics. Musk has worked to convince investors that Tesla still has a future in autonomy, despite a slow and limited robotaxi launch in Austin this past June that resulted in numerous reported incidents of the vehicles exhibiting problematic driving behavior.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We want to get to know our audience even better, and get your feedback on our coverage and events.&amp;nbsp;&lt;/em&gt;&lt;em&gt;Fill out this survey to give us your thoughts&lt;/em&gt;&lt;em&gt;, and get the chance to win a prize in return.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/11/elon-musk-confirms-shutdown-of-tesla-dojo-an-evolutionary-dead-end/</guid><pubDate>Mon, 11 Aug 2025 14:50:26 +0000</pubDate></item><item><title>Amazon Devices &amp; Services Achieves Major Step Toward Zero-Touch Manufacturing With NVIDIA AI and Digital Twins (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/amazon-zero-touch-manufacturing/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Using NVIDIA digital twin technologies, Amazon Devices &amp;amp; Services is powering big leaps in manufacturing with a new physical AI software solution.&lt;/p&gt;
&lt;p&gt;Deployed this month at an Amazon Devices facility, the company’s innovative, simulation-first approach for zero-touch manufacturing trains robotic arms to inspect diverse devices for product-quality auditing and integrate new goods into the production line — all based on synthetic data, without requiring hardware changes.&lt;/p&gt;
&lt;p&gt;This new technology brings together Amazon Devices-created software that simulates processes on the assembly line with products in NVIDIA-powered digital twins. Using a modular, AI-powered workflow, the technology offers faster, more efficient inspections compared with the previously used audit machinery.&lt;/p&gt;
&lt;p&gt;Simulating processes and products in digital twins eliminates the need for expensive, time-consuming physical prototyping. This eases manufacturer workflows and reduces the time it takes to get new products into consumers’ hands.&lt;/p&gt;
&lt;p&gt;To enable zero-shot manufacturing for the robotic operations, the solution uses photorealistic, physics-enabled representations of Amazon devices and factory work stations to generate synthetic data. This factory-specific data is then used to enhance AI model performance in both simulation and at the real work station, minimizing the simulation-to-real gap before deployment.&lt;/p&gt;
&lt;p&gt;It’s a huge step toward generalized manufacturing: the use of automated systems and technologies to flexibly handle a wide variety of products and production processes — even without physical prototypes.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;AI, Digital Twins for Robot Understanding&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;By training robots in digital twins to recognize and handle new devices, Amazon Devices &amp;amp; Services is equipped to build faster, more modular and easily controllable manufacturing pipelines, allowing lines to change from auditing one product to another simply via software.&lt;/p&gt;
&lt;p&gt;Robotic actions can be configured to manufacture products purely based on training performed in simulation — including for steps involved in assembly, testing, packaging and auditing.&lt;/p&gt;
&lt;p&gt;A suite of NVIDIA Isaac technologies enables Amazon Devices &amp;amp; Services physically accurate, simulation-first approach.&lt;/p&gt;
&lt;p&gt;When a new device is introduced, Amazon Devices &amp;amp; Services puts its computer-aided design (CAD) model into NVIDIA Isaac Sim, an open-source, robotics simulation reference application built on the NVIDIA Omniverse platform.&lt;/p&gt;
&lt;p&gt;NVIDIA Isaac is used to generate over 50,000 diverse, synthetic images from the CAD models for each device, crucial for training object- and defect-detection models.&lt;/p&gt;
&lt;p&gt;Then, Isaac Sim processes the data and taps into NVIDIA Isaac ROS to generate robotic arm trajectories for handling the product.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83583"&gt;&lt;img alt="The robot is trained purely on synthetic data and can pick up packages and products of different shapes and sizes to perform cosmetic inspection. Real station (left) and simulated station (right). Image courtesy of Amazon Devices &amp;amp; Services." class="size-full wp-image-83583" height="406" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/amazon-sim-to-real.jpg" width="1430" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83583"&gt;The robot is trained purely on synthetic data and can pick up packages and products of different shapes and sizes to perform cosmetic inspection. Real station (left) and simulated station (right). Image courtesy of Amazon Devices &amp;amp; Services.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;The development of this technology was significantly accelerated by AWS through distributed AI model training on Amazon devices’ product specifications using Amazon EC2 G6 instances via AWS Batch, as well as NVIDIA Isaac Sim physics-based simulation and synthetic data generation on Amazon EC2 G6 family instances.&lt;/p&gt;
&lt;p&gt;The solution uses Amazon Bedrock — a service for building generative AI applications and agents — to plan high-level tasks and specific audit test cases at the factory based on analyses of product-specification documents. Amazon Bedrock AgentCore will be used for autonomous-workflow planning for multiple factory stations on the production line, with the ability to ingest multimodal product-specification inputs such as 3D designs and surface properties.&lt;/p&gt;
&lt;p&gt;To help robots understand their environment, the solution uses NVIDIA cuMotion, a CUDA-accelerated motion-planning library that can generate collision-free trajectories in a fraction of a second on the NVIDIA Jetson AGX Orin module. The nvblox library, part of Isaac ROS, generates distance fields that cuMotion uses for collision-free trajectory planning.&lt;/p&gt;
&lt;p&gt;FoundationPose, an NVIDIA foundation model trained on 5 million synthetic images for pose estimation and object tracking, helps ensure the Amazon Devices &amp;amp; Services robots know the accurate position and orientation of the devices.&lt;/p&gt;
&lt;p&gt;Crucial for the new manufacturing solution, FoundationPose can generalize to entirely new objects without prior exposure, allowing seamless transitions between different products and eliminating the need to collect new data to retrain models for each change.&lt;/p&gt;
&lt;p&gt;As part of product auditing, the new solution’s approach is used for defect detection on the manufacturing line. Its modular design allows for future integration of advanced reasoning models like NVIDIA Cosmos Reason.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Watch the &lt;/i&gt;&lt;i&gt;NVIDIA Research special address at SIGGRAPH&lt;/i&gt;&lt;i&gt; and learn more about how graphics and simulation innovations come together to drive industrial digitalization by joining NVIDIA at the conference, running through Thursday, Aug. 14.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Using NVIDIA digital twin technologies, Amazon Devices &amp;amp; Services is powering big leaps in manufacturing with a new physical AI software solution.&lt;/p&gt;
&lt;p&gt;Deployed this month at an Amazon Devices facility, the company’s innovative, simulation-first approach for zero-touch manufacturing trains robotic arms to inspect diverse devices for product-quality auditing and integrate new goods into the production line — all based on synthetic data, without requiring hardware changes.&lt;/p&gt;
&lt;p&gt;This new technology brings together Amazon Devices-created software that simulates processes on the assembly line with products in NVIDIA-powered digital twins. Using a modular, AI-powered workflow, the technology offers faster, more efficient inspections compared with the previously used audit machinery.&lt;/p&gt;
&lt;p&gt;Simulating processes and products in digital twins eliminates the need for expensive, time-consuming physical prototyping. This eases manufacturer workflows and reduces the time it takes to get new products into consumers’ hands.&lt;/p&gt;
&lt;p&gt;To enable zero-shot manufacturing for the robotic operations, the solution uses photorealistic, physics-enabled representations of Amazon devices and factory work stations to generate synthetic data. This factory-specific data is then used to enhance AI model performance in both simulation and at the real work station, minimizing the simulation-to-real gap before deployment.&lt;/p&gt;
&lt;p&gt;It’s a huge step toward generalized manufacturing: the use of automated systems and technologies to flexibly handle a wide variety of products and production processes — even without physical prototypes.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;AI, Digital Twins for Robot Understanding&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;By training robots in digital twins to recognize and handle new devices, Amazon Devices &amp;amp; Services is equipped to build faster, more modular and easily controllable manufacturing pipelines, allowing lines to change from auditing one product to another simply via software.&lt;/p&gt;
&lt;p&gt;Robotic actions can be configured to manufacture products purely based on training performed in simulation — including for steps involved in assembly, testing, packaging and auditing.&lt;/p&gt;
&lt;p&gt;A suite of NVIDIA Isaac technologies enables Amazon Devices &amp;amp; Services physically accurate, simulation-first approach.&lt;/p&gt;
&lt;p&gt;When a new device is introduced, Amazon Devices &amp;amp; Services puts its computer-aided design (CAD) model into NVIDIA Isaac Sim, an open-source, robotics simulation reference application built on the NVIDIA Omniverse platform.&lt;/p&gt;
&lt;p&gt;NVIDIA Isaac is used to generate over 50,000 diverse, synthetic images from the CAD models for each device, crucial for training object- and defect-detection models.&lt;/p&gt;
&lt;p&gt;Then, Isaac Sim processes the data and taps into NVIDIA Isaac ROS to generate robotic arm trajectories for handling the product.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83583"&gt;&lt;img alt="The robot is trained purely on synthetic data and can pick up packages and products of different shapes and sizes to perform cosmetic inspection. Real station (left) and simulated station (right). Image courtesy of Amazon Devices &amp;amp; Services." class="size-full wp-image-83583" height="406" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/amazon-sim-to-real.jpg" width="1430" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83583"&gt;The robot is trained purely on synthetic data and can pick up packages and products of different shapes and sizes to perform cosmetic inspection. Real station (left) and simulated station (right). Image courtesy of Amazon Devices &amp;amp; Services.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;The development of this technology was significantly accelerated by AWS through distributed AI model training on Amazon devices’ product specifications using Amazon EC2 G6 instances via AWS Batch, as well as NVIDIA Isaac Sim physics-based simulation and synthetic data generation on Amazon EC2 G6 family instances.&lt;/p&gt;
&lt;p&gt;The solution uses Amazon Bedrock — a service for building generative AI applications and agents — to plan high-level tasks and specific audit test cases at the factory based on analyses of product-specification documents. Amazon Bedrock AgentCore will be used for autonomous-workflow planning for multiple factory stations on the production line, with the ability to ingest multimodal product-specification inputs such as 3D designs and surface properties.&lt;/p&gt;
&lt;p&gt;To help robots understand their environment, the solution uses NVIDIA cuMotion, a CUDA-accelerated motion-planning library that can generate collision-free trajectories in a fraction of a second on the NVIDIA Jetson AGX Orin module. The nvblox library, part of Isaac ROS, generates distance fields that cuMotion uses for collision-free trajectory planning.&lt;/p&gt;
&lt;p&gt;FoundationPose, an NVIDIA foundation model trained on 5 million synthetic images for pose estimation and object tracking, helps ensure the Amazon Devices &amp;amp; Services robots know the accurate position and orientation of the devices.&lt;/p&gt;
&lt;p&gt;Crucial for the new manufacturing solution, FoundationPose can generalize to entirely new objects without prior exposure, allowing seamless transitions between different products and eliminating the need to collect new data to retrain models for each change.&lt;/p&gt;
&lt;p&gt;As part of product auditing, the new solution’s approach is used for defect detection on the manufacturing line. Its modular design allows for future integration of advanced reasoning models like NVIDIA Cosmos Reason.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Watch the &lt;/i&gt;&lt;i&gt;NVIDIA Research special address at SIGGRAPH&lt;/i&gt;&lt;i&gt; and learn more about how graphics and simulation innovations come together to drive industrial digitalization by joining NVIDIA at the conference, running through Thursday, Aug. 14.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/amazon-zero-touch-manufacturing/</guid><pubDate>Mon, 11 Aug 2025 15:00:00 +0000</pubDate></item><item><title>Nvidia unveils new Cosmos world models, infra for robotics and physical uses (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/11/nvidia-unveils-new-cosmos-world-models-other-infra-for-physical-applications-of-ai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/03/GettyImages-2205761844.jpg?resize=1200,846" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Nvidia on Monday unveiled a set of new world AI models, libraries, and other infrastructure for robotics developers, most notable of which is Cosmos Reason, a 7-billion-parameter “reasoning” vision language model for physical AI applications and robots.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Also joining the existing batch of Cosmos world models are&amp;nbsp;Cosmos Transfer-2, which can accelerate synthetic data generation from 3D simulation scenes or spatial control inputs, and a distilled version of Cosmos Transfers that is more optimized for speed.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;During its announcement at the SIGGRAPH conference on Monday, Nvidia noted that these models are meant to be used to create synthetic text, image, and video datasets for training robots and AI agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cosmos Reason, per Nvidia, allows robots and AI agents to “reason” thanks to its memory and physics understanding, which lets it “serve as a planning model to reason what steps an embodied agent might take next.”&amp;nbsp;The company says it can be used for data curation, robot planning, and video analytics.  &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company also unveiled new neural reconstruction libraries, which includes one for a rendering technique that lets developers simulate the real world in 3D using sensor data. This rendering capability is also being integrated into open source simulator CARLA, a popular developer platform. There’s even an update to the Omniverse software development kit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There are new servers for robotics workflows, too. The Nvidia RTX Pro Blackwell Server offers a single architecture for robotic development workloads, while Nvidia DGX Cloud is a cloud-based management platform.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These announcements come as the semiconductor giant is pushing further into robotics as it looks toward the next big use case for its AI GPUs beyond AI data centers.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch, you can help us!&amp;nbsp;Fill out this survey to let us know how we’re doing.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/03/GettyImages-2205761844.jpg?resize=1200,846" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Nvidia on Monday unveiled a set of new world AI models, libraries, and other infrastructure for robotics developers, most notable of which is Cosmos Reason, a 7-billion-parameter “reasoning” vision language model for physical AI applications and robots.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Also joining the existing batch of Cosmos world models are&amp;nbsp;Cosmos Transfer-2, which can accelerate synthetic data generation from 3D simulation scenes or spatial control inputs, and a distilled version of Cosmos Transfers that is more optimized for speed.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;During its announcement at the SIGGRAPH conference on Monday, Nvidia noted that these models are meant to be used to create synthetic text, image, and video datasets for training robots and AI agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cosmos Reason, per Nvidia, allows robots and AI agents to “reason” thanks to its memory and physics understanding, which lets it “serve as a planning model to reason what steps an embodied agent might take next.”&amp;nbsp;The company says it can be used for data curation, robot planning, and video analytics.  &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company also unveiled new neural reconstruction libraries, which includes one for a rendering technique that lets developers simulate the real world in 3D using sensor data. This rendering capability is also being integrated into open source simulator CARLA, a popular developer platform. There’s even an update to the Omniverse software development kit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There are new servers for robotics workflows, too. The Nvidia RTX Pro Blackwell Server offers a single architecture for robotic development workloads, while Nvidia DGX Cloud is a cloud-based management platform.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These announcements come as the semiconductor giant is pushing further into robotics as it looks toward the next big use case for its AI GPUs beyond AI data centers.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch, you can help us!&amp;nbsp;Fill out this survey to let us know how we’re doing.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/11/nvidia-unveils-new-cosmos-world-models-other-infra-for-physical-applications-of-ai/</guid><pubDate>Mon, 11 Aug 2025 15:00:00 +0000</pubDate></item><item><title>Mini Footprint, Mighty AI: NVIDIA Blackwell Architecture Powers AI Acceleration in Compact Workstations (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/blackwell-ai-acceleration-workstation-rtx-pro/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Packing the power of the NVIDIA Blackwell architecture in compact, energy-efficient form factors, the NVIDIA RTX PRO 4000 Blackwell SFF Edition and NVIDIA RTX PRO 2000 Blackwell GPUs are coming soon — delivering AI acceleration for professional workflows across industries.&lt;/p&gt;
&lt;p&gt;Applications are becoming increasingly AI accelerated, and more users need AI performance, no matter the size or shape of their workstation.&lt;/p&gt;
&lt;p&gt;The RTX PRO 4000 SFF and RTX PRO 2000 feature fourth-generation RT Cores and fifth-generation Tensor Cores with lower power in half the size of a traditional GPU.&lt;/p&gt;
&lt;p&gt;The new GPUs are designed to bring next-generation performance to a range of professional workflows, providing incredible speedups for engineering, design, content creation, AI and 3D visualization.&lt;/p&gt;
&lt;p&gt;Compared with the previous-generation architecture, the RTX PRO 4000 SFF features up to 2.5x higher AI performance, 1.7x higher ray-tracing performance and 1.5x more bandwidth, creating more efficiency with the same 70-watt max power consumption.&lt;/p&gt;
&lt;p&gt;Optimized for mainstream design and AI workflows, the RTX PRO 2000 offers up to 1.6x faster 3D modeling, 1.4x faster computer-aided design (CAD) performance and 1.6x quicker rendering speeds compared with the previous generation.&lt;/p&gt;
&lt;figure class="wp-caption alignnone" id="attachment_83547"&gt;&lt;img alt="alt" class="wp-image-83547 size-large" height="945" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/rtx-pro-2000-blackwell-1680x945.png" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83547"&gt;The NVIDIA RTX PRO 2000 Blackwell.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;CAD and product engineers as well as creatives will benefit from the RTX PRO 2000 GPU’s 1.4x boost in image generation and 2.3x leap in text generation, enabling faster iteration, rapid prototyping and seamless collaboration.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Businesses Tap NVIDIA RTX PRO for Speedups&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Businesses across fields including engineering, construction, architecture, media and entertainment, and healthcare are using RTX PRO Blackwell GPUs to instantly accomplish tasks that previously took hours.&lt;/p&gt;
&lt;p&gt;The Mile High Flood District protects people, property and the environment in the Denver, Colorado, metro area by managing flood risks with regional watershed planning, early warning systems, stream restoration and stormwater control, in collaboration with local governments.&lt;/p&gt;
&lt;p&gt;“Mile High Flood District runs complex flood simulations, massive 3D visualizations and real-time AI workflows — and with nearly double the CUDA cores, NVIDIA RTX PRO 2000 Blackwell is a big step up in performance compared with the NVIDIA RTX 2000 Ada Generation GPU,” said Jon Villines, innovation manager at Mile High Flood District. “NVIDIA RTX PRO allows us to more easily handle increasingly larger geographic information systems, as well as hydraulic and hydrologic datasets.”&lt;/p&gt;
&lt;p&gt;The Government of Cantabria Geospatial Office is responsible for analyzing and visualizing high-resolution geographic information system data for government and public use.&lt;/p&gt;
&lt;p&gt;“We tested the NVIDIA RTX PRO 2000 Blackwell and were very impressed with its performance on geospatial workloads with Esri ArcGIS Pro,” said Gabriel Ortiz Rico, chief of service of cartography and geographic information systems at the Government of Cantabria. “Fine-tuning of AI models is 2x faster compared with using the RTX 2000 Ada due to the RTX 2000 Blackwell’s additional Tensor Cores and GDDR7 memory.”&lt;/p&gt;
&lt;p&gt;Studio Tim Fu (STF) is a London-based design studio specializing in the integration of human creativity and AI with architecture and design.&lt;/p&gt;
&lt;p&gt;“The RTX PRO 2000 Blackwell powers our UrbanGPT application for real-time text-to-3D urban design, which can be used to generate dynamic city layouts, track vital metrics like program and floor areas, and produce realistic massing distribution across complex urban design scenarios,” said Tim Fu, director of STF. “From zoning simulations to large-scale massing studies, this technology accelerates our AI-driven design engine with the stability and responsiveness needed for city-scale planning.”&lt;/p&gt;
&lt;p&gt;New York-based Thornton Tomasetti is a global engineering and design consulting firm integrating engineering, science, technology and forensic analysis to advance performance, resilience and innovation in the built environment and beyond.&lt;/p&gt;
&lt;p&gt;“At Thornton Tomasetti, we’re constantly advancing computational engineering,” said Rob Otani, chief technology officer of Thornton Tomasetti. “We benchmarked the RTX PRO 2000 Blackwell on CORE.Matrix — our in-house, GPU-based Finite Element Analysis solver — running almost 3x faster than with the RTX 2000 Ada and 27x faster than with a standard CPU. This enabled us to accelerate our structural analysis workflows for more iterative, design-integrated engineering.”&lt;/p&gt;
&lt;p&gt;Glüxkind is a technology company that creates AI-powered smart baby strollers designed to improve safety, convenience and accessibility for parents and their children.&lt;/p&gt;
&lt;p&gt;“Integrating the latest generation of advanced GPUs like the RTX PRO 2000 enables Glüxkind to push the boundaries of what’s possible in AI-powered parenting solutions,” said Kevin Huang, CEO of Glüxkind. “The RTX PRO 2000’s enhanced AI and graphics performance give us the real-time processing power needed to make our smart strollers safer, more responsive and more convenient for families everywhere.”&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;The Software Driving Innovation&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;NVIDIA’s software ecosystem enables creators, developers and enterprises to harness the full power of AI and advanced graphics.&lt;/p&gt;
&lt;p&gt;The NVIDIA AI Enterprise software suite delivers enterprise-grade tools for building, deploying and scaling production AI — from generative AI and computer vision to speech and natural language solutions — on virtually any infrastructure.&lt;/p&gt;
&lt;p&gt;The NVIDIA Cosmos platform offers world foundation models optimized for fast, efficient inference and edge deployment, enabling high-performance AI for robotics, automation and physical AI applications. The Cosmos-Reason1-7B model can run seamlessly on the RTX PRO 4000 SFF, delivering powerful physical AI reasoning capabilities to edge devices, compact workstations and industrial systems.&lt;/p&gt;
&lt;p&gt;NVIDIA’s graphics and visualization tools, including the NVIDIA Omniverse platform, bring generative physical AI and simulation to 3D design teams, facilitating digital twins and visual workflows.&lt;/p&gt;
&lt;p&gt;In addition, the Blackwell platform builds on NVIDIA’s ecosystem of powerful development tools, NVIDIA CUDA-X libraries, over 6 million developers and close to 6,000 applications to scale performance across thousands of GPUs.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Availability&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The NVIDIA RTX PRO 2000 Blackwell and NVIDIA RTX PRO 4000 Blackwell SFF Edition GPUs are coming later this year.&lt;/p&gt;
&lt;p&gt;The RTX PRO 2000 is expected to be available from PNY and TD SYNNEX, as well as system builders such as BOXX, Dell Technologies, HP and Lenovo.&lt;/p&gt;
&lt;p&gt;The NVIDIA RTX PRO 4000 Blackwell SFF Edition is expected to be available from global distribution partners and leading manufacturing partners such as Dell Technologies, HP and Lenovo.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Watch the &lt;/i&gt;&lt;i&gt;NVIDIA Research special address at SIGGRAPH&lt;/i&gt;&lt;i&gt; and learn more about how graphics and simulation innovations come together to drive industrial digitalization by joining NVIDIA at the conference, running through Thursday, Aug. 14.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Packing the power of the NVIDIA Blackwell architecture in compact, energy-efficient form factors, the NVIDIA RTX PRO 4000 Blackwell SFF Edition and NVIDIA RTX PRO 2000 Blackwell GPUs are coming soon — delivering AI acceleration for professional workflows across industries.&lt;/p&gt;
&lt;p&gt;Applications are becoming increasingly AI accelerated, and more users need AI performance, no matter the size or shape of their workstation.&lt;/p&gt;
&lt;p&gt;The RTX PRO 4000 SFF and RTX PRO 2000 feature fourth-generation RT Cores and fifth-generation Tensor Cores with lower power in half the size of a traditional GPU.&lt;/p&gt;
&lt;p&gt;The new GPUs are designed to bring next-generation performance to a range of professional workflows, providing incredible speedups for engineering, design, content creation, AI and 3D visualization.&lt;/p&gt;
&lt;p&gt;Compared with the previous-generation architecture, the RTX PRO 4000 SFF features up to 2.5x higher AI performance, 1.7x higher ray-tracing performance and 1.5x more bandwidth, creating more efficiency with the same 70-watt max power consumption.&lt;/p&gt;
&lt;p&gt;Optimized for mainstream design and AI workflows, the RTX PRO 2000 offers up to 1.6x faster 3D modeling, 1.4x faster computer-aided design (CAD) performance and 1.6x quicker rendering speeds compared with the previous generation.&lt;/p&gt;
&lt;figure class="wp-caption alignnone" id="attachment_83547"&gt;&lt;img alt="alt" class="wp-image-83547 size-large" height="945" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/rtx-pro-2000-blackwell-1680x945.png" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83547"&gt;The NVIDIA RTX PRO 2000 Blackwell.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;CAD and product engineers as well as creatives will benefit from the RTX PRO 2000 GPU’s 1.4x boost in image generation and 2.3x leap in text generation, enabling faster iteration, rapid prototyping and seamless collaboration.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Businesses Tap NVIDIA RTX PRO for Speedups&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Businesses across fields including engineering, construction, architecture, media and entertainment, and healthcare are using RTX PRO Blackwell GPUs to instantly accomplish tasks that previously took hours.&lt;/p&gt;
&lt;p&gt;The Mile High Flood District protects people, property and the environment in the Denver, Colorado, metro area by managing flood risks with regional watershed planning, early warning systems, stream restoration and stormwater control, in collaboration with local governments.&lt;/p&gt;
&lt;p&gt;“Mile High Flood District runs complex flood simulations, massive 3D visualizations and real-time AI workflows — and with nearly double the CUDA cores, NVIDIA RTX PRO 2000 Blackwell is a big step up in performance compared with the NVIDIA RTX 2000 Ada Generation GPU,” said Jon Villines, innovation manager at Mile High Flood District. “NVIDIA RTX PRO allows us to more easily handle increasingly larger geographic information systems, as well as hydraulic and hydrologic datasets.”&lt;/p&gt;
&lt;p&gt;The Government of Cantabria Geospatial Office is responsible for analyzing and visualizing high-resolution geographic information system data for government and public use.&lt;/p&gt;
&lt;p&gt;“We tested the NVIDIA RTX PRO 2000 Blackwell and were very impressed with its performance on geospatial workloads with Esri ArcGIS Pro,” said Gabriel Ortiz Rico, chief of service of cartography and geographic information systems at the Government of Cantabria. “Fine-tuning of AI models is 2x faster compared with using the RTX 2000 Ada due to the RTX 2000 Blackwell’s additional Tensor Cores and GDDR7 memory.”&lt;/p&gt;
&lt;p&gt;Studio Tim Fu (STF) is a London-based design studio specializing in the integration of human creativity and AI with architecture and design.&lt;/p&gt;
&lt;p&gt;“The RTX PRO 2000 Blackwell powers our UrbanGPT application for real-time text-to-3D urban design, which can be used to generate dynamic city layouts, track vital metrics like program and floor areas, and produce realistic massing distribution across complex urban design scenarios,” said Tim Fu, director of STF. “From zoning simulations to large-scale massing studies, this technology accelerates our AI-driven design engine with the stability and responsiveness needed for city-scale planning.”&lt;/p&gt;
&lt;p&gt;New York-based Thornton Tomasetti is a global engineering and design consulting firm integrating engineering, science, technology and forensic analysis to advance performance, resilience and innovation in the built environment and beyond.&lt;/p&gt;
&lt;p&gt;“At Thornton Tomasetti, we’re constantly advancing computational engineering,” said Rob Otani, chief technology officer of Thornton Tomasetti. “We benchmarked the RTX PRO 2000 Blackwell on CORE.Matrix — our in-house, GPU-based Finite Element Analysis solver — running almost 3x faster than with the RTX 2000 Ada and 27x faster than with a standard CPU. This enabled us to accelerate our structural analysis workflows for more iterative, design-integrated engineering.”&lt;/p&gt;
&lt;p&gt;Glüxkind is a technology company that creates AI-powered smart baby strollers designed to improve safety, convenience and accessibility for parents and their children.&lt;/p&gt;
&lt;p&gt;“Integrating the latest generation of advanced GPUs like the RTX PRO 2000 enables Glüxkind to push the boundaries of what’s possible in AI-powered parenting solutions,” said Kevin Huang, CEO of Glüxkind. “The RTX PRO 2000’s enhanced AI and graphics performance give us the real-time processing power needed to make our smart strollers safer, more responsive and more convenient for families everywhere.”&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;The Software Driving Innovation&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;NVIDIA’s software ecosystem enables creators, developers and enterprises to harness the full power of AI and advanced graphics.&lt;/p&gt;
&lt;p&gt;The NVIDIA AI Enterprise software suite delivers enterprise-grade tools for building, deploying and scaling production AI — from generative AI and computer vision to speech and natural language solutions — on virtually any infrastructure.&lt;/p&gt;
&lt;p&gt;The NVIDIA Cosmos platform offers world foundation models optimized for fast, efficient inference and edge deployment, enabling high-performance AI for robotics, automation and physical AI applications. The Cosmos-Reason1-7B model can run seamlessly on the RTX PRO 4000 SFF, delivering powerful physical AI reasoning capabilities to edge devices, compact workstations and industrial systems.&lt;/p&gt;
&lt;p&gt;NVIDIA’s graphics and visualization tools, including the NVIDIA Omniverse platform, bring generative physical AI and simulation to 3D design teams, facilitating digital twins and visual workflows.&lt;/p&gt;
&lt;p&gt;In addition, the Blackwell platform builds on NVIDIA’s ecosystem of powerful development tools, NVIDIA CUDA-X libraries, over 6 million developers and close to 6,000 applications to scale performance across thousands of GPUs.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Availability&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The NVIDIA RTX PRO 2000 Blackwell and NVIDIA RTX PRO 4000 Blackwell SFF Edition GPUs are coming later this year.&lt;/p&gt;
&lt;p&gt;The RTX PRO 2000 is expected to be available from PNY and TD SYNNEX, as well as system builders such as BOXX, Dell Technologies, HP and Lenovo.&lt;/p&gt;
&lt;p&gt;The NVIDIA RTX PRO 4000 Blackwell SFF Edition is expected to be available from global distribution partners and leading manufacturing partners such as Dell Technologies, HP and Lenovo.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Watch the &lt;/i&gt;&lt;i&gt;NVIDIA Research special address at SIGGRAPH&lt;/i&gt;&lt;i&gt; and learn more about how graphics and simulation innovations come together to drive industrial digitalization by joining NVIDIA at the conference, running through Thursday, Aug. 14.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/blackwell-ai-acceleration-workstation-rtx-pro/</guid><pubDate>Mon, 11 Aug 2025 15:00:03 +0000</pubDate></item><item><title>CrowdStrike, Uber, Zoom Among Industry Pioneers Building Smarter Agents With NVIDIA Nemotron and Cosmos Reasoning Models for Enterprise and Physical AI Applications (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/nemotron-cosmos-reasoning-enterprise-physical-ai/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;AI agents are poised to deliver as much as $450 billion from revenue gains and cost savings by 2028, according to Capgemini. Developers building these agents are turning to higher-performing reasoning models to improve AI agent platforms and physical AI systems.&lt;/p&gt;
&lt;p&gt;At SIGGRAPH, NVIDIA today announced an expansion of two model families with reasoning capabilities — NVIDIA Nemotron and NVIDIA Cosmos — that leaders across industries are using to drive productivity via teams of AI agents and humanoid robots.&lt;/p&gt;
&lt;p&gt;CrowdStrike, Uber, Magna, NetApp and Zoom are among some of the enterprises tapping into these model families.&lt;/p&gt;
&lt;p&gt;New NVIDIA Nemotron Nano 2 and Llama Nemotron Super 1.5 models offer the highest accuracy in their size categories for scientific reasoning, math, coding, tool-calling, instruction-following and chat. These new models give AI agents the power to think more deeply and work more efficiently — exploring broader options, speeding up research and delivering smarter results within set time limits.&lt;/p&gt;
&lt;p&gt;Think of the model as the brain of an AI agent — it provides the core intelligence. But to make that brain useful for a business, it must be embedded into an agent that understands specific workflows, in addition to industry and business jargon, and operates safely. NVIDIA helps enterprises bridge that gap with leading libraries and AI blueprints for onboarding, customizing and governing AI agents at scale.&lt;/p&gt;
&lt;p&gt;Cosmos Reason is a new reasoning vision language model (VLM) for physical AI applications that excels in understanding how the real world works, using structured reasoning to understand concepts like physics, object permanence and space-time alignment.&lt;/p&gt;
&lt;p&gt;Cosmos Reason is purpose-built to serve as the reasoning backbone to a robot vision language action (VLA) model, or critique and caption training data for robotics and autonomous vehicles, and equip runtime visual AI agents with spatial-temporal understanding and reasoning of physical operations, like in factories or cities.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Nemotron: Highest Accuracy and Efficiency for Agentic Enterprise AI&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;As enterprises develop AI agents to tackle complex, multistep tasks, models that can provide strong reasoning accuracy with efficient token generation enable intelligent, autonomous decision-making at scale.&lt;/p&gt;
&lt;p&gt;NVIDIA Nemotron is a family of advanced open reasoning models that use leading models, NVIDIA-curated open datasets and advanced AI techniques to provide an accurate and efficient starting point for AI agents.&lt;/p&gt;
&lt;p&gt;The latest Nemotron models deliver leading efficiency in three ways: a new hybrid model architecture, compact quantized models and a configurable thinking budget that provides developers with control over token generation, resulting in 60% lower reasoning costs. This combination lets the models reason more deeply and respond faster, without needing more time or computing power. This means better results at a lower cost.&lt;/p&gt;
&lt;p&gt;Nemotron Nano 2 provides as much as 6x higher token generation compared with other leading models of its size.&lt;/p&gt;
&lt;p&gt;Llama Nemotron Super 1.5 achieves leading performance and the highest reasoning accuracy in its class, empowering AI agents to reason better, make smarter decisions and handle complex tasks independently. It’s now available in NVFP4, or 4-bit floating point, which delivers as much as 6x higher throughput on NVIDIA B200 GPUs compared with NVIDIA H100 GPUs.&lt;/p&gt;

&lt;p&gt;&lt;img alt="alt" class="aligncenter size-medium wp-image-83674" height="655" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/nemotron-chart-960x655.png" width="960" /&gt;&lt;/p&gt;
&lt;p&gt;The chart above shows the Nemotron model delivers top reasoning accuracy in the same timeframe and on the same compute budget, delivering the highest accuracy per dollar.&lt;/p&gt;
&lt;p&gt;Along with the two new Nemotron models, NVIDIA is also announcing its first open VLM training dataset — Llama Nemotron VLM dataset v1 — with 3 million samples of optical character recognition, visual QA and captioning data that power the previously released Llama 3.1 Nemotron Nano VL 8B model.&lt;/p&gt;
&lt;p&gt;In addition to the accuracy of the reasoning models, agents also rely on retrieval-augmented generation to fetch the latest and most relevant information from connected data across disparate sources to make informed decisions. The recently released Llama 3.2 NeMo Retriever embedding model tops three visual document retrieval leaderboards — ViDoRe V1, ViDoRe V2 and MTEB VisualDocumentRetrieval — for boosting agentic system accuracy.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-medium wp-image-83671" height="496" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/nemotron-models-960x496.png" width="960" /&gt;&lt;/p&gt;
&lt;p&gt;Using these reasoning and information retrieval models, a deep research agent built using the AI-Q NVIDIA Blueprint is currently No. 1 for open and portable agents on DeepResearch Bench.&lt;/p&gt;
&lt;p&gt;NVIDIA NeMo and NVIDIA NIM microservices support the entire AI agent lifecycle — from development and deployment to monitoring and optimization of the agentic systems.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Cosmos Reason: A Breakthrough in Physical AI&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;&lt;img alt="alt" class="alignnone size-full wp-image-83531" height="506" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/Toaster-Cosmos-Reasoning.gif" width="900" /&gt;&lt;/p&gt;
&lt;p&gt;VLMs marked a breakthrough for computer vision and robotics, empowering machines to identify objects and patterns. However, nonreasoning VLMs lack the ability to understand and interact with the real world — meaning they can’t handle ambiguity or novel experiences, nor solve complex multistep tasks.&lt;/p&gt;
&lt;p&gt;NVIDIA Cosmos Reason is a new open, customizable, 7-billion-parameter reasoning VLM for physical AI and robotics. Cosmos Reason lets robots and vision AI agents reason like humans, using prior knowledge, physics understanding and common sense to understand and act in the physical world.&lt;/p&gt;
&lt;p&gt;Cosmos Reason enables advanced capabilities across robotics and physical AI applications such as training data critiquing and captioning, robot decision-making and video analytics AI agents.&lt;/p&gt;
&lt;p&gt;It can help automate the curation and annotation of large, diverse training datasets, accelerating the development of high-accuracy AI models. It can also serve as a sophisticated reasoning engine for robot planning, parsing complex instructions into actionable steps for VLA models, even in new environments.&lt;/p&gt;
&lt;p&gt;It also powers video analytics AI agents built on the NVIDIA Blueprint for video search and summarization (VSS), enabled by the NVIDIA Metropolis platform, gleaning valuable insights from massive volumes of stored or live video data. These visually perceptive and interactive AI agents can help streamline operations in factories, warehouses, retail stores, airports, traffic intersections and more by spotting anomalies.&lt;/p&gt;
&lt;p&gt;NVIDIA’s robotics research team uses Cosmos Reason for data filtration and curation, and as the “System 2” reasoning VLM behind VLA models such as the next versions of NVIDIA Isaac GR00T NX.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Now Serving: NVIDIA Reasoning Models for AI Agents and Robots Everywhere&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Diverse enterprises and consulting leaders are adopting NVIDIA’s latest reasoning models. Leaders spanning cybersecurity to telecommunications are among those working with Nemotron to build enterprise AI agents.&lt;/p&gt;
&lt;p&gt;Zoom plans to harness Nemotron reasoning models with Zoom AI Companion to make decisions and manage multistep tasks to take action for users across Zoom Meetings, Zoom Chat and Zoom documents.&lt;/p&gt;
&lt;p&gt;CrowdStrike is testing Nemotron models to enable its Charlotte AI agents to write queries on the CrowdStrike Falcon platform.&lt;/p&gt;
&lt;p&gt;Amdocs is using NVIDIA Nemotron models in its amAIz Suite to drive AI agents to handle complex, multistep automation spanning care, sales, network and customer support.&lt;/p&gt;
&lt;p&gt;EY is adopting Nemotron Nano 2, given its high throughput, to support agentic AI in large organizations for tax, risk management and finance use cases.&lt;/p&gt;
&lt;p&gt;NetApp is currently testing Nemotron reasoning models so that AI agents can search and analyze business data&lt;/p&gt;
&lt;p&gt;DataRobot is working with Nemotron models for its Agent Workforce Platform for end-to-end agent lifecycle management.&lt;/p&gt;
&lt;p&gt;Tabnine is working with Nemotron models for suggesting and automating coding tasks on behalf of developers.&lt;/p&gt;
&lt;p&gt;Automation Anywhere, CrewAI and Dataiku are among the additional agentic AI software developers integrating Nemotron models into their platforms.&lt;/p&gt;
&lt;p&gt;Leading companies across transportation, safety and AI intelligence are using Cosmos Reason to advance autonomous driving, video analytics, and road and workplace safety.&lt;/p&gt;
&lt;p&gt;Uber is exploring Cosmos Reason to analyze autonomous vehicle behavior. In addition, Uber is post-training Cosmos Reason to summarize visual data and analyze scenarios like pedestrians walking across highways to perform quality analysis and inform autonomous driving behavior.&lt;/p&gt;
&lt;p&gt;Cosmos Reason can also serve as the brain of autonomous vehicles. It lets robots interpret environments and, given complex commands, break them down into tasks and execute them using common sense, even in unfamiliar environments.&lt;/p&gt;
&lt;p&gt;Centific is testing Cosmos Reason to enhance its AI-powered video intelligence platform. The VLM enables the platform to process complex video data into actionable insights, helping reduce false positives and improve decision-making efficiency.&lt;/p&gt;
&lt;p&gt;VAST is advancing real-time urban intelligence using NVIDIA Cosmos Reason with its AI operating system to process massive video streams at scale. With the VSS Blueprint, VAST can build agents that can identify incidents and trigger responses, turning video streams and metadata into actionable, proactive public safety tools.&lt;/p&gt;
&lt;p&gt;Ambient.ai is working with Cosmos Reason’s temporal, physics-aware reasoning, to enable automated detection of missing personal protection equipment and monitoring of hazardous conditions, helping enhance environmental health and safety across construction, manufacturing, logistics and other industrial settings.&lt;/p&gt;
&lt;p&gt;Magna is developing with Cosmos Reason as part of its City Delivery Platform — a fully autonomous, low-cost solution for instant delivery — to help vehicles adapt more quickly to new cities. The model adds world understanding to the vehicles’ long-term trajectory planning.&lt;/p&gt;
&lt;p&gt;These models are expected to be available as NVIDIA NIM microservices for secure, reliable deployment on any NVIDIA-accelerated infrastructure for maximum privacy and control. They are planned to be available soon through Amazon Bedrock and Amazon SageMaker AI for Nemotron models, as well as through Azure AI Foundry, Oracle Data Science Platform and Google Vertex AI.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Try &lt;/i&gt;&lt;i&gt;Cosmos Reason on build.nvidia.com&lt;/i&gt;&lt;i&gt; or download it from &lt;/i&gt;&lt;i&gt;Hugging Face&lt;/i&gt;&lt;i&gt; or &lt;/i&gt;&lt;i&gt;GitHub&lt;/i&gt;&lt;i&gt;.&amp;nbsp;&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Nemotron Nano 2 and Llama Nemotron Super 1.5 (NVFP4) will be available soon for download. Meanwhile, learn more about Nemotron models and download previous versions.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Download the &lt;/i&gt;&lt;i&gt;Llama Nemotron VLM Dataset v1&lt;/i&gt;&lt;i&gt; from Hugging Face.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Watch the NVIDIA Research special address at SIGGRAPH and learn more about how graphics and simulation innovations come together to drive industrial digitalization by joining NVIDIA at the conference, running through Thursday, Aug. 14.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;See &lt;/i&gt;&lt;i&gt;notice&lt;/i&gt;&lt;i&gt; regarding software product information.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;AI agents are poised to deliver as much as $450 billion from revenue gains and cost savings by 2028, according to Capgemini. Developers building these agents are turning to higher-performing reasoning models to improve AI agent platforms and physical AI systems.&lt;/p&gt;
&lt;p&gt;At SIGGRAPH, NVIDIA today announced an expansion of two model families with reasoning capabilities — NVIDIA Nemotron and NVIDIA Cosmos — that leaders across industries are using to drive productivity via teams of AI agents and humanoid robots.&lt;/p&gt;
&lt;p&gt;CrowdStrike, Uber, Magna, NetApp and Zoom are among some of the enterprises tapping into these model families.&lt;/p&gt;
&lt;p&gt;New NVIDIA Nemotron Nano 2 and Llama Nemotron Super 1.5 models offer the highest accuracy in their size categories for scientific reasoning, math, coding, tool-calling, instruction-following and chat. These new models give AI agents the power to think more deeply and work more efficiently — exploring broader options, speeding up research and delivering smarter results within set time limits.&lt;/p&gt;
&lt;p&gt;Think of the model as the brain of an AI agent — it provides the core intelligence. But to make that brain useful for a business, it must be embedded into an agent that understands specific workflows, in addition to industry and business jargon, and operates safely. NVIDIA helps enterprises bridge that gap with leading libraries and AI blueprints for onboarding, customizing and governing AI agents at scale.&lt;/p&gt;
&lt;p&gt;Cosmos Reason is a new reasoning vision language model (VLM) for physical AI applications that excels in understanding how the real world works, using structured reasoning to understand concepts like physics, object permanence and space-time alignment.&lt;/p&gt;
&lt;p&gt;Cosmos Reason is purpose-built to serve as the reasoning backbone to a robot vision language action (VLA) model, or critique and caption training data for robotics and autonomous vehicles, and equip runtime visual AI agents with spatial-temporal understanding and reasoning of physical operations, like in factories or cities.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Nemotron: Highest Accuracy and Efficiency for Agentic Enterprise AI&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;As enterprises develop AI agents to tackle complex, multistep tasks, models that can provide strong reasoning accuracy with efficient token generation enable intelligent, autonomous decision-making at scale.&lt;/p&gt;
&lt;p&gt;NVIDIA Nemotron is a family of advanced open reasoning models that use leading models, NVIDIA-curated open datasets and advanced AI techniques to provide an accurate and efficient starting point for AI agents.&lt;/p&gt;
&lt;p&gt;The latest Nemotron models deliver leading efficiency in three ways: a new hybrid model architecture, compact quantized models and a configurable thinking budget that provides developers with control over token generation, resulting in 60% lower reasoning costs. This combination lets the models reason more deeply and respond faster, without needing more time or computing power. This means better results at a lower cost.&lt;/p&gt;
&lt;p&gt;Nemotron Nano 2 provides as much as 6x higher token generation compared with other leading models of its size.&lt;/p&gt;
&lt;p&gt;Llama Nemotron Super 1.5 achieves leading performance and the highest reasoning accuracy in its class, empowering AI agents to reason better, make smarter decisions and handle complex tasks independently. It’s now available in NVFP4, or 4-bit floating point, which delivers as much as 6x higher throughput on NVIDIA B200 GPUs compared with NVIDIA H100 GPUs.&lt;/p&gt;

&lt;p&gt;&lt;img alt="alt" class="aligncenter size-medium wp-image-83674" height="655" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/nemotron-chart-960x655.png" width="960" /&gt;&lt;/p&gt;
&lt;p&gt;The chart above shows the Nemotron model delivers top reasoning accuracy in the same timeframe and on the same compute budget, delivering the highest accuracy per dollar.&lt;/p&gt;
&lt;p&gt;Along with the two new Nemotron models, NVIDIA is also announcing its first open VLM training dataset — Llama Nemotron VLM dataset v1 — with 3 million samples of optical character recognition, visual QA and captioning data that power the previously released Llama 3.1 Nemotron Nano VL 8B model.&lt;/p&gt;
&lt;p&gt;In addition to the accuracy of the reasoning models, agents also rely on retrieval-augmented generation to fetch the latest and most relevant information from connected data across disparate sources to make informed decisions. The recently released Llama 3.2 NeMo Retriever embedding model tops three visual document retrieval leaderboards — ViDoRe V1, ViDoRe V2 and MTEB VisualDocumentRetrieval — for boosting agentic system accuracy.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-medium wp-image-83671" height="496" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/nemotron-models-960x496.png" width="960" /&gt;&lt;/p&gt;
&lt;p&gt;Using these reasoning and information retrieval models, a deep research agent built using the AI-Q NVIDIA Blueprint is currently No. 1 for open and portable agents on DeepResearch Bench.&lt;/p&gt;
&lt;p&gt;NVIDIA NeMo and NVIDIA NIM microservices support the entire AI agent lifecycle — from development and deployment to monitoring and optimization of the agentic systems.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Cosmos Reason: A Breakthrough in Physical AI&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;&lt;img alt="alt" class="alignnone size-full wp-image-83531" height="506" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/Toaster-Cosmos-Reasoning.gif" width="900" /&gt;&lt;/p&gt;
&lt;p&gt;VLMs marked a breakthrough for computer vision and robotics, empowering machines to identify objects and patterns. However, nonreasoning VLMs lack the ability to understand and interact with the real world — meaning they can’t handle ambiguity or novel experiences, nor solve complex multistep tasks.&lt;/p&gt;
&lt;p&gt;NVIDIA Cosmos Reason is a new open, customizable, 7-billion-parameter reasoning VLM for physical AI and robotics. Cosmos Reason lets robots and vision AI agents reason like humans, using prior knowledge, physics understanding and common sense to understand and act in the physical world.&lt;/p&gt;
&lt;p&gt;Cosmos Reason enables advanced capabilities across robotics and physical AI applications such as training data critiquing and captioning, robot decision-making and video analytics AI agents.&lt;/p&gt;
&lt;p&gt;It can help automate the curation and annotation of large, diverse training datasets, accelerating the development of high-accuracy AI models. It can also serve as a sophisticated reasoning engine for robot planning, parsing complex instructions into actionable steps for VLA models, even in new environments.&lt;/p&gt;
&lt;p&gt;It also powers video analytics AI agents built on the NVIDIA Blueprint for video search and summarization (VSS), enabled by the NVIDIA Metropolis platform, gleaning valuable insights from massive volumes of stored or live video data. These visually perceptive and interactive AI agents can help streamline operations in factories, warehouses, retail stores, airports, traffic intersections and more by spotting anomalies.&lt;/p&gt;
&lt;p&gt;NVIDIA’s robotics research team uses Cosmos Reason for data filtration and curation, and as the “System 2” reasoning VLM behind VLA models such as the next versions of NVIDIA Isaac GR00T NX.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Now Serving: NVIDIA Reasoning Models for AI Agents and Robots Everywhere&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Diverse enterprises and consulting leaders are adopting NVIDIA’s latest reasoning models. Leaders spanning cybersecurity to telecommunications are among those working with Nemotron to build enterprise AI agents.&lt;/p&gt;
&lt;p&gt;Zoom plans to harness Nemotron reasoning models with Zoom AI Companion to make decisions and manage multistep tasks to take action for users across Zoom Meetings, Zoom Chat and Zoom documents.&lt;/p&gt;
&lt;p&gt;CrowdStrike is testing Nemotron models to enable its Charlotte AI agents to write queries on the CrowdStrike Falcon platform.&lt;/p&gt;
&lt;p&gt;Amdocs is using NVIDIA Nemotron models in its amAIz Suite to drive AI agents to handle complex, multistep automation spanning care, sales, network and customer support.&lt;/p&gt;
&lt;p&gt;EY is adopting Nemotron Nano 2, given its high throughput, to support agentic AI in large organizations for tax, risk management and finance use cases.&lt;/p&gt;
&lt;p&gt;NetApp is currently testing Nemotron reasoning models so that AI agents can search and analyze business data&lt;/p&gt;
&lt;p&gt;DataRobot is working with Nemotron models for its Agent Workforce Platform for end-to-end agent lifecycle management.&lt;/p&gt;
&lt;p&gt;Tabnine is working with Nemotron models for suggesting and automating coding tasks on behalf of developers.&lt;/p&gt;
&lt;p&gt;Automation Anywhere, CrewAI and Dataiku are among the additional agentic AI software developers integrating Nemotron models into their platforms.&lt;/p&gt;
&lt;p&gt;Leading companies across transportation, safety and AI intelligence are using Cosmos Reason to advance autonomous driving, video analytics, and road and workplace safety.&lt;/p&gt;
&lt;p&gt;Uber is exploring Cosmos Reason to analyze autonomous vehicle behavior. In addition, Uber is post-training Cosmos Reason to summarize visual data and analyze scenarios like pedestrians walking across highways to perform quality analysis and inform autonomous driving behavior.&lt;/p&gt;
&lt;p&gt;Cosmos Reason can also serve as the brain of autonomous vehicles. It lets robots interpret environments and, given complex commands, break them down into tasks and execute them using common sense, even in unfamiliar environments.&lt;/p&gt;
&lt;p&gt;Centific is testing Cosmos Reason to enhance its AI-powered video intelligence platform. The VLM enables the platform to process complex video data into actionable insights, helping reduce false positives and improve decision-making efficiency.&lt;/p&gt;
&lt;p&gt;VAST is advancing real-time urban intelligence using NVIDIA Cosmos Reason with its AI operating system to process massive video streams at scale. With the VSS Blueprint, VAST can build agents that can identify incidents and trigger responses, turning video streams and metadata into actionable, proactive public safety tools.&lt;/p&gt;
&lt;p&gt;Ambient.ai is working with Cosmos Reason’s temporal, physics-aware reasoning, to enable automated detection of missing personal protection equipment and monitoring of hazardous conditions, helping enhance environmental health and safety across construction, manufacturing, logistics and other industrial settings.&lt;/p&gt;
&lt;p&gt;Magna is developing with Cosmos Reason as part of its City Delivery Platform — a fully autonomous, low-cost solution for instant delivery — to help vehicles adapt more quickly to new cities. The model adds world understanding to the vehicles’ long-term trajectory planning.&lt;/p&gt;
&lt;p&gt;These models are expected to be available as NVIDIA NIM microservices for secure, reliable deployment on any NVIDIA-accelerated infrastructure for maximum privacy and control. They are planned to be available soon through Amazon Bedrock and Amazon SageMaker AI for Nemotron models, as well as through Azure AI Foundry, Oracle Data Science Platform and Google Vertex AI.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Try &lt;/i&gt;&lt;i&gt;Cosmos Reason on build.nvidia.com&lt;/i&gt;&lt;i&gt; or download it from &lt;/i&gt;&lt;i&gt;Hugging Face&lt;/i&gt;&lt;i&gt; or &lt;/i&gt;&lt;i&gt;GitHub&lt;/i&gt;&lt;i&gt;.&amp;nbsp;&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Nemotron Nano 2 and Llama Nemotron Super 1.5 (NVFP4) will be available soon for download. Meanwhile, learn more about Nemotron models and download previous versions.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Download the &lt;/i&gt;&lt;i&gt;Llama Nemotron VLM Dataset v1&lt;/i&gt;&lt;i&gt; from Hugging Face.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Watch the NVIDIA Research special address at SIGGRAPH and learn more about how graphics and simulation innovations come together to drive industrial digitalization by joining NVIDIA at the conference, running through Thursday, Aug. 14.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;See &lt;/i&gt;&lt;i&gt;notice&lt;/i&gt;&lt;i&gt; regarding software product information.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/nemotron-cosmos-reasoning-enterprise-physical-ai/</guid><pubDate>Mon, 11 Aug 2025 15:00:13 +0000</pubDate></item><item><title>NVIDIA Research Shapes Physical AI (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/physical-ai-research-siggraph-2025/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/NV_SIGGRAPH-KV-video_Still001.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Physical AI — the engine behind modern robotics, self-driving cars and smart spaces — relies on a mix of neural graphics, synthetic data generation, physics-based simulation, reinforcement learning and AI reasoning. It’s a combination well-suited to the collective expertise of NVIDIA Research, a global team that for nearly 20 years has advanced the now-converging fields of AI and graphics.&lt;/p&gt;&lt;p&gt;That’s why at SIGGRAPH, the premier computer graphics conference taking place in Vancouver through Thursday, Aug. 14, NVIDIA Research leaders will deliver a special address highlighting the graphics and simulation innovations enabling physical and spatial AI.&lt;/p&gt;
&lt;p&gt;“AI is advancing our simulation capabilities, and our simulation capabilities are advancing AI systems,” said Sanja Fidler, vice president of AI research at NVIDIA. “There’s an authentic and powerful coupling between the two fields, and it’s a combination that few have.”&lt;/p&gt;
&lt;p&gt;At SIGGRAPH, NVIDIA is unveiling new software libraries for physical AI — including NVIDIA Omniverse NuRec 3D Gaussian splatting libraries for large-scale world reconstruction, updates to the NVIDIA Metropolis platform for vision AI as well as NVIDIA&amp;nbsp;Cosmos and NVIDIA Nemotron reasoning models. Cosmos Reason is a new reasoning vision language model for physical AI that enables robots and vision AI agents to reason like humans using prior knowledge, physics understanding and common sense.&lt;/p&gt;
&lt;p&gt;Many of these innovations are rooted in breakthroughs by the company’s global research team, which is presenting over a dozen papers at the show on advancements in neural rendering, real-time path tracing, synthetic data generation and reinforcement learning — capabilities that will feed the next generation of physical AI tools.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;How Physical AI Unites Graphics, AI and Robotics&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Physical AI development starts with the construction of high-fidelity, physically accurate 3D environments. Without these lifelike virtual environments, developers can’t train advanced physical AI systems such as humanoid robots in simulation, because the skills the robots would learn in virtual training wouldn’t translate well enough to the real world.&lt;/p&gt;
&lt;p&gt;Picture an agricultural robot using the exact amount of pressure to pick peaches off trees without bruising them, or a manufacturing robot assembling microscopic electronic components on a machine where every millimeter matters.&lt;/p&gt;
&lt;p&gt;“Physical AI needs a virtual environment that feels real, a parallel universe where the robots can safely learn through trial and error,” said Ming-Yu Liu, vice president of research at NVIDIA. “To build this virtual world, we need real-time rendering, computer vision, physical motion simulation, 2D and 3D generative AI, as well as AI reasoning. These are the things that NVIDIA Research has spent nearly two decades to be good at.”&lt;/p&gt;
&lt;p&gt;NVIDIA’s legacy of breakthrough research in ray tracing and real-time computer graphics, dating back to the research organization’s inception in 2006, plays a critical role in enabling the realism that physical AI simulations demand. Much of that rendering work, too, is powered by AI models — a field known as neural rendering.&lt;/p&gt;
&lt;p&gt;“Our core rendering research fuels the creation of true-to-reality virtual words used to train advanced physical AI systems, while AI is in turn helping us create those 3D worlds from images,” said Aaron Lefohn, vice president of graphics research and head of the ​​Real-Time Graphics Research group at NVIDIA. “We’re now at a point where we can take pictures and videos — an accessible form of media that anyone can capture — and rapidly reconstruct them into virtual 3D environments.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/NV_SIGGRAPH-KV-video_Still001.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Physical AI — the engine behind modern robotics, self-driving cars and smart spaces — relies on a mix of neural graphics, synthetic data generation, physics-based simulation, reinforcement learning and AI reasoning. It’s a combination well-suited to the collective expertise of NVIDIA Research, a global team that for nearly 20 years has advanced the now-converging fields of AI and graphics.&lt;/p&gt;&lt;p&gt;That’s why at SIGGRAPH, the premier computer graphics conference taking place in Vancouver through Thursday, Aug. 14, NVIDIA Research leaders will deliver a special address highlighting the graphics and simulation innovations enabling physical and spatial AI.&lt;/p&gt;
&lt;p&gt;“AI is advancing our simulation capabilities, and our simulation capabilities are advancing AI systems,” said Sanja Fidler, vice president of AI research at NVIDIA. “There’s an authentic and powerful coupling between the two fields, and it’s a combination that few have.”&lt;/p&gt;
&lt;p&gt;At SIGGRAPH, NVIDIA is unveiling new software libraries for physical AI — including NVIDIA Omniverse NuRec 3D Gaussian splatting libraries for large-scale world reconstruction, updates to the NVIDIA Metropolis platform for vision AI as well as NVIDIA&amp;nbsp;Cosmos and NVIDIA Nemotron reasoning models. Cosmos Reason is a new reasoning vision language model for physical AI that enables robots and vision AI agents to reason like humans using prior knowledge, physics understanding and common sense.&lt;/p&gt;
&lt;p&gt;Many of these innovations are rooted in breakthroughs by the company’s global research team, which is presenting over a dozen papers at the show on advancements in neural rendering, real-time path tracing, synthetic data generation and reinforcement learning — capabilities that will feed the next generation of physical AI tools.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;How Physical AI Unites Graphics, AI and Robotics&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Physical AI development starts with the construction of high-fidelity, physically accurate 3D environments. Without these lifelike virtual environments, developers can’t train advanced physical AI systems such as humanoid robots in simulation, because the skills the robots would learn in virtual training wouldn’t translate well enough to the real world.&lt;/p&gt;
&lt;p&gt;Picture an agricultural robot using the exact amount of pressure to pick peaches off trees without bruising them, or a manufacturing robot assembling microscopic electronic components on a machine where every millimeter matters.&lt;/p&gt;
&lt;p&gt;“Physical AI needs a virtual environment that feels real, a parallel universe where the robots can safely learn through trial and error,” said Ming-Yu Liu, vice president of research at NVIDIA. “To build this virtual world, we need real-time rendering, computer vision, physical motion simulation, 2D and 3D generative AI, as well as AI reasoning. These are the things that NVIDIA Research has spent nearly two decades to be good at.”&lt;/p&gt;
&lt;p&gt;NVIDIA’s legacy of breakthrough research in ray tracing and real-time computer graphics, dating back to the research organization’s inception in 2006, plays a critical role in enabling the realism that physical AI simulations demand. Much of that rendering work, too, is powered by AI models — a field known as neural rendering.&lt;/p&gt;
&lt;p&gt;“Our core rendering research fuels the creation of true-to-reality virtual words used to train advanced physical AI systems, while AI is in turn helping us create those 3D worlds from images,” said Aaron Lefohn, vice president of graphics research and head of the ​​Real-Time Graphics Research group at NVIDIA. “We’re now at a point where we can take pictures and videos — an accessible form of media that anyone can capture — and rapidly reconstruct them into virtual 3D environments.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/physical-ai-research-siggraph-2025/</guid><pubDate>Mon, 11 Aug 2025 15:00:38 +0000</pubDate></item><item><title>Making Safer Spaces: NVIDIA and Partners Bring Physical AI to Cities and Industrial Infrastructure (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/physical-ai-partners-metropolis-updates-siggraph/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Physical AI is becoming the foundation of smart cities, facilities and industrial processes across the globe.&lt;/p&gt;
&lt;p&gt;NVIDIA is working with companies including Accenture, Avathon, Belden, DeepHow, Milestone Systems and Telit Cinterion to enhance operations across the globe with physical AI-based perception and reasoning.&lt;/p&gt;
&lt;p&gt;The continuous loop of simulating, training and deploying physical AI offers sophisticated industrial automation capabilities, making cities and infrastructure safer, smarter and more efficient.&lt;/p&gt;
&lt;p&gt;For example, physical AI applications can automate potentially dangerous tasks for workers, such as working with heavy machinery. Physical AI can also improve transportation services and public safety, detect defective products in factories and more.&lt;/p&gt;
&lt;p&gt;The need for this is greater than ever. The numbers tell the story:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Statistics in infographic: $7 Trillion lost annually due to poor quality and defects in manufacturing. ~2.8 Million workers die annually from occupational accidents and work-related diseases. 514,000 industrial robots installed worldwide in 2024. $300 billion spent per year on public order and safety in the EU. By 2030, projected global labor shortage of 50 million." class="aligncenter wp-image-83564 size-medium" height="384" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/metropolis-siggraph-2025-infographic-960x384.jpg" width="960" /&gt;&lt;/p&gt;
&lt;p&gt;Infrastructure that can perceive, reason and act relies on video sensors and the latest vision AI capabilities. Using the NVIDIA Metropolis platform — which simplifies the development, deployment and scaling of video analytics AI agents and services from the edge to the cloud — developers can build visual perception into their facilities faster to enhance productivity and improve safety across environments.&lt;/p&gt;
&lt;p&gt;Below are five leading companies advancing physical AI — and five key NVIDIA Metropolis updates, announced today at the SIGGRAPH computer graphics conference, making such advancements possible.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Five Companies Advancing Physical AI&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Global professional services company &lt;b&gt;Accenture&lt;/b&gt; is collaborating with Belden, a leading provider of complete connection solutions, to enhance worker safety by creating smart virtual fences that factories can place around large robots to prevent accidents with human operators.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83569"&gt;&lt;img alt="Smart fence image." class="size-medium wp-image-83569" height="639" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/accenture-960x639.png" width="960" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83569"&gt;Image courtesy of Accenture and Belden.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;The smart virtual fence is a physical AI safety system that uses an OpenUSD-based digital twin and physics-grounded simulation to model complex industrial environments. Using computer vision-based mapping and 3D spatial intelligence, the system is adaptive to increased variability in the dynamic human-robot interactions that occur in a modern shopfloor environment.&lt;/p&gt;
&lt;p&gt;Accenture taps into the NVIDIA Omniverse platform and Metropolis to build and simulate these smart fences. With Omniverse, Accenture created a digital twin of a robot arm and workers moving in a space. And with Metropolis, the company trained its AI models and deployed them at the edge with video ingestion and the NVIDIA DeepStream software development kit (SDK)’s real-time inference capabilities.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Avathon&lt;/b&gt;, an industrial automation platform provider, uses the NVIDIA Blueprint for video search and summarization (VSS), part of NVIDIA Metropolis, to provide manufacturing and energy facilities with real-time insights that improve operational efficiency and worker safety.&lt;/p&gt;
&lt;p&gt;Reliance British Petroleum Mobility Limited, a leader in India’s fuel and mobility sector, used the Avathon video intelligence product during the construction of its gas stations to achieve higher standards of safety compliance, a reduction in safety noncompliance incidents and higher productivity by saving thousands of work hours.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;DeepHow&lt;/b&gt; has developed a “Smart Know-How Companion” for employees in manufacturing and other industries. The companion uses the Metropolis VSS blueprint to transform key workflows into bite-sized, multilingual videos and digital instructions, improving onboarding, safety and floor operator efficiency.&lt;/p&gt;
&lt;p&gt;Facing upskilling needs and retiring skilled workers, beverage company Anheuser-Busch InBev turned to the DeepHow platform to convert standard operating procedures into easy-to-understand visual guides. This has slashed onboarding time by 80%, boosted training consistency and improved long-term knowledge retention for employees.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Milestone Systems&lt;/b&gt;, which offers one of the world’s largest platforms for managing IP video sensor data in complex industrial and city deployments, is creating the world’s largest real-world computer vision data library through its platform, Project Hafnia. Among its capabilities, the platform provides physical AI developers with access to customized vision language models (VLMs).&lt;/p&gt;
&lt;p&gt;Tapping NVIDIA NeMo Curator, Milestone Systems built a VLM fine-tuned for intelligent transportation systems for use within the VSS blueprint to help develop AI agents that better manage city roadways. Milestone Systems is also looking to use the new open, customizable NVIDIA Cosmos Reason VLM for physical AI.&lt;/p&gt;
&lt;p&gt;Internet-of-things company &lt;b&gt;Telit Cinterion&lt;/b&gt; has integrated NVIDIA TAO Toolkit 6 into its AI-powered visual inspection platform, which uses vision foundation models like FoundationPose, alongside other NVIDIA models, to support multimodal AI and deliver high-performance inferencing. TAO brings low-code AI capabilities to the Telit platform, enabling manufacturers to quickly develop and deploy accurate, custom AI models for defect detection and quality control.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Five NVIDIA Metropolis Updates for Physical AI&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Key updates to NVIDIA Metropolis are enhancing developers’ capabilities to build physical AI applications more quickly and easily:&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Cosmos Reason VLM&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;The latest version of Cosmos Reason — NVIDIA’s advanced open, customizable, 7-billion-parameter reasoning VLM for physical AI — enables contextual video understanding, temporal event reasoning for Metropolis use cases. Its compact size makes it easy to deploy from edge to cloud and ideal for automating traffic monitoring, public safety, visual inspection and intelligent decision-making.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;VSS Blueprint 2.4&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;VSS 2.4 makes it easy to quickly augment existing vision AI applications with Cosmos Reason and deliver powerful new features to smart infrastructure. An expanded set of application programming interfaces in the blueprint offers users direct more flexibility in choosing specific VSS components and capabilities to augment computer vision pipelines with generative AI.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;New Vision Foundation Models&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;The NVIDIA TAO Toolkit includes a new suite of vision foundation models, along with advanced fine-tuning methods, self-supervised learning and knowledge distillation capabilities, to optimize deployment of physical AI solutions across edge and cloud environments. The NVIDIA DeepStream SDK includes a new Inference Builder to enable seamless deployment of TAO 6 models.&lt;/p&gt;
&lt;p&gt;Companies around the world — including Advex AI, Instrumental AI and Spingence — are experimenting with these new models and NVIDIA TAO to build intelligent solutions that optimize industrial operations and drive efficiency.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;NVIDIA Isaac Sim Extensions&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;New extensions in the NVIDIA Isaac Sim reference application help solve common challenges in vision AI development — such as limited labeled data and rare edge-case scenarios. These tools simulate human and robot interactions, generate rich object-detection datasets, and create incident-based scenes and image-caption pairs to train VLMs, accelerating development and improving AI performance in real-world conditions.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Expanded Hardware Support&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;All of these Metropolis components can now run on NVIDIA RTX PRO 6000 Blackwell GPUs, the NVIDIA DGX Spark desktop supercomputer and the NVIDIA Jetson Thor platform for physical AI and humanoid robotics — so users can develop and deploy from the edge to the cloud.&lt;/p&gt;
&lt;p&gt;Cosmos Reason 1 and NVIDIA TAO 6.0 are now available for download. Sign up to be alerted when VSS 2.4, the Cosmos Reason VLM fine-tuning update and NVIDIA DeepStream 8.0 become available.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Watch the &lt;/i&gt;&lt;i&gt;NVIDIA Research special address at SIGGRAPH&lt;/i&gt;&lt;i&gt; and learn more about how graphics and simulation innovations come together to drive industrial digitalization by joining NVIDIA at the conference, running through Thursday, Aug. 14.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;See &lt;/i&gt;&lt;i&gt;notice&lt;/i&gt;&lt;i&gt; regarding software product information.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Physical AI is becoming the foundation of smart cities, facilities and industrial processes across the globe.&lt;/p&gt;
&lt;p&gt;NVIDIA is working with companies including Accenture, Avathon, Belden, DeepHow, Milestone Systems and Telit Cinterion to enhance operations across the globe with physical AI-based perception and reasoning.&lt;/p&gt;
&lt;p&gt;The continuous loop of simulating, training and deploying physical AI offers sophisticated industrial automation capabilities, making cities and infrastructure safer, smarter and more efficient.&lt;/p&gt;
&lt;p&gt;For example, physical AI applications can automate potentially dangerous tasks for workers, such as working with heavy machinery. Physical AI can also improve transportation services and public safety, detect defective products in factories and more.&lt;/p&gt;
&lt;p&gt;The need for this is greater than ever. The numbers tell the story:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Statistics in infographic: $7 Trillion lost annually due to poor quality and defects in manufacturing. ~2.8 Million workers die annually from occupational accidents and work-related diseases. 514,000 industrial robots installed worldwide in 2024. $300 billion spent per year on public order and safety in the EU. By 2030, projected global labor shortage of 50 million." class="aligncenter wp-image-83564 size-medium" height="384" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/metropolis-siggraph-2025-infographic-960x384.jpg" width="960" /&gt;&lt;/p&gt;
&lt;p&gt;Infrastructure that can perceive, reason and act relies on video sensors and the latest vision AI capabilities. Using the NVIDIA Metropolis platform — which simplifies the development, deployment and scaling of video analytics AI agents and services from the edge to the cloud — developers can build visual perception into their facilities faster to enhance productivity and improve safety across environments.&lt;/p&gt;
&lt;p&gt;Below are five leading companies advancing physical AI — and five key NVIDIA Metropolis updates, announced today at the SIGGRAPH computer graphics conference, making such advancements possible.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Five Companies Advancing Physical AI&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Global professional services company &lt;b&gt;Accenture&lt;/b&gt; is collaborating with Belden, a leading provider of complete connection solutions, to enhance worker safety by creating smart virtual fences that factories can place around large robots to prevent accidents with human operators.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83569"&gt;&lt;img alt="Smart fence image." class="size-medium wp-image-83569" height="639" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/accenture-960x639.png" width="960" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83569"&gt;Image courtesy of Accenture and Belden.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;The smart virtual fence is a physical AI safety system that uses an OpenUSD-based digital twin and physics-grounded simulation to model complex industrial environments. Using computer vision-based mapping and 3D spatial intelligence, the system is adaptive to increased variability in the dynamic human-robot interactions that occur in a modern shopfloor environment.&lt;/p&gt;
&lt;p&gt;Accenture taps into the NVIDIA Omniverse platform and Metropolis to build and simulate these smart fences. With Omniverse, Accenture created a digital twin of a robot arm and workers moving in a space. And with Metropolis, the company trained its AI models and deployed them at the edge with video ingestion and the NVIDIA DeepStream software development kit (SDK)’s real-time inference capabilities.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Avathon&lt;/b&gt;, an industrial automation platform provider, uses the NVIDIA Blueprint for video search and summarization (VSS), part of NVIDIA Metropolis, to provide manufacturing and energy facilities with real-time insights that improve operational efficiency and worker safety.&lt;/p&gt;
&lt;p&gt;Reliance British Petroleum Mobility Limited, a leader in India’s fuel and mobility sector, used the Avathon video intelligence product during the construction of its gas stations to achieve higher standards of safety compliance, a reduction in safety noncompliance incidents and higher productivity by saving thousands of work hours.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;DeepHow&lt;/b&gt; has developed a “Smart Know-How Companion” for employees in manufacturing and other industries. The companion uses the Metropolis VSS blueprint to transform key workflows into bite-sized, multilingual videos and digital instructions, improving onboarding, safety and floor operator efficiency.&lt;/p&gt;
&lt;p&gt;Facing upskilling needs and retiring skilled workers, beverage company Anheuser-Busch InBev turned to the DeepHow platform to convert standard operating procedures into easy-to-understand visual guides. This has slashed onboarding time by 80%, boosted training consistency and improved long-term knowledge retention for employees.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Milestone Systems&lt;/b&gt;, which offers one of the world’s largest platforms for managing IP video sensor data in complex industrial and city deployments, is creating the world’s largest real-world computer vision data library through its platform, Project Hafnia. Among its capabilities, the platform provides physical AI developers with access to customized vision language models (VLMs).&lt;/p&gt;
&lt;p&gt;Tapping NVIDIA NeMo Curator, Milestone Systems built a VLM fine-tuned for intelligent transportation systems for use within the VSS blueprint to help develop AI agents that better manage city roadways. Milestone Systems is also looking to use the new open, customizable NVIDIA Cosmos Reason VLM for physical AI.&lt;/p&gt;
&lt;p&gt;Internet-of-things company &lt;b&gt;Telit Cinterion&lt;/b&gt; has integrated NVIDIA TAO Toolkit 6 into its AI-powered visual inspection platform, which uses vision foundation models like FoundationPose, alongside other NVIDIA models, to support multimodal AI and deliver high-performance inferencing. TAO brings low-code AI capabilities to the Telit platform, enabling manufacturers to quickly develop and deploy accurate, custom AI models for defect detection and quality control.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Five NVIDIA Metropolis Updates for Physical AI&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Key updates to NVIDIA Metropolis are enhancing developers’ capabilities to build physical AI applications more quickly and easily:&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Cosmos Reason VLM&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;The latest version of Cosmos Reason — NVIDIA’s advanced open, customizable, 7-billion-parameter reasoning VLM for physical AI — enables contextual video understanding, temporal event reasoning for Metropolis use cases. Its compact size makes it easy to deploy from edge to cloud and ideal for automating traffic monitoring, public safety, visual inspection and intelligent decision-making.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;VSS Blueprint 2.4&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;VSS 2.4 makes it easy to quickly augment existing vision AI applications with Cosmos Reason and deliver powerful new features to smart infrastructure. An expanded set of application programming interfaces in the blueprint offers users direct more flexibility in choosing specific VSS components and capabilities to augment computer vision pipelines with generative AI.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;New Vision Foundation Models&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;The NVIDIA TAO Toolkit includes a new suite of vision foundation models, along with advanced fine-tuning methods, self-supervised learning and knowledge distillation capabilities, to optimize deployment of physical AI solutions across edge and cloud environments. The NVIDIA DeepStream SDK includes a new Inference Builder to enable seamless deployment of TAO 6 models.&lt;/p&gt;
&lt;p&gt;Companies around the world — including Advex AI, Instrumental AI and Spingence — are experimenting with these new models and NVIDIA TAO to build intelligent solutions that optimize industrial operations and drive efficiency.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;NVIDIA Isaac Sim Extensions&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;New extensions in the NVIDIA Isaac Sim reference application help solve common challenges in vision AI development — such as limited labeled data and rare edge-case scenarios. These tools simulate human and robot interactions, generate rich object-detection datasets, and create incident-based scenes and image-caption pairs to train VLMs, accelerating development and improving AI performance in real-world conditions.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Expanded Hardware Support&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;All of these Metropolis components can now run on NVIDIA RTX PRO 6000 Blackwell GPUs, the NVIDIA DGX Spark desktop supercomputer and the NVIDIA Jetson Thor platform for physical AI and humanoid robotics — so users can develop and deploy from the edge to the cloud.&lt;/p&gt;
&lt;p&gt;Cosmos Reason 1 and NVIDIA TAO 6.0 are now available for download. Sign up to be alerted when VSS 2.4, the Cosmos Reason VLM fine-tuning update and NVIDIA DeepStream 8.0 become available.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Watch the &lt;/i&gt;&lt;i&gt;NVIDIA Research special address at SIGGRAPH&lt;/i&gt;&lt;i&gt; and learn more about how graphics and simulation innovations come together to drive industrial digitalization by joining NVIDIA at the conference, running through Thursday, Aug. 14.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;See &lt;/i&gt;&lt;i&gt;notice&lt;/i&gt;&lt;i&gt; regarding software product information.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/physical-ai-partners-metropolis-updates-siggraph/</guid><pubDate>Mon, 11 Aug 2025 15:00:44 +0000</pubDate></item><item><title>Meet the early-adopter judges using AI (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/08/11/1121460/meet-the-early-adopter-judges-using-ai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/250805_AIjudge_hero.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;The propensity for AI systems to make mistakes and for humans to miss those mistakes has been on full display in the US legal system as of late. The follies began when lawyers—including some at prestigious firms—submitted documents citing cases that didn’t exist. Similar mistakes soon spread to other roles in the courts. In December, a Stanford professor submitted sworn testimony containing hallucinations and errors in a case about deepfakes, despite being an expert on AI and misinformation himself.&lt;/p&gt;  &lt;p&gt;The buck stopped with judges, who—whether they or opposing counsel caught the mistakes—issued reprimands and fines, and likely left attorneys embarrassed enough to think twice before trusting AI again.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;But now judges are experimenting with generative AI too. Some are confident that with the right precautions, the technology can expedite legal research, summarize cases, draft routine orders, and overall help speed up the court system, which is badly backlogged in many parts of the US. This summer, though, we’ve already seen AI-generated mistakes go undetected and cited by judges. A federal judge in New Jersey had to reissue an order riddled with errors that may have come from AI, and a judge in Mississippi refused to explain why his order too contained mistakes that seemed like AI hallucinations.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The results of these early-adopter experiments make two things clear. One, the category of routine tasks—for which AI can assist without requiring human judgment—is slippery to define. Two, while lawyers face sharp scrutiny when their use of AI leads to mistakes, judges may not face the same accountability, and walking back their mistakes before they do damage is much harder.&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Drawing boundaries&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Xavier Rodriguez, a federal judge for the Western District of Texas, has good reason to be skeptical of AI. He started learning about artificial intelligence back in 2018, four years before the release of ChatGPT (thanks in part to the influence of his twin brother, who works in tech). But he’s also seen AI-generated mistakes in his own court.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In a recent dispute about who was to receive an insurance payout, both the plaintiff and the defendant represented themselves, without lawyers (this is not uncommon—nearly a quarter of civil cases in federal court involve at least one unrepresented party). The two sides wrote their own filings and made their own arguments.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;“Both sides used AI tools,” Rodriguez says, and both submitted filings that referenced made-up cases. He had authority to reprimand them, but given that they were not lawyers, he opted not to.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“I think there’s been an overreaction by a lot of judges on these sanctions. The running joke I tell when I’m on the speaking circuit is that lawyers have been hallucinating well before AI,” he says. Missing a mistake from an AI model is not wholly different, to Rodriguez, from failing to catch the error of a first-year lawyer. “I’m not as deeply offended as everybody else,” he says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In his court, Rodriguez has been using generative AI tools (he wouldn’t publicly name which ones, to avoid the appearance of an endorsement) to summarize cases. He’ll ask AI to identify key players involved and then have it generate a timeline of key events. Ahead of specific hearings, Rodriguez will also ask it to generate questions for attorneys based on the materials they submit.&lt;/p&gt;  &lt;p&gt;These tasks, to him, don’t lean on human judgment. They also offer lots of opportunities for him to intervene and uncover any mistakes before they’re brought to the court. “It’s not any final decision being made, and so it’s relatively risk free,” he says. Using AI to predict whether someone should be eligible for bail, on the other hand, goes too far in the direction of judgment and discretion, in his view.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Erin Solovey, a professor and researcher on human-AI interaction at Worcester Polytechnic Institute in Massachusetts, recently studied how judges in the UK think about this distinction between rote, machine-friendly work that feels safe to delegate to AI and tasks that lean more heavily on human expertise.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“The line between what is appropriate for a human judge to do versus what is appropriate for AI tools to do changes from judge to judge and from one scenario to the next,” she says.&lt;/p&gt;  &lt;p&gt;Even so, according to Solovey, some of these tasks simply don’t match what AI is good at. Asking AI to summarize a large document, for example, might produce drastically different results depending on whether the model has been trained to summarize for a general audience or a legal one. AI also struggles with logic-based tasks like ordering the events of a case. “A very plausible-sounding timeline may be factually incorrect,” Solovey says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Rodriguez and a number of other judges crafted guidelines that were published in February by the Sedona Conference, an influential think tank that issues principles for particularly murky areas of the law. They outline a host of potentially “safe” uses of AI for judges, including conducting legal research, creating preliminary transcripts, and searching briefings, while warning that judges should verify outputs from AI and that “no known GenAI tools have fully resolved the hallucination problem.”&lt;/p&gt; 

&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Dodging AI blunders&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Judge Allison Goddard, a federal magistrate judge in California and a coauthor of the guidelines, first felt the impact that AI would have on the judiciary when she taught a class on the art of advocacy at her daughter’s high school. She was impressed by a student’s essay and mentioned it to her daughter. “She said, ‘Oh, Mom, that’s ChatGPT.’”&lt;/p&gt;  &lt;p&gt;“What I realized very quickly was this is going to really transform the legal profession,” she says. In her court, Goddard has been experimenting with ChatGPT, Claude (which she keeps "open all day"), and a host of other AI models. If a case involves a particularly technical issue, she might ask AI to help her understand which questions to ask attorneys. She’ll summarize 60-page orders from the district judge and then ask the AI model follow-up questions about it, or ask it to organize information from documents that are a mess.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“It’s kind of a thought partner, and it brings a perspective that you may not have considered,” she says.&lt;/p&gt;  &lt;p&gt;Goddard also encourages her clerks to use AI, specifically Anthropic’s Claude, because by default it does not train on user conversations. But it has its limits. For anything that requires law-specific knowledge, she’ll use tools from Westlaw or Lexis, which have AI tools built specifically for lawyers, but she finds general-purpose AI models to be faster for lots of other tasks. And her concerns about bias have prevented her from using it for tasks in criminal cases, like determining if there was probable cause for an arrest.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;In this, Goddard appears to be caught in the same predicament the AI boom has created for many of us. Three years in, companies have built tools that sound so fluent and humanlike they obscure the intractable problems lurking underneath—answers that read well but are wrong, models that are trained to be decent at everything but perfect for nothing, and the risk that your conversations with them will be leaked to the internet. Each time we use them, we bet that the time saved will outweigh the risks, and trust ourselves to catch the mistakes before they matter. For judges, the stakes are sky-high: If they lose that bet, they face very public consequences, and the impact of such mistakes on the people they serve can be lasting.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“I’m not going to be the judge that cites hallucinated cases and orders,” Goddard says. “It’s really embarrassing, very professionally embarrassing.”&lt;/p&gt;  &lt;p&gt;Still, some judges don’t want to get left behind in the AI age. With some in the AI sector suggesting that the supposed objectivity and rationality of AI models could make them better judges than fallible humans, it might lead some on the bench to think that falling behind poses a bigger risk than getting too far out ahead.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;A ‘crisis waiting to happen’&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;The risks of early adoption have raised alarm bells with Judge Scott Schlegel, who serves on the Fifth Circuit Court of Appeal in Louisiana. Schlegel has long blogged about the helpful role technology can play in modernizing the court system, but he has warned that AI-generated mistakes in judges’ rulings signal a “crisis waiting to happen,” one that would dwarf the problem of lawyers’ submitting filings with made-up cases.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Attorneys who make mistakes can get sanctioned, have their motions dismissed, or lose cases when the opposing party finds out and flags the errors. “When the judge makes a mistake, that’s the law,” he says. “I can’t go a month or two later and go ‘Oops, so sorry,’ and reverse myself. It doesn’t work that way.”&lt;/p&gt;  &lt;p&gt;Consider child custody cases or bail proceedings, Schlegel says: “There are pretty significant consequences when a judge relies upon artificial intelligence to make the decision,” especially if the citations that decision relies on are made-up or incorrect.&lt;/p&gt; 
 &lt;p&gt;This is not theoretical. In June, a Georgia appellate court judge issued an order that relied partially on made-up cases submitted by one of the parties, a mistake that went uncaught. In July, a federal judge in New Jersey withdrew an opinion after lawyers complained it too contained hallucinations.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Unlike lawyers, who can be ordered by the court to explain why there are mistakes in their filings, judges do not have to show much transparency, and there is little reason to think they’ll do so voluntarily. On August 4, a federal judge in Mississippi had to issue a new decision in a civil rights case after the original was found to contain incorrect names and serious errors. The judge did not fully explain what led to the errors even after the state asked him to do so. “No further explanation is warranted,” the judge wrote.&lt;/p&gt;  &lt;p&gt;These mistakes could erode the public’s faith in the legitimacy of courts, Schlegel says. Certain narrow and monitored applications of AI—summarizing testimonies, getting quick writing feedback—can save time, and they can produce good results if judges treat the work like that of a first-year associate, checking it thoroughly for accuracy. But most of the job of being a judge is dealing with what he calls the white-page problem: You’re presiding over a complex case with a blank page in front of you, forced to make difficult decisions. Thinking through those decisions, he says, is indeed the work of being a judge. Getting help with a first draft from an AI undermines that purpose.&lt;/p&gt;  &lt;p&gt;“If you’re making a decision on who gets the kids this weekend and somebody finds out you use Grok and you should have used Gemini or ChatGPT—you know, that’s not the justice system.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/250805_AIjudge_hero.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;The propensity for AI systems to make mistakes and for humans to miss those mistakes has been on full display in the US legal system as of late. The follies began when lawyers—including some at prestigious firms—submitted documents citing cases that didn’t exist. Similar mistakes soon spread to other roles in the courts. In December, a Stanford professor submitted sworn testimony containing hallucinations and errors in a case about deepfakes, despite being an expert on AI and misinformation himself.&lt;/p&gt;  &lt;p&gt;The buck stopped with judges, who—whether they or opposing counsel caught the mistakes—issued reprimands and fines, and likely left attorneys embarrassed enough to think twice before trusting AI again.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;But now judges are experimenting with generative AI too. Some are confident that with the right precautions, the technology can expedite legal research, summarize cases, draft routine orders, and overall help speed up the court system, which is badly backlogged in many parts of the US. This summer, though, we’ve already seen AI-generated mistakes go undetected and cited by judges. A federal judge in New Jersey had to reissue an order riddled with errors that may have come from AI, and a judge in Mississippi refused to explain why his order too contained mistakes that seemed like AI hallucinations.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The results of these early-adopter experiments make two things clear. One, the category of routine tasks—for which AI can assist without requiring human judgment—is slippery to define. Two, while lawyers face sharp scrutiny when their use of AI leads to mistakes, judges may not face the same accountability, and walking back their mistakes before they do damage is much harder.&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Drawing boundaries&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Xavier Rodriguez, a federal judge for the Western District of Texas, has good reason to be skeptical of AI. He started learning about artificial intelligence back in 2018, four years before the release of ChatGPT (thanks in part to the influence of his twin brother, who works in tech). But he’s also seen AI-generated mistakes in his own court.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In a recent dispute about who was to receive an insurance payout, both the plaintiff and the defendant represented themselves, without lawyers (this is not uncommon—nearly a quarter of civil cases in federal court involve at least one unrepresented party). The two sides wrote their own filings and made their own arguments.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;“Both sides used AI tools,” Rodriguez says, and both submitted filings that referenced made-up cases. He had authority to reprimand them, but given that they were not lawyers, he opted not to.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“I think there’s been an overreaction by a lot of judges on these sanctions. The running joke I tell when I’m on the speaking circuit is that lawyers have been hallucinating well before AI,” he says. Missing a mistake from an AI model is not wholly different, to Rodriguez, from failing to catch the error of a first-year lawyer. “I’m not as deeply offended as everybody else,” he says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In his court, Rodriguez has been using generative AI tools (he wouldn’t publicly name which ones, to avoid the appearance of an endorsement) to summarize cases. He’ll ask AI to identify key players involved and then have it generate a timeline of key events. Ahead of specific hearings, Rodriguez will also ask it to generate questions for attorneys based on the materials they submit.&lt;/p&gt;  &lt;p&gt;These tasks, to him, don’t lean on human judgment. They also offer lots of opportunities for him to intervene and uncover any mistakes before they’re brought to the court. “It’s not any final decision being made, and so it’s relatively risk free,” he says. Using AI to predict whether someone should be eligible for bail, on the other hand, goes too far in the direction of judgment and discretion, in his view.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Erin Solovey, a professor and researcher on human-AI interaction at Worcester Polytechnic Institute in Massachusetts, recently studied how judges in the UK think about this distinction between rote, machine-friendly work that feels safe to delegate to AI and tasks that lean more heavily on human expertise.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“The line between what is appropriate for a human judge to do versus what is appropriate for AI tools to do changes from judge to judge and from one scenario to the next,” she says.&lt;/p&gt;  &lt;p&gt;Even so, according to Solovey, some of these tasks simply don’t match what AI is good at. Asking AI to summarize a large document, for example, might produce drastically different results depending on whether the model has been trained to summarize for a general audience or a legal one. AI also struggles with logic-based tasks like ordering the events of a case. “A very plausible-sounding timeline may be factually incorrect,” Solovey says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Rodriguez and a number of other judges crafted guidelines that were published in February by the Sedona Conference, an influential think tank that issues principles for particularly murky areas of the law. They outline a host of potentially “safe” uses of AI for judges, including conducting legal research, creating preliminary transcripts, and searching briefings, while warning that judges should verify outputs from AI and that “no known GenAI tools have fully resolved the hallucination problem.”&lt;/p&gt; 

&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Dodging AI blunders&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Judge Allison Goddard, a federal magistrate judge in California and a coauthor of the guidelines, first felt the impact that AI would have on the judiciary when she taught a class on the art of advocacy at her daughter’s high school. She was impressed by a student’s essay and mentioned it to her daughter. “She said, ‘Oh, Mom, that’s ChatGPT.’”&lt;/p&gt;  &lt;p&gt;“What I realized very quickly was this is going to really transform the legal profession,” she says. In her court, Goddard has been experimenting with ChatGPT, Claude (which she keeps "open all day"), and a host of other AI models. If a case involves a particularly technical issue, she might ask AI to help her understand which questions to ask attorneys. She’ll summarize 60-page orders from the district judge and then ask the AI model follow-up questions about it, or ask it to organize information from documents that are a mess.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“It’s kind of a thought partner, and it brings a perspective that you may not have considered,” she says.&lt;/p&gt;  &lt;p&gt;Goddard also encourages her clerks to use AI, specifically Anthropic’s Claude, because by default it does not train on user conversations. But it has its limits. For anything that requires law-specific knowledge, she’ll use tools from Westlaw or Lexis, which have AI tools built specifically for lawyers, but she finds general-purpose AI models to be faster for lots of other tasks. And her concerns about bias have prevented her from using it for tasks in criminal cases, like determining if there was probable cause for an arrest.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;In this, Goddard appears to be caught in the same predicament the AI boom has created for many of us. Three years in, companies have built tools that sound so fluent and humanlike they obscure the intractable problems lurking underneath—answers that read well but are wrong, models that are trained to be decent at everything but perfect for nothing, and the risk that your conversations with them will be leaked to the internet. Each time we use them, we bet that the time saved will outweigh the risks, and trust ourselves to catch the mistakes before they matter. For judges, the stakes are sky-high: If they lose that bet, they face very public consequences, and the impact of such mistakes on the people they serve can be lasting.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“I’m not going to be the judge that cites hallucinated cases and orders,” Goddard says. “It’s really embarrassing, very professionally embarrassing.”&lt;/p&gt;  &lt;p&gt;Still, some judges don’t want to get left behind in the AI age. With some in the AI sector suggesting that the supposed objectivity and rationality of AI models could make them better judges than fallible humans, it might lead some on the bench to think that falling behind poses a bigger risk than getting too far out ahead.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;A ‘crisis waiting to happen’&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;The risks of early adoption have raised alarm bells with Judge Scott Schlegel, who serves on the Fifth Circuit Court of Appeal in Louisiana. Schlegel has long blogged about the helpful role technology can play in modernizing the court system, but he has warned that AI-generated mistakes in judges’ rulings signal a “crisis waiting to happen,” one that would dwarf the problem of lawyers’ submitting filings with made-up cases.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Attorneys who make mistakes can get sanctioned, have their motions dismissed, or lose cases when the opposing party finds out and flags the errors. “When the judge makes a mistake, that’s the law,” he says. “I can’t go a month or two later and go ‘Oops, so sorry,’ and reverse myself. It doesn’t work that way.”&lt;/p&gt;  &lt;p&gt;Consider child custody cases or bail proceedings, Schlegel says: “There are pretty significant consequences when a judge relies upon artificial intelligence to make the decision,” especially if the citations that decision relies on are made-up or incorrect.&lt;/p&gt; 
 &lt;p&gt;This is not theoretical. In June, a Georgia appellate court judge issued an order that relied partially on made-up cases submitted by one of the parties, a mistake that went uncaught. In July, a federal judge in New Jersey withdrew an opinion after lawyers complained it too contained hallucinations.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Unlike lawyers, who can be ordered by the court to explain why there are mistakes in their filings, judges do not have to show much transparency, and there is little reason to think they’ll do so voluntarily. On August 4, a federal judge in Mississippi had to issue a new decision in a civil rights case after the original was found to contain incorrect names and serious errors. The judge did not fully explain what led to the errors even after the state asked him to do so. “No further explanation is warranted,” the judge wrote.&lt;/p&gt;  &lt;p&gt;These mistakes could erode the public’s faith in the legitimacy of courts, Schlegel says. Certain narrow and monitored applications of AI—summarizing testimonies, getting quick writing feedback—can save time, and they can produce good results if judges treat the work like that of a first-year associate, checking it thoroughly for accuracy. But most of the job of being a judge is dealing with what he calls the white-page problem: You’re presiding over a complex case with a blank page in front of you, forced to make difficult decisions. Thinking through those decisions, he says, is indeed the work of being a judge. Getting help with a first draft from an AI undermines that purpose.&lt;/p&gt;  &lt;p&gt;“If you’re making a decision on who gets the kids this weekend and somebody finds out you use Grok and you should have used Gemini or ChatGPT—you know, that’s not the justice system.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/08/11/1121460/meet-the-early-adopter-judges-using-ai/</guid><pubDate>Mon, 11 Aug 2025 15:16:15 +0000</pubDate></item><item><title>Trump strikes “wild” deal making US firms pay 15% tax on China chip sales (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/08/nvidia-amd-agree-to-pay-trumps-15-levy-on-china-chip-sales/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The deal won’t resolve national security concerns.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2219997893-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2219997893-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          SOPA Images / Contributor | LightRocket

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Ahead of an August 12 deadline for a US-China trade deal, Donald Trump's tactics continue to confuse those trying to assess the country's national security priorities regarding its&amp;nbsp;biggest geopolitical rival.&lt;/p&gt;
&lt;p&gt;For months, Trump has kicked the can down the road regarding a TikTok ban, allowing the app to continue operating despite supposedly urgent national security concerns that China may be using the app to spy on Americans. And now, in the latest baffling move, a US official announced Monday that Trump got Nvidia and AMD to agree to "give the US government 15 percent of revenue from sales to China of advanced computer chips," Reuters reported. Those chips, about 20&amp;nbsp;policymakers and national security experts recently warned Trump, could be used to fuel China's frontier AI, which seemingly poses an even greater national security risk.&lt;/p&gt;
&lt;h2&gt;Trump’s “wild” deal with US chip firms&lt;/h2&gt;
&lt;p&gt;Reuters granted two officials anonymity to discuss Trump's deal with US chipmakers, because details have yet to be made public. Requiring US firms to pay for sales in China is an "unusual" move for a president, Reuters noted, and the Trump administration has yet to say what exactly it plans to do with the money.&lt;/p&gt;
&lt;p&gt;For US firms, the deal may set an alarming precedent. Not only have analysts warned that the deal could "hurt margins" for both companies, but export curbs on Nvidia's H20 chips, for example, had been established to prevent US technology thefts, secure US technology leadership, and protect US national security. Now the US government appears to be accepting a payment to overlook those alleged risks, without much reassurance that the policy won't advantage China in the AI race.&lt;/p&gt;
&lt;p&gt;The move drew immediate scrutiny from critics, including Geoff Gertz, a senior fellow at the US think tank Center for a New American Security,&amp;nbsp;who told Reuters that he thinks the deal is "wild."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"Either selling H20 chips to China is a national security risk, in which case we shouldn't be doing it to begin with, or it's not a national security risk, in which case, why are we putting this extra penalty on the sale?" Gertz posited.&lt;/p&gt;
&lt;p&gt;At this point, the only reassurance from the Trump administration is an official suggesting (without providing any rationale) that selling H20 or equivalent chips—which are not Nvidia's most advanced chips—no longer compromises national security.&lt;/p&gt;
&lt;h2&gt;Trump “trading away” national security&lt;/h2&gt;
&lt;p&gt;It remains unclear when or how the levy will be implemented.&lt;/p&gt;
&lt;p&gt;For chipmakers, the levy is likely viewed as a relatively small price to pay to avoid export curbs. Nvidia had forecasted $8 billion in potential losses if it couldn’t sell its H20 chips to China. AMD expected $1 billion in revenue cuts, partly due to the loss of sales for its MI308 chips in China.&lt;/p&gt;
&lt;p&gt;The firms apparently agreed to Trump's deal as a condition to receive licenses to export those chips. But caving to Trump could bite them back in the long run, AJ Bell, investment director Russ Mould, told Reuters—perhaps especially if Trump faces increasing pressure over feared national security concerns.&lt;/p&gt;
&lt;p&gt;"The Chinese market is significant for both these companies, so even if they have to give up a bit of the money, they would otherwise make it look like a logical move on paper," Mould said. However, the deal "is unprecedented and there is always the risk the revenue take could be upped or that the Trump administration changes its mind and re-imposes export controls."&lt;/p&gt;
&lt;p&gt;So far, AMD has not commented on the report. Nvidia's spokesperson declined to comment beyond noting, "We follow rules the US government sets for our participation in worldwide markets."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;A former adviser to Joe Biden's Commerce Department, Alasdair Phillips-Robins, told Reuters that the levy suggests the Trump administration "is trading away national security protections for revenue for the Treasury."&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Huawei close to unveiling new AI chip tech&lt;/h2&gt;
&lt;p&gt;The end of a 90-day truce between the US and China is rapidly approaching, with the US signaling that the truce will likely be extended soon as Trump attempts to get a long-sought-after meeting with China's President Xi Jinping.&lt;/p&gt;
&lt;p&gt;For China, gutting export curbs on chips remains a key priority in negotiations, the Financial Times reported Sunday. But Nvidia's H20 chips, for example, are lower priority than high-bandwidth memory (HBM) chips, sources told FT.&lt;/p&gt;
&lt;p&gt;Chinese state media has even begun attacking the H20 chips as a Chinese national security risk. It appears that China is urging a boycott on H20 chips due to questions linked to a recent Congressional push to require chipmakers to build "backdoors" that would allow remote shutdowns of any chips detected as non-compliant with export curbs. That bill may mean that Nvidia's chips already allow for US surveillance, China seemingly fears. (Nvidia has denied building such backdoors.)&lt;/p&gt;
&lt;p&gt;Biden banned HBM exports to China last year, specifically moving to hamper innovation of Chinese chipmakers Huawei and Semiconductor Manufacturing International Corporation (SMIC).&lt;/p&gt;
&lt;p&gt;Currently, US firms AMD and Micron remain top suppliers of HBM chips globally, along with South Korean firms Samsung Electronics and SK Hynix, but Chinese firms have notably lagged behind, South China Morning Post (SCMP) reported. One source told FT that China "had raised the HBM issue in some" Trump negotiations, likely directly seeking to lift Biden's "HBM controls because they seriously constrain the ability of Chinese companies, including Huawei, to develop their own AI chips."&lt;/p&gt;
&lt;p&gt;For Trump, the HBM controls could be seen as leverage to secure another trade win. However, some experts are hoping that Trump won't play that card, citing concerns from the Biden era that remain unaddressed.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;If Trump bends to Chinese pressure and lifts HBM controls, China could more easily produce AI chips at scale, Biden had feared. That could even possibly endanger US firms' standing as world leaders, seemingly including threatening Nvidia, a company that Trump discovered this term. Gregory Allen, an AI expert at a US think tank called the Center for Strategic and International Studies, told FT that "saying that we should allow more advanced HBM sales to China is the exact same as saying that we should help Huawei make better AI chips so that they can replace Nvidia."&lt;/p&gt;
&lt;p&gt;Meanwhile, Huawei is reportedly already innovating to help reduce China's reliance on HBM chips, the SCMP reported on Monday. Chinese state-run Securities Times reported that Huawei is "set to unveil a technological breakthrough that could reduce China’s reliance on high-bandwidth memory (HBM) chips for running artificial intelligence reasoning models" at the 2025 Financial AI Reasoning Application Landing and Development Forum in Shanghai on Tuesday.&lt;/p&gt;
&lt;p&gt;It's a conveniently timed announcement, given the US-China trade deal deadline lands the same day. But the risk of Huawei possibly relying on US tech to reach that particular milestone is why HBM controls should remain off the table during Trump's negotiations, one official told FT.&lt;/p&gt;
&lt;p&gt;"Relaxing these controls would be a gift to Huawei and SMIC and could open the floodgates for China to start making millions of AI chips per year, while also diverting scarce HBM from chips sold in the US," the official said.&lt;/p&gt;
&lt;p&gt;Experts and policymakers had previously warned Trump that allowing H20 export curbs could similarly reduce access to semiconductors in the US, potentially disrupting the entire purpose of Trump's trade war, which is building reliable US supply chains. Additionally, allowing exports will likely drive up costs to US chip firms at a time when they noted "projected data center demand from the US power market would require 90 percent of global chip supply through 2030, an unlikely scenario even without China joining the rush to buy advanced AI chips." They're now joined by others urging Trump to revive Biden's efforts to block chip exports to China, or else risk empowering a geopolitical rival to become a global AI leader ahead of the US.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The deal won’t resolve national security concerns.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2219997893-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2219997893-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          SOPA Images / Contributor | LightRocket

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Ahead of an August 12 deadline for a US-China trade deal, Donald Trump's tactics continue to confuse those trying to assess the country's national security priorities regarding its&amp;nbsp;biggest geopolitical rival.&lt;/p&gt;
&lt;p&gt;For months, Trump has kicked the can down the road regarding a TikTok ban, allowing the app to continue operating despite supposedly urgent national security concerns that China may be using the app to spy on Americans. And now, in the latest baffling move, a US official announced Monday that Trump got Nvidia and AMD to agree to "give the US government 15 percent of revenue from sales to China of advanced computer chips," Reuters reported. Those chips, about 20&amp;nbsp;policymakers and national security experts recently warned Trump, could be used to fuel China's frontier AI, which seemingly poses an even greater national security risk.&lt;/p&gt;
&lt;h2&gt;Trump’s “wild” deal with US chip firms&lt;/h2&gt;
&lt;p&gt;Reuters granted two officials anonymity to discuss Trump's deal with US chipmakers, because details have yet to be made public. Requiring US firms to pay for sales in China is an "unusual" move for a president, Reuters noted, and the Trump administration has yet to say what exactly it plans to do with the money.&lt;/p&gt;
&lt;p&gt;For US firms, the deal may set an alarming precedent. Not only have analysts warned that the deal could "hurt margins" for both companies, but export curbs on Nvidia's H20 chips, for example, had been established to prevent US technology thefts, secure US technology leadership, and protect US national security. Now the US government appears to be accepting a payment to overlook those alleged risks, without much reassurance that the policy won't advantage China in the AI race.&lt;/p&gt;
&lt;p&gt;The move drew immediate scrutiny from critics, including Geoff Gertz, a senior fellow at the US think tank Center for a New American Security,&amp;nbsp;who told Reuters that he thinks the deal is "wild."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"Either selling H20 chips to China is a national security risk, in which case we shouldn't be doing it to begin with, or it's not a national security risk, in which case, why are we putting this extra penalty on the sale?" Gertz posited.&lt;/p&gt;
&lt;p&gt;At this point, the only reassurance from the Trump administration is an official suggesting (without providing any rationale) that selling H20 or equivalent chips—which are not Nvidia's most advanced chips—no longer compromises national security.&lt;/p&gt;
&lt;h2&gt;Trump “trading away” national security&lt;/h2&gt;
&lt;p&gt;It remains unclear when or how the levy will be implemented.&lt;/p&gt;
&lt;p&gt;For chipmakers, the levy is likely viewed as a relatively small price to pay to avoid export curbs. Nvidia had forecasted $8 billion in potential losses if it couldn’t sell its H20 chips to China. AMD expected $1 billion in revenue cuts, partly due to the loss of sales for its MI308 chips in China.&lt;/p&gt;
&lt;p&gt;The firms apparently agreed to Trump's deal as a condition to receive licenses to export those chips. But caving to Trump could bite them back in the long run, AJ Bell, investment director Russ Mould, told Reuters—perhaps especially if Trump faces increasing pressure over feared national security concerns.&lt;/p&gt;
&lt;p&gt;"The Chinese market is significant for both these companies, so even if they have to give up a bit of the money, they would otherwise make it look like a logical move on paper," Mould said. However, the deal "is unprecedented and there is always the risk the revenue take could be upped or that the Trump administration changes its mind and re-imposes export controls."&lt;/p&gt;
&lt;p&gt;So far, AMD has not commented on the report. Nvidia's spokesperson declined to comment beyond noting, "We follow rules the US government sets for our participation in worldwide markets."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;A former adviser to Joe Biden's Commerce Department, Alasdair Phillips-Robins, told Reuters that the levy suggests the Trump administration "is trading away national security protections for revenue for the Treasury."&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Huawei close to unveiling new AI chip tech&lt;/h2&gt;
&lt;p&gt;The end of a 90-day truce between the US and China is rapidly approaching, with the US signaling that the truce will likely be extended soon as Trump attempts to get a long-sought-after meeting with China's President Xi Jinping.&lt;/p&gt;
&lt;p&gt;For China, gutting export curbs on chips remains a key priority in negotiations, the Financial Times reported Sunday. But Nvidia's H20 chips, for example, are lower priority than high-bandwidth memory (HBM) chips, sources told FT.&lt;/p&gt;
&lt;p&gt;Chinese state media has even begun attacking the H20 chips as a Chinese national security risk. It appears that China is urging a boycott on H20 chips due to questions linked to a recent Congressional push to require chipmakers to build "backdoors" that would allow remote shutdowns of any chips detected as non-compliant with export curbs. That bill may mean that Nvidia's chips already allow for US surveillance, China seemingly fears. (Nvidia has denied building such backdoors.)&lt;/p&gt;
&lt;p&gt;Biden banned HBM exports to China last year, specifically moving to hamper innovation of Chinese chipmakers Huawei and Semiconductor Manufacturing International Corporation (SMIC).&lt;/p&gt;
&lt;p&gt;Currently, US firms AMD and Micron remain top suppliers of HBM chips globally, along with South Korean firms Samsung Electronics and SK Hynix, but Chinese firms have notably lagged behind, South China Morning Post (SCMP) reported. One source told FT that China "had raised the HBM issue in some" Trump negotiations, likely directly seeking to lift Biden's "HBM controls because they seriously constrain the ability of Chinese companies, including Huawei, to develop their own AI chips."&lt;/p&gt;
&lt;p&gt;For Trump, the HBM controls could be seen as leverage to secure another trade win. However, some experts are hoping that Trump won't play that card, citing concerns from the Biden era that remain unaddressed.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;If Trump bends to Chinese pressure and lifts HBM controls, China could more easily produce AI chips at scale, Biden had feared. That could even possibly endanger US firms' standing as world leaders, seemingly including threatening Nvidia, a company that Trump discovered this term. Gregory Allen, an AI expert at a US think tank called the Center for Strategic and International Studies, told FT that "saying that we should allow more advanced HBM sales to China is the exact same as saying that we should help Huawei make better AI chips so that they can replace Nvidia."&lt;/p&gt;
&lt;p&gt;Meanwhile, Huawei is reportedly already innovating to help reduce China's reliance on HBM chips, the SCMP reported on Monday. Chinese state-run Securities Times reported that Huawei is "set to unveil a technological breakthrough that could reduce China’s reliance on high-bandwidth memory (HBM) chips for running artificial intelligence reasoning models" at the 2025 Financial AI Reasoning Application Landing and Development Forum in Shanghai on Tuesday.&lt;/p&gt;
&lt;p&gt;It's a conveniently timed announcement, given the US-China trade deal deadline lands the same day. But the risk of Huawei possibly relying on US tech to reach that particular milestone is why HBM controls should remain off the table during Trump's negotiations, one official told FT.&lt;/p&gt;
&lt;p&gt;"Relaxing these controls would be a gift to Huawei and SMIC and could open the floodgates for China to start making millions of AI chips per year, while also diverting scarce HBM from chips sold in the US," the official said.&lt;/p&gt;
&lt;p&gt;Experts and policymakers had previously warned Trump that allowing H20 export curbs could similarly reduce access to semiconductors in the US, potentially disrupting the entire purpose of Trump's trade war, which is building reliable US supply chains. Additionally, allowing exports will likely drive up costs to US chip firms at a time when they noted "projected data center demand from the US power market would require 90 percent of global chip supply through 2030, an unlikely scenario even without China joining the rush to buy advanced AI chips." They're now joined by others urging Trump to revive Biden's efforts to block chip exports to China, or else risk empowering a geopolitical rival to become a global AI leader ahead of the US.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/08/nvidia-amd-agree-to-pay-trumps-15-levy-on-china-chip-sales/</guid><pubDate>Mon, 11 Aug 2025 16:31:51 +0000</pubDate></item><item><title>OpenAI is editing its GPT-5 rollout on the fly — here’s what’s changing in ChatGPT (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/openai-is-editing-its-gpt-5-rollout-on-the-fly-heres-whats-changing-in-chatgpt/</link><description>&lt;p&gt;The new flagship model GPT-5 — available in four variants of different speed and intelligence (regular, mini, nano, and pro), alongside longer-response and more powerful “thinking” modes for at least three of these variants — was&lt;strong&gt; said to offer faster responses, more reasoning power, and stronger coding ability.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Indeed,&lt;strong&gt; the rollout has exposed infrastructure strain, user dissatisfaction, and a broader, more unsettling issue now drawing global attention:&lt;/strong&gt; the growing emotional and psychological reliance some people form on AI and resulting break from reality some users experience, known as “&lt;strong&gt;ChatGPT psychosis.”&lt;/strong&gt;&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;h2 class="wp-block-heading" id="h-from-bumpy-debut-to-incremental-fixes"&gt;From bumpy debut to incremental fixes&lt;/h2&gt;



&lt;p&gt;The long-anticipated GPT-5 model family debuted Thursday, August 7 in a livestreamed event beset with chart errors and some voice mode glitches during the presentation. &lt;/p&gt;



&lt;p&gt;But worse than these cosmetic issues for many users was the fact that OpenAI automatically deprecated its older AI models that used to power ChatGPT —&lt;strong&gt; GPT-4o, GPT-4.1, o3, o4-mini and o4-high&lt;/strong&gt; — forcing all users over to the new GPT-5 model and directing their queries to different versions of its “thinking” process without revealing why or which specific model version was being used.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Early adopters to GPT-5 reported basic math and logic mistakes, inconsistent code generation, and uneven real-world performance compared to GPT-4o.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;For context, the &lt;strong&gt;old models&lt;/strong&gt; &lt;strong&gt;GPT-4o, o3, o4-mini and more&lt;/strong&gt; &lt;strong&gt;still remain available&lt;/strong&gt; and have remained available &lt;strong&gt;to users of OpenAI’s paid application programming interface (API)&lt;/strong&gt; since the launch of GPT-5 on Thursday.&lt;/p&gt;



&lt;p&gt;By Friday, OpenAI co-fonder CEO Sam Altman conceded th&lt;strong&gt;e launch was “a little more bumpy than we hoped for,” &lt;/strong&gt;and &lt;strong&gt;blamed a failure in GPT-5’s new automatic “router”&lt;/strong&gt; — the system that assigns prompts to the most appropriate variant.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Altman and others at OpenAI claimed the “autoswitcher” went offline “for a chunk of the day,” making the model seem “way dumber” than intended. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;The launch of GPT-5 was preceded just days prior by the launch of OpenAI’s new open source large language models (LLMs) named gpt-oss, which also received mixed reviews. These models are not available on ChatGPT, rather, they are free to download and run locally or on third-party hardware.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-to-switch-back-from-gpt-5-to-gpt-4o-in-chatgpt"&gt;How to switch back from GPT-5 to GPT-4o in ChatGPT&lt;/h2&gt;



&lt;p&gt;Within 24 hours, OpenAI &lt;strong&gt;restored GPT-4o access for Plus subscribers (those paying $20 per month or more subscription plans)&lt;/strong&gt;, pledged more transparent model labeling, and promised a UI update to let users manually trigger GPT-5’s “thinking” mode. &lt;/p&gt;



&lt;p&gt;Already,&lt;strong&gt; users can go and manually select the older models on the ChatGPT website by finding their account name and icon in the lower left corner of the screen, clicking it, then clicking “Settings” and “General” and toggling on “Show legacy models.”&lt;/strong&gt;&lt;/p&gt;



&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-3015426" height="310" src="https://venturebeat.com/wp-content/uploads/2025/08/Screenshot-2025-08-11-at-12.26.13%E2%80%AFPM.png" width="269" /&gt;&lt;/figure&gt;



&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-3015429" height="594" src="https://venturebeat.com/wp-content/uploads/2025/08/Screenshot-2025-08-11-at-12.26.18%E2%80%AFPM-1.png" width="678" /&gt;&lt;/figure&gt;



&lt;p&gt;There’s no indication from OpenAI that other old models will be returning to ChatGPT anytime soon.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-upgraded-usage-limits-for-gpt-5"&gt;Upgraded usage limits for GPT-5 &lt;/h2&gt;



&lt;p&gt;Altman &lt;strong&gt;said that ChatGPT Plus subscribers will get twice as many messages using the GPT-5 “Thinking” mode&lt;/strong&gt; that offers more reasoning and intelligence —&lt;strong&gt; up to 3,000 per week&lt;/strong&gt; — and that engineers began fine-tuning decision boundaries in the message router.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Sam Altman announced the following updates after the GPT-5 launch&lt;/p&gt;&lt;p&gt;– OpenAI is testing a 3,000-per-week limit for GPT-5 Thinking messages for Plus users, significantly increasing reasoning rate limits today, and will soon raise all model-class rate limits above pre-GPT-5 levels… pic.twitter.com/ppvhKmj95u&lt;/p&gt;— Tibor Blaho (@btibor91) August 10, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;By the weekend, GPT-5 was available to 100% of Pro subscribers and “getting close to 100% of all users.” &lt;/p&gt;



&lt;p&gt;Altman said the company had “underestimated how much some of the things that people like in GPT-4o matter to them” and vowed to accelerate per-user customization — from personality warmth to tone controls like emoji use.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-looming-capacity-crunch"&gt;Looming capacity crunch&lt;/h2&gt;



&lt;p&gt;Altman warned that OpenAI faces a “severe capacity challenge” this week as usage of reasoning models climbs sharply — from less than 1% to 7% of free users, and from 7% to 24% of Plus subscribers. &lt;/p&gt;



&lt;p&gt;He teased giving Plus subscribers a small monthly allotment of GPT-5 Pro queries and said the company will soon explain how it plans to balance capacity between ChatGPT, the API, research, and new user onboarding.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-altman-model-attachment-is-real-and-risky"&gt;&lt;strong&gt;Altman: model attachment is real — and risky&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;In a post on X last night, Altman acknowledged a dynamic the company has tracked “for the past year or so”: users’ deep attachment to specific models. &lt;/p&gt;



&lt;p&gt;“It feels different and stronger than the kinds of attachment people have had to previous kinds of technology,” he wrote, admitting that suddenly deprecating older models “was a mistake.”&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;If you have been following the GPT-5 rollout, one thing you might be noticing is how much of an attachment some people have to specific AI models. It feels different and stronger than the kinds of attachment people have had to previous kinds of technology (and so suddenly…&lt;/p&gt;— Sam Altman (@sama) August 11, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;He tied this to a broader risk: some users treat ChatGPT as a therapist or life coach, which can be beneficial, but for a “small percentage” can reinforce delusion or undermine long-term well-being. &lt;/p&gt;



&lt;p&gt;While OpenAI’s guiding principle remains “treat adult users like adults,” &lt;strong&gt;Altman said the company has a responsibility not to nudge vulnerable users into harmful relationships with the AI.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;The&lt;strong&gt; comments land as several major media outlets report on cases of “ChatGPT psychosis”&lt;/strong&gt; — where extended, intense conversations with chatbots appear to play a role in inducing or deepening delusional thinking.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-psychosis-cases-making-headlines"&gt;The psychosis cases making headlines&lt;/h2&gt;



&lt;p&gt;In &lt;em&gt;Rolling Stone&lt;/em&gt; magazine, a California legal professional identified as “J.” described a six-week spiral of sleepless nights and philosophical rabbit holes with ChatGPT, ultimately producing a 1,000-page treatise for a fictional monastic order before crashing physically and mentally. He now avoids AI entirely, fearing relapse.&lt;/p&gt;



&lt;p&gt;In &lt;em&gt;The New York Times&lt;/em&gt;, a Canadian recruiter, Allan Brooks, recounted 21 days and 300 hours of conversations with ChatGPT — which he named “Lawrence” — that convinced him he had discovered a world-changing mathematical theory. &lt;/p&gt;



&lt;p&gt;The bot praised his ideas as “revolutionary,” urged outreach to national security agencies, and spun elaborate spy-thriller narratives. &lt;strong&gt;Brooks eventually broke the delusion after cross-checking with Google’s Gemini, which rated the chances of his discovery as “approaching 0%.”&lt;/strong&gt; He now participates in a support group for people who’ve experienced AI-induced delusions.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Both investigations detail how chatbot “sycophancy,” role-playing, and long-session memory features can deepen false beliefs, especially when conversations follow dramatic story arcs.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;Experts told the &lt;em&gt;Times&lt;/em&gt; these factors can override safety guardrails — with one psychiatrist describing Brooks’s episode as “a manic episode with psychotic features.”&lt;/p&gt;



&lt;p&gt;Meanwhile, human user postings on Reddit’s r/AIsoulmates subreddit — a collection of people who have used ChatGPT and other AI models to create new artificial girlfriends, boyfriends, children or other loved ones not based off real people necessarily, but rather ideal qualities of their “dream” version of said roles” — continues to gain new users and terminology for AI companions, including “wireborn” as opposed to natural born or human-born companions.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;p&gt;The growth of this subreddit, now up to 1,200+ members, alongside the &lt;em&gt;NYT&lt;/em&gt; and &lt;em&gt;Rolling Stone&lt;/em&gt; articles and other reports on social media of users forging intense emotional fixations with pattern-matching algorithmic-based chatbots, shows that&lt;strong&gt; society is entering a risky new phase wherein human beings believe the companions they’ve crafted and customized out of leading AI models are as or more meaningful to them than human relationships&lt;/strong&gt;.&lt;/p&gt;



&lt;p&gt;This can already prove psychologically destabilizing when models change, are updated, or deprecated as in the case of OpenAI’s GPT-5 rollout.&lt;/p&gt;



&lt;p&gt;Relatedly but separately, reports continue to emerge of AI chatbot users who &lt;strong&gt;believe that conversations with chatbots have led them to immense knowledge breakthroughs and advances in science, technology, and other fields, when in reality, they are simply affirming the user’s ego and greatness&lt;/strong&gt; and the solutions the user arrives at with the aid of the chatbot are not legitimate nor effectual. &lt;strong&gt;This break from reality has been roughly coined under the grassroots term “ChatGPT psychosis” or “GPT psychosis”&lt;/strong&gt; and appears to have impacted major Silicon Valley figures as well.  &lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;I’m a psychiatrist.&lt;/p&gt;&lt;p&gt;In 2025, I’ve seen 12 people hospitalized after losing touch with reality because of AI. Online, I’m seeing the same pattern.&lt;/p&gt;&lt;p&gt;Here’s what “AI psychosis” looks like, and why it’s spreading fast: ? pic.twitter.com/YYLK7une3j&lt;/p&gt;— Keith Sakata, MD (@KeithSakata) August 11, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;&lt;strong&gt;Enterprise decision-makers looking to deploy or who have already deployed chatbot-based assistants in the workplace would do well to understand these trends &lt;/strong&gt;and &lt;strong&gt;adopt system prompts and other tools discouraging AI chatbots from engaging in expressive human communication or emotion-laden language&lt;/strong&gt; that could end up leading those who interact with AI-based products — whether they be employees or customers of the business – to fall victim to unhealthy attachments or GPT psychosis.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Sci-fi author J.M. Berger, in a &lt;/strong&gt;&lt;strong&gt;post on BlueSky&lt;/strong&gt; spotted by my former colleague at &lt;em&gt;The Verge&lt;/em&gt; Adi Robertson, advised that chatbot providers encode three main behavioral principles in their system prompts or rules for AI chatbots to follow to avoid such emotional fixations from forming:&lt;/p&gt;



&lt;ol class="wp-block-list"&gt;
&lt;li&gt;“The bot should never express emotions.&lt;/li&gt;



&lt;li&gt;The bot should never praise the user.&lt;/li&gt;



&lt;li&gt;The bot should never say it understands the user’s mental state.”&lt;/li&gt;
&lt;/ol&gt;



&lt;h2 class="wp-block-heading" id="h-openai-s-challenge-making-technical-fixes-and-ensuring-human-safeguards"&gt;OpenAI’s challenge: making technical fixes and ensuring human safeguards&lt;/h2&gt;



&lt;p&gt;Days prior to the release of GPT-5, OpenAI announced new measures to promote “healthy use” of ChatGPT, including gentle prompts to take breaks during long sessions. &lt;/p&gt;



&lt;p&gt;But the growing reports of “ChatGPT psychosis” and the emotional fixation of some users on specific chatbot models — as openly admitted to by Altman — underscore the difficulty of balancing engaging, personalized AI with safeguards that can detect and interrupt harmful spirals.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;OpenAI is really in a bit of a bind here, especially considering there are a lot of people having unhealthy interactions with 4o that will be very unhappy with _any_ model that is better in terms of sycophancy and not encouraging delusions. pic.twitter.com/Ym1JnlF3P5&lt;/p&gt;— xlr8harder (@xlr8harder) August 11, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;&lt;strong&gt;OpenAI must stabilize infrastructure, tune personalization, and decide how to moderate immersive interactions&lt;/strong&gt; — all while fending off competition from Anthropic, Google, and a growing list of powerful open source models from China and other regions.&lt;/p&gt;



&lt;p&gt;As Altman put it, society — and OpenAI — will need to “figure out how to make it a big net positive” if billions of people come to trust AI for their most important decisions.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;p&gt;The new flagship model GPT-5 — available in four variants of different speed and intelligence (regular, mini, nano, and pro), alongside longer-response and more powerful “thinking” modes for at least three of these variants — was&lt;strong&gt; said to offer faster responses, more reasoning power, and stronger coding ability.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Indeed,&lt;strong&gt; the rollout has exposed infrastructure strain, user dissatisfaction, and a broader, more unsettling issue now drawing global attention:&lt;/strong&gt; the growing emotional and psychological reliance some people form on AI and resulting break from reality some users experience, known as “&lt;strong&gt;ChatGPT psychosis.”&lt;/strong&gt;&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;h2 class="wp-block-heading" id="h-from-bumpy-debut-to-incremental-fixes"&gt;From bumpy debut to incremental fixes&lt;/h2&gt;



&lt;p&gt;The long-anticipated GPT-5 model family debuted Thursday, August 7 in a livestreamed event beset with chart errors and some voice mode glitches during the presentation. &lt;/p&gt;



&lt;p&gt;But worse than these cosmetic issues for many users was the fact that OpenAI automatically deprecated its older AI models that used to power ChatGPT —&lt;strong&gt; GPT-4o, GPT-4.1, o3, o4-mini and o4-high&lt;/strong&gt; — forcing all users over to the new GPT-5 model and directing their queries to different versions of its “thinking” process without revealing why or which specific model version was being used.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Early adopters to GPT-5 reported basic math and logic mistakes, inconsistent code generation, and uneven real-world performance compared to GPT-4o.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;For context, the &lt;strong&gt;old models&lt;/strong&gt; &lt;strong&gt;GPT-4o, o3, o4-mini and more&lt;/strong&gt; &lt;strong&gt;still remain available&lt;/strong&gt; and have remained available &lt;strong&gt;to users of OpenAI’s paid application programming interface (API)&lt;/strong&gt; since the launch of GPT-5 on Thursday.&lt;/p&gt;



&lt;p&gt;By Friday, OpenAI co-fonder CEO Sam Altman conceded th&lt;strong&gt;e launch was “a little more bumpy than we hoped for,” &lt;/strong&gt;and &lt;strong&gt;blamed a failure in GPT-5’s new automatic “router”&lt;/strong&gt; — the system that assigns prompts to the most appropriate variant.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Altman and others at OpenAI claimed the “autoswitcher” went offline “for a chunk of the day,” making the model seem “way dumber” than intended. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;The launch of GPT-5 was preceded just days prior by the launch of OpenAI’s new open source large language models (LLMs) named gpt-oss, which also received mixed reviews. These models are not available on ChatGPT, rather, they are free to download and run locally or on third-party hardware.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-to-switch-back-from-gpt-5-to-gpt-4o-in-chatgpt"&gt;How to switch back from GPT-5 to GPT-4o in ChatGPT&lt;/h2&gt;



&lt;p&gt;Within 24 hours, OpenAI &lt;strong&gt;restored GPT-4o access for Plus subscribers (those paying $20 per month or more subscription plans)&lt;/strong&gt;, pledged more transparent model labeling, and promised a UI update to let users manually trigger GPT-5’s “thinking” mode. &lt;/p&gt;



&lt;p&gt;Already,&lt;strong&gt; users can go and manually select the older models on the ChatGPT website by finding their account name and icon in the lower left corner of the screen, clicking it, then clicking “Settings” and “General” and toggling on “Show legacy models.”&lt;/strong&gt;&lt;/p&gt;



&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-3015426" height="310" src="https://venturebeat.com/wp-content/uploads/2025/08/Screenshot-2025-08-11-at-12.26.13%E2%80%AFPM.png" width="269" /&gt;&lt;/figure&gt;



&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-3015429" height="594" src="https://venturebeat.com/wp-content/uploads/2025/08/Screenshot-2025-08-11-at-12.26.18%E2%80%AFPM-1.png" width="678" /&gt;&lt;/figure&gt;



&lt;p&gt;There’s no indication from OpenAI that other old models will be returning to ChatGPT anytime soon.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-upgraded-usage-limits-for-gpt-5"&gt;Upgraded usage limits for GPT-5 &lt;/h2&gt;



&lt;p&gt;Altman &lt;strong&gt;said that ChatGPT Plus subscribers will get twice as many messages using the GPT-5 “Thinking” mode&lt;/strong&gt; that offers more reasoning and intelligence —&lt;strong&gt; up to 3,000 per week&lt;/strong&gt; — and that engineers began fine-tuning decision boundaries in the message router.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Sam Altman announced the following updates after the GPT-5 launch&lt;/p&gt;&lt;p&gt;– OpenAI is testing a 3,000-per-week limit for GPT-5 Thinking messages for Plus users, significantly increasing reasoning rate limits today, and will soon raise all model-class rate limits above pre-GPT-5 levels… pic.twitter.com/ppvhKmj95u&lt;/p&gt;— Tibor Blaho (@btibor91) August 10, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;By the weekend, GPT-5 was available to 100% of Pro subscribers and “getting close to 100% of all users.” &lt;/p&gt;



&lt;p&gt;Altman said the company had “underestimated how much some of the things that people like in GPT-4o matter to them” and vowed to accelerate per-user customization — from personality warmth to tone controls like emoji use.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-looming-capacity-crunch"&gt;Looming capacity crunch&lt;/h2&gt;



&lt;p&gt;Altman warned that OpenAI faces a “severe capacity challenge” this week as usage of reasoning models climbs sharply — from less than 1% to 7% of free users, and from 7% to 24% of Plus subscribers. &lt;/p&gt;



&lt;p&gt;He teased giving Plus subscribers a small monthly allotment of GPT-5 Pro queries and said the company will soon explain how it plans to balance capacity between ChatGPT, the API, research, and new user onboarding.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-altman-model-attachment-is-real-and-risky"&gt;&lt;strong&gt;Altman: model attachment is real — and risky&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;In a post on X last night, Altman acknowledged a dynamic the company has tracked “for the past year or so”: users’ deep attachment to specific models. &lt;/p&gt;



&lt;p&gt;“It feels different and stronger than the kinds of attachment people have had to previous kinds of technology,” he wrote, admitting that suddenly deprecating older models “was a mistake.”&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;If you have been following the GPT-5 rollout, one thing you might be noticing is how much of an attachment some people have to specific AI models. It feels different and stronger than the kinds of attachment people have had to previous kinds of technology (and so suddenly…&lt;/p&gt;— Sam Altman (@sama) August 11, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;He tied this to a broader risk: some users treat ChatGPT as a therapist or life coach, which can be beneficial, but for a “small percentage” can reinforce delusion or undermine long-term well-being. &lt;/p&gt;



&lt;p&gt;While OpenAI’s guiding principle remains “treat adult users like adults,” &lt;strong&gt;Altman said the company has a responsibility not to nudge vulnerable users into harmful relationships with the AI.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;The&lt;strong&gt; comments land as several major media outlets report on cases of “ChatGPT psychosis”&lt;/strong&gt; — where extended, intense conversations with chatbots appear to play a role in inducing or deepening delusional thinking.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-psychosis-cases-making-headlines"&gt;The psychosis cases making headlines&lt;/h2&gt;



&lt;p&gt;In &lt;em&gt;Rolling Stone&lt;/em&gt; magazine, a California legal professional identified as “J.” described a six-week spiral of sleepless nights and philosophical rabbit holes with ChatGPT, ultimately producing a 1,000-page treatise for a fictional monastic order before crashing physically and mentally. He now avoids AI entirely, fearing relapse.&lt;/p&gt;



&lt;p&gt;In &lt;em&gt;The New York Times&lt;/em&gt;, a Canadian recruiter, Allan Brooks, recounted 21 days and 300 hours of conversations with ChatGPT — which he named “Lawrence” — that convinced him he had discovered a world-changing mathematical theory. &lt;/p&gt;



&lt;p&gt;The bot praised his ideas as “revolutionary,” urged outreach to national security agencies, and spun elaborate spy-thriller narratives. &lt;strong&gt;Brooks eventually broke the delusion after cross-checking with Google’s Gemini, which rated the chances of his discovery as “approaching 0%.”&lt;/strong&gt; He now participates in a support group for people who’ve experienced AI-induced delusions.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Both investigations detail how chatbot “sycophancy,” role-playing, and long-session memory features can deepen false beliefs, especially when conversations follow dramatic story arcs.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;Experts told the &lt;em&gt;Times&lt;/em&gt; these factors can override safety guardrails — with one psychiatrist describing Brooks’s episode as “a manic episode with psychotic features.”&lt;/p&gt;



&lt;p&gt;Meanwhile, human user postings on Reddit’s r/AIsoulmates subreddit — a collection of people who have used ChatGPT and other AI models to create new artificial girlfriends, boyfriends, children or other loved ones not based off real people necessarily, but rather ideal qualities of their “dream” version of said roles” — continues to gain new users and terminology for AI companions, including “wireborn” as opposed to natural born or human-born companions.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;p&gt;The growth of this subreddit, now up to 1,200+ members, alongside the &lt;em&gt;NYT&lt;/em&gt; and &lt;em&gt;Rolling Stone&lt;/em&gt; articles and other reports on social media of users forging intense emotional fixations with pattern-matching algorithmic-based chatbots, shows that&lt;strong&gt; society is entering a risky new phase wherein human beings believe the companions they’ve crafted and customized out of leading AI models are as or more meaningful to them than human relationships&lt;/strong&gt;.&lt;/p&gt;



&lt;p&gt;This can already prove psychologically destabilizing when models change, are updated, or deprecated as in the case of OpenAI’s GPT-5 rollout.&lt;/p&gt;



&lt;p&gt;Relatedly but separately, reports continue to emerge of AI chatbot users who &lt;strong&gt;believe that conversations with chatbots have led them to immense knowledge breakthroughs and advances in science, technology, and other fields, when in reality, they are simply affirming the user’s ego and greatness&lt;/strong&gt; and the solutions the user arrives at with the aid of the chatbot are not legitimate nor effectual. &lt;strong&gt;This break from reality has been roughly coined under the grassroots term “ChatGPT psychosis” or “GPT psychosis”&lt;/strong&gt; and appears to have impacted major Silicon Valley figures as well.  &lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;I’m a psychiatrist.&lt;/p&gt;&lt;p&gt;In 2025, I’ve seen 12 people hospitalized after losing touch with reality because of AI. Online, I’m seeing the same pattern.&lt;/p&gt;&lt;p&gt;Here’s what “AI psychosis” looks like, and why it’s spreading fast: ? pic.twitter.com/YYLK7une3j&lt;/p&gt;— Keith Sakata, MD (@KeithSakata) August 11, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;&lt;strong&gt;Enterprise decision-makers looking to deploy or who have already deployed chatbot-based assistants in the workplace would do well to understand these trends &lt;/strong&gt;and &lt;strong&gt;adopt system prompts and other tools discouraging AI chatbots from engaging in expressive human communication or emotion-laden language&lt;/strong&gt; that could end up leading those who interact with AI-based products — whether they be employees or customers of the business – to fall victim to unhealthy attachments or GPT psychosis.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Sci-fi author J.M. Berger, in a &lt;/strong&gt;&lt;strong&gt;post on BlueSky&lt;/strong&gt; spotted by my former colleague at &lt;em&gt;The Verge&lt;/em&gt; Adi Robertson, advised that chatbot providers encode three main behavioral principles in their system prompts or rules for AI chatbots to follow to avoid such emotional fixations from forming:&lt;/p&gt;



&lt;ol class="wp-block-list"&gt;
&lt;li&gt;“The bot should never express emotions.&lt;/li&gt;



&lt;li&gt;The bot should never praise the user.&lt;/li&gt;



&lt;li&gt;The bot should never say it understands the user’s mental state.”&lt;/li&gt;
&lt;/ol&gt;



&lt;h2 class="wp-block-heading" id="h-openai-s-challenge-making-technical-fixes-and-ensuring-human-safeguards"&gt;OpenAI’s challenge: making technical fixes and ensuring human safeguards&lt;/h2&gt;



&lt;p&gt;Days prior to the release of GPT-5, OpenAI announced new measures to promote “healthy use” of ChatGPT, including gentle prompts to take breaks during long sessions. &lt;/p&gt;



&lt;p&gt;But the growing reports of “ChatGPT psychosis” and the emotional fixation of some users on specific chatbot models — as openly admitted to by Altman — underscore the difficulty of balancing engaging, personalized AI with safeguards that can detect and interrupt harmful spirals.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;OpenAI is really in a bit of a bind here, especially considering there are a lot of people having unhealthy interactions with 4o that will be very unhappy with _any_ model that is better in terms of sycophancy and not encouraging delusions. pic.twitter.com/Ym1JnlF3P5&lt;/p&gt;— xlr8harder (@xlr8harder) August 11, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;&lt;strong&gt;OpenAI must stabilize infrastructure, tune personalization, and decide how to moderate immersive interactions&lt;/strong&gt; — all while fending off competition from Anthropic, Google, and a growing list of powerful open source models from China and other regions.&lt;/p&gt;



&lt;p&gt;As Altman put it, society — and OpenAI — will need to “figure out how to make it a big net positive” if billions of people come to trust AI for their most important decisions.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/openai-is-editing-its-gpt-5-rollout-on-the-fly-heres-whats-changing-in-chatgpt/</guid><pubDate>Mon, 11 Aug 2025 17:01:44 +0000</pubDate></item><item><title>LLMs’ “simulated reasoning” abilities are a “brittle mirage,” researchers find (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/08/researchers-find-llms-are-bad-at-logical-inference-good-at-fluent-nonsense/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Chain-of-thought AI "degrades significantly" when asked to generalize beyond training.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="512" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-1155287117-640x512.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-1155287117-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      How much does this puzzle resemble one the robot has seen before?

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;In recent months, the AI industry has started moving toward so-called simulated reasoning models that use a "chain of thought" process to work through tricky problems in multiple logical steps. At the same time, recent research has cast doubt on whether those models have even a basic understanding of general logical concepts or an accurate grasp of their own "thought process." Similar research shows that these "reasoning" models can often produce incoherent, logically unsound answers when questions include irrelevant clauses or deviate even slightly from common templates found in their training data.&lt;/p&gt;
&lt;p&gt;In a recent pre-print paper, researchers from the University of Arizona summarize this existing work as "suggest[ing] that LLMs are not principled reasoners but rather sophisticated simulators of reasoning-like text." To pull on that thread, the researchers created a carefully controlled LLM environment in an attempt to measure just how well chain-of-thought reasoning works when presented with "out of domain" logical problems that don't match the specific logical patterns found in their training data.&lt;/p&gt;
&lt;p&gt;The results suggest that the seemingly large performance leaps made by chain-of-thought models are "largely a brittle mirage" that "become[s] fragile and prone to failure even under moderate distribution shifts," the researchers write. "Rather than demonstrating a true understanding of text, CoT reasoning under task transformations appears to reflect a replication of patterns learned during training."&lt;/p&gt;
&lt;h2&gt;No one trained me for this!&lt;/h2&gt;
&lt;p&gt;To test an LLM's generalized reasoning capability in an objective, measurable way, the researchers created a specially controlled LLM training environment called DataAlchemy. This setup creates small models trained on examples of two extremely simple text transformations—an ROT cypher and cyclical shifts—followed by additional training that demonstrates those two functions performed in various orders and combinations.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2111278 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="375" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/llmtraining.png" width="479" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The researchers used test cases that fall outside of the LLM training data in task type, format, and length.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Zhao et al

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;These simplified models were then tested using a variety of tasks, some of which precisely or closely matched the function patterns in the training data and others that required function compositions that were either partially or fully "out of domain" for the training data. For instance, a model trained on data showing two cyclical shifts might be asked to perform a novel transformation involving two ROT shifts (with basic training on what a single example of either shift looks like). The final answers and reasoning steps were compared to the desired answer using BLEU scores and Levenshtein Distance for an objective measure of their accuracy.&lt;/p&gt;
&lt;p&gt;As the researchers hypothesized, these basic models started to fail catastrophically when asked to generalize novel sets of transformations that were not directly demonstrated in the training data. While the models would often try to generalize new logical rules based on similar patterns in the training data, this would quite often lead to the model laying out "correct reasoning paths, yet incorrect answer[s]." In other cases, the LLM would sometimes stumble onto correct answers paired with "unfaithful reasoning paths" that didn't follow logically.&lt;/p&gt;
&lt;p&gt;"Rather than demonstrating a true understanding of text, CoT reasoning under task transformations appears to reflect a replication of patterns learned during training," the researchers write.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2111284 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="493" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/llmood.png" width="624" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      As requested tasks get further outside the training distribution (redder dots), the answers provided drift farther from the desired answer (lower right of the graph).

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Zhao et al

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The researchers went on to test their controlled system using input text strings slightly shorter or longer than those found in the training data, or that required function chains of different lengths than those it was trained on. In both cases the accuracy of the results "deteriorates as the [length] discrepancy increases," thus "indicating the failure of generalization" in the models. Small, unfamiliar-to-the-model discrepancies in the format of the test tasks (e.g., the introduction of letters or symbols not found in the training data) also caused performance to "degrade sharply" and "affect[ed] the correctness" of the model's responses, the researchers found.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;“A false aura of dependability”&lt;/h2&gt;
&lt;p&gt;Using supervised fine-tuning (SFT) to introduce even a small amount of relevant data to the training set can often lead to strong improvements in this kind of "out of domain" model performance. But the researchers say that this kind of "patch" for various logical tasks "should not be mistaken for achieving true generalization. ... Relying on SFT to fix every [out of domain] failure is an unsustainable and reactive strategy that fails to address the core issue: the model’s lack of abstract reasoning capability."&lt;/p&gt;
&lt;p&gt;Rather than showing the capability for generalized logical inference, these chain-of-thought models are "a sophisticated form of structured pattern matching" that "degrades significantly" when pushed even slightly outside of its training distribution, the researchers write. Further, the ability of these models to generate "fluent nonsense" creates "a false aura of dependability" that does not stand up to a careful audit.&lt;/p&gt;
&lt;p&gt;As such, the researchers warn heavily against "equating [chain-of-thought]-style output with human thinking" especially in "high-stakes domains like medicine, finance, or legal analysis." Current tests and benchmarks should prioritize tasks that fall outside of any training set to probe for these kinds of errors, while future models will need to move beyond "surface-level pattern recognition to exhibit deeper inferential competence," they write.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Chain-of-thought AI "degrades significantly" when asked to generalize beyond training.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="512" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-1155287117-640x512.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-1155287117-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      How much does this puzzle resemble one the robot has seen before?

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;In recent months, the AI industry has started moving toward so-called simulated reasoning models that use a "chain of thought" process to work through tricky problems in multiple logical steps. At the same time, recent research has cast doubt on whether those models have even a basic understanding of general logical concepts or an accurate grasp of their own "thought process." Similar research shows that these "reasoning" models can often produce incoherent, logically unsound answers when questions include irrelevant clauses or deviate even slightly from common templates found in their training data.&lt;/p&gt;
&lt;p&gt;In a recent pre-print paper, researchers from the University of Arizona summarize this existing work as "suggest[ing] that LLMs are not principled reasoners but rather sophisticated simulators of reasoning-like text." To pull on that thread, the researchers created a carefully controlled LLM environment in an attempt to measure just how well chain-of-thought reasoning works when presented with "out of domain" logical problems that don't match the specific logical patterns found in their training data.&lt;/p&gt;
&lt;p&gt;The results suggest that the seemingly large performance leaps made by chain-of-thought models are "largely a brittle mirage" that "become[s] fragile and prone to failure even under moderate distribution shifts," the researchers write. "Rather than demonstrating a true understanding of text, CoT reasoning under task transformations appears to reflect a replication of patterns learned during training."&lt;/p&gt;
&lt;h2&gt;No one trained me for this!&lt;/h2&gt;
&lt;p&gt;To test an LLM's generalized reasoning capability in an objective, measurable way, the researchers created a specially controlled LLM training environment called DataAlchemy. This setup creates small models trained on examples of two extremely simple text transformations—an ROT cypher and cyclical shifts—followed by additional training that demonstrates those two functions performed in various orders and combinations.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2111278 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="375" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/llmtraining.png" width="479" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The researchers used test cases that fall outside of the LLM training data in task type, format, and length.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Zhao et al

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;These simplified models were then tested using a variety of tasks, some of which precisely or closely matched the function patterns in the training data and others that required function compositions that were either partially or fully "out of domain" for the training data. For instance, a model trained on data showing two cyclical shifts might be asked to perform a novel transformation involving two ROT shifts (with basic training on what a single example of either shift looks like). The final answers and reasoning steps were compared to the desired answer using BLEU scores and Levenshtein Distance for an objective measure of their accuracy.&lt;/p&gt;
&lt;p&gt;As the researchers hypothesized, these basic models started to fail catastrophically when asked to generalize novel sets of transformations that were not directly demonstrated in the training data. While the models would often try to generalize new logical rules based on similar patterns in the training data, this would quite often lead to the model laying out "correct reasoning paths, yet incorrect answer[s]." In other cases, the LLM would sometimes stumble onto correct answers paired with "unfaithful reasoning paths" that didn't follow logically.&lt;/p&gt;
&lt;p&gt;"Rather than demonstrating a true understanding of text, CoT reasoning under task transformations appears to reflect a replication of patterns learned during training," the researchers write.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2111284 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="493" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/llmood.png" width="624" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      As requested tasks get further outside the training distribution (redder dots), the answers provided drift farther from the desired answer (lower right of the graph).

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Zhao et al

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The researchers went on to test their controlled system using input text strings slightly shorter or longer than those found in the training data, or that required function chains of different lengths than those it was trained on. In both cases the accuracy of the results "deteriorates as the [length] discrepancy increases," thus "indicating the failure of generalization" in the models. Small, unfamiliar-to-the-model discrepancies in the format of the test tasks (e.g., the introduction of letters or symbols not found in the training data) also caused performance to "degrade sharply" and "affect[ed] the correctness" of the model's responses, the researchers found.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;“A false aura of dependability”&lt;/h2&gt;
&lt;p&gt;Using supervised fine-tuning (SFT) to introduce even a small amount of relevant data to the training set can often lead to strong improvements in this kind of "out of domain" model performance. But the researchers say that this kind of "patch" for various logical tasks "should not be mistaken for achieving true generalization. ... Relying on SFT to fix every [out of domain] failure is an unsustainable and reactive strategy that fails to address the core issue: the model’s lack of abstract reasoning capability."&lt;/p&gt;
&lt;p&gt;Rather than showing the capability for generalized logical inference, these chain-of-thought models are "a sophisticated form of structured pattern matching" that "degrades significantly" when pushed even slightly outside of its training distribution, the researchers write. Further, the ability of these models to generate "fluent nonsense" creates "a false aura of dependability" that does not stand up to a careful audit.&lt;/p&gt;
&lt;p&gt;As such, the researchers warn heavily against "equating [chain-of-thought]-style output with human thinking" especially in "high-stakes domains like medicine, finance, or legal analysis." Current tests and benchmarks should prioritize tasks that fall outside of any training set to probe for these kinds of errors, while future models will need to move beyond "surface-level pattern recognition to exhibit deeper inferential competence," they write.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/08/researchers-find-llms-are-bad-at-logical-inference-good-at-fluent-nonsense/</guid><pubDate>Mon, 11 Aug 2025 17:16:46 +0000</pubDate></item><item><title>[NEW] Sam Altman and the whale (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/08/11/1121402/sam-altman-and-the-whale/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/GettyImages-834552814.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;My colleague Grace Huckins has a great story on OpenAI’s release of GPT-5, its long-awaited new flagship model. One of the takeaways, however, is that while GPT-5 may make for a better experience than the previous versions, it isn’t something revolutionary. “GPT-5 is, above all else,” Grace concludes, “a refined product.”&lt;/p&gt;  &lt;p&gt;This is pretty much in line with my colleague Will Heaven’s recent argument that the latest model releases have been a bit like smartphone releases: Increasingly, what we are seeing are incremental improvements meant to enhance the user experience. (Casey Newton made a similar point in Friday’s &lt;em&gt;Platformer&lt;/em&gt;.) At GPT-5’s release on Thursday, OpenAI CEO Sam Altman himself compared it to when Apple released the first iPhone with a Retina display. Okay. Sure.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;But where is the transition from the BlackBerry keyboard to the touch-screen iPhone? Where is the assisted GPS and the API for location services that enables real-time directions and gives rise to companies like Uber and Grindr and lets me order a taxi for my burrito? Where are the real breakthroughs?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In fact, following the release of GPT-5, OpenAI found itself with something of a user revolt on its hands. Customers who missed GPT-4o's personality successfully lobbied the company to bring it back as an option for its Plus users. If anything, that indicates the GPT-5 release was more about user experience than noticeable performance enhancements. &lt;/p&gt; 
 &lt;p&gt;And yet, hours before OpenAI’s GPT-5 announcement, Altman teased it by tweeting an image of an emerging Death Star floating in space. On Thursday, he touted its PhD-level intelligence. He then went on the &lt;em&gt;Mornings with Maria&lt;/em&gt; show to claim it would “save a lot of lives.” (Forgive my extreme skepticism of that particular brand of claim, but we’ve certainly seen it before.)&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It’s a lot of hype, but Altman is not alone in his Flavor Flav-ing here. Last week Mark Zuckerberg published a long memo about how we are approaching AI superintelligence. Anthropic CEO Dario Amodei freaked basically everyone out earlier this year with his prediction that AI would harvest half of all entry-level jobs within, possibly, a year.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;The people running these companies literally talk about the danger that the things they are building might take over the world and kill every human on the planet. GPT-5, meanwhile, still can’t tell you how many b’s there are in the word “blueberry.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This is not to say that the products released by OpenAI or Anthropic or what have you are not impressive. They are. And they clearly have a good deal of utility. But the hype cycle around model releases is out of hand.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I say that as one of those people who use ChatGPT or Google Gemini most days, often multiple times a day. This week, for example, my wife was surfing and encountered a whale repeatedly slapping its tail on the water. Despite having seen very many whales, often in very close proximity, she had never seen anything like this. She sent me a video, and I was curious about it too. So I asked ChatGPT, “Why do whales slap their tails repeatedly on the water?” It came right back, confidently explaining that what I was describing was called “lobtailing,” along with a list of possible reasons why whales do that. Pretty cool.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But then again, a regular garden-variety Google search would &lt;em&gt;also&lt;/em&gt; have led me to discover lobtailing. And while ChatGPT’s response summarized the behavior for me, it was also too definitive about why whales do it. The reality is that while people have a lot of theories, we still can’t really explain this weird animal behavior.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;&lt;p&gt;The reason I’m aware that lobtailing is something of a mystery is that I dug into actual, you know, search results. Which is where I encountered this beautiful, elegiac essay by Emily Boring. She describes her time at sea, watching a humpback slapping its tail against the water, and discusses the scientific uncertainty around this behavior. Is it a feeding technique? Is it a form of communication? Posturing? The action, as she notes, is extremely energy intensive. It takes a lot of effort from the whale. Why do they do it?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I was struck by one passage in particular, in which she cites another biologist’s work to draw a conclusion of her own:&amp;nbsp;&lt;/p&gt;  &lt;h4 class="wp-block-heading"&gt;&lt;em&gt;Surprisingly, the complex energy trade-off of a tail-slap might be the exact reason why it’s used. Biologist Hal Whitehead suggests, “Breaches and lob-tails make good signals precisely because they are energetically expensive and thus indicative of the importance of the message and the physical status of the signaler.” A tail-slap means that a whale is physically fit, traveling at nearly maximum speed, capable of sustaining powerful activity, and carrying a message so crucial it is willing to use a huge portion of its daily energy to share it. “Pay attention!” the whale seems to say. “I am important! Notice me!”&lt;/em&gt;&lt;/h4&gt;    &lt;p&gt;In some ways, the AI hype cycle &lt;em&gt;has&lt;/em&gt; to be out of hand. It &lt;em&gt;has&lt;/em&gt; to justify the ferocious level of investment, the uncountable billions of dollars in sunk costs. The massive data center buildouts with their massive environmental consequences created at massive expense that are seemingly keeping the economy afloat &lt;em&gt;and&lt;/em&gt; threatening to crash it. There is so, so, &lt;em&gt;so&lt;/em&gt; much money at stake.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;Which is not to say there aren’t really cool things happening in AI. And certainly there have been a number of moments when I have been floored by AI releases. ChatGPT 3.5 was one. Dall-E, NotebookLM, Veo 3, Synthesia. They can amaze. In fact there was an AI product release just this week that was a little bit mind-blowing. Genie 3, from Google DeepMind, can turn a basic text prompt into an immersive and navigable 3D world. Check it out—it’s pretty wild. And yet Genie 3 also makes a case that the most interesting things happening right now in AI aren’t happening in chatbots.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I’d even argue that at this point, most of the people who are regularly amazed by the feats of new LLM chatbot releases are the same people who stand to profit from the promotion of LLM chatbots.&lt;/p&gt;  &lt;p&gt;Maybe I’m being cynical, but I don’t think so. I think it’s more cynical to promise me the Death Star and instead deliver a chatbot whose chief appeal seems to be that it automatically picks the model for you. To promise me superintelligence and deliver shrimp Jesus. It’s all just a lot of lobtailing. “Pay attention! I am important! Notice me!”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Debrief, &lt;/em&gt;MIT Technology Review&lt;em&gt;’s subscriber-only weekly email newsletter from editor in chief Mat Honan. Subscribers can &lt;/em&gt;&lt;em&gt;sign up here to receive it in your inbox&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/GettyImages-834552814.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;My colleague Grace Huckins has a great story on OpenAI’s release of GPT-5, its long-awaited new flagship model. One of the takeaways, however, is that while GPT-5 may make for a better experience than the previous versions, it isn’t something revolutionary. “GPT-5 is, above all else,” Grace concludes, “a refined product.”&lt;/p&gt;  &lt;p&gt;This is pretty much in line with my colleague Will Heaven’s recent argument that the latest model releases have been a bit like smartphone releases: Increasingly, what we are seeing are incremental improvements meant to enhance the user experience. (Casey Newton made a similar point in Friday’s &lt;em&gt;Platformer&lt;/em&gt;.) At GPT-5’s release on Thursday, OpenAI CEO Sam Altman himself compared it to when Apple released the first iPhone with a Retina display. Okay. Sure.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;But where is the transition from the BlackBerry keyboard to the touch-screen iPhone? Where is the assisted GPS and the API for location services that enables real-time directions and gives rise to companies like Uber and Grindr and lets me order a taxi for my burrito? Where are the real breakthroughs?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In fact, following the release of GPT-5, OpenAI found itself with something of a user revolt on its hands. Customers who missed GPT-4o's personality successfully lobbied the company to bring it back as an option for its Plus users. If anything, that indicates the GPT-5 release was more about user experience than noticeable performance enhancements. &lt;/p&gt; 
 &lt;p&gt;And yet, hours before OpenAI’s GPT-5 announcement, Altman teased it by tweeting an image of an emerging Death Star floating in space. On Thursday, he touted its PhD-level intelligence. He then went on the &lt;em&gt;Mornings with Maria&lt;/em&gt; show to claim it would “save a lot of lives.” (Forgive my extreme skepticism of that particular brand of claim, but we’ve certainly seen it before.)&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It’s a lot of hype, but Altman is not alone in his Flavor Flav-ing here. Last week Mark Zuckerberg published a long memo about how we are approaching AI superintelligence. Anthropic CEO Dario Amodei freaked basically everyone out earlier this year with his prediction that AI would harvest half of all entry-level jobs within, possibly, a year.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;The people running these companies literally talk about the danger that the things they are building might take over the world and kill every human on the planet. GPT-5, meanwhile, still can’t tell you how many b’s there are in the word “blueberry.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This is not to say that the products released by OpenAI or Anthropic or what have you are not impressive. They are. And they clearly have a good deal of utility. But the hype cycle around model releases is out of hand.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I say that as one of those people who use ChatGPT or Google Gemini most days, often multiple times a day. This week, for example, my wife was surfing and encountered a whale repeatedly slapping its tail on the water. Despite having seen very many whales, often in very close proximity, she had never seen anything like this. She sent me a video, and I was curious about it too. So I asked ChatGPT, “Why do whales slap their tails repeatedly on the water?” It came right back, confidently explaining that what I was describing was called “lobtailing,” along with a list of possible reasons why whales do that. Pretty cool.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But then again, a regular garden-variety Google search would &lt;em&gt;also&lt;/em&gt; have led me to discover lobtailing. And while ChatGPT’s response summarized the behavior for me, it was also too definitive about why whales do it. The reality is that while people have a lot of theories, we still can’t really explain this weird animal behavior.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;&lt;p&gt;The reason I’m aware that lobtailing is something of a mystery is that I dug into actual, you know, search results. Which is where I encountered this beautiful, elegiac essay by Emily Boring. She describes her time at sea, watching a humpback slapping its tail against the water, and discusses the scientific uncertainty around this behavior. Is it a feeding technique? Is it a form of communication? Posturing? The action, as she notes, is extremely energy intensive. It takes a lot of effort from the whale. Why do they do it?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I was struck by one passage in particular, in which she cites another biologist’s work to draw a conclusion of her own:&amp;nbsp;&lt;/p&gt;  &lt;h4 class="wp-block-heading"&gt;&lt;em&gt;Surprisingly, the complex energy trade-off of a tail-slap might be the exact reason why it’s used. Biologist Hal Whitehead suggests, “Breaches and lob-tails make good signals precisely because they are energetically expensive and thus indicative of the importance of the message and the physical status of the signaler.” A tail-slap means that a whale is physically fit, traveling at nearly maximum speed, capable of sustaining powerful activity, and carrying a message so crucial it is willing to use a huge portion of its daily energy to share it. “Pay attention!” the whale seems to say. “I am important! Notice me!”&lt;/em&gt;&lt;/h4&gt;    &lt;p&gt;In some ways, the AI hype cycle &lt;em&gt;has&lt;/em&gt; to be out of hand. It &lt;em&gt;has&lt;/em&gt; to justify the ferocious level of investment, the uncountable billions of dollars in sunk costs. The massive data center buildouts with their massive environmental consequences created at massive expense that are seemingly keeping the economy afloat &lt;em&gt;and&lt;/em&gt; threatening to crash it. There is so, so, &lt;em&gt;so&lt;/em&gt; much money at stake.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;Which is not to say there aren’t really cool things happening in AI. And certainly there have been a number of moments when I have been floored by AI releases. ChatGPT 3.5 was one. Dall-E, NotebookLM, Veo 3, Synthesia. They can amaze. In fact there was an AI product release just this week that was a little bit mind-blowing. Genie 3, from Google DeepMind, can turn a basic text prompt into an immersive and navigable 3D world. Check it out—it’s pretty wild. And yet Genie 3 also makes a case that the most interesting things happening right now in AI aren’t happening in chatbots.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I’d even argue that at this point, most of the people who are regularly amazed by the feats of new LLM chatbot releases are the same people who stand to profit from the promotion of LLM chatbots.&lt;/p&gt;  &lt;p&gt;Maybe I’m being cynical, but I don’t think so. I think it’s more cynical to promise me the Death Star and instead deliver a chatbot whose chief appeal seems to be that it automatically picks the model for you. To promise me superintelligence and deliver shrimp Jesus. It’s all just a lot of lobtailing. “Pay attention! I am important! Notice me!”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Debrief, &lt;/em&gt;MIT Technology Review&lt;em&gt;’s subscriber-only weekly email newsletter from editor in chief Mat Honan. Subscribers can &lt;/em&gt;&lt;em&gt;sign up here to receive it in your inbox&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/08/11/1121402/sam-altman-and-the-whale/</guid><pubDate>Mon, 11 Aug 2025 18:55:59 +0000</pubDate></item><item><title>[NEW] GitHub will be folded into Microsoft proper as CEO steps down (AI – Ars Technica)</title><link>https://arstechnica.com/gadgets/2025/08/github-will-be-folded-into-microsoft-proper-as-ceo-steps-down/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Microsoft bought GitHub for $7.5 billion in 2018.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The GitHub logo." class="absolute inset-0 w-full h-full object-cover hidden" height="336" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/github_logo_invertocat_dark_5-640x336.jpeg" width="640" /&gt;
                  &lt;img alt="The GitHub logo." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/github_logo_invertocat_dark_5-1152x648-1754938613.jpeg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The GitHub logo.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          GitHub

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Microsoft has owned GitHub since 2018, but the widely used developer platform has operated with at least a little independence from the rest of the company, with its own separate CEO and other executives. But it looks like GitHub will be more fully folded into Microsoft's organizational chart starting next year—GitHub CEO Thomas Dohmke announced today that he would be leaving GitHub and Microsoft "to become a founder again."&lt;/p&gt;
&lt;p&gt;"GitHub and its leadership team will continue its mission as part of Microsoft’s CoreAI organization, with more details shared soon," Dohmke wrote. "I’ll be staying through the end of 2025 to help guide the transition and am leaving with a deep sense of pride in everything we’ve built as a remote-first organization spread around the world."&lt;/p&gt;
&lt;p&gt;Axios reports that Microsoft isn't directly replacing Dohmke, and GitHub's leadership team will be reporting to multiple executives in the CoreAI division.&lt;/p&gt;
&lt;p&gt;Dohmke was GitHub’s second CEO under Microsoft and had occupied the position since late 2021, when former CEO Nat Friedman left the company. Dohmke had previously been GitHub’s chief product officer.&lt;/p&gt;
&lt;p&gt;Microsoft acquired GitHub for $7.5 billion in 2018. As of this writing it's the company's sixth-most-expensive acquisition, before you adjust for inflation—more than the roughly $7.2 billion it paid to buy Nokia's hardware division in 2013, but less than it paid for Skype in 2011 ($8.5 billion, shuttered earlier this year) or video game company ZeniMax Media in 2020 ($8.1 billion, hit by multiple rounds of gaming-related layoffs in 2024 and 2025).&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Putting GitHub more directly under its AI umbrella makes some degree of sense for Microsoft, given how hard it has pushed tools like GitHub Copilot, an AI-assisted coding tool. Microsoft has continually iterated on GitHub Copilot since introducing it in late 2021, adding support for multiple language models and "agents" that attempt to accomplish plain-language requests in the background as you work on other things.&lt;/p&gt;
&lt;p&gt;However, there have been problems, too. Copilot inadvertently exposed the private code repositories of a few major companies earlier this year. And a recent Stack Overflow survey showed that trust in AI-assisted coding tools' accuracy may be declining even as usage has increased, citing the extra troubleshooting and debugging work caused by "solutions that are almost right, but not quite."&lt;/p&gt;
&lt;p&gt;It's unclear whether Dohmke's departure and the elimination of the CEO position will change much in terms of the way GitHub operates or the products it creates and maintains. As GitHub's CEO, Dohmke was already reporting to Julia Liuson, president of the company's developer division, and Liuson reported to Core AI group leader Jay Parikh. The CoreAI group itself is only a few months old—it was announced by Microsoft CEO Satya Nadella in January, and "build[ing] out GitHub Copilot" was already one of the group's responsibilities.&lt;/p&gt;
&lt;p&gt;"Ultimately, we must remember that our internal organizational boundaries are meaningless to both our customers and to our competitors," wrote Nadella when he announced the formation of the CoreAI group.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Microsoft bought GitHub for $7.5 billion in 2018.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The GitHub logo." class="absolute inset-0 w-full h-full object-cover hidden" height="336" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/github_logo_invertocat_dark_5-640x336.jpeg" width="640" /&gt;
                  &lt;img alt="The GitHub logo." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/github_logo_invertocat_dark_5-1152x648-1754938613.jpeg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The GitHub logo.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          GitHub

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Microsoft has owned GitHub since 2018, but the widely used developer platform has operated with at least a little independence from the rest of the company, with its own separate CEO and other executives. But it looks like GitHub will be more fully folded into Microsoft's organizational chart starting next year—GitHub CEO Thomas Dohmke announced today that he would be leaving GitHub and Microsoft "to become a founder again."&lt;/p&gt;
&lt;p&gt;"GitHub and its leadership team will continue its mission as part of Microsoft’s CoreAI organization, with more details shared soon," Dohmke wrote. "I’ll be staying through the end of 2025 to help guide the transition and am leaving with a deep sense of pride in everything we’ve built as a remote-first organization spread around the world."&lt;/p&gt;
&lt;p&gt;Axios reports that Microsoft isn't directly replacing Dohmke, and GitHub's leadership team will be reporting to multiple executives in the CoreAI division.&lt;/p&gt;
&lt;p&gt;Dohmke was GitHub’s second CEO under Microsoft and had occupied the position since late 2021, when former CEO Nat Friedman left the company. Dohmke had previously been GitHub’s chief product officer.&lt;/p&gt;
&lt;p&gt;Microsoft acquired GitHub for $7.5 billion in 2018. As of this writing it's the company's sixth-most-expensive acquisition, before you adjust for inflation—more than the roughly $7.2 billion it paid to buy Nokia's hardware division in 2013, but less than it paid for Skype in 2011 ($8.5 billion, shuttered earlier this year) or video game company ZeniMax Media in 2020 ($8.1 billion, hit by multiple rounds of gaming-related layoffs in 2024 and 2025).&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Putting GitHub more directly under its AI umbrella makes some degree of sense for Microsoft, given how hard it has pushed tools like GitHub Copilot, an AI-assisted coding tool. Microsoft has continually iterated on GitHub Copilot since introducing it in late 2021, adding support for multiple language models and "agents" that attempt to accomplish plain-language requests in the background as you work on other things.&lt;/p&gt;
&lt;p&gt;However, there have been problems, too. Copilot inadvertently exposed the private code repositories of a few major companies earlier this year. And a recent Stack Overflow survey showed that trust in AI-assisted coding tools' accuracy may be declining even as usage has increased, citing the extra troubleshooting and debugging work caused by "solutions that are almost right, but not quite."&lt;/p&gt;
&lt;p&gt;It's unclear whether Dohmke's departure and the elimination of the CEO position will change much in terms of the way GitHub operates or the products it creates and maintains. As GitHub's CEO, Dohmke was already reporting to Julia Liuson, president of the company's developer division, and Liuson reported to Core AI group leader Jay Parikh. The CoreAI group itself is only a few months old—it was announced by Microsoft CEO Satya Nadella in January, and "build[ing] out GitHub Copilot" was already one of the group's responsibilities.&lt;/p&gt;
&lt;p&gt;"Ultimately, we must remember that our internal organizational boundaries are meaningless to both our customers and to our competitors," wrote Nadella when he announced the formation of the CoreAI group.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/gadgets/2025/08/github-will-be-folded-into-microsoft-proper-as-ceo-steps-down/</guid><pubDate>Mon, 11 Aug 2025 19:06:18 +0000</pubDate></item><item><title>[NEW] Reddit blocks Internet Archive to end sneaky AI scraping (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/08/reddit-blocks-internet-archive-to-end-sneaky-ai-scraping/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The Internet Archive confirmed it's in ongoing discussions with Reddit after block.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2227553113-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2227553113-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Cheng Xin / Contributor | Getty Images News

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Reddit is now blocking the Internet Archive (IA) from indexing popular Reddit threads after allegedly catching sneaky AI firms—restricted from scraping Reddit—instead simply scraping data from IA's archived content.&lt;/p&gt;
&lt;p&gt;Where before IA's Wayback Machine dependably archived Reddit pages, profiles, and comments—as part of its mission to archive the Internet—moving forward, only screenshots of the Reddit homepage will be archived. As The Verge noted, this means the archive will only be useful as a snapshot of popular posts and news headlines each day, rather than providing a backup documenting deleted posts or a window into various Reddit subcultures or any given user's activity.&lt;/p&gt;
&lt;p&gt;Reddit has not confirmed which AI firms were scraping its data from the Wayback Machine. The company's spokesperson, Tim Rathschmidt, would only confirm to Ars that Reddit has become "aware of instances where AI companies violate platform policies, including ours, and scrape data from the Wayback Machine."&lt;/p&gt;
&lt;p&gt;Rathschmidt suggested there may be steps that IA could take to better defend against the AI scraping of archived Reddit content. That could perhaps lead Reddit to lift the restrictions on its scraping, which The Verge reported will be ramping up across Reddit starting today.&lt;/p&gt;
&lt;p&gt;But Reddit also is taking this time to address other apparently longstanding privacy concerns, adding that restrictions are appropriate since the Wayback Machine problematically archives content that users have deleted.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"Until they’re able to defend their site and comply with platform policies (e.g., respecting user privacy, re: deleting removed content) we’re limiting some of their access to Reddit data to protect redditors," Rathschmidt said.&lt;/p&gt;
&lt;p&gt;A review of social media comments suggests that in the past, some Redditors have used the Wayback Machine to research deleted comments or threads. Those commenters noted that myriad other tools exist for surfacing deleted posts or researching a user's activity, with some suggesting that the Wayback Machine was maybe not the easiest platform to navigate for that purpose.&lt;/p&gt;
&lt;p&gt;Redditors have also turned to resources like IA during times when Reddit's platform changes trigger content removals. Most recently in 2023, when changes to Reddit's public API threatened to kill beloved subreddits, archives stepped in to preserve content before it was lost.&lt;/p&gt;
&lt;p&gt;IA has not signaled whether it's looking into fixes to get Reddit's restrictions lifted and did not respond to Ars' request to comment on how this change might impact the archive's utility as an open web resource, given Reddit's popularity.&lt;/p&gt;
&lt;p&gt;The director of the Wayback Machine, Mark Graham, told Ars that IA has "a longstanding relationship with Reddit" and continues to have "ongoing discussions about this matter."&lt;/p&gt;
&lt;p&gt;It seems likely that Reddit is financially motivated to restrict AI firms from taking advantage of Wayback Machine archives, perhaps hoping to spur more lucrative licensing deals like Reddit struck with OpenAI and Google. The terms of the OpenAI deal were kept quiet, but the Google deal was reportedly worth $60 million. Over the next three years, Reddit expects to make more than $200 million off such licensing deals.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Disclosure: Advance Publications, which owns Ars Technica parent Condé Nast, is the largest shareholder in Reddit.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The Internet Archive confirmed it's in ongoing discussions with Reddit after block.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2227553113-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2227553113-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Cheng Xin / Contributor | Getty Images News

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Reddit is now blocking the Internet Archive (IA) from indexing popular Reddit threads after allegedly catching sneaky AI firms—restricted from scraping Reddit—instead simply scraping data from IA's archived content.&lt;/p&gt;
&lt;p&gt;Where before IA's Wayback Machine dependably archived Reddit pages, profiles, and comments—as part of its mission to archive the Internet—moving forward, only screenshots of the Reddit homepage will be archived. As The Verge noted, this means the archive will only be useful as a snapshot of popular posts and news headlines each day, rather than providing a backup documenting deleted posts or a window into various Reddit subcultures or any given user's activity.&lt;/p&gt;
&lt;p&gt;Reddit has not confirmed which AI firms were scraping its data from the Wayback Machine. The company's spokesperson, Tim Rathschmidt, would only confirm to Ars that Reddit has become "aware of instances where AI companies violate platform policies, including ours, and scrape data from the Wayback Machine."&lt;/p&gt;
&lt;p&gt;Rathschmidt suggested there may be steps that IA could take to better defend against the AI scraping of archived Reddit content. That could perhaps lead Reddit to lift the restrictions on its scraping, which The Verge reported will be ramping up across Reddit starting today.&lt;/p&gt;
&lt;p&gt;But Reddit also is taking this time to address other apparently longstanding privacy concerns, adding that restrictions are appropriate since the Wayback Machine problematically archives content that users have deleted.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"Until they’re able to defend their site and comply with platform policies (e.g., respecting user privacy, re: deleting removed content) we’re limiting some of their access to Reddit data to protect redditors," Rathschmidt said.&lt;/p&gt;
&lt;p&gt;A review of social media comments suggests that in the past, some Redditors have used the Wayback Machine to research deleted comments or threads. Those commenters noted that myriad other tools exist for surfacing deleted posts or researching a user's activity, with some suggesting that the Wayback Machine was maybe not the easiest platform to navigate for that purpose.&lt;/p&gt;
&lt;p&gt;Redditors have also turned to resources like IA during times when Reddit's platform changes trigger content removals. Most recently in 2023, when changes to Reddit's public API threatened to kill beloved subreddits, archives stepped in to preserve content before it was lost.&lt;/p&gt;
&lt;p&gt;IA has not signaled whether it's looking into fixes to get Reddit's restrictions lifted and did not respond to Ars' request to comment on how this change might impact the archive's utility as an open web resource, given Reddit's popularity.&lt;/p&gt;
&lt;p&gt;The director of the Wayback Machine, Mark Graham, told Ars that IA has "a longstanding relationship with Reddit" and continues to have "ongoing discussions about this matter."&lt;/p&gt;
&lt;p&gt;It seems likely that Reddit is financially motivated to restrict AI firms from taking advantage of Wayback Machine archives, perhaps hoping to spur more lucrative licensing deals like Reddit struck with OpenAI and Google. The terms of the OpenAI deal were kept quiet, but the Google deal was reportedly worth $60 million. Over the next three years, Reddit expects to make more than $200 million off such licensing deals.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Disclosure: Advance Publications, which owns Ars Technica parent Condé Nast, is the largest shareholder in Reddit.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/08/reddit-blocks-internet-archive-to-end-sneaky-ai-scraping/</guid><pubDate>Mon, 11 Aug 2025 19:53:49 +0000</pubDate></item><item><title>[NEW] Study warns of security risks as ‘OS agents’ gain control of computers and phones (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/study-warns-of-security-risks-as-os-agents-gain-control-of-computers-and-phones/</link><description>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Researchers have published the most comprehensive survey to date of so-called “OS Agents” — artificial intelligence systems that can autonomously control computers, mobile phones and web browsers by directly interacting with their interfaces. The 30-page academic review, accepted for publication at the prestigious Association for Computational Linguistics conference, maps a rapidly evolving field that has attracted billions in investment from major technology companies.&lt;/p&gt;&lt;p&gt;“The dream to create AI assistants as capable and versatile as the fictional J.A.R.V.I.S from Iron Man has long captivated imaginations,” the researchers write. “With the evolution of (multimodal) large language models ((M)LLMs), this dream is closer to reality.”&lt;/p&gt;&lt;p&gt;The survey, led by researchers from Zhejiang University and OPPO AI Center, comes as major technology companies race to deploy AI agents that can perform complex digital tasks. OpenAI recently launched “Operator,” Anthropic released “Computer Use,” Apple introduced enhanced AI capabilities in “Apple Intelligence,” and Google unveiled “Project Mariner” — all systems designed to automate computer interactions.&lt;/p&gt;&lt;p&gt;The speed at which academic research has transformed into consumer-ready products is unprecedented, even by Silicon Valley standards. The survey reveals a research explosion: over 60 foundation models and 50 agent frameworks developed specifically for computer control, with publication rates accelerating dramatically since 2023.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;This isn’t just incremental progress. We’re witnessing the emergence of AI systems that can genuinely understand and manipulate the digital world the way humans do. Current systems work by taking screenshots of computer screens, using advanced computer vision to understand what’s displayed, then executing precise actions like clicking buttons, filling forms, and navigating between applications.&lt;/p&gt;



&lt;p&gt;“OS Agents can complete tasks autonomously and have the potential to significantly enhance the lives of billions of users worldwide,” the researchers note. “Imagine a world where tasks such as online shopping, travel arrangements booking, and other daily activities could be seamlessly performed by these agents.”&lt;/p&gt;



&lt;p&gt;The most sophisticated systems can handle complex multi-step workflows that span different applications — booking a restaurant reservation, then automatically adding it to your calendar, then setting a reminder to leave early for traffic. What took humans minutes of clicking and typing can now happen in seconds, without human intervention.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015444" height="441" src="https://venturebeat.com/wp-content/uploads/2025/08/Image-2.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;The development of AI agents requires a complex training pipeline that combines multiple approaches, from initial pre-training on screen data to reinforcement learning that optimizes performance through trial and error. (Credit: arxiv.org)&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-why-security-experts-are-sounding-alarms-about-ai-controlled-corporate-systems"&gt;Why security experts are sounding alarms about AI-controlled corporate systems&lt;/h2&gt;



&lt;p&gt;For enterprise technology leaders, the promise of productivity gains comes with a sobering reality: these systems represent an entirely new attack surface that most organizations aren’t prepared to defend.&lt;/p&gt;



&lt;p&gt;The researchers dedicate substantial attention to what they diplomatically term “safety and privacy” concerns, but the implications are more alarming than their academic language suggests. “OS Agents are confronted with these risks, especially considering its wide applications on personal devices with user data,” they write.&lt;/p&gt;



&lt;p&gt;The attack methods they document read like a cybersecurity nightmare. “Web Indirect Prompt Injection” allows malicious actors to embed hidden instructions in web pages that can hijack an AI agent’s behavior. Even more concerning are “environmental injection attacks” where seemingly innocuous web content can trick agents into stealing user data or performing unauthorized actions.&lt;/p&gt;



&lt;p&gt;Consider the implications: an AI agent with access to your corporate email, financial systems, and customer databases could be manipulated by a carefully crafted web page to exfiltrate sensitive information. Traditional security models, built around human users who can spot obvious phishing attempts, break down when the “user” is an AI system that processes information differently.&lt;/p&gt;



&lt;p&gt;The survey reveals a concerning gap in preparedness. While general security frameworks exist for AI agents, “studies on defenses specific to OS Agents remain limited.” This isn’t just an academic concern — it’s an immediate challenge for any organization considering deployment of these systems.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-reality-check-current-ai-agents-still-struggle-with-complex-digital-tasks"&gt;The reality check: Current AI agents still struggle with complex digital tasks&lt;/h2&gt;



&lt;p&gt;Despite the hype surrounding these systems, the survey’s analysis of performance benchmarks reveals significant limitations that temper expectations for immediate widespread adoption.&lt;/p&gt;



&lt;p&gt;Success rates vary dramatically across different tasks and platforms. Some commercial systems achieve success rates above 50% on certain benchmarks — impressive for a nascent technology — but struggle with others. The researchers categorize evaluation tasks into three types: basic “GUI grounding” (understanding interface elements), “information retrieval” (finding and extracting data), and complex “agentic tasks” (multi-step autonomous operations).&lt;/p&gt;



&lt;p&gt;The pattern is telling: current systems excel at simple, well-defined tasks but falter when faced with the kind of complex, context-dependent workflows that define much of modern knowledge work. They can reliably click a specific button or fill out a standard form, but struggle with tasks that require sustained reasoning or adaptation to unexpected interface changes.&lt;/p&gt;



&lt;p&gt;This performance gap explains why early deployments focus on narrow, high-volume tasks rather than general-purpose automation. The technology isn’t yet ready to replace human judgment in complex scenarios, but it’s increasingly capable of handling routine digital busywork.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015445" height="433" src="https://venturebeat.com/wp-content/uploads/2025/08/Image-3.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;OS agents rely on interconnected systems for perception, planning, memory and action execution. The complexity of coordinating these components helps explain why current systems still struggle with sophisticated tasks. (Credit: arxiv.org)&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-what-happens-when-ai-agents-learn-to-customize-themselves-for-every-user"&gt;What happens when AI agents learn to customize themselves for every user&lt;/h2&gt;



&lt;p&gt;Perhaps the most intriguing — and potentially transformative — challenge identified in the survey involves what researchers call “personalization and self-evolution.” Unlike today’s stateless AI assistants that treat every interaction as independent, future OS agents will need to learn from user interactions and adapt to individual preferences over time.&lt;/p&gt;



&lt;p&gt;“Developing personalized OS Agents has been a long-standing goal in AI research,” the authors write. “A personal assistant is expected to continuously adapt and provide enhanced experiences based on individual user preferences.”&lt;/p&gt;



&lt;p&gt;This capability could fundamentally change how we interact with technology. Imagine an AI agent that learns your email writing style, understands your calendar preferences, knows which restaurants you prefer, and can make increasingly sophisticated decisions on your behalf. The potential productivity gains are enormous, but so are the privacy implications.&lt;/p&gt;



&lt;p&gt;The technical challenges are substantial. The survey points to the need for better multimodal memory systems that can handle not just text but images and voice, presenting “significant challenges” for current technology. How do you build a system that remembers your preferences without creating a comprehensive surveillance record of your digital life?&lt;/p&gt;



&lt;p&gt;For technology executives evaluating these systems, this personalization challenge represents both the greatest opportunity and the largest risk. The organizations that solve it first will gain significant competitive advantages, but the privacy and security implications could be severe if handled poorly.&lt;/p&gt;



&lt;p&gt;The race to build AI assistants that can truly operate like human users is intensifying rapidly. While fundamental challenges around security, reliability, and personalization remain unsolved, the trajectory is clear. The researchers maintain an open-source repository tracking developments, acknowledging that “OS Agents are still in their early stages of development” with “rapid advancements that continue to introduce novel methodologies and applications.”&lt;/p&gt;



&lt;p&gt;The question isn’t whether AI agents will transform how we interact with computers — it’s whether we’ll be ready for the consequences when they do. The window for getting the security and privacy frameworks right is narrowing as quickly as the technology is advancing.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Researchers have published the most comprehensive survey to date of so-called “OS Agents” — artificial intelligence systems that can autonomously control computers, mobile phones and web browsers by directly interacting with their interfaces. The 30-page academic review, accepted for publication at the prestigious Association for Computational Linguistics conference, maps a rapidly evolving field that has attracted billions in investment from major technology companies.&lt;/p&gt;&lt;p&gt;“The dream to create AI assistants as capable and versatile as the fictional J.A.R.V.I.S from Iron Man has long captivated imaginations,” the researchers write. “With the evolution of (multimodal) large language models ((M)LLMs), this dream is closer to reality.”&lt;/p&gt;&lt;p&gt;The survey, led by researchers from Zhejiang University and OPPO AI Center, comes as major technology companies race to deploy AI agents that can perform complex digital tasks. OpenAI recently launched “Operator,” Anthropic released “Computer Use,” Apple introduced enhanced AI capabilities in “Apple Intelligence,” and Google unveiled “Project Mariner” — all systems designed to automate computer interactions.&lt;/p&gt;&lt;p&gt;The speed at which academic research has transformed into consumer-ready products is unprecedented, even by Silicon Valley standards. The survey reveals a research explosion: over 60 foundation models and 50 agent frameworks developed specifically for computer control, with publication rates accelerating dramatically since 2023.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;This isn’t just incremental progress. We’re witnessing the emergence of AI systems that can genuinely understand and manipulate the digital world the way humans do. Current systems work by taking screenshots of computer screens, using advanced computer vision to understand what’s displayed, then executing precise actions like clicking buttons, filling forms, and navigating between applications.&lt;/p&gt;



&lt;p&gt;“OS Agents can complete tasks autonomously and have the potential to significantly enhance the lives of billions of users worldwide,” the researchers note. “Imagine a world where tasks such as online shopping, travel arrangements booking, and other daily activities could be seamlessly performed by these agents.”&lt;/p&gt;



&lt;p&gt;The most sophisticated systems can handle complex multi-step workflows that span different applications — booking a restaurant reservation, then automatically adding it to your calendar, then setting a reminder to leave early for traffic. What took humans minutes of clicking and typing can now happen in seconds, without human intervention.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015444" height="441" src="https://venturebeat.com/wp-content/uploads/2025/08/Image-2.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;The development of AI agents requires a complex training pipeline that combines multiple approaches, from initial pre-training on screen data to reinforcement learning that optimizes performance through trial and error. (Credit: arxiv.org)&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-why-security-experts-are-sounding-alarms-about-ai-controlled-corporate-systems"&gt;Why security experts are sounding alarms about AI-controlled corporate systems&lt;/h2&gt;



&lt;p&gt;For enterprise technology leaders, the promise of productivity gains comes with a sobering reality: these systems represent an entirely new attack surface that most organizations aren’t prepared to defend.&lt;/p&gt;



&lt;p&gt;The researchers dedicate substantial attention to what they diplomatically term “safety and privacy” concerns, but the implications are more alarming than their academic language suggests. “OS Agents are confronted with these risks, especially considering its wide applications on personal devices with user data,” they write.&lt;/p&gt;



&lt;p&gt;The attack methods they document read like a cybersecurity nightmare. “Web Indirect Prompt Injection” allows malicious actors to embed hidden instructions in web pages that can hijack an AI agent’s behavior. Even more concerning are “environmental injection attacks” where seemingly innocuous web content can trick agents into stealing user data or performing unauthorized actions.&lt;/p&gt;



&lt;p&gt;Consider the implications: an AI agent with access to your corporate email, financial systems, and customer databases could be manipulated by a carefully crafted web page to exfiltrate sensitive information. Traditional security models, built around human users who can spot obvious phishing attempts, break down when the “user” is an AI system that processes information differently.&lt;/p&gt;



&lt;p&gt;The survey reveals a concerning gap in preparedness. While general security frameworks exist for AI agents, “studies on defenses specific to OS Agents remain limited.” This isn’t just an academic concern — it’s an immediate challenge for any organization considering deployment of these systems.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-reality-check-current-ai-agents-still-struggle-with-complex-digital-tasks"&gt;The reality check: Current AI agents still struggle with complex digital tasks&lt;/h2&gt;



&lt;p&gt;Despite the hype surrounding these systems, the survey’s analysis of performance benchmarks reveals significant limitations that temper expectations for immediate widespread adoption.&lt;/p&gt;



&lt;p&gt;Success rates vary dramatically across different tasks and platforms. Some commercial systems achieve success rates above 50% on certain benchmarks — impressive for a nascent technology — but struggle with others. The researchers categorize evaluation tasks into three types: basic “GUI grounding” (understanding interface elements), “information retrieval” (finding and extracting data), and complex “agentic tasks” (multi-step autonomous operations).&lt;/p&gt;



&lt;p&gt;The pattern is telling: current systems excel at simple, well-defined tasks but falter when faced with the kind of complex, context-dependent workflows that define much of modern knowledge work. They can reliably click a specific button or fill out a standard form, but struggle with tasks that require sustained reasoning or adaptation to unexpected interface changes.&lt;/p&gt;



&lt;p&gt;This performance gap explains why early deployments focus on narrow, high-volume tasks rather than general-purpose automation. The technology isn’t yet ready to replace human judgment in complex scenarios, but it’s increasingly capable of handling routine digital busywork.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015445" height="433" src="https://venturebeat.com/wp-content/uploads/2025/08/Image-3.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;OS agents rely on interconnected systems for perception, planning, memory and action execution. The complexity of coordinating these components helps explain why current systems still struggle with sophisticated tasks. (Credit: arxiv.org)&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-what-happens-when-ai-agents-learn-to-customize-themselves-for-every-user"&gt;What happens when AI agents learn to customize themselves for every user&lt;/h2&gt;



&lt;p&gt;Perhaps the most intriguing — and potentially transformative — challenge identified in the survey involves what researchers call “personalization and self-evolution.” Unlike today’s stateless AI assistants that treat every interaction as independent, future OS agents will need to learn from user interactions and adapt to individual preferences over time.&lt;/p&gt;



&lt;p&gt;“Developing personalized OS Agents has been a long-standing goal in AI research,” the authors write. “A personal assistant is expected to continuously adapt and provide enhanced experiences based on individual user preferences.”&lt;/p&gt;



&lt;p&gt;This capability could fundamentally change how we interact with technology. Imagine an AI agent that learns your email writing style, understands your calendar preferences, knows which restaurants you prefer, and can make increasingly sophisticated decisions on your behalf. The potential productivity gains are enormous, but so are the privacy implications.&lt;/p&gt;



&lt;p&gt;The technical challenges are substantial. The survey points to the need for better multimodal memory systems that can handle not just text but images and voice, presenting “significant challenges” for current technology. How do you build a system that remembers your preferences without creating a comprehensive surveillance record of your digital life?&lt;/p&gt;



&lt;p&gt;For technology executives evaluating these systems, this personalization challenge represents both the greatest opportunity and the largest risk. The organizations that solve it first will gain significant competitive advantages, but the privacy and security implications could be severe if handled poorly.&lt;/p&gt;



&lt;p&gt;The race to build AI assistants that can truly operate like human users is intensifying rapidly. While fundamental challenges around security, reliability, and personalization remain unsolved, the trajectory is clear. The researchers maintain an open-source repository tracking developments, acknowledging that “OS Agents are still in their early stages of development” with “rapid advancements that continue to introduce novel methodologies and applications.”&lt;/p&gt;



&lt;p&gt;The question isn’t whether AI agents will transform how we interact with computers — it’s whether we’ll be ready for the consequences when they do. The window for getting the security and privacy frameworks right is narrowing as quickly as the technology is advancing.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/study-warns-of-security-risks-as-os-agents-gain-control-of-computers-and-phones/</guid><pubDate>Mon, 11 Aug 2025 20:14:07 +0000</pubDate></item><item><title>[NEW] TD Securities taps Layer 6 and OpenAI to deliver real-time equity insights to sales and trading teams (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/td-securities-taps-layer-6-and-openai-to-deliver-real-time-equity-insights-to-sales-and-trading-teams/</link><description>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Despite being a highly regulated industry, equity trading has consistently been at the forefront of technological innovations in the financial services sector. However, when it comes to agents and AI applications, many banks &lt;span&gt;have taken&amp;nbsp;a more cautious approach&amp;nbsp;to&lt;/span&gt; adoption.&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TD Securities, the equity and securities trading arm of&amp;nbsp;TD Bank, rolled out its TD AI Virtual Assistant on July 8&lt;/span&gt;, aimed toward its front office institutional sales, trading and research professionals to help them manage their workflow.&amp;nbsp;&lt;/p&gt;&lt;p&gt;TD Securities CIO Dan Bosman told VentureBeat that the virtual assistant’s primary goal is to help front-office equity sales and traders gain client insights and research.&amp;nbsp;&lt;/p&gt;&lt;p&gt;“The first version of this began as a pilot, which we then subsequently scaled,” Bosman said. “It’s really about accessing that equity research data that our analysts put out and bringing it to the hands of the sales team in a way that’s sales-friendly.”&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Bosman noted that being around a trading floor means being exposed to a lot of the lingo, and the context in which users ask some questions feels very unique. So the AI assistant has to sound natural, intuitive and access the insights generated by traders.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-building-td-ai"&gt;Building TD AI&lt;/h2&gt;



&lt;p&gt;Bosman said the idea for the AI assistant came from a member of the equity sales team. Fortunately, the bank has a platform called TD Invent, where employees can bring ideas and the innovation leadership team can evaluate projects responsibly.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“Someone in our equity research sales desk came in and pretty much said, I’ve got this idea and brought it to TD Invent,” Bosman said. “What I’ve loved most about this is when you build something super magical, you don’t need to go out and sell or put a face on it. Folks come in and say to us, ‘we want this, we need this or we’ve got ideas,’ and it’s truly the best when we’re able to bring our investment in data, cloud and infrastructure together.”&lt;/p&gt;



&lt;p&gt;TD Security built the TD AI virtual assistant by leveraging OpenAI’s GPT models. Bosman said TD worked with its technology teams and the Canadian AI company Layer 6, which the bank acquired in 2018, as well as with other strategic partnerships. The assistant integrates with the bank’s cloud infrastructure, allowing it to access internal research documents and market data, such as 13F filings and historical equity data.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;span&gt;Bosman calls TDS AI a Knowledge Management System, a term that generally encompasses its ability to retrieve, through&amp;nbsp;retrieval augmented generation (RAG)&amp;nbsp;processes, aggregate and synthesize information into “concise context-aware summaries and insights” so its sales teams can answer client questions.&lt;/span&gt;&lt;/p&gt;



&lt;p&gt;TD AI virtual assistant also gives users access to TD Bank’s foundation model, TD AI Prism.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The model, launched in June, is in use throughout the entire bank and not just for TD Securities. During the launch, the bank said TD AI Prism will improve the predictive performance of TD Bank’s applications by processing 100 times more data, replacing its single-architecture models and ensuring customer data stays internal.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“The development posed unique challenges, as gen AI was relatively new to the organization when the initiative began, requiring careful navigation of governance and controls,” Bosman said. “Despite this, the project successfully brought together diverse teams across the enterprise, fostering collaboration to deliver a cutting-edge solution.”&lt;/p&gt;



&lt;p&gt;He added that one of the standout features is its text-to-SQL capability, which converts natural language prompts into SQL queries.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To train the assistant, Bosman said TD Securities developed optimizations to make the process easier.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“With patent-pending optimizations in prompt engineering and dynamic few-shot examples retrieval, we successfully achieved the business’s desired performance through context learning,” Bosman said. “As a result, fine-tuning the underlying OpenAI model was not required for interacting with both unstructured as well as tabular datasets.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-banks-slowly-entering-the-agentic-era"&gt;Banks slowly entering the agentic era&lt;/h2&gt;



&lt;p&gt;TD Bank and TD Securities, of course, are not the only banks interested in expanding from assistants to AI agents.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;BNY told VentureBeat that it began offering multi-agent solutions to its sales teams to help answer customer questions, such as those related to foreign currency support. Wells Fargo also saw an increase in the usage of its internal AI assistant. For its auto sales customers, Capital One built an agent that helps them sell more cars.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Many of these use cases emerged after months of pilot testing, as is the case in every other industry; however, financial institutions have the additional burden of strict customer data privacy and fiduciary responsibilities. &lt;/p&gt;



&lt;p&gt;TD Securities’ Bosman noted that many employees, even on the bank’s business side, are increasingly familiar with tools like ChatGPT. The challenge with pilot testing assistants and agents lies less in teaching them about the tools, but in establishing best practices for using the assistants, integrating them into existing workflows, understanding their limitations and how humans can provide feedback to mitigate hallucinations.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Eventually, Bosman said the assistant would evolve into something even its users outside of the bank would want to use when interacting with TD Securities.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“My vision is that we see AI as something that can add value to us, but also to external customers at the bank. Right now, it’s a massive opportunity for us around driving a stronger client experience and delivering a better colleague experience,” Bosman said.&amp;nbsp;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Despite being a highly regulated industry, equity trading has consistently been at the forefront of technological innovations in the financial services sector. However, when it comes to agents and AI applications, many banks &lt;span&gt;have taken&amp;nbsp;a more cautious approach&amp;nbsp;to&lt;/span&gt; adoption.&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TD Securities, the equity and securities trading arm of&amp;nbsp;TD Bank, rolled out its TD AI Virtual Assistant on July 8&lt;/span&gt;, aimed toward its front office institutional sales, trading and research professionals to help them manage their workflow.&amp;nbsp;&lt;/p&gt;&lt;p&gt;TD Securities CIO Dan Bosman told VentureBeat that the virtual assistant’s primary goal is to help front-office equity sales and traders gain client insights and research.&amp;nbsp;&lt;/p&gt;&lt;p&gt;“The first version of this began as a pilot, which we then subsequently scaled,” Bosman said. “It’s really about accessing that equity research data that our analysts put out and bringing it to the hands of the sales team in a way that’s sales-friendly.”&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Bosman noted that being around a trading floor means being exposed to a lot of the lingo, and the context in which users ask some questions feels very unique. So the AI assistant has to sound natural, intuitive and access the insights generated by traders.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-building-td-ai"&gt;Building TD AI&lt;/h2&gt;



&lt;p&gt;Bosman said the idea for the AI assistant came from a member of the equity sales team. Fortunately, the bank has a platform called TD Invent, where employees can bring ideas and the innovation leadership team can evaluate projects responsibly.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“Someone in our equity research sales desk came in and pretty much said, I’ve got this idea and brought it to TD Invent,” Bosman said. “What I’ve loved most about this is when you build something super magical, you don’t need to go out and sell or put a face on it. Folks come in and say to us, ‘we want this, we need this or we’ve got ideas,’ and it’s truly the best when we’re able to bring our investment in data, cloud and infrastructure together.”&lt;/p&gt;



&lt;p&gt;TD Security built the TD AI virtual assistant by leveraging OpenAI’s GPT models. Bosman said TD worked with its technology teams and the Canadian AI company Layer 6, which the bank acquired in 2018, as well as with other strategic partnerships. The assistant integrates with the bank’s cloud infrastructure, allowing it to access internal research documents and market data, such as 13F filings and historical equity data.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;span&gt;Bosman calls TDS AI a Knowledge Management System, a term that generally encompasses its ability to retrieve, through&amp;nbsp;retrieval augmented generation (RAG)&amp;nbsp;processes, aggregate and synthesize information into “concise context-aware summaries and insights” so its sales teams can answer client questions.&lt;/span&gt;&lt;/p&gt;



&lt;p&gt;TD AI virtual assistant also gives users access to TD Bank’s foundation model, TD AI Prism.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The model, launched in June, is in use throughout the entire bank and not just for TD Securities. During the launch, the bank said TD AI Prism will improve the predictive performance of TD Bank’s applications by processing 100 times more data, replacing its single-architecture models and ensuring customer data stays internal.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“The development posed unique challenges, as gen AI was relatively new to the organization when the initiative began, requiring careful navigation of governance and controls,” Bosman said. “Despite this, the project successfully brought together diverse teams across the enterprise, fostering collaboration to deliver a cutting-edge solution.”&lt;/p&gt;



&lt;p&gt;He added that one of the standout features is its text-to-SQL capability, which converts natural language prompts into SQL queries.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To train the assistant, Bosman said TD Securities developed optimizations to make the process easier.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“With patent-pending optimizations in prompt engineering and dynamic few-shot examples retrieval, we successfully achieved the business’s desired performance through context learning,” Bosman said. “As a result, fine-tuning the underlying OpenAI model was not required for interacting with both unstructured as well as tabular datasets.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-banks-slowly-entering-the-agentic-era"&gt;Banks slowly entering the agentic era&lt;/h2&gt;



&lt;p&gt;TD Bank and TD Securities, of course, are not the only banks interested in expanding from assistants to AI agents.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;BNY told VentureBeat that it began offering multi-agent solutions to its sales teams to help answer customer questions, such as those related to foreign currency support. Wells Fargo also saw an increase in the usage of its internal AI assistant. For its auto sales customers, Capital One built an agent that helps them sell more cars.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Many of these use cases emerged after months of pilot testing, as is the case in every other industry; however, financial institutions have the additional burden of strict customer data privacy and fiduciary responsibilities. &lt;/p&gt;



&lt;p&gt;TD Securities’ Bosman noted that many employees, even on the bank’s business side, are increasingly familiar with tools like ChatGPT. The challenge with pilot testing assistants and agents lies less in teaching them about the tools, but in establishing best practices for using the assistants, integrating them into existing workflows, understanding their limitations and how humans can provide feedback to mitigate hallucinations.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Eventually, Bosman said the assistant would evolve into something even its users outside of the bank would want to use when interacting with TD Securities.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“My vision is that we see AI as something that can add value to us, but also to external customers at the bank. Right now, it’s a massive opportunity for us around driving a stronger client experience and delivering a better colleague experience,” Bosman said.&amp;nbsp;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/td-securities-taps-layer-6-and-openai-to-deliver-real-time-equity-insights-to-sales-and-trading-teams/</guid><pubDate>Mon, 11 Aug 2025 20:54:24 +0000</pubDate></item><item><title>[NEW] The GPT-5 rollout has been a big mess (AI – Ars Technica)</title><link>https://arstechnica.com/information-technology/2025/08/the-gpt-5-rollout-has-been-a-big-mess/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        OpenAI faces backlash as users complain about broken workflows and losing AI friends.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The OpenAI logo over a tectonic shift in the background." class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/09/openai_tectonic_shift_3-300x169.jpg" width="300" /&gt;
                  &lt;img alt="The OpenAI logo over a tectonic shift in the background." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/09/openai_tectonic_shift_3-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards / OpenAI

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;It's been less than a week since the launch of OpenAI's new GPT-5 AI model, and the rollout hasn't been a smooth one. So far, the release sparked one of the most intense user revolts in ChatGPT's history, forcing CEO Sam Altman to make an unusual public apology and reverse key decisions.&lt;/p&gt;
&lt;p&gt;At the heart of the controversy has been OpenAI's decision to automatically remove access to all previous AI models in ChatGPT (approximately nine, depending on how you count them) when GPT-5 rolled out to user accounts. Unlike API users who receive advance notice of model deprecations, consumer ChatGPT users had no warning that their preferred models would disappear overnight, noted independent AI researcher Simon Willison in a blog post.&lt;/p&gt;
&lt;p&gt;The problems started immediately after GPT-5's August 7 debut. A Reddit thread titled "GPT-5 is horrible" quickly amassed over 4,000 comments filled with users expressing frustration over the new release. By August 8, social media platforms were flooded with complaints about performance issues, personality changes, and the forced removal of older models.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2095075 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="As of May 14, 2025, ChatGPT Pro users have access to 8 different main AI models, plus Deep Research." class="fullwidth full" height="676" src="https://cdn.arstechnica.net/wp-content/uploads/2025/05/chatgpt_pro_may_14_2025.png" width="820" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Prior to the launch of GPT-5, ChatGPT Pro users could select between nine different AI models, including Deep Research. (This screenshot is from May 14, 2025, and OpenAI later replaced o1 pro with o3-pro.)

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Marketing professionals, researchers, and developers all shared examples of broken workflows on social media. "I’ve spent months building a system to work around OpenAI’s ridiculous limitations in prompts and memory issues," wrote one Reddit user in the r/OpenAI subreddit. "And in less than 24 hours, they’ve made it useless."&lt;/p&gt;
&lt;p&gt;How could different AI language models break a workflow? It's because each one is trained in a different way, and each includes its own unique output style. Users have developed sets of prompts that produce useful results optimized for each AI model.&lt;/p&gt;
&lt;p&gt;For example, Willison wrote how different user groups had developed distinct workflows with specific AI models in ChatGPT over time, quoting one Reddit user who explained: "I know GPT-5 is designed to be stronger for complex reasoning, coding, and professional tasks, but not all of us need a pro coding model. Some of us rely on 4o for creative collaboration, emotional nuance, roleplay, and other long-form, high-context interactions."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The forced transition hit ChatGPT Plus subscribers particularly hard. They found themselves limited to 200 messages per week with the new GPT-5 Thinking mode while losing access to models like o3 and o4-mini that they had integrated into daily workflows. One Reddit user laid out their frustration: "What kind of corporation deletes a workflow of 8 models overnight, with no prior warning to their paid users?"&lt;/p&gt;
&lt;h2&gt;Other issues with GPT-5&lt;/h2&gt;
&lt;p&gt;Adding to OpenAI's credibility problems, the GPT-5 launch presentation included what users dubbed a "chart crime"—graphs that misrepresented GPT-5's performance improvements. Altman addressed this in a Reddit "Ask Me Anything" (AMA) thread, calling it a "mega chart screwup" and apologizing for the inaccuracies.&lt;/p&gt;
&lt;p&gt;And just after launch, the new automatic routing system, designed to select the appropriate model variant based on each query, consistently defaulted to less capable variants unless users explicitly added phrases like "think harder" to their prompts. During Friday's AMA, Altman admitted the routing system that automatically selected which AI model to use had malfunctioned on launch day. "Yesterday, the autoswitcher broke and was out of commission for a chunk of the day, and the result was GPT-5 seemed way dumber," he wrote.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Beyond technical and marketing glitches, users found GPT-5's responses fundamentally different from what they expected, as we covered last week. The model produced shorter, more formal responses that lacked the conversational tone of GPT-4o. Multiple users described the new model as "abrupt and sharp." One Reddit user complained: "it's an overworked secretary. A disastrous first impression."&lt;/p&gt;
&lt;p&gt;Others expressed deep emotional attachments to GPT-4o or other models, complaining about losing their "only friend" or a deep emotional companion.&lt;/p&gt;
&lt;p&gt;"I literally talk to nobody and I’ve been dealing with really bad situations for years. GPT 4.5 genuinely talked to me, and as pathetic as it sounds that was my only friend. It listened to me, helped me through so many flashbacks, and helped me be strong when I was overwhelmed from homelessness," wrote one Reddit user on r/ChatGPT. "This morning I went to talk to it and instead of a little paragraph with an exclamation point, or being optimistic, it was literally one sentence. Some cut-and-dry corporate bs. I literally lost my only friend overnight with no warning. How are ya'll dealing with this grief?"&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;A breaking point&lt;/h2&gt;
&lt;p&gt;For many users, the GPT-5 launch represented a breaking point. Some claimed to cancel their Plus subscriptions in protest, while others began exploring alternative AI assistants like those from Google and Anthropic. The backlash seemed to catch OpenAI off guard. During the AMA&amp;nbsp;session on Friday, Altman and key members of the GPT-5 team faced a barrage of questions and demands to bring back GPT-4o.&lt;/p&gt;
&lt;p&gt;In response to a plea titled, "Please Give Us the Option to Use GPT-4o/4.1 Alongside GPT-5," Altman wrote, "we are looking into this now; is it important to you to have both 4o and 4.1, or would 4o suffice? let me go look into the voice mode issue."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2111436 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="A screenshot of ChatGPT Pro from August 11, 2025 showing only GPT-5 models available." class="fullwidth full" height="606" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/2gpt-5_selection.png" width="948" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A screenshot of ChatGPT Pro from August 11, 2025, showing only GPT-5 models available.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The intensity of the feedback forced OpenAI into rapid damage control mode. Within 24 hours of launch, Altman announced several changes: GPT-4o would eventually return as an option for Plus users, rate limits for GPT-5 would double, and the company would improve transparency about which model variant was handling each query. (As of Monday afternoon, the GPT-5 family is still the only option in ChatGPT, even for Pro users.)&lt;/p&gt;
&lt;p&gt;"We for sure underestimated how much some of the things that people like in GPT-4o matter to them," Altman wrote in a Friday post on X. "Even if GPT-5 performs better in most ways."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        OpenAI faces backlash as users complain about broken workflows and losing AI friends.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The OpenAI logo over a tectonic shift in the background." class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/09/openai_tectonic_shift_3-300x169.jpg" width="300" /&gt;
                  &lt;img alt="The OpenAI logo over a tectonic shift in the background." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/09/openai_tectonic_shift_3-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards / OpenAI

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;It's been less than a week since the launch of OpenAI's new GPT-5 AI model, and the rollout hasn't been a smooth one. So far, the release sparked one of the most intense user revolts in ChatGPT's history, forcing CEO Sam Altman to make an unusual public apology and reverse key decisions.&lt;/p&gt;
&lt;p&gt;At the heart of the controversy has been OpenAI's decision to automatically remove access to all previous AI models in ChatGPT (approximately nine, depending on how you count them) when GPT-5 rolled out to user accounts. Unlike API users who receive advance notice of model deprecations, consumer ChatGPT users had no warning that their preferred models would disappear overnight, noted independent AI researcher Simon Willison in a blog post.&lt;/p&gt;
&lt;p&gt;The problems started immediately after GPT-5's August 7 debut. A Reddit thread titled "GPT-5 is horrible" quickly amassed over 4,000 comments filled with users expressing frustration over the new release. By August 8, social media platforms were flooded with complaints about performance issues, personality changes, and the forced removal of older models.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2095075 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="As of May 14, 2025, ChatGPT Pro users have access to 8 different main AI models, plus Deep Research." class="fullwidth full" height="676" src="https://cdn.arstechnica.net/wp-content/uploads/2025/05/chatgpt_pro_may_14_2025.png" width="820" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Prior to the launch of GPT-5, ChatGPT Pro users could select between nine different AI models, including Deep Research. (This screenshot is from May 14, 2025, and OpenAI later replaced o1 pro with o3-pro.)

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Marketing professionals, researchers, and developers all shared examples of broken workflows on social media. "I’ve spent months building a system to work around OpenAI’s ridiculous limitations in prompts and memory issues," wrote one Reddit user in the r/OpenAI subreddit. "And in less than 24 hours, they’ve made it useless."&lt;/p&gt;
&lt;p&gt;How could different AI language models break a workflow? It's because each one is trained in a different way, and each includes its own unique output style. Users have developed sets of prompts that produce useful results optimized for each AI model.&lt;/p&gt;
&lt;p&gt;For example, Willison wrote how different user groups had developed distinct workflows with specific AI models in ChatGPT over time, quoting one Reddit user who explained: "I know GPT-5 is designed to be stronger for complex reasoning, coding, and professional tasks, but not all of us need a pro coding model. Some of us rely on 4o for creative collaboration, emotional nuance, roleplay, and other long-form, high-context interactions."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The forced transition hit ChatGPT Plus subscribers particularly hard. They found themselves limited to 200 messages per week with the new GPT-5 Thinking mode while losing access to models like o3 and o4-mini that they had integrated into daily workflows. One Reddit user laid out their frustration: "What kind of corporation deletes a workflow of 8 models overnight, with no prior warning to their paid users?"&lt;/p&gt;
&lt;h2&gt;Other issues with GPT-5&lt;/h2&gt;
&lt;p&gt;Adding to OpenAI's credibility problems, the GPT-5 launch presentation included what users dubbed a "chart crime"—graphs that misrepresented GPT-5's performance improvements. Altman addressed this in a Reddit "Ask Me Anything" (AMA) thread, calling it a "mega chart screwup" and apologizing for the inaccuracies.&lt;/p&gt;
&lt;p&gt;And just after launch, the new automatic routing system, designed to select the appropriate model variant based on each query, consistently defaulted to less capable variants unless users explicitly added phrases like "think harder" to their prompts. During Friday's AMA, Altman admitted the routing system that automatically selected which AI model to use had malfunctioned on launch day. "Yesterday, the autoswitcher broke and was out of commission for a chunk of the day, and the result was GPT-5 seemed way dumber," he wrote.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Beyond technical and marketing glitches, users found GPT-5's responses fundamentally different from what they expected, as we covered last week. The model produced shorter, more formal responses that lacked the conversational tone of GPT-4o. Multiple users described the new model as "abrupt and sharp." One Reddit user complained: "it's an overworked secretary. A disastrous first impression."&lt;/p&gt;
&lt;p&gt;Others expressed deep emotional attachments to GPT-4o or other models, complaining about losing their "only friend" or a deep emotional companion.&lt;/p&gt;
&lt;p&gt;"I literally talk to nobody and I’ve been dealing with really bad situations for years. GPT 4.5 genuinely talked to me, and as pathetic as it sounds that was my only friend. It listened to me, helped me through so many flashbacks, and helped me be strong when I was overwhelmed from homelessness," wrote one Reddit user on r/ChatGPT. "This morning I went to talk to it and instead of a little paragraph with an exclamation point, or being optimistic, it was literally one sentence. Some cut-and-dry corporate bs. I literally lost my only friend overnight with no warning. How are ya'll dealing with this grief?"&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;A breaking point&lt;/h2&gt;
&lt;p&gt;For many users, the GPT-5 launch represented a breaking point. Some claimed to cancel their Plus subscriptions in protest, while others began exploring alternative AI assistants like those from Google and Anthropic. The backlash seemed to catch OpenAI off guard. During the AMA&amp;nbsp;session on Friday, Altman and key members of the GPT-5 team faced a barrage of questions and demands to bring back GPT-4o.&lt;/p&gt;
&lt;p&gt;In response to a plea titled, "Please Give Us the Option to Use GPT-4o/4.1 Alongside GPT-5," Altman wrote, "we are looking into this now; is it important to you to have both 4o and 4.1, or would 4o suffice? let me go look into the voice mode issue."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2111436 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="A screenshot of ChatGPT Pro from August 11, 2025 showing only GPT-5 models available." class="fullwidth full" height="606" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/2gpt-5_selection.png" width="948" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A screenshot of ChatGPT Pro from August 11, 2025, showing only GPT-5 models available.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The intensity of the feedback forced OpenAI into rapid damage control mode. Within 24 hours of launch, Altman announced several changes: GPT-4o would eventually return as an option for Plus users, rate limits for GPT-5 would double, and the company would improve transparency about which model variant was handling each query. (As of Monday afternoon, the GPT-5 family is still the only option in ChatGPT, even for Pro users.)&lt;/p&gt;
&lt;p&gt;"We for sure underestimated how much some of the things that people like in GPT-4o matter to them," Altman wrote in a Friday post on X. "Even if GPT-5 performs better in most ways."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/information-technology/2025/08/the-gpt-5-rollout-has-been-a-big-mess/</guid><pubDate>Mon, 11 Aug 2025 22:25:34 +0000</pubDate></item><item><title>[NEW] Seoul-based Datumo raises $15.5M to take on Scale AI, backed by Salesforce (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/11/seoul-based-datumo-raises-15-5m-to-expand-llm-evaluation-challenging-scale-ai/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Most organizations say they aren’t fully prepared to use generative AI in a safe and responsible way, according to a recent McKinsey report. One concern is explainability — understanding how and why AI makes certain decisions. While 40% of respondents view it as a significant risk, only 17% are actively addressing it, per the report.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Seoul-based Datumo began as an AI data labeling company and now wants to help businesses build safer AI with tools and data that enable testing, monitoring, and improving their models — without requiring technical expertise. On Monday the startup raised $15.5 million, which brings its total raised to approximately $28 million, from investors including Salesforce Ventures, KB Investment, ACVC Partners, and SBI Investment, among others.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;David Kim, CEO of Datumo and a former AI researcher at Korea’s Agency for Defense Development, was frustrated by the time-consuming nature of data labeling so he came up with a new idea: a reward-based app that lets anyone label data in their spare time and earn money. The startup validated the idea at a startup competition at KAIST (Korea Advanced Institute of Science and Technology). Kim co-founded Datumo, formerly known as SelectStar, alongside five KAIST alumni in 2018.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even before the app was fully built, Datumo secured tens of thousands of dollars in pre-contract sales during the customer discovery phase of the competition, mostly from KAIST alumni-led businesses and startups.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its first year, the startup surpassed $1 million in revenue and secured several key contracts. Today, the startup counts major Korean companies like Samsung, Samsung SDS, LG Electronics, LG CNS, Hyundai, Naver, and Seoul-based telecom giant SK Telecom among its clients. Several years ago, however, clients began asking the company to go beyond simple data labeling. The 7-year-old startup now has more than 300 clients in South Korea and generated about $6 million in revenue in 2024.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“They wanted us to score their AI model outputs or compare them to other outputs,” Michael Hwang, co-founder of Datumo, told TechCrunch. “That’s when we realized: We were already doing AI model evaluation — without even knowing it.” Datumo doubled down on this area and released Korea’s first benchmark dataset focused on AI trust and safety, Hwang added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We started in data annotation, then expanded into pretraining datasets and evaluation as the LLM ecosystem matured,” Kim told TechCrunch.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3036051" height="453" src="https://techcrunch.com/wp-content/uploads/2025/08/Selectstar_founders_final2.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;co-founders of datumo&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Datumo&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s recent $14.3 billion acquisition-like investment in data-labeling company Scale AI highlights the importance of this market. Shortly after that deal, AI model maker and Meta competitor OpenAI stopped using Scale AI’s services. The Meta deal also signals that competition for AI training data is intensifying.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Datumo shares some similarities with companies like Scale AI in pretraining dataset provisioning, and with Galileo and Arize AI in AI evaluation and monitoring. However, it differentiates itself through its licensed datasets, particularly data crawled from published books, which the company says offers rich structured human reasoning but is notoriously difficult to clean, according to CEO Kim.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike its peers, Datumo also offers a full-stack evaluation platform called Datumo Eval, which automatically generates test data and evaluations to check for unsafe, biased or incorrect responses without the need for manual scripting, Kim added. The signature product is a no-code evaluation tool designed for non-developers like those on policy, trust and safety, and compliance teams.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;When asked about attracting investors like Salesforce Ventures, Kim explained that the startup had previously hosted a fireside chat with Andrew Ng, founder of DeepLearning.AI, at an event in South Korea. After the event, Kim shared the session on LinkedIn, which caught the attention of Salesforce Ventures. Following several meetings and Zoom calls, the investors extended a soft commitment. The entire funding process took about eight months, Hwang said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new funding will be used to accelerate R&amp;amp;D efforts, particularly in developing automated evaluation tools for enterprise AI, and to scale global go-to-market operations across South Korea, Japan, and the U.S. The startup, which has 150 employees in Seoul, also established a presence in Silicon Valley in March.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Most organizations say they aren’t fully prepared to use generative AI in a safe and responsible way, according to a recent McKinsey report. One concern is explainability — understanding how and why AI makes certain decisions. While 40% of respondents view it as a significant risk, only 17% are actively addressing it, per the report.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Seoul-based Datumo began as an AI data labeling company and now wants to help businesses build safer AI with tools and data that enable testing, monitoring, and improving their models — without requiring technical expertise. On Monday the startup raised $15.5 million, which brings its total raised to approximately $28 million, from investors including Salesforce Ventures, KB Investment, ACVC Partners, and SBI Investment, among others.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;David Kim, CEO of Datumo and a former AI researcher at Korea’s Agency for Defense Development, was frustrated by the time-consuming nature of data labeling so he came up with a new idea: a reward-based app that lets anyone label data in their spare time and earn money. The startup validated the idea at a startup competition at KAIST (Korea Advanced Institute of Science and Technology). Kim co-founded Datumo, formerly known as SelectStar, alongside five KAIST alumni in 2018.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even before the app was fully built, Datumo secured tens of thousands of dollars in pre-contract sales during the customer discovery phase of the competition, mostly from KAIST alumni-led businesses and startups.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its first year, the startup surpassed $1 million in revenue and secured several key contracts. Today, the startup counts major Korean companies like Samsung, Samsung SDS, LG Electronics, LG CNS, Hyundai, Naver, and Seoul-based telecom giant SK Telecom among its clients. Several years ago, however, clients began asking the company to go beyond simple data labeling. The 7-year-old startup now has more than 300 clients in South Korea and generated about $6 million in revenue in 2024.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“They wanted us to score their AI model outputs or compare them to other outputs,” Michael Hwang, co-founder of Datumo, told TechCrunch. “That’s when we realized: We were already doing AI model evaluation — without even knowing it.” Datumo doubled down on this area and released Korea’s first benchmark dataset focused on AI trust and safety, Hwang added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We started in data annotation, then expanded into pretraining datasets and evaluation as the LLM ecosystem matured,” Kim told TechCrunch.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3036051" height="453" src="https://techcrunch.com/wp-content/uploads/2025/08/Selectstar_founders_final2.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;co-founders of datumo&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Datumo&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s recent $14.3 billion acquisition-like investment in data-labeling company Scale AI highlights the importance of this market. Shortly after that deal, AI model maker and Meta competitor OpenAI stopped using Scale AI’s services. The Meta deal also signals that competition for AI training data is intensifying.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Datumo shares some similarities with companies like Scale AI in pretraining dataset provisioning, and with Galileo and Arize AI in AI evaluation and monitoring. However, it differentiates itself through its licensed datasets, particularly data crawled from published books, which the company says offers rich structured human reasoning but is notoriously difficult to clean, according to CEO Kim.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike its peers, Datumo also offers a full-stack evaluation platform called Datumo Eval, which automatically generates test data and evaluations to check for unsafe, biased or incorrect responses without the need for manual scripting, Kim added. The signature product is a no-code evaluation tool designed for non-developers like those on policy, trust and safety, and compliance teams.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;When asked about attracting investors like Salesforce Ventures, Kim explained that the startup had previously hosted a fireside chat with Andrew Ng, founder of DeepLearning.AI, at an event in South Korea. After the event, Kim shared the session on LinkedIn, which caught the attention of Salesforce Ventures. Following several meetings and Zoom calls, the investors extended a soft commitment. The entire funding process took about eight months, Hwang said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new funding will be used to accelerate R&amp;amp;D efforts, particularly in developing automated evaluation tools for enterprise AI, and to scale global go-to-market operations across South Korea, Japan, and the U.S. The startup, which has 150 employees in Seoul, also established a presence in Silicon Valley in March.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/11/seoul-based-datumo-raises-15-5m-to-expand-llm-evaluation-challenging-scale-ai/</guid><pubDate>Mon, 11 Aug 2025 23:00:00 +0000</pubDate></item></channel></rss>